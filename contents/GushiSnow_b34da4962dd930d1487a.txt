{"tags": ["Chainer", "\u81ea\u7136\u8a00\u8a9e\u51e6\u7406", "\u30cb\u30e5\u30fc\u30e9\u30eb\u30cd\u30c3\u30c8\u30ef\u30fc\u30af"], "context": " More than 1 year has passed since last update.\n\n\u30ea\u30ab\u30ec\u30f3\u30c8\u30cb\u30e5\u30fc\u30e9\u30eb\u30cd\u30c3\u30c8\u30ef\u30fc\u30af\u8a00\u8a9e\u30e2\u30c7\u30eb\n\u30ea\u30ab\u30ec\u30f3\u30c8\u30cb\u30e5\u30fc\u30e9\u30eb\u30cd\u30c3\u30c8\u30ef\u30fc\u30af\u8a00\u8a9e\u30e2\u30c7\u30eb\uff08\u30cb\u30e5\u30fc\u30e9\u30eb\u8a00\u8a9e\u30e2\u30c7\u30eb\uff09\u306b\u3064\u3044\u3066Chainer\u306e\u30b3\u30fc\u30c9\u3092\u4f7f\u3063\u3066\u89e3\u8aac\u3057\u3066\u307f\u307e\u3057\u305f\u3002\n\n\nGPU\u306b\u3064\u3044\u3066\n\u8a00\u8a9e\u51e6\u7406\u306f\u3059\u3054\u304f\u6642\u9593\u304c\u304b\u304b\u308b\u306e\u3067GPU\u8a2d\u5b9a\u3092\u304a\u30b9\u30b9\u30e1\u3057\u3066\u3044\u307e\u3059\u3002\n\u3057\u304b\u3057\u4e00\u6982\u306b\u4f7f\u3048\u3070\u826f\u3044\u3068\u3044\u3046\u3053\u3068\u3067\u306f\u306a\u304f\u4e0b\u8a18\u306e\u3088\u3046\u306a\u8a2d\u5b9a\u3067\u306f\u6709\u52b9\u306b\u50cd\u304d\u307e\u3059\u3002\n\u8a73\u7d30\u306a\u4ed5\u7d44\u307f\u306e\u4e2d\u8eab\u3092\u77e5\u308a\u305f\u3044\u65b9\u306f\u4e0b\u8a18\u3092\u3054\u89a7\u304f\u3060\u3055\u3044\u3002\nhttp://www.kumikomi.net/archives/2008/06/12gpu1.php?page=1\n\uff0a\u5f97\u610f\n\u884c\u5217\u8a08\u7b97\n\u30e1\u30e2\u30ea\u306b\u30b7\u30fc\u30b1\u30f3\u30b7\u30e3\u30eb\u306b\u30a2\u30af\u30bb\u30b9\u3057\u3001\u304b\u3064\u6761\u4ef6\u5206\u5c90\u306e\u7121\u3044\u8a08\u7b97\uff08\u6f14\u7b97\u5bc6\u5ea6\u306e\u9ad8\u3044\u51e6\u7406\uff09\u306b\u5f37\u3044\u3002\n\uff0a\u82e6\u624b\n\u4e8c\u5206\u63a2\u7d22\n\u30e1\u30e2\u30ea\u306b\u30e9\u30f3\u30c0\u30e0\u30a2\u30af\u30bb\u30b9\u3057\u3001\u304b\u3064\u6761\u4ef6\u5206\u5c90\u304c\u591a\u3044\u3002\n\nGPU\u30c9\u30e9\u30a4\u30d0\u8a2d\u5b9a\nAWS\u3067\u306eGPU\u8a2d\u5b9a\u306f\u4e0b\u8a18\u306e\u30b5\u30a4\u30c8\u3092\u53c2\u8003\u306b\u884c\u3044\u307e\u3057\u305f\u3002\nhttp://tleyden.github.io/blog/2014/10/25/cuda-6-dot-5-on-aws-gpu-instance-running-ubuntu-14-dot-04/\napt-get update && apt-get install build-essential\n\nCuda\u306e\u30a4\u30f3\u30b9\u30c8\u30fc\u30e9\u30fc\u3092\u53d6\u5f97\nwget http://developer.download.nvidia.com/compute/cuda/6_5/rel/installers/cuda_6.5.14_linux_64.run\n\nCuda\u306e\u30a4\u30f3\u30b9\u30c8\u30fc\u30e9\u30fc\u306e\u307f\u53d6\u5f97\nchmod +x cuda_6.5.14_linux_64.run\nmkdir nvidia_installers\n./cuda_6.5.14_linux_64.run -extract=`pwd`/nvidia_installers\n\nimage-extract\u3092\u53d6\u5f97\nsudo apt-get install linux-image-extra-virtual\n\n\u518d\u8d77\u52d5\nreboot\n\n\u30d5\u30a1\u30a4\u30eb\u3092\u4f5c\u6210\nvi /etc/modprobe.d/blacklist-nouveau.conf\n\nnouveau\u3068lbm-nouveau\u306e\u8d77\u52d5\u3057\u306a\u3044\u3088\u3046\u306b\u8a2d\u5b9a\nblacklist nouveau\nblacklist lbm-nouveau\noptions nouveau modeset=0\nalias nouveau off\nalias lbm-nouveau off\n\nKernel Nouveau\u3092\u8d77\u52d5\u3057\u306a\u3044\u3088\u3046\u306b\u8a2d\u5b9a\n echo options nouveau modeset=0 | sudo tee -a /etc/modprobe.d/nouveau-kms.conf\n\n\u30ab\u30fc\u30cd\u30eb\u8d77\u52d5\u6642\u306b\u3042\u3089\u304b\u3058\u3081\u30e1\u30e2\u30ea\u306b\u5c55\u958b\u3059\u308b\u3053\u3068\u3067\u30d5\u30a1\u30a4\u30eb\u30b7\u30b9\u30c6\u30e0\u3092\u69cb\u6210\u3059\u308b\u8a2d\u5b9a\u3092\u3057\u3066\u304b\u3089\u518d\u8d77\u52d5\nupdate-initramfs -u\nreboot\n\n\u30ab\u30fc\u30cd\u30eb\u306e\u30bd\u30fc\u30b9\u3092\u53d6\u5f97\napt-get install linux-source\napt-get install linux-headers-3.13.0-37-generic\n\nNVIDIA\u306e\u30c9\u30e9\u30a4\u30d0\u3092\u30a4\u30f3\u30b9\u30c8\u30fc\u30eb\ncd nvidia_installers\n./NVIDIA-Linux-x86_64-340.29.run\n\n\u4e0b\u8a18\u306e\u30a8\u30e9\u30fc\u5bfe\u5fdc\nNVIDIA driver install - Error: Unable to find the kernel source tree\n\nsudo apt-get install linux-headers-`uname -r`\n\n\u4e0b\u8a18\u306e\u30b3\u30de\u30f3\u30c9\u3067\u30c9\u30e9\u30a4\u30d0\u304c\u30a4\u30f3\u30b9\u30c8\u30fc\u30eb\u3055\u308c\u305f\u304b\u3092\u78ba\u8a8d\u3059\u308b\u3002\nnvidia-smi\nWed Aug  5 07:48:36 2015\n+------------------------------------------------------+\n| NVIDIA-SMI 340.29     Driver Version: 340.29         |\n|-------------------------------+----------------------+----------------------+\n| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n|===============================+======================+======================|\n|   0  GRID K520           Off  | 0000:00:03.0     Off |                  N/A |\n| N/A   54C    P0    80W / 125W |    391MiB /  4095MiB |     99%      Default |\n+-------------------------------+----------------------+----------------------+\n\n+-----------------------------------------------------------------------------+\n| Compute processes:                                               GPU Memory |\n|  GPU       PID  Process name                                     Usage      |\n|=============================================================================|\n|    0      8013  python                                               378MiB |\n+-----------------------------------------------------------------------------+\n\n\u4e0a\u8a18\u306eGPU\u306b\u632f\u3089\u308c\u3066\u3044\u308b\u756a\u53f7\u304cGPU\u306eID\u3067\u3042\u308b\u3002\u3053\u308c\u306f\u5f8c\u3067Chainer\u3092\u52d5\u4f5c\u3055\u305b\u308b\u3068\u304d\u306b\u4f7f\u7528\u3059\u308b\u3002\n\nPython\u306e\u8a2d\u5b9a\nPython3\u306e\u8a2d\u5b9a\u3092\u884c\u3044\u307e\u3057\u305f\u3002\n\u4e0b\u8a18\u306e\u30b3\u30de\u30f3\u30c9\u3092\u5b9f\u884c\u3057\u3066\u4e8b\u524d\u306b\u5fc5\u8981\u306a\u3082\u306e\u3092\u30a4\u30f3\u30b9\u30c8\u30fc\u30eb\u3057\u3066\u304a\u304f\n\napt-get update\napt-get install gcc gcc++ kmod perl python-dev\nsudo reboot\n\npip\u5c0e\u5165\u624b\u9806\nhttps://pip.pypa.io/en/stable/installing.html\nPyenv\u5c0e\u5165\u624b\u9806\nhttps://github.com/yyuu/pyenv\n\npip install virtualenv\n\npyenv install 3.4\n\nvirtualenv my_env -p = ~/.pyenv/versions/3.4.0/bin/python3.4\n\n\nrequirement.txt\u306e\u8a2d\u5b9a\u3092\u884c\u3044\u307e\u3057\u305f\u3002\nnumpy\nscikit-learn\nMako\nsix\nchainer\nscikit-cuda\n\n\u5fc5\u8981\u306a\u30e9\u30a4\u30d6\u30e9\u30ea\u3092\u30a4\u30f3\u30b9\u30c8\u30fc\u30eb\npip install -r requirement.txt\n\n\u4e0b\u8a18\u304b\u3089\"install-headers\"\u3092\u30c0\u30a6\u30f3\u30ed\u30fc\u30c9\u3057\u3066\u304f\u308b\u3002\nhttps://android.googlesource.com/toolchain/python/+/47a24ea6662f20c8e165d541ab6facdf009bfee4/Python-2.7.5/Lib/distutils/command/install_headers.py\nPyCuda\u306e\u30a4\u30f3\u30b9\u30c8\u30fc\u30eb\nwget https://pypi.python.org/packages/source/p/pycuda/pycuda-2015.1.2.tar.gz\ntar zxvf pycuda-2015.1.2.tar.gz\ncd pycuda-2015.1.2\n./configure.py\nmake\nmake install\n\n\nChainer \u30ea\u30ab\u30ec\u30f3\u30c8\u30cb\u30e5\u30fc\u30e9\u30eb\u8a00\u8a9e\u30e2\u30c7\u30eb\u3000\u30b5\u30f3\u30d7\u30eb\u30b3\u30fc\u30c9\n\u30b3\u30fc\u30c9\u69cb\u6210\u56f3\n\n\n\u5404\u7a2e\u30e9\u30a4\u30d6\u30e9\u30ea\u3092\u30a4\u30f3\u30dd\u30fc\u30c8\n\n#!/usr/bin/env python\n\"\"\"Sample script of recurrent neural network language model.\n\nThis code is ported from following implementation written in Torch.\nhttps://github.com/tomsercu/lstm\n\n\"\"\"\nimport argparse\nimport math\nimport sys\nimport time\n\nimport numpy as np\nimport six\n\nimport chainer\nfrom chainer import cuda\nimport chainer.functions as F\nfrom chainer import optimizers\n\n\n\n\u521d\u671f\u8a2d\u5b9a\n\u30fb\u5f15\u6570\u3067GPU\u3092\u4f7f\u7528\u3059\u308b\u304b\u3069\u3046\u304b\u3092\u5224\u65ad\u3057\u3066\u3044\u307e\u3059\u3002\n\u30fbGPU\u304c\u6307\u5b9a\u3055\u308c\u308c\u3070cuda\u3092\u5b9f\u884c\u3059\u308b\u3088\u3046\u306b\u8a2d\u5b9a\u3055\u308c\u3066\u3044\u307e\u3059\u3002\n\u30fb\u5b66\u7fd2\u56de\u6570\u3001\u30e6\u30cb\u30c3\u30c8\u6570\u3001\u78ba\u7387\u7684\u52fe\u914d\u6cd5\u306b\u4f7f\u7528\u3059\u308b\u30c7\u30fc\u30bf\u306e\u6570\u3001\u5b66\u7fd2\u306b\u4f7f\u7528\u3059\u308b\u6587\u5b57\u5217\u306e\u9577\u3055\u3001\u52fe\u914d\u6cd5\u3067\u4f7f\u7528\u3059\u308b\u6577\u5c45\u5024\u3092\u8a2d\u5b9a\u3057\u3066\u3044\u307e\u3059\u3002\n\nparser = argparse.ArgumentParser()\nparser.add_argument('--gpu', '-g', default=-1, type=int,\n                    help='GPU ID (negative value indicates CPU)')\nargs = parser.parse_args()\nmod = cuda if args.gpu >= 0 else np\n\nn_epoch = 39   # number of epochs\nn_units = 650  # number of units per layer\nbatchsize = 20   # minibatch size\nbprop_len = 35   # length of truncated BPTT\ngrad_clip = 5    # gradient norm threshold to clip\n\n\n\n\u30c7\u30fc\u30bf\u4fdd\u6301\n\u4e88\u3081download.py\u3067\u30c0\u30a6\u30f3\u30ed\u30fc\u30c9\u3057\u305f\u30d5\u30a1\u30a4\u30eb\u3092\u30d7\u30ed\u30b0\u30e9\u30e0\u306b\u8aad\u307e\u305b\u308b\u51e6\u7406\u3092\u95a2\u6570\u5316\u3057\u3066\u3044\u307e\u3059\u3002\n\u30fb\u6700\u7d42\u6587\u5b57\u3092\u6539\u884c\u304b\u3089<eos>\u306b\u5909\u66f4\u3057\u3066\u3044\u307e\u3059\u3002<eos>\u306f\u6700\u7d42\u6587\u5b57\u3092\u8868\u3059\u660e\u793a\u7684\u306a\u7269\u306a\u306e\u3067\u6539\u884c\u30b3\u30fc\u30c9\u3092\u7f6e\u304d\u63db\u3048\u3066\u660e\u793a\u7684\u306b\u6700\u7d42\u6587\u5b57\u306b\u3057\u3066\u3044\u307e\u3059\u3002\n\u30fb\u6587\u5b57\u30c7\u30fc\u30bf\u3092\u78ba\u4fdd\u3059\u308b\u305f\u3081\u306e\u884c\u5217\u3092\u5b9a\u7fa9\u3057\u3066\u3044\u307e\u3059\u3002\n\u30fb\u30c7\u30fc\u30bf\u3092\u5358\u8a9e\u3092\u30ad\u30fc\u3001\u9577\u3055\u3092\u5024\u3068\u3057\u305f\u8f9e\u66f8\u30c7\u30fc\u30bf\u306b\u3057\u3066\u884c\u5217\u30c7\u30fc\u30bf\u30bb\u30c3\u30c8\u306b\u767b\u9332\u3057\u3066\u3044\u307e\u3059\u3002\n\u5b66\u7fd2\u30c7\u30fc\u30bf\nvalid\u30c7\u30fc\u30bf\n\u30c6\u30b9\u30c8\u30c7\u30fc\u30bf\n\u4e0a\u8a18\u3092\u305d\u308c\u305e\u308c\u884c\u5217\u30c7\u30fc\u30bf\u3068\u3057\u3066\u4fdd\u6301\u3057\u3066\u3044\u307e\u3059\u3002\n# Prepare dataset (preliminary download dataset by ./download.py)\nvocab = {}\n\n\ndef load_data(filename):\n    global vocab, n_vocab\n    words = open(filename).read().replace('\\n', '<eos>').strip().split()\n    dataset = np.ndarray((len(words),), dtype=np.int32)\n    for i, word in enumerate(words):\n        if word not in vocab:\n            vocab[word] = len(vocab)\n        dataset[i] = vocab[word]\n    return dataset\n\ntrain_data = load_data('ptb.train.txt')\nvalid_data = load_data('ptb.valid.txt')\ntest_data = load_data('ptb.test.txt')\nprint('#vocab =', len(vocab))\n\n\n\n\u30ea\u30ab\u30ec\u30f3\u30c8\u30cb\u30e5\u30fc\u30e9\u30eb\u8a00\u8a9e\u30e2\u30c7\u30eb\nRNNLM(\u30ea\u30ab\u30ec\u30f3\u30c8\u30cb\u30e5\u30fc\u30e9\u30eb\u8a00\u8a9e\u30e2\u30c7\u30eb\u306e\u8a2d\u5b9a\u3092\u884c\u3063\u3066\u3044\u307e\u3059\uff09\n\u30fb\u8f9e\u66f8\u30c7\u30fc\u30bf\u3092\u3001\u5165\u529b\u30e6\u30cb\u30c3\u30c8\u6570\u5206\u306e\u30c7\u30fc\u30bf\u306b\u5909\u63db\u3059\u308b\u51e6\u7406\uff08\u6f5c\u5728\u30d9\u30af\u30c8\u30eb\u7a7a\u9593\u3078\u306e\u5909\u63db\uff09\u3092\u884c\u3063\u3066\u3044\u307e\u3059\u3002\n\u30fb\u51fa\u529b\u304c4\u500d\u306e\u7406\u7531\u306fLSTM\u3092\u4f7f\u7528\u3057\u3066\u3044\u308b\u305f\u3081\u3001\u51fa\u529b\u3001\u5165\u529b\u5236\u5fa1\u3001\u5fd8\u5374\u3001\u51fa\u529b\u5236\u5fa1\u3092\u884c\u3046\u305f\u3081\u306b\u7528\u3044\u3089\u308c\u3066\u3044\u307e\u3059\u3002\n\u30fb\u521d\u671f\u306e\u30d1\u30e9\u30e1\u30fc\u30bf\u3092-0.1\u301c0.1\u306e\u9593\u3067\u4e0e\u3048\u3066\u3044\u307e\u3059\u3002\n\u30fbGPU\u306e\u5f15\u6570\u304c\u4e00\u3064\u4ee5\u4e0a\u306a\u3089\u3070\u3001cuda\u306e\u521d\u671f\u5316\u3068\u30e2\u30c7\u30eb\u3092GPU\u306b\u9069\u7528\u3055\u305b\u308b\u51e6\u7406\u3092\u884c\u3063\u3066\u3044\u307e\u3059\u3002\n\n# Prepare RNNLM model\nmodel = chainer.FunctionSet(embed=F.EmbedID(len(vocab), n_units),\n                            l1_x=F.Linear(n_units, 4 * n_units),\n                            l1_h=F.Linear(n_units, 4 * n_units),\n                            l2_x=F.Linear(n_units, 4 * n_units),\n                            l2_h=F.Linear(n_units, 4 * n_units),\n                            l3=F.Linear(n_units, len(vocab)))\nfor param in model.parameters:\n    param[:] = np.random.uniform(-0.1, 0.1, param.shape)\nif args.gpu >= 0:\n    cuda.init(args.gpu)\n    model.to_gpu()\n\n\n\n\u5b66\u7fd2\u95a2\u6570\u306e\u8a2d\u5b9a\n1\u30b9\u30c6\u30c3\u30d7\u524d\u65b9\u51e6\u7406\u95a2\u6570\uff1a\u5b66\u7fd2\u30c7\u30fc\u30bf\u3001\u30e9\u30d9\u30eb\u3001\u72b6\u614b\u3092\u4e0e\u3048\u308b\n\u30fbGPU\u6307\u5b9a\u304c\u3042\u308c\u3070\u3001cuda\u7528\u306e\u30c7\u30fc\u30bf\u306b\u5909\u63db\u3059\u308b\n\u30fb\u5b66\u7fd2\u7528\u30c7\u30fc\u30bf\u3092\u4f5c\u6210\uff08\u7279\u5fb4\u91cf\u30c7\u30fc\u30bf\u3001\u30e9\u30d9\u30eb\u30c7\u30fc\u30bf\uff09\n\u30fb\u7279\u5fb4\u30d9\u30af\u30c8\u30eb\u306fBag of words\u306e\u5f62\u5f0f\u306a\u306e\u3067\u6f5c\u5728\u30d9\u30af\u30c8\u30eb\u7a7a\u9593\u306b\u5727\u7e2e\u3059\u308b\n\u30fb\u904e\u5b66\u7fd2\u3092\u3057\u306a\u3044\u3088\u3046\u306b\u30e9\u30f3\u30c0\u30e0\u306b\u4e00\u90e8\u306e\u30c7\u30fc\u30bf\u3092\u6368\u3066\u3001\u904e\u53bb\u306e\u72b6\u614b\u306e\u3082\u8003\u616e\u3057\u305f\u7b2c\u4e00\u306e\u96a0\u308c\u5c64\u3092\u4f5c\u6210\n\u30fbLSTM\u306b\u73fe\u5728\u306e\u72b6\u614b\u3068\u5148\u307b\u3069\u5b9a\u7fa9\u3057\u305f\u96a0\u308c\u5c64\u3092\u4ed8\u4e0e\u3057\u3066\u5b66\u7fd2\u3057\u3001\u96a0\u308c\u5c64\u3068\u72b6\u614b\u3092\u51fa\u529b\n\u30fb2\u5c64\u76ee\u30821\u5c64\u76ee\u3068\u540c\u69d8\u306e\u51e6\u7406\u3092\u884c\u3046\n\u30fb\u30e9\u30d9\u30eb\u306f3\u5c64\u76ee\u306e\u51e6\u7406\u3067\u51fa\u529b\u3055\u308c\u305f\u5024\u3092\u4f7f\u7528\u3059\u308b\u3002\n\u72b6\u614b\u306e\u521d\u671f\u5316\uff1a\u78ba\u7387\u7684\u52fe\u914d\u6cd5\u306b\u5fc5\u8981\u306a\u30c7\u30fc\u30bf\u3092\u4e0e\u3048\u3001\u5b66\u7fd2\u30c7\u30fc\u30bf\u3068\u8a8d\u8b58\u3055\u305b\u308b\n\u5404\u96a0\u308c\u5c64\u3068\u5024\u3092\u901a\u3059\u304b\u5224\u65ad\u3059\u308bc\u306e\u5024\u30920\u3067\u5fc5\u8981\u306a\u30c7\u30fc\u30bf\u5206\u521d\u671f\u5316\u3059\u308b\n# Neural net architecture\n\n\ndef forward_one_step(x_data, y_data, state, train=True):\n    if args.gpu >= 0:\n        x_data = cuda.to_gpu(x_data)\n        y_data = cuda.to_gpu(y_data)\n    x = chainer.Variable(x_data, volatile=not train)\n    t = chainer.Variable(y_data, volatile=not train)\n    h0 = model.embed(x)\n    h1_in = model.l1_x(F.dropout(h0, train=train)) + model.l1_h(state['h1'])\n    c1, h1 = F.lstm(state['c1'], h1_in)\n    h2_in = model.l2_x(F.dropout(h1, train=train)) + model.l2_h(state['h2'])\n    c2, h2 = F.lstm(state['c2'], h2_in)\n    y = model.l3(F.dropout(h2, train=train))\n    state = {'c1': c1, 'h1': h1, 'c2': c2, 'h2': h2}\n    return state, F.softmax_cross_entropy(y, t)\n\n\ndef make_initial_state(batchsize=batchsize, train=True):\n    return {name: chainer.Variable(mod.zeros((batchsize, n_units),\n                                             dtype=np.float32),\n                                   volatile=not train)\n            for name in ('c1', 'h1', 'c2', 'h2')}\n\n\n\u66f4\u65b0\u5e45\u30921\u306b\u8a2d\u5b9a\u3057\u3066\u78ba\u7387\u7684\u52fe\u914d\u6cd5\u306b\u3088\u308b\u6700\u9069\u5316\u3092\u884c\u3046\u3088\u3046\u306b\u8a2d\u5b9a\u3057\u3066\u3044\u308b\u3002\n\n# Setup optimizer\noptimizer = optimizers.SGD(lr=1.)\noptimizer.setup(model.collect_parameters())\n\n\n\n\u8a55\u4fa1\u95a2\u6570\u306e\u8a2d\u5b9a\n\u8a55\u4fa1\u306e\u95a2\u6570\n1\uff1a\u72b6\u614b\u306e\u521d\u671f\u5316\u3068\u640d\u5931\u306e\u521d\u671f\u5316\n2\uff1a\u30c7\u30fc\u30bf\u306e\u30b5\u30a4\u30ba\u5206\u78ba\u7387\u7684\u52fe\u914d\u6cd5\u306b\u57fa\u3065\u3044\u3066\u66f4\u65b0\u3057\u3066\u3044\u304f\n3\uff1a\u640d\u5931\u306e\u5e73\u5747\u5024\u3092exp\u95a2\u6570\u306b\u4e0e\u3048\u3066\u8fd4\u3059\u3002\uff08\u4f4e\u3044\u5024\u3067\u30820\u306b\u306a\u3089\u306a\u3044\u306e\u304c\u7279\u5fb4\u3067\u6b63\u306e\u5024\u3060\u3068\u6025\u6fc0\u306b\u5897\u3048\u308b\u305f\u3081\u640d\u5931\u304c\u5927\u304d\u3044\u6642\u306b\u306f\u6709\u52b9\u306b\u50cd\u304f\uff09\n\n# Evaluation routine\n\n\ndef evaluate(dataset):\n    sum_log_perp = mod.zeros(())\n    state = make_initial_state(batchsize=1, train=False)\n    for i in six.moves.range(dataset.size - 1):\n        x_batch = dataset[i:i + 1]\n        y_batch = dataset[i + 1:i + 2]\n        state, loss = forward_one_step(x_batch, y_batch, state, train=False)\n        sum_log_perp += loss.data.reshape(())\n\n    return math.exp(cuda.to_cpu(sum_log_perp) / (dataset.size - 1))\n\n\n\n\u5b66\u7fd2\u51e6\u7406\u3092\u59cb\u3081\u308b\u524d\u306e\u8a2d\u5b9a\n\u30fb\u5b66\u7fd2\u30c7\u30fc\u30bf\u306e\u30b5\u30a4\u30ba\u3092\u53d6\u5f97\n\u30fb\u30b8\u30e3\u30f3\u30d7\u306e\u5e45\u3092\u8a2d\u5b9a\uff08\u9806\u6b21\u5b66\u7fd2\u3057\u306a\u3044\uff09\n\u30fb\u30d1\u30fc\u30d7\u30ec\u30ad\u30b7\u30c6\u30a3\u30920\u3067\u521d\u671f\u5316\n\u30fb\u6700\u521d\u306e\u6642\u9593\u60c5\u5831\u3092\u53d6\u5f97\n\u30fb\u521d\u671f\u72b6\u614b\u3092\u73fe\u5728\u306e\u72b6\u614b\u306b\u4ed8\u4e0e\n\u30fb\u72b6\u614b\u306e\u521d\u671f\u5316\n\u30fb\u640d\u5931\u30920\u3067\u521d\u671f\u5316\n\n# Learning loop\nwhole_len = train_data.shape[0]\njump = whole_len // batchsize\ncur_log_perp = mod.zeros(())\nepoch = 0\nstart_at = time.time()\ncur_at = start_at\nstate = make_initial_state()\naccum_loss = chainer.Variable(mod.zeros(()))\nprint('going to train {} iterations'.format(jump * n_epoch))\n\n\n\u78ba\u7387\u7684\u52fe\u914d\u6cd5\u3092\u7528\u3044\u305f\u5b66\u7fd2\n\u78ba\u7387\u7684\u52fe\u914d\u6cd5\u3092\u7528\u3044\u3066\u5b66\u7fd2\u3057\u3066\u3044\u308b\u3002\n\u4e00\u5b9a\u306e\u30c7\u30fc\u30bf\u3092\u9078\u629e\u3057\u640d\u5931\u8a08\u7b97\u3092\u3057\u306a\u304c\u3089\u30d1\u30e9\u30e1\u30fc\u30bf\u66f4\u65b0\u3092\u3057\u3066\u3044\u308b\u3002\n\u9010\u6b21\u5c24\u5ea6\u306e\u8a08\u7b97\u3082\u884c\u3063\u3066\u3044\u308b\u3002\nfor i in six.moves.range(jump * n_epoch):\n    x_batch = np.array([train_data[(jump * j + i) % whole_len]\n                        for j in six.moves.range(batchsize)])\n    y_batch = np.array([train_data[(jump * j + i + 1) % whole_len]\n                        for j in six.moves.range(batchsize)])\n    state, loss_i = forward_one_step(x_batch, y_batch, state)\n    accum_loss += loss_i\n    cur_log_perp += loss_i.data.reshape(())\n\n\n\u30fb\u30d0\u30c3\u30af\u30d7\u30ed\u30d1\u30b2\u30fc\u30b7\u30e7\u30f3\u3067\u30d1\u30e9\u30e1\u30fc\u30bf\u3092\u66f4\u65b0\u3059\u308b\u3002\n\u30fbtruncate\u306f\u3069\u308c\u3060\u3051\u904e\u53bb\u306e\u5c65\u6b74\u3092\u898b\u308b\u304b\u3092\u8868\u3057\u3066\u3044\u308b\u3002\nhttp://kiyukuta.github.io/2013/12/09/mlac2013_day9_recurrent_neural_network_language_model.html#recurrent-neural-network\n\u30fbL2\u6b63\u898f\u5316\u3092\u304b\u3051\u3066\u3044\u308b\u3002\n\n    if (i + 1) % bprop_len == 0:  # Run truncated BPTT\n        optimizer.zero_grads()\n        accum_loss.backward()\n        accum_loss.unchain_backward()  # truncate\n        accum_loss = chainer.Variable(mod.zeros(()))\n\n        optimizer.clip_grads(grad_clip)\n        optimizer.update()\n\n\u5b66\u7fd2\u30c7\u30fc\u30bf\u306e\u30d1\u30fc\u30d7\u30ec\u30ad\u30b7\u30c6\u30a3\u306e\u8a08\u7b97\uff089999\u56de\u306b1\u56de\u884c\u3046\uff09\u3057\u3001\u8868\u793a\u3059\u308b\u3002\n\n    if (i + 1) % 10000 == 0:\n        now = time.time()\n        throuput = 10000. / (now - cur_at)\n        perp = math.exp(cuda.to_cpu(cur_log_perp) / 10000)\n        print('iter {} training perplexity: {:.2f} ({:.2f} iters/sec)'.format(\n            i + 1, perp, throuput))\n        cur_at = now\n        cur_log_perp.fill(0)\n\n\u30d0\u30ea\u30c7\u30fc\u30b7\u30e7\u30f3\u30c7\u30fc\u30bf\u306e\u30d1\u30fc\u30d7\u30ec\u30ad\u30b7\u30c6\u30a3\u306e\u8a08\u7b97\uff08\u30d0\u30ea\u30c7\u30fc\u30b7\u30e7\u30f3\u306e\u5e45\u306b\u3088\u3063\u3066\u7570\u306a\u308b\uff09\u3057\u8868\u793a\u3059\u308b\n\n    if (i + 1) % jump == 0:\n        epoch += 1\n        print('evaluate')\n        now = time.time()\n        perp = evaluate(valid_data)\n        print('epoch {} validation perplexity: {:.2f}'.format(epoch, perp))\n        cur_at += time.time() - now  # skip time of evaluation\n\n        if epoch >= 6:\n            optimizer.lr /= 1.2\n            print('learning rate =', optimizer.lr)\n\n    sys.stdout.flush()\n\n\n\n\u8a55\u4fa1\n\u30c6\u30b9\u30c8\u30c7\u30fc\u30bf\u306b\u5bfe\u3059\u308b\u30d1\u30fc\u30d7\u30ec\u30ad\u30b7\u30c6\u30a3\u306e\u8a08\u7b97\n\n# Evaluate on test dataset\nprint('test')\ntest_perp = evaluate(test_data)\nprint('test perplexity:', test_perp)\n\n\n\u53c2\u8003\u30b5\u30a4\u30c8\u4e00\u89a7\n\u8a00\u8a9e\u30e2\u30c7\u30eb\u306e\u30ab\u30d0\u30ec\u30fc\u30b8\u3001\u30d1\u30fc\u30d7\u30ec\u30ad\u30b7\u30c6\u30a3\u306e\u8aac\u660e\nhttp://marujirou.hatenablog.com/entry/2014/08/22/235215\n\u30c7\u30a3\u30fc\u30d7\u30e9\u30fc\u30cb\u30f3\u30b0\u30d5\u30ec\u30fc\u30e0\u30ef\u30fc\u30afChainer\u3092EC2\u306eGPU\u30a4\u30f3\u30b9\u30bf\u30f3\u30b9\u3067\u52d5\u304b\u3059 g2.2xlarge instance\nhttp://ukonlly.hatenablog.jp/entry/2015/07/04/210149\nDrop Out\nhttp://olanleed.hatenablog.com/entry/2013/12/03/010945\nLearning to forget continual prediction with lstm\nhttp://www.slideshare.net/FujimotoKeisuke/learning-to-forget-continual-prediction-with-lstm\nZaremba, Wojciech, Ilya Sutskever, and Oriol Vinyals. \"Recurrent neural network regularization.\" arXiv preprint arXiv:1409.2329 (2014).\nGoogle Mikolov\nhttp://www.rnnlm.org/\nNeural Network(NN)\u3092\u5229\u7528\u3057\u305fLanguage Model(LM)\uff0c\u3064\u307e\u308aNeural Network Language Model(NNLM)\u306e\u4e00\u7a2e\u3067\u3042\u308a\uff0c Recurrent Neural Network(RNN)\u3092\u4f7f\u3063\u305fRecurrent Neural Network Language Model(RNNLM)\nhttp://kiyukuta.github.io/2013/12/09/mlac2013_day9_recurrent_neural_network_language_model.html\nLong Short-term Memory\nhttp://www.slideshare.net/nishio/long-shortterm-memory\nChainer\u306eptb\u30b5\u30f3\u30d7\u30eb\u3092\u89e3\u8aac\u3057\u3064\u3064\u3001\u81ea\u5206\u306e\u6587\u7ae0\u3092\u6df1\u5c64\u5b66\u7fd2\u3055\u305b\u3066\u3001\u50d5\u306e\u6587\u7ae0\u3063\u307d\u3044\u6587\u3092\u81ea\u52d5\u751f\u6210\u3055\u305b\u3066\u307f\u308b\nhttp://d.hatena.ne.jp/shi3z/20150714/1436832305\nRNNLM\nhttp://www.slideshare.net/uchumik/rnnln\n\u30b9\u30d1\u30fc\u30b9\u63a8\u5b9a\u6982\u89b3\uff1a\u30e2\u30c7\u30eb\u30fb\u7406\u8ad6\u30fb\u5fdc\u7528\nhttp://www.is.titech.ac.jp/~s-taiji/tmp/sparse_tutorial_2014.pdf\n\u6b63\u5247\u5316\u5b66\u7fd2\u6cd5\u306b\u304a\u3051\u308b\u6700\u9069\u5316\u624b\u6cd5\nhttp://imi.kyushu-u.ac.jp/~waki/ws2013/slide/suzuki.pdf\n\u30ea\u30ab\u30ec\u30f3\u30c8\u30cb\u30e5\u30fc\u30e9\u30eb\u8a00\u8a9e\u30e2\u30c7\u30eb\u4f5c\u6210\u53c2\u8003\nhttps://github.com/yusuketomoto/chainer-char-rnn\n\u30cb\u30e5\u30fc\u30e9\u30eb\u30cd\u30c3\u30c8\u3000\u81ea\u7136\u8a00\u8a9e\u51e6\u7406\nhttp://www.orsj.or.jp/archive2/or60-4/or60_4_205.pdf\n\u8a00\u8a9e\u30e2\u30c7\u30eb\u4f5c\u6210\nhttp://www.slideshare.net/uchumik/rnnln\n\u81ea\u7136\u8a00\u8a9e\u51e6\u7406\u30d7\u30ed\u30b0\u30e9\u30df\u30f3\u30b0\u52c9\u5f37\u4f1an-gram\u8a00\u8a9e\u30e2\u30c7\u30eb\nhttp://www.phontron.com/slides/nlp-programming-ja-02-bigramlm.pdf\nStatistical Semantic\u5165\u9580 ~\u5206\u5e03\u4eee\u8aac\u304b\u3089word2vec\u307e\u3067~\nhttp://www.slideshare.net/unnonouno/20140206-statistical-semantics\nlinux source code\nhttps://github.com/torvalds/linux\n\u306a\u305cGPU\u30b3\u30f3\u30d4\u30e5\u30fc\u30c6\u30a3\u30f3\u30b0\u304c\u6ce8\u76ee\u3092\u6d74\u3073\u3066\u3044\u308b\u304b - \u6176\u61c9\u7fa9\u587e http://www.yasuoka.mech.keio.ac.jp/gpu/gpu_0.php\nCUDA\u6280\u8853\u3092\u5229\u7528\u3057\u305fGPU\u30b3\u30f3\u30d4\u30e5\u30fc\u30c6\u30a3\u30f3\u30b0\u306e\u5b9f\u969b\uff08\u524d\u7de8\uff09 \u2015\u2015 \u30b0\u30e9\u30d5\u30a3\u30c3\u30af\u30b9\u5206\u91ce\u3067\u78e8\u304b\u308c\u305f\u4e26\u5217\u51e6\u7406\u6280\u8853\u3092\u6c4e\u7528\u6570\u5024\u8a08\u7b97\u306b\u5fdc\u7528\nhttp://www.kumikomi.net/archives/2008/06/12gpu1.php?page=1\nGPGPU\nhttps://ja.wikipedia.org/wiki/GPGPU#.E7.89.B9.E5.BE.B4.E3.81.A8.E8.AA.B2.E9.A1.8C\n#\u30ea\u30ab\u30ec\u30f3\u30c8\u30cb\u30e5\u30fc\u30e9\u30eb\u30cd\u30c3\u30c8\u30ef\u30fc\u30af\u8a00\u8a9e\u30e2\u30c7\u30eb\n\u30ea\u30ab\u30ec\u30f3\u30c8\u30cb\u30e5\u30fc\u30e9\u30eb\u30cd\u30c3\u30c8\u30ef\u30fc\u30af\u8a00\u8a9e\u30e2\u30c7\u30eb\uff08\u30cb\u30e5\u30fc\u30e9\u30eb\u8a00\u8a9e\u30e2\u30c7\u30eb\uff09\u306b\u3064\u3044\u3066Chainer\u306e\u30b3\u30fc\u30c9\u3092\u4f7f\u3063\u3066\u89e3\u8aac\u3057\u3066\u307f\u307e\u3057\u305f\u3002\n\n![\u30b9\u30e9\u30a4\u30c91.JPG](https://qiita-image-store.s3.amazonaws.com/0/10496/080447a3-8fd5-9cb3-8e33-5107c4f0ac5e.jpeg)\n\n##GPU\u306b\u3064\u3044\u3066\n\n\u8a00\u8a9e\u51e6\u7406\u306f\u3059\u3054\u304f\u6642\u9593\u304c\u304b\u304b\u308b\u306e\u3067GPU\u8a2d\u5b9a\u3092\u304a\u30b9\u30b9\u30e1\u3057\u3066\u3044\u307e\u3059\u3002\n\u3057\u304b\u3057\u4e00\u6982\u306b\u4f7f\u3048\u3070\u826f\u3044\u3068\u3044\u3046\u3053\u3068\u3067\u306f\u306a\u304f\u4e0b\u8a18\u306e\u3088\u3046\u306a\u8a2d\u5b9a\u3067\u306f\u6709\u52b9\u306b\u50cd\u304d\u307e\u3059\u3002\n\u8a73\u7d30\u306a\u4ed5\u7d44\u307f\u306e\u4e2d\u8eab\u3092\u77e5\u308a\u305f\u3044\u65b9\u306f\u4e0b\u8a18\u3092\u3054\u89a7\u304f\u3060\u3055\u3044\u3002\nhttp://www.kumikomi.net/archives/2008/06/12gpu1.php?page=1\n\n\uff0a\u5f97\u610f\n\u884c\u5217\u8a08\u7b97\n\u30e1\u30e2\u30ea\u306b\u30b7\u30fc\u30b1\u30f3\u30b7\u30e3\u30eb\u306b\u30a2\u30af\u30bb\u30b9\u3057\u3001\u304b\u3064\u6761\u4ef6\u5206\u5c90\u306e\u7121\u3044\u8a08\u7b97\uff08\u6f14\u7b97\u5bc6\u5ea6\u306e\u9ad8\u3044\u51e6\u7406\uff09\u306b\u5f37\u3044\u3002\n\n\uff0a\u82e6\u624b\n\u4e8c\u5206\u63a2\u7d22\n\u30e1\u30e2\u30ea\u306b\u30e9\u30f3\u30c0\u30e0\u30a2\u30af\u30bb\u30b9\u3057\u3001\u304b\u3064\u6761\u4ef6\u5206\u5c90\u304c\u591a\u3044\u3002\n\n##GPU\u30c9\u30e9\u30a4\u30d0\u8a2d\u5b9a\n\nAWS\u3067\u306eGPU\u8a2d\u5b9a\u306f\u4e0b\u8a18\u306e\u30b5\u30a4\u30c8\u3092\u53c2\u8003\u306b\u884c\u3044\u307e\u3057\u305f\u3002\n\nhttp://tleyden.github.io/blog/2014/10/25/cuda-6-dot-5-on-aws-gpu-instance-running-ubuntu-14-dot-04/\n\n```shell-session\napt-get update && apt-get install build-essential\n```\n\nCuda\u306e\u30a4\u30f3\u30b9\u30c8\u30fc\u30e9\u30fc\u3092\u53d6\u5f97\n\n```shell-session\nwget http://developer.download.nvidia.com/compute/cuda/6_5/rel/installers/cuda_6.5.14_linux_64.run\n```\n\nCuda\u306e\u30a4\u30f3\u30b9\u30c8\u30fc\u30e9\u30fc\u306e\u307f\u53d6\u5f97\n\n```shell-session\nchmod +x cuda_6.5.14_linux_64.run\nmkdir nvidia_installers\n./cuda_6.5.14_linux_64.run -extract=`pwd`/nvidia_installers\n```\n\nimage-extract\u3092\u53d6\u5f97\n\n```shell-session\nsudo apt-get install linux-image-extra-virtual\n```\n\n\u518d\u8d77\u52d5\n\n```shell-session\nreboot\n```\n\n\u30d5\u30a1\u30a4\u30eb\u3092\u4f5c\u6210\n\n```shell-session\nvi /etc/modprobe.d/blacklist-nouveau.conf\n```\n\nnouveau\u3068lbm-nouveau\u306e\u8d77\u52d5\u3057\u306a\u3044\u3088\u3046\u306b\u8a2d\u5b9a\n\n```\nblacklist nouveau\nblacklist lbm-nouveau\noptions nouveau modeset=0\nalias nouveau off\nalias lbm-nouveau off\n```\n\nKernel Nouveau\u3092\u8d77\u52d5\u3057\u306a\u3044\u3088\u3046\u306b\u8a2d\u5b9a\n\n```\n echo options nouveau modeset=0 | sudo tee -a /etc/modprobe.d/nouveau-kms.conf\n```\n\n\u30ab\u30fc\u30cd\u30eb\u8d77\u52d5\u6642\u306b\u3042\u3089\u304b\u3058\u3081\u30e1\u30e2\u30ea\u306b\u5c55\u958b\u3059\u308b\u3053\u3068\u3067\u30d5\u30a1\u30a4\u30eb\u30b7\u30b9\u30c6\u30e0\u3092\u69cb\u6210\u3059\u308b\u8a2d\u5b9a\u3092\u3057\u3066\u304b\u3089\u518d\u8d77\u52d5\n\n```\nupdate-initramfs -u\nreboot\n```\n\u30ab\u30fc\u30cd\u30eb\u306e\u30bd\u30fc\u30b9\u3092\u53d6\u5f97\n\n```shell-session\napt-get install linux-source\napt-get install linux-headers-3.13.0-37-generic\n```\n\nNVIDIA\u306e\u30c9\u30e9\u30a4\u30d0\u3092\u30a4\u30f3\u30b9\u30c8\u30fc\u30eb\n\n```shell-session\ncd nvidia_installers\n./NVIDIA-Linux-x86_64-340.29.run\n```\n\n\u4e0b\u8a18\u306e\u30a8\u30e9\u30fc\u5bfe\u5fdc\n\n```\nNVIDIA driver install - Error: Unable to find the kernel source tree\n```\n\n```\nsudo apt-get install linux-headers-`uname -r`\n```\n\n\u4e0b\u8a18\u306e\u30b3\u30de\u30f3\u30c9\u3067\u30c9\u30e9\u30a4\u30d0\u304c\u30a4\u30f3\u30b9\u30c8\u30fc\u30eb\u3055\u308c\u305f\u304b\u3092\u78ba\u8a8d\u3059\u308b\u3002\n\n```shell-session\nnvidia-smi\nWed Aug  5 07:48:36 2015\n+------------------------------------------------------+\n| NVIDIA-SMI 340.29     Driver Version: 340.29         |\n|-------------------------------+----------------------+----------------------+\n| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n|===============================+======================+======================|\n|   0  GRID K520           Off  | 0000:00:03.0     Off |                  N/A |\n| N/A   54C    P0    80W / 125W |    391MiB /  4095MiB |     99%      Default |\n+-------------------------------+----------------------+----------------------+\n\n+-----------------------------------------------------------------------------+\n| Compute processes:                                               GPU Memory |\n|  GPU       PID  Process name                                     Usage      |\n|=============================================================================|\n|    0      8013  python                                               378MiB |\n+-----------------------------------------------------------------------------+\n```\n\n\u4e0a\u8a18\u306eGPU\u306b\u632f\u3089\u308c\u3066\u3044\u308b\u756a\u53f7\u304cGPU\u306eID\u3067\u3042\u308b\u3002\u3053\u308c\u306f\u5f8c\u3067Chainer\u3092\u52d5\u4f5c\u3055\u305b\u308b\u3068\u304d\u306b\u4f7f\u7528\u3059\u308b\u3002\n\n\n##Python\u306e\u8a2d\u5b9a\n\nPython3\u306e\u8a2d\u5b9a\u3092\u884c\u3044\u307e\u3057\u305f\u3002\n\n\u4e0b\u8a18\u306e\u30b3\u30de\u30f3\u30c9\u3092\u5b9f\u884c\u3057\u3066\u4e8b\u524d\u306b\u5fc5\u8981\u306a\u3082\u306e\u3092\u30a4\u30f3\u30b9\u30c8\u30fc\u30eb\u3057\u3066\u304a\u304f\n\n```shell-session\n\napt-get update\napt-get install gcc gcc++ kmod perl python-dev\nsudo reboot\n```\n\npip\u5c0e\u5165\u624b\u9806\nhttps://pip.pypa.io/en/stable/installing.html\n\nPyenv\u5c0e\u5165\u624b\u9806\nhttps://github.com/yyuu/pyenv\n\n```shell-session\n\npip install virtualenv\n\npyenv install 3.4\n\nvirtualenv my_env -p = ~/.pyenv/versions/3.4.0/bin/python3.4\n\n```\n\nrequirement.txt\u306e\u8a2d\u5b9a\u3092\u884c\u3044\u307e\u3057\u305f\u3002\n\n```shell-session\nnumpy\nscikit-learn\nMako\nsix\nchainer\nscikit-cuda\n```\n\n\u5fc5\u8981\u306a\u30e9\u30a4\u30d6\u30e9\u30ea\u3092\u30a4\u30f3\u30b9\u30c8\u30fc\u30eb\n\n```shell-session\npip install -r requirement.txt\n```\n\n\u4e0b\u8a18\u304b\u3089\"install-headers\"\u3092\u30c0\u30a6\u30f3\u30ed\u30fc\u30c9\u3057\u3066\u304f\u308b\u3002\n\nhttps://android.googlesource.com/toolchain/python/+/47a24ea6662f20c8e165d541ab6facdf009bfee4/Python-2.7.5/Lib/distutils/command/install_headers.py\n\nPyCuda\u306e\u30a4\u30f3\u30b9\u30c8\u30fc\u30eb\n\n```shell-session\nwget https://pypi.python.org/packages/source/p/pycuda/pycuda-2015.1.2.tar.gz\ntar zxvf pycuda-2015.1.2.tar.gz\ncd pycuda-2015.1.2\n./configure.py\nmake\nmake install\n```\n\n##Chainer \u30ea\u30ab\u30ec\u30f3\u30c8\u30cb\u30e5\u30fc\u30e9\u30eb\u8a00\u8a9e\u30e2\u30c7\u30eb\u3000\u30b5\u30f3\u30d7\u30eb\u30b3\u30fc\u30c9\n\n\u30b3\u30fc\u30c9\u69cb\u6210\u56f3\n\n![\u30b9\u30e9\u30a4\u30c92.JPG](https://qiita-image-store.s3.amazonaws.com/0/10496/c7dfebdc-9b43-dc7a-6d2c-d1415ab845a5.jpeg)\n\n###\u5404\u7a2e\u30e9\u30a4\u30d6\u30e9\u30ea\u3092\u30a4\u30f3\u30dd\u30fc\u30c8\n\n```py\n\n#!/usr/bin/env python\n\"\"\"Sample script of recurrent neural network language model.\n\nThis code is ported from following implementation written in Torch.\nhttps://github.com/tomsercu/lstm\n\n\"\"\"\nimport argparse\nimport math\nimport sys\nimport time\n\nimport numpy as np\nimport six\n\nimport chainer\nfrom chainer import cuda\nimport chainer.functions as F\nfrom chainer import optimizers\n\n````\n\n###\u521d\u671f\u8a2d\u5b9a\n\n\u30fb\u5f15\u6570\u3067GPU\u3092\u4f7f\u7528\u3059\u308b\u304b\u3069\u3046\u304b\u3092\u5224\u65ad\u3057\u3066\u3044\u307e\u3059\u3002\n\u30fbGPU\u304c\u6307\u5b9a\u3055\u308c\u308c\u3070cuda\u3092\u5b9f\u884c\u3059\u308b\u3088\u3046\u306b\u8a2d\u5b9a\u3055\u308c\u3066\u3044\u307e\u3059\u3002\n\u30fb\u5b66\u7fd2\u56de\u6570\u3001\u30e6\u30cb\u30c3\u30c8\u6570\u3001\u78ba\u7387\u7684\u52fe\u914d\u6cd5\u306b\u4f7f\u7528\u3059\u308b\u30c7\u30fc\u30bf\u306e\u6570\u3001\u5b66\u7fd2\u306b\u4f7f\u7528\u3059\u308b\u6587\u5b57\u5217\u306e\u9577\u3055\u3001\u52fe\u914d\u6cd5\u3067\u4f7f\u7528\u3059\u308b\u6577\u5c45\u5024\u3092\u8a2d\u5b9a\u3057\u3066\u3044\u307e\u3059\u3002\n\n```py\n\nparser = argparse.ArgumentParser()\nparser.add_argument('--gpu', '-g', default=-1, type=int,\n                    help='GPU ID (negative value indicates CPU)')\nargs = parser.parse_args()\nmod = cuda if args.gpu >= 0 else np\n\nn_epoch = 39   # number of epochs\nn_units = 650  # number of units per layer\nbatchsize = 20   # minibatch size\nbprop_len = 35   # length of truncated BPTT\ngrad_clip = 5    # gradient norm threshold to clip\n\n```\n\n###\u30c7\u30fc\u30bf\u4fdd\u6301\n\n\u4e88\u3081download.py\u3067\u30c0\u30a6\u30f3\u30ed\u30fc\u30c9\u3057\u305f\u30d5\u30a1\u30a4\u30eb\u3092\u30d7\u30ed\u30b0\u30e9\u30e0\u306b\u8aad\u307e\u305b\u308b\u51e6\u7406\u3092\u95a2\u6570\u5316\u3057\u3066\u3044\u307e\u3059\u3002\n\n\u30fb\u6700\u7d42\u6587\u5b57\u3092\u6539\u884c\u304b\u3089\\<eos>\u306b\u5909\u66f4\u3057\u3066\u3044\u307e\u3059\u3002\\<eos>\u306f\u6700\u7d42\u6587\u5b57\u3092\u8868\u3059\u660e\u793a\u7684\u306a\u7269\u306a\u306e\u3067\u6539\u884c\u30b3\u30fc\u30c9\u3092\u7f6e\u304d\u63db\u3048\u3066\u660e\u793a\u7684\u306b\u6700\u7d42\u6587\u5b57\u306b\u3057\u3066\u3044\u307e\u3059\u3002\n\u30fb\u6587\u5b57\u30c7\u30fc\u30bf\u3092\u78ba\u4fdd\u3059\u308b\u305f\u3081\u306e\u884c\u5217\u3092\u5b9a\u7fa9\u3057\u3066\u3044\u307e\u3059\u3002\n\u30fb\u30c7\u30fc\u30bf\u3092\u5358\u8a9e\u3092\u30ad\u30fc\u3001\u9577\u3055\u3092\u5024\u3068\u3057\u305f\u8f9e\u66f8\u30c7\u30fc\u30bf\u306b\u3057\u3066\u884c\u5217\u30c7\u30fc\u30bf\u30bb\u30c3\u30c8\u306b\u767b\u9332\u3057\u3066\u3044\u307e\u3059\u3002\n\n\u5b66\u7fd2\u30c7\u30fc\u30bf\nvalid\u30c7\u30fc\u30bf\n\u30c6\u30b9\u30c8\u30c7\u30fc\u30bf\n\n\u4e0a\u8a18\u3092\u305d\u308c\u305e\u308c\u884c\u5217\u30c7\u30fc\u30bf\u3068\u3057\u3066\u4fdd\u6301\u3057\u3066\u3044\u307e\u3059\u3002\n\n```py\n# Prepare dataset (preliminary download dataset by ./download.py)\nvocab = {}\n\n\ndef load_data(filename):\n    global vocab, n_vocab\n    words = open(filename).read().replace('\\n', '<eos>').strip().split()\n    dataset = np.ndarray((len(words),), dtype=np.int32)\n    for i, word in enumerate(words):\n        if word not in vocab:\n            vocab[word] = len(vocab)\n        dataset[i] = vocab[word]\n    return dataset\n\ntrain_data = load_data('ptb.train.txt')\nvalid_data = load_data('ptb.valid.txt')\ntest_data = load_data('ptb.test.txt')\nprint('#vocab =', len(vocab))\n\n```\n###\u30ea\u30ab\u30ec\u30f3\u30c8\u30cb\u30e5\u30fc\u30e9\u30eb\u8a00\u8a9e\u30e2\u30c7\u30eb\n\nRNNLM(\u30ea\u30ab\u30ec\u30f3\u30c8\u30cb\u30e5\u30fc\u30e9\u30eb\u8a00\u8a9e\u30e2\u30c7\u30eb\u306e\u8a2d\u5b9a\u3092\u884c\u3063\u3066\u3044\u307e\u3059\uff09\n\u30fb\u8f9e\u66f8\u30c7\u30fc\u30bf\u3092\u3001\u5165\u529b\u30e6\u30cb\u30c3\u30c8\u6570\u5206\u306e\u30c7\u30fc\u30bf\u306b\u5909\u63db\u3059\u308b\u51e6\u7406\uff08\u6f5c\u5728\u30d9\u30af\u30c8\u30eb\u7a7a\u9593\u3078\u306e\u5909\u63db\uff09\u3092\u884c\u3063\u3066\u3044\u307e\u3059\u3002\n\u30fb\u51fa\u529b\u304c4\u500d\u306e\u7406\u7531\u306fLSTM\u3092\u4f7f\u7528\u3057\u3066\u3044\u308b\u305f\u3081\u3001\u51fa\u529b\u3001\u5165\u529b\u5236\u5fa1\u3001\u5fd8\u5374\u3001\u51fa\u529b\u5236\u5fa1\u3092\u884c\u3046\u305f\u3081\u306b\u7528\u3044\u3089\u308c\u3066\u3044\u307e\u3059\u3002\n\u30fb\u521d\u671f\u306e\u30d1\u30e9\u30e1\u30fc\u30bf\u3092-0.1\u301c0.1\u306e\u9593\u3067\u4e0e\u3048\u3066\u3044\u307e\u3059\u3002\n\u30fbGPU\u306e\u5f15\u6570\u304c\u4e00\u3064\u4ee5\u4e0a\u306a\u3089\u3070\u3001cuda\u306e\u521d\u671f\u5316\u3068\u30e2\u30c7\u30eb\u3092GPU\u306b\u9069\u7528\u3055\u305b\u308b\u51e6\u7406\u3092\u884c\u3063\u3066\u3044\u307e\u3059\u3002\n\n```py\n\n# Prepare RNNLM model\nmodel = chainer.FunctionSet(embed=F.EmbedID(len(vocab), n_units),\n                            l1_x=F.Linear(n_units, 4 * n_units),\n                            l1_h=F.Linear(n_units, 4 * n_units),\n                            l2_x=F.Linear(n_units, 4 * n_units),\n                            l2_h=F.Linear(n_units, 4 * n_units),\n                            l3=F.Linear(n_units, len(vocab)))\nfor param in model.parameters:\n    param[:] = np.random.uniform(-0.1, 0.1, param.shape)\nif args.gpu >= 0:\n    cuda.init(args.gpu)\n    model.to_gpu()\n\n```\n###\u5b66\u7fd2\u95a2\u6570\u306e\u8a2d\u5b9a\n\n1\u30b9\u30c6\u30c3\u30d7\u524d\u65b9\u51e6\u7406\u95a2\u6570\uff1a\u5b66\u7fd2\u30c7\u30fc\u30bf\u3001\u30e9\u30d9\u30eb\u3001\u72b6\u614b\u3092\u4e0e\u3048\u308b\n\n\u30fbGPU\u6307\u5b9a\u304c\u3042\u308c\u3070\u3001cuda\u7528\u306e\u30c7\u30fc\u30bf\u306b\u5909\u63db\u3059\u308b\n\u30fb\u5b66\u7fd2\u7528\u30c7\u30fc\u30bf\u3092\u4f5c\u6210\uff08\u7279\u5fb4\u91cf\u30c7\u30fc\u30bf\u3001\u30e9\u30d9\u30eb\u30c7\u30fc\u30bf\uff09\n\u30fb\u7279\u5fb4\u30d9\u30af\u30c8\u30eb\u306fBag of words\u306e\u5f62\u5f0f\u306a\u306e\u3067\u6f5c\u5728\u30d9\u30af\u30c8\u30eb\u7a7a\u9593\u306b\u5727\u7e2e\u3059\u308b\n\u30fb\u904e\u5b66\u7fd2\u3092\u3057\u306a\u3044\u3088\u3046\u306b\u30e9\u30f3\u30c0\u30e0\u306b\u4e00\u90e8\u306e\u30c7\u30fc\u30bf\u3092\u6368\u3066\u3001\u904e\u53bb\u306e\u72b6\u614b\u306e\u3082\u8003\u616e\u3057\u305f\u7b2c\u4e00\u306e\u96a0\u308c\u5c64\u3092\u4f5c\u6210\n\u30fbLSTM\u306b\u73fe\u5728\u306e\u72b6\u614b\u3068\u5148\u307b\u3069\u5b9a\u7fa9\u3057\u305f\u96a0\u308c\u5c64\u3092\u4ed8\u4e0e\u3057\u3066\u5b66\u7fd2\u3057\u3001\u96a0\u308c\u5c64\u3068\u72b6\u614b\u3092\u51fa\u529b\n\u30fb2\u5c64\u76ee\u30821\u5c64\u76ee\u3068\u540c\u69d8\u306e\u51e6\u7406\u3092\u884c\u3046\n\u30fb\u30e9\u30d9\u30eb\u306f3\u5c64\u76ee\u306e\u51e6\u7406\u3067\u51fa\u529b\u3055\u308c\u305f\u5024\u3092\u4f7f\u7528\u3059\u308b\u3002\n\n\u72b6\u614b\u306e\u521d\u671f\u5316\uff1a\u78ba\u7387\u7684\u52fe\u914d\u6cd5\u306b\u5fc5\u8981\u306a\u30c7\u30fc\u30bf\u3092\u4e0e\u3048\u3001\u5b66\u7fd2\u30c7\u30fc\u30bf\u3068\u8a8d\u8b58\u3055\u305b\u308b\n\n\u5404\u96a0\u308c\u5c64\u3068\u5024\u3092\u901a\u3059\u304b\u5224\u65ad\u3059\u308bc\u306e\u5024\u30920\u3067\u5fc5\u8981\u306a\u30c7\u30fc\u30bf\u5206\u521d\u671f\u5316\u3059\u308b\n\n```py\n# Neural net architecture\n\n\ndef forward_one_step(x_data, y_data, state, train=True):\n    if args.gpu >= 0:\n        x_data = cuda.to_gpu(x_data)\n        y_data = cuda.to_gpu(y_data)\n    x = chainer.Variable(x_data, volatile=not train)\n    t = chainer.Variable(y_data, volatile=not train)\n    h0 = model.embed(x)\n    h1_in = model.l1_x(F.dropout(h0, train=train)) + model.l1_h(state['h1'])\n    c1, h1 = F.lstm(state['c1'], h1_in)\n    h2_in = model.l2_x(F.dropout(h1, train=train)) + model.l2_h(state['h2'])\n    c2, h2 = F.lstm(state['c2'], h2_in)\n    y = model.l3(F.dropout(h2, train=train))\n    state = {'c1': c1, 'h1': h1, 'c2': c2, 'h2': h2}\n    return state, F.softmax_cross_entropy(y, t)\n\n\ndef make_initial_state(batchsize=batchsize, train=True):\n    return {name: chainer.Variable(mod.zeros((batchsize, n_units),\n                                             dtype=np.float32),\n                                   volatile=not train)\n            for name in ('c1', 'h1', 'c2', 'h2')}\n\n```\n\u66f4\u65b0\u5e45\u30921\u306b\u8a2d\u5b9a\u3057\u3066\u78ba\u7387\u7684\u52fe\u914d\u6cd5\u306b\u3088\u308b\u6700\u9069\u5316\u3092\u884c\u3046\u3088\u3046\u306b\u8a2d\u5b9a\u3057\u3066\u3044\u308b\u3002\n\n```py\n\n# Setup optimizer\noptimizer = optimizers.SGD(lr=1.)\noptimizer.setup(model.collect_parameters())\n\n```\n\n###\u8a55\u4fa1\u95a2\u6570\u306e\u8a2d\u5b9a\n\n\u8a55\u4fa1\u306e\u95a2\u6570\n1\uff1a\u72b6\u614b\u306e\u521d\u671f\u5316\u3068\u640d\u5931\u306e\u521d\u671f\u5316\n2\uff1a\u30c7\u30fc\u30bf\u306e\u30b5\u30a4\u30ba\u5206\u78ba\u7387\u7684\u52fe\u914d\u6cd5\u306b\u57fa\u3065\u3044\u3066\u66f4\u65b0\u3057\u3066\u3044\u304f\n3\uff1a\u640d\u5931\u306e\u5e73\u5747\u5024\u3092exp\u95a2\u6570\u306b\u4e0e\u3048\u3066\u8fd4\u3059\u3002\uff08\u4f4e\u3044\u5024\u3067\u30820\u306b\u306a\u3089\u306a\u3044\u306e\u304c\u7279\u5fb4\u3067\u6b63\u306e\u5024\u3060\u3068\u6025\u6fc0\u306b\u5897\u3048\u308b\u305f\u3081\u640d\u5931\u304c\u5927\u304d\u3044\u6642\u306b\u306f\u6709\u52b9\u306b\u50cd\u304f\uff09\n\n\n```py\n\n# Evaluation routine\n\n\ndef evaluate(dataset):\n    sum_log_perp = mod.zeros(())\n    state = make_initial_state(batchsize=1, train=False)\n    for i in six.moves.range(dataset.size - 1):\n        x_batch = dataset[i:i + 1]\n        y_batch = dataset[i + 1:i + 2]\n        state, loss = forward_one_step(x_batch, y_batch, state, train=False)\n        sum_log_perp += loss.data.reshape(())\n\n    return math.exp(cuda.to_cpu(sum_log_perp) / (dataset.size - 1))\n\n```\n\n###\u5b66\u7fd2\u51e6\u7406\u3092\u59cb\u3081\u308b\u524d\u306e\u8a2d\u5b9a\n\n\u30fb\u5b66\u7fd2\u30c7\u30fc\u30bf\u306e\u30b5\u30a4\u30ba\u3092\u53d6\u5f97\n\u30fb\u30b8\u30e3\u30f3\u30d7\u306e\u5e45\u3092\u8a2d\u5b9a\uff08\u9806\u6b21\u5b66\u7fd2\u3057\u306a\u3044\uff09\n\u30fb\u30d1\u30fc\u30d7\u30ec\u30ad\u30b7\u30c6\u30a3\u30920\u3067\u521d\u671f\u5316\n\u30fb\u6700\u521d\u306e\u6642\u9593\u60c5\u5831\u3092\u53d6\u5f97\n\u30fb\u521d\u671f\u72b6\u614b\u3092\u73fe\u5728\u306e\u72b6\u614b\u306b\u4ed8\u4e0e\n\u30fb\u72b6\u614b\u306e\u521d\u671f\u5316\n\u30fb\u640d\u5931\u30920\u3067\u521d\u671f\u5316\n\n```py\n\n# Learning loop\nwhole_len = train_data.shape[0]\njump = whole_len // batchsize\ncur_log_perp = mod.zeros(())\nepoch = 0\nstart_at = time.time()\ncur_at = start_at\nstate = make_initial_state()\naccum_loss = chainer.Variable(mod.zeros(()))\nprint('going to train {} iterations'.format(jump * n_epoch))\n```\n\n###\u78ba\u7387\u7684\u52fe\u914d\u6cd5\u3092\u7528\u3044\u305f\u5b66\u7fd2\n\n\u78ba\u7387\u7684\u52fe\u914d\u6cd5\u3092\u7528\u3044\u3066\u5b66\u7fd2\u3057\u3066\u3044\u308b\u3002\n\u4e00\u5b9a\u306e\u30c7\u30fc\u30bf\u3092\u9078\u629e\u3057\u640d\u5931\u8a08\u7b97\u3092\u3057\u306a\u304c\u3089\u30d1\u30e9\u30e1\u30fc\u30bf\u66f4\u65b0\u3092\u3057\u3066\u3044\u308b\u3002\n\u9010\u6b21\u5c24\u5ea6\u306e\u8a08\u7b97\u3082\u884c\u3063\u3066\u3044\u308b\u3002\n\n```py\nfor i in six.moves.range(jump * n_epoch):\n    x_batch = np.array([train_data[(jump * j + i) % whole_len]\n                        for j in six.moves.range(batchsize)])\n    y_batch = np.array([train_data[(jump * j + i + 1) % whole_len]\n                        for j in six.moves.range(batchsize)])\n    state, loss_i = forward_one_step(x_batch, y_batch, state)\n    accum_loss += loss_i\n    cur_log_perp += loss_i.data.reshape(())\n\n```\n\u30fb\u30d0\u30c3\u30af\u30d7\u30ed\u30d1\u30b2\u30fc\u30b7\u30e7\u30f3\u3067\u30d1\u30e9\u30e1\u30fc\u30bf\u3092\u66f4\u65b0\u3059\u308b\u3002\n\u30fbtruncate\u306f\u3069\u308c\u3060\u3051\u904e\u53bb\u306e\u5c65\u6b74\u3092\u898b\u308b\u304b\u3092\u8868\u3057\u3066\u3044\u308b\u3002\nhttp://kiyukuta.github.io/2013/12/09/mlac2013_day9_recurrent_neural_network_language_model.html#recurrent-neural-network\n\u30fbL2\u6b63\u898f\u5316\u3092\u304b\u3051\u3066\u3044\u308b\u3002\n\n```py\n\n    if (i + 1) % bprop_len == 0:  # Run truncated BPTT\n        optimizer.zero_grads()\n        accum_loss.backward()\n        accum_loss.unchain_backward()  # truncate\n        accum_loss = chainer.Variable(mod.zeros(()))\n\n        optimizer.clip_grads(grad_clip)\n        optimizer.update()\n```\n\n\u5b66\u7fd2\u30c7\u30fc\u30bf\u306e\u30d1\u30fc\u30d7\u30ec\u30ad\u30b7\u30c6\u30a3\u306e\u8a08\u7b97\uff089999\u56de\u306b1\u56de\u884c\u3046\uff09\u3057\u3001\u8868\u793a\u3059\u308b\u3002\n\n\n```py\n\n    if (i + 1) % 10000 == 0:\n        now = time.time()\n        throuput = 10000. / (now - cur_at)\n        perp = math.exp(cuda.to_cpu(cur_log_perp) / 10000)\n        print('iter {} training perplexity: {:.2f} ({:.2f} iters/sec)'.format(\n            i + 1, perp, throuput))\n        cur_at = now\n        cur_log_perp.fill(0)\n```\n\n\u30d0\u30ea\u30c7\u30fc\u30b7\u30e7\u30f3\u30c7\u30fc\u30bf\u306e\u30d1\u30fc\u30d7\u30ec\u30ad\u30b7\u30c6\u30a3\u306e\u8a08\u7b97\uff08\u30d0\u30ea\u30c7\u30fc\u30b7\u30e7\u30f3\u306e\u5e45\u306b\u3088\u3063\u3066\u7570\u306a\u308b\uff09\u3057\u8868\u793a\u3059\u308b\n\n```py\n\n    if (i + 1) % jump == 0:\n        epoch += 1\n        print('evaluate')\n        now = time.time()\n        perp = evaluate(valid_data)\n        print('epoch {} validation perplexity: {:.2f}'.format(epoch, perp))\n        cur_at += time.time() - now  # skip time of evaluation\n\n        if epoch >= 6:\n            optimizer.lr /= 1.2\n            print('learning rate =', optimizer.lr)\n\n    sys.stdout.flush()\n\n```\n\n###\u8a55\u4fa1\n\n\u30c6\u30b9\u30c8\u30c7\u30fc\u30bf\u306b\u5bfe\u3059\u308b\u30d1\u30fc\u30d7\u30ec\u30ad\u30b7\u30c6\u30a3\u306e\u8a08\u7b97\n\n```py\n\n# Evaluate on test dataset\nprint('test')\ntest_perp = evaluate(test_data)\nprint('test perplexity:', test_perp)\n```\n\n\n#\u53c2\u8003\u30b5\u30a4\u30c8\u4e00\u89a7\n\n\u8a00\u8a9e\u30e2\u30c7\u30eb\u306e\u30ab\u30d0\u30ec\u30fc\u30b8\u3001\u30d1\u30fc\u30d7\u30ec\u30ad\u30b7\u30c6\u30a3\u306e\u8aac\u660e\n\nhttp://marujirou.hatenablog.com/entry/2014/08/22/235215\n\n\u30c7\u30a3\u30fc\u30d7\u30e9\u30fc\u30cb\u30f3\u30b0\u30d5\u30ec\u30fc\u30e0\u30ef\u30fc\u30afChainer\u3092EC2\u306eGPU\u30a4\u30f3\u30b9\u30bf\u30f3\u30b9\u3067\u52d5\u304b\u3059 g2.2xlarge instance\n\nhttp://ukonlly.hatenablog.jp/entry/2015/07/04/210149\n\nDrop Out\n\nhttp://olanleed.hatenablog.com/entry/2013/12/03/010945\n\nLearning to forget continual prediction with lstm\n\nhttp://www.slideshare.net/FujimotoKeisuke/learning-to-forget-continual-prediction-with-lstm\n\nZaremba, Wojciech, Ilya Sutskever, and Oriol Vinyals. \"Recurrent neural network regularization.\" arXiv preprint arXiv:1409.2329 (2014).\n\nGoogle Mikolov\n\nhttp://www.rnnlm.org/\n\nNeural Network(NN)\u3092\u5229\u7528\u3057\u305fLanguage Model(LM)\uff0c\u3064\u307e\u308aNeural Network Language Model(NNLM)\u306e\u4e00\u7a2e\u3067\u3042\u308a\uff0c Recurrent Neural Network(RNN)\u3092\u4f7f\u3063\u305fRecurrent Neural Network Language Model(RNNLM)\n\nhttp://kiyukuta.github.io/2013/12/09/mlac2013_day9_recurrent_neural_network_language_model.html\n\nLong Short-term Memory\n\nhttp://www.slideshare.net/nishio/long-shortterm-memory\n\nChainer\u306eptb\u30b5\u30f3\u30d7\u30eb\u3092\u89e3\u8aac\u3057\u3064\u3064\u3001\u81ea\u5206\u306e\u6587\u7ae0\u3092\u6df1\u5c64\u5b66\u7fd2\u3055\u305b\u3066\u3001\u50d5\u306e\u6587\u7ae0\u3063\u307d\u3044\u6587\u3092\u81ea\u52d5\u751f\u6210\u3055\u305b\u3066\u307f\u308b\n\nhttp://d.hatena.ne.jp/shi3z/20150714/1436832305\n\nRNNLM\n\nhttp://www.slideshare.net/uchumik/rnnln\n\n\u30b9\u30d1\u30fc\u30b9\u63a8\u5b9a\u6982\u89b3\uff1a\u30e2\u30c7\u30eb\u30fb\u7406\u8ad6\u30fb\u5fdc\u7528\n\nhttp://www.is.titech.ac.jp/~s-taiji/tmp/sparse_tutorial_2014.pdf\n\n\u6b63\u5247\u5316\u5b66\u7fd2\u6cd5\u306b\u304a\u3051\u308b\u6700\u9069\u5316\u624b\u6cd5\n\nhttp://imi.kyushu-u.ac.jp/~waki/ws2013/slide/suzuki.pdf\n\n\u30ea\u30ab\u30ec\u30f3\u30c8\u30cb\u30e5\u30fc\u30e9\u30eb\u8a00\u8a9e\u30e2\u30c7\u30eb\u4f5c\u6210\u53c2\u8003\nhttps://github.com/yusuketomoto/chainer-char-rnn\n\n\u30cb\u30e5\u30fc\u30e9\u30eb\u30cd\u30c3\u30c8\u3000\u81ea\u7136\u8a00\u8a9e\u51e6\u7406\nhttp://www.orsj.or.jp/archive2/or60-4/or60_4_205.pdf\n\n\u8a00\u8a9e\u30e2\u30c7\u30eb\u4f5c\u6210\nhttp://www.slideshare.net/uchumik/rnnln\n\n\u81ea\u7136\u8a00\u8a9e\u51e6\u7406\u30d7\u30ed\u30b0\u30e9\u30df\u30f3\u30b0\u52c9\u5f37\u4f1an-gram\u8a00\u8a9e\u30e2\u30c7\u30eb\nhttp://www.phontron.com/slides/nlp-programming-ja-02-bigramlm.pdf\n\nStatistical Semantic\u5165\u9580 ~\u5206\u5e03\u4eee\u8aac\u304b\u3089word2vec\u307e\u3067~\nhttp://www.slideshare.net/unnonouno/20140206-statistical-semantics\n\nlinux source code\nhttps://github.com/torvalds/linux\n\n\u306a\u305cGPU\u30b3\u30f3\u30d4\u30e5\u30fc\u30c6\u30a3\u30f3\u30b0\u304c\u6ce8\u76ee\u3092\u6d74\u3073\u3066\u3044\u308b\u304b - \u6176\u61c9\u7fa9\u587e http://www.yasuoka.mech.keio.ac.jp/gpu/gpu_0.php\n\nCUDA\u6280\u8853\u3092\u5229\u7528\u3057\u305fGPU\u30b3\u30f3\u30d4\u30e5\u30fc\u30c6\u30a3\u30f3\u30b0\u306e\u5b9f\u969b\uff08\u524d\u7de8\uff09 \u2015\u2015 \u30b0\u30e9\u30d5\u30a3\u30c3\u30af\u30b9\u5206\u91ce\u3067\u78e8\u304b\u308c\u305f\u4e26\u5217\u51e6\u7406\u6280\u8853\u3092\u6c4e\u7528\u6570\u5024\u8a08\u7b97\u306b\u5fdc\u7528\nhttp://www.kumikomi.net/archives/2008/06/12gpu1.php?page=1\n\nGPGPU\nhttps://ja.wikipedia.org/wiki/GPGPU#.E7.89.B9.E5.BE.B4.E3.81.A8.E8.AA.B2.E9.A1.8C\n"}