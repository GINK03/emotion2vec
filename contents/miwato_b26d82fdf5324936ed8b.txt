{"context": "\n\n\u74b0\u5883\nPrometheus\u306fDocker\u30b3\u30f3\u30c6\u30ca\u4e0a\u3067\u52d5\u304b\u3057\u3066\u3044\u307e\u3059\u3002\n\u30af\u30e9\u30a6\u30c9\u74b0\u5883\uff1aAzure\nDocker\u30db\u30b9\u30c8\uff1aCentOS7.3\nDocker\u30b3\u30f3\u30c6\u30ca\uff1a\uff08prometheus\u30b5\u30fc\u30d0\uff09CentOS7.3\n<\u76e3\u8996\u5bfe\u8c61>\nDocker\u30db\u30b9\u30c8\uff1aCentOS7.3\nDocker\u30b3\u30f3\u30c6\u30ca\uff1aCentOS7.3 (Web\u30b5\u30fc\u30d0\u3092\u60f3\u5b9a\u3057\u3066Apache\u3092\u8d77\u52d5\uff09\n\n\u524d\u63d0\u6761\u4ef6\n\u30fbPrometheus\u30b5\u30fc\u30d0\u306e\u30a4\u30f3\u30b9\u30c8\u30fc\u30eb\u304c\u5b8c\u4e86\u3057\u3066\u3044\u308b\u3053\u3068\nPrometheus\u3092CentOS7.3\uff06Docker\u4e0a\u306b\u30a4\u30f3\u30b9\u30c8\u30fc\u30eb\u3057\u3066\u307f\u305f\n\nAlertManager\u306e\u30a4\u30f3\u30b9\u30c8\u30fc\u30eb\n\uff11\uff0eAlertMananager\u306eURL\u30b3\u30d4\u30fc\nPrometheus\u516c\u5f0f\u30b5\u30a4\u30c8 \u304b\u3089AlertManager\u3092\u30c0\u30a6\u30f3\u30ed\u30fc\u30c9\u3057\u307e\u3059\u3002\n\u4eca\u56de\u306e\u74b0\u5883\u3067\u306f\u3001\u6b21\u306e\u3082\u306e\u3092\u9078\u629e\u3057\u307e\u3059\u3002\nOperating system: linux\nArchitecture: amd64\nalertmanager\u3092\u63a2\u3057\u3066\u3001\u30ea\u30f3\u30af\u306e\u30a2\u30c9\u30ec\u30b9\u3092\u30b3\u30d4\u30fc\u3057\u3066\u304f\u3060\u3055\u3044\u3002\n\uff12\uff0e\u30c0\u30a6\u30f3\u30ed\u30fc\u30c9\n<Promethus\u30b5\u30fc\u30d0>\n## cd /usr/local/src\n## wget https://github.com/prometheus/alertmanager/releases/download/v0.5.1/alertmanager-0.5.1.linux-amd64.tar.gz\n## tar xfvz alertmanager-0.5.1.linux-amd64.tar.gz\n## cd alertmanager-0.5.1.linux-amd64/\n## cp -p alertmanager /usr/bin/.\n\n\uff13\uff0e\u8a2d\u5b9a\u30d5\u30a1\u30a4\u30eb\u306e\u914d\u7f6e\n<Promethus\u30b5\u30fc\u30d0>\n## cd /etc/prometheus\n## wget https://raw.githubusercontent.com/alerta/prometheus-config/master/alertmanager.yml\n(Default\u72b6\u614b)\n## cat /etc/prometheus/alertmanager.yml\nglobal:\n  # The smarthost and SMTP sender used for mail notifications.\n  smtp_smarthost: 'localhost:25'                  \n  smtp_from: 'alertmanager@example.org'           \n\nroute:\n  receiver: \"alerta\"\n  group_by: ['alertname']\n  group_wait:      30s\n  group_interval:  5m\n  repeat_interval: 2h\n\nreceivers:\n- name: \"alerta\"\n  webhook_configs:\n  - url: 'http://localhost:8080/webhooks/prometheus'\n    send_resolved: true\n\n\uff14\uff0e\u81ea\u52d5\u8d77\u52d5\u8a2d\u5b9a\nAlertManager\u3082\u3057\u3063\u304b\u308a\u3068\u81ea\u52d5\u8d77\u52d5\u3059\u308b\u3088\u3046\u306b\u3057\u307e\u3057\u3087\u3046\u3002\n<Promethus\u30b5\u30fc\u30d0>\n## vi /etc/default/alertmanager\nOPTIONS=\"-config.file /etc/prometheus/alertmanager.yml\"\n\n## vi /usr/lib/systemd/system/alertmanager.service\n\n[Unit]\nDescription=Prometheus alertmanager Service\nAfter=syslog.target.prometheus.alertmanager.service\n\n[Service]\nType=simple\nEnvironmentFile=-/etc/default/alertmanager\nExecStart=/usr/bin/alertmanager $OPTIONS\nPrivateTmp=true\n\n[Install]\nWantedBy=multi-user.target\n\n\n## systemctl enable alertmanager.service\nCreated symlink from /etc/systemd/system/multi-user.target.wants/alertmanager.service to /usr/lib/systemd/system/alertmanager.service.\n## systemctl start alertmanager\n\n\n\uff15\uff0e\u30a2\u30e9\u30fc\u30c8\u8a2d\u5b9a\u524d\u6e96\u5099\uff08\u30e1\u30fc\u30eb\u8a2d\u5b9a\uff09\n\u30e1\u30fc\u30eb\u9001\u4fe1\u306e\u4ed5\u7d44\u307f\u306f\u3001\u74b0\u5883\u306b\u5408\u308f\u305b\u3066\u5b9f\u65bd\u3057\u307e\u3057\u3087\u3046\u3002\n\u4eca\u56de\u306f\u3001Azure\u306eVM\u4e0a\u3067\u74b0\u5883\u3092\u7d44\u307f\u7acb\u3066\u3066\u3044\u308b\u3053\u3068\u3082\u3042\u308a\u3001\u3053\u3061\u3089\u3092\u53c2\u8003\u306b\u30e1\u30fc\u30eb\u9001\u4fe1\u306e\u6a5f\u80fd\u3092\u5177\u5099\u3057\u307e\u3059\u3002\nAzure\u306e\u30e1\u30fc\u30eb\u9001\u4fe1\u306fSendGrid\n\n\uff16\uff0e\u30a2\u30e9\u30fc\u30c8\u8a2d\u5b9a\n\u300c\uff13\uff0e\u8a2d\u5b9a\u30d5\u30a1\u30a4\u30eb\u306e\u914d\u7f6e\u300d\u306econfig\u30d5\u30a1\u30a4\u30eb\u3092\u7de8\u96c6\u3057\u307e\u3057\u3087\u3046\u3002\n\u4eca\u56de\u306f\u3001Mail\u30a2\u30e9\u30fc\u30c8\u306e\u8a2d\u5b9a\u3092\u5165\u308c\u307e\u3059\u3002\u5024\u306fDefault\u5024\u304b\u3089\u5909\u3048\u3066\u3044\u307e\u3059\u3002\n<Promethus\u30b5\u30fc\u30d0>\n## cat alertmanager.yml\nglobal:\n# The smarthost and SMTP sender used for mail notifications.\n  smtp_smarthost: 'smtp.sendgrid.net:25'    \u2605 SendGrid \u306eSMTP\u63a5\u7d9a\u5148\n  smtp_from: '****************@******'      \u2605 SendGrid \u767b\u9332\u30e1\u30fc\u30eb\u30a2\u30c9\u30ec\u30b9\n  smtp_auth_username: '****@azure.com'      \u2605 SendGrid \u3067\u6255\u3044\u51fa\u3055\u308c\u305fUserName\n  smtp_auth_password: '*******'             \u2605 SendGrid \u3067\u8a2d\u5b9a\u3057\u305f\u30d1\u30b9\u30ef\u30fc\u30c9\uff08\u5e73\u6587\u3067\u8a18\u8f09\u3059\u308b\u306e\u306f\u3061\u3087\u3063\u3068\u306d\uff09\n  smtp_auth_secret: '*********'             \u2605 SendGrid \u3067\u6255\u3044\u51fa\u3055\u308c\u305fAPI\u30ad\u30fc\n\nroute:\n  receiver: \"mail\"\n  group_by: ['alertname', 'instance', 'severity']   \u2605 \u540c\u4e00\u30a2\u30e9\u30fc\u30c8\u540d\u3001\u540c\u4e00\u30a4\u30f3\u30b9\u30bf\u30f3\u30b9\u3001\u540c\u4e00\u30b5\u30fc\u30d3\u30b9\u306e\u30a2\u30e9\u30fc\u30c8\u306b\u5bfe\u3057\u3066\n  group_wait: 30s                                   \u2605 30\u79d2\u4ee5\u5185\u306e\u30a2\u30e9\u30fc\u30c8\u306f\u540c\u4e00\u30a2\u30e9\u30fc\u30c8\u3068\u898b\u306a\u3059\n  group_interval: 10m                               \u2605 10\u5206\u6bce\u306b\u901a\u77e5\n  repeat_interval: 1h                               \u2605 \u4e00\u5ea6\u901a\u77e5\u3057\u305f\u30a2\u30e9\u30fc\u30c8\u306f 1\u6642\u9593\u5f8c\u306b\u901a\u77e5\n\n#  receiver: \"slack-notifications\"\n#  group_by: ['alertname', 'instance']\n\nreceivers:\n - name: 'mail'\n   email_configs:\n   - to: *****@********,####@######        \u2605 \u30a2\u30e9\u30fc\u30c8\u9001\u4fe1\u5148\u306e\u30a2\u30c9\u30ec\u30b9\uff08\u8907\u6570\u3042\u308b\u3068\u304d\u306f\u3001, \u30ab\u30f3\u30de\u533a\u5207\u308a\uff09\n                                           \u2605 \u33c4\u306f\u3001\u9811\u5f35\u3063\u305f\u3051\u3069\u3067\u304d\u306a\u3044\u3002\u3002\u3002\n                                           \u2605 to\u3092\u5206\u3051\u305f\u3044\u3068\u304d\u306f\u3001-to: \u3092\u540c\u3058\u3088\u3046\u306b\u8a18\u8f09\u3059\u308c\u3070OK\n\ninhibit_rules:\n - source_match:\n     severity: 'critical'                  \u2605 \u30a2\u30e9\u30fc\u30c8\u306e\u6df1\u523b\u5ea6(severity) \u304c critical \u306e\u5834\u5408\u3001\n   target_match:                           \u2605 \u540c\u4e00\u306e\u30a2\u30e9\u30fc\u30c8\u540d\u3067 warning \u306e\u3082\u306e\u306f\u901a\u77e5\u3057\u306a\u3044\u3002\n     severity: 'warning'\n   equal: ['alertname']\n\n\n\uff17\uff0e\u30eb\u30fc\u30eb\u8a2d\u5b9a\n\u30eb\u30fc\u30eb\u8a2d\u5b9a\u306f\u3001\u81ea\u5206\u3067\u5fc5\u8981\u3068\u306a\u308b\u30eb\u30fc\u30eb\u3092\u691c\u8a0e\u3057\u3066\u307f\u3066\u304f\u3060\u3055\u3044\u3002\n<Promethus\u30b5\u30fc\u30d0>\n## cat /etc/prometheus/alert.rules\nALERT instance_down\n  IF up == 0\n  FOR 2m\n  LABELS { severity = \"critical\" }\n  ANNOTATIONS {\n    summary = \"Instance {{ $labels.instance }} down\",\n    description = \"{{ $labels.instance }} of job {{ $labels.job }} has been down for more than 2 minutes.\",\n  }\n\nALERT cpu_threshold_exceeded\n  IF (100 * (1 - avg by(instance)(irate(node_cpu{job='node',mode='idle'}[5m])))) > THRESHOLD_CPU\n  ANNOTATIONS {\n    summary = \"Instance {{ $labels.instance }} CPU usage is dangerously high\",\n    description = \"This device's cpu usage has exceeded the threshold with a value of {{ $value }}.\",\n  }\n\nALERT mem_threshold_exceeded\n  IF (node_memory_MemFree{job='node'} + node_memory_Cached{job='node'} + node_memory_Buffers{job='node'})/1000000 < THRESHOLD_MEM\n  ANNOTATIONS {\n    summary = \"Instance {{ $labels.instance }} memory usage is dangerously high\",\n    description = \"This device's memory usage has exceeded the threshold with a value of {{ $value }}.\",\n  }\n\nALERT filesystem_threshold_exceeded\n  IF node_filesystem_avail{job='node',mountpoint='/'} / node_filesystem_size{job='node'} * 100 < THRESHOLD_FS\n  ANNOTATIONS {\n    summary = \"Instance {{ $labels.instance }} filesystem usage is dangerously high\",\n    description = \"This device's filesystem usage has exceeded the threshold with a value of {{ $value }}.\",\n  }\n\nALERT node_high_loadaverage\n  IF rate(node_load1[1m]) > 2\n  FOR 10s\n  LABELS { severity = \"warning\" }\n  ANNOTATIONS {\n    summary = \"High load average on {{$labels.instance}}\",\n    description = \"{{$labels.instance}} has a high load average above 10s (current value: {{$value}})\"\n  }\n\n\n\n\uff18\uff0eprometheus \u306b\u7d44\u307f\u8fbc\u307f\nPrometheus\u306bAlertmanager\u3092\u7d44\u307f\u8fbc\u307f\u307e\u3057\u3087\u3046\u3002\n/etc/prometheus/prometheus.yml \u306e\u672b\u5c3e\u306b\u8ffd\u52a0\u3057\u307e\u3059\u3002\nalerting:\n  alertmanagers:\n  - scheme: http\n    static_configs:\n    - targets: ['<\u30db\u30b9\u30c8\u540d>.japaneast.cloudapp.azure.com:9093']\n\n\n\uff19\uff0e\u6700\u5f8c\u306b\n\u8a2d\u5b9a\u30d5\u30a1\u30a4\u30eb\u306e\u8a18\u8f09\u304c\u6b63\u3057\u3044\u304b\u3061\u3083\u3093\u3068\u78ba\u8a8d\u3057\u307e\u3057\u3087\u3046\u3002\n<Promethus\u30b5\u30fc\u30d0>\n## promtool check-config /etc/prometheus/prometheus.yml\n## promtool check-config /etc/prometheus/alertmanager.yml\n\n\nalertmanager\u3001Prometheus\u3092\u518d\u8d77\u52d5\u3057\u3066\u5b8c\u4e86\u3067\u3059\u3002\n<Promethus\u30b5\u30fc\u30d0>\n## systemctl restart alertmanager\n## systemctl restart prometheus\n\n\n\n\uff11\uff10\uff0e\u52d5\u4f5c\u78ba\u8a8d\n\u9069\u5f53\u306b\u76e3\u8996\u5bfe\u8c61\u306e\u30b5\u30fc\u30d0\u3092\u6b62\u3081\u3066\u307f\u307e\u3057\u3087\u3046\u3002\n\u30e1\u30fc\u30eb\u304c\u98db\u3093\u3067\u304d\u307e\u3059\u3002\n\n\n\u53c2\u8003\u30b5\u30a4\u30c8\nTech-Sketch\nPrometheus\u74b0\u5883\u69cb\u7bc9\u624b\u9806\nAzure\u306e\u30e1\u30fc\u30eb\u9001\u4fe1\u306fSendGrid\n# \u74b0\u5883\nPrometheus\u306fDocker\u30b3\u30f3\u30c6\u30ca\u4e0a\u3067\u52d5\u304b\u3057\u3066\u3044\u307e\u3059\u3002\n\u30af\u30e9\u30a6\u30c9\u74b0\u5883\uff1aAzure\nDocker\u30db\u30b9\u30c8\uff1aCentOS7.3\nDocker\u30b3\u30f3\u30c6\u30ca\uff1a\uff08prometheus\u30b5\u30fc\u30d0\uff09CentOS7.3\n\n<\u76e3\u8996\u5bfe\u8c61>\nDocker\u30db\u30b9\u30c8\uff1aCentOS7.3\nDocker\u30b3\u30f3\u30c6\u30ca\uff1aCentOS7.3 (Web\u30b5\u30fc\u30d0\u3092\u60f3\u5b9a\u3057\u3066Apache\u3092\u8d77\u52d5\uff09\n\n\n# \u524d\u63d0\u6761\u4ef6\n\u30fbPrometheus\u30b5\u30fc\u30d0\u306e\u30a4\u30f3\u30b9\u30c8\u30fc\u30eb\u304c\u5b8c\u4e86\u3057\u3066\u3044\u308b\u3053\u3068\n[Prometheus\u3092CentOS7.3\uff06Docker\u4e0a\u306b\u30a4\u30f3\u30b9\u30c8\u30fc\u30eb\u3057\u3066\u307f\u305f](http://qiita.com/miwato/items/db455d8e8bd1cc3c5642)\n\n# AlertManager\u306e\u30a4\u30f3\u30b9\u30c8\u30fc\u30eb\n\n\uff11\uff0eAlertMananager\u306eURL\u30b3\u30d4\u30fc\n\n[Prometheus\u516c\u5f0f\u30b5\u30a4\u30c8](https://prometheus.io/download/) \u304b\u3089AlertManager\u3092\u30c0\u30a6\u30f3\u30ed\u30fc\u30c9\u3057\u307e\u3059\u3002\n\n\u4eca\u56de\u306e\u74b0\u5883\u3067\u306f\u3001\u6b21\u306e\u3082\u306e\u3092\u9078\u629e\u3057\u307e\u3059\u3002\nOperating system: linux\nArchitecture: amd64\n\nalertmanager\u3092\u63a2\u3057\u3066\u3001\u30ea\u30f3\u30af\u306e\u30a2\u30c9\u30ec\u30b9\u3092\u30b3\u30d4\u30fc\u3057\u3066\u304f\u3060\u3055\u3044\u3002\n\n\n\uff12\uff0e\u30c0\u30a6\u30f3\u30ed\u30fc\u30c9\n\n```\n<Promethus\u30b5\u30fc\u30d0>\n## cd /usr/local/src\n## wget https://github.com/prometheus/alertmanager/releases/download/v0.5.1/alertmanager-0.5.1.linux-amd64.tar.gz\n## tar xfvz alertmanager-0.5.1.linux-amd64.tar.gz\n## cd alertmanager-0.5.1.linux-amd64/\n## cp -p alertmanager /usr/bin/.\n```\n\n\uff13\uff0e\u8a2d\u5b9a\u30d5\u30a1\u30a4\u30eb\u306e\u914d\u7f6e\n\n```\n<Promethus\u30b5\u30fc\u30d0>\n## cd /etc/prometheus\n## wget https://raw.githubusercontent.com/alerta/prometheus-config/master/alertmanager.yml\n(Default\u72b6\u614b)\n## cat /etc/prometheus/alertmanager.yml\nglobal:\n  # The smarthost and SMTP sender used for mail notifications.\n  smtp_smarthost: 'localhost:25'                  \n  smtp_from: 'alertmanager@example.org'           \n\nroute:\n  receiver: \"alerta\"\n  group_by: ['alertname']\n  group_wait:      30s\n  group_interval:  5m\n  repeat_interval: 2h\n\nreceivers:\n- name: \"alerta\"\n  webhook_configs:\n  - url: 'http://localhost:8080/webhooks/prometheus'\n    send_resolved: true\n```\n\n\uff14\uff0e\u81ea\u52d5\u8d77\u52d5\u8a2d\u5b9a\nAlertManager\u3082\u3057\u3063\u304b\u308a\u3068\u81ea\u52d5\u8d77\u52d5\u3059\u308b\u3088\u3046\u306b\u3057\u307e\u3057\u3087\u3046\u3002\n\n```\n<Promethus\u30b5\u30fc\u30d0>\n## vi /etc/default/alertmanager\nOPTIONS=\"-config.file /etc/prometheus/alertmanager.yml\"\n\n## vi /usr/lib/systemd/system/alertmanager.service\n\n[Unit]\nDescription=Prometheus alertmanager Service\nAfter=syslog.target.prometheus.alertmanager.service\n\n[Service]\nType=simple\nEnvironmentFile=-/etc/default/alertmanager\nExecStart=/usr/bin/alertmanager $OPTIONS\nPrivateTmp=true\n\n[Install]\nWantedBy=multi-user.target\n\n\n## systemctl enable alertmanager.service\nCreated symlink from /etc/systemd/system/multi-user.target.wants/alertmanager.service to /usr/lib/systemd/system/alertmanager.service.\n## systemctl start alertmanager\n```\n\n# \uff15\uff0e\u30a2\u30e9\u30fc\u30c8\u8a2d\u5b9a\u524d\u6e96\u5099\uff08\u30e1\u30fc\u30eb\u8a2d\u5b9a\uff09\n\u30e1\u30fc\u30eb\u9001\u4fe1\u306e\u4ed5\u7d44\u307f\u306f\u3001\u74b0\u5883\u306b\u5408\u308f\u305b\u3066\u5b9f\u65bd\u3057\u307e\u3057\u3087\u3046\u3002\n\u4eca\u56de\u306f\u3001Azure\u306eVM\u4e0a\u3067\u74b0\u5883\u3092\u7d44\u307f\u7acb\u3066\u3066\u3044\u308b\u3053\u3068\u3082\u3042\u308a\u3001\u3053\u3061\u3089\u3092\u53c2\u8003\u306b\u30e1\u30fc\u30eb\u9001\u4fe1\u306e\u6a5f\u80fd\u3092\u5177\u5099\u3057\u307e\u3059\u3002\n[Azure\u306e\u30e1\u30fc\u30eb\u9001\u4fe1\u306fSendGrid](http://qiita.com/miwato/items/af684bdcba49a2e2293e)\n\n\n# \uff16\uff0e\u30a2\u30e9\u30fc\u30c8\u8a2d\u5b9a\n\u300c\uff13\uff0e\u8a2d\u5b9a\u30d5\u30a1\u30a4\u30eb\u306e\u914d\u7f6e\u300d\u306econfig\u30d5\u30a1\u30a4\u30eb\u3092\u7de8\u96c6\u3057\u307e\u3057\u3087\u3046\u3002\n\u4eca\u56de\u306f\u3001Mail\u30a2\u30e9\u30fc\u30c8\u306e\u8a2d\u5b9a\u3092\u5165\u308c\u307e\u3059\u3002\u5024\u306fDefault\u5024\u304b\u3089\u5909\u3048\u3066\u3044\u307e\u3059\u3002\n\n```\n<Promethus\u30b5\u30fc\u30d0>\n## cat alertmanager.yml\nglobal:\n# The smarthost and SMTP sender used for mail notifications.\n  smtp_smarthost: 'smtp.sendgrid.net:25'    \u2605 SendGrid \u306eSMTP\u63a5\u7d9a\u5148\n  smtp_from: '****************@******'      \u2605 SendGrid \u767b\u9332\u30e1\u30fc\u30eb\u30a2\u30c9\u30ec\u30b9\n  smtp_auth_username: '****@azure.com'      \u2605 SendGrid \u3067\u6255\u3044\u51fa\u3055\u308c\u305fUserName\n  smtp_auth_password: '*******'             \u2605 SendGrid \u3067\u8a2d\u5b9a\u3057\u305f\u30d1\u30b9\u30ef\u30fc\u30c9\uff08\u5e73\u6587\u3067\u8a18\u8f09\u3059\u308b\u306e\u306f\u3061\u3087\u3063\u3068\u306d\uff09\n  smtp_auth_secret: '*********'             \u2605 SendGrid \u3067\u6255\u3044\u51fa\u3055\u308c\u305fAPI\u30ad\u30fc\n\nroute:\n  receiver: \"mail\"\n  group_by: ['alertname', 'instance', 'severity']   \u2605 \u540c\u4e00\u30a2\u30e9\u30fc\u30c8\u540d\u3001\u540c\u4e00\u30a4\u30f3\u30b9\u30bf\u30f3\u30b9\u3001\u540c\u4e00\u30b5\u30fc\u30d3\u30b9\u306e\u30a2\u30e9\u30fc\u30c8\u306b\u5bfe\u3057\u3066\n  group_wait: 30s                                   \u2605 30\u79d2\u4ee5\u5185\u306e\u30a2\u30e9\u30fc\u30c8\u306f\u540c\u4e00\u30a2\u30e9\u30fc\u30c8\u3068\u898b\u306a\u3059\n  group_interval: 10m                               \u2605 10\u5206\u6bce\u306b\u901a\u77e5\n  repeat_interval: 1h                               \u2605 \u4e00\u5ea6\u901a\u77e5\u3057\u305f\u30a2\u30e9\u30fc\u30c8\u306f 1\u6642\u9593\u5f8c\u306b\u901a\u77e5\n\n#  receiver: \"slack-notifications\"\n#  group_by: ['alertname', 'instance']\n\nreceivers:\n - name: 'mail'\n   email_configs:\n   - to: *****@********,####@######        \u2605 \u30a2\u30e9\u30fc\u30c8\u9001\u4fe1\u5148\u306e\u30a2\u30c9\u30ec\u30b9\uff08\u8907\u6570\u3042\u308b\u3068\u304d\u306f\u3001, \u30ab\u30f3\u30de\u533a\u5207\u308a\uff09\n                                           \u2605 \u33c4\u306f\u3001\u9811\u5f35\u3063\u305f\u3051\u3069\u3067\u304d\u306a\u3044\u3002\u3002\u3002\n                                           \u2605 to\u3092\u5206\u3051\u305f\u3044\u3068\u304d\u306f\u3001-to: \u3092\u540c\u3058\u3088\u3046\u306b\u8a18\u8f09\u3059\u308c\u3070OK\n\ninhibit_rules:\n - source_match:\n     severity: 'critical'                  \u2605 \u30a2\u30e9\u30fc\u30c8\u306e\u6df1\u523b\u5ea6(severity) \u304c critical \u306e\u5834\u5408\u3001\n   target_match:                           \u2605 \u540c\u4e00\u306e\u30a2\u30e9\u30fc\u30c8\u540d\u3067 warning \u306e\u3082\u306e\u306f\u901a\u77e5\u3057\u306a\u3044\u3002\n     severity: 'warning'\n   equal: ['alertname']\n```\n\n# \uff17\uff0e\u30eb\u30fc\u30eb\u8a2d\u5b9a\n\u30eb\u30fc\u30eb\u8a2d\u5b9a\u306f\u3001\u81ea\u5206\u3067\u5fc5\u8981\u3068\u306a\u308b\u30eb\u30fc\u30eb\u3092\u691c\u8a0e\u3057\u3066\u307f\u3066\u304f\u3060\u3055\u3044\u3002\n\n```\n<Promethus\u30b5\u30fc\u30d0>\n## cat /etc/prometheus/alert.rules\nALERT instance_down\n  IF up == 0\n  FOR 2m\n  LABELS { severity = \"critical\" }\n  ANNOTATIONS {\n    summary = \"Instance {{ $labels.instance }} down\",\n    description = \"{{ $labels.instance }} of job {{ $labels.job }} has been down for more than 2 minutes.\",\n  }\n\nALERT cpu_threshold_exceeded\n  IF (100 * (1 - avg by(instance)(irate(node_cpu{job='node',mode='idle'}[5m])))) > THRESHOLD_CPU\n  ANNOTATIONS {\n    summary = \"Instance {{ $labels.instance }} CPU usage is dangerously high\",\n    description = \"This device's cpu usage has exceeded the threshold with a value of {{ $value }}.\",\n  }\n\nALERT mem_threshold_exceeded\n  IF (node_memory_MemFree{job='node'} + node_memory_Cached{job='node'} + node_memory_Buffers{job='node'})/1000000 < THRESHOLD_MEM\n  ANNOTATIONS {\n    summary = \"Instance {{ $labels.instance }} memory usage is dangerously high\",\n    description = \"This device's memory usage has exceeded the threshold with a value of {{ $value }}.\",\n  }\n\nALERT filesystem_threshold_exceeded\n  IF node_filesystem_avail{job='node',mountpoint='/'} / node_filesystem_size{job='node'} * 100 < THRESHOLD_FS\n  ANNOTATIONS {\n    summary = \"Instance {{ $labels.instance }} filesystem usage is dangerously high\",\n    description = \"This device's filesystem usage has exceeded the threshold with a value of {{ $value }}.\",\n  }\n\nALERT node_high_loadaverage\n  IF rate(node_load1[1m]) > 2\n  FOR 10s\n  LABELS { severity = \"warning\" }\n  ANNOTATIONS {\n    summary = \"High load average on {{$labels.instance}}\",\n    description = \"{{$labels.instance}} has a high load average above 10s (current value: {{$value}})\"\n  }\n\n```\n\n# \uff18\uff0eprometheus \u306b\u7d44\u307f\u8fbc\u307f\nPrometheus\u306bAlertmanager\u3092\u7d44\u307f\u8fbc\u307f\u307e\u3057\u3087\u3046\u3002\n/etc/prometheus/prometheus.yml \u306e\u672b\u5c3e\u306b\u8ffd\u52a0\u3057\u307e\u3059\u3002\n\n```\nalerting:\n  alertmanagers:\n  - scheme: http\n    static_configs:\n    - targets: ['<\u30db\u30b9\u30c8\u540d>.japaneast.cloudapp.azure.com:9093']\n```\n\n# \uff19\uff0e\u6700\u5f8c\u306b\n\u8a2d\u5b9a\u30d5\u30a1\u30a4\u30eb\u306e\u8a18\u8f09\u304c\u6b63\u3057\u3044\u304b\u3061\u3083\u3093\u3068\u78ba\u8a8d\u3057\u307e\u3057\u3087\u3046\u3002\n\n```\n<Promethus\u30b5\u30fc\u30d0>\n## promtool check-config /etc/prometheus/prometheus.yml\n## promtool check-config /etc/prometheus/alertmanager.yml\n\n```\n\nalertmanager\u3001Prometheus\u3092\u518d\u8d77\u52d5\u3057\u3066\u5b8c\u4e86\u3067\u3059\u3002\n\n```\n<Promethus\u30b5\u30fc\u30d0>\n## systemctl restart alertmanager\n## systemctl restart prometheus\n\n```\n\n\n\n# \uff11\uff10\uff0e\u52d5\u4f5c\u78ba\u8a8d\n\u9069\u5f53\u306b\u76e3\u8996\u5bfe\u8c61\u306e\u30b5\u30fc\u30d0\u3092\u6b62\u3081\u3066\u307f\u307e\u3057\u3087\u3046\u3002\n\u30e1\u30fc\u30eb\u304c\u98db\u3093\u3067\u304d\u307e\u3059\u3002\n\n![alertmanager02.png](https://qiita-image-store.s3.amazonaws.com/0/109620/a71e33ec-76e1-62dc-088b-e14fb2fdcb55.png)\n\n\n# \u53c2\u8003\u30b5\u30a4\u30c8\n[Tech-Sketch](http://tech-sketch.jp/2016/04/prometheus_alertmanager.html)\n[Prometheus\u74b0\u5883\u69cb\u7bc9\u624b\u9806](http://qiita.com/tSU_RooT/items/fec5b9217417758988ae)\n[Azure\u306e\u30e1\u30fc\u30eb\u9001\u4fe1\u306fSendGrid](http://qiita.com/miwato/items/af684bdcba49a2e2293e)\n", "tags": ["centos7", "AlertManager", "prometheus"]}