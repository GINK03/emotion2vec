{"context": "dlib\u3068OpenCV\u306e\u9854\u691c\u51fa\u6bd4\u8f03\u3092\u3057\u3066\u307f\u307e\u3057\u305f\u3002\n\u6642\u3005\u898b\u304b\u3051\u308b\u52d5\u753b\u3067\u3059\u304c\u3001\u81ea\u5206\u3067\u3082\u3084\u3063\u3066\u307f\u305f\u304b\u3063\u305f\u306e\u3067\u3001\u3061\u3087\u3063\u3068\u304a\u8a66\u3057\u3002\ndlib\u306e\u307b\u3046\u304c\u5411\u304d\u3068\u304b\u306b\u5bfe\u3059\u308b\u7cbe\u5ea6\u304c\u3088\u304f\u3066\u3001\nOpenCV\u306e\u307b\u3046\u304c\u65e9\u3044\u611f\u3058\uff08Adaboost\u306e\u304a\u304b\u3052\uff1f\n\u696d\u52d9\u3067\u4f7f\u7528\u3059\u308b\u3053\u3068\u306b\u306a\u3063\u305f\u3089\u3001\u3082\u3063\u3068\u8a73\u7d30\u306b\u8abf\u67fb\u4e88\u5b9a\u3002\nLinux\u306e\u307b\u3046\u304cdlib\u306e\u5c0e\u5165\u304c\u7c21\u5358\u306a\u306e\u3067\u3001Ubutntu\u3067\u3084\u3063\u3066\u307e\u3059\u3002\nWindows\u3067\u3082dlib\u3044\u308c\u308c\u3070\u540c\u3058\u30bd\u30fc\u30b9\u3067\u52d5\u304f\u306f\u305a\u3002\u3002\u3002\uff1f\n\u52d5\u753b\u306f\u4ee5\u4e0b\u3002\n\u8d64\u8272\u304cOpenCV\u306b\u3088\u308b\u691c\u51fa\u3067\u3001\u9752\u8272\u304cdlib\u306b\u3088\u308b\u691c\u51fa\u3067\u3059\u3002\n\n\u30bd\u30fc\u30b9\u30b3\u30fc\u30c9\u306f\u4ee5\u4e0b\u3002\n\u52d5\u4f5c\u3055\u305b\u308b\u306b\u306f\u3001py\u30d5\u30a1\u30a4\u30eb\u3068\u540c\u3058\u30c7\u30a3\u30ec\u30af\u30c8\u30ea\u306bOpenCV\u306e\u5b66\u7fd2\u6e08\u307f\u30c7\u30fc\u30bf\u3092\n\u914d\u7f6e\u3059\u308b\u5fc5\u8981\u304c\u3042\u308a\u307e\u3059\u3002\n\u2192./data/haarcascades/haarcascade_frontalface_alt.xml\n\n#!/usr/bin/env python\n# -*- coding: utf-8 -*-\n\n'''\nface_landmark_detector.py.\n\nUsage:\n  face_landmark_detector.py [<video source>] [<resize rate>]\n'''\n\nimport sys\nimport dlib\nimport cv2\nimport time\nimport copy\n\ntry:\n    fn = sys.argv[1]\n    if fn.isdigit() == True:\n        fn = int(fn)\nexcept:\n    fn = 0\n\ntry:\n    resize_rate = sys.argv[2]\n    resize_rate = int(resize_rate)\nexcept:\n    resize_rate = 1\n\n# Dlib\ndetector = dlib.get_frontal_face_detector()\n\n# OpenCV\ncascade_fn = \"./data/haarcascades/haarcascade_frontalface_alt.xml\"\ncascade = cv2.CascadeClassifier(cascade_fn)\n\nvideo_input = cv2.VideoCapture(fn)\n\ntotal_frame_count = 0\nface_detection_frame_count_dlib = 0\nface_detection_frame_count_opencv = 0\n\nwhile(video_input.isOpened() == True):\n    total_frame_count += 1\n\n    ret, frame = video_input.read()\n    temp_frame = copy.deepcopy(frame)\n\n    # \u51e6\u7406\u8ca0\u8377\u8efd\u6e1b\u306e\u305f\u3081\u306e\u5bfe\u8c61\u30d5\u30ec\u30fc\u30e0\u7e2e\u5c0f\uff08\u5f15\u6570\u6307\u5b9a\u6642\uff09\n    height, width = frame.shape[:2]\n    temp_frame = cv2.resize(frame, (int(width/resize_rate), int(height/resize_rate)))\n\n    # \u9854\u691c\u51fa(dlib)\n    start = time.time()\n    dets = detector(temp_frame, 1)\n    elapsed_time_dlib = time.time() - start\n\n    if len(dets) > 0:\n        face_detection_frame_count_dlib += 1\n\n    # \u691c\u51fa\u7d50\u679c\u63cf\u753b\uff08dlib\uff09\n    for k, d in enumerate(dets):\n        cv2.rectangle(frame, (int(d.left() * resize_rate), int(d.top() * resize_rate)), \\\n            (int(d.right() * resize_rate), int(d.bottom() * resize_rate)), (255, 0, 0), -1)\n\n    # \u9854\u691c\u51fa(opencv)\n    gray_image = cv2.cvtColor(temp_frame, cv2.COLOR_BGR2GRAY)\n    gray_image = cv2.equalizeHist(gray_image)\n\n    start = time.time()\n    rects = cascade.detectMultiScale(gray_image, scaleFactor=1.3, minNeighbors=4, minSize=(30, 30), flags=cv2.CASCADE_SCALE_IMAGE)\n    if len(rects) == 0:\n        rects = []\n    else:\n        rects[:,2:] += rects[:,:2]\n    elapsed_time_opencv = time.time() - start\n\n\n    if len(rects) > 0:\n        face_detection_frame_count_opencv += 1\n\n    # \u691c\u51fa\u7d50\u679c\u63cf\u753b\uff08OpenCV\uff09\n    for x1, y1, x2, y2 in rects:\n        cv2.putText(frame, \"OpenCV\", (int(x1 * resize_rate), int(y1 * resize_rate)), cv2.FONT_HERSHEY_PLAIN, 2.0, (0, 0, 255), thickness = 2)\n        cv2.rectangle(frame, (int(x1 * resize_rate), int(y1 * resize_rate)), (int(x2 * resize_rate), int(y2 * resize_rate)), (0, 0, 255), -1)\n    # \u691c\u51fa\u7d50\u679c\u63cf\u753b\uff08dlib\uff09\n    for k, d in enumerate(dets):\n        cv2.putText(frame, \"Dlib\", (int(d.left() * resize_rate), int(d.top() * resize_rate)), cv2.FONT_HERSHEY_PLAIN, 2.0, (255, 0, 0), thickness = 2)\n        cv2.rectangle(frame, (int(d.left() * resize_rate), int(d.top() * resize_rate)), \\\n            (int(d.right() * resize_rate), int(d.bottom() * resize_rate)), (255, 0, 0), 2)\n\n    print (\"face detect(dlib) processing time:{0}\".format(elapsed_time_dlib)) + \"[sec]\"\n    print (\"face detect(opencv) processing time:{0}\".format(elapsed_time_opencv)) + \"[sec]\"\n    print (\"face detect(dlib) success count:\" + '%06d' % face_detection_frame_count_dlib + \"/\" + '%06d' % total_frame_count)\n    print (\"face detect(opencv) success count:\" + '%06d' % face_detection_frame_count_opencv + \"/\" + '%06d' % total_frame_count)\n    print\n\n    cv2.imshow('face detector vs', frame)\n\n    c = cv2.waitKey(50) & 0xFF\n\n    if c==27: # ESC\n        break\n\nvideo_input.release()\ncv2.destroyAllWindows()\n\n\u4ee5\u4e0a\u3002\ndlib\u3068OpenCV\u306e\u9854\u691c\u51fa\u6bd4\u8f03\u3092\u3057\u3066\u307f\u307e\u3057\u305f\u3002\n\u6642\u3005\u898b\u304b\u3051\u308b\u52d5\u753b\u3067\u3059\u304c\u3001\u81ea\u5206\u3067\u3082\u3084\u3063\u3066\u307f\u305f\u304b\u3063\u305f\u306e\u3067\u3001\u3061\u3087\u3063\u3068\u304a\u8a66\u3057\u3002\n\ndlib\u306e\u307b\u3046\u304c\u5411\u304d\u3068\u304b\u306b\u5bfe\u3059\u308b\u7cbe\u5ea6\u304c\u3088\u304f\u3066\u3001\nOpenCV\u306e\u307b\u3046\u304c\u65e9\u3044\u611f\u3058\uff08Adaboost\u306e\u304a\u304b\u3052\uff1f\n\u696d\u52d9\u3067\u4f7f\u7528\u3059\u308b\u3053\u3068\u306b\u306a\u3063\u305f\u3089\u3001\u3082\u3063\u3068\u8a73\u7d30\u306b\u8abf\u67fb\u4e88\u5b9a\u3002\n\nLinux\u306e\u307b\u3046\u304cdlib\u306e\u5c0e\u5165\u304c\u7c21\u5358\u306a\u306e\u3067\u3001Ubutntu\u3067\u3084\u3063\u3066\u307e\u3059\u3002\nWindows\u3067\u3082dlib\u3044\u308c\u308c\u3070\u540c\u3058\u30bd\u30fc\u30b9\u3067\u52d5\u304f\u306f\u305a\u3002\u3002\u3002\uff1f\n\n\u52d5\u753b\u306f\u4ee5\u4e0b\u3002\n\u8d64\u8272\u304cOpenCV\u306b\u3088\u308b\u691c\u51fa\u3067\u3001\u9752\u8272\u304cdlib\u306b\u3088\u308b\u691c\u51fa\u3067\u3059\u3002\n[![\u3010Ubuntu\u3011\u3010Python\u3011dlib\u3068OpenCV\u306e\u9854\u691c\u51fa\u6bd4\u3079\n](http://img.youtube.com/vi/SQTXLfwlPjQ/0.jpg)](http://www.youtube.com/watch?v=SQTXLfwlPjQ)\n\n\n\u30bd\u30fc\u30b9\u30b3\u30fc\u30c9\u306f\u4ee5\u4e0b\u3002\n\u52d5\u4f5c\u3055\u305b\u308b\u306b\u306f\u3001py\u30d5\u30a1\u30a4\u30eb\u3068\u540c\u3058\u30c7\u30a3\u30ec\u30af\u30c8\u30ea\u306bOpenCV\u306e\u5b66\u7fd2\u6e08\u307f\u30c7\u30fc\u30bf\u3092\n\u914d\u7f6e\u3059\u308b\u5fc5\u8981\u304c\u3042\u308a\u307e\u3059\u3002\n\u2192./data/haarcascades/haarcascade_frontalface_alt.xml\n\n```py\n\n#!/usr/bin/env python\n# -*- coding: utf-8 -*-\n\n'''\nface_landmark_detector.py.\n\nUsage:\n  face_landmark_detector.py [<video source>] [<resize rate>]\n'''\n\nimport sys\nimport dlib\nimport cv2\nimport time\nimport copy\n\ntry:\n    fn = sys.argv[1]\n    if fn.isdigit() == True:\n        fn = int(fn)\nexcept:\n    fn = 0\n\ntry:\n    resize_rate = sys.argv[2]\n    resize_rate = int(resize_rate)\nexcept:\n    resize_rate = 1\n\n# Dlib\ndetector = dlib.get_frontal_face_detector()\n\n# OpenCV\ncascade_fn = \"./data/haarcascades/haarcascade_frontalface_alt.xml\"\ncascade = cv2.CascadeClassifier(cascade_fn)\n\nvideo_input = cv2.VideoCapture(fn)\n\ntotal_frame_count = 0\nface_detection_frame_count_dlib = 0\nface_detection_frame_count_opencv = 0\n\nwhile(video_input.isOpened() == True):\n    total_frame_count += 1\n\n    ret, frame = video_input.read()\n    temp_frame = copy.deepcopy(frame)\n\n    # \u51e6\u7406\u8ca0\u8377\u8efd\u6e1b\u306e\u305f\u3081\u306e\u5bfe\u8c61\u30d5\u30ec\u30fc\u30e0\u7e2e\u5c0f\uff08\u5f15\u6570\u6307\u5b9a\u6642\uff09\n    height, width = frame.shape[:2]\n    temp_frame = cv2.resize(frame, (int(width/resize_rate), int(height/resize_rate)))\n\n    # \u9854\u691c\u51fa(dlib)\n    start = time.time()\n    dets = detector(temp_frame, 1)\n    elapsed_time_dlib = time.time() - start\n\n    if len(dets) > 0:\n        face_detection_frame_count_dlib += 1\n\n    # \u691c\u51fa\u7d50\u679c\u63cf\u753b\uff08dlib\uff09\n    for k, d in enumerate(dets):\n        cv2.rectangle(frame, (int(d.left() * resize_rate), int(d.top() * resize_rate)), \\\n            (int(d.right() * resize_rate), int(d.bottom() * resize_rate)), (255, 0, 0), -1)\n\n    # \u9854\u691c\u51fa(opencv)\n    gray_image = cv2.cvtColor(temp_frame, cv2.COLOR_BGR2GRAY)\n    gray_image = cv2.equalizeHist(gray_image)\n\n    start = time.time()\n    rects = cascade.detectMultiScale(gray_image, scaleFactor=1.3, minNeighbors=4, minSize=(30, 30), flags=cv2.CASCADE_SCALE_IMAGE)\n    if len(rects) == 0:\n        rects = []\n    else:\n        rects[:,2:] += rects[:,:2]\n    elapsed_time_opencv = time.time() - start\n\n\n    if len(rects) > 0:\n        face_detection_frame_count_opencv += 1\n\n    # \u691c\u51fa\u7d50\u679c\u63cf\u753b\uff08OpenCV\uff09\n    for x1, y1, x2, y2 in rects:\n        cv2.putText(frame, \"OpenCV\", (int(x1 * resize_rate), int(y1 * resize_rate)), cv2.FONT_HERSHEY_PLAIN, 2.0, (0, 0, 255), thickness = 2)\n        cv2.rectangle(frame, (int(x1 * resize_rate), int(y1 * resize_rate)), (int(x2 * resize_rate), int(y2 * resize_rate)), (0, 0, 255), -1)\n    # \u691c\u51fa\u7d50\u679c\u63cf\u753b\uff08dlib\uff09\n    for k, d in enumerate(dets):\n        cv2.putText(frame, \"Dlib\", (int(d.left() * resize_rate), int(d.top() * resize_rate)), cv2.FONT_HERSHEY_PLAIN, 2.0, (255, 0, 0), thickness = 2)\n        cv2.rectangle(frame, (int(d.left() * resize_rate), int(d.top() * resize_rate)), \\\n            (int(d.right() * resize_rate), int(d.bottom() * resize_rate)), (255, 0, 0), 2)\n\n    print (\"face detect(dlib) processing time:{0}\".format(elapsed_time_dlib)) + \"[sec]\"\n    print (\"face detect(opencv) processing time:{0}\".format(elapsed_time_opencv)) + \"[sec]\"\n    print (\"face detect(dlib) success count:\" + '%06d' % face_detection_frame_count_dlib + \"/\" + '%06d' % total_frame_count)\n    print (\"face detect(opencv) success count:\" + '%06d' % face_detection_frame_count_opencv + \"/\" + '%06d' % total_frame_count)\n    print\n\n    cv2.imshow('face detector vs', frame)\n\n    c = cv2.waitKey(50) & 0xFF\n\n    if c==27: # ESC\n        break\n\nvideo_input.release()\ncv2.destroyAllWindows()\n```\n\n\u4ee5\u4e0a\u3002\n", "tags": ["OpenCV", "dlib", "Python"]}