{"context": "\n\n\u306f\u3058\u3081\u306b\n\u65b0\u305f\u306a\u74b0\u5883\u306btensorflow\u3092\u5c0e\u5165\u3059\u308b\u6a5f\u4f1a\u304c\u3042\u308a\u307e\u3057\u305f\u306e\u3067\uff0c\u5099\u5fd8\u9332\u3068\u3057\u3066\u305d\u306e\u624b\u9806\u3092\u307e\u3068\u3081\u3066\u304a\u304d\u307e\u3059\uff0e \u516c\u5f0f\u306e\u30c1\u30e5\u30fc\u30c8\u30ea\u30a2\u30eb\u306b\u5f93\u3063\u3066\u3044\u304f\u3060\u3051\u3067\u3059\u304c\uff0e \n16/4/30 - cuDNN\u30e9\u30a4\u30d6\u30e9\u30ea\u3092docker\u5185\u306b\u5c0e\u5165\u3059\u308b\u5fc5\u8981\u304c\u3042\u308b\u3088\u3046\u3067\u3059\n16/5/10 - \u65b0\u305f\u306a\u8a18\u4e8b\u3092\u8ffd\u52a0\u3057\u307e\u3057\u305f\uff0envidia-docker\u3092\u4f7f\u3046\u3068\u7c21\u5358\u3067\u3059\n\n\u5c0e\u5165\u624b\u9806\n\u4ee5\u524d\u306f\u30db\u30b9\u30c8\u74b0\u5883\u306b\u76f4\u63a5\u30a4\u30f3\u30b9\u30c8\u30fc\u30eb\u3057\u305f\u306e\u3067\u3059\u304c\uff0c\u6700\u8fd1docker\u3092\u63a8\u9032\u3057\u3066\u3044\u308b\u306e\u3067[\u8ab0\u304c?]\u4eca\u56de\u306fdocker\u3092\u4f7f\u3063\u3066\u307f\u307e\u3057\u305f\uff0e\u5206\u6563\u30b3\u30f3\u30d4\u30e5\u30fc\u30c6\u30a3\u30f3\u30b0\u3059\u308b\u3068\u304d\u3068\u304b\u306b\u4fbf\u5229\u304b\u306a\u3068\uff0e\n\u624b\u9806\u306f(1)cuda\u74b0\u5883\u306e\u5c0e\u5165\uff0c(2)docker\u3092\u8d70\u3089\u305b\u308b\uff0c\u3067\u3059\uff0ecuda\u306e\u74b0\u5883\u306f\u30db\u30b9\u30c8\u306e\u74b0\u5883\u306b\u5c0e\u5165\u3057\u3066\u3042\u308b\u5fc5\u8981\u304c\u3042\u308a\u307e\u3059\uff0e\u3061\u306a\u307f\u306bGPU\u3092\u4f7f\u308f\u306a\u3044\u306e\u3067\u3042\u308c\u3070\u3068\u304f\u306b\u74b0\u5883\u306e\u6e96\u5099\u306a\u304ftensorflow\u3092\u8d70\u3089\u305b\u308b\u3053\u3068\u304c\u3067\u304d\u307e\u3059\uff0edocker\u3059\u3054\u3044\u3067\u3059\u306d\uff0e\n\ncuda\u306e\u5c0e\u5165\nCuda Toolkit\u3068cuDNN\u3092\u5c0e\u5165\u3057\u307e\u3059\uff0eNvidia\u306e\u30b5\u30a4\u30c8\u304b\u3089\u30c0\u30a6\u30f3\u30ed\u30fc\u30c9\u3057\u3066\u304d\u307e\u3059\u304c\uff0c\u30d0\u30fc\u30b8\u30e7\u30f3\u304c\u8907\u6570\u3042\u308a\u307e\u3059\uff0e\u74b0\u5883\u69cb\u7bc9\u3067\u306f\u6700\u65b0\u30d0\u30fc\u30b8\u30e7\u30f3\u3092\u5165\u308c\u308b\u3068\u3046\u307e\u304f\u3044\u304b\u306a\u3044\u3068\u3044\u3063\u305f\u30c8\u30e9\u30d6\u30eb\u304c\u3088\u304f\u3042\u308a\u307e\u3059\u304c\uff0c\u79c1\u306e\u77e5\u308b\u9650\u308a7.0-v4, 7.5-v4, 7.5-v5 (toolkit-cuDnn)\u306e\u7d44\u307f\u5408\u308f\u305b\u306f\u52d5\u3044\u3066\u3044\u307e\u3059\uff0e\u4eca\u56de\u306f7.5-v4\u3092\u5c0e\u5165\u3057\u307e\u3057\u305f\uff0e\n16/4/30 - cuDNN v5\u306f\u52d5\u304d\u307e\u305b\u3093\u3067\u3057\u305f\uff0c\u3059\u307f\u307e\u305b\u3093\uff0e\n16/5/2 - \u518d\u4fee\u6b63\u3067\u3059\uff0c7.5-v4\u306e\u7d44\u307f\u5408\u308f\u305b\u306e\u307f\u30b5\u30dd\u30fc\u30c8\u306e\u3088\u3046\u3067\u3059\uff0e\u6df7\u4e71\u3057\u3066\u3057\u307e\u3044\u7533\u3057\u8a33\u3042\u308a\u307e\u305b\u3093\n\nThe GPU version (Linux only) works best with Cuda Toolkit 7.5 and cuDNN v4. \n\n\n\u30c0\u30a6\u30f3\u30ed\u30fc\u30c9\nCuda toolkit\u306f\u30b0\u30b0\u30c3\u3066nvidia\u306e\u30b5\u30a4\u30c8\u304b\u3089OS\u3084\u30d0\u30fc\u30b8\u30e7\u30f3\u3092\u9078\u629e\u3057\u3066\u30c0\u30a6\u30f3\u30ed\u30fc\u30c9\u3057\u307e\u3059\uff0e\u30a4\u30f3\u30b9\u30c8\u30fc\u30eb\u65b9\u6cd5\u3092\u8907\u6570\u9078\u629e\u3067\u304d\u307e\u3059\u304c\uff0c\u79c1\u306f\u30ed\u30fc\u30ab\u30eb\u306e.deb\u3092\u9078\u3073\u307e\u3057\u305f\uff0e\u30ed\u30fc\u30ab\u30eb\u3067\u3042\u308c\u3070\u30c0\u30a6\u30f3\u30ed\u30fc\u30c9\u3057\u305f\u30d5\u30a1\u30a4\u30eb\u3092\u518d\u5229\u7528\u3067\u304d\u307e\u3059\u306e\u3067\uff0e\n\u30c0\u30a6\u30f3\u30ed\u30fc\u30c9\u30d5\u30a1\u30a4\u30eb: cuda-repo-ubuntu1404-7-5-local_7.5-18_amd64.deb\ncuDnn\u306f\u30a2\u30ab\u30a6\u30f3\u30c8\u3092\u767b\u9332\u3057\u306a\u3044\u3068\u30c0\u30a6\u30f3\u30ed\u30fc\u30c9\u3067\u304d\u307e\u305b\u3093\uff0e\u6709\u52b9\u306a\u30e1\u30fc\u30eb\u30a2\u30c9\u30ec\u30b9\u3092\u4f7f\u3063\u3066\u767b\u9332\u3057\u307e\u3059\uff0e\u30a4\u30f3\u30b9\u30c8\u30fc\u30eb\u3067\u306f\u306a\u304f.tgz\u306e\u30d5\u30a1\u30a4\u30eb\u3092\u30c0\u30a6\u30f3\u30ed\u30fc\u30c9\u3057\u307e\u3059\uff0e\n\u30c0\u30a6\u30f3\u30ed\u30fc\u30c9\u30d5\u30a1\u30a4\u30eb: cudnn-7.5-linux-x64-v5.0-rc.tgz\n\u30c0\u30a6\u30f3\u30ed\u30fc\u30c9\u30d5\u30a1\u30a4\u30eb: cudnn-7.0-linux-x64-v4.0-prod.tgz\n\n\u30a4\u30f3\u30b9\u30c8\u30fc\u30eb\n\ncuda toolkit\ncuda toolkit\u3092\u30a4\u30f3\u30b9\u30c8\u30fc\u30eb\u3057\u307e\u3059\uff0e\nsudo dpkg -i cuda-repo-ubuntu1404-7-5-local_7.5-18_amd64.deb \nsudo apt-get update  \nsudo apt-get install cuda\n\ncuda\u306e\u30b5\u30f3\u30d7\u30eb\u30d7\u30ed\u30b0\u30e9\u30e0\u3067CUDA\u74b0\u5883\u3092\u78ba\u8a8d\u3067\u304d\u307e\u3059\uff0e\n$ /usr/local/cuda/samples/1_Utilities/deviceQuery/deviceQuery\n\n\n CUDA Device Query (Runtime API) version (CUDART static linking)\n\nDetected 1 CUDA Capable device(s)\n\nDevice 0: \"GeForce GTX 750 Ti\"\n  CUDA Driver Version / Runtime Version          7.5 / 7.5\n  CUDA Capability Major/Minor version number:    5.0\n  Total amount of global memory:                 2045 MBytes (2144010240 bytes)\n  ( 5) Multiprocessors, (128) CUDA Cores/MP:     640 CUDA Cores\n  GPU Max Clock rate:                            1110 MHz (1.11 GHz)\n...\n\n\ncuDNN\ncuDNN\u306f\u5c55\u958b\u3057\u3066\u30e9\u30a4\u30d6\u30e9\u30ea\u3092\u30b3\u30d4\u30fc\u3057\u307e\u3059\uff0ecudnn-7.5-linux-x64-v5.0-rc.tgz\u306e\u5c55\u958b\u5148\u3092``./cudnn''\u3068\u3057\u307e\u3059\uff0e\n16/4/30 - \u4ee5\u524d\u306e\u65b9\u6cd5\u3067\u306f\u6b63\u3057\u304f\u5c0e\u5165\u3067\u304d\u3066\u3044\u306a\u304b\u3063\u305f\u305f\u3081\u4fee\u6b63\u3057\u307e\u3057\u305f\ncuDNN\u306fdocker\u74b0\u5883\u306e\u4e2d\u306b\u5c0e\u5165\u3057\u306a\u3051\u308c\u3070\u306a\u3089\u306a\u3044\u3088\u3046\u3067\u3059\uff0e\u3046\u307e\u304f\u74b0\u5883\u69cb\u7bc9\u3067\u304d\u305f\u3068\u601d\u3063\u3066\u3044\u305f\u3089\uff0c\u5b9f\u969b\u306e\u8a08\u7b97\u3092\u56de\u3057\u305f\u3068\u3053\u308d\u3067\u30a8\u30e9\u30fc\u304c\u767a\u751f\u3057\u307e\u3057\u305f\uff0e\u305d\u3053\u3067\u4ee5\u4e0b\u306e\u3088\u3046\u306aDocker Image\u3092\u4f5c\u6210\u3057\u307e\u3057\u305f\uff0e\nFROM gcr.io/tensorflow/tensorflow:0.8.0-gpu\n\nRUN mkdir /tmp/cudnn\nCOPY ./cudnn-7.0-linux-x64-v4.0-prod.tgz /tmp/cudnn\nRUN tar xvzf /tmp/cudnn/cudnn*.tgz -C /tmp/cudnn/\nRUN cp /tmp/cudnn/cuda/include/cudnn.h /usr/local/cuda/include\nRUN cp /tmp/cudnn/cuda/lib64/libcudnn* /usr/local/cuda/lib64\nRUN chmod a+r /usr/local/cuda/lib64/libcudnn*\nRUN ln -s /usr/local/cuda /usr/local/nvidia\n\nDocker\u521d\u5fc3\u8005\u306a\u306e\u3067\u3053\u308c\u3067\u3044\u3044\u306e\u304b\u5206\u304b\u308a\u307e\u305b\u3093\u304c\uff0ccudnn-7.0-linux-x64-v4.0-prod.tgz\u306f\u4f1a\u54e1\u767b\u9332\u3092\u3057\u306a\u3044\u3068\u30c0\u30a6\u30f3\u30ed\u30fc\u30c9\u51fa\u6765\u307e\u305b\u3093\u306e\u3067\uff0cDockerfile\u3068\u540c\u3058\u30c7\u30a3\u30ec\u30af\u30c8\u30ea\u306b\u30c0\u30a6\u30f3\u30ed\u30fc\u30c9\u3057\u3066\u304a\u304d\uff0c\u30b3\u30f3\u30c6\u30ca\u5185\u306b\u30b3\u30d4\u30fc\u3057\u3066\u4f7f\u3046\u3088\u3046\u306b\u3057\u307e\u3057\u305f\uff0eFROM\u306b\u3064\u3044\u3066\u306f\u6b21\u7bc0\u3092\u53c2\u7167\u304f\u3060\u3055\u3044\uff0e\n\ndocker run\ncuda\u74b0\u5883\u3055\u3048\u5c0e\u5165\u3067\u304d\u308c\u3070\u3042\u3068\u306f\u7c21\u5358\u3067\u3059(docker\u74b0\u5883\u306f\u5c0e\u5165\u6e08\u307f\u3068\u3059\u308b)\uff0e\ncuDNN\u3092\u5c0e\u5165\u3059\u308b\u305f\u3081\u306bDockerfile\u3092build\u3057\u3066\u81ea\u5206\u306eimage\u3092\u4f5c\u6210\u3057\u306a\u3051\u308c\u3070\u306a\u308a\u307e\u305b\u3093\uff0e\n\nWe provide 4 Docker images:\n\ngcr.io/tensorflow/tensorflow: TensorFlow CPU binary image.\ngcr.io/tensorflow/tensorflow:latest-devel: CPU Binary image plus source code.\ngcr.io/tensorflow/tensorflow:latest-gpu: TensorFlow GPU binary image.\ngcr.io/tensorflow/tensorflow:latest-devel-gpu: GPU Binary image plus source code.\n\n\n\nCPU\u30e2\u30fc\u30c9(\u53c2\u8003)\nGPU\u3092\u4f7f\u308f\u306a\u3044\u30a4\u30e1\u30fc\u30b8\u306e\u5834\u5408\n\ndocker run -it gcr.io/tensorflow/tensorflow\n\n\nGPU\u30e2\u30fc\u30c9\u306e\u5834\u5408  16/4/30 - \u4fee\u6b63\u3057\u307e\u3057\u305f\n\n\u307e\u305a\uff0cDockerfile\u3092build\u3059\u308b\u5fc5\u8981\u304c\u3042\u308a\u307e\u3059\uff0eDockerfile\u306e\u5b58\u5728\u3059\u308b\u30c7\u30a3\u30ec\u30af\u30c8\u30ea\u3067\u4ee5\u4e0b\u306e\u30b3\u30de\u30f3\u30c9\u3067build\u3057\u307e\u3059\uff0e\ndocker build -t=\"userName/imageName\" .\n\n\u5b9f\u884c\u306b\u306fscript\u3092\u4f7f\u3044\u307e\u3059\uff0e\n\nIf you're using a container with GPU support, some additional flags must be passed to expose the GPU device to the container. For the default config, we include a script in the repo with these flags, so the command-line would look like ...\n\n\u30c0\u30a6\u30f3\u30ed\u30fc\u30c9\u3057\u305fdocker_run_gpu.sh\u3092\u4f7f\u3046\u3068\u4ee5\u4e0b\u306e\u3088\u3046\u306b\u8d77\u52d5\u3067\u304d\u307e\u3059\uff0e\n./docker_run_gpu.sh userName/imageName /bin/bash\n\ndocker\u74b0\u5883\u3092\u8d77\u52d5\u3057\u305f\u72b6\u614b\u3067tensorflow\u3092\u52d5\u304b\u3057\u3066\u307f\u308b\u3068\u4ee5\u4e0b\u306e\u3088\u3046\u306bcuda\u74b0\u5883\u304c\u6b63\u3057\u304f\u52d5\u3044\u3066\u3044\u308b\u3053\u3068\u304c\u5206\u304b\u308a\u307e\u3059\uff0e\u5b9f\u969b\u306b\u81ea\u5206\u306e\u30b3\u30fc\u30c9\u3092\u5b9f\u884c\u3057\u3066\u307f\u3066\u8a08\u7b97\u53ef\u80fd\u306a\u3053\u3068\u3092\u78ba\u8a8d\u3057\u307e\u3057\u305f\uff0e\n\ntest.py\n$ python\n>>>import tensorflow as tf #\u4ee5\u4e0b\u306e\u3088\u3046\u306b\u3059\u3079\u3066\u306eCUDA library\u304csuccessfully\u306bopen\u3067\u304d\u308c\u3070OK\u3067\u3059\nI tensorflow/stream_executor/dso_loader.cc:105] successfully opened CUDA library libcublas.so locally\nI tensorflow/stream_executor/dso_loader.cc:105] successfully opened CUDA library libcudnn.so locally\nI tensorflow/stream_executor/dso_loader.cc:105] successfully opened CUDA library libcufft.so locally\nI tensorflow/stream_executor/dso_loader.cc:105] successfully opened CUDA library libcuda.so.1 locally\nI tensorflow/stream_executor/dso_loader.cc:105] successfully opened CUDA library libcurand.so locally\n>>>sess = tf.Session()\nI tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:900] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\nI tensorflow/core/common_runtime/gpu/gpu_init.cc:102] Found device 0 with properties:\nname: GeForce GTX 750 Ti\n...\n>>>hello = tf.constant('hello')\n>>>sess.run(hello)\n'hello'\n\n\n#\u306f\u3058\u3081\u306b\n\u65b0\u305f\u306a\u74b0\u5883\u306btensorflow\u3092\u5c0e\u5165\u3059\u308b\u6a5f\u4f1a\u304c\u3042\u308a\u307e\u3057\u305f\u306e\u3067\uff0c\u5099\u5fd8\u9332\u3068\u3057\u3066\u305d\u306e\u624b\u9806\u3092\u307e\u3068\u3081\u3066\u304a\u304d\u307e\u3059\uff0e ~~[\u516c\u5f0f\u306e\u30c1\u30e5\u30fc\u30c8\u30ea\u30a2\u30eb](https://www.tensorflow.org/versions/master/get_started/os_setup.html)\u306b\u5f93\u3063\u3066\u3044\u304f\u3060\u3051\u3067\u3059\u304c\uff0e~~ \n**16/4/30 - cuDNN\u30e9\u30a4\u30d6\u30e9\u30ea\u3092docker\u5185\u306b\u5c0e\u5165\u3059\u308b\u5fc5\u8981\u304c\u3042\u308b\u3088\u3046\u3067\u3059**\n**16/5/10 - [\u65b0\u305f\u306a\u8a18\u4e8b](http://qiita.com/ymfj/items/6d2658240aaa02663453)\u3092\u8ffd\u52a0\u3057\u307e\u3057\u305f\uff0envidia-docker\u3092\u4f7f\u3046\u3068\u7c21\u5358\u3067\u3059**\n\n#\u5c0e\u5165\u624b\u9806\n\u4ee5\u524d\u306f\u30db\u30b9\u30c8\u74b0\u5883\u306b\u76f4\u63a5\u30a4\u30f3\u30b9\u30c8\u30fc\u30eb\u3057\u305f\u306e\u3067\u3059\u304c\uff0c\u6700\u8fd1docker\u3092\u63a8\u9032\u3057\u3066\u3044\u308b\u306e\u3067[\u8ab0\u304c?]\u4eca\u56de\u306fdocker\u3092\u4f7f\u3063\u3066\u307f\u307e\u3057\u305f\uff0e\u5206\u6563\u30b3\u30f3\u30d4\u30e5\u30fc\u30c6\u30a3\u30f3\u30b0\u3059\u308b\u3068\u304d\u3068\u304b\u306b\u4fbf\u5229\u304b\u306a\u3068\uff0e\n\u624b\u9806\u306f(1)cuda\u74b0\u5883\u306e\u5c0e\u5165\uff0c(2)docker\u3092\u8d70\u3089\u305b\u308b\uff0c\u3067\u3059\uff0ecuda\u306e\u74b0\u5883\u306f\u30db\u30b9\u30c8\u306e\u74b0\u5883\u306b\u5c0e\u5165\u3057\u3066\u3042\u308b\u5fc5\u8981\u304c\u3042\u308a\u307e\u3059\uff0e\u3061\u306a\u307f\u306bGPU\u3092\u4f7f\u308f\u306a\u3044\u306e\u3067\u3042\u308c\u3070\u3068\u304f\u306b\u74b0\u5883\u306e\u6e96\u5099\u306a\u304ftensorflow\u3092\u8d70\u3089\u305b\u308b\u3053\u3068\u304c\u3067\u304d\u307e\u3059\uff0edocker\u3059\u3054\u3044\u3067\u3059\u306d\uff0e\n\n##cuda\u306e\u5c0e\u5165\nCuda Toolkit\u3068cuDNN\u3092\u5c0e\u5165\u3057\u307e\u3059\uff0eNvidia\u306e\u30b5\u30a4\u30c8\u304b\u3089\u30c0\u30a6\u30f3\u30ed\u30fc\u30c9\u3057\u3066\u304d\u307e\u3059\u304c\uff0c\u30d0\u30fc\u30b8\u30e7\u30f3\u304c\u8907\u6570\u3042\u308a\u307e\u3059\uff0e\u74b0\u5883\u69cb\u7bc9\u3067\u306f\u6700\u65b0\u30d0\u30fc\u30b8\u30e7\u30f3\u3092\u5165\u308c\u308b\u3068\u3046\u307e\u304f\u3044\u304b\u306a\u3044\u3068\u3044\u3063\u305f\u30c8\u30e9\u30d6\u30eb\u304c\u3088\u304f\u3042\u308a\u307e\u3059\u304c\uff0c~~\u79c1\u306e\u77e5\u308b\u9650\u308a7.0-v4, 7.5-v4, 7.5-v5 (toolkit-cuDnn)\u306e\u7d44\u307f\u5408\u308f\u305b\u306f\u52d5\u3044\u3066\u3044\u307e\u3059\uff0e~~\u4eca\u56de\u306f7.5-v4\u3092\u5c0e\u5165\u3057\u307e\u3057\u305f\uff0e\n**16/4/30 - cuDNN v5\u306f\u52d5\u304d\u307e\u305b\u3093\u3067\u3057\u305f\uff0c\u3059\u307f\u307e\u305b\u3093\uff0e**\n**16/5/2 - \u518d\u4fee\u6b63\u3067\u3059\uff0c7.5-v4\u306e\u7d44\u307f\u5408\u308f\u305b\u306e\u307f\u30b5\u30dd\u30fc\u30c8\u306e\u3088\u3046\u3067\u3059\uff0e\u6df7\u4e71\u3057\u3066\u3057\u307e\u3044\u7533\u3057\u8a33\u3042\u308a\u307e\u305b\u3093**\n> The GPU version (Linux only) works best with Cuda Toolkit 7.5 and cuDNN v4. \n\n###\u30c0\u30a6\u30f3\u30ed\u30fc\u30c9\nCuda toolkit\u306f\u30b0\u30b0\u30c3\u3066nvidia\u306e\u30b5\u30a4\u30c8\u304b\u3089OS\u3084\u30d0\u30fc\u30b8\u30e7\u30f3\u3092\u9078\u629e\u3057\u3066\u30c0\u30a6\u30f3\u30ed\u30fc\u30c9\u3057\u307e\u3059\uff0e\u30a4\u30f3\u30b9\u30c8\u30fc\u30eb\u65b9\u6cd5\u3092\u8907\u6570\u9078\u629e\u3067\u304d\u307e\u3059\u304c\uff0c\u79c1\u306f\u30ed\u30fc\u30ab\u30eb\u306e.deb\u3092\u9078\u3073\u307e\u3057\u305f\uff0e\u30ed\u30fc\u30ab\u30eb\u3067\u3042\u308c\u3070\u30c0\u30a6\u30f3\u30ed\u30fc\u30c9\u3057\u305f\u30d5\u30a1\u30a4\u30eb\u3092\u518d\u5229\u7528\u3067\u304d\u307e\u3059\u306e\u3067\uff0e\n\u30c0\u30a6\u30f3\u30ed\u30fc\u30c9\u30d5\u30a1\u30a4\u30eb: ``cuda-repo-ubuntu1404-7-5-local_7.5-18_amd64.deb``\n\ncuDnn\u306f\u30a2\u30ab\u30a6\u30f3\u30c8\u3092\u767b\u9332\u3057\u306a\u3044\u3068\u30c0\u30a6\u30f3\u30ed\u30fc\u30c9\u3067\u304d\u307e\u305b\u3093\uff0e\u6709\u52b9\u306a\u30e1\u30fc\u30eb\u30a2\u30c9\u30ec\u30b9\u3092\u4f7f\u3063\u3066\u767b\u9332\u3057\u307e\u3059\uff0e\u30a4\u30f3\u30b9\u30c8\u30fc\u30eb\u3067\u306f\u306a\u304f.tgz\u306e\u30d5\u30a1\u30a4\u30eb\u3092\u30c0\u30a6\u30f3\u30ed\u30fc\u30c9\u3057\u307e\u3059\uff0e\n~~\u30c0\u30a6\u30f3\u30ed\u30fc\u30c9\u30d5\u30a1\u30a4\u30eb: ``cudnn-7.5-linux-x64-v5.0-rc.tgz``~~\n\u30c0\u30a6\u30f3\u30ed\u30fc\u30c9\u30d5\u30a1\u30a4\u30eb: ``cudnn-7.0-linux-x64-v4.0-prod.tgz``\n\n###\u30a4\u30f3\u30b9\u30c8\u30fc\u30eb\n####cuda toolkit\ncuda toolkit\u3092\u30a4\u30f3\u30b9\u30c8\u30fc\u30eb\u3057\u307e\u3059\uff0e\n\n```\nsudo dpkg -i cuda-repo-ubuntu1404-7-5-local_7.5-18_amd64.deb \nsudo apt-get update  \nsudo apt-get install cuda\n```\n\ncuda\u306e\u30b5\u30f3\u30d7\u30eb\u30d7\u30ed\u30b0\u30e9\u30e0\u3067CUDA\u74b0\u5883\u3092\u78ba\u8a8d\u3067\u304d\u307e\u3059\uff0e\n\n```\n$ /usr/local/cuda/samples/1_Utilities/deviceQuery/deviceQuery\n\n\n CUDA Device Query (Runtime API) version (CUDART static linking)\n\nDetected 1 CUDA Capable device(s)\n\nDevice 0: \"GeForce GTX 750 Ti\"\n  CUDA Driver Version / Runtime Version          7.5 / 7.5\n  CUDA Capability Major/Minor version number:    5.0\n  Total amount of global memory:                 2045 MBytes (2144010240 bytes)\n  ( 5) Multiprocessors, (128) CUDA Cores/MP:     640 CUDA Cores\n  GPU Max Clock rate:                            1110 MHz (1.11 GHz)\n...\n```\n\n####cuDNN\n~~cuDNN\u306f\u5c55\u958b\u3057\u3066\u30e9\u30a4\u30d6\u30e9\u30ea\u3092\u30b3\u30d4\u30fc\u3057\u307e\u3059\uff0e``cudnn-7.5-linux-x64-v5.0-rc.tgz``\u306e\u5c55\u958b\u5148\u3092``./cudnn''\u3068\u3057\u307e\u3059\uff0e~~\n**16/4/30 - \u4ee5\u524d\u306e\u65b9\u6cd5\u3067\u306f\u6b63\u3057\u304f\u5c0e\u5165\u3067\u304d\u3066\u3044\u306a\u304b\u3063\u305f\u305f\u3081\u4fee\u6b63\u3057\u307e\u3057\u305f**\ncuDNN\u306fdocker\u74b0\u5883\u306e\u4e2d\u306b\u5c0e\u5165\u3057\u306a\u3051\u308c\u3070\u306a\u3089\u306a\u3044\u3088\u3046\u3067\u3059\uff0e\u3046\u307e\u304f\u74b0\u5883\u69cb\u7bc9\u3067\u304d\u305f\u3068\u601d\u3063\u3066\u3044\u305f\u3089\uff0c\u5b9f\u969b\u306e\u8a08\u7b97\u3092\u56de\u3057\u305f\u3068\u3053\u308d\u3067\u30a8\u30e9\u30fc\u304c\u767a\u751f\u3057\u307e\u3057\u305f\uff0e\u305d\u3053\u3067\u4ee5\u4e0b\u306e\u3088\u3046\u306aDocker Image\u3092\u4f5c\u6210\u3057\u307e\u3057\u305f\uff0e\n\n```Dockerfile\nFROM gcr.io/tensorflow/tensorflow:0.8.0-gpu\n\nRUN mkdir /tmp/cudnn\nCOPY ./cudnn-7.0-linux-x64-v4.0-prod.tgz /tmp/cudnn\nRUN tar xvzf /tmp/cudnn/cudnn*.tgz -C /tmp/cudnn/\nRUN cp /tmp/cudnn/cuda/include/cudnn.h /usr/local/cuda/include\nRUN cp /tmp/cudnn/cuda/lib64/libcudnn* /usr/local/cuda/lib64\nRUN chmod a+r /usr/local/cuda/lib64/libcudnn*\nRUN ln -s /usr/local/cuda /usr/local/nvidia\n```\nDocker\u521d\u5fc3\u8005\u306a\u306e\u3067\u3053\u308c\u3067\u3044\u3044\u306e\u304b\u5206\u304b\u308a\u307e\u305b\u3093\u304c\uff0c``cudnn-7.0-linux-x64-v4.0-prod.tgz``\u306f\u4f1a\u54e1\u767b\u9332\u3092\u3057\u306a\u3044\u3068\u30c0\u30a6\u30f3\u30ed\u30fc\u30c9\u51fa\u6765\u307e\u305b\u3093\u306e\u3067\uff0cDockerfile\u3068\u540c\u3058\u30c7\u30a3\u30ec\u30af\u30c8\u30ea\u306b\u30c0\u30a6\u30f3\u30ed\u30fc\u30c9\u3057\u3066\u304a\u304d\uff0c\u30b3\u30f3\u30c6\u30ca\u5185\u306b\u30b3\u30d4\u30fc\u3057\u3066\u4f7f\u3046\u3088\u3046\u306b\u3057\u307e\u3057\u305f\uff0eFROM\u306b\u3064\u3044\u3066\u306f\u6b21\u7bc0\u3092\u53c2\u7167\u304f\u3060\u3055\u3044\uff0e\n\n\n\n##docker run\n~~cuda\u74b0\u5883\u3055\u3048\u5c0e\u5165\u3067\u304d\u308c\u3070\u3042\u3068\u306f\u7c21\u5358\u3067\u3059(docker\u74b0\u5883\u306f\u5c0e\u5165\u6e08\u307f\u3068\u3059\u308b)\uff0e~~\ncuDNN\u3092\u5c0e\u5165\u3059\u308b\u305f\u3081\u306bDockerfile\u3092build\u3057\u3066\u81ea\u5206\u306eimage\u3092\u4f5c\u6210\u3057\u306a\u3051\u308c\u3070\u306a\u308a\u307e\u305b\u3093\uff0e\n\n>We provide 4 Docker images:\n>\n>* gcr.io/tensorflow/tensorflow: TensorFlow CPU binary image.\n>* gcr.io/tensorflow/tensorflow:latest-devel: CPU Binary image plus source code.\n>* gcr.io/tensorflow/tensorflow:latest-gpu: TensorFlow GPU binary image.\n>* gcr.io/tensorflow/tensorflow:latest-devel-gpu: GPU Binary image plus source code.\n\n###CPU\u30e2\u30fc\u30c9(\u53c2\u8003)\nGPU\u3092\u4f7f\u308f\u306a\u3044\u30a4\u30e1\u30fc\u30b8\u306e\u5834\u5408\n```\ndocker run -it gcr.io/tensorflow/tensorflow\n```\n\n###GPU\u30e2\u30fc\u30c9\u306e\u5834\u5408  **16/4/30 - \u4fee\u6b63\u3057\u307e\u3057\u305f**\n\n\u307e\u305a\uff0cDockerfile\u3092build\u3059\u308b\u5fc5\u8981\u304c\u3042\u308a\u307e\u3059\uff0eDockerfile\u306e\u5b58\u5728\u3059\u308b\u30c7\u30a3\u30ec\u30af\u30c8\u30ea\u3067\u4ee5\u4e0b\u306e\u30b3\u30de\u30f3\u30c9\u3067build\u3057\u307e\u3059\uff0e\n\n```\ndocker build -t=\"userName/imageName\" .\n```\n\n\n\u5b9f\u884c\u306b\u306fscript\u3092\u4f7f\u3044\u307e\u3059\uff0e\n\n>If you're using a container with GPU support, some additional flags must be passed to expose the GPU device to the container. For the default config, we include a [script](https://github.com/tensorflow/tensorflow/blob/master/tensorflow/tools/docker/docker_run_gpu.sh) in the repo with these flags, so the command-line would look like ...\n\n\u30c0\u30a6\u30f3\u30ed\u30fc\u30c9\u3057\u305f``docker_run_gpu.sh``\u3092\u4f7f\u3046\u3068\u4ee5\u4e0b\u306e\u3088\u3046\u306b\u8d77\u52d5\u3067\u304d\u307e\u3059\uff0e\n\n```\n./docker_run_gpu.sh userName/imageName /bin/bash\n```\n\ndocker\u74b0\u5883\u3092\u8d77\u52d5\u3057\u305f\u72b6\u614b\u3067tensorflow\u3092\u52d5\u304b\u3057\u3066\u307f\u308b\u3068\u4ee5\u4e0b\u306e\u3088\u3046\u306bcuda\u74b0\u5883\u304c\u6b63\u3057\u304f\u52d5\u3044\u3066\u3044\u308b\u3053\u3068\u304c\u5206\u304b\u308a\u307e\u3059\uff0e**\u5b9f\u969b\u306b\u81ea\u5206\u306e\u30b3\u30fc\u30c9\u3092\u5b9f\u884c\u3057\u3066\u307f\u3066\u8a08\u7b97\u53ef\u80fd\u306a\u3053\u3068\u3092\u78ba\u8a8d\u3057\u307e\u3057\u305f\uff0e**\n\n```test.py\n$ python\n>>>import tensorflow as tf #\u4ee5\u4e0b\u306e\u3088\u3046\u306b\u3059\u3079\u3066\u306eCUDA library\u304csuccessfully\u306bopen\u3067\u304d\u308c\u3070OK\u3067\u3059\nI tensorflow/stream_executor/dso_loader.cc:105] successfully opened CUDA library libcublas.so locally\nI tensorflow/stream_executor/dso_loader.cc:105] successfully opened CUDA library libcudnn.so locally\nI tensorflow/stream_executor/dso_loader.cc:105] successfully opened CUDA library libcufft.so locally\nI tensorflow/stream_executor/dso_loader.cc:105] successfully opened CUDA library libcuda.so.1 locally\nI tensorflow/stream_executor/dso_loader.cc:105] successfully opened CUDA library libcurand.so locally\n>>>sess = tf.Session()\nI tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:900] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\nI tensorflow/core/common_runtime/gpu/gpu_init.cc:102] Found device 0 with properties:\nname: GeForce GTX 750 Ti\n...\n>>>hello = tf.constant('hello')\n>>>sess.run(hello)\n'hello'\n```\n", "tags": ["TensorFlow", "CUDA", "docker"]}