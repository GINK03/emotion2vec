{"context": "Embulk\u306e\u5404\u30d7\u30e9\u30b0\u30a4\u30f3\u306econfig\u8a2d\u5b9a\u4f8b\u3092\u30e1\u30e2\u3057\u3066\u3044\u304d\u307e\u3059\u3002\n(MySQL\u3001Bigquery\u3001Redshit\u3001Redis\u3001S3\u306a\u3069)\n\u30d7\u30e9\u30b0\u30a4\u30f3\u306e\u30a4\u30f3\u30b9\u30c8\u30fc\u30eb\u304c\u5fc5\u8981\n\u4f8b\uff1aembulk gem install embulk-output-bigquery\nembulk\u3092\u305f\u304f\u3055\u3093\u9806\u5e8f\u3088\u304f\u53e9\u3044\u3066\u3001\u3042\u3044\u307e\u306b\u3061\u3087\u3063\u3068\u3057\u305f\u51e6\u7406\u3082\u884c\u3044\u305f\u3044\u306e\u3067\u3001\ndigdag\u3082\u8a66\u3057\u307e\u3059\u3002\n\nEmbulk\u30d7\u30e9\u30b0\u30a4\u30f3\u306econfig(liquid\u524d\u63d0)\n\nInput\n\nembulk-input-s3\n\nin:\n  type: s3\n  path_prefix: yyy/xxxxxx\n  file_ext: .zip\n  access_key_id: {{ env.AWS_ACCESS_KEY }}\n  secret_access_key: {{ env.AWS_SECRET_KEY }}\n  iam_user_name: yyy-xxxxxx-access\n  bucket: {{ env.S3_YY_BUCKET }}\n  endpoint: s3-ap-northeast-1.amazonaws.com\n  decoders:\n  - {type: gzip}\n  parser:\n    charset: UTF-8\n    newline: LF\n    type: csv\n    delimiter: ','\n    quote: '\"'\n    escape: '\"'\n    max_quoted_size_limit: 134217728\n    columns:\n    - {name: url, type: string}\n    - {name: site, type: string}\n    - {name: contents, type: string}\n\n\nembulk csv\nin:\n  type: file\n  path_prefix: \"yyy/xxxxxx.csv\"\n  parser:\n    charset: UTF-8\n    newline: LF\n    type: csv\n    default_timezone: \"Asia/Tokyo\"\n    delimiter: ','\n    null_string: 'NULL'\n    columns:\n    - {name: x, type: string}\n    - {name: y, type: string}\n\n\nembulk-input-gcs\n\nin:\n  type: gcs\n  bucket: xx-yyy-zzz\n  path_prefix: xxx/zzz_\n  auth_method: private_key\n  service_account_email: {{ env.SERVICE_ACCOUNT_EMAIL }} \n  p12_keyfile: ../bq/key/{{ env.P12_FILENAME }}\n  application_name: zzzz\n  tasks: 1\n  parser:\n    charset: UTF-8\n    newline: LF\n    header_line: true\n    type: csv\n    delimiter: ','\n    quote: '\"'\n    columns:\n    - {name: site, type: string}\n    - {name: category, type: string}\n\n\nembulk-input-redis\n\nin:\n  type: redis \n  host: localhost\n  port: 6379\n  db: 1\n  key_prefix: yyy-xxxxxx\n  encode: hash\n  columns:\n  - {name: site, type: string}\n  - {name: category, type: string}\n\n\nembulk-input-mysql\n\nin:\n  type: mysql\n  host: {{ env.XXXXX_DB_HOST }}\n  user: {{ env.XXXXX_DB_USER }}\n  password: {{ env.XXXXX_DB_PASSWORD }} \n  database: {{ env.XXXXX_DB_NAME }}\n  table: xxxx\n  select: \"aaa, bbb, ccc\"\n  where: \"status = 0 AND id = 12345\"\n\n\nembulk-input-redshift\n\n  type: redshift\n  host: {{ env.XXXXX_RS_DB_HOST }}\n  user: {{ env.XXXXX_RS_DB_USER }}\n  password: {{ env.XXXXX_DATABASE_PASSWORD }}\n  database: {{ env.XXXXX_DATABASE_NAME }}\n  table: xxx\n  select: \"name,url,title\"\n  fetch_rows: 1000\n\n\nOutput\n\nembulk-output-bigquery\n\nout:\n  type: bigquery\n  mode: append\n  auth_method: private_key\n  service_account_email: {{ env.SERVICE_ACCOUNT_EMAIL }}\n  p12_keyfile: key/{{ env.P12_FILENAME }}\n  path_prefix: tmp/\n  file_ext: csv.gz\n  source_format: CSV\n  project: {{ env.XXXX_PROJECT }}\n  dataset: xxx_yyyy_zzz\n  auto_create_table: true\n  table: xxxes\n  schema_file: schema/yyyy_zzzz_schema.json\n  prevent_duplicate_insert: true\n  formatter:\n    type: csv\n    header_line: false\n    timezone: Asia/Tokyo\n  encoders:\n  - {type: gzip}\n  allow_quoted_newlines: 1\n\n\u5927\u91cf\u30c7\u30fc\u30bf\u3092\u6295\u5165\u3059\u308b\u5834\u5408\u306b\u306ftimeout_sec\u3068open_timeout_sec\u3092\u8a2d\u5b9a\n\n  timeout_sec: 6000\n  open_timeout_sec: 6000\n\n\u305d\u3046\u3057\u306a\u3044\u3068\n\nCaused by: org.jruby.exceptions.RaiseException: (TransmissionError) execution expired\n\n\nembulk-output-td\n\nout:\n  type: td\n  apikey: {{ env.TD_API_KEY }}\n  endpoint: api.treasuredata.com\n  database: xxx_yyyy_zzz\n  table: xxxes\n  default_timezone: Asia/Tokyo \n\n\nembulk-output-redis\n\nout:\n  type: redis\n  host: localhost\n  port: 6379\n  db: 0\n  key_prefix: \"yyy-xxxxxx\"\n  encode: hash\n  key: url\n  columns:\n  - {name: url, type: string}\n  - {name: category, type: string}\n\n\nembulk-output-dynamodb\n\nout:\n  type: dynamodb\n  mode: upsert\n  region: ap-northeast-1\n  auth_method: basic\n  access_key_id: {{ env.AWS_ACCESS_KEY }}\n  secret_access_key: {{ env.AWS_SECRET_KEY }}\n  auto_create_table: false\n  table: xxxes\n  primary_key: id\n  primary_key_type: Number\n  write_capacity_units:\n    normal: 5\n    raise: 20\n  read_capacity_units:\n    normal: 6\n    raise: 30\n\n\nembulk-output-mysql\n\nout:\n  type: mysql\n  host: {{ env.XXX_DB_HOST }}\n  user: {{ env.XXX_DB_USER }}\n  password: {{ env.XXX_DB_PASSWORD }}\n  database: {{ env.XXX_DB_NAME }}\n  table: yyyy\n  mode: truncate_insert\n  default_timezone: \"Japan\"\n\n\nembulk csv\nout:\n  type: file\n  path_prefix: tmp/yyy\n  file_ext: txt\n  formatter:\n    type: csv\n    charset: UTF-8\n    delimiter: '\\'\n    header_line: false\n    newline: LF\n    quote: ''\n    quote_policy: NONE\n    escape: '\\'\n\n\nembulk-output-redshift\n\nout:\n  type: redshift\n  host: {{ env.XXXXX_RS_DB_HOST }}\n  user: {{ env.XXXXX_RS_DB_USER }}\n  password: {{ env.XXXXX_RS_DB_PASSWORD }}\n  database: {{ env.XXXXX_RS_DB_NAME }}\n  table: xxxes_tmp\n  access_key_id: {{ env.AWS_ACCESS_KEY }}\n  secret_access_key: {{ env.AWS_SECRET_KEY }}\n  iam_user_name: yyy-xxxxxx-access\n  s3_bucket: {{ env.S3_BUCKET }}\n  s3_key_prefix: redshift\n  mode: truncate_insert\n  default_timezone: \"Japan\"\n\n\nFilter\n\nembulk-filter-ruby_proc\n\nfilters:\n  - type: ruby_proc\n    requires:\n      - cgi\n    variables:\n      multiply: 1\n    before:\n      - proc: |\n          -> do\n            puts \"before proc\"\n            @started_at = Time.now\n          end\n    after:\n      - proc: |\n          -> do\n            puts \"after proc\"\n            p Time.now - @started_at\n          end\n    columns:\n      - name: words\n        proc: |\n          ->(words) do\n            words # \u3053\u3053\u306bruby\u3067\u51e6\u7406\u3092\u66f8\u304f\n          end\n        type: string\n\n\nparser\n\nembulk-parser-none\n\nparse\u3055\u305b\u305f\u304f\u306a\u3044\u3068\u304d\u3082\u3042\u308a\u307e\u3059\u3002\nin:\n  type: file\n  path_prefix: example/example.jsonl\n  parser:\n    type: none\n    column_name: payload\nout:\n  type: bigquery\n  payload_column_index: 0 # or, payload_column: payload\n\n\netc\n\nmax_quoted_size_limit\nThe size of the quoted value exceeds the limit size (131072)\nhttp://www.embulk.org/docs/built-in.html\n134217728\u306a\u3069\u306e\u5927\u304d\u3081\u306e\u5024\u306b\u3057\u305f\u3089\u3001\u30a8\u30e9\u30fc\u304c\u51fa\u306a\u304f\u306a\u3063\u305f\n\nDigdag\n\ninstall\nsudo curl -o /usr/local/bin/digdag --create-dirs -L \"https://dl.digdag.io/digdag-latest\"\nsudo chmod +x /usr/local/bin/digdag\n\njava\u306e\u30d0\u30fc\u30b8\u30e7\u30f3\u304cJava8\u4ee5\u4e0a\u3067\u306a\u3044\u3068\u3060\u3081\nsudo yum -y remove java\nsudo yum -y install java-1.8.0-openjdk-devel\njava -version\njavac -version\n\n\n\u30ef\u30fc\u30af\u30d5\u30ed\u30fc\u306e\u521d\u671f\u5316\u30fb\u4f5c\u6210\ndigdag init workflow\n\n2016-07-06 15:14:26 +0900: Digdag v0.8.3\n  Creating workflow/.gitignore\n  Creating workflow/tasks/shell_sample.sh\n  Creating workflow/tasks/repeat_hello.sh\n  Creating workflow/tasks/__init__.py\n  Creating workflow/workflow.dig\nDone. Type `cd workflow` and then `digdag run workflow.dig` to run the workflow. Enjoy!\n\n\nworkflow.dig\ntimezone: Asia/Tokyo\n\n+step1:\n  sh>: embulk run s3/yyy-xxxxxx.yml.liquid\n\n+last:\n  py>: tasks.XXXYYYWorkflow.last_notification\n\n\n\ntasks/__init__.py\n#coding:utf-8\n\nimport os\nimport slackweb\nimport digdag\n\nclass XXXYYYWorkflow(object):\n    def xxx_notification(self):\n        slack = slackweb.Slack(url=os.environ[\"SLACK_INCOMING_URL\"])\n        slack.notify(text=\"This is a *digdag test*...\", \\\n        channel=\"#system-log\", username=\"dig_dagger\", icon_emoji=\":coffee\", mrkdwn=True)\n\n\n\n\u5b9f\u884c\nembulk\u3092\u5b9f\u884c\u3057\u3001\u6700\u5f8c\u306bslack\u3078\u901a\u77e5\u3057\u305f\n> digdag run workflow\nSuccess. Task state is saved at .digdag/status/20160706T000000+0900 directory.\n\n\n\u518d\u5b9f\u884c\n\u4e00\u5ea6\u5b9f\u884c\u3059\u308b\u3068.digdag/status\u4e0b\u306b\u5b9f\u884c\u30ed\u30b0\uff08&\u30b9\u30c6\u30fc\u30bf\u30b9\uff09\u304c\u305f\u307e\u308b\u3002\n\u305d\u306e\u4e0b\u306e\u30d5\u30a9\u30eb\u30c0\u3084\u30d5\u30a1\u30a4\u30eb\u3092\u524a\u9664\u3057\u3066\u3082\u518d\u5b9f\u884c\u3067\u304d\u308b\u304c\u3001rerun\u3068\u3044\u3046\u30aa\u30d7\u30b7\u30e7\u30f3\u3082\u3042\u308b\n> digdag run --rerun workflow\n\narchitecture\nhttp://www.digdag.io/architecture.html#architecture\n\n\u7d50\u8ad6\n\nembulk\u306f\u3059\u3070\u3089\u3057\u3044\uff01\ndigdag\u306f\u4eca\u5f8c\u306b\u671f\u5f85\n\nEmbulk\u306e\u5404\u30d7\u30e9\u30b0\u30a4\u30f3\u306econfig\u8a2d\u5b9a\u4f8b\u3092\u30e1\u30e2\u3057\u3066\u3044\u304d\u307e\u3059\u3002\n(MySQL\u3001Bigquery\u3001Redshit\u3001Redis\u3001S3\u306a\u3069)\n \n\u30d7\u30e9\u30b0\u30a4\u30f3\u306e\u30a4\u30f3\u30b9\u30c8\u30fc\u30eb\u304c\u5fc5\u8981\n\u4f8b\uff1a`embulk gem install embulk-output-bigquery`\n\nembulk\u3092\u305f\u304f\u3055\u3093\u9806\u5e8f\u3088\u304f\u53e9\u3044\u3066\u3001\u3042\u3044\u307e\u306b\u3061\u3087\u3063\u3068\u3057\u305f\u51e6\u7406\u3082\u884c\u3044\u305f\u3044\u306e\u3067\u3001\ndigdag\u3082\u8a66\u3057\u307e\u3059\u3002\n\n# Embulk\u30d7\u30e9\u30b0\u30a4\u30f3\u306econfig(liquid\u524d\u63d0)\n## Input\n### [embulk-input-s3](https://github.com/embulk/embulk-input-s3)\n```\nin:\n  type: s3\n  path_prefix: yyy/xxxxxx\n  file_ext: .zip\n  access_key_id: {{ env.AWS_ACCESS_KEY }}\n  secret_access_key: {{ env.AWS_SECRET_KEY }}\n  iam_user_name: yyy-xxxxxx-access\n  bucket: {{ env.S3_YY_BUCKET }}\n  endpoint: s3-ap-northeast-1.amazonaws.com\n  decoders:\n  - {type: gzip}\n  parser:\n    charset: UTF-8\n    newline: LF\n    type: csv\n    delimiter: ','\n    quote: '\"'\n    escape: '\"'\n    max_quoted_size_limit: 134217728\n    columns:\n    - {name: url, type: string}\n    - {name: site, type: string}\n    - {name: contents, type: string}\n```\n\n### embulk csv\n```\nin:\n  type: file\n  path_prefix: \"yyy/xxxxxx.csv\"\n  parser:\n    charset: UTF-8\n    newline: LF\n    type: csv\n    default_timezone: \"Asia/Tokyo\"\n    delimiter: ','\n    null_string: 'NULL'\n    columns:\n    - {name: x, type: string}\n    - {name: y, type: string}\n```\n\n### [embulk-input-gcs](https://github.com/embulk/embulk-input-gcs)\n```\nin:\n  type: gcs\n  bucket: xx-yyy-zzz\n  path_prefix: xxx/zzz_\n  auth_method: private_key\n  service_account_email: {{ env.SERVICE_ACCOUNT_EMAIL }} \n  p12_keyfile: ../bq/key/{{ env.P12_FILENAME }}\n  application_name: zzzz\n  tasks: 1\n  parser:\n    charset: UTF-8\n    newline: LF\n    header_line: true\n    type: csv\n    delimiter: ','\n    quote: '\"'\n    columns:\n    - {name: site, type: string}\n    - {name: category, type: string}\n```\n\n### [embulk-input-redis](https://github.com/komamitsu/embulk-input-redis)\n```\nin:\n  type: redis \n  host: localhost\n  port: 6379\n  db: 1\n  key_prefix: yyy-xxxxxx\n  encode: hash\n  columns:\n  - {name: site, type: string}\n  - {name: category, type: string}\n```\n\n### [embulk-input-mysql](https://github.com/embulk/embulk-input-jdbc/tree/master/embulk-input-mysql)\n```\nin:\n  type: mysql\n  host: {{ env.XXXXX_DB_HOST }}\n  user: {{ env.XXXXX_DB_USER }}\n  password: {{ env.XXXXX_DB_PASSWORD }} \n  database: {{ env.XXXXX_DB_NAME }}\n  table: xxxx\n  select: \"aaa, bbb, ccc\"\n  where: \"status = 0 AND id = 12345\"\n```\n\n### [embulk-input-redshift](https://github.com/embulk/embulk-input-jdbc/tree/master/embulk-input-redshift)\n```\n  type: redshift\n  host: {{ env.XXXXX_RS_DB_HOST }}\n  user: {{ env.XXXXX_RS_DB_USER }}\n  password: {{ env.XXXXX_DATABASE_PASSWORD }}\n  database: {{ env.XXXXX_DATABASE_NAME }}\n  table: xxx\n  select: \"name,url,title\"\n  fetch_rows: 1000\n```\n\n## Output\n### [embulk-output-bigquery](https://github.com/embulk/embulk-output-bigquery)\n```\nout:\n  type: bigquery\n  mode: append\n  auth_method: private_key\n  service_account_email: {{ env.SERVICE_ACCOUNT_EMAIL }}\n  p12_keyfile: key/{{ env.P12_FILENAME }}\n  path_prefix: tmp/\n  file_ext: csv.gz\n  source_format: CSV\n  project: {{ env.XXXX_PROJECT }}\n  dataset: xxx_yyyy_zzz\n  auto_create_table: true\n  table: xxxes\n  schema_file: schema/yyyy_zzzz_schema.json\n  prevent_duplicate_insert: true\n  formatter:\n    type: csv\n    header_line: false\n    timezone: Asia/Tokyo\n  encoders:\n  - {type: gzip}\n  allow_quoted_newlines: 1\n```\n\n\u5927\u91cf\u30c7\u30fc\u30bf\u3092\u6295\u5165\u3059\u308b\u5834\u5408\u306b\u306ftimeout_sec\u3068open_timeout_sec\u3092\u8a2d\u5b9a\n```\n  timeout_sec: 6000\n  open_timeout_sec: 6000\n```\n\u305d\u3046\u3057\u306a\u3044\u3068\n```\nCaused by: org.jruby.exceptions.RaiseException: (TransmissionError) execution expired\n```\n\n\n### [embulk-output-td](https://github.com/treasure-data/embulk-output-td)\n```\nout:\n  type: td\n  apikey: {{ env.TD_API_KEY }}\n  endpoint: api.treasuredata.com\n  database: xxx_yyyy_zzz\n  table: xxxes\n  default_timezone: Asia/Tokyo \n```\n\n### [embulk-output-redis](https://github.com/komamitsu/embulk-output-redis)\n```\nout:\n  type: redis\n  host: localhost\n  port: 6379\n  db: 0\n  key_prefix: \"yyy-xxxxxx\"\n  encode: hash\n  key: url\n  columns:\n  - {name: url, type: string}\n  - {name: category, type: string}\n```\n\n### [embulk-output-dynamodb](https://github.com/sakama/embulk-output-dynamodb)\n```\nout:\n  type: dynamodb\n  mode: upsert\n  region: ap-northeast-1\n  auth_method: basic\n  access_key_id: {{ env.AWS_ACCESS_KEY }}\n  secret_access_key: {{ env.AWS_SECRET_KEY }}\n  auto_create_table: false\n  table: xxxes\n  primary_key: id\n  primary_key_type: Number\n  write_capacity_units:\n    normal: 5\n    raise: 20\n  read_capacity_units:\n    normal: 6\n    raise: 30\n```\n\n### [embulk-output-mysql](https://github.com/embulk/embulk-output-jdbc/tree/master/embulk-output-mysql)\n```\nout:\n  type: mysql\n  host: {{ env.XXX_DB_HOST }}\n  user: {{ env.XXX_DB_USER }}\n  password: {{ env.XXX_DB_PASSWORD }}\n  database: {{ env.XXX_DB_NAME }}\n  table: yyyy\n  mode: truncate_insert\n  default_timezone: \"Japan\"\n```\n\n### embulk csv\n```\nout:\n  type: file\n  path_prefix: tmp/yyy\n  file_ext: txt\n  formatter:\n    type: csv\n    charset: UTF-8\n    delimiter: '\\'\n    header_line: false\n    newline: LF\n    quote: ''\n    quote_policy: NONE\n    escape: '\\'\n```\n\n### [embulk-output-redshift](https://github.com/embulk/embulk-output-jdbc/tree/master/embulk-output-redshift)\n```\nout:\n  type: redshift\n  host: {{ env.XXXXX_RS_DB_HOST }}\n  user: {{ env.XXXXX_RS_DB_USER }}\n  password: {{ env.XXXXX_RS_DB_PASSWORD }}\n  database: {{ env.XXXXX_RS_DB_NAME }}\n  table: xxxes_tmp\n  access_key_id: {{ env.AWS_ACCESS_KEY }}\n  secret_access_key: {{ env.AWS_SECRET_KEY }}\n  iam_user_name: yyy-xxxxxx-access\n  s3_bucket: {{ env.S3_BUCKET }}\n  s3_key_prefix: redshift\n  mode: truncate_insert\n  default_timezone: \"Japan\"\n```\n\n## Filter\n### [embulk-filter-ruby_proc](https://github.com/joker1007/embulk-filter-ruby_proc)\n\n```\nfilters:\n  - type: ruby_proc\n    requires:\n      - cgi\n    variables:\n      multiply: 1\n    before:\n      - proc: |\n          -> do\n            puts \"before proc\"\n            @started_at = Time.now\n          end\n    after:\n      - proc: |\n          -> do\n            puts \"after proc\"\n            p Time.now - @started_at\n          end\n    columns:\n      - name: words\n        proc: |\n          ->(words) do\n            words # \u3053\u3053\u306bruby\u3067\u51e6\u7406\u3092\u66f8\u304f\n          end\n        type: string\n```\n\n## parser\n### [embulk-parser-none](https://github.com/sonots/embulk-parser-none)\nparse\u3055\u305b\u305f\u304f\u306a\u3044\u3068\u304d\u3082\u3042\u308a\u307e\u3059\u3002\n\n```\nin:\n  type: file\n  path_prefix: example/example.jsonl\n  parser:\n    type: none\n    column_name: payload\nout:\n  type: bigquery\n  payload_column_index: 0 # or, payload_column: payload\n```\n\n\n## etc\n### max_quoted_size_limit\n`The size of the quoted value exceeds the limit size (131072)`\nhttp://www.embulk.org/docs/built-in.html\n134217728\u306a\u3069\u306e\u5927\u304d\u3081\u306e\u5024\u306b\u3057\u305f\u3089\u3001\u30a8\u30e9\u30fc\u304c\u51fa\u306a\u304f\u306a\u3063\u305f\n\n\n# Digdag \n\n## install \n```\nsudo curl -o /usr/local/bin/digdag --create-dirs -L \"https://dl.digdag.io/digdag-latest\"\nsudo chmod +x /usr/local/bin/digdag\n```\n\njava\u306e\u30d0\u30fc\u30b8\u30e7\u30f3\u304cJava8\u4ee5\u4e0a\u3067\u306a\u3044\u3068\u3060\u3081\n\n```\nsudo yum -y remove java\nsudo yum -y install java-1.8.0-openjdk-devel\njava -version\njavac -version\n```\n\n## \u30ef\u30fc\u30af\u30d5\u30ed\u30fc\u306e\u521d\u671f\u5316\u30fb\u4f5c\u6210\n```\ndigdag init workflow\n```\n\n```\n2016-07-06 15:14:26 +0900: Digdag v0.8.3\n  Creating workflow/.gitignore\n  Creating workflow/tasks/shell_sample.sh\n  Creating workflow/tasks/repeat_hello.sh\n  Creating workflow/tasks/__init__.py\n  Creating workflow/workflow.dig\nDone. Type `cd workflow` and then `digdag run workflow.dig` to run the workflow. Enjoy!\n```\n\n```yaml:workflow.dig\ntimezone: Asia/Tokyo\n\n+step1:\n  sh>: embulk run s3/yyy-xxxxxx.yml.liquid\n\n+last:\n  py>: tasks.XXXYYYWorkflow.last_notification\n```\n\n```py:tasks/__init__.py\n#coding:utf-8\n\nimport os\nimport slackweb\nimport digdag\n\nclass XXXYYYWorkflow(object):\n    def xxx_notification(self):\n        slack = slackweb.Slack(url=os.environ[\"SLACK_INCOMING_URL\"])\n        slack.notify(text=\"This is a *digdag test*...\", \\\n        channel=\"#system-log\", username=\"dig_dagger\", icon_emoji=\":coffee\", mrkdwn=True)\n```\n\n## \u5b9f\u884c\nembulk\u3092\u5b9f\u884c\u3057\u3001\u6700\u5f8c\u306bslack\u3078\u901a\u77e5\u3057\u305f\n`> digdag run workflow`\n\n```\nSuccess. Task state is saved at .digdag/status/20160706T000000+0900 directory.\n```\n\n## \u518d\u5b9f\u884c\n\u4e00\u5ea6\u5b9f\u884c\u3059\u308b\u3068.digdag/status\u4e0b\u306b\u5b9f\u884c\u30ed\u30b0\uff08&\u30b9\u30c6\u30fc\u30bf\u30b9\uff09\u304c\u305f\u307e\u308b\u3002\n\u305d\u306e\u4e0b\u306e\u30d5\u30a9\u30eb\u30c0\u3084\u30d5\u30a1\u30a4\u30eb\u3092\u524a\u9664\u3057\u3066\u3082\u518d\u5b9f\u884c\u3067\u304d\u308b\u304c\u3001rerun\u3068\u3044\u3046\u30aa\u30d7\u30b7\u30e7\u30f3\u3082\u3042\u308b\n`> digdag run --rerun workflow`\n\n## architecture\nhttp://www.digdag.io/architecture.html#architecture\n\n# \u7d50\u8ad6\n  - embulk\u306f\u3059\u3070\u3089\u3057\u3044\uff01\n  - digdag\u306f\u4eca\u5f8c\u306b\u671f\u5f85\n", "tags": ["redshift", "Embulk", "digdag"]}