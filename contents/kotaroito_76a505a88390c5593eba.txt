{"context": "\u5b9f\u8df5 \u6a5f\u68b0\u5b66\u7fd2\u30b7\u30b9\u30c6\u30e0 \u306e\u7b2c6\u7ae0\u306b\u30ca\u30a4\u30fc\u30d6\u30d9\u30a4\u30ba\u306b\u3088\u308b\u30c6\u30ad\u30b9\u30c8\u5206\u985e\u4e8b\u4f8b\u304c\u3042\u3063\u305f\u306e\u3067\u3001\u81ea\u5206\u3067\u3082\u30c1\u30e3\u30ec\u30f3\u30b8\u3057\u3066\u307f\u307e\u3059\u3002\n\n\u3084\u308b\u3053\u3068\nsklearn\u306e\u30c7\u30fc\u30bf\u30bb\u30c3\u30c8 20newsgroups \u3092 sklearn.naive_bayes.MultinomialNB \u4f7f\u3063\u3066\u30ab\u30c6\u30b4\u30ea\u5206\u985e\u3057\u307e\u3059\u3002\n\n\nCountVectorizer \u3092\u5229\u7528\u3057\u3066\u3001 \u30c9\u30ad\u30e5\u30e1\u30f3\u30c8\u3092\u5358\u8a9e\u51fa\u73fe\u983b\u5ea6\u306e\u884c\u5217\u306b\u5909\u63db\u3059\u308b\n\nMultinomialNB \u3092\u5229\u7528\u3057\u3066\u3001\u30ca\u30a4\u30fc\u30d6\u30d9\u30a4\u30ba\u5206\u985e\u5668\u3092\u5b66\u7fd2\u3055\u305b\u308b\n\u30c6\u30b9\u30c8\u30c7\u30fc\u30bf\u306b\u3088\u308b\u691c\u8a3c\u3092\u884c\u3046\n\n\u3068\u3044\u3046\u6d41\u308c\u306b\u306a\u308a\u307e\u3059\u3002\n\n\u5b9f\u88c5\n\u30b9\u30c8\u30c3\u30d7\u30ef\u30fc\u30c9\u306e\u8a2d\u5b9a\u4ee5\u5916\u306f\u5168\u3066\u30c7\u30d5\u30a9\u30eb\u30c8\u306e\u307e\u307e\u3067\u3059\u3002\nimport numpy as np\nfrom sklearn.datasets import fetch_20newsgroups\nfrom sklearn.naive_bayes import MultinomialNB\nfrom sklearn.feature_extraction.text import CountVectorizer\nimport nltk\n\ndef stopwords():\n    symbols = [\"'\", '\"', '`', '.', ',', '-', '!', '?', ':', ';', '(', ')', '*', '--', '\\\\']\n    stopwords = nltk.corpus.stopwords.words('english')\n    return stopwords + symbols\n\nnewsgroups_train = fetch_20newsgroups(subset='train', remove=('headers', 'footers', 'quotes'))\nnewsgroups_test  = fetch_20newsgroups(subset='test', remove=('headers', 'footers', 'quotes'))\n\nvectorizer = CountVectorizer(stop_words=stopwords())\nvectorizer.fit(newsgroups_train.data)\n\n# Train\nX = vectorizer.transform(newsgroups_train.data)\ny = newsgroups_train.target\nprint(X.shape)\n\nclf = MultinomialNB()\nclf.fit(X, y)\nprint(clf.score(X,y))\n\n# Test\nX_test = vectorizer.transform(newsgroups_test.data) \ny_test = newsgroups_test.target\n\nprint(clf.score(X_test, y_test))\n\n\n\u7d50\u679c\n\u30c6\u30b9\u30c8\u30c7\u30fc\u30bf\u306b\u5bfe\u3059\u308b\u6b63\u7b54\u7387\u306f 62% \u3067\u3057\u305f\u3002\n\uff08\u306a\u304a\u3001\u30c8\u30ec\u30fc\u30cb\u30f3\u30b0\u30c7\u30fc\u30bf\u306b\u5bfe\u3057\u3066\u306f 81%\uff09\nsklearn\u3092\u4f7f\u3046\u3068\u3001\u30ca\u30a4\u30fc\u30d6\u30d9\u30a4\u30ba\u5206\u985e\u5668\u3092\u4f7f\u3063\u305f\u30c6\u30ad\u30b9\u30c8\u5206\u985e\u304c\u624b\u8efd\u306b\u3067\u304d\u308b\u3053\u3068\u304c\u308f\u304b\u308a\u307e\u3057\u305f\u3002\n\u305f\u3060\u3001\u6b63\u7b54\u7387\u304c 62% \u306a\u306e\u3067\u3001\u7cbe\u5ea6\u3092\u4e0a\u3052\u308b\u305f\u3081\u306b\u306fTfIdf\u3001Stemming \u7b49\u3001\u8af8\u3005\u306e\u81ea\u7136\u8a00\u8a9e\u51e6\u7406\u3092\u9069\u7528\u3059\u308b\u5fc5\u8981\u304c\u3042\u308a\u305d\u3046\u3067\u3059\u3002\n\n\u8ffd\u8a18(2016/03/30\uff09\nTfidVectorizer \u306b\u5909\u66f4\u3057\u3001\u3055\u3089\u306b GridSearchCV\u3092\u4f7f\u3063\u3066\u6700\u9069\u306a\u30d1\u30e9\u30e1\u30bf\u3092\u63a2\u7d22\u3059\u308b\u65b9\u6cd5\u3082\u3084\u3063\u3066\u307f\u305f\u3002\n\u30c6\u30b9\u30c8\u30c7\u30fc\u30bf\u306b\u5bfe\u3059\u308b\u6b63\u7b54\u7387\u306f 66% \u3068\u5c11\u3057\u4e0a\u6607\u3002\nimport numpy as np\nfrom sklearn.datasets import fetch_20newsgroups\nfrom sklearn.naive_bayes import MultinomialNB\nfrom sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\nfrom sklearn.grid_search import GridSearchCV\nfrom sklearn.pipeline import Pipeline\nimport nltk\n\ndef stopwords():\n    symbols = [\"'\", '\"', '`', '.', ',', '-', '!', '?', ':', ';', '(', ')', '*', '--', '\\\\']\n    stopwords = nltk.corpus.stopwords.words('english')\n    return stopwords + symbols\n\nnewsgroups_train = fetch_20newsgroups(subset='train', remove=('headers', 'footers', 'quotes'))\nnewsgroups_test  = fetch_20newsgroups(subset='test', remove=('headers', 'footers', 'quotes'))\n\n# Pipeline\npipeline = Pipeline([('vectorizer', TfidfVectorizer()), ('multinomial_nb', MultinomialNB())])\nparams = {\n    'vectorizer__max_df': [1.0, 0.99],\n    'vectorizer__ngram_range': [(1,1), (1, 2)],\n    'vectorizer__stop_words' : [stopwords()],\n}\nclf = GridSearchCV(pipeline, params)\n\n# Train\nX = newsgroups_train.data\ny = newsgroups_train.target\nclf.fit(X,y)\nprint(clf.score(X, y))\n\n# Test\nX_test = newsgroups_test.data\ny_test = newsgroups_test.target\nprint(clf.score(X_test, y_test))\n\n[\u5b9f\u8df5 \u6a5f\u68b0\u5b66\u7fd2\u30b7\u30b9\u30c6\u30e0](http://www.oreilly.co.jp/books/9784873116983/) \u306e\u7b2c6\u7ae0\u306b\u30ca\u30a4\u30fc\u30d6\u30d9\u30a4\u30ba\u306b\u3088\u308b\u30c6\u30ad\u30b9\u30c8\u5206\u985e\u4e8b\u4f8b\u304c\u3042\u3063\u305f\u306e\u3067\u3001\u81ea\u5206\u3067\u3082\u30c1\u30e3\u30ec\u30f3\u30b8\u3057\u3066\u307f\u307e\u3059\u3002\n\n\n## \u3084\u308b\u3053\u3068\n\nsklearn\u306e\u30c7\u30fc\u30bf\u30bb\u30c3\u30c8 [20newsgroups](http://scikit-learn.org/stable/modules/generated/sklearn.datasets.fetch_20newsgroups.html#sklearn.datasets.fetch_20newsgroups) \u3092 [sklearn.naive_bayes.MultinomialNB](http://scikit-learn.org/stable/modules/generated/sklearn.naive_bayes.MultinomialNB.html) \u4f7f\u3063\u3066\u30ab\u30c6\u30b4\u30ea\u5206\u985e\u3057\u307e\u3059\u3002\n\n\n1. [CountVectorizer](http://scikit-learn.org/stable/modules/generated/sklearn.feature_extraction.text.CountVectorizer.html) \u3092\u5229\u7528\u3057\u3066\u3001 \u30c9\u30ad\u30e5\u30e1\u30f3\u30c8\u3092\u5358\u8a9e\u51fa\u73fe\u983b\u5ea6\u306e\u884c\u5217\u306b\u5909\u63db\u3059\u308b\n2. [MultinomialNB](http://scikit-learn.org/stable/modules/generated/sklearn.naive_bayes.MultinomialNB.html#sklearn.naive_bayes.MultinomialNBCont) \u3092\u5229\u7528\u3057\u3066\u3001\u30ca\u30a4\u30fc\u30d6\u30d9\u30a4\u30ba\u5206\u985e\u5668\u3092\u5b66\u7fd2\u3055\u305b\u308b\n3. \u30c6\u30b9\u30c8\u30c7\u30fc\u30bf\u306b\u3088\u308b\u691c\u8a3c\u3092\u884c\u3046\n\n\u3068\u3044\u3046\u6d41\u308c\u306b\u306a\u308a\u307e\u3059\u3002\n\n## \u5b9f\u88c5\n\n\u30b9\u30c8\u30c3\u30d7\u30ef\u30fc\u30c9\u306e\u8a2d\u5b9a\u4ee5\u5916\u306f\u5168\u3066\u30c7\u30d5\u30a9\u30eb\u30c8\u306e\u307e\u307e\u3067\u3059\u3002\n\n```py3\nimport numpy as np\nfrom sklearn.datasets import fetch_20newsgroups\nfrom sklearn.naive_bayes import MultinomialNB\nfrom sklearn.feature_extraction.text import CountVectorizer\nimport nltk\n\ndef stopwords():\n    symbols = [\"'\", '\"', '`', '.', ',', '-', '!', '?', ':', ';', '(', ')', '*', '--', '\\\\']\n    stopwords = nltk.corpus.stopwords.words('english')\n    return stopwords + symbols\n\nnewsgroups_train = fetch_20newsgroups(subset='train', remove=('headers', 'footers', 'quotes'))\nnewsgroups_test  = fetch_20newsgroups(subset='test', remove=('headers', 'footers', 'quotes'))\n\nvectorizer = CountVectorizer(stop_words=stopwords())\nvectorizer.fit(newsgroups_train.data)\n\n# Train\nX = vectorizer.transform(newsgroups_train.data)\ny = newsgroups_train.target\nprint(X.shape)\n\nclf = MultinomialNB()\nclf.fit(X, y)\nprint(clf.score(X,y))\n\n# Test\nX_test = vectorizer.transform(newsgroups_test.data) \ny_test = newsgroups_test.target\n\nprint(clf.score(X_test, y_test))\n```\n\n## \u7d50\u679c\n\n\u30c6\u30b9\u30c8\u30c7\u30fc\u30bf\u306b\u5bfe\u3059\u308b\u6b63\u7b54\u7387\u306f 62% \u3067\u3057\u305f\u3002\n\uff08\u306a\u304a\u3001\u30c8\u30ec\u30fc\u30cb\u30f3\u30b0\u30c7\u30fc\u30bf\u306b\u5bfe\u3057\u3066\u306f 81%\uff09\n\n\nsklearn\u3092\u4f7f\u3046\u3068\u3001\u30ca\u30a4\u30fc\u30d6\u30d9\u30a4\u30ba\u5206\u985e\u5668\u3092\u4f7f\u3063\u305f\u30c6\u30ad\u30b9\u30c8\u5206\u985e\u304c\u624b\u8efd\u306b\u3067\u304d\u308b\u3053\u3068\u304c\u308f\u304b\u308a\u307e\u3057\u305f\u3002\n\u305f\u3060\u3001\u6b63\u7b54\u7387\u304c 62% \u306a\u306e\u3067\u3001\u7cbe\u5ea6\u3092\u4e0a\u3052\u308b\u305f\u3081\u306b\u306fTfIdf\u3001Stemming \u7b49\u3001\u8af8\u3005\u306e\u81ea\u7136\u8a00\u8a9e\u51e6\u7406\u3092\u9069\u7528\u3059\u308b\u5fc5\u8981\u304c\u3042\u308a\u305d\u3046\u3067\u3059\u3002\n\n\n## \u8ffd\u8a18(2016/03/30\uff09\n\nTfidVectorizer \u306b\u5909\u66f4\u3057\u3001\u3055\u3089\u306b GridSearchCV\u3092\u4f7f\u3063\u3066\u6700\u9069\u306a\u30d1\u30e9\u30e1\u30bf\u3092\u63a2\u7d22\u3059\u308b\u65b9\u6cd5\u3082\u3084\u3063\u3066\u307f\u305f\u3002\n\u30c6\u30b9\u30c8\u30c7\u30fc\u30bf\u306b\u5bfe\u3059\u308b\u6b63\u7b54\u7387\u306f 66% \u3068\u5c11\u3057\u4e0a\u6607\u3002\n\n\n```py3\nimport numpy as np\nfrom sklearn.datasets import fetch_20newsgroups\nfrom sklearn.naive_bayes import MultinomialNB\nfrom sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\nfrom sklearn.grid_search import GridSearchCV\nfrom sklearn.pipeline import Pipeline\nimport nltk\n\ndef stopwords():\n    symbols = [\"'\", '\"', '`', '.', ',', '-', '!', '?', ':', ';', '(', ')', '*', '--', '\\\\']\n    stopwords = nltk.corpus.stopwords.words('english')\n    return stopwords + symbols\n\nnewsgroups_train = fetch_20newsgroups(subset='train', remove=('headers', 'footers', 'quotes'))\nnewsgroups_test  = fetch_20newsgroups(subset='test', remove=('headers', 'footers', 'quotes'))\n\n# Pipeline\npipeline = Pipeline([('vectorizer', TfidfVectorizer()), ('multinomial_nb', MultinomialNB())])\nparams = {\n    'vectorizer__max_df': [1.0, 0.99],\n    'vectorizer__ngram_range': [(1,1), (1, 2)],\n    'vectorizer__stop_words' : [stopwords()],\n}\nclf = GridSearchCV(pipeline, params)\n\n# Train\nX = newsgroups_train.data\ny = newsgroups_train.target\nclf.fit(X,y)\nprint(clf.score(X, y))\n\n# Test\nX_test = newsgroups_test.data\ny_test = newsgroups_test.target\nprint(clf.score(X_test, y_test))\n```\n", "tags": ["Python", "MachineLearning", "sklearn"]}