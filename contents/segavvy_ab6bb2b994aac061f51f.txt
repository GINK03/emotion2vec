{"context": "\u8a00\u8a9e\u51e6\u7406100\u672c\u30ce\u30c3\u30af 2015\u306e\u6311\u6226\u8a18\u9332\u3067\u3059\u3002\u74b0\u5883\u306fUbuntu 16.04 LTS \uff0b Python 3.5.2 :: Anaconda 4.1.1 (64-bit)\u3067\u3059\u3002\u904e\u53bb\u306e\u30ce\u30c3\u30af\u306e\u4e00\u89a7\u306f\u3053\u3061\u3089\u304b\u3089\u3069\u3046\u305e\u3002\n\n\u7b2c6\u7ae0: \u82f1\u8a9e\u30c6\u30ad\u30b9\u30c8\u306e\u51e6\u7406\n\n\u82f1\u8a9e\u306e\u30c6\u30ad\u30b9\u30c8\uff08nlp.txt\uff09\u306b\u5bfe\u3057\u3066\uff0c\u4ee5\u4e0b\u306e\u51e6\u7406\u3092\u5b9f\u884c\u305b\u3088\uff0e\n\n\n53. Tokenization\n\nStanford Core NLP\u3092\u7528\u3044\uff0c\u5165\u529b\u30c6\u30ad\u30b9\u30c8\u306e\u89e3\u6790\u7d50\u679c\u3092XML\u5f62\u5f0f\u3067\u5f97\u3088\uff0e\u307e\u305f\uff0c\u3053\u306eXML\u30d5\u30a1\u30a4\u30eb\u3092\u8aad\u307f\u8fbc\u307f\uff0c\u5165\u529b\u30c6\u30ad\u30b9\u30c8\u30921\u884c1\u5358\u8a9e\u306e\u5f62\u5f0f\u3067\u51fa\u529b\u305b\u3088\uff0e\n\n\n\u51fa\u6765\u4e0a\u304c\u3063\u305f\u30b3\u30fc\u30c9\uff1a\n\nmain.py\n# coding: utf-8\nimport os\nimport subprocess\nimport xml.etree.ElementTree as ET\n\nfname = 'nlp.txt'\nfname_parsed = 'nlp.txt.xml'\n\n\ndef parse_nlp():\n    '''nlp.txt\u3092Stanford Core NLP\u3067\u89e3\u6790\u3057xml\u30d5\u30a1\u30a4\u30eb\u3078\u51fa\u529b\n    \u3059\u3067\u306b\u7d50\u679c\u30d5\u30a1\u30a4\u30eb\u304c\u5b58\u5728\u3059\u308b\u5834\u5408\u306f\u5b9f\u884c\u3057\u306a\u3044\n    '''\n    if not os.path.exists(fname_parsed):\n\n        # StanfordCoreNLP\u5b9f\u884c\u3001\u6a19\u6e96\u30a8\u30e9\u30fc\u306fparse.out\u3078\u51fa\u529b\n        subprocess.run(\n            'java -cp \"/usr/local/lib/stanford-corenlp-full-2016-10-31/*\"'\n            ' -Xmx2g'\n            ' edu.stanford.nlp.pipeline.StanfordCoreNLP'\n            ' -annotators tokenize,ssplit,pos,lemma,ner,parse,dcoref'\n            ' -file ' + fname + ' 2>parse.out',\n            shell=True,     # shell\u3067\u5b9f\u884c\n            check=True      # \u30a8\u30e9\u30fc\u30c1\u30a7\u30c3\u30af\u3042\u308a\n        )\n\n\n# nlp.txt\u3092\u89e3\u6790\nparse_nlp()\n\n# \u89e3\u6790\u7d50\u679c\u306exml\u3092\u30d1\u30fc\u30b9\nroot = ET.parse(fname_parsed)\n\n# word\u306e\u307f\u53d6\u308a\u51fa\u3057\nfor word in root.iter('word'):\n    print(word.text)\n\n\n\n\u5b9f\u884c\u7d50\u679c\uff1a\n\u9577\u3044\u306e\u3067\u5148\u982d\u90e8\u5206\u306e\u629c\u7c8b\u3067\u3059\u3002\n\n\u7aef\u672b\uff1a\u5148\u982d\u90e8\u5206\nNatural\nlanguage\nprocessing\nFrom\nWikipedia\n,\nthe\nfree\nencyclopedia\nNatural\nlanguage\nprocessing\n-LRB-\nNLP\n-RRB-\nis\na\nfield\nof\ncomputer\nscience\n,\nartificial\nintelligence\n,\nand\nlinguistics\nconcerned\nwith\nthe\ninteractions\nbetween\ncomputers\nand\nhuman\n-LRB-\nnatural\n-RRB-\nlanguages\n.\nAs\nsuch\n,\nNLP\nis\nrelated\nto\nthe\narea\nof\nhumani-computer\ninteraction\n.\n\n\n\u5168\u4f53\u306e\u7d50\u679c\u306fGitHub\u306b\u30a2\u30c3\u30d7\u3057\u3066\u3044\u307e\u3059\u3002\n\u306a\u304a\u3001Stanford Core NLP\u306e\u5b9f\u884c\u6642\u306f\u6a19\u6e96\u30a8\u30e9\u30fc\u306b\u6b21\u306e\u3088\u3046\u306a\u30e1\u30c3\u30bb\u30fc\u30b8\u304c\u51fa\u529b\u3055\u308c\u307e\u3059\u3002\u4eca\u56de\u306e\u30d7\u30ed\u30b0\u30e9\u30e0\u3067\u306fparse.out\u306b\u30ea\u30c0\u30a4\u30ec\u30af\u30c8\u3055\u305b\u307e\u3057\u305f\u3002\n\n\u7aef\u672b\uff1aparse.out\n[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator tokenize\n[main] INFO edu.stanford.nlp.pipeline.TokenizerAnnotator - No tokenizer type provided. Defaulting to PTBTokenizer.\n[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator ssplit\n[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator pos\n[main] INFO edu.stanford.nlp.tagger.maxent.MaxentTagger - Reading POS tagger model from edu/stanford/nlp/models/pos-tagger/english-left3words/english-left3words-distsim.tagger ... done [2.6 sec].\n[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator lemma\n[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator ner\n[main] INFO edu.stanford.nlp.ie.AbstractSequenceClassifier - Loading classifier from edu/stanford/nlp/models/ner/english.all.3class.distsim.crf.ser.gz ... done [5.3 sec].\n[main] INFO edu.stanford.nlp.ie.AbstractSequenceClassifier - Loading classifier from edu/stanford/nlp/models/ner/english.muc.7class.distsim.crf.ser.gz ... done [3.7 sec].\n[main] INFO edu.stanford.nlp.ie.AbstractSequenceClassifier - Loading classifier from edu/stanford/nlp/models/ner/english.conll.4class.distsim.crf.ser.gz ... done [4.9 sec].\n[main] INFO edu.stanford.nlp.time.JollyDayHolidays - Initializing JollyDayHoliday for SUTime from classpath edu/stanford/nlp/models/sutime/jollyday/Holidays_sutime.xml as sutime.binder.1.\n[main] INFO edu.stanford.nlp.ling.tokensregex.CoreMapExpressionExtractor - Reading TokensRegex rules from edu/stanford/nlp/models/sutime/defs.sutime.txt\n[main] INFO edu.stanford.nlp.ling.tokensregex.CoreMapExpressionExtractor - Read 84 rules\n[main] INFO edu.stanford.nlp.ling.tokensregex.CoreMapExpressionExtractor - Reading TokensRegex rules from edu/stanford/nlp/models/sutime/english.sutime.txt\n[main] INFO edu.stanford.nlp.ling.tokensregex.CoreMapExpressionExtractor - Read 267 rules\n[main] INFO edu.stanford.nlp.ling.tokensregex.CoreMapExpressionExtractor - Reading TokensRegex rules from edu/stanford/nlp/models/sutime/english.holidays.sutime.txt\n[main] INFO edu.stanford.nlp.ling.tokensregex.CoreMapExpressionExtractor - Read 25 rules\n[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator parse\n[main] INFO edu.stanford.nlp.parser.common.ParserGrammar - Loading parser from serialized file edu/stanford/nlp/models/lexparser/englishPCFG.ser.gz ... done [0.6 sec].\n[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator dcoref\n\nProcessing file /home/segavvy/\u30c9\u30ad\u30e5\u30e1\u30f3\u30c8/\u8a00\u8a9e\u51e6\u7406100\u672c\u30ce\u30c3\u30af2015/53/nlp.txt ... writing to /home/segavvy/\u30c9\u30ad\u30e5\u30e1\u30f3\u30c8/\u8a00\u8a9e\u51e6\u7406100\u672c\u30ce\u30c3\u30af2015/53/nlp.txt.xml\nAnnotating file /home/segavvy/\u30c9\u30ad\u30e5\u30e1\u30f3\u30c8/\u8a00\u8a9e\u51e6\u7406100\u672c\u30ce\u30c3\u30af2015/53/nlp.txt ... done [20.6 sec].\n\nAnnotation pipeline timing information:\nTokenizerAnnotator: 0.2 sec.\nWordsToSentencesAnnotator: 0.0 sec.\nPOSTaggerAnnotator: 0.2 sec.\nMorphaAnnotator: 0.1 sec.\nNERCombinerAnnotator: 2.6 sec.\nParserAnnotator: 12.8 sec.\nDeterministicCorefAnnotator: 4.7 sec.\nTOTAL: 20.6 sec. for 1452 tokens at 70.5 tokens/sec.\nPipeline setup: 27.2 sec.\nTotal time for StanfordCoreNLP pipeline: 48.1 sec.\n\n\n\u7279\u306b\u6c17\u306b\u3059\u308b\u5185\u5bb9\u306f\u306a\u3055\u305d\u3046\u3067\u3059\u3002\n\nStanford Core NLP\u306e\u30a4\u30f3\u30b9\u30c8\u30fc\u30eb\n\u30d7\u30ed\u30b0\u30e9\u30df\u30f3\u30b0\u306e\u524d\u306b\u74b0\u5883\u306e\u69cb\u7bc9\u3067\u3059\u3002\n\u4eca\u56de\u306f\u554f\u984c\u3067\u6307\u793a\u3055\u308c\u3066\u3044\u308b\u300cStanford Core NLP\u300d\u304c\u5fc5\u8981\u3067\u3059\u3002\u30aa\u30d5\u30a3\u30b7\u30e3\u30eb\u30b5\u30a4\u30c8\u306f\u3053\u3061\u3089\u3067\u3059\u3002\n\u3053\u306e\u30b5\u30a4\u30c8\u306e\u300cProgramming languages and operating systems\u300d\u306e\u3068\u3053\u308d\u3092\u898b\u308b\u3068Java 1.8\u4ee5\u4e0a\u304c\u5fc5\u8981\u3068\u3042\u308a\u307e\u3059\u306e\u3067\u3001Java\u306e\u30a4\u30f3\u30b9\u30c8\u30fc\u30eb\u304b\u3089\u59cb\u3081\u307e\u3059\u3002\n\nJava 1.8\u306e\u30a4\u30f3\u30b9\u30c8\u30fc\u30eb\n\u79c1\u306fOpenJDK 8\u306eJRE\u3092\u5165\u308c\u307e\u3057\u305f\u3002\u3053\u308c\u306fapt\u4e00\u767a\u3067\u3044\u3051\u307e\u3059\u3002\n\n\u7aef\u672b\uff1aOpenJDK8\u30a4\u30f3\u30b9\u30c8\u30fc\u30eb\nsegavvy@ubuntu:~$ sudo apt install openjdk-8-jre\n[sudo] segavvy \u306e\u30d1\u30b9\u30ef\u30fc\u30c9: \n\u30d1\u30c3\u30b1\u30fc\u30b8\u30ea\u30b9\u30c8\u3092\u8aad\u307f\u8fbc\u3093\u3067\u3044\u307e\u3059... \u5b8c\u4e86\n\u4f9d\u5b58\u95a2\u4fc2\u30c4\u30ea\u30fc\u3092\u4f5c\u6210\u3057\u3066\u3044\u307e\u3059                \n\u72b6\u614b\u60c5\u5831\u3092\u8aad\u307f\u53d6\u3063\u3066\u3044\u307e\u3059... \u5b8c\u4e86\n\u4ee5\u4e0b\u306e\u8ffd\u52a0\u30d1\u30c3\u30b1\u30fc\u30b8\u304c\u30a4\u30f3\u30b9\u30c8\u30fc\u30eb\u3055\u308c\u307e\u3059:\n  ca-certificates-java fonts-dejavu-extra java-common libbonobo2-0\n  libbonobo2-common libgif7 libgnome-2-0 libgnome2-common libgnomevfs2-0\n  libgnomevfs2-common liborbit-2-0 openjdk-8-jre-headless\n\u63d0\u6848\u30d1\u30c3\u30b1\u30fc\u30b8:\n  default-jre libbonobo2-bin desktop-base libgnomevfs2-bin libgnomevfs2-extra\n  gamin | fam gnome-mime-data icedtea-8-plugin openjdk-8-jre-jamvm\n  fonts-ipafont-gothic fonts-ipafont-mincho ttf-wqy-microhei | ttf-wqy-zenhei\n  fonts-indic\n\u4ee5\u4e0b\u306e\u30d1\u30c3\u30b1\u30fc\u30b8\u304c\u65b0\u305f\u306b\u30a4\u30f3\u30b9\u30c8\u30fc\u30eb\u3055\u308c\u307e\u3059:\n  ca-certificates-java fonts-dejavu-extra java-common libbonobo2-0\n  libbonobo2-common libgif7 libgnome-2-0 libgnome2-common libgnomevfs2-0\n  libgnomevfs2-common liborbit-2-0 openjdk-8-jre openjdk-8-jre-headless\n\u30a2\u30c3\u30d7\u30b0\u30ec\u30fc\u30c9: 0 \u500b\u3001\u65b0\u898f\u30a4\u30f3\u30b9\u30c8\u30fc\u30eb: 13 \u500b\u3001\u524a\u9664: 0 \u500b\u3001\u4fdd\u7559: 169 \u500b\u3002\n29.5 MB \u306e\u30a2\u30fc\u30ab\u30a4\u30d6\u3092\u53d6\u5f97\u3059\u308b\u5fc5\u8981\u304c\u3042\u308a\u307e\u3059\u3002\n\u3053\u306e\u64cd\u4f5c\u5f8c\u306b\u8ffd\u52a0\u3067 111 MB \u306e\u30c7\u30a3\u30b9\u30af\u5bb9\u91cf\u304c\u6d88\u8cbb\u3055\u308c\u307e\u3059\u3002\n\u7d9a\u884c\u3057\u307e\u3059\u304b? [Y/n] y\n\u53d6\u5f97:1 http://us.archive.ubuntu.com/ubuntu xenial/main amd64 libbonobo2-common all 2.32.1-3 [34.7 kB]\n\u53d6\u5f97:2 http://us.archive.ubuntu.com/ubuntu xenial/main amd64 liborbit-2-0 amd64 1:2.14.19-1build1 [140 kB]\n\u53d6\u5f97:3 http://us.archive.ubuntu.com/ubuntu xenial/main amd64 libbonobo2-0 amd64 2.32.1-3 [211 kB]\n\u53d6\u5f97:4 http://us.archive.ubuntu.com/ubuntu xenial/main amd64 ca-certificates-java all 20160321 [12.9 kB]\n\u53d6\u5f97:5 http://us.archive.ubuntu.com/ubuntu xenial/main amd64 java-common all 0.56ubuntu2 [7,742 B]\n\u53d6\u5f97:6 http://us.archive.ubuntu.com/ubuntu xenial-updates/main amd64 openjdk-8-jre-headless amd64 8u111-b14-2ubuntu0.16.04.2 [26.9 MB]\n\uff08\u4ee5\u4e0b\u7565\uff09\n\n\n\u7d42\u308f\u3063\u305f\u3089\u3001\u6b63\u3057\u304f\u30a4\u30f3\u30b9\u30c8\u30fc\u30eb\u3067\u304d\u3066\u3044\u308b\u304b\u3001\u30d0\u30fc\u30b8\u30e7\u30f3\u8868\u793a\u3067\u78ba\u8a8d\u3057\u3066\u307f\u307e\u3059\u3002\n\n\u7aef\u672b\uff1aOpenJDK8\u30a4\u30f3\u30b9\u30c8\u30fc\u30eb\nsegavvy@ubuntu:~$ java -version\nopenjdk version \"1.8.0_111\"\nOpenJDK Runtime Environment (build 1.8.0_111-8u111-b14-2ubuntu0.16.04.2-b14)\nOpenJDK 64-Bit Server VM (build 25.111-b14, mixed mode)\n\n\n\u5927\u4e08\u592b\u305d\u3046\u3067\u3059\u306d\u3002\n\nStanford Core NLP\u306e\u30a4\u30f3\u30b9\u30c8\u30fc\u30eb\n\u7d9a\u3044\u3066Stanford Core NLP\u672c\u4f53\u3067\u3059\u3002\nStanford Core NLP\u306f\u30aa\u30d5\u30a3\u30b7\u30e3\u30eb\u30b5\u30a4\u30c8\u306e\u30c0\u30a6\u30f3\u30ed\u30fc\u30c9\u30da\u30fc\u30b8\u304b\u3089\u30c0\u30a6\u30f3\u30ed\u30fc\u30c9\u3067\u304d\u307e\u3059\u3002zip\u30d5\u30a1\u30a4\u30eb\u306b\u306a\u3063\u3066\u3044\u308b\u306e\u3067\u30c0\u30a6\u30f3\u30ed\u30fc\u30c9\u3057\u3066\u5c55\u958b\u3057\u307e\u3059\u3002\n\u79c1\u306f\u30c0\u30a6\u30f3\u30ed\u30fc\u30c9\u5f8c\u3001/usr/local/lib/\u306b\u5c55\u958b\u3057\u307e\u3057\u305f\u3002\n\n\u7aef\u672b\uff1azip\u30d5\u30a1\u30a4\u30eb\u306e\u5c55\u958b\nsegavvy@ubuntu:~/\u30c0\u30a6\u30f3\u30ed\u30fc\u30c9$ sudo unzip stanford-corenlp-full-2016-10-31.zip -d /usr/local/lib/\n[sudo] segavvy \u306e\u30d1\u30b9\u30ef\u30fc\u30c9: \nArchive:  stanford-corenlp-full-2016-10-31.zip\n   creating: /usr/local/lib/stanford-corenlp-full-2016-10-31/\n  inflating: /usr/local/lib/stanford-corenlp-full-2016-10-31/xom-1.2.10-src.jar  \n  inflating: /usr/local/lib/stanford-corenlp-full-2016-10-31/CoreNLP-to-HTML.xsl  \n  inflating: /usr/local/lib/stanford-corenlp-full-2016-10-31/README.txt  \n  inflating: /usr/local/lib/stanford-corenlp-full-2016-10-31/jollyday-0.4.9-sources.jar  \n \uff08\u4ee5\u4e0b\u7565\uff09\n\n\n\nPython\u30d0\u30a4\u30f3\u30c7\u30a3\u30f3\u30b0\u306e\u30a4\u30f3\u30b9\u30c8\u30fc\u30eb\u306f\u898b\u9001\u308a\nStanford Core NLP\u3092Python\u3067\u76f4\u63a5\u4f7f\u3046\u305f\u3081\u306b\u306f\u3001corenlp-python\u306a\u3069\u306e\u30e9\u30a4\u30d6\u30e9\u30ea\u304c\u5fc5\u8981\u3067\u3059\u3002\n\u305f\u3060\u3001\u4eca\u56de\u306e\u554f\u984c\u306e\u6307\u793a\u306f\u3001\u89e3\u6790\u7d50\u679c\u306exml\u30d5\u30a1\u30a4\u30eb\u3092\u307e\u305a\u4f5c\u308a\u3001\u305d\u308c\u3092\u6539\u3081\u3066\u8aad\u307f\u8fbc\u3093\u3067\u304b\u3089\u51e6\u7406\u3057\u306a\u3055\u3044\u3068\u3044\u3046\u5185\u5bb9\u3067\u3059\u3002\u89e3\u6790\u7d50\u679c\u306eXML\u306fStanford Core NLP\u306e\u30b3\u30de\u30f3\u30c9\u3067\u4f5c\u6210\u3067\u304d\u308b\u305f\u3081\u3001\u3069\u3046\u3084\u3089Python\u304b\u3089Stanford Core NLP\u3092\u76f4\u63a5\u4f7f\u3046\u5f62\u306f\u60f3\u5b9a\u3057\u3066\u3044\u306a\u3044\u3088\u3046\u3067\u3059\uff08\u3082\u3046\u30a4\u30f3\u30b9\u30c8\u30fc\u30eb\u3067\u82e6\u52b4\u3057\u305f\u304f\u306a\u3044\u79c1\u306e\u5e0c\u671b\u7684\u89b3\u6e2c^^\uff09\u3002\u3068\u3044\u3046\u3053\u3068\u3067\u3001Stanford Core NLP\u306ePython\u30d0\u30a4\u30f3\u30c7\u30a3\u30f3\u30b0\u306f\u4f7f\u308f\u306a\u3044\u3053\u3068\u306b\u3057\u307e\u3057\u305f\u3002\n\u305d\u306e\u305f\u3081\u3001\u4eca\u56de\u306e\u74b0\u5883\u69cb\u7bc9\u306f\u3053\u308c\u3067\u7d42\u308f\u308a\u3067\u3059\u3002\n\nStanford Core NLP\u3092\u4f7f\u3063\u305f\u89e3\u6790\n\u4e0a\u8ff0\u306e\u3088\u3046\u306b\u3001\u89e3\u6790\u306f\u30b3\u30de\u30f3\u30c9\u3067\u3067\u304d\u307e\u3059\u3002\u4eca\u56de\u306f\u3001Quick start\u3067\u89e3\u8aac\u3055\u308c\u3066\u3044\u308b\u30b3\u30de\u30f3\u30c9\u30e9\u30a4\u30f3\u3092\u307b\u307c\u305d\u306e\u307e\u307e\u4f7f\u3063\u3066xml\u30d5\u30a1\u30a4\u30eb\u3092\u4f5c\u308a\u307e\u3057\u305f\u3002\n\u306a\u304a\u3001\u89e3\u6790\u306b\u306f\u5c11\u3057\u6642\u9593\u304c\u304b\u304b\u308a\u307e\u3059\u3002\u305d\u306e\u305f\u3081\u3001\u3059\u3067\u306bnlp.txt.xml\u304c\u5b58\u5728\u3057\u3066\u3044\u308b\u5834\u5408\u306f\u89e3\u6790\u3057\u306a\u3044\u3088\u3046\u306b\u3057\u307e\u3057\u305f\u3002\u89e3\u6790\u3092\u3084\u308a\u76f4\u3057\u305f\u3044\u5834\u5408\u306f\u3001nlp.txt.xml\u3092\u524a\u9664\u3057\u3066\u304b\u3089\u5b9f\u884c\u3057\u3066\u304f\u3060\u3055\u3044\u3002\n\n\u30b3\u30de\u30f3\u30c9\u306e\u5b9f\u884c\nPython\u304b\u3089\u306e\u30b3\u30de\u30f3\u30c9\u306e\u5b9f\u884c\u306f\u3001subprocess.run()\u3092\u4f7f\u3044\u307e\u3057\u305f\u3002\n\u6700\u521d\u3001shell=True\u306e\u6307\u5b9a\u3092\u3057\u3066\u304a\u3089\u305a\u300cNo such file or directory\u300d\u306e\u30a8\u30e9\u30fc\u306b\u306a\u3063\u3066\u60a9\u307f\u307e\u3057\u305f\u304c\u3001\u30d1\u30b9\u306e\u89e3\u6c7a\u306f\u30b7\u30a7\u30eb\u304c\u3084\u3063\u3066\u3044\u308b\u305f\u3081\u3001\u30b7\u30a7\u30eb\u7d4c\u7531\u3067\u5b9f\u884c\u3057\u306a\u3044\u3068java\u306e\u5834\u6240\u304c\u5206\u304b\u3089\u306a\u3044\u304b\u3089\u3067\u3059\u306d\u3001\u304a\u305d\u3089\u304f\u3002\n\u3042\u3068\u3001check=True\u3092\u6307\u5b9a\u3059\u308b\u3068\u3001\u30b3\u30de\u30f3\u30c9\u304c\u30a8\u30e9\u30fc\u3092\u8fd4\u3057\u305f\u6642\u306b\u4f8b\u5916\u304c\u8d77\u304d\u308b\u3088\u3046\u306b\u306a\u308b\u306e\u3067\u3001\u30b3\u30de\u30f3\u30c9\u306e\u5b9f\u884c\u5931\u6557\u306b\u6c17\u3065\u3051\u308b\u3088\u3046\u306b\u306a\u308a\u307e\u3059\u3002\n\nStanford Core NLP\u306eXML\n\u4eca\u56de\u51fa\u529b\u3055\u308c\u305fXML\u306e\u5148\u982d\u90e8\u5206\u306f\u3001\u6b21\u306e\u3088\u3046\u306a\u611f\u3058\u306b\u306a\u3063\u3066\u3044\u307e\u3059\u3002\n\n\u7aef\u672b\uff1anlp.txt.xml\u306e\u5148\u982d\u90e8\u5206\n<?xml version=\"1.0\" encoding=\"UTF-8\"?>\n<?xml-stylesheet href=\"CoreNLP-to-HTML.xsl\" type=\"text/xsl\"?>\n<root>\n  <document>\n    <sentences>\n      <sentence id=\"1\">\n        <tokens>\n          <token id=\"1\">\n            <word>Natural</word>\n            <lemma>natural</lemma>\n            <CharacterOffsetBegin>0</CharacterOffsetBegin>\n            <CharacterOffsetEnd>7</CharacterOffsetEnd>\n            <POS>JJ</POS>\n            <NER>O</NER>\n            <Speaker>PER0</Speaker>\n          </token>\n          <token id=\"2\">\n            <word>language</word>\n            <lemma>language</lemma>\n            <CharacterOffsetBegin>8</CharacterOffsetBegin>\n            <CharacterOffsetEnd>16</CharacterOffsetEnd>\n            <POS>NN</POS>\n            <NER>O</NER>\n            <Speaker>PER0</Speaker>\n          </token>\n          <token id=\"3\">\n            <word>processing</word>\n            <lemma>processing</lemma>\n            <CharacterOffsetBegin>17</CharacterOffsetBegin>\n            <CharacterOffsetEnd>27</CharacterOffsetEnd>\n            <POS>NN</POS>\n            <NER>O</NER>\n            <Speaker>PER0</Speaker>\n          </token>\n\n\n\u30d5\u30a1\u30a4\u30eb\u5168\u4f53\u306fGitHub\u306b\u30a2\u30c3\u30d7\u3057\u3066\u3044\u307e\u3059\u3002\n\u3053\u306eXML\u306fXSLT\u30b9\u30bf\u30a4\u30eb\u30b7\u30fc\u30c8\u306b\u5f93\u3063\u305f\u30d5\u30a9\u30fc\u30de\u30c3\u30c8\u306b\u306a\u3063\u3066\u3044\u307e\u3059\u3002xml\u30d5\u30a1\u30a4\u30eb\u306e\u5148\u982d\u90e8\u5206\u306b\u3042\u308bCoreNLP-to-HTML.xsl\u3068\u3044\u3046\u306e\u304c\u305d\u308c\u3067\u3001Stanford Core NLP\u306e\u30a4\u30f3\u30b9\u30c8\u30fc\u30eb\u5148\uff08\u79c1\u306e\u5834\u5408\u306f/usr/local/lib/stanford-corenlp-full-2016-10-31\uff09\u306b\u5165\u3063\u3066\u3044\u307e\u3059\u3002\n\u3053\u306e\u30d5\u30a1\u30a4\u30eb\u3092nlp.txt.xml\u3068\u540c\u3058\u4f4d\u7f6e\u306b\u6301\u3063\u3066\u304d\u3066\u3001nlp.txt.xml\u3092\u30d6\u30e9\u30a6\u30b6\u3067\u958b\u304f\u3068\u3001\u6b21\u306e\u3088\u3046\u306b\u4e2d\u8eab\u304c\u78ba\u8a8d\u3067\u304d\u308b\u3088\u3046\u306b\u306a\u308a\u307e\u3059\u3002\n\n\u4eca\u56de\u306e\u554f\u984c\u306f\u5358\u8a9e\u3092\u62bd\u51fa\u3059\u308c\u3070\u826f\u3044\u306e\u3067\u3001word\u30bf\u30b0\u306e\u5185\u5bb9\u3092\u53d6\u308a\u51fa\u305b\u3070\u826f\u3055\u305d\u3046\u3067\u3059\u3002\n\nXML\u306e\u89e3\u6790\nXML\u306e\u89e3\u6790\u306fElementTree XML API\u3092\u4f7f\u3044\u307e\u3057\u305f\u3002ElementTree XML API\u306e\u30c1\u30e5\u30fc\u30c8\u30ea\u30a2\u30eb\u3092\u9069\u5f53\u306b\u771f\u4f3c\u3057\u3066\u66f8\u3044\u3066\u3044\u307e\u3059\u304c\u3001\u6307\u5b9a\u30bf\u30b0\u306e\u4e2d\u8eab\u3092\u5217\u6319\u3059\u308b\u3060\u3051\u306a\u3089\u7c21\u5358\u3067\u3059\u3002\n\u3000\n54\u672c\u76ee\u306e\u30ce\u30c3\u30af\u306f\u4ee5\u4e0a\u3067\u3059\u3002\u8aa4\u308a\u306a\u3069\u3042\u308a\u307e\u3057\u305f\u3089\u3001\u3054\u6307\u6458\u3044\u305f\u3060\u3051\u307e\u3059\u3068\u5e78\u3044\u3067\u3059\u3002\n\n\u5b9f\u884c\u7d50\u679c\u306b\u306f\u3001100\u672c\u30ce\u30c3\u30af\u3067\u7528\u3044\u308b\u30b3\u30fc\u30d1\u30b9\u30fb\u30c7\u30fc\u30bf\u3067\u914d\u5e03\u3055\u308c\u3066\u3044\u308b\u30c7\u30fc\u30bf\u306e\u4e00\u90e8\u304c\u542b\u307e\u308c\u307e\u3059\u3002\u3053\u306e\u7b2c6\u7ae0\u3067\u7528\u3044\u3066\u3044\u308b\u30c7\u30fc\u30bf\u306e\u30e9\u30a4\u30bb\u30f3\u30b9\u306f\u30af\u30ea\u30a8\u30a4\u30c6\u30a3\u30d6\u30fb\u30b3\u30e2\u30f3\u30ba \u8868\u793a-\u7d99\u627f 3.0 \u975e\u79fb\u690d\uff08\u65e5\u672c\u8a9e\u8a33\uff09\u3067\u3059\u3002\n\n[\u8a00\u8a9e\u51e6\u7406100\u672c\u30ce\u30c3\u30af 2015](http://www.cl.ecei.tohoku.ac.jp/nlp100/)\u306e\u6311\u6226\u8a18\u9332\u3067\u3059\u3002\u74b0\u5883\u306fUbuntu 16.04 LTS \uff0b Python 3.5.2 \\:\\: Anaconda 4.1.1 (64-bit)\u3067\u3059\u3002\u904e\u53bb\u306e\u30ce\u30c3\u30af\u306e\u4e00\u89a7\u306f[\u3053\u3061\u3089](http://qiita.com/segavvy/items)\u304b\u3089\u3069\u3046\u305e\u3002\n\n## \u7b2c6\u7ae0: \u82f1\u8a9e\u30c6\u30ad\u30b9\u30c8\u306e\u51e6\u7406\n>\u82f1\u8a9e\u306e\u30c6\u30ad\u30b9\u30c8\uff08nlp.txt\uff09\u306b\u5bfe\u3057\u3066\uff0c\u4ee5\u4e0b\u306e\u51e6\u7406\u3092\u5b9f\u884c\u305b\u3088\uff0e\n\n###53. Tokenization\n>[Stanford Core NLP](http://stanfordnlp.github.io/CoreNLP/)\u3092\u7528\u3044\uff0c\u5165\u529b\u30c6\u30ad\u30b9\u30c8\u306e\u89e3\u6790\u7d50\u679c\u3092XML\u5f62\u5f0f\u3067\u5f97\u3088\uff0e\u307e\u305f\uff0c\u3053\u306eXML\u30d5\u30a1\u30a4\u30eb\u3092\u8aad\u307f\u8fbc\u307f\uff0c\u5165\u529b\u30c6\u30ad\u30b9\u30c8\u30921\u884c1\u5358\u8a9e\u306e\u5f62\u5f0f\u3067\u51fa\u529b\u305b\u3088\uff0e\n\n####\u51fa\u6765\u4e0a\u304c\u3063\u305f\u30b3\u30fc\u30c9\uff1a\n\n```python:main.py\n# coding: utf-8\nimport os\nimport subprocess\nimport xml.etree.ElementTree as ET\n\nfname = 'nlp.txt'\nfname_parsed = 'nlp.txt.xml'\n\n\ndef parse_nlp():\n\t'''nlp.txt\u3092Stanford Core NLP\u3067\u89e3\u6790\u3057xml\u30d5\u30a1\u30a4\u30eb\u3078\u51fa\u529b\n\t\u3059\u3067\u306b\u7d50\u679c\u30d5\u30a1\u30a4\u30eb\u304c\u5b58\u5728\u3059\u308b\u5834\u5408\u306f\u5b9f\u884c\u3057\u306a\u3044\n\t'''\n\tif not os.path.exists(fname_parsed):\n\n\t\t# StanfordCoreNLP\u5b9f\u884c\u3001\u6a19\u6e96\u30a8\u30e9\u30fc\u306fparse.out\u3078\u51fa\u529b\n\t\tsubprocess.run(\n\t\t\t'java -cp \"/usr/local/lib/stanford-corenlp-full-2016-10-31/*\"'\n\t\t\t' -Xmx2g'\n\t\t\t' edu.stanford.nlp.pipeline.StanfordCoreNLP'\n\t\t\t' -annotators tokenize,ssplit,pos,lemma,ner,parse,dcoref'\n\t\t\t' -file ' + fname + ' 2>parse.out',\n\t\t\tshell=True,\t\t# shell\u3067\u5b9f\u884c\n\t\t\tcheck=True\t\t# \u30a8\u30e9\u30fc\u30c1\u30a7\u30c3\u30af\u3042\u308a\n\t\t)\n\n\n# nlp.txt\u3092\u89e3\u6790\nparse_nlp()\n\n# \u89e3\u6790\u7d50\u679c\u306exml\u3092\u30d1\u30fc\u30b9\nroot = ET.parse(fname_parsed)\n\n# word\u306e\u307f\u53d6\u308a\u51fa\u3057\nfor word in root.iter('word'):\n\tprint(word.text)\n```\n\n####\u5b9f\u884c\u7d50\u679c\uff1a\n\n\u9577\u3044\u306e\u3067\u5148\u982d\u90e8\u5206\u306e\u629c\u7c8b\u3067\u3059\u3002\n\n```console:\u7aef\u672b\uff1a\u5148\u982d\u90e8\u5206\nNatural\nlanguage\nprocessing\nFrom\nWikipedia\n,\nthe\nfree\nencyclopedia\nNatural\nlanguage\nprocessing\n-LRB-\nNLP\n-RRB-\nis\na\nfield\nof\ncomputer\nscience\n,\nartificial\nintelligence\n,\nand\nlinguistics\nconcerned\nwith\nthe\ninteractions\nbetween\ncomputers\nand\nhuman\n-LRB-\nnatural\n-RRB-\nlanguages\n.\nAs\nsuch\n,\nNLP\nis\nrelated\nto\nthe\narea\nof\nhumani-computer\ninteraction\n.\n```\n\n\u5168\u4f53\u306e\u7d50\u679c\u306f[GitHub](https://github.com/segavvy/nlp100_Python/tree/master/53)\u306b\u30a2\u30c3\u30d7\u3057\u3066\u3044\u307e\u3059\u3002\n\n\u306a\u304a\u3001Stanford Core NLP\u306e\u5b9f\u884c\u6642\u306f\u6a19\u6e96\u30a8\u30e9\u30fc\u306b\u6b21\u306e\u3088\u3046\u306a\u30e1\u30c3\u30bb\u30fc\u30b8\u304c\u51fa\u529b\u3055\u308c\u307e\u3059\u3002\u4eca\u56de\u306e\u30d7\u30ed\u30b0\u30e9\u30e0\u3067\u306fparse.out\u306b\u30ea\u30c0\u30a4\u30ec\u30af\u30c8\u3055\u305b\u307e\u3057\u305f\u3002\n\n```console:\u7aef\u672b\uff1aparse.out\n[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator tokenize\n[main] INFO edu.stanford.nlp.pipeline.TokenizerAnnotator - No tokenizer type provided. Defaulting to PTBTokenizer.\n[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator ssplit\n[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator pos\n[main] INFO edu.stanford.nlp.tagger.maxent.MaxentTagger - Reading POS tagger model from edu/stanford/nlp/models/pos-tagger/english-left3words/english-left3words-distsim.tagger ... done [2.6 sec].\n[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator lemma\n[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator ner\n[main] INFO edu.stanford.nlp.ie.AbstractSequenceClassifier - Loading classifier from edu/stanford/nlp/models/ner/english.all.3class.distsim.crf.ser.gz ... done [5.3 sec].\n[main] INFO edu.stanford.nlp.ie.AbstractSequenceClassifier - Loading classifier from edu/stanford/nlp/models/ner/english.muc.7class.distsim.crf.ser.gz ... done [3.7 sec].\n[main] INFO edu.stanford.nlp.ie.AbstractSequenceClassifier - Loading classifier from edu/stanford/nlp/models/ner/english.conll.4class.distsim.crf.ser.gz ... done [4.9 sec].\n[main] INFO edu.stanford.nlp.time.JollyDayHolidays - Initializing JollyDayHoliday for SUTime from classpath edu/stanford/nlp/models/sutime/jollyday/Holidays_sutime.xml as sutime.binder.1.\n[main] INFO edu.stanford.nlp.ling.tokensregex.CoreMapExpressionExtractor - Reading TokensRegex rules from edu/stanford/nlp/models/sutime/defs.sutime.txt\n[main] INFO edu.stanford.nlp.ling.tokensregex.CoreMapExpressionExtractor - Read 84 rules\n[main] INFO edu.stanford.nlp.ling.tokensregex.CoreMapExpressionExtractor - Reading TokensRegex rules from edu/stanford/nlp/models/sutime/english.sutime.txt\n[main] INFO edu.stanford.nlp.ling.tokensregex.CoreMapExpressionExtractor - Read 267 rules\n[main] INFO edu.stanford.nlp.ling.tokensregex.CoreMapExpressionExtractor - Reading TokensRegex rules from edu/stanford/nlp/models/sutime/english.holidays.sutime.txt\n[main] INFO edu.stanford.nlp.ling.tokensregex.CoreMapExpressionExtractor - Read 25 rules\n[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator parse\n[main] INFO edu.stanford.nlp.parser.common.ParserGrammar - Loading parser from serialized file edu/stanford/nlp/models/lexparser/englishPCFG.ser.gz ... done [0.6 sec].\n[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator dcoref\n\nProcessing file /home/segavvy/\u30c9\u30ad\u30e5\u30e1\u30f3\u30c8/\u8a00\u8a9e\u51e6\u7406100\u672c\u30ce\u30c3\u30af2015/53/nlp.txt ... writing to /home/segavvy/\u30c9\u30ad\u30e5\u30e1\u30f3\u30c8/\u8a00\u8a9e\u51e6\u7406100\u672c\u30ce\u30c3\u30af2015/53/nlp.txt.xml\nAnnotating file /home/segavvy/\u30c9\u30ad\u30e5\u30e1\u30f3\u30c8/\u8a00\u8a9e\u51e6\u7406100\u672c\u30ce\u30c3\u30af2015/53/nlp.txt ... done [20.6 sec].\n\nAnnotation pipeline timing information:\nTokenizerAnnotator: 0.2 sec.\nWordsToSentencesAnnotator: 0.0 sec.\nPOSTaggerAnnotator: 0.2 sec.\nMorphaAnnotator: 0.1 sec.\nNERCombinerAnnotator: 2.6 sec.\nParserAnnotator: 12.8 sec.\nDeterministicCorefAnnotator: 4.7 sec.\nTOTAL: 20.6 sec. for 1452 tokens at 70.5 tokens/sec.\nPipeline setup: 27.2 sec.\nTotal time for StanfordCoreNLP pipeline: 48.1 sec.\n```\n\n\u7279\u306b\u6c17\u306b\u3059\u308b\u5185\u5bb9\u306f\u306a\u3055\u305d\u3046\u3067\u3059\u3002\n\n###Stanford Core NLP\u306e\u30a4\u30f3\u30b9\u30c8\u30fc\u30eb\n\u30d7\u30ed\u30b0\u30e9\u30df\u30f3\u30b0\u306e\u524d\u306b\u74b0\u5883\u306e\u69cb\u7bc9\u3067\u3059\u3002\n\u4eca\u56de\u306f\u554f\u984c\u3067\u6307\u793a\u3055\u308c\u3066\u3044\u308b\u300cStanford Core NLP\u300d\u304c\u5fc5\u8981\u3067\u3059\u3002\u30aa\u30d5\u30a3\u30b7\u30e3\u30eb\u30b5\u30a4\u30c8\u306f[\u3053\u3061\u3089](http://stanfordnlp.github.io/CoreNLP/)\u3067\u3059\u3002\n\u3053\u306e\u30b5\u30a4\u30c8\u306e\u300cProgramming languages and operating systems\u300d\u306e\u3068\u3053\u308d\u3092\u898b\u308b\u3068Java 1.8\u4ee5\u4e0a\u304c\u5fc5\u8981\u3068\u3042\u308a\u307e\u3059\u306e\u3067\u3001Java\u306e\u30a4\u30f3\u30b9\u30c8\u30fc\u30eb\u304b\u3089\u59cb\u3081\u307e\u3059\u3002\n\n####Java 1.8\u306e\u30a4\u30f3\u30b9\u30c8\u30fc\u30eb\n\u79c1\u306fOpenJDK 8\u306eJRE\u3092\u5165\u308c\u307e\u3057\u305f\u3002\u3053\u308c\u306fapt\u4e00\u767a\u3067\u3044\u3051\u307e\u3059\u3002\n\n```console:\u7aef\u672b\uff1aOpenJDK8\u30a4\u30f3\u30b9\u30c8\u30fc\u30eb\nsegavvy@ubuntu:~$ sudo apt install openjdk-8-jre\n[sudo] segavvy \u306e\u30d1\u30b9\u30ef\u30fc\u30c9: \n\u30d1\u30c3\u30b1\u30fc\u30b8\u30ea\u30b9\u30c8\u3092\u8aad\u307f\u8fbc\u3093\u3067\u3044\u307e\u3059... \u5b8c\u4e86\n\u4f9d\u5b58\u95a2\u4fc2\u30c4\u30ea\u30fc\u3092\u4f5c\u6210\u3057\u3066\u3044\u307e\u3059                \n\u72b6\u614b\u60c5\u5831\u3092\u8aad\u307f\u53d6\u3063\u3066\u3044\u307e\u3059... \u5b8c\u4e86\n\u4ee5\u4e0b\u306e\u8ffd\u52a0\u30d1\u30c3\u30b1\u30fc\u30b8\u304c\u30a4\u30f3\u30b9\u30c8\u30fc\u30eb\u3055\u308c\u307e\u3059:\n  ca-certificates-java fonts-dejavu-extra java-common libbonobo2-0\n  libbonobo2-common libgif7 libgnome-2-0 libgnome2-common libgnomevfs2-0\n  libgnomevfs2-common liborbit-2-0 openjdk-8-jre-headless\n\u63d0\u6848\u30d1\u30c3\u30b1\u30fc\u30b8:\n  default-jre libbonobo2-bin desktop-base libgnomevfs2-bin libgnomevfs2-extra\n  gamin | fam gnome-mime-data icedtea-8-plugin openjdk-8-jre-jamvm\n  fonts-ipafont-gothic fonts-ipafont-mincho ttf-wqy-microhei | ttf-wqy-zenhei\n  fonts-indic\n\u4ee5\u4e0b\u306e\u30d1\u30c3\u30b1\u30fc\u30b8\u304c\u65b0\u305f\u306b\u30a4\u30f3\u30b9\u30c8\u30fc\u30eb\u3055\u308c\u307e\u3059:\n  ca-certificates-java fonts-dejavu-extra java-common libbonobo2-0\n  libbonobo2-common libgif7 libgnome-2-0 libgnome2-common libgnomevfs2-0\n  libgnomevfs2-common liborbit-2-0 openjdk-8-jre openjdk-8-jre-headless\n\u30a2\u30c3\u30d7\u30b0\u30ec\u30fc\u30c9: 0 \u500b\u3001\u65b0\u898f\u30a4\u30f3\u30b9\u30c8\u30fc\u30eb: 13 \u500b\u3001\u524a\u9664: 0 \u500b\u3001\u4fdd\u7559: 169 \u500b\u3002\n29.5 MB \u306e\u30a2\u30fc\u30ab\u30a4\u30d6\u3092\u53d6\u5f97\u3059\u308b\u5fc5\u8981\u304c\u3042\u308a\u307e\u3059\u3002\n\u3053\u306e\u64cd\u4f5c\u5f8c\u306b\u8ffd\u52a0\u3067 111 MB \u306e\u30c7\u30a3\u30b9\u30af\u5bb9\u91cf\u304c\u6d88\u8cbb\u3055\u308c\u307e\u3059\u3002\n\u7d9a\u884c\u3057\u307e\u3059\u304b? [Y/n] y\n\u53d6\u5f97:1 http://us.archive.ubuntu.com/ubuntu xenial/main amd64 libbonobo2-common all 2.32.1-3 [34.7 kB]\n\u53d6\u5f97:2 http://us.archive.ubuntu.com/ubuntu xenial/main amd64 liborbit-2-0 amd64 1:2.14.19-1build1 [140 kB]\n\u53d6\u5f97:3 http://us.archive.ubuntu.com/ubuntu xenial/main amd64 libbonobo2-0 amd64 2.32.1-3 [211 kB]\n\u53d6\u5f97:4 http://us.archive.ubuntu.com/ubuntu xenial/main amd64 ca-certificates-java all 20160321 [12.9 kB]\n\u53d6\u5f97:5 http://us.archive.ubuntu.com/ubuntu xenial/main amd64 java-common all 0.56ubuntu2 [7,742 B]\n\u53d6\u5f97:6 http://us.archive.ubuntu.com/ubuntu xenial-updates/main amd64 openjdk-8-jre-headless amd64 8u111-b14-2ubuntu0.16.04.2 [26.9 MB]\n\uff08\u4ee5\u4e0b\u7565\uff09\n```\n\n\u7d42\u308f\u3063\u305f\u3089\u3001\u6b63\u3057\u304f\u30a4\u30f3\u30b9\u30c8\u30fc\u30eb\u3067\u304d\u3066\u3044\u308b\u304b\u3001\u30d0\u30fc\u30b8\u30e7\u30f3\u8868\u793a\u3067\u78ba\u8a8d\u3057\u3066\u307f\u307e\u3059\u3002\n\n```console:\u7aef\u672b\uff1aOpenJDK8\u30a4\u30f3\u30b9\u30c8\u30fc\u30eb\nsegavvy@ubuntu:~$ java -version\nopenjdk version \"1.8.0_111\"\nOpenJDK Runtime Environment (build 1.8.0_111-8u111-b14-2ubuntu0.16.04.2-b14)\nOpenJDK 64-Bit Server VM (build 25.111-b14, mixed mode)\n```\n\n\u5927\u4e08\u592b\u305d\u3046\u3067\u3059\u306d\u3002\n\n####Stanford Core NLP\u306e\u30a4\u30f3\u30b9\u30c8\u30fc\u30eb\n\n\u7d9a\u3044\u3066Stanford Core NLP\u672c\u4f53\u3067\u3059\u3002\nStanford Core NLP\u306f\u30aa\u30d5\u30a3\u30b7\u30e3\u30eb\u30b5\u30a4\u30c8\u306e[\u30c0\u30a6\u30f3\u30ed\u30fc\u30c9\u30da\u30fc\u30b8](http://stanfordnlp.github.io/CoreNLP/download.html)\u304b\u3089\u30c0\u30a6\u30f3\u30ed\u30fc\u30c9\u3067\u304d\u307e\u3059\u3002zip\u30d5\u30a1\u30a4\u30eb\u306b\u306a\u3063\u3066\u3044\u308b\u306e\u3067\u30c0\u30a6\u30f3\u30ed\u30fc\u30c9\u3057\u3066\u5c55\u958b\u3057\u307e\u3059\u3002\n\u79c1\u306f\u30c0\u30a6\u30f3\u30ed\u30fc\u30c9\u5f8c\u3001/usr/local/lib/\u306b\u5c55\u958b\u3057\u307e\u3057\u305f\u3002\n\n```console:\u7aef\u672b\uff1azip\u30d5\u30a1\u30a4\u30eb\u306e\u5c55\u958b\nsegavvy@ubuntu:~/\u30c0\u30a6\u30f3\u30ed\u30fc\u30c9$ sudo unzip stanford-corenlp-full-2016-10-31.zip -d /usr/local/lib/\n[sudo] segavvy \u306e\u30d1\u30b9\u30ef\u30fc\u30c9: \nArchive:  stanford-corenlp-full-2016-10-31.zip\n   creating: /usr/local/lib/stanford-corenlp-full-2016-10-31/\n  inflating: /usr/local/lib/stanford-corenlp-full-2016-10-31/xom-1.2.10-src.jar  \n  inflating: /usr/local/lib/stanford-corenlp-full-2016-10-31/CoreNLP-to-HTML.xsl  \n  inflating: /usr/local/lib/stanford-corenlp-full-2016-10-31/README.txt  \n  inflating: /usr/local/lib/stanford-corenlp-full-2016-10-31/jollyday-0.4.9-sources.jar  \n \uff08\u4ee5\u4e0b\u7565\uff09\n```\n\n####Python\u30d0\u30a4\u30f3\u30c7\u30a3\u30f3\u30b0\u306e\u30a4\u30f3\u30b9\u30c8\u30fc\u30eb\u306f\u898b\u9001\u308a\n\nStanford Core NLP\u3092Python\u3067\u76f4\u63a5\u4f7f\u3046\u305f\u3081\u306b\u306f\u3001[corenlp-python](https://pypi.python.org/pypi/corenlp-python)\u306a\u3069\u306e\u30e9\u30a4\u30d6\u30e9\u30ea\u304c\u5fc5\u8981\u3067\u3059\u3002\n\n\u305f\u3060\u3001\u4eca\u56de\u306e\u554f\u984c\u306e\u6307\u793a\u306f\u3001\u89e3\u6790\u7d50\u679c\u306exml\u30d5\u30a1\u30a4\u30eb\u3092\u307e\u305a\u4f5c\u308a\u3001\u305d\u308c\u3092\u6539\u3081\u3066\u8aad\u307f\u8fbc\u3093\u3067\u304b\u3089\u51e6\u7406\u3057\u306a\u3055\u3044\u3068\u3044\u3046\u5185\u5bb9\u3067\u3059\u3002\u89e3\u6790\u7d50\u679c\u306eXML\u306fStanford Core NLP\u306e\u30b3\u30de\u30f3\u30c9\u3067\u4f5c\u6210\u3067\u304d\u308b\u305f\u3081\u3001\u3069\u3046\u3084\u3089Python\u304b\u3089Stanford Core NLP\u3092\u76f4\u63a5\u4f7f\u3046\u5f62\u306f\u60f3\u5b9a\u3057\u3066\u3044\u306a\u3044\u3088\u3046\u3067\u3059\uff08\u3082\u3046\u30a4\u30f3\u30b9\u30c8\u30fc\u30eb\u3067\u82e6\u52b4\u3057\u305f\u304f\u306a\u3044\u79c1\u306e\u5e0c\u671b\u7684\u89b3\u6e2c^^\uff09\u3002\u3068\u3044\u3046\u3053\u3068\u3067\u3001Stanford Core NLP\u306ePython\u30d0\u30a4\u30f3\u30c7\u30a3\u30f3\u30b0\u306f\u4f7f\u308f\u306a\u3044\u3053\u3068\u306b\u3057\u307e\u3057\u305f\u3002\n\n\u305d\u306e\u305f\u3081\u3001\u4eca\u56de\u306e\u74b0\u5883\u69cb\u7bc9\u306f\u3053\u308c\u3067\u7d42\u308f\u308a\u3067\u3059\u3002\n\n###Stanford Core NLP\u3092\u4f7f\u3063\u305f\u89e3\u6790\n\n\u4e0a\u8ff0\u306e\u3088\u3046\u306b\u3001\u89e3\u6790\u306f\u30b3\u30de\u30f3\u30c9\u3067\u3067\u304d\u307e\u3059\u3002\u4eca\u56de\u306f\u3001[Quick start](http://stanfordnlp.github.io/CoreNLP/cmdline.html#quick-start)\u3067\u89e3\u8aac\u3055\u308c\u3066\u3044\u308b\u30b3\u30de\u30f3\u30c9\u30e9\u30a4\u30f3\u3092\u307b\u307c\u305d\u306e\u307e\u307e\u4f7f\u3063\u3066xml\u30d5\u30a1\u30a4\u30eb\u3092\u4f5c\u308a\u307e\u3057\u305f\u3002\n\n\u306a\u304a\u3001\u89e3\u6790\u306b\u306f\u5c11\u3057\u6642\u9593\u304c\u304b\u304b\u308a\u307e\u3059\u3002\u305d\u306e\u305f\u3081\u3001\u3059\u3067\u306bnlp.txt.xml\u304c\u5b58\u5728\u3057\u3066\u3044\u308b\u5834\u5408\u306f\u89e3\u6790\u3057\u306a\u3044\u3088\u3046\u306b\u3057\u307e\u3057\u305f\u3002\u89e3\u6790\u3092\u3084\u308a\u76f4\u3057\u305f\u3044\u5834\u5408\u306f\u3001nlp.txt.xml\u3092\u524a\u9664\u3057\u3066\u304b\u3089\u5b9f\u884c\u3057\u3066\u304f\u3060\u3055\u3044\u3002\n\n\n###\u30b3\u30de\u30f3\u30c9\u306e\u5b9f\u884c\n\nPython\u304b\u3089\u306e\u30b3\u30de\u30f3\u30c9\u306e\u5b9f\u884c\u306f\u3001[`subprocess.run()`](http://docs.python.jp/3/library/subprocess.html#subprocess.run)\u3092\u4f7f\u3044\u307e\u3057\u305f\u3002\n\n\u6700\u521d\u3001`shell=True`\u306e\u6307\u5b9a\u3092\u3057\u3066\u304a\u3089\u305a\u300cNo such file or directory\u300d\u306e\u30a8\u30e9\u30fc\u306b\u306a\u3063\u3066\u60a9\u307f\u307e\u3057\u305f\u304c\u3001\u30d1\u30b9\u306e\u89e3\u6c7a\u306f\u30b7\u30a7\u30eb\u304c\u3084\u3063\u3066\u3044\u308b\u305f\u3081\u3001\u30b7\u30a7\u30eb\u7d4c\u7531\u3067\u5b9f\u884c\u3057\u306a\u3044\u3068java\u306e\u5834\u6240\u304c\u5206\u304b\u3089\u306a\u3044\u304b\u3089\u3067\u3059\u306d\u3001\u304a\u305d\u3089\u304f\u3002\n\n\u3042\u3068\u3001`check=True`\u3092\u6307\u5b9a\u3059\u308b\u3068\u3001\u30b3\u30de\u30f3\u30c9\u304c\u30a8\u30e9\u30fc\u3092\u8fd4\u3057\u305f\u6642\u306b\u4f8b\u5916\u304c\u8d77\u304d\u308b\u3088\u3046\u306b\u306a\u308b\u306e\u3067\u3001\u30b3\u30de\u30f3\u30c9\u306e\u5b9f\u884c\u5931\u6557\u306b\u6c17\u3065\u3051\u308b\u3088\u3046\u306b\u306a\u308a\u307e\u3059\u3002\n\n###Stanford Core NLP\u306eXML\n\n\u4eca\u56de\u51fa\u529b\u3055\u308c\u305fXML\u306e\u5148\u982d\u90e8\u5206\u306f\u3001\u6b21\u306e\u3088\u3046\u306a\u611f\u3058\u306b\u306a\u3063\u3066\u3044\u307e\u3059\u3002\n\n```console:\u7aef\u672b\uff1anlp.txt.xml\u306e\u5148\u982d\u90e8\u5206\n<?xml version=\"1.0\" encoding=\"UTF-8\"?>\n<?xml-stylesheet href=\"CoreNLP-to-HTML.xsl\" type=\"text/xsl\"?>\n<root>\n  <document>\n    <sentences>\n      <sentence id=\"1\">\n        <tokens>\n          <token id=\"1\">\n            <word>Natural</word>\n            <lemma>natural</lemma>\n            <CharacterOffsetBegin>0</CharacterOffsetBegin>\n            <CharacterOffsetEnd>7</CharacterOffsetEnd>\n            <POS>JJ</POS>\n            <NER>O</NER>\n            <Speaker>PER0</Speaker>\n          </token>\n          <token id=\"2\">\n            <word>language</word>\n            <lemma>language</lemma>\n            <CharacterOffsetBegin>8</CharacterOffsetBegin>\n            <CharacterOffsetEnd>16</CharacterOffsetEnd>\n            <POS>NN</POS>\n            <NER>O</NER>\n            <Speaker>PER0</Speaker>\n          </token>\n          <token id=\"3\">\n            <word>processing</word>\n            <lemma>processing</lemma>\n            <CharacterOffsetBegin>17</CharacterOffsetBegin>\n            <CharacterOffsetEnd>27</CharacterOffsetEnd>\n            <POS>NN</POS>\n            <NER>O</NER>\n            <Speaker>PER0</Speaker>\n          </token>\n```\n\n\u30d5\u30a1\u30a4\u30eb\u5168\u4f53\u306f[GitHub](https://github.com/segavvy/nlp100_Python/tree/master/53)\u306b\u30a2\u30c3\u30d7\u3057\u3066\u3044\u307e\u3059\u3002\n\n\u3053\u306eXML\u306fXSLT\u30b9\u30bf\u30a4\u30eb\u30b7\u30fc\u30c8\u306b\u5f93\u3063\u305f\u30d5\u30a9\u30fc\u30de\u30c3\u30c8\u306b\u306a\u3063\u3066\u3044\u307e\u3059\u3002xml\u30d5\u30a1\u30a4\u30eb\u306e\u5148\u982d\u90e8\u5206\u306b\u3042\u308bCoreNLP-to-HTML.xsl\u3068\u3044\u3046\u306e\u304c\u305d\u308c\u3067\u3001Stanford Core NLP\u306e\u30a4\u30f3\u30b9\u30c8\u30fc\u30eb\u5148\uff08\u79c1\u306e\u5834\u5408\u306f/usr/local/lib/stanford-corenlp-full-2016-10-31\uff09\u306b\u5165\u3063\u3066\u3044\u307e\u3059\u3002\n\n\u3053\u306e\u30d5\u30a1\u30a4\u30eb\u3092nlp.txt.xml\u3068\u540c\u3058\u4f4d\u7f6e\u306b\u6301\u3063\u3066\u304d\u3066\u3001nlp.txt.xml\u3092\u30d6\u30e9\u30a6\u30b6\u3067\u958b\u304f\u3068\u3001\u6b21\u306e\u3088\u3046\u306b\u4e2d\u8eab\u304c\u78ba\u8a8d\u3067\u304d\u308b\u3088\u3046\u306b\u306a\u308a\u307e\u3059\u3002\n\n![Kobito.8ozB3P.png](https://qiita-image-store.s3.amazonaws.com/0/139624/7548d2fc-9528-af57-ed7a-f4653303485f.png \"Kobito.8ozB3P.png\")\n\n\n\u4eca\u56de\u306e\u554f\u984c\u306f\u5358\u8a9e\u3092\u62bd\u51fa\u3059\u308c\u3070\u826f\u3044\u306e\u3067\u3001word\u30bf\u30b0\u306e\u5185\u5bb9\u3092\u53d6\u308a\u51fa\u305b\u3070\u826f\u3055\u305d\u3046\u3067\u3059\u3002\n\n\n###XML\u306e\u89e3\u6790\nXML\u306e\u89e3\u6790\u306f[ElementTree XML API](http://docs.python.jp/3/library/xml.etree.elementtree.html)\u3092\u4f7f\u3044\u307e\u3057\u305f\u3002ElementTree XML API\u306e[\u30c1\u30e5\u30fc\u30c8\u30ea\u30a2\u30eb](http://docs.python.jp/3/library/xml.etree.elementtree.html#tutorial)\u3092\u9069\u5f53\u306b\u771f\u4f3c\u3057\u3066\u66f8\u3044\u3066\u3044\u307e\u3059\u304c\u3001\u6307\u5b9a\u30bf\u30b0\u306e\u4e2d\u8eab\u3092\u5217\u6319\u3059\u308b\u3060\u3051\u306a\u3089\u7c21\u5358\u3067\u3059\u3002\n\n\u3000\n54\u672c\u76ee\u306e\u30ce\u30c3\u30af\u306f\u4ee5\u4e0a\u3067\u3059\u3002\u8aa4\u308a\u306a\u3069\u3042\u308a\u307e\u3057\u305f\u3089\u3001\u3054\u6307\u6458\u3044\u305f\u3060\u3051\u307e\u3059\u3068\u5e78\u3044\u3067\u3059\u3002\n<hr>\n\n*\u5b9f\u884c\u7d50\u679c\u306b\u306f\u3001[100\u672c\u30ce\u30c3\u30af\u3067\u7528\u3044\u308b\u30b3\u30fc\u30d1\u30b9\u30fb\u30c7\u30fc\u30bf](http://www.cl.ecei.tohoku.ac.jp/nlp100/#data)\u3067\u914d\u5e03\u3055\u308c\u3066\u3044\u308b\u30c7\u30fc\u30bf\u306e\u4e00\u90e8\u304c\u542b\u307e\u308c\u307e\u3059\u3002\u3053\u306e\u7b2c6\u7ae0\u3067\u7528\u3044\u3066\u3044\u308b\u30c7\u30fc\u30bf\u306e\u30e9\u30a4\u30bb\u30f3\u30b9\u306f[\u30af\u30ea\u30a8\u30a4\u30c6\u30a3\u30d6\u30fb\u30b3\u30e2\u30f3\u30ba \u8868\u793a-\u7d99\u627f 3.0 \u975e\u79fb\u690d](https://creativecommons.org/licenses/by-sa/3.0/legalcode)\uff08[\u65e5\u672c\u8a9e\u8a33](https://creativecommons.org/licenses/by-sa/3.0/deed.ja)\uff09\u3067\u3059\u3002*\n", "tags": ["\u81ea\u7136\u8a00\u8a9e\u51e6\u7406", "\u8a00\u8a9e\u51e6\u7406100\u672c\u30ce\u30c3\u30af", "Python"]}