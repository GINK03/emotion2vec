{"tags": ["TensorFlow", "AWS", "NVIDIA", "\u30d9\u30f3\u30c1\u30de\u30fc\u30af", "DeepLearning"], "context": "\n\n\u3053\u306e\u8a18\u4e8b\u306f\n\nTensorflow\u3092\u4f7f\u3063\u3066\u5927\u91cf\u306e\u753b\u50cf\u30c7\u30fc\u30bf\u306e\u5b66\u7fd2\u3092\u3057\u3066\u3044\u307e\u3059\n\u53ce\u675f\u307e\u3067\u3068\u306b\u304b\u304f\u6642\u9593\u304c\u304b\u304b\u308b\u306e\u3067\u5b66\u7fd2\u74b0\u5883\u3092\u30a2\u30c3\u30d7\u30b0\u30ec\u30fc\u30c9\u3057\u3066\u304d\u307e\u3057\u305f\n\u5404\u74b0\u5883\u3067Tensorflow\u306e\u51e6\u7406\u901f\u5ea6\u304c\u3069\u306e\u4f4d\u51fa\u305f\u306e\u304b\u304c\u30d9\u30f3\u30c1\u30de\u30fc\u30af\u7684\u306a\u610f\u5473\u5408\u3044\u3092\u6301\u3061\u305d\u3046\u306a\u306e\u3067\u516c\u958b\u3057\u3066\u304a\u304d\u307e\u3059\n\n\nOS\u542b\u3081\u3066\u8af8\u3005\u74b0\u5883\u306e\u30d0\u30fc\u30b8\u30e7\u30f3\u985e\u304c\u7570\u306a\u308b\u306e\u3067\u3042\u304f\u307e\u3067\u53c2\u8003\u3068\u3057\u3066\u307f\u3066\u3044\u305f\u3060\u3051\u308c\u3070\n\n\n\n\n\u5b9f\u884c\u51e6\u7406\u5185\u5bb9\n\nTensorflow\u4e0a\u3067CNN\u306e\u6700\u9ad8\u5cf0\u3001Inception-v3\u3092\u4f7f\u3063\u3066\u30aa\u30ea\u30b8\u30ca\u30eb\u306e\u753b\u50cf\u3067\u30c8\u30ec\u30fc\u30cb\u30f3\u30b0\u3057\u307e\u3059\n\n\n\u679a\u6570\u306f\u6570\u5341\u4e07\u30aa\u30fc\u30c0\uff08\u6027\u80fd\u306b\u306f\u5f71\u97ff\u3057\u306a\u3044\u306f\u305a\uff09\n1000\u30ab\u30c6\u30b4\u30ea\u3078\u306e\u5206\u985e\u5668\n\n\n\u5b9f\u884c\u30b3\u30de\u30f3\u30c9\u306f\u4e0b\u8a18\n\n$ bazel-bin/inception/imagenet_train --num_gpus=[gpu\u6570] --batch_size=32 --train_dir=/share/train/ --data_dir=/share/tfrecord/ --max_steps=1000000\n\n\n\u305d\u306e\uff11\uff1a\u30ed\u30fc\u30ab\u30ebMac\u306eCPU\u3067\u5b66\u7fd2\n\n\u74b0\u5883\n\n\u666e\u901a\u306eiMac\u306eCPU\u3067\u5b9f\u884c\nIntel(R) Core(TM) i5-5575R CPU @ 2.80GHz\n\n\n4\u30b3\u30a2\nGPU\u306fIntel\u88fd\u306a\u306e\u3067\u30c7\u30a3\u30fc\u30d7\u30e9\u30fc\u30cb\u30f3\u30b0\u7528\u9014\u306b\u306f\u4f7f\u3048\u307e\u305b\u3093\n\n\n\u4fa1\u683c\uff1a\u666e\u901a\u306b\u4f7f\u3063\u3066\u308bPC\u306a\u306e\u3067\u3042\u308b\u610f\u5473\u7121\u6599\n\n\n\u5b9f\u884c\u7d50\u679c\n\n1\u30d0\u30c3\u30c1\u3042\u305f\u308a30\u79d2\u524d\u5f8c\n\n2016-09-26 17:56:45.949423: step 30, loss = 13.59 (1.1 examples/sec; 29.730 sec/batch)\n2016-09-26 18:01:42.534258: step 40, loss = 13.25 (1.1 examples/sec; 29.905 sec/batch)\n2016-09-26 18:06:38.385538: step 50, loss = 12.30 (1.1 examples/sec; 29.519 sec/batch)\n2016-09-26 18:11:30.349846: step 60, loss = 12.23 (1.1 examples/sec; 29.360 sec/batch)\n2016-09-26 18:16:23.778464: step 70, loss = 12.23 (1.1 examples/sec; 29.447 sec/batch)\n\n\n\u305d\u306e\uff12\uff1aAWS\u306eg2.2xlarge\n\n\u74b0\u5883\n\nAWS\u306e\u3061\u3087\u3063\u3068\u53e4\u3081\u306eGPU\u7279\u5316\u30a4\u30f3\u30b9\u30bf\u30f3\u30b9\n\n\n\u516c\u5f0f\u60c5\u5831\u306b\u3088\u308b\u30681,536 CUDA \u30b3\u30a2\u3068 4GB \u306e\u30d3\u30c7\u30aa\u30e1\u30e2\u30ea\u3092\u642d\u8f09\u3057\u305f\u9ad8\u30d1\u30d5\u30a9\u30fc\u30de\u30f3\u30b9\u306e NVIDIA GPU\u3068\u306e\u3053\u3068\n\u5b9f\u969b\u306b\u306fTesla GRID K520\u304c\u5165\u3063\u3066\u3044\u308b\n\n\n\u4fa1\u683c\uff1a$0.65/hour => \u670855000\u5186\u304f\u3089\u3044\n\n\n\u5b9f\u884c\u7d50\u679c\n\n1\u30d0\u30c3\u30c1\u3042\u305f\u308a3\u79d2\u7a0b\u5ea6\nCPU\u306e\u7d0410\u500d\n\n2016-09-28 05:42:09.139757: step 30, loss = 14.32 (10.9 examples/sec; 2.940 sec/batch)\n2016-09-28 05:42:38.594894: step 40, loss = 13.47 (10.9 examples/sec; 2.938 sec/batch)\n2016-09-28 05:43:08.045541: step 50, loss = 13.50 (10.8 examples/sec; 2.953 sec/batch)\n2016-09-28 05:43:37.505273: step 60, loss = 12.33 (10.9 examples/sec; 2.948 sec/batch)\n2016-09-28 05:44:07.017434: step 70, loss = 12.46 (10.9 examples/sec; 2.948 sec/batch)\n\n\n\u305d\u306e\uff13\uff1aAWS\u306ep2.xlarge\n\n\u74b0\u5883\n\nAWS\u306e\u4eca\u5e74\u306e\u79cb\u306b\u51fa\u305f\u3070\u304b\u308a\u306eGPU\u7279\u5316\u30a4\u30f3\u30b9\u30bf\u30f3\u30b9\n\n\n\u516c\u5f0f\u306b\u3088\u308b\u3068\u305d\u308c\u305e\u308c 2,496 \u500b\u306e\u4e26\u5217\u51e6\u7406\u30b3\u30a2\u3068 12 GiB \u306e GPU \u30e1\u30e2\u30ea\u304c\u642d\u8f09\u3055\u308c\u305f\u9ad8\u6027\u80fd\u306a NVIDIA K80 GPU\u3068\u306e\u3053\u3068\nTesla K80\u304c\u5165\u3063\u3066\u3044\u308b\n\n\n\u4fa1\u683c\uff1a$0.9/hour => \u670877000\u5186\u304f\u3089\u3044\n\n\n\u5b9f\u884c\u7d50\u679c\n\n1\u30d0\u30c3\u30c1\u3042\u305f\u308a1.5\u79d2\u7a0b\u5ea6\nCPU\u306e\u7d0420\u500d, g2\u30a4\u30f3\u30b9\u30bf\u30f3\u30b9\u306e2\u500d\n\n2016-10-26 03:25:52.783221: step 960, loss = 12.68 (19.9 examples/sec; 1.612 sec/batch)\n2016-10-26 03:26:08.821457: step 970, loss = 12.76 (20.0 examples/sec; 1.599 sec/batch)\n2016-10-26 03:26:24.932045: step 980, loss = 12.82 (21.1 examples/sec; 1.518 sec/batch)\n2016-10-26 03:26:41.364723: step 990, loss = 12.62 (19.8 examples/sec; 1.620 sec/batch)\n\n\n\u305d\u306e\uff14\uff1aTITAN X(Pascal) \u306e\u30b5\u30fc\u30d0\n\n\u74b0\u5883\n\n\u30c7\u30a3\u30fc\u30d7\u30e9\u30fc\u30cb\u30f3\u30b0\u7528\u306b\u69cb\u7bc9\u3057\u305f\u7269\u7406\u30b5\u30fc\u30d0\n\n\nTITAN X (Pascal\u4e16\u4ee3)\n\n\n\u4fa1\u683c\uff1a\u30b5\u30fc\u30d0\u4ee3\u91d1 50\u4e07\u5186\u4f4d\n\n\n\u5b9f\u884c\u7d50\u679c\n\n1\u30d0\u30c3\u30c1\u3042\u305f\u308a0.7\u79d2\u7a0b\u5ea6\nCPU\u306e\u7d0440\u500d, g2\u30a4\u30f3\u30b9\u30bf\u30f3\u30b9\u306e4\u500d, p2\u30a4\u30f3\u30b9\u30bf\u30f3\u30b9\u306e2\u500d\n\n2016-12-16 03:34:36.980520: step 60, loss = 13.75 (41.7 examples/sec; 0.767 sec/batch)\n2016-12-16 03:34:44.441697: step 70, loss = 13.13 (42.3 examples/sec; 0.757 sec/batch)\n2016-12-16 03:34:52.268679: step 80, loss = 13.02 (38.8 examples/sec; 0.824 sec/batch)\n2016-12-16 03:34:59.539936: step 90, loss = 13.12 (48.0 examples/sec; 0.667 sec/batch)\n2016-12-16 03:35:06.701569: step 100, loss = 12.96 (45.8 examples/sec; 0.698 sec/batch)\n\n\n\uff082016/12/23\u8ffd\u8a18)\n\n\n\u3053\u3061\u3089\u306e\u8a18\u4e8b\u3067\u66f8\u3044\u305f\u306e\u3067\u3059\u304c\u3001TitanX\u30ec\u30d9\u30eb\u306e\u7206\u901f\u5b66\u7fd2\u306e\u5834\u5408\u3001\u524d\u51e6\u7406\u306eCPU\u304c\u30dc\u30c8\u30eb\u30cd\u30c3\u30af\u306b\u306a\u3063\u3066\u8a08\u7b97\u6027\u80fd\u3092\u843d\u3068\u3057\u3066\u3057\u307e\u3046\u3053\u3068\u304c\u308f\u304b\u308a\u307e\u3057\u305f\u3002\n\u4e0a\u8a18\u8a18\u4e8b\u3067\u30dc\u30c8\u30eb\u30cd\u30c3\u30af\u3092\u89e3\u6d88\u3057\u305f\u7d50\u679c\u3001TitanX * 1\u57fa\u3067\u3082\u4e0b\u8a18\u306e\u6027\u80fd\u304c\u51fa\u307e\u3057\u305f\u306e\u3067\u5ff5\u306e\u305f\u3081\u3053\u3053\u306b\u3082\u8a18\u8f09\u3057\u3066\u304a\u304d\u307e\u3059\u3002\n\u3053\u308c\u3060\u3068cpu\u306e\u7d0460\u500d\u3067\u3059\u306d\u3002\n\n2016-12-21 12:20:44.338667: step 20, loss = 14.27 (69.2 examples/sec; 0.462 sec/batch)\n2016-12-21 12:20:48.906566: step 30, loss = 14.48 (69.4 examples/sec; 0.461 sec/batch)\n2016-12-21 12:20:53.492054: step 40, loss = 13.77 (69.6 examples/sec; 0.459 sec/batch)\n\n\n\u7d42\u308f\u308a\u306b\n\nTITAN X(Pascal) 1\u679a\u5206\u306e\u6027\u80fd\u304cAWS\u3060\u3068\u67087\uff5e8\u4e07\u5186\n\n\nTITAN\u306f3\uff5e4\u304b\u6708\u4f4d\u4f7f\u3046\u3068\u5143\u304c\u53d6\u308c\u308b\u4f4d\u306e\u8a08\u7b97\u3067\u3059\u304b\u306d\n\n\n\u3061\u306a\u307f\u306b\u4eca\u306e\u753b\u50cf\u91cf\u3060\u3068500000step\u304f\u3089\u3044\u30c8\u30ec\u30fc\u30cb\u30f3\u30b0\u3057\u306a\u3044\u3068\u53ce\u675f\u3057\u307e\u305b\u3093\n\n\nTITAN\u3060\u30684.5\u65e5\u304f\u3089\u3044\u3067\u7d42\u308f\u308a\u307e\u3059\u304c\u3001CPU\u3060\u3068\u534a\u5e74\u304f\u3089\u3044\u639b\u304b\u308b\u8a08\u7b97\u306b\u306a\u308a\u307e\u3059\nNVIDIA\u306f\u4eba\u985e\u306e\u9032\u6b69\u306b\u975e\u5e38\u306b\u8ca2\u732e\u3057\u3066\u307e\u3059\u306d\uff01\n\n\n\n\u3053\u306e\u8a18\u4e8b\u306f\n===\n\n* Tensorflow\u3092\u4f7f\u3063\u3066\u5927\u91cf\u306e\u753b\u50cf\u30c7\u30fc\u30bf\u306e\u5b66\u7fd2\u3092\u3057\u3066\u3044\u307e\u3059\n* \u53ce\u675f\u307e\u3067\u3068\u306b\u304b\u304f\u6642\u9593\u304c\u304b\u304b\u308b\u306e\u3067\u5b66\u7fd2\u74b0\u5883\u3092\u30a2\u30c3\u30d7\u30b0\u30ec\u30fc\u30c9\u3057\u3066\u304d\u307e\u3057\u305f\n* \u5404\u74b0\u5883\u3067Tensorflow\u306e\u51e6\u7406\u901f\u5ea6\u304c\u3069\u306e\u4f4d\u51fa\u305f\u306e\u304b\u304c\u30d9\u30f3\u30c1\u30de\u30fc\u30af\u7684\u306a\u610f\u5473\u5408\u3044\u3092\u6301\u3061\u305d\u3046\u306a\u306e\u3067\u516c\u958b\u3057\u3066\u304a\u304d\u307e\u3059\n  * OS\u542b\u3081\u3066\u8af8\u3005\u74b0\u5883\u306e\u30d0\u30fc\u30b8\u30e7\u30f3\u985e\u304c\u7570\u306a\u308b\u306e\u3067\u3042\u304f\u307e\u3067\u53c2\u8003\u3068\u3057\u3066\u307f\u3066\u3044\u305f\u3060\u3051\u308c\u3070\n\n\u5b9f\u884c\u51e6\u7406\u5185\u5bb9\n===\n\n* Tensorflow\u4e0a\u3067CNN\u306e\u6700\u9ad8\u5cf0\u3001[Inception-v3](https://github.com/tensorflow/models/tree/master/inception)\u3092\u4f7f\u3063\u3066\u30aa\u30ea\u30b8\u30ca\u30eb\u306e\u753b\u50cf\u3067\u30c8\u30ec\u30fc\u30cb\u30f3\u30b0\u3057\u307e\u3059\n  * \u679a\u6570\u306f\u6570\u5341\u4e07\u30aa\u30fc\u30c0\uff08\u6027\u80fd\u306b\u306f\u5f71\u97ff\u3057\u306a\u3044\u306f\u305a\uff09\n  * 1000\u30ab\u30c6\u30b4\u30ea\u3078\u306e\u5206\u985e\u5668\n* \u5b9f\u884c\u30b3\u30de\u30f3\u30c9\u306f\u4e0b\u8a18\n\n```\n$ bazel-bin/inception/imagenet_train --num_gpus=[gpu\u6570] --batch_size=32 --train_dir=/share/train/ --data_dir=/share/tfrecord/ --max_steps=1000000\n```\n\n\u305d\u306e\uff11\uff1a\u30ed\u30fc\u30ab\u30ebMac\u306eCPU\u3067\u5b66\u7fd2\n===\n\n\u74b0\u5883\n---\n\n* \u666e\u901a\u306eiMac\u306eCPU\u3067\u5b9f\u884c\n* Intel(R) Core(TM) i5-5575R CPU @ 2.80GHz\n  * 4\u30b3\u30a2\n  * GPU\u306fIntel\u88fd\u306a\u306e\u3067\u30c7\u30a3\u30fc\u30d7\u30e9\u30fc\u30cb\u30f3\u30b0\u7528\u9014\u306b\u306f\u4f7f\u3048\u307e\u305b\u3093\n* \u4fa1\u683c\uff1a\u666e\u901a\u306b\u4f7f\u3063\u3066\u308bPC\u306a\u306e\u3067\u3042\u308b\u610f\u5473\u7121\u6599\n\n\u5b9f\u884c\u7d50\u679c\n---\n\n* 1\u30d0\u30c3\u30c1\u3042\u305f\u308a30\u79d2\u524d\u5f8c\n\n```\n2016-09-26 17:56:45.949423: step 30, loss = 13.59 (1.1 examples/sec; 29.730 sec/batch)\n2016-09-26 18:01:42.534258: step 40, loss = 13.25 (1.1 examples/sec; 29.905 sec/batch)\n2016-09-26 18:06:38.385538: step 50, loss = 12.30 (1.1 examples/sec; 29.519 sec/batch)\n2016-09-26 18:11:30.349846: step 60, loss = 12.23 (1.1 examples/sec; 29.360 sec/batch)\n2016-09-26 18:16:23.778464: step 70, loss = 12.23 (1.1 examples/sec; 29.447 sec/batch)\n```\n\n\u305d\u306e\uff12\uff1aAWS\u306eg2.2xlarge\n===\n\n\u74b0\u5883\n---\n\n* AWS\u306e\u3061\u3087\u3063\u3068\u53e4\u3081\u306eGPU\u7279\u5316\u30a4\u30f3\u30b9\u30bf\u30f3\u30b9\n  * \u516c\u5f0f\u60c5\u5831\u306b\u3088\u308b\u3068```1,536 CUDA \u30b3\u30a2\u3068 4GB \u306e\u30d3\u30c7\u30aa\u30e1\u30e2\u30ea\u3092\u642d\u8f09\u3057\u305f\u9ad8\u30d1\u30d5\u30a9\u30fc\u30de\u30f3\u30b9\u306e NVIDIA GPU```\u3068\u306e\u3053\u3068\n  * \u5b9f\u969b\u306b\u306fTesla GRID K520\u304c\u5165\u3063\u3066\u3044\u308b\n* \u4fa1\u683c\uff1a$0.65/hour => \u670855000\u5186\u304f\u3089\u3044\n\n\u5b9f\u884c\u7d50\u679c\n---\n\n* 1\u30d0\u30c3\u30c1\u3042\u305f\u308a3\u79d2\u7a0b\u5ea6\n* CPU\u306e\u7d0410\u500d\n\n```\n2016-09-28 05:42:09.139757: step 30, loss = 14.32 (10.9 examples/sec; 2.940 sec/batch)\n2016-09-28 05:42:38.594894: step 40, loss = 13.47 (10.9 examples/sec; 2.938 sec/batch)\n2016-09-28 05:43:08.045541: step 50, loss = 13.50 (10.8 examples/sec; 2.953 sec/batch)\n2016-09-28 05:43:37.505273: step 60, loss = 12.33 (10.9 examples/sec; 2.948 sec/batch)\n2016-09-28 05:44:07.017434: step 70, loss = 12.46 (10.9 examples/sec; 2.948 sec/batch)\n```\n\n\u305d\u306e\uff13\uff1aAWS\u306ep2.xlarge\n===\n\n\u74b0\u5883\n---\n\n* AWS\u306e\u4eca\u5e74\u306e\u79cb\u306b\u51fa\u305f\u3070\u304b\u308a\u306eGPU\u7279\u5316\u30a4\u30f3\u30b9\u30bf\u30f3\u30b9\n  * \u516c\u5f0f\u306b\u3088\u308b\u3068```\u305d\u308c\u305e\u308c 2,496 \u500b\u306e\u4e26\u5217\u51e6\u7406\u30b3\u30a2\u3068 12 GiB \u306e GPU \u30e1\u30e2\u30ea\u304c\u642d\u8f09\u3055\u308c\u305f\u9ad8\u6027\u80fd\u306a NVIDIA K80 GPU```\u3068\u306e\u3053\u3068\n  * Tesla K80\u304c\u5165\u3063\u3066\u3044\u308b\n* \u4fa1\u683c\uff1a$0.9/hour => \u670877000\u5186\u304f\u3089\u3044\n\n\u5b9f\u884c\u7d50\u679c\n---\n\n* 1\u30d0\u30c3\u30c1\u3042\u305f\u308a1.5\u79d2\u7a0b\u5ea6\n* CPU\u306e\u7d0420\u500d, g2\u30a4\u30f3\u30b9\u30bf\u30f3\u30b9\u306e2\u500d\n\n```\n2016-10-26 03:25:52.783221: step 960, loss = 12.68 (19.9 examples/sec; 1.612 sec/batch)\n2016-10-26 03:26:08.821457: step 970, loss = 12.76 (20.0 examples/sec; 1.599 sec/batch)\n2016-10-26 03:26:24.932045: step 980, loss = 12.82 (21.1 examples/sec; 1.518 sec/batch)\n2016-10-26 03:26:41.364723: step 990, loss = 12.62 (19.8 examples/sec; 1.620 sec/batch)\n```\n\n\n\u305d\u306e\uff14\uff1aTITAN X(Pascal) \u306e\u30b5\u30fc\u30d0\n===\n\n\u74b0\u5883\n---\n\n* \u30c7\u30a3\u30fc\u30d7\u30e9\u30fc\u30cb\u30f3\u30b0\u7528\u306b\u69cb\u7bc9\u3057\u305f\u7269\u7406\u30b5\u30fc\u30d0\n  * TITAN X (Pascal\u4e16\u4ee3)\n* \u4fa1\u683c\uff1a\u30b5\u30fc\u30d0\u4ee3\u91d1 50\u4e07\u5186\u4f4d\n\n\u5b9f\u884c\u7d50\u679c\n---\n\n* 1\u30d0\u30c3\u30c1\u3042\u305f\u308a0.7\u79d2\u7a0b\u5ea6\n* CPU\u306e\u7d0440\u500d, g2\u30a4\u30f3\u30b9\u30bf\u30f3\u30b9\u306e4\u500d, p2\u30a4\u30f3\u30b9\u30bf\u30f3\u30b9\u306e2\u500d\n\n```\n2016-12-16 03:34:36.980520: step 60, loss = 13.75 (41.7 examples/sec; 0.767 sec/batch)\n2016-12-16 03:34:44.441697: step 70, loss = 13.13 (42.3 examples/sec; 0.757 sec/batch)\n2016-12-16 03:34:52.268679: step 80, loss = 13.02 (38.8 examples/sec; 0.824 sec/batch)\n2016-12-16 03:34:59.539936: step 90, loss = 13.12 (48.0 examples/sec; 0.667 sec/batch)\n2016-12-16 03:35:06.701569: step 100, loss = 12.96 (45.8 examples/sec; 0.698 sec/batch)\n```\n\n\uff082016/12/23\u8ffd\u8a18)\n---\n\n* [\u3053\u3061\u3089](http://qiita.com/shouta-dev/items/a12b0ca3838ebe6e176f)\u306e\u8a18\u4e8b\u3067\u66f8\u3044\u305f\u306e\u3067\u3059\u304c\u3001TitanX\u30ec\u30d9\u30eb\u306e\u7206\u901f\u5b66\u7fd2\u306e\u5834\u5408\u3001\u524d\u51e6\u7406\u306eCPU\u304c\u30dc\u30c8\u30eb\u30cd\u30c3\u30af\u306b\u306a\u3063\u3066\u8a08\u7b97\u6027\u80fd\u3092\u843d\u3068\u3057\u3066\u3057\u307e\u3046\u3053\u3068\u304c\u308f\u304b\u308a\u307e\u3057\u305f\u3002\n* \u4e0a\u8a18\u8a18\u4e8b\u3067\u30dc\u30c8\u30eb\u30cd\u30c3\u30af\u3092\u89e3\u6d88\u3057\u305f\u7d50\u679c\u3001TitanX * 1\u57fa\u3067\u3082\u4e0b\u8a18\u306e\u6027\u80fd\u304c\u51fa\u307e\u3057\u305f\u306e\u3067\u5ff5\u306e\u305f\u3081\u3053\u3053\u306b\u3082\u8a18\u8f09\u3057\u3066\u304a\u304d\u307e\u3059\u3002\n* \u3053\u308c\u3060\u3068cpu\u306e\u7d0460\u500d\u3067\u3059\u306d\u3002\n\n```\n2016-12-21 12:20:44.338667: step 20, loss = 14.27 (69.2 examples/sec; 0.462 sec/batch)\n2016-12-21 12:20:48.906566: step 30, loss = 14.48 (69.4 examples/sec; 0.461 sec/batch)\n2016-12-21 12:20:53.492054: step 40, loss = 13.77 (69.6 examples/sec; 0.459 sec/batch)\n```\n\n\u7d42\u308f\u308a\u306b\n===\n\n* TITAN X(Pascal) 1\u679a\u5206\u306e\u6027\u80fd\u304cAWS\u3060\u3068\u67087\uff5e8\u4e07\u5186\n  * TITAN\u306f3\uff5e4\u304b\u6708\u4f4d\u4f7f\u3046\u3068\u5143\u304c\u53d6\u308c\u308b\u4f4d\u306e\u8a08\u7b97\u3067\u3059\u304b\u306d\n* \u3061\u306a\u307f\u306b\u4eca\u306e\u753b\u50cf\u91cf\u3060\u3068500000step\u304f\u3089\u3044\u30c8\u30ec\u30fc\u30cb\u30f3\u30b0\u3057\u306a\u3044\u3068\u53ce\u675f\u3057\u307e\u305b\u3093\n  * TITAN\u3060\u30684.5\u65e5\u304f\u3089\u3044\u3067\u7d42\u308f\u308a\u307e\u3059\u304c\u3001CPU\u3060\u3068\u534a\u5e74\u304f\u3089\u3044\u639b\u304b\u308b\u8a08\u7b97\u306b\u306a\u308a\u307e\u3059\n  * NVIDIA\u306f\u4eba\u985e\u306e\u9032\u6b69\u306b\u975e\u5e38\u306b\u8ca2\u732e\u3057\u3066\u307e\u3059\u306d\uff01\n"}