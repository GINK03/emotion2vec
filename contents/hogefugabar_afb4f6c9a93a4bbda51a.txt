{"tags": ["Keras", "Python", "\u6df1\u5c64\u5b66\u7fd2", "DeepLearning"], "context": "\n\n\u306f\u3058\u3081\u306b\n\u3060\u3044\u305f\u30441\u5e74\u304f\u3089\u3044\u524d\u306bChainer\u3067\u66f8\u3044\u305f\u30a2\u30cb\u30e1\u9854\u3092\u5206\u985e\u3059\u308b\u30d7\u30ed\u30b0\u30e9\u30e0\u3067\u3059\u304c\uff0c\u4eca\u56de\u306fKeras\u3067\u66f8\u304d\u307e\u3057\u305f\uff0e\u30d7\u30ed\u30b0\u30e9\u30e0\u306fGitHub\u306b\u3042\u3052\u307e\u3057\u305f\uff0e\n\n\u30c7\u30fc\u30bf\u30bb\u30c3\u30c8\n\u30c7\u30fc\u30bf\u30bb\u30c3\u30c8\u306fanimeface-character-dataset\u304b\u3089\u5165\u624b\u3059\u308b\u3053\u3068\u304c\u3067\u304d\u307e\u3059\uff0e\n\u53c2\u8003:DenoisingAutoEncoder\u3067\u30a2\u30cb\u30e1\u9854\u306e\u7279\u5fb4\u3092\u62bd\u51fa\u3057\u3066\u307f\u305f\n\n\u30c7\u30fc\u30bf\u30bb\u30c3\u30c8\u524d\u51e6\u7406\n\u524d\u3088\u308a\u5c11\u3057\u3060\u3051\u6539\u826f\u3057\u307e\u3057\u305f\uff0e32\u00d732\u306eRGB\u306e\u30c7\u30fc\u30bf(shape=(3, 32, 32))\u306b\u30ea\u30b5\u30a4\u30ba\u3057\u307e\u3059\uff0e\u524d\u56de\u3068\u9055\u3046\u306e\u306f\uff0c\u30c7\u30fc\u30bf\u306e\u5165\u3063\u3066\u3044\u306a\u3044\u7a7a\u306e\u30d5\u30a9\u30eb\u30c0\u3092\u524a\u9664\u3057\u306a\u304f\u3066\u3082\u591a\u5206\u3061\u3083\u3093\u3068\u52d5\u304f\u3068\u3053\u308d\u3067\u3059\uff0e\nRequirements\u306f\n\nsix\nnumpy\nopencv\nprogressbar2\n\n\u3068\u306a\u3063\u3066\u3044\u307e\u3059\uff0e\n#! -*- coding: utf-8 -*-\n\nimport os\nimport six.moves.cPickle as pickle\nimport numpy as np\ntry:\n    import cv2 as cv\nexcept:\n    pass\nfrom progressbar import ProgressBar\n\nclass AnimeFaceDataset:\n    def __init__(self):\n        self.data_dir_path = u\"./animeface-character-dataset/thumb/\"\n        self.data = None\n        self.target = None\n        self.n_types_target = -1\n        self.dump_name = u'animedata'\n        self.image_size = 32\n\n    def get_dir_list(self):\n        tmp = os.listdir(self.data_dir_path)\n        if tmp is None:\n            return None\n        ret = []\n        for x in tmp:\n            if os.path.isdir(self.data_dir_path+x):\n                if len(os.listdir(self.data_dir_path+x)) >= 2:\n                    ret.append(x)\n        return sorted(ret)\n\n    def get_class_id(self, fname):\n        dir_list = self.get_dir_list()\n        dir_name = filter(lambda x: x in fname, dir_list)\n        return dir_list.index(dir_name[0])\n\n    def get_class_name(self, id):\n        dir_list = self.get_dir_list()\n        return dir_list[id]\n\n    def load_data_target(self):\n        if os.path.exists(self.dump_name+\".pkl\"):\n            print \"load from pickle\"\n            self.load_dataset()\n            print \"done\"\n        else:\n            dir_list = self.get_dir_list()\n            ret = {}\n            self.target = []\n            self.data = []\n            print(\"now loading...\")\n            pb = ProgressBar(min_value=0, max_value=len(dir_list)).start()\n            for i, dir_name in enumerate(dir_list):\n                pb.update(i)\n                file_list = os.listdir(self.data_dir_path+dir_name)\n                for file_name in file_list:\n                    root, ext = os.path.splitext(file_name)\n                    if ext == u'.png':\n                        abs_name = self.data_dir_path+dir_name+'/'+file_name\n                        # read class id i.e., target\n                        class_id = self.get_class_id(abs_name)\n                        self.target.append(class_id)\n                        # read image i.e., data\n                        image = cv.imread(abs_name)\n                        image = cv.resize(image, (self.image_size, self.image_size))\n                        image = image.transpose(2,0,1)\n                        image = image/255.\n                        self.data.append(image)\n            pb.finish()\n            print(\"done.\")\n            self.data = np.array(self.data, np.float32)\n            self.target = np.array(self.target, np.int32)\n\n            self.dump_dataset()\n\n    def dump_dataset(self):\n        pickle.dump((self.data,self.target), open(self.dump_name+\".pkl\", 'wb'), -1)\n\n    def load_dataset(self):\n        self.data, self.target = pickle.load(open(self.dump_name+\".pkl\", 'rb'))\n\n\nif __name__ == '__main__':\n    dataset = AnimeFaceDataset()\n    dataset.load_data_target()\n\n\u5b9f\u969b\u306b\u8aad\u307f\u8fbc\u3093\u3067\u307f\u308b\u3068\nIn [1]: from animeface import AnimeFaceDataset\n\nIn [2]: dataset = AnimeFaceDataset()\n\nIn [3]: dataset.load_data_target()\nload from pickle\ndone\n\nIn [4]: x = dataset.data\n\nIn [5]: y = dataset.target\n\nIn [6]: print x.shape, y.shape\n(14490, 3, 32, 32) (14490,)\n\n\u3068\u306a\u308a\uff0c\u30c7\u30fc\u30bf\u657014490\uff0c\u30af\u30e9\u30b9\u6570(\u30ad\u30e3\u30e9\u30af\u30bf\u30fc\u6570)176\u306e\u5206\u985e\u554f\u984c\u3068\u306a\u308a\u307e\u3059\uff0e(\u3053\u3053\u307e\u3067\u306f\u307b\u3068\u3093\u3069\u524d\u56de\u3068\u540c\u3058\u3067\u3059\uff0e)\n\nKeras\u306b\u3088\u308bConvolutional Neural Networks\u306e\u5b9f\u88c5\n\n\u30e2\u30c7\u30eb\u306e\u69cb\u7bc9\nfrom keras.layers.convolutional import Convolution2D\nfrom keras.layers.convolutional import MaxPooling2D\nfrom keras.layers.core import Activation\nfrom keras.layers.core import Dense\nfrom keras.layers.core import Dropout\nfrom keras.layers.core import Flatten\nfrom keras.models import Sequential\n\ndef build_deep_cnn(num_classes=3):\n    model = Sequential()\n\n    model.add(Convolution2D(96, 3, 3, border_mode='same', input_shape=(3, 32, 32)))\n    model.add(Activation('relu'))\n\n    model.add(Convolution2D(128, 3, 3))\n    model.add(Activation('relu'))\n    model.add(MaxPooling2D(pool_size=(2, 2)))\n    model.add(Dropout(0.5))\n\n    model.add(Convolution2D(256, 3, 3, border_mode='same'))\n    model.add(Activation('relu'))\n\n    model.add(Convolution2D(256, 3, 3))\n    model.add(Activation('relu'))\n    model.add(MaxPooling2D(pool_size=(2, 2)))\n    model.add(Dropout(0.5))\n\n    model.add(Flatten())\n    model.add(Dense(1024))\n    model.add(Activation('relu'))\n    model.add(Dropout(0.5))\n\n    model.add(Dense(num_classes))\n    model.add(Activation('softmax'))\n\n    return model\n\n\u6700\u521d\u306bmodel = Sequential()\u3067\u30b7\u30fc\u30b1\u30f3\u30b7\u30e3\u30eb\u30e2\u30c7\u30eb\u3092\u751f\u6210\u3057\u3066\uff0c\u305d\u308c\u306bConvolutional2D\u3084Dense\u3092\u8ffd\u52a0\u3057\u3066\u3044\u304f\u3060\u3051\u3067\u30cd\u30c3\u30c8\u30ef\u30fc\u30af\u3092\u69cb\u7bc9\u3067\u304d\u307e\u3059\uff0e\nConvolutional2D\u304c\u7573\u307f\u8fbc\u307f\u5c64\uff0cDense\u304c\u5168\u7d50\u5408\u5c64\u306b\u76f8\u5f53\u3059\u308b\u611f\u3058\u3067\u3059\uff0e\n\u4e00\u756a\u6700\u521d\u306e\uff0c\nConvolution2D(96, 3, 3, border_mode='same', input_shape=(3, 32, 32))\n\n\u3060\u3051\u306finput_shape\u3092\u6307\u5b9a\u3059\u308b\u5fc5\u8981\u304c\u3042\u308a\u307e\u3059\uff0e\nConvolutional2D\u306b\u3064\u3044\u3066\u7c21\u5358\u306b\u8aac\u660e\u3059\u308b\u3068\uff0c\u6700\u521d\u306e\u5f15\u6570\u304c\uff0c\u7573\u307f\u8fbc\u307f\u30ab\u30fc\u30cd\u30eb\u306e\u679a\u6570\uff0c\u7b2c2\uff0c3\u5f15\u6570\u304c\u7573\u307f\u8fbc\u307f\u30ab\u30fc\u30cd\u30eb\u5927\u304d\u3055\u3092\u6307\u5b9a\u3059\u308b\u3082\u306e\u3067\u3059\uff0eborder_mode\u306b\u306fsame\u3068valid\u306e2\u7a2e\u985e\u304c\u3042\u308a\u307e\u3059\u304c\uff0csame\u306fpadding\u304c\u30ab\u30fc\u30cd\u30eb\u306e\u5927\u304d\u3055\u306e\u534a\u5206\uff0c\u3064\u307e\u308a\u51fa\u529b\u306e\u7e26\u6a2a\u306e\u5927\u304d\u3055\u306f\u5165\u529b\u306e\u7e26\u6a2a\u306e\u5927\u304d\u3055\u306f\u5909\u308f\u308a\u307e\u305b\u3093\uff0evalid\u306fpadding\u304c\u306a\u3044\u72b6\u614b\uff0c\u3064\u307e\u308a\u51fa\u529b\u306e\u7e26\u6a2a\u306e\u5927\u304d\u3055\u306f\u5165\u529b\u306e\u7e26\u6a2a\u306e\u5927\u304d\u3055\u3088\u308a\u3082\u5c0f\u3055\u304f\u306a\u308a\u307e\u3059\uff0epadding\u306b\u3064\u3044\u306f\u3053\u3061\u3089\u304c\u308f\u304b\u308a\u3084\u3059\u3044\u3067\u3059\uff0e\u4eca\u56de\u306fsame\u3067\u7573\u307f\u8fbc\u307f\u30ab\u30fc\u30cd\u30eb\u306eshape\u304c(96, 3, 3)\uff0c\u5165\u529b\u306eshape\u304c(3, 32, 32)\u306e\u305f\u3081\u3053\u306e\u5c64\u306e\u51fa\u529b\u306eshape\u306f(96, 32, 32)\u3068\u306a\u308a\u307e\u3059\uff0evalid\u306e\u5834\u5408\u306e\u51fa\u529b\u306eshape\u306f(96, 32-(3-1), 32-(3-1))=(96, 30, 30)\u3068\u306a\u308a\u307e\u3059\uff0e\u305d\u306e\u4ed6\u306bstride\u306a\u3069\u3082\u8a2d\u5b9a\u3059\u308b\u3053\u3068\u304c\u3067\u304d\u307e\u3059\uff0e\n\n\u30e2\u30c7\u30eb\u306e\u5b66\u7fd2\nfrom keras.callbacks import EarlyStopping\nfrom keras.callbacks import LearningRateScheduler\nfrom keras.optimizers import Adam\nfrom keras.optimizers import SGD\nfrom animeface import AnimeFaceDataset\n\nclass Schedule(object):\n    def __init__(self, init=0.01):\n        self.init = init\n    def __call__(self, epoch):\n        lr = self.init\n        for i in xrange(1, epoch+1):\n            if i%5==0:\n                lr *= 0.5\n        return lr\n\ndef get_schedule_func(init):\n    return Schedule(init)\n\ndataset = AnimeFaceDataset()\ndataset.load_data_target()\nx = dataset.data\ny = dataset.target\nn_class = len(set(y))\nperm = np.random.permutation(len(y))\nx = x[perm]\ny = y[perm]\n\nmodel = build_deep_cnn(n_class)\nmodel.summary()\ninit_learning_rate = 1e-2\nopt = SGD(lr=init_learning_rate, decay=0.0, momentum=0.9, nesterov=False)\nmodel.compile(loss='sparse_categorical_crossentropy', optimizer=opt, metrics=[\"acc\"])\nearly_stopping = EarlyStopping(monitor='val_loss', patience=3, verbose=0, mode='auto')\nlrs = LearningRateScheduler(get_schedule_func(init_learning_rate))\n\nhist = model.fit(x, y, \n                batch_size=128, \n                nb_epoch=50, \n                validation_split=0.1, \n                verbose=1, \n                callbacks=[early_stopping, lrs])\n\n\u5b66\u7fd2\u3059\u308bfit\u95a2\u6570\u306e\u5f15\u6570\u306ecallbacks\u306b\u306f\uff0c\u53ce\u675f\u5224\u5b9a\u3057\u305f\u3089\u81ea\u52d5\u7684\u306b\u5b66\u7fd2\u3092\u7d42\u4e86\u3059\u308bEarlyStopping\u3084\uff0cepoch\u6bce\u306b\u5b66\u7fd2\u7387\u3092\u8abf\u6574\u3059\u308b\u3053\u3068\u304c\u3067\u304d\u308bLearningRateScheduler\u306a\u3069\u3092\u6307\u5b9a\u3059\u308b\u3053\u3068\u304c\u3067\u304d\uff0c\u4fbf\u5229\u3067\u3059\uff0e  \n\u7c21\u5358\u306bLearningRateScheduler\u306b\u3064\u3044\u3066\u8aac\u660e\u3059\u308b\u3068\uff0c\u300c\u5f15\u6570\u306b\u73fe\u5728\u306eepoch\u6570\u3092(0\u306f\u3058\u307e\u308a)\u3092\u4e0e\u3048\u305f\u6642\u306b\u5b66\u7fd2\u7387\u3092\u8fd4\u3057\u3066\u304f\u308c\u308b\u95a2\u6570\u300d\u3092\u5f15\u6570\u306b\u53d6\u308a\u307e\u3059\uff0e\u4f8b\u3048\u3070\uff0c\nclass Schedule(object):\n    def __init__(self, init=0.01):\n        self.init = init\n    def __call__(self, epoch):\n        lr = self.init\n        for i in xrange(1, epoch+1):\n            if i%5==0:\n                lr *= 0.5\n        return lr\n\ndef get_schedule_func(init):\n    return Schedule(init)\n\nlrs = LearningRateScheduler(get_schedule_fun(0.01))\n\n\u306e\u3088\u3046\u306b\u3084\u308b\u3068\uff0c\u521d\u671f\u5b66\u7fd2\u73870.01\u30675epoch\u6bce\u306b\u5b66\u7fd2\u7387\u304c\u534a\u6e1b\u3059\u308b\uff0c\u3068\u3044\u3063\u305f\u611f\u3058\u306b\u306a\u308a\u307e\u3059\uff0e  \n\u307e\u305f\uff0cfit\u306e\u8fd4\u308a\u5024\u306e\u30aa\u30d6\u30b8\u30a7\u30af\u30c8\u306e.history\u306b\u306f\u8f9e\u66f8\u578b\u3067\u5404epoch\u6bce\u306e\u8aa4\u5dee\u95a2\u6570\u7b49\u3092\u4fdd\u5b58\u3057\u3066\u304f\u308c\u307e\u3059\uff0ePandas\u3068Matplotlib\u3092\u4f7f\u3046\u3068\u4fbf\u5229\u306b\u53ef\u8996\u5316\u3059\u308b\u3053\u3068\u304c\u3067\u304d\u307e\u3059\uff0e\nimport pandas as pd\nimport matplotlib.pyplot as plt\nplt.style.use(\"ggplot\")\n\ndf = pd.DataFrame(hist.history)\ndf.index += 1\ndf.index.name = \"epoch\"\ndf[[\"acc\", \"val_acc\"]].plot(linewidth=2)\nplt.savefig(\"acc_history.pdf\")\ndf[[\"loss\", \"val_loss\"]].plot(linewidth=2)\nplt.savefig(\"loss_history.pdf\")\n\n\n\u5b9f\u9a13\u7d50\u679c\n\u7d50\u679c\u306f\u4ee5\u4e0b\u306e\u901a\u308a\u3068\u306a\u308a\uff0c\u691c\u8a3c\u7528\u306e\u6b63\u89e3\u7387\u306f\u7d046\u5272\u5f31\u3068\u306a\u308a\u307e\u3057\u305f\uff0e\n\u5b9f\u306f\u6700\u9069\u5316\u624b\u6cd5\u306bAdam\u3092\u4f7f\u3046\u3068\u691c\u8a3c\u7528\u306e\u6b63\u89e3\u7387\u306f7\u5272\u3092\u8d85\u3048\u308b\u306e\u3067\u3084\u3063\u3066\u307f\u3066\u304f\u3060\u3055\u3044\uff0e\n\n\u8aa4\u5dee\u95a2\u6570\u306e\u63a8\u79fb\n\n\n\u6b63\u89e3\u7387\u306e\u63a8\u79fb\n\n# \u306f\u3058\u3081\u306b\n\u3060\u3044\u305f\u30441\u5e74\u304f\u3089\u3044\u524d\u306b[Chainer\u3067\u66f8\u3044\u305f](http://qiita.com/hogefugabar/items/312707a09d29632e7288)\u30a2\u30cb\u30e1\u9854\u3092\u5206\u985e\u3059\u308b\u30d7\u30ed\u30b0\u30e9\u30e0\u3067\u3059\u304c\uff0c\u4eca\u56de\u306fKeras\u3067\u66f8\u304d\u307e\u3057\u305f\uff0e\u30d7\u30ed\u30b0\u30e9\u30e0\u306f[GitHub](https://github.com/hogefugabar/cnn-animeface-keras)\u306b\u3042\u3052\u307e\u3057\u305f\uff0e\n\n# \u30c7\u30fc\u30bf\u30bb\u30c3\u30c8\n\u30c7\u30fc\u30bf\u30bb\u30c3\u30c8\u306f[animeface-character-dataset](http://www.nurs.or.jp/%7Enagadomi/animeface-character-dataset/)\u304b\u3089\u5165\u624b\u3059\u308b\u3053\u3068\u304c\u3067\u304d\u307e\u3059\uff0e\n[\u53c2\u8003:DenoisingAutoEncoder\u3067\u30a2\u30cb\u30e1\u9854\u306e\u7279\u5fb4\u3092\u62bd\u51fa\u3057\u3066\u307f\u305f](http://nonbiri-tereka.hatenablog.com/entry/2015/06/30/222616)\n\n## \u30c7\u30fc\u30bf\u30bb\u30c3\u30c8\u524d\u51e6\u7406\n\u524d\u3088\u308a\u5c11\u3057\u3060\u3051\u6539\u826f\u3057\u307e\u3057\u305f\uff0e32\u00d732\u306eRGB\u306e\u30c7\u30fc\u30bf(shape=(3, 32, 32))\u306b\u30ea\u30b5\u30a4\u30ba\u3057\u307e\u3059\uff0e\u524d\u56de\u3068\u9055\u3046\u306e\u306f\uff0c\u30c7\u30fc\u30bf\u306e\u5165\u3063\u3066\u3044\u306a\u3044\u7a7a\u306e\u30d5\u30a9\u30eb\u30c0\u3092\u524a\u9664\u3057\u306a\u304f\u3066\u3082\u591a\u5206\u3061\u3083\u3093\u3068\u52d5\u304f\u3068\u3053\u308d\u3067\u3059\uff0e\nRequirements\u306f\n\n- six\n- numpy\n- opencv\n- progressbar2\n\n\u3068\u306a\u3063\u3066\u3044\u307e\u3059\uff0e\n\n\n```py\n#! -*- coding: utf-8 -*-\n\nimport os\nimport six.moves.cPickle as pickle\nimport numpy as np\ntry:\n\timport cv2 as cv\nexcept:\n\tpass\nfrom progressbar import ProgressBar\n\nclass AnimeFaceDataset:\n\tdef __init__(self):\n\t\tself.data_dir_path = u\"./animeface-character-dataset/thumb/\"\n\t\tself.data = None\n\t\tself.target = None\n\t\tself.n_types_target = -1\n\t\tself.dump_name = u'animedata'\n\t\tself.image_size = 32\n\n\tdef get_dir_list(self):\n\t\ttmp = os.listdir(self.data_dir_path)\n\t\tif tmp is None:\n\t\t\treturn None\n\t\tret = []\n\t\tfor x in tmp:\n\t\t\tif os.path.isdir(self.data_dir_path+x):\n\t\t\t\tif len(os.listdir(self.data_dir_path+x)) >= 2:\n\t\t\t\t\tret.append(x)\n\t\treturn sorted(ret)\n\n\tdef get_class_id(self, fname):\n\t\tdir_list = self.get_dir_list()\n\t\tdir_name = filter(lambda x: x in fname, dir_list)\n\t\treturn dir_list.index(dir_name[0])\n\n\tdef get_class_name(self, id):\n\t\tdir_list = self.get_dir_list()\n\t\treturn dir_list[id]\n\n\tdef load_data_target(self):\n\t\tif os.path.exists(self.dump_name+\".pkl\"):\n\t\t\tprint \"load from pickle\"\n\t\t\tself.load_dataset()\n\t\t\tprint \"done\"\n\t\telse:\n\t\t\tdir_list = self.get_dir_list()\n\t\t\tret = {}\n\t\t\tself.target = []\n\t\t\tself.data = []\n\t\t\tprint(\"now loading...\")\n\t\t\tpb = ProgressBar(min_value=0, max_value=len(dir_list)).start()\n\t\t\tfor i, dir_name in enumerate(dir_list):\n\t\t\t\tpb.update(i)\n\t\t\t\tfile_list = os.listdir(self.data_dir_path+dir_name)\n\t\t\t\tfor file_name in file_list:\n\t\t\t\t\troot, ext = os.path.splitext(file_name)\n\t\t\t\t\tif ext == u'.png':\n\t\t\t\t\t\tabs_name = self.data_dir_path+dir_name+'/'+file_name\n\t\t\t\t\t\t# read class id i.e., target\n\t\t\t\t\t\tclass_id = self.get_class_id(abs_name)\n\t\t\t\t\t\tself.target.append(class_id)\n\t\t\t\t\t\t# read image i.e., data\n\t\t\t\t\t\timage = cv.imread(abs_name)\n\t\t\t\t\t\timage = cv.resize(image, (self.image_size, self.image_size))\n\t\t\t\t\t\timage = image.transpose(2,0,1)\n\t\t\t\t\t\timage = image/255.\n\t\t\t\t\t\tself.data.append(image)\n\t\t\tpb.finish()\n\t\t\tprint(\"done.\")\n\t\t\tself.data = np.array(self.data, np.float32)\n\t\t\tself.target = np.array(self.target, np.int32)\n\n\t\t\tself.dump_dataset()\n\n\tdef dump_dataset(self):\n\t\tpickle.dump((self.data,self.target), open(self.dump_name+\".pkl\", 'wb'), -1)\n\n\tdef load_dataset(self):\n\t\tself.data, self.target = pickle.load(open(self.dump_name+\".pkl\", 'rb'))\n\n\nif __name__ == '__main__':\n\tdataset = AnimeFaceDataset()\n\tdataset.load_data_target()\n```\n\n\u5b9f\u969b\u306b\u8aad\u307f\u8fbc\u3093\u3067\u307f\u308b\u3068\n\n```py\nIn [1]: from animeface import AnimeFaceDataset\n\nIn [2]: dataset = AnimeFaceDataset()\n\nIn [3]: dataset.load_data_target()\nload from pickle\ndone\n\nIn [4]: x = dataset.data\n\nIn [5]: y = dataset.target\n\nIn [6]: print x.shape, y.shape\n(14490, 3, 32, 32) (14490,)\n```\n\n\u3068\u306a\u308a\uff0c\u30c7\u30fc\u30bf\u657014490\uff0c\u30af\u30e9\u30b9\u6570(\u30ad\u30e3\u30e9\u30af\u30bf\u30fc\u6570)176\u306e\u5206\u985e\u554f\u984c\u3068\u306a\u308a\u307e\u3059\uff0e(\u3053\u3053\u307e\u3067\u306f\u307b\u3068\u3093\u3069\u524d\u56de\u3068\u540c\u3058\u3067\u3059\uff0e)\n\n\n# Keras\u306b\u3088\u308bConvolutional Neural Networks\u306e\u5b9f\u88c5\n## \u30e2\u30c7\u30eb\u306e\u69cb\u7bc9\n\n```py\nfrom keras.layers.convolutional import Convolution2D\nfrom keras.layers.convolutional import MaxPooling2D\nfrom keras.layers.core import Activation\nfrom keras.layers.core import Dense\nfrom keras.layers.core import Dropout\nfrom keras.layers.core import Flatten\nfrom keras.models import Sequential\n\ndef build_deep_cnn(num_classes=3):\n\tmodel = Sequential()\n\n\tmodel.add(Convolution2D(96, 3, 3, border_mode='same', input_shape=(3, 32, 32)))\n\tmodel.add(Activation('relu'))\n\n\tmodel.add(Convolution2D(128, 3, 3))\n\tmodel.add(Activation('relu'))\n\tmodel.add(MaxPooling2D(pool_size=(2, 2)))\n\tmodel.add(Dropout(0.5))\n\n\tmodel.add(Convolution2D(256, 3, 3, border_mode='same'))\n\tmodel.add(Activation('relu'))\n\n\tmodel.add(Convolution2D(256, 3, 3))\n\tmodel.add(Activation('relu'))\n\tmodel.add(MaxPooling2D(pool_size=(2, 2)))\n\tmodel.add(Dropout(0.5))\n\n\tmodel.add(Flatten())\n\tmodel.add(Dense(1024))\n\tmodel.add(Activation('relu'))\n\tmodel.add(Dropout(0.5))\n\n\tmodel.add(Dense(num_classes))\n\tmodel.add(Activation('softmax'))\n\t\n\treturn model\n```\n\n\u6700\u521d\u306b`model = Sequential()`\u3067\u30b7\u30fc\u30b1\u30f3\u30b7\u30e3\u30eb\u30e2\u30c7\u30eb\u3092\u751f\u6210\u3057\u3066\uff0c\u305d\u308c\u306b`Convolutional2D`\u3084`Dense`\u3092\u8ffd\u52a0\u3057\u3066\u3044\u304f\u3060\u3051\u3067\u30cd\u30c3\u30c8\u30ef\u30fc\u30af\u3092\u69cb\u7bc9\u3067\u304d\u307e\u3059\uff0e\n`Convolutional2D`\u304c\u7573\u307f\u8fbc\u307f\u5c64\uff0c`Dense`\u304c\u5168\u7d50\u5408\u5c64\u306b\u76f8\u5f53\u3059\u308b\u611f\u3058\u3067\u3059\uff0e\n\u4e00\u756a\u6700\u521d\u306e\uff0c\n\n```py\nConvolution2D(96, 3, 3, border_mode='same', input_shape=(3, 32, 32))\n```\n\u3060\u3051\u306f`input_shape`\u3092\u6307\u5b9a\u3059\u308b\u5fc5\u8981\u304c\u3042\u308a\u307e\u3059\uff0e  \n`Convolutional2D`\u306b\u3064\u3044\u3066\u7c21\u5358\u306b\u8aac\u660e\u3059\u308b\u3068\uff0c\u6700\u521d\u306e\u5f15\u6570\u304c\uff0c\u7573\u307f\u8fbc\u307f\u30ab\u30fc\u30cd\u30eb\u306e\u679a\u6570\uff0c\u7b2c2\uff0c3\u5f15\u6570\u304c\u7573\u307f\u8fbc\u307f\u30ab\u30fc\u30cd\u30eb\u5927\u304d\u3055\u3092\u6307\u5b9a\u3059\u308b\u3082\u306e\u3067\u3059\uff0e`border_mode`\u306b\u306f`same`\u3068`valid`\u306e2\u7a2e\u985e\u304c\u3042\u308a\u307e\u3059\u304c\uff0c`same`\u306fpadding\u304c\u30ab\u30fc\u30cd\u30eb\u306e\u5927\u304d\u3055\u306e\u534a\u5206\uff0c\u3064\u307e\u308a\u51fa\u529b\u306e\u7e26\u6a2a\u306e\u5927\u304d\u3055\u306f\u5165\u529b\u306e\u7e26\u6a2a\u306e\u5927\u304d\u3055\u306f\u5909\u308f\u308a\u307e\u305b\u3093\uff0e`valid`\u306fpadding\u304c\u306a\u3044\u72b6\u614b\uff0c\u3064\u307e\u308a\u51fa\u529b\u306e\u7e26\u6a2a\u306e\u5927\u304d\u3055\u306f\u5165\u529b\u306e\u7e26\u6a2a\u306e\u5927\u304d\u3055\u3088\u308a\u3082\u5c0f\u3055\u304f\u306a\u308a\u307e\u3059\uff0epadding\u306b\u3064\u3044\u306f[\u3053\u3061\u3089](https://github.com/vdumoulin/conv_arithmetic)\u304c\u308f\u304b\u308a\u3084\u3059\u3044\u3067\u3059\uff0e\u4eca\u56de\u306f`same`\u3067\u7573\u307f\u8fbc\u307f\u30ab\u30fc\u30cd\u30eb\u306e`shape`\u304c`(96, 3, 3)`\uff0c\u5165\u529b\u306e`shape`\u304c`(3, 32, 32)`\u306e\u305f\u3081\u3053\u306e\u5c64\u306e\u51fa\u529b\u306e`shape`\u306f`(96, 32, 32)`\u3068\u306a\u308a\u307e\u3059\uff0e`valid`\u306e\u5834\u5408\u306e\u51fa\u529b\u306e`shape`\u306f`(96, 32-(3-1), 32-(3-1))=(96, 30, 30)`\u3068\u306a\u308a\u307e\u3059\uff0e\u305d\u306e\u4ed6\u306b`stride`\u306a\u3069\u3082\u8a2d\u5b9a\u3059\u308b\u3053\u3068\u304c\u3067\u304d\u307e\u3059\uff0e\n\n\n\n## \u30e2\u30c7\u30eb\u306e\u5b66\u7fd2\n\n```py\nfrom keras.callbacks import EarlyStopping\nfrom keras.callbacks import LearningRateScheduler\nfrom keras.optimizers import Adam\nfrom keras.optimizers import SGD\nfrom animeface import AnimeFaceDataset\n\nclass Schedule(object):\n\tdef __init__(self, init=0.01):\n\t\tself.init = init\n\tdef __call__(self, epoch):\n\t\tlr = self.init\n\t\tfor i in xrange(1, epoch+1):\n\t\t\tif i%5==0:\n\t\t\t\tlr *= 0.5\n\t\treturn lr\n\ndef get_schedule_func(init):\n\treturn Schedule(init)\n\ndataset = AnimeFaceDataset()\ndataset.load_data_target()\nx = dataset.data\ny = dataset.target\nn_class = len(set(y))\nperm = np.random.permutation(len(y))\nx = x[perm]\ny = y[perm]\n\nmodel = build_deep_cnn(n_class)\nmodel.summary()\ninit_learning_rate = 1e-2\nopt = SGD(lr=init_learning_rate, decay=0.0, momentum=0.9, nesterov=False)\nmodel.compile(loss='sparse_categorical_crossentropy', optimizer=opt, metrics=[\"acc\"])\nearly_stopping = EarlyStopping(monitor='val_loss', patience=3, verbose=0, mode='auto')\nlrs = LearningRateScheduler(get_schedule_func(init_learning_rate))\n\nhist = model.fit(x, y, \n\t\t\t\tbatch_size=128, \n\t\t\t\tnb_epoch=50, \n\t\t\t\tvalidation_split=0.1, \n\t\t\t\tverbose=1, \n\t\t\t\tcallbacks=[early_stopping, lrs])\n```\n\n\u5b66\u7fd2\u3059\u308b`fit`\u95a2\u6570\u306e\u5f15\u6570\u306e`callbacks`\u306b\u306f\uff0c\u53ce\u675f\u5224\u5b9a\u3057\u305f\u3089\u81ea\u52d5\u7684\u306b\u5b66\u7fd2\u3092\u7d42\u4e86\u3059\u308b`EarlyStopping`\u3084\uff0c`epoch`\u6bce\u306b\u5b66\u7fd2\u7387\u3092\u8abf\u6574\u3059\u308b\u3053\u3068\u304c\u3067\u304d\u308b`LearningRateScheduler`\u306a\u3069\u3092\u6307\u5b9a\u3059\u308b\u3053\u3068\u304c\u3067\u304d\uff0c\u4fbf\u5229\u3067\u3059\uff0e  \n\n\u7c21\u5358\u306b`LearningRateScheduler`\u306b\u3064\u3044\u3066\u8aac\u660e\u3059\u308b\u3068\uff0c\u300c\u5f15\u6570\u306b\u73fe\u5728\u306e`epoch`\u6570\u3092(0\u306f\u3058\u307e\u308a)\u3092\u4e0e\u3048\u305f\u6642\u306b\u5b66\u7fd2\u7387\u3092\u8fd4\u3057\u3066\u304f\u308c\u308b\u95a2\u6570\u300d\u3092\u5f15\u6570\u306b\u53d6\u308a\u307e\u3059\uff0e\u4f8b\u3048\u3070\uff0c\n\n```py\nclass Schedule(object):\n    def __init__(self, init=0.01):\n        self.init = init\n    def __call__(self, epoch):\n        lr = self.init\n        for i in xrange(1, epoch+1):\n            if i%5==0:\n                lr *= 0.5\n        return lr\n\ndef get_schedule_func(init):\n    return Schedule(init)\n\nlrs = LearningRateScheduler(get_schedule_fun(0.01))\n```\n\n\u306e\u3088\u3046\u306b\u3084\u308b\u3068\uff0c\u521d\u671f\u5b66\u7fd2\u73870.01\u30675epoch\u6bce\u306b\u5b66\u7fd2\u7387\u304c\u534a\u6e1b\u3059\u308b\uff0c\u3068\u3044\u3063\u305f\u611f\u3058\u306b\u306a\u308a\u307e\u3059\uff0e  \n\n\u307e\u305f\uff0c`fit`\u306e\u8fd4\u308a\u5024\u306e\u30aa\u30d6\u30b8\u30a7\u30af\u30c8\u306e`.history`\u306b\u306f\u8f9e\u66f8\u578b\u3067\u5404epoch\u6bce\u306e\u8aa4\u5dee\u95a2\u6570\u7b49\u3092\u4fdd\u5b58\u3057\u3066\u304f\u308c\u307e\u3059\uff0ePandas\u3068Matplotlib\u3092\u4f7f\u3046\u3068\u4fbf\u5229\u306b\u53ef\u8996\u5316\u3059\u308b\u3053\u3068\u304c\u3067\u304d\u307e\u3059\uff0e\n\n```py\nimport pandas as pd\nimport matplotlib.pyplot as plt\nplt.style.use(\"ggplot\")\n\ndf = pd.DataFrame(hist.history)\ndf.index += 1\ndf.index.name = \"epoch\"\ndf[[\"acc\", \"val_acc\"]].plot(linewidth=2)\nplt.savefig(\"acc_history.pdf\")\ndf[[\"loss\", \"val_loss\"]].plot(linewidth=2)\nplt.savefig(\"loss_history.pdf\")\n```\n\n# \u5b9f\u9a13\u7d50\u679c\n\u7d50\u679c\u306f\u4ee5\u4e0b\u306e\u901a\u308a\u3068\u306a\u308a\uff0c\u691c\u8a3c\u7528\u306e\u6b63\u89e3\u7387\u306f\u7d046\u5272\u5f31\u3068\u306a\u308a\u307e\u3057\u305f\uff0e  \n\u5b9f\u306f\u6700\u9069\u5316\u624b\u6cd5\u306bAdam\u3092\u4f7f\u3046\u3068\u691c\u8a3c\u7528\u306e\u6b63\u89e3\u7387\u306f7\u5272\u3092\u8d85\u3048\u308b\u306e\u3067\u3084\u3063\u3066\u307f\u3066\u304f\u3060\u3055\u3044\uff0e\n\n## \u8aa4\u5dee\u95a2\u6570\u306e\u63a8\u79fb\n<img width=\"480\" alt=\"\u30b9\u30af\u30ea\u30fc\u30f3\u30b7\u30e7\u30c3\u30c8 2016-06-12 14.40.39.png\" src=\"https://qiita-image-store.s3.amazonaws.com/0/31899/2156aabb-56ed-155a-63f2-2c1999ee9252.png\">\n\n## \u6b63\u89e3\u7387\u306e\u63a8\u79fb\n<img width=\"480\" alt=\"\u30b9\u30af\u30ea\u30fc\u30f3\u30b7\u30e7\u30c3\u30c8 2016-06-12 14.40.15.png\" src=\"https://qiita-image-store.s3.amazonaws.com/0/31899/e97f347f-a7cd-d27a-8903-816327f1deec.png\">\n"}