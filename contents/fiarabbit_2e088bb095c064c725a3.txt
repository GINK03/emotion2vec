{"context": "\n\nno face detected\ndlib\u3092AFW\u3067\u30c8\u30ec\u30fc\u30cb\u30f3\u30b0\u3057\u3066\u3082\u9854\u691c\u51fa\u304c\u30de\u30b7\u306b\u306a\u3063\u305f\u308a\u306f\u3057\u306a\u304b\u3063\u305f\u3088\n\ncode\n\ntrain.py\nimport cv2, dlib\nimport matplotlib.pyplot as plt\nimport matplotlib.patches as patches\nimport matplotlib.animation as animation\nimport sys\n\nVIDEO_PATH = '/home/hashimoto/experimental_video/video_20170123_161533.mp4'\n\n#options = dlib.simple_object_detector_training_options()\n#options.C=5\n#options.be_verbose=True\n#options.num_threads=12\n#dlib.train_simple_object_detector(\"/home/hashimoto/datasets/AFW/IMAGES/AFW.xml\",\"detector.svm\",options)\ndetector = dlib.simple_object_detector(\"detector.svm\")\n#detector = dlib.get_frontal_face_detector()\nvideo_capture = cv2.VideoCapture(VIDEO_PATH)\n\ndef face_detect(img):\n    rects, _, _ = detector(img,1)\n    if len(rects)>0:\n        rect = rects[0]\n        return rect\n    else:\n        return None\n\ndef plot(frame):\n    print(frame)\n    plt.cla()\n    if video_capture.isOpened():\n        ret, img = video_capture.read()\n        img_corrected=cv2.cvtColor(img,cv2.COLOR_BGR2RGB)\n        plt.imshow(img_corrected)\n        rect = face_detect(img)\n        if not(rect is None):\n            patch = patches.Rectangle((rect.left(),rect.top()),rect.width(),rect.height(),linewidth=1,edgecolor='r',facecolor='none')\n            plt.gca().add_patch(patch)\n        else:\n            print('no faces detected')\n    else:\n        print('could not open video')\n\nfig = plt.figure()\nani = animation.FuncAnimation(fig,plot,interval=100,frames=100,repeat=False)\nplt.show()\n\n\n# no face detected\ndlib\u3092AFW\u3067\u30c8\u30ec\u30fc\u30cb\u30f3\u30b0\u3057\u3066\u3082\u9854\u691c\u51fa\u304c\u30de\u30b7\u306b\u306a\u3063\u305f\u308a\u306f\u3057\u306a\u304b\u3063\u305f\u3088\n# code\n```train.py\nimport cv2, dlib\nimport matplotlib.pyplot as plt\nimport matplotlib.patches as patches\nimport matplotlib.animation as animation\nimport sys\n\nVIDEO_PATH = '/home/hashimoto/experimental_video/video_20170123_161533.mp4'\n\n#options = dlib.simple_object_detector_training_options()\n#options.C=5\n#options.be_verbose=True\n#options.num_threads=12\n#dlib.train_simple_object_detector(\"/home/hashimoto/datasets/AFW/IMAGES/AFW.xml\",\"detector.svm\",options)\ndetector = dlib.simple_object_detector(\"detector.svm\")\n#detector = dlib.get_frontal_face_detector()\nvideo_capture = cv2.VideoCapture(VIDEO_PATH)\n\ndef face_detect(img):\n    rects, _, _ = detector(img,1)\n    if len(rects)>0:\n        rect = rects[0]\n        return rect\n    else:\n        return None\n\ndef plot(frame):\n    print(frame)\n    plt.cla()\n    if video_capture.isOpened():\n        ret, img = video_capture.read()\n        img_corrected=cv2.cvtColor(img,cv2.COLOR_BGR2RGB)\n        plt.imshow(img_corrected)\n        rect = face_detect(img)\n        if not(rect is None):\n            patch = patches.Rectangle((rect.left(),rect.top()),rect.width(),rect.height(),linewidth=1,edgecolor='r',facecolor='none')\n            plt.gca().add_patch(patch)\n        else:\n            print('no faces detected')\n    else:\n        print('could not open video')\n\nfig = plt.figure()\nani = animation.FuncAnimation(fig,plot,interval=100,frames=100,repeat=False)\nplt.show()\n```\n\n#\n", "tags": ["python3", "dlib"]}