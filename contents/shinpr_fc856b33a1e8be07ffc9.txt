{"tags": ["MacOSX", "Spark", "hadoop", "Scala"], "context": "Mac\u306b\u30aa\u30fc\u30eb\u30a4\u30f3\u30ef\u30f3\u306aSpark\u958b\u767a\u74b0\u5883\u3092\u69cb\u7bc9\u3059\u308b\u624b\u9806\u306e\u307e\u3068\u3081\nMac\u4e0a\u3067Hadoop\u3092\u52d5\u304b\u3059\u305f\u3081\u5b9f\u7528\u7684\u3067\u306f\u306a\u3044\u3067\u3059\u304c\u3001\u30df\u30cb\u30de\u30e0\u306a\u958b\u767a\u74b0\u5883\u3068\u3057\u3066\u306f\u4fa1\u5024\u304c\u3042\u308b\u306e\u3067\u306f\u306a\u3044\u304b\u3068\u601d\u3044\u307e\u3059\u3002\n\n\u74b0\u5883\n\nOS X 10.11.1\nJava 1.7.0_45\nScala 2.11.7\nHomebrew 0.9.9\nHadoop 2.7.2\nSpark 1.6.1\n\n\nHadoop\u306e\u30a4\u30f3\u30b9\u30c8\u30fc\u30eb\n\u4eca\u56de\u306fHomebrew\u3092\u4f7f\u7528\u3057\u307e\u3059\u3002\n$ brew install hadoop\n\nHadoop\u306e\u30a4\u30f3\u30b9\u30c8\u30fc\u30eb\u304c\u7d42\u308f\u3063\u305f\u3089\u3001native-hadoop library\u3092\u4f5c\u6210\u3057\u307e\u3059\u3002\n\u203b \u3053\u308c\u304c\u7121\u3044\u3068\u4ee5\u4e0b\u306e\u30a8\u30e9\u30fc\u304c\u51fa\u3066Hadoop\u304c\u8d77\u52d5\u3057\u307e\u305b\u3093\nutil.NativeCodeLoader: Unable to load native-hadoop library for your platform...\n\n\n\u30a4\u30f3\u30b9\u30c8\u30fc\u30eb\u3057\u305fHadoop\u306e\u30d0\u30fc\u30b8\u30e7\u30f3\u78ba\u8a8d\n\n$ hadoop version\nHadoop 2.7.2\n...\nCompiled with protoc 2.5.0\n\n\n\u540c\u30d0\u30fc\u30b8\u30e7\u30f3\u306eSource\u3092\u30c0\u30a6\u30f3\u30ed\u30fc\u30c9\n\nhttp://hadoop.apache.org/releases.html\n$ curl -O http://ftp.jaist.ac.jp/pub/apache/hadoop/common/hadoop-2.7.2/hadoop-2.7.2-src.tar.gz\n\n\nProtocol Buffers\u304c\u5165\u3063\u3066\u3044\u306a\u3051\u308c\u3070\u30a4\u30f3\u30b9\u30c8\u30fc\u30eb\n\n\u203b \u30d0\u30fc\u30b8\u30e7\u30f3\u306f\u305d\u308d\u3048\u308b\u3053\u3068\n$ brew install protobuf250\n\n\nMaven\u304c\u5165\u3063\u3066\u3044\u306a\u3051\u308c\u3070\u30a4\u30f3\u30b9\u30c8\u30fc\u30eb\n\n$ brew install maven\n\n\nnative-hadoop library\u306e\u4f5c\u6210\n\n$ cd hadoop-2.7.2-src/hadoop-common-project/hadoop-common/\n$ sudo mvn -P native compile\n[INFO] Scanning for projects...\n[INFO]\n[INFO] ------------------------------------------------------------------------\n[INFO] Building Apache Hadoop Common 2.7.2\n[INFO] ------------------------------------------------------------------------\n[INFO]\n...\n[INFO] Executed tasks\n[INFO] ------------------------------------------------------------------------\n[INFO] BUILD SUCCESS\n[INFO] ------------------------------------------------------------------------\n[INFO] Total time: xx:xx min\n[INFO] Finished at: xxxx-xx-xxTxx:xx:xx+09:00\n[INFO] Final Memory: 32M/254M\n[INFO] ------------------------------------------------------------------------\n$ ls target/native/target/usr/local/lib/\nlibhadoop.1.0.0.dylib   libhadoop.a     libhadoop.dylib\n\n\u4f5c\u6210\u3057\u305f\u30e9\u30a4\u30d6\u30e9\u30ea\u3092/Library/Java/Extensions\u306b\u914d\u7f6e\u3057\u3066\u304f\u3060\u3055\u3044\u3002\n\nHadoop\u306e\u8a2d\u5b9a\n\u3053\u3061\u3089\u306e\u8a18\u4e8b\u3092\u53c2\u8003\u306b\u3057\u307e\u3057\u305f\u3002\nMac\u3067hadoop\u3092\u3061\u3087\u3063\u3068\u3060\u3051\u52d5\u304b\u3057\u3066\u307f\u308b\n\u30d0\u30fc\u30b8\u30e7\u30f3\u304c\u9055\u3046\u306e\u3067$HADOOP_HOME\u304c\u4e0b\u8a18\u306b\u306a\u308a\u307e\u3059\n/usr/local/Cellar/hadoop/2.7.2\n\n\nHadoop\u306e\u8d77\u52d5\n$ cd /usr/local/Cellar/hadoop/2.7.2/sbin/\n$ ./start-all.sh\n\nUnable to load native-hadoop library\u301c\u304c\u51fa\u308b\u5834\u5408\u306fjava.library.path\u306b/Library/Java/Extensions\u304c\u8a2d\u5b9a\u3055\u308c\u3066\u3044\u308b\u304b\u78ba\u8a8d\u3057\u3066\u304f\u3060\u3055\u3044\u3002\n\u203b \u8d77\u52d5\u6642\u306b\u4ee5\u4e0b\u306e\u30a8\u30e9\u30fc\u304c\u51fa\u307e\u3059\u304c\u3001Java1.7\u3067\u306e\u89e3\u6c7a\u65b9\u6cd5\u304c\u898b\u3064\u3051\u3089\u308c\u306a\u304b\u3063\u305f\u4e8b\u3068\u3001\u52d5\u4f5c\u306f\u3059\u308b\u306e\u3067\u30b9\u30eb\u30fc\u3057\u307e\u3057\u305f\u3002\nUnable to load realm info from SCDynamicStore\n\n\nSpark\u30b5\u30f3\u30d7\u30eb\u306e\u30d7\u30ed\u30b8\u30a7\u30af\u30c8\u4f5c\u6210\n\nActivator\u306e\u30a4\u30f3\u30b9\u30c8\u30fc\u30eb\n\n\u3053\u3061\u3089\u304b\u3089\u30c0\u30a6\u30f3\u30ed\u30fc\u30c9\u3057\u307e\u3059\u3002\nhttp://www.lightbend.com/activator/download\n$ curl -O https://downloads.typesafe.com/typesafe-activator/1.3.10/typesafe-activator-1.3.10-minimal.zip\n\n\u89e3\u51cd\u30fb\u914d\u7f6e\u3057\u305f\u3089PATH\u306b\u767b\u9332\u3057\u3066\u304a\u304f\u3068\u4fbf\u5229\u3067\u3059\u3002\n\n~/.bash_profile\nexport ACTIVATOR_HOME=/usr/local/Cellar/activator-1.3.10-minimal\nexport PATH=$ACTIVATOR_HOME/bin:$PATH\n\n\n$ source ~/.bash_profile\n\n\n\u30b5\u30f3\u30d7\u30eb\u30c7\u30fc\u30bf\u306e\u8a2d\u7f6e\n\n\u4eca\u56de\u306fMovieLens 1M\u3092\u4f7f\u7528\u3057\u307e\u3059\u3002\n$ curl -O http://files.grouplens.org/datasets/movielens/ml-1m.zip\n$ unzip ml-1m.zip\n$ cd ml-1m\n\n$ hadoop fs -mkdir /input/\n$ hadoop fs -put ratings.dat /input/\n$ hadoop fs -ls -R /\ndrwxr-xr-x   - root supergroup          0 2016-xx-xx xx:xx /input\n-rw-r--r--   1 root supergroup   24594131 2016-xx-xx xx:xx /input/ratings.dat\n\n\n\u30d7\u30ed\u30b8\u30a7\u30af\u30c8\u306e\u4f5c\u6210\n\nActivator\u3067\u30d7\u30ed\u30b8\u30a7\u30af\u30c8\u3092\u4f5c\u6210\u3057\u307e\u3059\u3002\n$ activator new SparkSample\n\nFetching the latest list of templates...\n\nBrowse the list of templates: http://lightbend.com/activator/templates\nChoose from these featured templates or enter a template name:\n  1) minimal-akka-java-seed\n  2) minimal-akka-scala-seed\n  3) minimal-java\n  4) minimal-scala\n  5) play-java\n  6) play-scala\n(hit tab to see a list of all templates)\n> 4\nOK, application \"SparkSample\" is being created using the \"minimal-scala\" template.\n...\n\n\n\u30e9\u30a4\u30d6\u30e9\u30ea\u30fb\u30d7\u30e9\u30b0\u30a4\u30f3\u306e\u8a2d\u5b9a\n\nSpark\u30e9\u30a4\u30d6\u30e9\u30ea\u3068\u3001\u30b3\u30de\u30f3\u30c9\u30e9\u30a4\u30f3\u5b9f\u884c\u7528\u306e\u30d7\u30e9\u30b0\u30a4\u30f3\u3092\u8a2d\u5b9a\u3057\u307e\u3059\u3002\nminimal-scala\u306e\u30d7\u30ed\u30b8\u30a7\u30af\u30c8\u3060\u3068project/plugins.sbt\u304c\u7121\u3044\u3068\u601d\u3046\u306e\u3067\u4f5c\u6210\u3057\u3066\u304f\u3060\u3055\u3044\u3002\n\nproject/plugins.sbt\naddSbtPlugin(\"com.typesafe.sbt\" % \"sbt-native-packager\" % \"1.0.6\")\n\n\n\nbuild.sbt\nscalaVersion := \"2.11.7\"\n\nlibraryDependencies ++= Seq(\n  \"org.apache.spark\" % \"spark-core_2.11\" % \"1.6.1\",\n  \"org.scalatest\" %% \"scalatest\" % \"2.2.4\" % \"test\"\n)\n\nenablePlugins(JavaAppPackaging)\n\n\n\n\u30b5\u30f3\u30d7\u30eb\u30b3\u30fc\u30c9\n\u4eca\u56de\u306f\u30c7\u30fc\u30bf\u3092\u53d6\u5f97\u3067\u304d\u308b\u304b\u3092\u758e\u901a\u78ba\u8a8d\u3059\u308b\u3060\u3051\u306e\u30b3\u30fc\u30c9\u3092\u4f5c\u6210\u3057\u307e\u3059\u3002\n\u5225\u9014\u3001\u4eca\u56de\u306e\u74b0\u5883\u3067\u7c21\u5358\u306a\u30ec\u30b3\u30e1\u30f3\u30c9\u30ed\u30b8\u30c3\u30af\u306e\u5b9f\u88c5\u3092\u884c\u3046\u4e88\u5b9a\u3067\u3059\u3002\n\nHello.scala\npackage com.example\n\nimport org.apache.spark.SparkContext\nimport org.apache.spark.SparkConf\n\nobject Hello {\n  def main(args: Array[String]): Unit = {\n    val conf = new SparkConf()\n                      .setAppName(\"SparkSample\")\n                      .setMaster(\"local\")\n    val sc = new SparkContext(conf)\n    val textFile = sc.textFile(\"hdfs://localhost:9000/input/ratings.dat\")\n    println(s\"###file line count=${textFile.count}\")\n\n    sc.stop\n  }\n}\n\n\n\n\u5b9f\u884c\n\u4e0a\u8a18\u306e\u30bd\u30fc\u30b9\u3092\u30b3\u30f3\u30d1\u30a4\u30eb\u3057\u3001ratings.dat\u306e\u884c\u6570\u3092\u51fa\u529b\u3055\u305b\u307e\u3059\u3002\n$ cd SparkSample\n$ activator compile\n...\n[info] Done updating.\n[info] Compiling 1 Scala source to /xxx/SparkSample/target/scala-2.11/classes...\n[success] Total time: 36 s, completed 2016/xx/xx xx:xx:xx\n\n$ activator stage\n...\n[info] Done packaging.\n[success] Total time: 11 s, completed 2016/xx/xx xx:xx:xx\n\n$ cd target/universal/stage/bin/\n$ ./sparksample\n16/xx/xx xx:xx:xx INFO SparkContext: Running Spark version 1.6.1\n...\n###file line count=1000209\n\n\u7d50\u679c(1,000,209\u884c)\u304c\u51fa\u529b\u3055\u308c\u307e\u3057\u305f\u3002\n\u5b9f\u30d5\u30a1\u30a4\u30eb\u306e\u884c\u6570\u3068\u4e00\u81f4\u3057\u3066\u3044\u307e\u3059\u3002\n$ cat ratings.dat | wc -l\n 1000209\n\n\n\u304a\u307e\u3051\nIntelliJ\u306eSBT Console\u3067Unable to load native-hadoop library\u301c\u30a8\u30e9\u30fc\u304c\u51fa\u308b\u5834\u5408\u306f\u3001Preferences...\u304b\u3089java.library.path\u3092\u8a2d\u5b9a\u3059\u308b\u3068\u3088\u3055\u305d\u3046\u3067\u3059\u3002\n\nMac\u306b\u30aa\u30fc\u30eb\u30a4\u30f3\u30ef\u30f3\u306aSpark\u958b\u767a\u74b0\u5883\u3092\u69cb\u7bc9\u3059\u308b\u624b\u9806\u306e\u307e\u3068\u3081\n\nMac\u4e0a\u3067Hadoop\u3092\u52d5\u304b\u3059\u305f\u3081\u5b9f\u7528\u7684\u3067\u306f\u306a\u3044\u3067\u3059\u304c\u3001\u30df\u30cb\u30de\u30e0\u306a\u958b\u767a\u74b0\u5883\u3068\u3057\u3066\u306f\u4fa1\u5024\u304c\u3042\u308b\u306e\u3067\u306f\u306a\u3044\u304b\u3068\u601d\u3044\u307e\u3059\u3002\n\n## \u74b0\u5883\n- OS X 10.11.1\n- Java 1.7.0_45\n- Scala 2.11.7\n- Homebrew 0.9.9\n- Hadoop 2.7.2\n- Spark 1.6.1\n\n## Hadoop\u306e\u30a4\u30f3\u30b9\u30c8\u30fc\u30eb\n\u4eca\u56de\u306fHomebrew\u3092\u4f7f\u7528\u3057\u307e\u3059\u3002\n\n```bash\n$ brew install hadoop\n```\n\nHadoop\u306e\u30a4\u30f3\u30b9\u30c8\u30fc\u30eb\u304c\u7d42\u308f\u3063\u305f\u3089\u3001native-hadoop library\u3092\u4f5c\u6210\u3057\u307e\u3059\u3002\n\u203b \u3053\u308c\u304c\u7121\u3044\u3068\u4ee5\u4e0b\u306e\u30a8\u30e9\u30fc\u304c\u51fa\u3066Hadoop\u304c\u8d77\u52d5\u3057\u307e\u305b\u3093\n\n```bash\nutil.NativeCodeLoader: Unable to load native-hadoop library for your platform...\n```\n\n- \u30a4\u30f3\u30b9\u30c8\u30fc\u30eb\u3057\u305fHadoop\u306e\u30d0\u30fc\u30b8\u30e7\u30f3\u78ba\u8a8d\n\n```bash\n$ hadoop version\nHadoop 2.7.2\n...\nCompiled with protoc 2.5.0\n```\n\n- \u540c\u30d0\u30fc\u30b8\u30e7\u30f3\u306eSource\u3092\u30c0\u30a6\u30f3\u30ed\u30fc\u30c9\n\nhttp://hadoop.apache.org/releases.html\n\n```bash\n$ curl -O http://ftp.jaist.ac.jp/pub/apache/hadoop/common/hadoop-2.7.2/hadoop-2.7.2-src.tar.gz\n```\n\n- Protocol Buffers\u304c\u5165\u3063\u3066\u3044\u306a\u3051\u308c\u3070\u30a4\u30f3\u30b9\u30c8\u30fc\u30eb\n\n\u203b \u30d0\u30fc\u30b8\u30e7\u30f3\u306f\u305d\u308d\u3048\u308b\u3053\u3068\n\n\n```bash\n$ brew install protobuf250\n```\n\n- Maven\u304c\u5165\u3063\u3066\u3044\u306a\u3051\u308c\u3070\u30a4\u30f3\u30b9\u30c8\u30fc\u30eb\n\n```bash\n$ brew install maven\n```\n\n- native-hadoop library\u306e\u4f5c\u6210\n\n```bash\n$ cd hadoop-2.7.2-src/hadoop-common-project/hadoop-common/\n$ sudo mvn -P native compile\n[INFO] Scanning for projects...\n[INFO]\n[INFO] ------------------------------------------------------------------------\n[INFO] Building Apache Hadoop Common 2.7.2\n[INFO] ------------------------------------------------------------------------\n[INFO]\n...\n[INFO] Executed tasks\n[INFO] ------------------------------------------------------------------------\n[INFO] BUILD SUCCESS\n[INFO] ------------------------------------------------------------------------\n[INFO] Total time: xx:xx min\n[INFO] Finished at: xxxx-xx-xxTxx:xx:xx+09:00\n[INFO] Final Memory: 32M/254M\n[INFO] ------------------------------------------------------------------------\n$ ls target/native/target/usr/local/lib/\nlibhadoop.1.0.0.dylib\tlibhadoop.a\t\tlibhadoop.dylib\n```\n\n\u4f5c\u6210\u3057\u305f\u30e9\u30a4\u30d6\u30e9\u30ea\u3092```/Library/Java/Extensions```\u306b\u914d\u7f6e\u3057\u3066\u304f\u3060\u3055\u3044\u3002\n\n## Hadoop\u306e\u8a2d\u5b9a\n\u3053\u3061\u3089\u306e\u8a18\u4e8b\u3092\u53c2\u8003\u306b\u3057\u307e\u3057\u305f\u3002\n[Mac\u3067hadoop\u3092\u3061\u3087\u3063\u3068\u3060\u3051\u52d5\u304b\u3057\u3066\u307f\u308b](http://qiita.com/ysk_1031/items/26752b5da1629c9db8f7#1-4)\n\n\u30d0\u30fc\u30b8\u30e7\u30f3\u304c\u9055\u3046\u306e\u3067```$HADOOP_HOME```\u304c\u4e0b\u8a18\u306b\u306a\u308a\u307e\u3059\n\n```bash\n/usr/local/Cellar/hadoop/2.7.2\n```\n\n## Hadoop\u306e\u8d77\u52d5\n\n```bash\n$ cd /usr/local/Cellar/hadoop/2.7.2/sbin/\n$ ./start-all.sh\n```\n\n```Unable to load native-hadoop library\u301c```\u304c\u51fa\u308b\u5834\u5408\u306f```java.library.path```\u306b```/Library/Java/Extensions```\u304c\u8a2d\u5b9a\u3055\u308c\u3066\u3044\u308b\u304b\u78ba\u8a8d\u3057\u3066\u304f\u3060\u3055\u3044\u3002\n\n\u203b \u8d77\u52d5\u6642\u306b\u4ee5\u4e0b\u306e\u30a8\u30e9\u30fc\u304c\u51fa\u307e\u3059\u304c\u3001Java1.7\u3067\u306e\u89e3\u6c7a\u65b9\u6cd5\u304c\u898b\u3064\u3051\u3089\u308c\u306a\u304b\u3063\u305f\u4e8b\u3068\u3001\u52d5\u4f5c\u306f\u3059\u308b\u306e\u3067\u30b9\u30eb\u30fc\u3057\u307e\u3057\u305f\u3002\n\n```bash\nUnable to load realm info from SCDynamicStore\n```\n\n## Spark\u30b5\u30f3\u30d7\u30eb\u306e\u30d7\u30ed\u30b8\u30a7\u30af\u30c8\u4f5c\u6210\n\n- Activator\u306e\u30a4\u30f3\u30b9\u30c8\u30fc\u30eb\n\n\u3053\u3061\u3089\u304b\u3089\u30c0\u30a6\u30f3\u30ed\u30fc\u30c9\u3057\u307e\u3059\u3002\nhttp://www.lightbend.com/activator/download\n\n```bash\n$ curl -O https://downloads.typesafe.com/typesafe-activator/1.3.10/typesafe-activator-1.3.10-minimal.zip\n```\n\n\u89e3\u51cd\u30fb\u914d\u7f6e\u3057\u305f\u3089PATH\u306b\u767b\u9332\u3057\u3066\u304a\u304f\u3068\u4fbf\u5229\u3067\u3059\u3002\n\n```bash:~/.bash_profile\nexport ACTIVATOR_HOME=/usr/local/Cellar/activator-1.3.10-minimal\nexport PATH=$ACTIVATOR_HOME/bin:$PATH\n```\n\n```bash\n$ source ~/.bash_profile\n```\n\n- \u30b5\u30f3\u30d7\u30eb\u30c7\u30fc\u30bf\u306e\u8a2d\u7f6e\n\n\u4eca\u56de\u306f[MovieLens 1M](http://grouplens.org/datasets/movielens/)\u3092\u4f7f\u7528\u3057\u307e\u3059\u3002\n\n```bash\n$ curl -O http://files.grouplens.org/datasets/movielens/ml-1m.zip\n$ unzip ml-1m.zip\n$ cd ml-1m\n\n$ hadoop fs -mkdir /input/\n$ hadoop fs -put ratings.dat /input/\n$ hadoop fs -ls -R /\ndrwxr-xr-x   - root supergroup          0 2016-xx-xx xx:xx /input\n-rw-r--r--   1 root supergroup   24594131 2016-xx-xx xx:xx /input/ratings.dat\n```\n\n- \u30d7\u30ed\u30b8\u30a7\u30af\u30c8\u306e\u4f5c\u6210\n\nActivator\u3067\u30d7\u30ed\u30b8\u30a7\u30af\u30c8\u3092\u4f5c\u6210\u3057\u307e\u3059\u3002\n\n```bash\n$ activator new SparkSample\n\nFetching the latest list of templates...\n\nBrowse the list of templates: http://lightbend.com/activator/templates\nChoose from these featured templates or enter a template name:\n  1) minimal-akka-java-seed\n  2) minimal-akka-scala-seed\n  3) minimal-java\n  4) minimal-scala\n  5) play-java\n  6) play-scala\n(hit tab to see a list of all templates)\n> 4\nOK, application \"SparkSample\" is being created using the \"minimal-scala\" template.\n...\n```\n\n- \u30e9\u30a4\u30d6\u30e9\u30ea\u30fb\u30d7\u30e9\u30b0\u30a4\u30f3\u306e\u8a2d\u5b9a\n\nSpark\u30e9\u30a4\u30d6\u30e9\u30ea\u3068\u3001\u30b3\u30de\u30f3\u30c9\u30e9\u30a4\u30f3\u5b9f\u884c\u7528\u306e\u30d7\u30e9\u30b0\u30a4\u30f3\u3092\u8a2d\u5b9a\u3057\u307e\u3059\u3002\n```minimal-scala```\u306e\u30d7\u30ed\u30b8\u30a7\u30af\u30c8\u3060\u3068```project/plugins.sbt```\u304c\u7121\u3044\u3068\u601d\u3046\u306e\u3067\u4f5c\u6210\u3057\u3066\u304f\u3060\u3055\u3044\u3002\n\n```scala:project/plugins.sbt\naddSbtPlugin(\"com.typesafe.sbt\" % \"sbt-native-packager\" % \"1.0.6\")\n```\n\n```scala:build.sbt\nscalaVersion := \"2.11.7\"\n\nlibraryDependencies ++= Seq(\n  \"org.apache.spark\" % \"spark-core_2.11\" % \"1.6.1\",\n  \"org.scalatest\" %% \"scalatest\" % \"2.2.4\" % \"test\"\n)\n\nenablePlugins(JavaAppPackaging)\n```\n\n## \u30b5\u30f3\u30d7\u30eb\u30b3\u30fc\u30c9\n\u4eca\u56de\u306f\u30c7\u30fc\u30bf\u3092\u53d6\u5f97\u3067\u304d\u308b\u304b\u3092\u758e\u901a\u78ba\u8a8d\u3059\u308b\u3060\u3051\u306e\u30b3\u30fc\u30c9\u3092\u4f5c\u6210\u3057\u307e\u3059\u3002\n\u5225\u9014\u3001\u4eca\u56de\u306e\u74b0\u5883\u3067\u7c21\u5358\u306a\u30ec\u30b3\u30e1\u30f3\u30c9\u30ed\u30b8\u30c3\u30af\u306e\u5b9f\u88c5\u3092\u884c\u3046\u4e88\u5b9a\u3067\u3059\u3002\n\n```scala:Hello.scala\npackage com.example\n\nimport org.apache.spark.SparkContext\nimport org.apache.spark.SparkConf\n\nobject Hello {\n  def main(args: Array[String]): Unit = {\n    val conf = new SparkConf()\n                      .setAppName(\"SparkSample\")\n                      .setMaster(\"local\")\n    val sc = new SparkContext(conf)\n    val textFile = sc.textFile(\"hdfs://localhost:9000/input/ratings.dat\")\n    println(s\"###file line count=${textFile.count}\")\n\n    sc.stop\n  }\n}\n```\n\n## \u5b9f\u884c\n\u4e0a\u8a18\u306e\u30bd\u30fc\u30b9\u3092\u30b3\u30f3\u30d1\u30a4\u30eb\u3057\u3001```ratings.dat```\u306e\u884c\u6570\u3092\u51fa\u529b\u3055\u305b\u307e\u3059\u3002\n\n```bash\n$ cd SparkSample\n$ activator compile\n...\n[info] Done updating.\n[info] Compiling 1 Scala source to /xxx/SparkSample/target/scala-2.11/classes...\n[success] Total time: 36 s, completed 2016/xx/xx xx:xx:xx\n\n$ activator stage\n...\n[info] Done packaging.\n[success] Total time: 11 s, completed 2016/xx/xx xx:xx:xx\n\n$ cd target/universal/stage/bin/\n$ ./sparksample\n16/xx/xx xx:xx:xx INFO SparkContext: Running Spark version 1.6.1\n...\n###file line count=1000209\n```\n\n\u7d50\u679c(1,000,209\u884c)\u304c\u51fa\u529b\u3055\u308c\u307e\u3057\u305f\u3002\n\u5b9f\u30d5\u30a1\u30a4\u30eb\u306e\u884c\u6570\u3068\u4e00\u81f4\u3057\u3066\u3044\u307e\u3059\u3002\n\n```bash\n$ cat ratings.dat | wc -l\n 1000209\n```\n\n## \u304a\u307e\u3051\nIntelliJ\u306eSBT Console\u3067```Unable to load native-hadoop library\u301c```\u30a8\u30e9\u30fc\u304c\u51fa\u308b\u5834\u5408\u306f\u3001Preferences...\u304b\u3089```java.library.path```\u3092\u8a2d\u5b9a\u3059\u308b\u3068\u3088\u3055\u305d\u3046\u3067\u3059\u3002\n![\u30b9\u30af\u30ea\u30fc\u30f3\u30b7\u30e7\u30c3\u30c8 2016-05-30 16.43.27.png](https://qiita-image-store.s3.amazonaws.com/0/64234/4c0d32c1-cadb-c3c1-f1a4-237097a69bb0.png)\n"}