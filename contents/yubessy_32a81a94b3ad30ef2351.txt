{"context": "Spark\u306eDataFrameReader\u306e json \u30e1\u30bd\u30c3\u30c9\u306b\u306f\u3001HDFS\u3084S3\u306b\u5bfe\u3059\u308bglob\u30d1\u30bf\u30fc\u30f3\u3092\u8907\u6570\u6307\u5b9a\u3067\u304d\u307e\u3059\u3002\nsqlContext.read.json(\n  \"s3://mybucket/data/year=2016/month=11/day=*/\",\n  \"s3://mybucket/data/year=2016/month=12/day=*/\",\n  \"s3://mybucket/data/year=2017/month=01/day=*/\"\n)\n\n\u305f\u3060\u3057\u3001\u30de\u30c3\u30c1\u3059\u308b\u30aa\u30d6\u30b8\u30a7\u30af\u30c8\u304c\u4e00\u3064\u3082\u5b58\u5728\u3057\u306a\u3044\u3088\u3046\u306a\u30d1\u30b9\u304c\u542b\u307e\u308c\u3066\u3044\u308b\u3068\u30a8\u30e9\u30fc\u306b\u306a\u308a\u307e\u3059\u3002\norg.apache.spark.sql.AnalysisException: Path does not exist: s3://mybucket/data/year=2017/month=01/day=*/;\n\n\u4eca\u306e\u3068\u3053\u308d\u30a8\u30e9\u30fc\u3092\u7121\u8996\u3057\u3066\u5b58\u5728\u3059\u308b\u30d1\u30b9\u3060\u3051\u8aad\u307f\u51fa\u3059\u3088\u3046\u306a\u30aa\u30d7\u30b7\u30e7\u30f3\u306f\u7528\u610f\u3055\u308c\u3066\u3044\u306a\u3044\u3088\u3046\u3067\u3059\u3002\n\u3053\u306e\u305f\u3081\u3001\u4e88\u3081glob\u30d1\u30bf\u30fc\u30f3\u306b\u5bfe\u3057\u3066\u30de\u30c3\u30c1\u3059\u308b\u30aa\u30d6\u30b8\u30a7\u30af\u30c8\u304c\u5b58\u5728\u3059\u308b\u304b\u3092\u78ba\u8a8d\u3059\u308b\u5fc5\u8981\u304c\u3042\u308a\u307e\u3059\u3002\n\u3053\u308c\u306f org.apache.hadoop.fs \u30d1\u30c3\u30b1\u30fc\u30b8\u3092\u5229\u7528\u3059\u308b\u3068\u5b9f\u73fe\u3067\u304d\u307e\u3059\u3002\nimport java.net.URI\nimport org.apache.hadoop.fs.{FileSystem, Path}\nimport org.apache.spark.SparkContext\nimport org.apache.spark.deploy.SparkHadoopUtil\n\ndef checkPathExists(path: String): Boolean = {\n  val fs = FileSystem.get(new URI(path), sc.hadoopConfiguration)\n  val p = new Path(path)\n  val qualified = p.makeQualified(fs.getUri, fs.getWorkingDirectory)\n  val glob = SparkHadoopUtil.get.globPathIfNecessary(qualified)\n  glob.nonEmpty && fs.exists(glob.head)\n}\n\ncheckPathExists(\"s3://mybucket/data/year=2017/month=01/day=*/\")\n// => false\n\n\n\u53c2\u8003\n\nhttps://github.com/apache/spark/blob/v2.0.2/sql/core/src/main/scala/org/apache/spark/sql/execution/datasources/DataSource.scala#L380-L391\n\nSpark\u306eDataFrameReader\u306e `json` \u30e1\u30bd\u30c3\u30c9\u306b\u306f\u3001HDFS\u3084S3\u306b\u5bfe\u3059\u308bglob\u30d1\u30bf\u30fc\u30f3\u3092\u8907\u6570\u6307\u5b9a\u3067\u304d\u307e\u3059\u3002\n\n```scala\nsqlContext.read.json(\n  \"s3://mybucket/data/year=2016/month=11/day=*/\",\n  \"s3://mybucket/data/year=2016/month=12/day=*/\",\n  \"s3://mybucket/data/year=2017/month=01/day=*/\"\n)\n```\n\n\u305f\u3060\u3057\u3001\u30de\u30c3\u30c1\u3059\u308b\u30aa\u30d6\u30b8\u30a7\u30af\u30c8\u304c\u4e00\u3064\u3082\u5b58\u5728\u3057\u306a\u3044\u3088\u3046\u306a\u30d1\u30b9\u304c\u542b\u307e\u308c\u3066\u3044\u308b\u3068\u30a8\u30e9\u30fc\u306b\u306a\u308a\u307e\u3059\u3002\n\n```\norg.apache.spark.sql.AnalysisException: Path does not exist: s3://mybucket/data/year=2017/month=01/day=*/;\n```\n\n\u4eca\u306e\u3068\u3053\u308d\u30a8\u30e9\u30fc\u3092\u7121\u8996\u3057\u3066\u5b58\u5728\u3059\u308b\u30d1\u30b9\u3060\u3051\u8aad\u307f\u51fa\u3059\u3088\u3046\u306a\u30aa\u30d7\u30b7\u30e7\u30f3\u306f\u7528\u610f\u3055\u308c\u3066\u3044\u306a\u3044\u3088\u3046\u3067\u3059\u3002\n\u3053\u306e\u305f\u3081\u3001\u4e88\u3081glob\u30d1\u30bf\u30fc\u30f3\u306b\u5bfe\u3057\u3066\u30de\u30c3\u30c1\u3059\u308b\u30aa\u30d6\u30b8\u30a7\u30af\u30c8\u304c\u5b58\u5728\u3059\u308b\u304b\u3092\u78ba\u8a8d\u3059\u308b\u5fc5\u8981\u304c\u3042\u308a\u307e\u3059\u3002\n\u3053\u308c\u306f `org.apache.hadoop.fs` \u30d1\u30c3\u30b1\u30fc\u30b8\u3092\u5229\u7528\u3059\u308b\u3068\u5b9f\u73fe\u3067\u304d\u307e\u3059\u3002\n\n```scala\nimport java.net.URI\nimport org.apache.hadoop.fs.{FileSystem, Path}\nimport org.apache.spark.SparkContext\nimport org.apache.spark.deploy.SparkHadoopUtil\n\ndef checkPathExists(path: String): Boolean = {\n  val fs = FileSystem.get(new URI(path), sc.hadoopConfiguration)\n  val p = new Path(path)\n  val qualified = p.makeQualified(fs.getUri, fs.getWorkingDirectory)\n  val glob = SparkHadoopUtil.get.globPathIfNecessary(qualified)\n  glob.nonEmpty && fs.exists(glob.head)\n}\n```\n\n```scala\ncheckPathExists(\"s3://mybucket/data/year=2017/month=01/day=*/\")\n// => false\n```\n\n### \u53c2\u8003\n\n* https://github.com/apache/spark/blob/v2.0.2/sql/core/src/main/scala/org/apache/spark/sql/execution/datasources/DataSource.scala#L380-L391\n\n", "tags": ["Spark"]}