{"context": " More than 1 year has passed since last update.\n\n\u4eca\u56de\u3084\u308b\u3053\u3068\n\u3069\u3046\u3082\u3067\u3059\u3002@akachochin\u3067\u3059\u3002\n\u524d\u56de\u8aad\u3093\u3060do_linear_fault()\u306e\u7d9a\u304d\u3067\u3059\u3002\ndo_linear_fault()\u306f\u524d\u56de\u306e\u8868\u3092\u898b\u308b\u3068\u308f\u304b\u308a\u307e\u3059\u304c\u3001\u30d0\u30c3\u30ad\u30f3\u30b0\u30b9\u30c8\u30a2\u3042\u308a/\u7269\u7406\u30e1\u30e2\u30ea\u672a\u5272\u308a\u5f53\u3066\u306e\u9818\u57df\u306b\u5bfe\u3059\u308b\u30da\u30fc\u30b8\u30d5\u30a9\u30eb\u30c8\u3092\u30cf\u30f3\u30c9\u30ea\u30f3\u30b0\u3059\u308b\u521d\u7406\u3067\u3059\u3002\nCOW\u306b\u3064\u3044\u3066\u306f\u524d\u56de\u3084\u308a\u307e\u3057\u305f\u306e\u3067\u3001\u6b8b\u308a2\u3064(Read/Shared Write)\u306b\u3064\u3044\u3066\u898b\u305f\u3044\u3068\u601d\u3044\u307e\u3059\u3002\n\n\u307e\u305a\u306f\u3001do_read_fault()\n\u30d0\u30c3\u30ad\u30f3\u30b0\u30b9\u30c8\u30a2\u3042\u308a\u306e\u9818\u57df/\u7269\u7406\u30e1\u30e2\u30ea\u672a\u5272\u4ed8/\u30a2\u30af\u30bb\u30b9read\u306e\u3068\u304d\u306b\u4ee5\u4e0b\u306e\u95a2\u6570\u304c\u547c\u3070\u308c\u307e\u3059\u3002\n\nmm/memory.c\nstatic int do_read_fault(struct mm_struct *mm, struct vm_area_struct *vma,\n    unsigned long address, pmd_t *pmd,\n    pgoff_t pgoff, unsigned int flags, pte_t orig_pte)\n{\n  /* \u7565 */\n  ret = __do_fault(vma, address, pgoff, flags, &fault_page);\n  if (unlikely(ret & (VM_FAULT_ERROR | VM_FAULT_NOPAGE | VM_FAULT_RETRY)))\n    return ret;\n\n  /* \u7565 */\n  do_set_pte(vma, address, fault_page, pte, false, false);\n  /* \u7565 */\n\n  return ret;\n}\n\n\n_do_fault()\u3067\u672c\u7b4b\u306e\u51e6\u7406\u3092\u884c\u3044\u3001\u30a2\u30c9\u30ec\u30b9\u89e3\u6c7a\u3057\u305f\u7d50\u679c\u3092do_setpte\u3067PTE\u306b\u66f8\u304d\u8fbc\u3080\u3068\u3044\u3046\u3068\u3053\u308d\u304c\u5927\u7b4b\u3060\u3068\u308f\u304b\u308a\u307e\u3059\u3002\n\n\u6b21\u306f\u3001do_shared_fault()\n\u30d0\u30c3\u30ad\u30f3\u30b0\u30b9\u30c8\u30a2\u3042\u308a\u306e\u9818\u57df/\u7269\u7406\u30e1\u30e2\u30ea\u672a\u5272\u4ed8/\u30a2\u30af\u30bb\u30b9write\u306e\u3068\u304d\u306b\u4ee5\u4e0b\u306e\u95a2\u6570\u304c\u547c\u3070\u308c\u307e\u3059\u3002\n\u30d0\u30c3\u30ad\u30f3\u30b0\u30b9\u30c8\u30a2\u3092\u5171\u6709\u3057\u3066\u3044\u308b\u306e\u3067\u3001\u66f8\u3044\u305f\u5185\u5bb9\u306f\u4ed6\u306e\u5171\u6709\u8005\u304b\u3089\u3082\u898b\u3048\u308b\u3053\u3068\u306b\u306a\u308a\u307e\u3059\u3002\u306a\u306e\u3067\u300cshared\u300d\u306a\u306e\u3067\u3059\u3002\u3053\u306e\u70b9\u304cCOW\u3068\u9055\u3046\u3068\u3053\u308d\u3067\u3059\u3002\n\nmm/memory.c\nstatic int do_shared_fault(struct mm_struct *mm, struct vm_area_struct *vma,\n    unsigned long address, pmd_t *pmd,\n    pgoff_t pgoff, unsigned int flags, pte_t orig_pte)\n{\n  /* \u7565 */\n  ret = __do_fault(vma, address, pgoff, flags, &fault_page);\n  if (unlikely(ret & (VM_FAULT_ERROR | VM_FAULT_NOPAGE | VM_FAULT_RETRY)))\n    return ret;\n\n  /*\n   * Check if the backing address space wants to know that the page is\n   * about to become writable\n   */\n  /* \u30d0\u30c3\u30ad\u30f3\u30b0\u30b9\u30c8\u30a2\u304cpage_mkwrite\u3068\u3044\u3046I/F\u3092\u6301\u3064\u5834\u5408\u3001\u305d\u308c\u3092\n   * do_page_mkwrite()\u3067\u547c\u3073\u51fa\u3059\u3002\n   * page_mkwrite\u306f\u300c\u30da\u30fc\u30b8\u304c\u66f8\u304d\u8fbc\u307f\u53ef\u80fd\u306b\u306a\u308b\u3053\u3068\u3092\u901a\u77e5\u3059\u308b\u3053\u3068\n   * \u3067\u30d0\u30c3\u30ad\u30f3\u30b0\u30b9\u30c8\u30a2\u5074\u3067\u5fc5\u8981\u306a\u51e6\u7406\u3092\u3055\u305b\u305f\u308a\u62d2\u5426\u3055\u305b\u305f\u308a\u3059\u308b\u300d\n   * \u305f\u3081\u306eI/F\u3002\u8a73\u7d30\u306fmm/memory.c\u306edo_page_mkwrite()\u53c2\u7167\u3002\n   */\n  if (vma->vm_ops->page_mkwrite) {\n    unlock_page(fault_page);\n    tmp = do_page_mkwrite(vma, fault_page, address);\n    if (unlikely(!tmp ||\n        (tmp & (VM_FAULT_ERROR | VM_FAULT_NOPAGE)))) {\n      page_cache_release(fault_page);\n      return tmp;\n    }\n  }\n\n  /* \u7565 */\n  do_set_pte(vma, address, fault_page, pte, true, false);\n  pte_unmap_unlock(pte, ptl);\n\n  if (set_page_dirty(fault_page))\n    dirtied = 1;\n  mapping = fault_page->mapping;\n  unlock_page(fault_page);\n  /* \u7565 */\n  /* file_update_time outside page_lock */\n  /* \u30d0\u30c3\u30ad\u30f3\u30b0\u30b9\u30c8\u30a2\u306bpage_mkwrite()\u304c\u306a\u3044\u5834\u5408\u3001\u30d0\u30c3\u30ad\u30f3\u30b0\u30b9\u30c8\u30a2\n   * \u306b\u901a\u77e5\u304c\u3067\u304d\u306a\u3044\u306e\u3067\u3001\u305b\u3081\u3066\u66f4\u65b0\u6642\u523b\u3060\u3051\u3067\u3082\u5909\u66f4\u3059\u308b\n   */\n  if (vma->vm_file && !vma->vm_ops->page_mkwrite)\n    file_update_time(vma->vm_file);\n\n  return ret;\n}\n\n\n\u5148\u306edo_read_fault()\u3082do_shared_fault()\u3082\u809d\u5fc3\u306a\u3068\u3053\u308d\u306f__do_fault()\u3067\u5b9f\u65bd\u3057\u3066\u3044\u308b\u3088\u3046\u3060\u3002\n\n__do_fault()\n\u3088\u3063\u3066\u3001__do_fault()\u3092\u898b\u308b\u3002\n\nmm/fault.c\nstatic int __do_fault(struct vm_area_struct *vma, unsigned long address,\n    pgoff_t pgoff, unsigned int flags, struct page **page)\n{\n  struct vm_fault vmf;\n  int ret;\n\n  vmf.virtual_address = (void __user *)(address & PAGE_MASK);\n  vmf.pgoff = pgoff;\n  vmf.flags = flags;\n  vmf.page = NULL;\n\n  ret = vma->vm_ops->fault(vma, &vmf);\n  if (unlikely(ret & (VM_FAULT_ERROR | VM_FAULT_NOPAGE | VM_FAULT_RETRY)))\n    return ret; \n\n  if (unlikely(PageHWPoison(vmf.page))) {\n    if (ret & VM_FAULT_LOCKED)\n      unlock_page(vmf.page);\n    page_cache_release(vmf.page);\n    return VM_FAULT_HWPOISON;\n  }\n\n  if (unlikely(!(ret & VM_FAULT_LOCKED)))\n    lock_page(vmf.page);\n  else\n    VM_BUG_ON_PAGE(!PageLocked(vmf.page), vmf.page);\n\n  *page = vmf.page;\n  return ret;\n}\n\n\n\u809d\u5fc3\u306e\u3068\u3053\u308d\u306f\u3001\u30d5\u30a1\u30a4\u30eb\u306e\u30da\u30fc\u30b8\u30e3(vma->vm_ops->fault)\u6b21\u7b2c\u3068\u3044\u3046\u3053\u3068\u304c\u308f\u304b\u308a\u307e\u3059\u3002\n\u30d0\u30c3\u30ad\u30f3\u30b0\u30b9\u30c8\u30a2\u306f\u5404\u30d5\u30a1\u30a4\u30eb\u7a2e\u5225(Regular file\u3068\u304bShared memory\u306a\u3069)\u3054\u3068\u306b\u51e6\u7406\u304c\u9055\u3046\u305f\u3081\u306b\u3053\u306e\u3088\u3046\u306a\u3053\u3068\u306b\u306a\u3063\u3066\u3044\u307e\u3059\u3002\n\n\u6b21\u56de\n\u4e26\u884c\u3067Anonymous Memory(\u30d0\u30c3\u30ad\u30f3\u30b0\u30b9\u30c8\u30a2\u306a\u3057)\u306e\u9818\u57df/\u7269\u7406\u30e1\u30e2\u30ea\u672a\u5272\u4ed8\u306e\u30b1\u30fc\u30b9\u3001\u3064\u307e\u308ado_anonymous_page()\u3092\u8aad\u307f\u307e\u3059\u3002\n## \u4eca\u56de\u3084\u308b\u3053\u3068\n\u3069\u3046\u3082\u3067\u3059\u3002@akachochin\u3067\u3059\u3002\n[\u524d\u56de](http://qiita.com/akachochin/items/e7ffdca00c00d322022a)\u8aad\u3093\u3060do_linear_fault()\u306e\u7d9a\u304d\u3067\u3059\u3002\ndo_linear_fault()\u306f\u524d\u56de\u306e\u8868\u3092\u898b\u308b\u3068\u308f\u304b\u308a\u307e\u3059\u304c\u3001\u30d0\u30c3\u30ad\u30f3\u30b0\u30b9\u30c8\u30a2\u3042\u308a/\u7269\u7406\u30e1\u30e2\u30ea\u672a\u5272\u308a\u5f53\u3066\u306e\u9818\u57df\u306b\u5bfe\u3059\u308b\u30da\u30fc\u30b8\u30d5\u30a9\u30eb\u30c8\u3092\u30cf\u30f3\u30c9\u30ea\u30f3\u30b0\u3059\u308b\u521d\u7406\u3067\u3059\u3002\n\nCOW\u306b\u3064\u3044\u3066\u306f\u524d\u56de\u3084\u308a\u307e\u3057\u305f\u306e\u3067\u3001\u6b8b\u308a2\u3064(Read/Shared Write)\u306b\u3064\u3044\u3066\u898b\u305f\u3044\u3068\u601d\u3044\u307e\u3059\u3002\n\n\n## \u307e\u305a\u306f\u3001do_read_fault()\n\u30d0\u30c3\u30ad\u30f3\u30b0\u30b9\u30c8\u30a2\u3042\u308a\u306e\u9818\u57df/\u7269\u7406\u30e1\u30e2\u30ea\u672a\u5272\u4ed8/\u30a2\u30af\u30bb\u30b9read\u306e\u3068\u304d\u306b\u4ee5\u4e0b\u306e\u95a2\u6570\u304c\u547c\u3070\u308c\u307e\u3059\u3002\n\n```c:mm/memory.c\nstatic int do_read_fault(struct mm_struct *mm, struct vm_area_struct *vma,\n    unsigned long address, pmd_t *pmd,\n    pgoff_t pgoff, unsigned int flags, pte_t orig_pte)\n{\n  /* \u7565 */\n  ret = __do_fault(vma, address, pgoff, flags, &fault_page);\n  if (unlikely(ret & (VM_FAULT_ERROR | VM_FAULT_NOPAGE | VM_FAULT_RETRY)))\n    return ret;\n\n  /* \u7565 */\n  do_set_pte(vma, address, fault_page, pte, false, false);\n  /* \u7565 */\n\n  return ret;\n}\n```\n\n__do_fault()\u3067\u672c\u7b4b\u306e\u51e6\u7406\u3092\u884c\u3044\u3001\u30a2\u30c9\u30ec\u30b9\u89e3\u6c7a\u3057\u305f\u7d50\u679c\u3092do_set_pte\u3067PTE\u306b\u66f8\u304d\u8fbc\u3080\u3068\u3044\u3046\u3068\u3053\u308d\u304c\u5927\u7b4b\u3060\u3068\u308f\u304b\u308a\u307e\u3059\u3002\n\n## \u6b21\u306f\u3001do_shared_fault()\n\u30d0\u30c3\u30ad\u30f3\u30b0\u30b9\u30c8\u30a2\u3042\u308a\u306e\u9818\u57df/\u7269\u7406\u30e1\u30e2\u30ea\u672a\u5272\u4ed8/\u30a2\u30af\u30bb\u30b9write\u306e\u3068\u304d\u306b\u4ee5\u4e0b\u306e\u95a2\u6570\u304c\u547c\u3070\u308c\u307e\u3059\u3002\n\u30d0\u30c3\u30ad\u30f3\u30b0\u30b9\u30c8\u30a2\u3092\u5171\u6709\u3057\u3066\u3044\u308b\u306e\u3067\u3001\u66f8\u3044\u305f\u5185\u5bb9\u306f\u4ed6\u306e\u5171\u6709\u8005\u304b\u3089\u3082\u898b\u3048\u308b\u3053\u3068\u306b\u306a\u308a\u307e\u3059\u3002\u306a\u306e\u3067\u300cshared\u300d\u306a\u306e\u3067\u3059\u3002\u3053\u306e\u70b9\u304cCOW\u3068\u9055\u3046\u3068\u3053\u308d\u3067\u3059\u3002\n\n```c:mm/memory.c\nstatic int do_shared_fault(struct mm_struct *mm, struct vm_area_struct *vma,\n    unsigned long address, pmd_t *pmd,\n    pgoff_t pgoff, unsigned int flags, pte_t orig_pte)\n{\n  /* \u7565 */\n  ret = __do_fault(vma, address, pgoff, flags, &fault_page);\n  if (unlikely(ret & (VM_FAULT_ERROR | VM_FAULT_NOPAGE | VM_FAULT_RETRY)))\n    return ret;\n\n  /*\n   * Check if the backing address space wants to know that the page is\n   * about to become writable\n   */\n  /* \u30d0\u30c3\u30ad\u30f3\u30b0\u30b9\u30c8\u30a2\u304cpage_mkwrite\u3068\u3044\u3046I/F\u3092\u6301\u3064\u5834\u5408\u3001\u305d\u308c\u3092\n   * do_page_mkwrite()\u3067\u547c\u3073\u51fa\u3059\u3002\n   * page_mkwrite\u306f\u300c\u30da\u30fc\u30b8\u304c\u66f8\u304d\u8fbc\u307f\u53ef\u80fd\u306b\u306a\u308b\u3053\u3068\u3092\u901a\u77e5\u3059\u308b\u3053\u3068\n   * \u3067\u30d0\u30c3\u30ad\u30f3\u30b0\u30b9\u30c8\u30a2\u5074\u3067\u5fc5\u8981\u306a\u51e6\u7406\u3092\u3055\u305b\u305f\u308a\u62d2\u5426\u3055\u305b\u305f\u308a\u3059\u308b\u300d\n   * \u305f\u3081\u306eI/F\u3002\u8a73\u7d30\u306fmm/memory.c\u306edo_page_mkwrite()\u53c2\u7167\u3002\n   */\n  if (vma->vm_ops->page_mkwrite) {\n    unlock_page(fault_page);\n    tmp = do_page_mkwrite(vma, fault_page, address);\n    if (unlikely(!tmp ||\n        (tmp & (VM_FAULT_ERROR | VM_FAULT_NOPAGE)))) {\n      page_cache_release(fault_page);\n      return tmp;\n    }\n  }\n\n  /* \u7565 */\n  do_set_pte(vma, address, fault_page, pte, true, false);\n  pte_unmap_unlock(pte, ptl);\n\n  if (set_page_dirty(fault_page))\n    dirtied = 1;\n  mapping = fault_page->mapping;\n  unlock_page(fault_page);\n  /* \u7565 */\n  /* file_update_time outside page_lock */\n  /* \u30d0\u30c3\u30ad\u30f3\u30b0\u30b9\u30c8\u30a2\u306bpage_mkwrite()\u304c\u306a\u3044\u5834\u5408\u3001\u30d0\u30c3\u30ad\u30f3\u30b0\u30b9\u30c8\u30a2\n   * \u306b\u901a\u77e5\u304c\u3067\u304d\u306a\u3044\u306e\u3067\u3001\u305b\u3081\u3066\u66f4\u65b0\u6642\u523b\u3060\u3051\u3067\u3082\u5909\u66f4\u3059\u308b\n   */\n  if (vma->vm_file && !vma->vm_ops->page_mkwrite)\n    file_update_time(vma->vm_file);\n\n  return ret;\n}\n```\n\n\u5148\u306edo_read_fault()\u3082do_shared_fault()\u3082\u809d\u5fc3\u306a\u3068\u3053\u308d\u306f__do_fault()\u3067\u5b9f\u65bd\u3057\u3066\u3044\u308b\u3088\u3046\u3060\u3002\n\n## __do_fault()\n\u3088\u3063\u3066\u3001__do_fault()\u3092\u898b\u308b\u3002\n\n```c:mm/fault.c\nstatic int __do_fault(struct vm_area_struct *vma, unsigned long address,\n    pgoff_t pgoff, unsigned int flags, struct page **page)\n{\n  struct vm_fault vmf;\n  int ret;\n\n  vmf.virtual_address = (void __user *)(address & PAGE_MASK);\n  vmf.pgoff = pgoff;\n  vmf.flags = flags;\n  vmf.page = NULL;\n\n  ret = vma->vm_ops->fault(vma, &vmf);\n  if (unlikely(ret & (VM_FAULT_ERROR | VM_FAULT_NOPAGE | VM_FAULT_RETRY)))\n    return ret; \n\n  if (unlikely(PageHWPoison(vmf.page))) {\n    if (ret & VM_FAULT_LOCKED)\n      unlock_page(vmf.page);\n    page_cache_release(vmf.page);\n    return VM_FAULT_HWPOISON;\n  }\n\n  if (unlikely(!(ret & VM_FAULT_LOCKED)))\n    lock_page(vmf.page);\n  else\n    VM_BUG_ON_PAGE(!PageLocked(vmf.page), vmf.page);\n\n  *page = vmf.page;\n  return ret;\n}\n```\n\n\u809d\u5fc3\u306e\u3068\u3053\u308d\u306f\u3001\u30d5\u30a1\u30a4\u30eb\u306e\u30da\u30fc\u30b8\u30e3(vma->vm_ops->fault)\u6b21\u7b2c\u3068\u3044\u3046\u3053\u3068\u304c\u308f\u304b\u308a\u307e\u3059\u3002\n\u30d0\u30c3\u30ad\u30f3\u30b0\u30b9\u30c8\u30a2\u306f\u5404\u30d5\u30a1\u30a4\u30eb\u7a2e\u5225(Regular file\u3068\u304bShared memory\u306a\u3069)\u3054\u3068\u306b\u51e6\u7406\u304c\u9055\u3046\u305f\u3081\u306b\u3053\u306e\u3088\u3046\u306a\u3053\u3068\u306b\u306a\u3063\u3066\u3044\u307e\u3059\u3002\n\n## \u6b21\u56de\n\u4e26\u884c\u3067Anonymous Memory(\u30d0\u30c3\u30ad\u30f3\u30b0\u30b9\u30c8\u30a2\u306a\u3057)\u306e\u9818\u57df/\u7269\u7406\u30e1\u30e2\u30ea\u672a\u5272\u4ed8\u306e\u30b1\u30fc\u30b9\u3001\u3064\u307e\u308ado_anonymous_page()\u3092\u8aad\u307f\u307e\u3059\u3002\n\n", "tags": ["Linux", "\u4eee\u60f3\u8a18\u61b6", "kernel", "kernelvm"]}