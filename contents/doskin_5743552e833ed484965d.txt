{"context": " More than 1 year has passed since last update.\n\n\u74b0\u5883\nOS X 10.8.4\nHadoop 1.2.1\n\u7591\u4f3c\u5206\u6563\u30e2\u30fc\u30c9\n\nhttps://github.com/tomwhite/hadoop-book \u304b\u3089 \u30b5\u30f3\u30d7\u30eb\u30b3\u30fc\u30c9\u3092\u30c0\u30a6\u30f3\u30ed\u30fc\u30c9\u3059\u308b\n\u30c0\u30a6\u30f3\u30ed\u30fc\u30c9\u3057\u305f\u30d5\u30a9\u30eb\u30c0\u306b\u79fb\u52d5\u3057\u3066\u3001\u81ea\u5206\u306e hadoop version \u306b\u5408\u308f\u305b\u3066\u3001\nhadoop-meta/pom.xml \u3092\u66f8\u304d\u63db\u3048\u308b\n 32       <activation>\n 33         <property>\n 34           <name>hadoop.version</name>\n 35           <value>1.2.1</value>\n 36         </property>\n 37       </activation>\n 38       <properties>\n 39         <hadoop.version>1.2.1</hadoop.version>\n\n\u4e0a\u306e\u4f8b\u3067\u306f 35 \u884c\u76ee  \u3068 39 \u884c\u76ee  \u3092\u81ea\u5206\u306e hadoo \u306e\u30d0\u30fc\u30b8\u30e7\u30f3\u306b\u5408\u308f\u305b\u3066\u66f8\u304d\u63db\u3048\u308b\n\n\u30b3\u30f3\u30d1\u30a4\u30eb\n# move to the folder corresponding to chapter\ncd ch02\nmvn package -DskipTests -Dhadoop.version=1.1.2\n\nch02/target/ch02-3.0.jar \u304c\u4f5c\u6210\u3055\u308c\u308b\n.jar \u306e\u540d\u524d\u306f ch02/pom.xml \u3067\u6307\u5b9a\u3055\u308c\u308b\n 11   <artifactId>ch02</artifactId>\n 12   <packaging>jar</packaging>\n 13   <version>3.0</version>\n\n\n\u5b9f\u884c\nch02-03.jar \u306e\u30af\u30e9\u30b9\u30d1\u30b9\u3092\u6307\u5b9a\u3059\u308b\u3057\u3066\u3001MaxTemperature \u3092\u5b9f\u884c\u3059\u308b\nexport HADOOP_CLASSPATH=ch02/target/ch02-3.0.jar\nhadoop MaxTemperature input/ncdc/sample.txt output\n\n\u3067\u4ee5\u4e0b\u306e\u30a8\u30e9\u30fc\u304c\u51fa\u305f...\n13/09/15 13:14:06 WARN util.NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n13/09/15 13:14:06 WARN mapred.JobClient: Use GenericOptionsParser for parsing the arguments. Applications should implement Tool for the same.\n13/09/15 13:14:06 INFO mapred.JobClient: Cleaning up the staging area file:/tmp/hadoop-cinemania/mapred/staging/cinemania2105296101/.staging/job_local2105296101_0001\n13/09/15 13:14:06 ERROR security.UserGroupInformation: PriviledgedActionException as:cinemania cause:org.apache.hadoop.mapreduce.lib.input.InvalidInputException: Input path does not exist: hdfs://localhost/user/cinemania/input/ncdc/sample.txt\nException in thread \"main\" org.apache.hadoop.mapreduce.lib.input.InvalidInputException: Input path does not exist: hdfs://localhost/user/cinemania/input/ncdc/sample.txt\n    at org.apache.hadoop.mapreduce.lib.input.FileInputFormat.listStatus(FileInputFormat.java:235)\n    at org.apache.hadoop.mapreduce.lib.input.FileInputFormat.getSplits(FileInputFormat.java:252)\n    at org.apache.hadoop.mapred.JobClient.writeNewSplits(JobClient.java:1054)\n    at org.apache.hadoop.mapred.JobClient.writeSplits(JobClient.java:1071)\n    at org.apache.hadoop.mapred.JobClient.access$700(JobClient.java:179)\n    at org.apache.hadoop.mapred.JobClient$2.run(JobClient.java:983)\n    at org.apache.hadoop.mapred.JobClient$2.run(JobClient.java:936)\n    at java.security.AccessController.doPrivileged(Native Method)\n    at javax.security.auth.Subject.doAs(Subject.java:396)\n    at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1190)\n    at org.apache.hadoop.mapred.JobClient.submitJobInternal(JobClient.java:936)\n    at org.apache.hadoop.mapreduce.Job.submit(Job.java:550)\n    at org.apache.hadoop.mapreduce.Job.waitForCompletion(Job.java:580)\n    at MaxTemperature.main(MaxTemperature.java:31)\n\norg.apache.hadoop.mapreduce.lib.input.InvalidInputException: Input path does not exist: hdfs://localhost/user/cinemania/input/ncdc/sample.txt\nhdfs \u306b input \u30d5\u30a1\u30a4\u30eb\u304c\u7121\u3044\u3068\u8b66\u544a\u3055\u308c\u305f\u306e\u3067\u3001\u30d5\u30a1\u30a4\u30eb\u3092\u30a2\u30c3\u30d7\u30ed\u30fc\u30c9\u3059\u308b\nhadoop fs -copyFromLocal input/ncdc/sample.txt hdfs://localhost/user/cinemania/input/ncdc/sample.txt\n\n\u518d\u5ea6 hadoop MaxTemperature input/ncdc/sample.txt output\n\u4e0b\u8a18\u306e Log \u304c\u51fa\u3066\u6210\u529f\n13/09/15 21:51:52 WARN util.NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n13/09/15 21:51:52 WARN mapred.JobClient: Use GenericOptionsParser for parsing the arguments. Applications should implement Tool for the same.\n13/09/15 21:51:52 INFO input.FileInputFormat: Total input paths to process : 1\n13/09/15 21:51:53 INFO mapred.JobClient: Running job: job_local788403347_0001\n13/09/15 21:51:53 INFO mapred.LocalJobRunner: Waiting for map tasks\n13/09/15 21:51:53 INFO mapred.LocalJobRunner: Starting task: attempt_local788403347_0001_m_000000_0\n13/09/15 21:51:53 INFO mapred.Task:  Using ResourceCalculatorPlugin : null\n13/09/15 21:51:53 INFO mapred.MapTask: Processing split: hdfs://localhost/user/root/input/ncdc/sample.txt:0+0\n13/09/15 21:51:53 INFO mapred.MapTask: io.sort.mb = 100\n13/09/15 21:51:53 INFO mapred.MapTask: data buffer = 79691776/99614720\n13/09/15 21:51:53 INFO mapred.MapTask: record buffer = 262144/327680\n13/09/15 21:51:53 WARN snappy.LoadSnappy: Snappy native library not loaded\n13/09/15 21:51:53 INFO mapred.MapTask: Starting flush of map output\n13/09/15 21:51:53 INFO mapred.Task: Task:attempt_local788403347_0001_m_000000_0 is done. And is in the process of commiting\n13/09/15 21:51:53 INFO mapred.LocalJobRunner: \n13/09/15 21:51:53 INFO mapred.Task: Task 'attempt_local788403347_0001_m_000000_0' done.\n13/09/15 21:51:53 INFO mapred.LocalJobRunner: Finishing task: attempt_local788403347_0001_m_000000_0\n13/09/15 21:51:53 INFO mapred.LocalJobRunner: Map task executor complete.\n13/09/15 21:51:53 INFO mapred.Task:  Using ResourceCalculatorPlugin : null\n13/09/15 21:51:53 INFO mapred.LocalJobRunner: \n13/09/15 21:51:53 INFO mapred.Merger: Merging 1 sorted segments\n13/09/15 21:51:53 INFO mapred.Merger: Down to the last merge-pass, with 0 segments left of total size: 0 bytes\n13/09/15 21:51:53 INFO mapred.LocalJobRunner: \n13/09/15 21:51:53 INFO mapred.Task: Task:attempt_local788403347_0001_r_000000_0 is done. And is in the process of commiting\n13/09/15 21:51:53 INFO mapred.LocalJobRunner: \n13/09/15 21:51:53 INFO mapred.Task: Task attempt_local788403347_0001_r_000000_0 is allowed to commit now\n13/09/15 21:51:53 INFO output.FileOutputCommitter: Saved output of task 'attempt_local788403347_0001_r_000000_0' to output\n13/09/15 21:51:53 INFO mapred.LocalJobRunner: reduce > reduce\n13/09/15 21:51:53 INFO mapred.Task: Task 'attempt_local788403347_0001_r_000000_0' done.\n13/09/15 21:51:54 INFO mapred.JobClient:  map 0% reduce 100%\n13/09/15 21:51:54 INFO mapred.JobClient: Job complete: job_local788403347_0001\n13/09/15 21:51:54 INFO mapred.JobClient: Counters: 17\n13/09/15 21:51:54 INFO mapred.JobClient:   File Output Format Counters \n13/09/15 21:51:54 INFO mapred.JobClient:     Bytes Written=0\n13/09/15 21:51:54 INFO mapred.JobClient:   File Input Format Counters \n13/09/15 21:51:54 INFO mapred.JobClient:     Bytes Read=0\n13/09/15 21:51:54 INFO mapred.JobClient:   FileSystemCounters\n13/09/15 21:51:54 INFO mapred.JobClient:     FILE_BYTES_READ=26788\n13/09/15 21:51:54 INFO mapred.JobClient:     FILE_BYTES_WRITTEN=162688\n13/09/15 21:51:54 INFO mapred.JobClient:   Map-Reduce Framework\n13/09/15 21:51:54 INFO mapred.JobClient:     Map output materialized bytes=6\n13/09/15 21:51:54 INFO mapred.JobClient:     Map input records=0\n13/09/15 21:51:54 INFO mapred.JobClient:     Reduce shuffle bytes=0\n13/09/15 21:51:54 INFO mapred.JobClient:     Spilled Records=0\n13/09/15 21:51:54 INFO mapred.JobClient:     Map output bytes=0\n13/09/15 21:51:54 INFO mapred.JobClient:     Total committed heap usage (bytes)=369238016\n13/09/15 21:51:54 INFO mapred.JobClient:     Combine input records=0\n13/09/15 21:51:54 INFO mapred.JobClient:     SPLIT_RAW_BYTES=113\n13/09/15 21:51:54 INFO mapred.JobClient:     Reduce input records=0\n13/09/15 21:51:54 INFO mapred.JobClient:     Reduce input groups=0\n13/09/15 21:51:54 INFO mapred.JobClient:     Combine output records=0\n13/09/15 21:51:54 INFO mapred.JobClient:     Reduce output records=0\n13/09/15 21:51:54 INFO mapred.JobClient:     Map output records=0\n\n\u7d50\u679c\u306f localhost:50070\u304b\u3089\u78ba\u8a8d\u51fa\u6765\u308b\n###\u74b0\u5883\n```\nOS X 10.8.4\nHadoop 1.2.1\n\u7591\u4f3c\u5206\u6563\u30e2\u30fc\u30c9\n```\n\n`https://github.com/tomwhite/hadoop-book` \u304b\u3089 \u30b5\u30f3\u30d7\u30eb\u30b3\u30fc\u30c9\u3092\u30c0\u30a6\u30f3\u30ed\u30fc\u30c9\u3059\u308b\n\n\u30c0\u30a6\u30f3\u30ed\u30fc\u30c9\u3057\u305f\u30d5\u30a9\u30eb\u30c0\u306b\u79fb\u52d5\u3057\u3066\u3001\u81ea\u5206\u306e hadoop version \u306b\u5408\u308f\u305b\u3066\u3001\nhadoop-meta/pom.xml \u3092\u66f8\u304d\u63db\u3048\u308b\n\n```\n 32       <activation>\n 33         <property>\n 34           <name>hadoop.version</name>\n 35           <value>1.2.1</value>\n 36         </property>\n 37       </activation>\n 38       <properties>\n 39         <hadoop.version>1.2.1</hadoop.version>\n```\n\u4e0a\u306e\u4f8b\u3067\u306f 35 \u884c\u76ee <value> \u3068 39 \u884c\u76ee <hadoop.version> \u3092\u81ea\u5206\u306e hadoo \u306e\u30d0\u30fc\u30b8\u30e7\u30f3\u306b\u5408\u308f\u305b\u3066\u66f8\u304d\u63db\u3048\u308b\n\n###\u30b3\u30f3\u30d1\u30a4\u30eb\n```\n# move to the folder corresponding to chapter\ncd ch02\nmvn package -DskipTests -Dhadoop.version=1.1.2\n```\n\n```ch02/target/ch02-3.0.jar``` \u304c\u4f5c\u6210\u3055\u308c\u308b\n\n.jar \u306e\u540d\u524d\u306f ch02/pom.xml \u3067\u6307\u5b9a\u3055\u308c\u308b\n\n```\n 11   <artifactId>ch02</artifactId>\n 12   <packaging>jar</packaging>\n 13   <version>3.0</version>\n```\n\n###\u5b9f\u884c\nch02-03.jar \u306e\u30af\u30e9\u30b9\u30d1\u30b9\u3092\u6307\u5b9a\u3059\u308b\u3057\u3066\u3001MaxTemperature \u3092\u5b9f\u884c\u3059\u308b\n\n```\nexport HADOOP_CLASSPATH=ch02/target/ch02-3.0.jar\nhadoop MaxTemperature input/ncdc/sample.txt output\n```\n\n\u3067\u4ee5\u4e0b\u306e\u30a8\u30e9\u30fc\u304c\u51fa\u305f...\n\n```\n13/09/15 13:14:06 WARN util.NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n13/09/15 13:14:06 WARN mapred.JobClient: Use GenericOptionsParser for parsing the arguments. Applications should implement Tool for the same.\n13/09/15 13:14:06 INFO mapred.JobClient: Cleaning up the staging area file:/tmp/hadoop-cinemania/mapred/staging/cinemania2105296101/.staging/job_local2105296101_0001\n13/09/15 13:14:06 ERROR security.UserGroupInformation: PriviledgedActionException as:cinemania cause:org.apache.hadoop.mapreduce.lib.input.InvalidInputException: Input path does not exist: hdfs://localhost/user/cinemania/input/ncdc/sample.txt\nException in thread \"main\" org.apache.hadoop.mapreduce.lib.input.InvalidInputException: Input path does not exist: hdfs://localhost/user/cinemania/input/ncdc/sample.txt\n\tat org.apache.hadoop.mapreduce.lib.input.FileInputFormat.listStatus(FileInputFormat.java:235)\n\tat org.apache.hadoop.mapreduce.lib.input.FileInputFormat.getSplits(FileInputFormat.java:252)\n\tat org.apache.hadoop.mapred.JobClient.writeNewSplits(JobClient.java:1054)\n\tat org.apache.hadoop.mapred.JobClient.writeSplits(JobClient.java:1071)\n\tat org.apache.hadoop.mapred.JobClient.access$700(JobClient.java:179)\n\tat org.apache.hadoop.mapred.JobClient$2.run(JobClient.java:983)\n\tat org.apache.hadoop.mapred.JobClient$2.run(JobClient.java:936)\n\tat java.security.AccessController.doPrivileged(Native Method)\n\tat javax.security.auth.Subject.doAs(Subject.java:396)\n\tat org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1190)\n\tat org.apache.hadoop.mapred.JobClient.submitJobInternal(JobClient.java:936)\n\tat org.apache.hadoop.mapreduce.Job.submit(Job.java:550)\n\tat org.apache.hadoop.mapreduce.Job.waitForCompletion(Job.java:580)\n\tat MaxTemperature.main(MaxTemperature.java:31)\n```\n\n`org.apache.hadoop.mapreduce.lib.input.InvalidInputException: Input path does not exist: hdfs://localhost/user/cinemania/input/ncdc/sample.txt`\n\nhdfs \u306b input \u30d5\u30a1\u30a4\u30eb\u304c\u7121\u3044\u3068\u8b66\u544a\u3055\u308c\u305f\u306e\u3067\u3001\u30d5\u30a1\u30a4\u30eb\u3092\u30a2\u30c3\u30d7\u30ed\u30fc\u30c9\u3059\u308b\n\n```\nhadoop fs -copyFromLocal input/ncdc/sample.txt hdfs://localhost/user/cinemania/input/ncdc/sample.txt\n```\n\n\u518d\u5ea6 `hadoop MaxTemperature input/ncdc/sample.txt output`\n\n\u4e0b\u8a18\u306e Log \u304c\u51fa\u3066\u6210\u529f\n\n```\n13/09/15 21:51:52 WARN util.NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n13/09/15 21:51:52 WARN mapred.JobClient: Use GenericOptionsParser for parsing the arguments. Applications should implement Tool for the same.\n13/09/15 21:51:52 INFO input.FileInputFormat: Total input paths to process : 1\n13/09/15 21:51:53 INFO mapred.JobClient: Running job: job_local788403347_0001\n13/09/15 21:51:53 INFO mapred.LocalJobRunner: Waiting for map tasks\n13/09/15 21:51:53 INFO mapred.LocalJobRunner: Starting task: attempt_local788403347_0001_m_000000_0\n13/09/15 21:51:53 INFO mapred.Task:  Using ResourceCalculatorPlugin : null\n13/09/15 21:51:53 INFO mapred.MapTask: Processing split: hdfs://localhost/user/root/input/ncdc/sample.txt:0+0\n13/09/15 21:51:53 INFO mapred.MapTask: io.sort.mb = 100\n13/09/15 21:51:53 INFO mapred.MapTask: data buffer = 79691776/99614720\n13/09/15 21:51:53 INFO mapred.MapTask: record buffer = 262144/327680\n13/09/15 21:51:53 WARN snappy.LoadSnappy: Snappy native library not loaded\n13/09/15 21:51:53 INFO mapred.MapTask: Starting flush of map output\n13/09/15 21:51:53 INFO mapred.Task: Task:attempt_local788403347_0001_m_000000_0 is done. And is in the process of commiting\n13/09/15 21:51:53 INFO mapred.LocalJobRunner: \n13/09/15 21:51:53 INFO mapred.Task: Task 'attempt_local788403347_0001_m_000000_0' done.\n13/09/15 21:51:53 INFO mapred.LocalJobRunner: Finishing task: attempt_local788403347_0001_m_000000_0\n13/09/15 21:51:53 INFO mapred.LocalJobRunner: Map task executor complete.\n13/09/15 21:51:53 INFO mapred.Task:  Using ResourceCalculatorPlugin : null\n13/09/15 21:51:53 INFO mapred.LocalJobRunner: \n13/09/15 21:51:53 INFO mapred.Merger: Merging 1 sorted segments\n13/09/15 21:51:53 INFO mapred.Merger: Down to the last merge-pass, with 0 segments left of total size: 0 bytes\n13/09/15 21:51:53 INFO mapred.LocalJobRunner: \n13/09/15 21:51:53 INFO mapred.Task: Task:attempt_local788403347_0001_r_000000_0 is done. And is in the process of commiting\n13/09/15 21:51:53 INFO mapred.LocalJobRunner: \n13/09/15 21:51:53 INFO mapred.Task: Task attempt_local788403347_0001_r_000000_0 is allowed to commit now\n13/09/15 21:51:53 INFO output.FileOutputCommitter: Saved output of task 'attempt_local788403347_0001_r_000000_0' to output\n13/09/15 21:51:53 INFO mapred.LocalJobRunner: reduce > reduce\n13/09/15 21:51:53 INFO mapred.Task: Task 'attempt_local788403347_0001_r_000000_0' done.\n13/09/15 21:51:54 INFO mapred.JobClient:  map 0% reduce 100%\n13/09/15 21:51:54 INFO mapred.JobClient: Job complete: job_local788403347_0001\n13/09/15 21:51:54 INFO mapred.JobClient: Counters: 17\n13/09/15 21:51:54 INFO mapred.JobClient:   File Output Format Counters \n13/09/15 21:51:54 INFO mapred.JobClient:     Bytes Written=0\n13/09/15 21:51:54 INFO mapred.JobClient:   File Input Format Counters \n13/09/15 21:51:54 INFO mapred.JobClient:     Bytes Read=0\n13/09/15 21:51:54 INFO mapred.JobClient:   FileSystemCounters\n13/09/15 21:51:54 INFO mapred.JobClient:     FILE_BYTES_READ=26788\n13/09/15 21:51:54 INFO mapred.JobClient:     FILE_BYTES_WRITTEN=162688\n13/09/15 21:51:54 INFO mapred.JobClient:   Map-Reduce Framework\n13/09/15 21:51:54 INFO mapred.JobClient:     Map output materialized bytes=6\n13/09/15 21:51:54 INFO mapred.JobClient:     Map input records=0\n13/09/15 21:51:54 INFO mapred.JobClient:     Reduce shuffle bytes=0\n13/09/15 21:51:54 INFO mapred.JobClient:     Spilled Records=0\n13/09/15 21:51:54 INFO mapred.JobClient:     Map output bytes=0\n13/09/15 21:51:54 INFO mapred.JobClient:     Total committed heap usage (bytes)=369238016\n13/09/15 21:51:54 INFO mapred.JobClient:     Combine input records=0\n13/09/15 21:51:54 INFO mapred.JobClient:     SPLIT_RAW_BYTES=113\n13/09/15 21:51:54 INFO mapred.JobClient:     Reduce input records=0\n13/09/15 21:51:54 INFO mapred.JobClient:     Reduce input groups=0\n13/09/15 21:51:54 INFO mapred.JobClient:     Combine output records=0\n13/09/15 21:51:54 INFO mapred.JobClient:     Reduce output records=0\n13/09/15 21:51:54 INFO mapred.JobClient:     Map output records=0\n```\n\n\u7d50\u679c\u306f `localhost:50070`\u304b\u3089\u78ba\u8a8d\u51fa\u6765\u308b", "tags": ["hadoop"]}