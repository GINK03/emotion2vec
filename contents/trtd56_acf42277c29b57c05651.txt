{"context": "\n\n\u306f\u3058\u3081\u306b\n\u524d\u56deChainer\u306e\u65b0\u6a5f\u80fd\u3001trainer\u3092\u4f7f\u3063\u3066CIFAR-10\u306e\u753b\u50cf\u5206\u985e\u306b\u6311\u6226\u3057\u3088\u3046\u3068\u3057\u305f\u306e\u3067\u3059\u304c\u3001\u30de\u30b7\u30f3\u30d1\u30ef\u30fc\u306e\u90fd\u5408\u4e0a\u3001\u52d5\u4f5c\u3092\u78ba\u8a8d\u3067\u304d\u305a\u306b\u7d42\u308f\u3063\u3066\u3057\u307e\u3044\u307e\u3057\u305f\u3002\n\u305d\u3053\u3067\u4eca\u56de\u306fMNIST\u3092\u4f7f\u3063\u305fAutoencoder\u306e\u4f5c\u6210\u3092\u901a\u3057\u3066trainer\u306e\u4f7f\u3044\u65b9\u3092\u78ba\u8a8d\u3057\u3066\u3044\u3053\u3046\u3068\u601d\u3044\u307e\u3059\u3002\nAutoencoder\u306b\u95a2\u3057\u3066\u306f\u3053\u3061\u3089\u306e\u8a18\u4e8b\u3092\u53c2\u8003\u306b\u3057\u307e\u3057\u305f\u3002\n\n\u3010\u30c7\u30a3\u30fc\u30d7\u30e9\u30fc\u30cb\u30f3\u30b0\u3011Chainer\u3067Autoencoder\u3092\u8a66\u3057\u3066\u7d50\u679c\u3092\u53ef\u8996\u5316\u3057\u3066\u307f\u308b\u3002\nChainer\u3067Deep Autoencoder\u3092\u4f5c\u3063\u3066\u307f\u308b\n\n\n\u5b9f\u88c5\nMNIST\u306e\u624b\u66f8\u304d\u6587\u5b571000\u500b\u3092\u5165\u529b\u3068\u3057\u3001\u96a0\u308c\u5c64\u30921\u5c64\u901a\u3057\u3066\u5165\u529b\u3068\u7b49\u3057\u304f\u306a\u308b\u3088\u3046\u306a\u51fa\u529b\u3092\u5f97\u308b\u30cd\u30c3\u30c8\u30ef\u30fc\u30af\u3092\u4f5c\u6210\u3057\u307e\u3059\u3002\n\u30b3\u30fc\u30c9\u5168\u4f53\u306f\u3053\u3061\u3089\u306b\u3042\u3052\u3066\u3044\u307e\u3059\u3002\n\n\u30cd\u30c3\u30c8\u30ef\u30fc\u30af\u90e8\u5206\n\u96a0\u308c\u5c64\u306e\u30e6\u30cb\u30c3\u30c8\u6570\u306f64\u307e\u3067\u7d5e\u3063\u3066\u3044\u307e\u3059\u3002\n\u307e\u305f\u3001hidden=True\u3067\u547c\u3073\u51fa\u3059\u3068\u96a0\u308c\u5c64\u3092\u51fa\u529b\u3067\u304d\u308b\u3088\u3046\u306b\u3057\u3066\u3044\u307e\u3059\u3002\nclass Autoencoder(chainer.Chain):\n    def __init__(self):\n        super(Autoencoder, self).__init__(\n                encoder = L.Linear(784, 64),\n                decoder = L.Linear(64, 784))\n\n    def __call__(self, x, hidden=False):\n        h = F.relu(self.encoder(x))\n        if hidden:\n            return h\n        else:\n            return F.relu(self.decoder(h))\n\n\n\u30c7\u30fc\u30bf\u4f5c\u6210\u90e8\u5206\nMNIST\u306e\u30c7\u30fc\u30bf\u3092\u8aad\u307f\u8fbc\u3093\u3067\u3001\u6559\u5e2b\u30c7\u30fc\u30bf\u3068\u30c6\u30b9\u30c8\u30c7\u30fc\u30bf\u3092\u4f5c\u6210\u3057\u307e\u3059\u3002\n\u6559\u5e2b\u30c7\u30fc\u30bf\u306e\u30e9\u30d9\u30eb\u306f\u5fc5\u8981\u306a\u304f\u3001\u51fa\u529b\u306f\u5165\u529b\u3068\u540c\u3058\u3082\u306e\u306b\u306a\u308b\u306e\u3067\u3001\u5c11\u3057\u30c7\u30fc\u30bf\u306e\u5f62\u3092\u3044\u3058\u3063\u3066\u3044\u307e\u3059\u3002\n# MNIST\u306e\u30c7\u30fc\u30bf\u306e\u8aad\u307f\u8fbc\u307f\ntrain, test = chainer.datasets.get_mnist()\n\n# \u6559\u5e2b\u30c7\u30fc\u30bf\ntrain = train[0:1000]\ntrain = [i[0] for i in train]\ntrain = tuple_dataset.TupleDataset(train, train)\ntrain_iter = chainer.iterators.SerialIterator(train, 100)\n\n# \u30c6\u30b9\u30c8\u7528\u30c7\u30fc\u30bf\ntest = test[0:25]\n\n\n\u30e2\u30c7\u30eb\u4f5c\u6210\nmodel = L.Classifier(Autoencoder(), lossfun=F.mean_squared_error)\nmodel.compute_accuracy = False\noptimizer = chainer.optimizers.Adam()\noptimizer.setup(model)\n\n\u3053\u3053\u3067\u6ce8\u610f\u3059\u308b\u3053\u3068\u304c2\u70b9\n\nloss\u95a2\u6570\u306e\u5b9a\u7fa9\nL.Classifier\u3067\u30e2\u30c7\u30eb\u3092\u5b9a\u7fa9\u3057\u305f\u969b\u3001\u30c7\u30d5\u30a9\u30eb\u30c8\u3067\u306floss\u95a2\u6570\u306fsoftmax_cross_entropy\u3068\u306a\u308b\u3088\u3046\u3067\u3059\u304c\u3001\u4eca\u56de\u306fmean_squared_error\u3092\u4f7f\u3044\u305f\u3044\u306e\u3067\u3001lossfun\u3067\u5b9a\u7fa9\u3057\u306a\u3051\u308c\u3070\u306a\u308a\u307e\u305b\u3093\u3002\naccuracy\u3092\u8a08\u7b97\u3057\u306a\u3044\n\u4eca\u56de\u306f\u6559\u5e2b\u30c7\u30fc\u30bf\u306b\u30e9\u30d9\u30eb\u3092\u4f7f\u308f\u306a\u3044\u306e\u3067accuracy\u306e\u8a08\u7b97\u306f\u5fc5\u8981\u3042\u308a\u307e\u305b\u3093\u3002\u306a\u306e\u3067compute_accuracy\u3092False\u306b\u3057\u3066\u304a\u304f\u5fc5\u8981\u304c\u3042\u308a\u307e\u3059\u3002\n\n\n\u5b66\u7fd2\u90e8\u5206\n\u7279\u306b\u8aac\u660e\u306e\u5fc5\u8981\u306f\u306a\u3044\u3068\u601d\u3044\u307e\u3059\u3002\ntrainer\u304c\u4f7f\u3048\u308b\u3088\u3046\u306b\u306a\u3063\u3066\u304b\u3089\u3001\u3053\u306e\u90e8\u5206\u304c\u7c21\u5358\u306b\u66f8\u3051\u308b\u3088\u3046\u306b\u306a\u3063\u3066\u52a9\u304b\u3063\u3066\u3044\u307e\u3059^^\nupdater = training.StandardUpdater(train_iter, optimizer, device=-1)\ntrainer = training.Trainer(updater, (N_EPOCH, 'epoch'), out=\"result\")\ntrainer.extend(extensions.LogReport())\ntrainer.extend(extensions.PrintReport( ['epoch', 'main/loss']))\ntrainer.extend(extensions.ProgressBar())\n\ntrainer.run()\n\n\n\u7d50\u679c\u78ba\u8a8d\n\u95a2\u6570\u3092\u4f5c\u3063\u3066matplotlib\u3067\u7d50\u679c\u3092\u30d7\u30ed\u30c3\u30c8\u3057\u307e\u3059\u3002\n\u753b\u50cf\u4e0a\u90e8\u306b\u8d64\u6587\u5b57\u3067\u5143\u306e\u30e9\u30d9\u30eb\u3092\u30d7\u30ea\u30f3\u30c8\u3057\u3066\u3044\u307e\u3059\u3002\u5ea7\u6a19\u306e\u8abf\u6574\u3092\u304d\u3061\u3093\u3068\u3057\u3066\u3044\u306a\u3044\u306e\u3067\u82e5\u5e72\u304b\u3076\u3063\u3066\u3044\u308b\u90e8\u5206\u3082\u3042\u308a\u307e\u3059\u304c...\n\u3061\u306a\u307f\u306b\u3053\u306e\u95a2\u6570\u306btest\u7528\u30c7\u30fc\u30bf\u3092\u305d\u306e\u307e\u307e\u5165\u529b\u3059\u308b\u3068\u3001\u5143\u306e\u30c7\u30fc\u30bf\u306e\u753b\u50cf\u304c\u51fa\u529b\u3055\u308c\u307e\u3059\u3002\ndef plot_mnist_data(samples):\n    for index, (data, label) in enumerate(samples):\n        plt.subplot(5, 5, index + 1)\n        plt.axis('off')\n        plt.imshow(data.reshape(28, 28), cmap=cm.gray_r, interpolation='nearest')\n        n = int(label)\n        plt.title(n, color='red')\n    plt.show()\n\npred_list = []\nfor (data, label) in test:\n    pred_data = model.predictor(np.array([data]).astype(np.float32)).data\n    pred_list.append((pred_data, label))\nplot_mnist_data(pred_list)\n\n\n\u7d50\u679c\nepoch\u3092\u5897\u3084\u3057\u3066\u3044\u304f\u3068\u3069\u306e\u3088\u3046\u306b\u5909\u5316\u3057\u3066\u3044\u304f\u306e\u304b\u3092\u898b\u3066\u3044\u304d\u307e\u3059\u3002\n\n\u5143\u306e\u753b\u50cf\n\n0\u301c9\u307e\u3067\u3059\u3079\u3066\u542b\u3093\u306016\u500b\u306e\u753b\u50cf\u3067\u3059\u3002\u3053\u306e16\u7a2e\u985e\u306e\u5909\u5316\u3092\u898b\u3066\u3044\u304d\u307e\u3059\u3002\n\nepoch = 1\n\n\u30c6\u30ec\u30d3\u306e\u7802\u5d50\u306e\u3088\u3046\u306b\u306a\u3063\u3066\u3053\u306e\u6642\u70b9\u3067\u306f\u4f55\u306a\u306a\u3093\u3060\u304b\u308f\u304b\u308a\u307e\u305b\u3093\u3002\n\nepoch = 5\n\n\u3088\u3046\u3084\u304f\u6570\u5b57\u306e\u3088\u3046\u306a\u3082\u306e\u304c\u898b\u3048\u3066\u304d\u307e\u3057\u305f\u304c\u3001\u307e\u3060\u307e\u3060\u6570\u5b57\u3068\u306f\u308f\u304b\u308a\u307e\u305b\u3093\u3002\n\nepoch = 10\n\n0, 1, 3\u306a\u3069\u306f\u3060\u3093\u3060\u3093\u5f62\u304c\u898b\u3048\u3066\u304d\u307e\u3057\u305f\u3002\u4e8c\u6bb5\u76ee\u306e6\u306f\u307e\u3060\u3064\u3076\u308c\u3066\u3066\u3088\u304f\u308f\u304b\u308a\u307e\u305b\u3093\u3002\n\nepoch = 20\n\n\u307b\u307c\u6570\u5b57\u304c\u898b\u3048\u3066\u304d\u307e\u3057\u305f\u3002\n\nepoch = 100\n\n\u4e00\u6c17\u306b100\u307e\u3067\u9032\u3081\u3066\u307f\u307e\u3057\u305f\u3002\u307b\u3068\u3093\u3069\u6f70\u308c\u3066\u3044\u305f2\u6bb5\u76ee\u306e6\u3082\u5f62\u304c\u898b\u3048\u3066\u304d\u307e\u3057\u305f\u3002\n\u3082\u3063\u3068epoch\u3092\u5897\u3084\u305b\u3070\u306f\u3063\u304d\u308a\u3068\u898b\u3048\u3066\u304f\u308b\u306e\u3067\u3057\u3087\u3046\u304c\u3001\u4eca\u56de\u306f\u3053\u3053\u307e\u3067\u3002\n\n\u304a\u308f\u308a\u306b\n\u30cd\u30c3\u30c8\u30ef\u30fc\u30af\u304c\u6570\u5b57\u3092\u6570\u5b57\u3068\u8a8d\u8b58\u3057\u3066\u3044\u304f\u904e\u7a0b\u3092\u307f\u308b\u306e\u306f\u697d\u3057\u304b\u3063\u305f\u3067\u3059\u3002\ntrainer\u306f\u4fbf\u5229\u3067\u3059\u304c\u3001loss\u95a2\u6570\u306a\u3069\u3044\u308d\u3044\u308d\u306a\u90e8\u5206\u304c\u81ea\u52d5\u3067\u6c7a\u307e\u3063\u3066\u3057\u307e\u3046\u306e\u3067\u6ce8\u610f\u304c\u5fc5\u8981\u3067\u3059\u306d\u3002\n(2016.08.10 \u4fee\u6b63)\nloss\u95a2\u6570\u304c\u30c7\u30d5\u30a9\u30eb\u30c8\u3067soft_max_cross_entropy\u306b\u8a2d\u5b9a\u3055\u308c\u308b\u306e\u306ftrainer\u3067\u306f\u306a\u304fClassifer\u306e\u4ed5\u69d8\u3067\u3057\u305f\u3002trainer\u3067\u4f7f\u7528\u3059\u308bupdater\u306e\u5b9a\u7fa9\u306e\u969b\u306bloss\u95a2\u6570\u3092\u6307\u5b9a\u3059\u308b\u3053\u3068\u306b\u306a\u308b\u306e\u3067\u3059\u304c\u3001\u901a\u5e38\u306foptimizer\u306b\u30bb\u30c3\u30c8\u3057\u305f\u3082\u306e\u304c\u30ea\u30f3\u30af\u3055\u308c\u308b\u3088\u3046\u3067\u3059\u3002\n# \u306f\u3058\u3081\u306b\n\n[\u524d\u56de](http://qiita.com/trtd56/items/6f1deddc5b9d1f2d6c06)Chainer\u306e\u65b0\u6a5f\u80fd\u3001trainer\u3092\u4f7f\u3063\u3066CIFAR-10\u306e\u753b\u50cf\u5206\u985e\u306b\u6311\u6226\u3057\u3088\u3046\u3068\u3057\u305f\u306e\u3067\u3059\u304c\u3001\u30de\u30b7\u30f3\u30d1\u30ef\u30fc\u306e\u90fd\u5408\u4e0a\u3001\u52d5\u4f5c\u3092\u78ba\u8a8d\u3067\u304d\u305a\u306b\u7d42\u308f\u3063\u3066\u3057\u307e\u3044\u307e\u3057\u305f\u3002\n\u305d\u3053\u3067\u4eca\u56de\u306fMNIST\u3092\u4f7f\u3063\u305fAutoencoder\u306e\u4f5c\u6210\u3092\u901a\u3057\u3066trainer\u306e\u4f7f\u3044\u65b9\u3092\u78ba\u8a8d\u3057\u3066\u3044\u3053\u3046\u3068\u601d\u3044\u307e\u3059\u3002\n\nAutoencoder\u306b\u95a2\u3057\u3066\u306f\u3053\u3061\u3089\u306e\u8a18\u4e8b\u3092\u53c2\u8003\u306b\u3057\u307e\u3057\u305f\u3002\n\n- [\u3010\u30c7\u30a3\u30fc\u30d7\u30e9\u30fc\u30cb\u30f3\u30b0\u3011Chainer\u3067Autoencoder\u3092\u8a66\u3057\u3066\u7d50\u679c\u3092\u53ef\u8996\u5316\u3057\u3066\u307f\u308b\u3002](http://qiita.com/kenmatsu4/items/99d4a54d5a57405ecaf8)\n- [Chainer\u3067Deep Autoencoder\u3092\u4f5c\u3063\u3066\u307f\u308b](http://qiita.com/nykergoto/items/bb49e1ab8770f6bfb7d1)\n\n\n# \u5b9f\u88c5\n\nMNIST\u306e\u624b\u66f8\u304d\u6587\u5b571000\u500b\u3092\u5165\u529b\u3068\u3057\u3001\u96a0\u308c\u5c64\u30921\u5c64\u901a\u3057\u3066\u5165\u529b\u3068\u7b49\u3057\u304f\u306a\u308b\u3088\u3046\u306a\u51fa\u529b\u3092\u5f97\u308b\u30cd\u30c3\u30c8\u30ef\u30fc\u30af\u3092\u4f5c\u6210\u3057\u307e\u3059\u3002\n\u30b3\u30fc\u30c9\u5168\u4f53\u306f[\u3053\u3061\u3089](https://github.com/trtd56/Autoencoder)\u306b\u3042\u3052\u3066\u3044\u307e\u3059\u3002\n\n## \u30cd\u30c3\u30c8\u30ef\u30fc\u30af\u90e8\u5206\n\n\u96a0\u308c\u5c64\u306e\u30e6\u30cb\u30c3\u30c8\u6570\u306f64\u307e\u3067\u7d5e\u3063\u3066\u3044\u307e\u3059\u3002\n\u307e\u305f\u3001_hidden=True_\u3067\u547c\u3073\u51fa\u3059\u3068\u96a0\u308c\u5c64\u3092\u51fa\u529b\u3067\u304d\u308b\u3088\u3046\u306b\u3057\u3066\u3044\u307e\u3059\u3002\n\n~~~python\nclass Autoencoder(chainer.Chain):\n    def __init__(self):\n        super(Autoencoder, self).__init__(\n                encoder = L.Linear(784, 64),\n                decoder = L.Linear(64, 784))\n\n    def __call__(self, x, hidden=False):\n        h = F.relu(self.encoder(x))\n        if hidden:\n            return h\n        else:\n            return F.relu(self.decoder(h))\n~~~\n\n\n## \u30c7\u30fc\u30bf\u4f5c\u6210\u90e8\u5206\n\nMNIST\u306e\u30c7\u30fc\u30bf\u3092\u8aad\u307f\u8fbc\u3093\u3067\u3001\u6559\u5e2b\u30c7\u30fc\u30bf\u3068\u30c6\u30b9\u30c8\u30c7\u30fc\u30bf\u3092\u4f5c\u6210\u3057\u307e\u3059\u3002\n\u6559\u5e2b\u30c7\u30fc\u30bf\u306e\u30e9\u30d9\u30eb\u306f\u5fc5\u8981\u306a\u304f\u3001\u51fa\u529b\u306f\u5165\u529b\u3068\u540c\u3058\u3082\u306e\u306b\u306a\u308b\u306e\u3067\u3001\u5c11\u3057\u30c7\u30fc\u30bf\u306e\u5f62\u3092\u3044\u3058\u3063\u3066\u3044\u307e\u3059\u3002\n\n~~~python\n# MNIST\u306e\u30c7\u30fc\u30bf\u306e\u8aad\u307f\u8fbc\u307f\ntrain, test = chainer.datasets.get_mnist()\n\n# \u6559\u5e2b\u30c7\u30fc\u30bf\ntrain = train[0:1000]\ntrain = [i[0] for i in train]\ntrain = tuple_dataset.TupleDataset(train, train)\ntrain_iter = chainer.iterators.SerialIterator(train, 100)\n\n# \u30c6\u30b9\u30c8\u7528\u30c7\u30fc\u30bf\ntest = test[0:25]\n~~~\n\n## \u30e2\u30c7\u30eb\u4f5c\u6210\n\n~~~python\nmodel = L.Classifier(Autoencoder(), lossfun=F.mean_squared_error)\nmodel.compute_accuracy = False\noptimizer = chainer.optimizers.Adam()\noptimizer.setup(model)\n~~~\n\n\u3053\u3053\u3067\u6ce8\u610f\u3059\u308b\u3053\u3068\u304c2\u70b9\n\n0. loss\u95a2\u6570\u306e\u5b9a\u7fa9\nL.Classifier\u3067\u30e2\u30c7\u30eb\u3092\u5b9a\u7fa9\u3057\u305f\u969b\u3001\u30c7\u30d5\u30a9\u30eb\u30c8\u3067\u306floss\u95a2\u6570\u306fsoftmax_cross_entropy\u3068\u306a\u308b\u3088\u3046\u3067\u3059\u304c\u3001\u4eca\u56de\u306fmean_squared_error\u3092\u4f7f\u3044\u305f\u3044\u306e\u3067\u3001lossfun\u3067\u5b9a\u7fa9\u3057\u306a\u3051\u308c\u3070\u306a\u308a\u307e\u305b\u3093\u3002\n\n1. accuracy\u3092\u8a08\u7b97\u3057\u306a\u3044\n\u4eca\u56de\u306f\u6559\u5e2b\u30c7\u30fc\u30bf\u306b\u30e9\u30d9\u30eb\u3092\u4f7f\u308f\u306a\u3044\u306e\u3067accuracy\u306e\u8a08\u7b97\u306f\u5fc5\u8981\u3042\u308a\u307e\u305b\u3093\u3002\u306a\u306e\u3067compute_accuracy\u3092False\u306b\u3057\u3066\u304a\u304f\u5fc5\u8981\u304c\u3042\u308a\u307e\u3059\u3002\n\n## \u5b66\u7fd2\u90e8\u5206\n\n\u7279\u306b\u8aac\u660e\u306e\u5fc5\u8981\u306f\u306a\u3044\u3068\u601d\u3044\u307e\u3059\u3002\ntrainer\u304c\u4f7f\u3048\u308b\u3088\u3046\u306b\u306a\u3063\u3066\u304b\u3089\u3001\u3053\u306e\u90e8\u5206\u304c\u7c21\u5358\u306b\u66f8\u3051\u308b\u3088\u3046\u306b\u306a\u3063\u3066\u52a9\u304b\u3063\u3066\u3044\u307e\u3059^^\n\n~~~python\nupdater = training.StandardUpdater(train_iter, optimizer, device=-1)\ntrainer = training.Trainer(updater, (N_EPOCH, 'epoch'), out=\"result\")\ntrainer.extend(extensions.LogReport())\ntrainer.extend(extensions.PrintReport( ['epoch', 'main/loss']))\ntrainer.extend(extensions.ProgressBar())\n\ntrainer.run()\n~~~\n\n## \u7d50\u679c\u78ba\u8a8d\n\n\u95a2\u6570\u3092\u4f5c\u3063\u3066matplotlib\u3067\u7d50\u679c\u3092\u30d7\u30ed\u30c3\u30c8\u3057\u307e\u3059\u3002\n\u753b\u50cf\u4e0a\u90e8\u306b\u8d64\u6587\u5b57\u3067\u5143\u306e\u30e9\u30d9\u30eb\u3092\u30d7\u30ea\u30f3\u30c8\u3057\u3066\u3044\u307e\u3059\u3002\u5ea7\u6a19\u306e\u8abf\u6574\u3092\u304d\u3061\u3093\u3068\u3057\u3066\u3044\u306a\u3044\u306e\u3067\u82e5\u5e72\u304b\u3076\u3063\u3066\u3044\u308b\u90e8\u5206\u3082\u3042\u308a\u307e\u3059\u304c...\n\n\u3061\u306a\u307f\u306b\u3053\u306e\u95a2\u6570\u306btest\u7528\u30c7\u30fc\u30bf\u3092\u305d\u306e\u307e\u307e\u5165\u529b\u3059\u308b\u3068\u3001\u5143\u306e\u30c7\u30fc\u30bf\u306e\u753b\u50cf\u304c\u51fa\u529b\u3055\u308c\u307e\u3059\u3002\n\n~~~python\ndef plot_mnist_data(samples):\n    for index, (data, label) in enumerate(samples):\n        plt.subplot(5, 5, index + 1)\n        plt.axis('off')\n        plt.imshow(data.reshape(28, 28), cmap=cm.gray_r, interpolation='nearest')\n        n = int(label)\n        plt.title(n, color='red')\n    plt.show()\n\npred_list = []\nfor (data, label) in test:\n    pred_data = model.predictor(np.array([data]).astype(np.float32)).data\n    pred_list.append((pred_data, label))\nplot_mnist_data(pred_list)\n~~~\n\n# \u7d50\u679c\n\nepoch\u3092\u5897\u3084\u3057\u3066\u3044\u304f\u3068\u3069\u306e\u3088\u3046\u306b\u5909\u5316\u3057\u3066\u3044\u304f\u306e\u304b\u3092\u898b\u3066\u3044\u304d\u307e\u3059\u3002\n\n## \u5143\u306e\u753b\u50cf\n![epoch_origin.png](https://qiita-image-store.s3.amazonaws.com/0/91517/f063c1e0-da84-414c-008f-c27b3265cf1c.png)\n\n\n0\u301c9\u307e\u3067\u3059\u3079\u3066\u542b\u3093\u306016\u500b\u306e\u753b\u50cf\u3067\u3059\u3002\u3053\u306e16\u7a2e\u985e\u306e\u5909\u5316\u3092\u898b\u3066\u3044\u304d\u307e\u3059\u3002\n\n## epoch = 1\n\n![epoch_1.png](https://qiita-image-store.s3.amazonaws.com/0/91517/1f56e262-faed-b374-1a5c-db7a7e00872e.png)\n\n\u30c6\u30ec\u30d3\u306e\u7802\u5d50\u306e\u3088\u3046\u306b\u306a\u3063\u3066\u3053\u306e\u6642\u70b9\u3067\u306f\u4f55\u306a\u306a\u3093\u3060\u304b\u308f\u304b\u308a\u307e\u305b\u3093\u3002\n\n## epoch = 5\n\n![epoch_5.png](https://qiita-image-store.s3.amazonaws.com/0/91517/a0040384-9f34-c4dc-b7e3-ce0bbed3d016.png)\n\n\u3088\u3046\u3084\u304f\u6570\u5b57\u306e\u3088\u3046\u306a\u3082\u306e\u304c\u898b\u3048\u3066\u304d\u307e\u3057\u305f\u304c\u3001\u307e\u3060\u307e\u3060\u6570\u5b57\u3068\u306f\u308f\u304b\u308a\u307e\u305b\u3093\u3002\n\n## epoch = 10\n\n![epoch_10.png](https://qiita-image-store.s3.amazonaws.com/0/91517/3e608308-9d97-dbfb-ecd6-d3edf6f1ef83.png)\n\n0, 1, 3\u306a\u3069\u306f\u3060\u3093\u3060\u3093\u5f62\u304c\u898b\u3048\u3066\u304d\u307e\u3057\u305f\u3002\u4e8c\u6bb5\u76ee\u306e6\u306f\u307e\u3060\u3064\u3076\u308c\u3066\u3066\u3088\u304f\u308f\u304b\u308a\u307e\u305b\u3093\u3002\n\n## epoch = 20\n\n![epoch_20.png](https://qiita-image-store.s3.amazonaws.com/0/91517/3b842e05-23c9-6a11-aed4-b39aa72b531b.png)\n\n\u307b\u307c\u6570\u5b57\u304c\u898b\u3048\u3066\u304d\u307e\u3057\u305f\u3002\n\n## epoch = 100\n\n![epoch_100.png](https://qiita-image-store.s3.amazonaws.com/0/91517/3f862bdc-dce8-99d8-d754-6f5a328a97a0.png)\n\n\u4e00\u6c17\u306b100\u307e\u3067\u9032\u3081\u3066\u307f\u307e\u3057\u305f\u3002\u307b\u3068\u3093\u3069\u6f70\u308c\u3066\u3044\u305f2\u6bb5\u76ee\u306e6\u3082\u5f62\u304c\u898b\u3048\u3066\u304d\u307e\u3057\u305f\u3002\n\u3082\u3063\u3068epoch\u3092\u5897\u3084\u305b\u3070\u306f\u3063\u304d\u308a\u3068\u898b\u3048\u3066\u304f\u308b\u306e\u3067\u3057\u3087\u3046\u304c\u3001\u4eca\u56de\u306f\u3053\u3053\u307e\u3067\u3002\n\n# \u304a\u308f\u308a\u306b\n\n\u30cd\u30c3\u30c8\u30ef\u30fc\u30af\u304c\u6570\u5b57\u3092\u6570\u5b57\u3068\u8a8d\u8b58\u3057\u3066\u3044\u304f\u904e\u7a0b\u3092\u307f\u308b\u306e\u306f\u697d\u3057\u304b\u3063\u305f\u3067\u3059\u3002\n~~trainer\u306f\u4fbf\u5229\u3067\u3059\u304c\u3001loss\u95a2\u6570\u306a\u3069\u3044\u308d\u3044\u308d\u306a\u90e8\u5206\u304c\u81ea\u52d5\u3067\u6c7a\u307e\u3063\u3066\u3057\u307e\u3046\u306e\u3067\u6ce8\u610f\u304c\u5fc5\u8981\u3067\u3059\u306d\u3002~~\n(2016.08.10 \u4fee\u6b63)\nloss\u95a2\u6570\u304c\u30c7\u30d5\u30a9\u30eb\u30c8\u3067soft_max_cross_entropy\u306b\u8a2d\u5b9a\u3055\u308c\u308b\u306e\u306ftrainer\u3067\u306f\u306a\u304fClassifer\u306e\u4ed5\u69d8\u3067\u3057\u305f\u3002trainer\u3067\u4f7f\u7528\u3059\u308bupdater\u306e\u5b9a\u7fa9\u306e\u969b\u306bloss\u95a2\u6570\u3092\u6307\u5b9a\u3059\u308b\u3053\u3068\u306b\u306a\u308b\u306e\u3067\u3059\u304c\u3001\u901a\u5e38\u306foptimizer\u306b\u30bb\u30c3\u30c8\u3057\u305f\u3082\u306e\u304c\u30ea\u30f3\u30af\u3055\u308c\u308b\u3088\u3046\u3067\u3059\u3002\n", "tags": ["Chainer", "Python", "DeepLearning"]}