{"context": "\n\nComputer Vision Group\n\nTUM\uff08\u30df\u30e5\u30f3\u30d8\u30f3\u5de5\u79d1\u5927\u5b66\uff09\u306e\u30b3\u30f3\u30d4\u30e5\u30fc\u30bf\u30d3\u30b8\u30e7\u30f3\u30b0\u30eb\u30fc\u30d7\u306f\u3001SLAM\uff08\u30b9\u30e9\u30e0\uff09\u306e\u7814\u7a76\u304c\u3059\u3054\u3044\u3002SLAM(Simultaneous Localization and Mapping)\uff1a\u81ea\u5df1\u4f4d\u7f6e\u63a8\u5b9a\u3068\u5730\u56f3\u4f5c\u6210\u3092\u540c\u6642\u306b\u884c\u3046\u3053\u3068\u3067\u3042\u308a\u3001UAVs\u3084AR, VR\u306e\u5206\u91ce\u3067\u5fdc\u7528\u3055\u308c\u308b\u3002KinectFusion\u306a\u3093\u304b\u3082\u305d\u3046\u3002\u3053\u306e\u30da\u30fc\u30b8\u3067\u306f\u3001RGB-D SLAM\u306b\u3064\u3044\u3066\u30e1\u30e2\u3057\u3066\u3044\u304f\u3002\n\nReal-time 3D visual SLAM with a hand-held camera, European Robotics Forum, 2011.\n\n\u3053\u308c\u304c\u6700\u521d\u306eRGB-D SLAM\u3067\u3042\u308b\u3002\n\n\u30a2\u30eb\u30b4\u30ea\u30ba\u30e0\n\u30a2\u30eb\u30b4\u30ea\u30ba\u30e0\u306f\u3001\u4ee5\u4e0b\u306e\u3088\u3046\u306b\u306a\u3063\u3066\u3044\u308b\u3002\n1. RGB-D\u753b\u50cf\u306e\u8aad\u307f\u8fbc\u307f\n2. SURF\u7279\u5fb4\u91cf\u62bd\u51fa\u3068\u30de\u30c3\u30c1\u30f3\u30b0\n3. \u81ea\u5df1\u4f4d\u7f6e\u63a8\u5b9a\uff08RANSAC\uff09\n4. \u81ea\u5df1\u4f4d\u7f6e\u306e\u88dc\u6b63\uff08ICP\uff09\n5. \u30dd\u30fc\u30ba\u30b0\u30e9\u30d5\u306b\u3088\u308b\u6700\u9069\u5316\uff08HOGMAN\uff09\n6. 3\u6b21\u5143\u30e2\u30c7\u30eb\u306e\u51fa\u529b\uff08\u8272\u4ed8\u304d\uff09\n\n\u30d7\u30ed\u30b0\u30e9\u30e0\n\u30aa\u30fc\u30d7\u30f3\u30bd\u30fc\u30b9\u3067ROS\u306b\u516c\u958b\u3057\u3066\u3042\u308b\u3002\n\u8ad6\u6587\u3067\u306f\u3001Kinect\u3092\u3086\u3063\u304f\u308a\u3068\u52d5\u304b\u3057\u64ae\u5f71\u3055\u308c\u305f12\u679a\u306eRGB-D\u753b\u50cf\u3092\u7528\u3044\u3066\u3044\u308b\u3002\u30e2\u30c7\u30eb\u306e\u51fa\u529b\u901f\u5ea6\u306f0.5fps\u3067\u3042\u308b\u3002\uff08Intel i7 with 2GHz\uff09\n\u3057\u304b\u3057\u3001ground truth\uff08\u771f\u5024\uff09\u304c\u306a\u304f\u3001\u3053\u306e\u30e2\u30c7\u30eb\u306e\u8a55\u4fa1\u304c\u3067\u304d\u306a\u3044\u3002\n\nTowards a benchmark for RGB-D SLAM evaluation, RSS'11\n\nground truth(\u771f\u5024)\u304c\u306a\u3044\u305f\u3081\u3001RGB-D SLAM\u3092\u8a55\u4fa1\u3059\u308b\u305f\u3081\u306b\u30c7\u30fc\u30bf\u30bb\u30c3\u30c8\u3068\u30d9\u30f3\u30c1\u30de\u30fc\u30af\u3092\u4f5c\u6210\u3002\u771f\u5024\u306f\u3001\u9ad8\u901f\u306a\u30e2\u30fc\u30b7\u30e7\u30f3\u30ad\u30e3\u30d7\u30c1\u30e3\u30b7\u30b9\u30c6\u30e0\uff08from MotionAnalysis\uff09\u306b\u3088\u308a\u5f97\u3089\u308c\u308b\u3002\n\nRGB-D\u30c7\u30fc\u30bf\u30bb\u30c3\u30c8\u3068\u30d9\u30f3\u30c1\u30de\u30fc\u30af\n\u30c7\u30fc\u30bf\u30bb\u30c3\u30c8\u306e\u4f5c\u6210\u65b9\u6cd5\u306f\u4ee5\u4e0b\u306e\u3088\u3046\u306b\u306a\u3063\u3066\u3044\u308b\u3002\n1. 30Hz\u3067RGB-D\u753b\u50cf\u306e\u53d6\u5f97\uff08OpenNI\u30c9\u30e9\u30a4\u30d0\uff09\n2. 500Hz\u3067Kinect\u306e\u52a0\u901f\u5ea6\u30bb\u30f3\u30b5\u3092\u8a18\u9332\n3. \u30ab\u30e1\u30e9\u306e\u5185\u90e8\u30d1\u30e9\u30e1\u30fc\u30bf\u306f\u51fa\u8377\u6642\u306e\u3082\u306e\u306b\u8a2d\u5b9a\n4. \u30ab\u30e1\u30e9\u306e\u8ecc\u9053\u3092100Hz\u3067\u53d6\u5f97\uff08\u30e2\u30fc\u30b7\u30e7\u30f3\u30ad\u30e3\u30d7\u30c1\u30e3\u30b7\u30b9\u30c6\u30e0\uff09\n5. \u30e2\u30fc\u30b7\u30e7\u30f3\u30ad\u30e3\u30d7\u30c1\u30e3\u30b7\u30b9\u30c6\u30e0\u3068Kinect\u306e\u5ea7\u6a19\u5909\u63db\uff08\u30ad\u30e3\u30ea\u30d6\u30ec\u30fc\u30b7\u30e7\u30f3\uff09\n6. \u5916\u90e8\u304b\u3089\u30ab\u30e1\u30e9\u306e\u8ecc\u9053\u3068\u5b9f\u9a13\u74b0\u5883\u306e\u52d5\u753b\u3092\u53d6\u308b\n\u3053\u306e\u3088\u3046\u306b\u3057\u3066\u4f5c\u6210\u3055\u308c\u305f50GB\u306eKinect\u30c7\u30fc\u30bf\u30bb\u30c3\u30c8\u304c\u516c\u958b\u3055\u308c\u3066\u3044\u308b\u3002(\u30af\u30ea\u30a8\u30a4\u30c6\u30a3\u30d6\u30fb\u30b3\u30e2\u30f3\u30ba\u30fb\u30e9\u30a4\u30bb\u30f3\u30b9)\n\u3053\u308c\u306b\u3088\u3063\u3066\u3001\u7d76\u5bfe\u8ecc\u9053\u8aa4\u5dee\uff08ATE\uff09\u3084\u76f8\u5bfe\u4f4d\u7f6e\u8aa4\u5dee\uff08RPE\uff09\u304c\u6e2c\u308c\u308b\u3002\nATE\u306fVisual SLAM\u306e\u8a55\u4fa1\u306b\u3001RPE\u306fVisual Odometry\u306e\u30c9\u30ea\u30d5\u30c8\u306e\u8a55\u4fa1\u306b\u7528\u3044\u308b\u3002\n\nReal-Time Visual Odometry from Dense RGB-D Images, ICCV'11\n\nvisual odometry\u306e\u63a8\u5b9a\u306benergy-based approach\uff08\u306e\u3061\u306bdense visual odometry, Direct Methods\uff09\u3092\u7528\u3044\u308b\u3002\n\u4eca\u307e\u3067\u306f\u3001SIFT\u3084SURF\u306a\u3069\u306e\u7279\u5fb4\u91cf\u3092\u7528\u3044\u3066\u3044\u305f\u305f\u3081\u3001Feature-based Methods\u3068\u547c\u3070\u308c\u308b\u3002\n\n\u30ad\u30fc\u30a2\u30eb\u30b4\u30ea\u30ba\u30e0\nMaximizing photo-consistency\n\u30d0\u30c3\u30af\u30d7\u30ed\u30b8\u30a7\u30af\u30b7\u30e7\u30f3\u30a8\u30e9\u30fc(\u8f1d\u5ea6\u5dee)\u306e\u6700\u9069\u5316\u306b\u3088\u3063\u3066\u3001\u6b21\u306e\u30d5\u30ec\u30fc\u30e0\u3092\u6700\u521d\u306e\u30d5\u30ec\u30fc\u30e0\u306b\u4f4d\u7f6e\u5408\u308f\u305b\u3059\u308b\u5909\u63db\u884c\u5217\u3092\u6c42\u3081\u308b\u554f\u984c\u3002\n\n\u7d50\u679c\nRGB-D\u30c7\u30fc\u30bf\u30bb\u30c3\u30c8\u3092\u7528\u3044\u3066\u3001GICP\uff08Generalized-ICP\uff09\u3068\u6bd4\u8f03\u3001\u8a55\u4fa1\u3059\u308b\u3002\n\n\n\nDataset\nOurs\nGICP\nImprovement\n\n\n\n\nfreiburg1/desk\n0.0053m\n0.0103m\n1.94x\n\n\n\n0.0065deg\n0.0154deg\n2.37x\n\n\nfreiburg2/desk\n0.0015m\n0.0062m\n4.13x\n\n\n\n0.0027deg\n0.0060deg\n2.22x\n\n\n\n\u5404\u30d5\u30ec\u30fc\u30e0\u3054\u3068\u306e\u30c9\u30ea\u30d5\u30c8\uff08RPE\uff09\u306e\u4e2d\u592e\u5024[mm/frame]\u3092\u8868\u3057\u3066\u3044\u308b\u3002\nGICP\u3067\u306f\u3001\u3059\u3079\u3066\u306e\u30d5\u30ec\u30fc\u30e0\u306e15.3%\u306b1cm\u4ee5\u4e0a\u306e\u8aa4\u5dee\u304c\u51fa\u3066\u304a\u308a\u3001\u63d0\u6848\u624b\u6cd5\u3067\u306f2070\u30d5\u30ec\u30fc\u30e0\u4e2d(freiburg2/desk)1\u30d5\u30ec\u30fc\u30e0\u3060\u3051\u3067\u3042\u3063\u305f\u3002\n\u307e\u305f\u3001\u5b9f\u884c\u901f\u5ea6\u306b\u3064\u3044\u3066\u306f\u3001Intel Xeon E5520 CPU with 2.27GHz\u3067\u63d0\u6848\u624b\u6cd5\u304c0.08s(real-time at 12.5Hz), GICP\u306f7.52s per match\u3067\u3042\u308b\u3002\n\nAn Evaluation of the RGB-D SLAM System, ICRA'12\n\nRGB-D\u30c7\u30fc\u30bf\u30bb\u30c3\u30c8\u3068\u30d9\u30f3\u30c1\u30de\u30fc\u30af\u3092\u7528\u3044\u305fRGB-D SLAM\u306e\u8a55\u4fa1\u3092\u3057\u3066\u3044\u308b\u3002\n\n\u30c7\u30fc\u30bf\u30bb\u30c3\u30c8\u306efr1\u306b\u304a\u3051\u308b\u5e73\u5747\u7cbe\u5ea6\u3068\u51e6\u7406\u6642\u9593\u306e\u7d50\u679c\nSIFTGPU\u3001SURF\u3001ORB\u306b\u304a\u3051\u308bVisual Odometry\u306e\u8a55\u4fa1\nSIFTGPU\u3001SURF\u3001ORB\u306b\u304a\u3051\u308b\u5b9f\u884c\u901f\u5ea6\u306e\u8a55\u4fa1\n\u30de\u30c3\u30c1\u30f3\u30b0\u306e\u969b\u306b\u7528\u3044\u308bFLANN\u3068Brute Force, 2\u7a2e\u985e\u306eNN(nearest neighbor method)\u306e\u51e6\u7406\u901f\u5ea6\u306e\u8a55\u4fa1\n\n\n\u30a2\u30eb\u30b4\u30ea\u30ba\u30e0\n\nRGB-D\u753b\u50cf\u306e\u53d6\u5f97\nRGB\u753b\u50cf\u304b\u3089\u7279\u5fb4\u70b9\u30de\u30c3\u30c1\u30f3\u30b0\uff08SURF,SIFT,ORB\uff09\n\u30de\u30c3\u30c1\u30f3\u30b0\u7d50\u679c\u3088\u308a\u3001\u5909\u63db\u884c\u5217\u63a8\u5b9a\uff08RANSAC,GICP\uff09\n\u30dd\u30fc\u30ba\u30b0\u30e9\u30d5\u306b\u3088\u308b\u6700\u9069\u5316\uff08g2o\uff09\n3\u6b21\u5143\u70b9\u7fa4\u306e\u4f4d\u7f6e\u5408\u308f\u305b\nOctoMap\u306b\u3088\u308b\u30dc\u30af\u30bb\u30eb\u5316\n3\u6b21\u5143\u5360\u6709\u30b0\u30ea\u30c3\u30c9\u30de\u30c3\u30d7\u3092\u51fa\u529b\n\n\n\u7d50\u679c\n\u63d0\u6848\u624b\u6cd5\uff08SIFTGPU and FLANN matching\uff09\u306f\u3001\u7cbe\u5ea6\uff08RPE.RMSE\uff09\u304c9.7cm\u30013.95\u00b0\u3001\u51e6\u7406\u6642\u9593\u306f0.35s/frame\u3002\nSIFTGPU/SURF\u306e\u7cbe\u5ea6\u304c\u3088\u304f\u3001ORB\u304c\u6700\u3082\u9ad8\u901f\u3002\nSIFTGPU\u304cSURF\u306b\u6bd4\u3079\u30663.5\u500d\u901f\u3044\u3002\n\u30de\u30c3\u30c1\u30f3\u30b0\u306fFLANN\u304c\u901f\u3044\u3002\n\u3053\u306eRGB-D SLAM SYSTEM\u306f\u30aa\u30fc\u30d7\u30f3\u30bd\u30fc\u30b9\u3067ROS\u306b\u516c\u958b\u3057\u3066\u3042\u308b\u3002\uff08\u8a55\u4fa1\uff09\n\nA Benchmark for the Evaluation of RGB-D SLAM Systems, IROS'12\n\nRGB-D\u30c7\u30fc\u30bf\u30bb\u30c3\u30c8\u3068\u30d9\u30f3\u30c1\u30de\u30fc\u30af\u306b\u3064\u3044\u3066\u8a18\u8ff0\u3057\u3066\u3042\u308b\u3002\u30c7\u30fc\u30bf\u30bb\u30c3\u30c8\u3092\u7528\u3044\u308b\u5834\u5408\u306f\u3001\u3053\u306e\u8ad6\u6587\u3092\u53c2\u8003\u6587\u732e\u306b\u5165\u308c\u308b\u3053\u3068\u3002\n\n\u30c7\u30fc\u30bf\u30bb\u30c3\u30c8\u306e\u4f5c\u6210\u65b9\u6cd5\n\n\u30e2\u30fc\u30b7\u30e7\u30f3\u30ad\u30e3\u30d7\u30c1\u30e3\u30b7\u30b9\u30c6\u30e0\u306e\u30ad\u30e3\u30ea\u30d6\u30ec\u30fc\u30b7\u30e7\u30f3\nKinect\u306e\u30ad\u30e3\u30ea\u30d6\u30ec\u30fc\u30b7\u30e7\u30f3\n\u5916\u90e8\u30d1\u30e9\u30e1\u30fc\u30bf\u306e\u30ad\u30e3\u30ea\u30d6\u30ec\u30fc\u30b7\u30e7\u30f3\n\u30ad\u30e3\u30d7\u30c1\u30e3\u6642\u9593\u306e\u540c\u671f\n\n\n\u8a55\u4fa1\u306e\u4ed5\u65b9\n\nRelative Pose Error(RPE)\u306e\u6e2c\u5b9a\u65b9\u6cd5\nAbsolute Trajectory Error\u306e\u6e2c\u5b9a\u65b9\u6cd5\n\n\nEvaluating Egomotion and Structure-from-Motion Approaches Using the TUM RGB-D Benchmark, IROS'12 Workshop\n\nA Benchmark for the Evaluation of RGB-D SLAM Systems\u3068\u307b\u307c\u4e00\u7dd2\u3002\n\nRobust Odometry Estimation for RGB-D Cameras, ICRA'13\n\nDirect Method\u306b\u3088\u308bVisual Odometry\u306e\u6539\u826f\u7248(DVO)\u3067\u3001\u30b3\u30fc\u30c9\u304c\u516c\u958b\u3055\u308c\u3066\u3044\u308b\u3002\ndesk\u306e\u8ecc\u8de1\u306e\u8a55\u4fa1(RPE.RMSE[m/s])\n\n\n\nMethod\nfr1/desk2\nfr1/desk\nfr2/desk\nfr2/person\n\n\n\n\nreference\n0.3416\n0.5370\n0.0205\n0.0708\n\n\nno weights\n0.1003\n0.0551\n0.0231\n0.0567\n\n\nTukey weights\n0.2072\n0.1740\n0.1080\n0.1073\n\n\nt-dist. weights\n0.0708\n0.0458\n0.0203\n0.0360\n\n\nt-dist. w.+temporal\n0.0687\n0.0491\n0.0188\n0.0345\n\n\navg. camera velocity\n0.413\n0.426\n0.193\n0.121\n\n\n\n\u30ab\u30e1\u30e9\u306e\u901f\u5ea6\u304c\u901f\u3044\u3068\u304d\u30015cm\u304f\u3089\u3044\u306e\u8aa4\u5dee\u3067\u3001\u9045\u3044\u3068\u304d\u306f2cm\u304f\u3089\u3044\u3068\u601d\u3063\u305f\u3089\u3044\u3044\u3060\u308d\u3046\u3002\n\nDense Visual SLAM for RGB-D Cameras, IROS'13\n\nDVO\u306eSLAM\u7248\nRGB\u306e\u307f\u3001Depth\u306e\u307f\u3001RGB-D Visual Odometry\u306e\u8a55\u4fa1\n\n\n\nstructure\ntexture\ndistance\nRGB\nDepth\nRGB+Depth\n\n\n\n\n-\nx\nnear\n0.0591\n0.2438\n0.0275\n\n\n-\nx\nfar\n0.1620\n0.2870\n0.0730\n\n\nx\n-\nnear\n0.1962\n0.0481\n0.0207\n\n\nx\n-\nfar\n0.1021\n0.0840\n0.0388\n\n\nx\nx\nnear\n0.0176\n0.0677\n0.0407\n\n\nx\nx\nfar\n0.0170\n0.0855\n0.0390\n\n\n\nfr3\u306e\u30c7\u30fc\u30bf\u30bb\u30c3\u30c8\u3092\u7528\u3044\u3066RPE(RMSE[m/s])\u306e\u8a55\u4fa1\u3092\u3057\u3066\u3044\u308b\u3002\n\u5efa\u9020\u7269\u3068\u30c6\u30af\u30b9\u30c1\u30e3\u306e\u3069\u3061\u3089\u304b\u306e\u5834\u5408\u3067RGB-D Odometry\u304c\u3044\u3044\u7d50\u679c\u3092\u51fa\u3057\u3066\u304a\u308a\u3001\u5efa\u9020\u7269\u3068\u30c6\u30af\u30b9\u30c1\u30e3\u304c\u3042\u308b\u3068\u304d\u306f\u3001RGB\u306e\u307f\u304c\u3044\u3044\u7d50\u679c\u3068\u306a\u3063\u305f\u3002\nRGB-D Odometry\u306eframe-to-frame\u3001frame-to-keyframe\u3001frame-to-keyframe\u3068\u30dd\u30fc\u30ba\u30b0\u30e9\u30d5\u306b\u3088\u308b\u6700\u9069\u5316\u306e\uff13\u3064\u306e\u624b\u6cd5\u3092fr1\u30c7\u30fc\u30bf\u30bb\u30c3\u30c8\u3067\u8a55\u4fa1(RPE.RMSE[m/s])\u30fb\u6bd4\u8f03\u3057\u3066\u3044\u308b\u3002\n\n\n\nDataset\nRGB+D\nRGB+D+KF\nRGB+D+KF+Opt\n\n\n\n\nfr1/desk\n0.036\n0.030\n0.024\n\n\nfr1/desk (v)\n0.035\n0.037\n0.035\n\n\nfr1/desk2\n0.049\n0.055\n0.050\n\n\nfr1/desk2 (v)\n0.020\n0.020\n0.017\n\n\nfr1/room\n0.058\n0.048\n0.043\n\n\nfr1/room (v)\n0.076\n0.042\n0.094\n\n\nfr1/360\n0.119\n0.119\n0.092\n\n\nfr1/360 (v)\n0.097\n0.125\n0.096\n\n\nfr1/teddy\n0.060\n0.067\n0.043\n\n\nfr1/floor\nfail\n0.090\n0.232\n\n\nfr1/xyz\n0.026\n0.024\n0.018\n\n\nfr1/xyz (v)\n0.047\n0.051\n0.058\n\n\nfr1/rpy\n0.040\n0.043\n0.032\n\n\nfr1/rpy (v)\n0.103\n0.082\n0.044\n\n\nfr1/plant\n0.036\n0.036\n0.025\n\n\nfr1/plant (v)\n0.063\n0.062\n0.191\n\n\navg. improvement\n0%\n16%\n20%\n\n\n\n\u63d0\u6848\u624b\u6cd5\u306eRGB-D SLAM(frame-to-keyframe\u3068\u30dd\u30fc\u30ba\u30b0\u30e9\u30d5\u6700\u9069\u5316\uff09\u306fRGB-D Odometry\u306e\u7d50\u679c\u309220\u30d1\u30fc\u30bb\u30f3\u30c8\u306e\u6539\u5584\u3057\u3066\u3044\u308b\u3002\n\u4ed6\u306e\u6700\u5148\u7aef\u624b\u6cd5\u3068\u306e\u6bd4\u8f03:ATE(RMSE[m])\n\n\n\nDataset\n# KF\nOurs\nRGB-D SLAM ICRA'12\nMRSMap\nKinFu\n\n\n\n\nfr1/xyz\n68\n0.011\n0.014\n0.013\n0.026\n\n\nfr1/rpy\n73\n0.020\n0.026\n0.027\n0.133\n\n\nfr1/desk\n67\n0.021\n0.023\n0.043\n0.057\n\n\nfr1/desk2\n93\n0.046\n0.043\n0.049\n0.420\n\n\nfr1/room\n186\n0.053\n0.084\n0.069\n0.313\n\n\nfr1/360\n126\n0.083\n0.079\n0.069\n0.913\n\n\nfr1/teddy\n181\n0.034\n0.076\n0.039\n0.154\n\n\nfr1/plant\n156\n0.028\n0.091\n0.026\n0.598\n\n\nfr2/desk\n181\n0.017\n-\n0.052\n-\n\n\nfr3/office\n168\n0.035\n-\n-\n0.064\n\n\naverage\n\n0.034\n0.054\n0.043\n0.297\n\n\n\n\u5e73\u5747\u3092\u307f\u308b\u3068\u63d0\u6848\u624b\u6cd5\u304c\u512a\u308c\u3066\u3044\u308b\u3002\n\nDense Tracking and Mapping with a Quadrocopter, UAV-g'13\n\nUAV\u306b\u5fdc\u7528\n\nCopyMe3D: Scanning and Printing Persons in 3D, GCPR'13\n\n3D\u30b9\u30ad\u30e3\u30f3\u3057\u30663D\u30d7\u30ea\u30f3\u30c8\n\nSubmap-based Bundle Adjustment for 3D Reconstruction from RGB-D Data, GCPR'14\n\n\u30de\u30c3\u30d7\u6700\u9069\u5316\u306bBA\u3092\u7528\u3044\u308b\nATE(RMSE)\u306e\u8a55\u4fa1[m]\n\n\n\nSequence\nNo BA\nFull 2D\nFull 3D\nSubmap-based 3D BA\nRGB-D SLAM ICRA'12\nKinFu\nDirect RSS'13\n\n\n\n\nFR1/360\n0.108\n0.099\n0.077\n0.079\n0.079\n0.591\n0.119\n\n\nFR1/desk\n0.047\n0.021\n0.022\n0.022\n0.023\n0.068\n0.035\n\n\nFR1/desk2\n0.098\n0.044\n0.030\n0.031\n0.043\n0.635\n0.062\n\n\nFR1/plant\n0.048\n0.023\n0.042\n0.043\n0.091\n0.281\n0.043\n\n\nFR1/room\n0.275\n0.228\n0.085\n0.086\n0.084\n0.304\n0.078\n\n\nFR1/rpy\n0.046\n0.058\n0.027\n0.027\n0.026\n0.081\n0.042\n\n\nFR1/teddy\n0.277\n0.060\n0.056\n0.057\n0.076\n0.337\n0.080\n\n\nFR1/xyz\n0.015\n0.013\n0.013\n0.013\n0.014\n0.025\n0.023\n\n\nFR2/desk\n0.201\n0.080\n0.079\n0.076\n-\n-\n-\n\n\nFR3/office\n0.176\n0.039\n0.036\n0.035\n-\n0.061\n0.040\n\n\naverage\n0.129\n0.066\n0.047\n0.047\n0.054\n0.264\n0.058\n\n\n\n\nTowards Illumination-invariant 3D Reconstruction using ToF RGB-D Cameras\n\nToF\u65b9\u5f0f\u306b\u5bfe\u5fdc\u3002\n\nMonocular SLAM\u306e\u7d39\u4ecb\nRGB-D SLAM\u306fKinect\u3084Xtion\u3068\u3044\u3063\u305fRGB\u3068Depth\u304c\u5f97\u3089\u308c\u308b\u30bb\u30f3\u30b5\u3092\u7528\u3044\u305fSLAM\u3067\u3042\u308b\u3002\u3053\u3053\u304b\u3089\u306f\u3001\u6700\u8fd1\u306e\u5358\u773c\u30ab\u30e1\u30e9\u306e\u307f\u7528\u3044\u305fSLAM\u3092\u5c11\u3057\u3060\u3051\u7d39\u4ecb\u3059\u308b\u3002\n\nSemi-Dense Visual Odometry for AR on a Smartphone, ISMAR'14\n\nfull Dense \u2192 Semi-Dense VO\n\u30c1\u30e5\u30fc\u30ea\u30c3\u30d2\u5927\u5b66\u306eSVO\u306e\u30b3\u30fc\u30c9\u6709\u308a\u3002\n\n\n\n\n\n\nfr2/xyz\n\nfr2/desk\n\n\n\n\n\nmethod\nmapping\ntracking\n(cm/s)\n(deg/s)\n(cm/s)\n(deg/s)\n\n\nPTAM\n640\u00d7480\n640\u00d7480\n8.2\n3.2\nfail\nfail\n\n\nours\n640\u00d7480\n640\u00d7480\n0.50\n0.31\n2.2\n0.96\n\n\nours\n640\u00d7480\n320\u00d7240\n0.58\n0.32\n3.6\n1.25\n\n\nours\n320\u00d7240\n320\u00d7240\n0.58\n0.32\n3.3\n0.96\n\n\nours\n320\u00d7240\n160\u00d7120\n0.62\n0.33\n4.9\n1.38\n\n\nours\n160\u00d7120\n160\u00d7120\n0.68\n0.37\nfail\nfail\n\n\nours\n160\u00d7120\n80\u00d760\n1.58\n0.71\nfail\nfail\n\n\n\n\nLSD-SLAM: Large-Scale Direct Monocular SLAM, ECCV'14\n\nSVO\u306eSLAM\u7248\u3001\u3057\u304b\u3082\u5927\u898f\u6a21\u3002\u30b3\u30fc\u30c9\u6709\u308a\u3002\nATE(RMSE)\u306e\u8a55\u4fa1[cm]\n\n\n\nError\nLSD-SLAM (#KF)\nSVO ICRA'14\nPTAM\nDense Visual SLAM IROS'13\nRGB-D SLAM ICRA'12\n\n\n\n\nfr2/desk\n4.52 (116)\n13.50\nx\n1.77\n9.5\n\n\nfr2/xyz\n1.47 (38)\n3.79\n24.28\n1.18\n2.6\n\n\nsim/desk\n0.04 (39)\n1.53\n-\n0.27\n-\n\n\nsim/slowmo\n0.35 (12)\n2.21\n-\n0.13\n-\n\n\n\n\u5e73\u5747\u306f\u5358\u773cSLAM\u3088\u308a\u3082RGB-D SLAM\u306e\u307b\u3046\u304c\u826f\u3044\u3088\u3046\u3060\u3002\u8aa4\u5dee\u306f5cm\u4ee5\u5185\u3002\n# [Computer Vision Group](http://vision.in.tum.de/)\nTUM\uff08\u30df\u30e5\u30f3\u30d8\u30f3\u5de5\u79d1\u5927\u5b66\uff09\u306e\u30b3\u30f3\u30d4\u30e5\u30fc\u30bf\u30d3\u30b8\u30e7\u30f3\u30b0\u30eb\u30fc\u30d7\u306f\u3001SLAM\uff08\u30b9\u30e9\u30e0\uff09\u306e\u7814\u7a76\u304c\u3059\u3054\u3044\u3002SLAM(Simultaneous Localization and Mapping)\uff1a\u81ea\u5df1\u4f4d\u7f6e\u63a8\u5b9a\u3068\u5730\u56f3\u4f5c\u6210\u3092\u540c\u6642\u306b\u884c\u3046\u3053\u3068\u3067\u3042\u308a\u3001UAVs\u3084AR, VR\u306e\u5206\u91ce\u3067\u5fdc\u7528\u3055\u308c\u308b\u3002[KinectFusion](http://qiita.com/SatoshiRobatoFujimoto/items/bddefc89456c0716b00a)\u306a\u3093\u304b\u3082\u305d\u3046\u3002\u3053\u306e\u30da\u30fc\u30b8\u3067\u306f\u3001[RGB-D SLAM](http://vision.in.tum.de/data/datasets/rgbd-dataset)\u306b\u3064\u3044\u3066\u30e1\u30e2\u3057\u3066\u3044\u304f\u3002\n\n# [Real-time 3D visual SLAM with a hand-held camera, European Robotics Forum, 2011.](http://vision.in.tum.de/publications#2011)\n\n\u3053\u308c\u304c\u6700\u521d\u306eRGB-D SLAM\u3067\u3042\u308b\u3002\n\n## \u30a2\u30eb\u30b4\u30ea\u30ba\u30e0\n\u30a2\u30eb\u30b4\u30ea\u30ba\u30e0\u306f\u3001\u4ee5\u4e0b\u306e\u3088\u3046\u306b\u306a\u3063\u3066\u3044\u308b\u3002\n1. RGB-D\u753b\u50cf\u306e\u8aad\u307f\u8fbc\u307f\n2. SURF\u7279\u5fb4\u91cf\u62bd\u51fa\u3068\u30de\u30c3\u30c1\u30f3\u30b0\n3. \u81ea\u5df1\u4f4d\u7f6e\u63a8\u5b9a\uff08RANSAC\uff09\n4. \u81ea\u5df1\u4f4d\u7f6e\u306e\u88dc\u6b63\uff08ICP\uff09\n5. \u30dd\u30fc\u30ba\u30b0\u30e9\u30d5\u306b\u3088\u308b\u6700\u9069\u5316\uff08HOGMAN\uff09\n6. 3\u6b21\u5143\u30e2\u30c7\u30eb\u306e\u51fa\u529b\uff08\u8272\u4ed8\u304d\uff09\n\n## \u30d7\u30ed\u30b0\u30e9\u30e0\n\u30aa\u30fc\u30d7\u30f3\u30bd\u30fc\u30b9\u3067ROS\u306b[\u516c\u958b](http://wiki.ros.org/openni/Contests/ROS%203D/RGBD-6D-SLAM)\u3057\u3066\u3042\u308b\u3002\n\n\u8ad6\u6587\u3067\u306f\u3001Kinect\u3092\u3086\u3063\u304f\u308a\u3068\u52d5\u304b\u3057\u64ae\u5f71\u3055\u308c\u305f12\u679a\u306eRGB-D\u753b\u50cf\u3092\u7528\u3044\u3066\u3044\u308b\u3002\u30e2\u30c7\u30eb\u306e\u51fa\u529b\u901f\u5ea6\u306f0.5fps\u3067\u3042\u308b\u3002\uff08Intel i7 with 2GHz\uff09\n\u3057\u304b\u3057\u3001ground truth\uff08\u771f\u5024\uff09\u304c\u306a\u304f\u3001\u3053\u306e\u30e2\u30c7\u30eb\u306e\u8a55\u4fa1\u304c\u3067\u304d\u306a\u3044\u3002\n\n# [Towards a benchmark for RGB-D SLAM evaluation, RSS'11](http://vision.in.tum.de/publications#2011)\n\nground truth(\u771f\u5024)\u304c\u306a\u3044\u305f\u3081\u3001RGB-D SLAM\u3092\u8a55\u4fa1\u3059\u308b\u305f\u3081\u306b\u30c7\u30fc\u30bf\u30bb\u30c3\u30c8\u3068\u30d9\u30f3\u30c1\u30de\u30fc\u30af\u3092\u4f5c\u6210\u3002\u771f\u5024\u306f\u3001\u9ad8\u901f\u306a\u30e2\u30fc\u30b7\u30e7\u30f3\u30ad\u30e3\u30d7\u30c1\u30e3\u30b7\u30b9\u30c6\u30e0\uff08from MotionAnalysis\uff09\u306b\u3088\u308a\u5f97\u3089\u308c\u308b\u3002\n\n## RGB-D\u30c7\u30fc\u30bf\u30bb\u30c3\u30c8\u3068\u30d9\u30f3\u30c1\u30de\u30fc\u30af\n\u30c7\u30fc\u30bf\u30bb\u30c3\u30c8\u306e\u4f5c\u6210\u65b9\u6cd5\u306f\u4ee5\u4e0b\u306e\u3088\u3046\u306b\u306a\u3063\u3066\u3044\u308b\u3002\n1. 30Hz\u3067RGB-D\u753b\u50cf\u306e\u53d6\u5f97\uff08OpenNI\u30c9\u30e9\u30a4\u30d0\uff09\n2. 500Hz\u3067Kinect\u306e\u52a0\u901f\u5ea6\u30bb\u30f3\u30b5\u3092\u8a18\u9332\n3. \u30ab\u30e1\u30e9\u306e\u5185\u90e8\u30d1\u30e9\u30e1\u30fc\u30bf\u306f\u51fa\u8377\u6642\u306e\u3082\u306e\u306b\u8a2d\u5b9a\n4. \u30ab\u30e1\u30e9\u306e\u8ecc\u9053\u3092100Hz\u3067\u53d6\u5f97\uff08\u30e2\u30fc\u30b7\u30e7\u30f3\u30ad\u30e3\u30d7\u30c1\u30e3\u30b7\u30b9\u30c6\u30e0\uff09\n5. \u30e2\u30fc\u30b7\u30e7\u30f3\u30ad\u30e3\u30d7\u30c1\u30e3\u30b7\u30b9\u30c6\u30e0\u3068Kinect\u306e\u5ea7\u6a19\u5909\u63db\uff08\u30ad\u30e3\u30ea\u30d6\u30ec\u30fc\u30b7\u30e7\u30f3\uff09\n6. \u5916\u90e8\u304b\u3089\u30ab\u30e1\u30e9\u306e\u8ecc\u9053\u3068\u5b9f\u9a13\u74b0\u5883\u306e\u52d5\u753b\u3092\u53d6\u308b\n\n\u3053\u306e\u3088\u3046\u306b\u3057\u3066\u4f5c\u6210\u3055\u308c\u305f50GB\u306eKinect[\u30c7\u30fc\u30bf\u30bb\u30c3\u30c8](http://vision.in.tum.de/data/datasets/rgbd-dataset)\u304c\u516c\u958b\u3055\u308c\u3066\u3044\u308b\u3002(\u30af\u30ea\u30a8\u30a4\u30c6\u30a3\u30d6\u30fb\u30b3\u30e2\u30f3\u30ba\u30fb\u30e9\u30a4\u30bb\u30f3\u30b9)\n\n\u3053\u308c\u306b\u3088\u3063\u3066\u3001\u7d76\u5bfe\u8ecc\u9053\u8aa4\u5dee\uff08ATE\uff09\u3084\u76f8\u5bfe\u4f4d\u7f6e\u8aa4\u5dee\uff08RPE\uff09\u304c\u6e2c\u308c\u308b\u3002\nATE\u306fVisual SLAM\u306e\u8a55\u4fa1\u306b\u3001RPE\u306fVisual Odometry\u306e\u30c9\u30ea\u30d5\u30c8\u306e\u8a55\u4fa1\u306b\u7528\u3044\u308b\u3002\n\n# [Real-Time Visual Odometry from Dense RGB-D Images, ICCV'11](http://vision.in.tum.de/publications#2011)\n\nvisual odometry\u306e\u63a8\u5b9a\u306benergy-based approach\uff08\u306e\u3061\u306bdense visual odometry, Direct Methods\uff09\u3092\u7528\u3044\u308b\u3002\n\u4eca\u307e\u3067\u306f\u3001SIFT\u3084SURF\u306a\u3069\u306e\u7279\u5fb4\u91cf\u3092\u7528\u3044\u3066\u3044\u305f\u305f\u3081\u3001Feature-based Methods\u3068\u547c\u3070\u308c\u308b\u3002\n\n## \u30ad\u30fc\u30a2\u30eb\u30b4\u30ea\u30ba\u30e0\nMaximizing photo-consistency\n\u30d0\u30c3\u30af\u30d7\u30ed\u30b8\u30a7\u30af\u30b7\u30e7\u30f3\u30a8\u30e9\u30fc(\u8f1d\u5ea6\u5dee)\u306e\u6700\u9069\u5316\u306b\u3088\u3063\u3066\u3001\u6b21\u306e\u30d5\u30ec\u30fc\u30e0\u3092\u6700\u521d\u306e\u30d5\u30ec\u30fc\u30e0\u306b\u4f4d\u7f6e\u5408\u308f\u305b\u3059\u308b\u5909\u63db\u884c\u5217\u3092\u6c42\u3081\u308b\u554f\u984c\u3002\n\n## \u7d50\u679c\nRGB-D\u30c7\u30fc\u30bf\u30bb\u30c3\u30c8\u3092\u7528\u3044\u3066\u3001[GICP](http://www.roboticsproceedings.org/rss05/p21.pdf)\uff08Generalized-ICP\uff09\u3068\u6bd4\u8f03\u3001\u8a55\u4fa1\u3059\u308b\u3002\n\n| Dataset | Ours | GICP | Improvement |\n|:-----------:|:------------:|:------------:|:------------:|\n| freiburg1/desk | 0.0053m | 0.0103m | 1.94x |\n| | 0.0065deg | 0.0154deg | 2.37x | \n| freiburg2/desk | 0.0015m | 0.0062m | 4.13x |\n| | 0.0027deg | 0.0060deg | 2.22x |\n\u5404\u30d5\u30ec\u30fc\u30e0\u3054\u3068\u306e\u30c9\u30ea\u30d5\u30c8\uff08RPE\uff09\u306e\u4e2d\u592e\u5024[mm/frame]\u3092\u8868\u3057\u3066\u3044\u308b\u3002\n\nGICP\u3067\u306f\u3001\u3059\u3079\u3066\u306e\u30d5\u30ec\u30fc\u30e0\u306e15.3%\u306b1cm\u4ee5\u4e0a\u306e\u8aa4\u5dee\u304c\u51fa\u3066\u304a\u308a\u3001\u63d0\u6848\u624b\u6cd5\u3067\u306f2070\u30d5\u30ec\u30fc\u30e0\u4e2d(freiburg2/desk)1\u30d5\u30ec\u30fc\u30e0\u3060\u3051\u3067\u3042\u3063\u305f\u3002\n\u307e\u305f\u3001\u5b9f\u884c\u901f\u5ea6\u306b\u3064\u3044\u3066\u306f\u3001Intel Xeon E5520 CPU with 2.27GHz\u3067\u63d0\u6848\u624b\u6cd5\u304c0.08s(real-time at 12.5Hz), GICP\u306f7.52s per match\u3067\u3042\u308b\u3002\n\n\n# [An Evaluation of the RGB-D SLAM System, ICRA'12](http://vision.in.tum.de/publications#2012)\nRGB-D\u30c7\u30fc\u30bf\u30bb\u30c3\u30c8\u3068\u30d9\u30f3\u30c1\u30de\u30fc\u30af\u3092\u7528\u3044\u305fRGB-D SLAM\u306e\u8a55\u4fa1\u3092\u3057\u3066\u3044\u308b\u3002\n\n- \u30c7\u30fc\u30bf\u30bb\u30c3\u30c8\u306efr1\u306b\u304a\u3051\u308b\u5e73\u5747\u7cbe\u5ea6\u3068\u51e6\u7406\u6642\u9593\u306e\u7d50\u679c\n- SIFTGPU\u3001SURF\u3001ORB\u306b\u304a\u3051\u308bVisual Odometry\u306e\u8a55\u4fa1\n- SIFTGPU\u3001SURF\u3001ORB\u306b\u304a\u3051\u308b\u5b9f\u884c\u901f\u5ea6\u306e\u8a55\u4fa1\n- \u30de\u30c3\u30c1\u30f3\u30b0\u306e\u969b\u306b\u7528\u3044\u308bFLANN\u3068Brute Force, 2\u7a2e\u985e\u306eNN(nearest neighbor method)\u306e\u51e6\u7406\u901f\u5ea6\u306e\u8a55\u4fa1\n\n## \u30a2\u30eb\u30b4\u30ea\u30ba\u30e0\n\n1. RGB-D\u753b\u50cf\u306e\u53d6\u5f97\n2. RGB\u753b\u50cf\u304b\u3089\u7279\u5fb4\u70b9\u30de\u30c3\u30c1\u30f3\u30b0\uff08SURF,SIFT,ORB\uff09\n3. \u30de\u30c3\u30c1\u30f3\u30b0\u7d50\u679c\u3088\u308a\u3001\u5909\u63db\u884c\u5217\u63a8\u5b9a\uff08RANSAC,GICP\uff09\n4. \u30dd\u30fc\u30ba\u30b0\u30e9\u30d5\u306b\u3088\u308b\u6700\u9069\u5316\uff08g2o\uff09\n5. 3\u6b21\u5143\u70b9\u7fa4\u306e\u4f4d\u7f6e\u5408\u308f\u305b\n6. OctoMap\u306b\u3088\u308b\u30dc\u30af\u30bb\u30eb\u5316\n7. 3\u6b21\u5143\u5360\u6709\u30b0\u30ea\u30c3\u30c9\u30de\u30c3\u30d7\u3092\u51fa\u529b\n\n## \u7d50\u679c\n\u63d0\u6848\u624b\u6cd5\uff08SIFTGPU and FLANN matching\uff09\u306f\u3001\u7cbe\u5ea6\uff08RPE.RMSE\uff09\u304c9.7cm\u30013.95\u00b0\u3001\u51e6\u7406\u6642\u9593\u306f0.35s/frame\u3002\nSIFTGPU/SURF\u306e\u7cbe\u5ea6\u304c\u3088\u304f\u3001ORB\u304c\u6700\u3082\u9ad8\u901f\u3002\nSIFTGPU\u304cSURF\u306b\u6bd4\u3079\u30663.5\u500d\u901f\u3044\u3002\n\u30de\u30c3\u30c1\u30f3\u30b0\u306fFLANN\u304c\u901f\u3044\u3002\n\u3053\u306eRGB-D SLAM SYSTEM\u306f\u30aa\u30fc\u30d7\u30f3\u30bd\u30fc\u30b9\u3067[ROS](http://wiki.ros.org/rgbdslam/)\u306b\u516c\u958b\u3057\u3066\u3042\u308b\u3002[\uff08\u8a55\u4fa1\uff09](http://wiki.ros.org/rgbdslam_electric/evaluation)\n\n# [A Benchmark for the Evaluation of RGB-D SLAM Systems, IROS'12](http://vision.in.tum.de/publications#2012)\n\nRGB-D\u30c7\u30fc\u30bf\u30bb\u30c3\u30c8\u3068\u30d9\u30f3\u30c1\u30de\u30fc\u30af\u306b\u3064\u3044\u3066\u8a18\u8ff0\u3057\u3066\u3042\u308b\u3002\u30c7\u30fc\u30bf\u30bb\u30c3\u30c8\u3092\u7528\u3044\u308b\u5834\u5408\u306f\u3001\u3053\u306e\u8ad6\u6587\u3092\u53c2\u8003\u6587\u732e\u306b\u5165\u308c\u308b\u3053\u3068\u3002\n\n## \u30c7\u30fc\u30bf\u30bb\u30c3\u30c8\u306e\u4f5c\u6210\u65b9\u6cd5\n- \u30e2\u30fc\u30b7\u30e7\u30f3\u30ad\u30e3\u30d7\u30c1\u30e3\u30b7\u30b9\u30c6\u30e0\u306e\u30ad\u30e3\u30ea\u30d6\u30ec\u30fc\u30b7\u30e7\u30f3\n- Kinect\u306e\u30ad\u30e3\u30ea\u30d6\u30ec\u30fc\u30b7\u30e7\u30f3\n- \u5916\u90e8\u30d1\u30e9\u30e1\u30fc\u30bf\u306e\u30ad\u30e3\u30ea\u30d6\u30ec\u30fc\u30b7\u30e7\u30f3\n- \u30ad\u30e3\u30d7\u30c1\u30e3\u6642\u9593\u306e\u540c\u671f\n\n## \u8a55\u4fa1\u306e\u4ed5\u65b9\n- Relative Pose Error(RPE)\u306e\u6e2c\u5b9a\u65b9\u6cd5\n- Absolute Trajectory Error\u306e\u6e2c\u5b9a\u65b9\u6cd5\n\n# [Evaluating Egomotion and Structure-from-Motion Approaches Using the TUM RGB-D Benchmark, IROS'12 Workshop](http://vision.in.tum.de/publications#2012)\nA Benchmark for the Evaluation of RGB-D SLAM Systems\u3068\u307b\u307c\u4e00\u7dd2\u3002\n\n# [Robust Odometry Estimation for RGB-D Cameras, ICRA'13](http://vision.in.tum.de/publications#2013)\n\nDirect Method\u306b\u3088\u308bVisual Odometry\u306e\u6539\u826f\u7248(DVO)\u3067\u3001[\u30b3\u30fc\u30c9](https://github.com/tum-vision/dvo_slam)\u304c\u516c\u958b\u3055\u308c\u3066\u3044\u308b\u3002\n\ndesk\u306e\u8ecc\u8de1\u306e\u8a55\u4fa1(RPE.RMSE[m/s])\n\n| Method|  fr1/desk2 | fr1/desk | fr2/desk | fr2/person|\n|:-----------:|:------------:|:------------:|:------------:|:------------:|\n|reference |0.3416 |0.5370 |0.0205 |0.0708|\n|no weights |0.1003 |0.0551 |0.0231 |0.0567|\n|Tukey weights |0.2072 |0.1740 |0.1080 |0.1073|\n|t-dist. weights |0.0708 |0.0458 |0.0203 |0.0360|\n|t-dist. w.+temporal |0.0687 |0.0491 |0.0188 |0.0345|\n|avg. camera velocity |0.413 |0.426 |0.193 |0.121|\n\n\u30ab\u30e1\u30e9\u306e\u901f\u5ea6\u304c\u901f\u3044\u3068\u304d\u30015cm\u304f\u3089\u3044\u306e\u8aa4\u5dee\u3067\u3001\u9045\u3044\u3068\u304d\u306f2cm\u304f\u3089\u3044\u3068\u601d\u3063\u305f\u3089\u3044\u3044\u3060\u308d\u3046\u3002\n\n# [Dense Visual SLAM for RGB-D Cameras, IROS'13](http://vision.in.tum.de/publications#2013)\n\nDVO\u306eSLAM\u7248\n\nRGB\u306e\u307f\u3001Depth\u306e\u307f\u3001RGB-D Visual Odometry\u306e\u8a55\u4fa1\n\n|structure |texture |distance |RGB |Depth |RGB+Depth|\n|:-----------:|:------------:|:------------:|:------------:|:------------:|:------------:|\n|- |x |near |0.0591 |0.2438 |0.0275|\n|- |x |far |0.1620 |0.2870 |0.0730|\n|x |- |near |0.1962 |0.0481 |0.0207|\n|x |- |far |0.1021 |0.0840 |0.0388|\n|x |x |near |0.0176 |0.0677 |0.0407|\n|x |x |far |0.0170 |0.0855 |0.0390|\n\nfr3\u306e\u30c7\u30fc\u30bf\u30bb\u30c3\u30c8\u3092\u7528\u3044\u3066RPE(RMSE[m/s])\u306e\u8a55\u4fa1\u3092\u3057\u3066\u3044\u308b\u3002\n\u5efa\u9020\u7269\u3068\u30c6\u30af\u30b9\u30c1\u30e3\u306e\u3069\u3061\u3089\u304b\u306e\u5834\u5408\u3067RGB-D Odometry\u304c\u3044\u3044\u7d50\u679c\u3092\u51fa\u3057\u3066\u304a\u308a\u3001\u5efa\u9020\u7269\u3068\u30c6\u30af\u30b9\u30c1\u30e3\u304c\u3042\u308b\u3068\u304d\u306f\u3001RGB\u306e\u307f\u304c\u3044\u3044\u7d50\u679c\u3068\u306a\u3063\u305f\u3002\n\nRGB-D Odometry\u306eframe-to-frame\u3001frame-to-keyframe\u3001frame-to-keyframe\u3068\u30dd\u30fc\u30ba\u30b0\u30e9\u30d5\u306b\u3088\u308b\u6700\u9069\u5316\u306e\uff13\u3064\u306e\u624b\u6cd5\u3092fr1\u30c7\u30fc\u30bf\u30bb\u30c3\u30c8\u3067\u8a55\u4fa1(RPE.RMSE[m/s])\u30fb\u6bd4\u8f03\u3057\u3066\u3044\u308b\u3002\n\n|Dataset |RGB+D |RGB+D+KF |RGB+D+KF+Opt|\n|:-----------:|:------------:|:------------:|:------------:|\n|fr1/desk |0.036 |0.030 |0.024|\n|fr1/desk (v) |0.035 |0.037 |0.035|\n|fr1/desk2 |0.049 |0.055 |0.050|\n|fr1/desk2 (v) |0.020 |0.020 |0.017|\n|fr1/room |0.058 |0.048 |0.043|\n|fr1/room (v) |0.076 |0.042 |0.094|\n|fr1/360 |0.119 |0.119 |0.092|\n|fr1/360 (v) |0.097 |0.125 |0.096|\n|fr1/teddy |0.060 |0.067 |0.043|\n|fr1/floor |fail |0.090 |0.232|\n|fr1/xyz |0.026 |0.024 |0.018|\n|fr1/xyz (v) |0.047 |0.051 |0.058|\n|fr1/rpy |0.040 |0.043 |0.032|\n|fr1/rpy (v) |0.103 |0.082 |0.044|\n|fr1/plant |0.036 |0.036 |0.025|\n|fr1/plant (v) |0.063 |0.062 |0.191|\n|avg. improvement |0% |16% |20%|\n\n\u63d0\u6848\u624b\u6cd5\u306eRGB-D SLAM(frame-to-keyframe\u3068\u30dd\u30fc\u30ba\u30b0\u30e9\u30d5\u6700\u9069\u5316\uff09\u306fRGB-D Odometry\u306e\u7d50\u679c\u309220\u30d1\u30fc\u30bb\u30f3\u30c8\u306e\u6539\u5584\u3057\u3066\u3044\u308b\u3002\n\n\u4ed6\u306e\u6700\u5148\u7aef\u624b\u6cd5\u3068\u306e\u6bd4\u8f03:ATE(RMSE[m])\n\n|Dataset |# KF |Ours |RGB-D SLAM ICRA'12 |MRSMap |KinFu|\n|:-----------:|:------------:|:------------:|:------------:|:-----------:|:-----------:|:-----------:|\n|fr1/xyz |68 |0.011 |0.014 |0.013 |0.026|\n|fr1/rpy |73 |0.020 |0.026 |0.027 |0.133|\n|fr1/desk |67 |0.021 |0.023 |0.043 |0.057|\n|fr1/desk2 |93 |0.046 |0.043 |0.049 |0.420|\n|fr1/room |186 |0.053 |0.084 |0.069 |0.313|\n|fr1/360 |126 |0.083 |0.079 |0.069 |0.913|\n|fr1/teddy |181 |0.034 |0.076 |0.039 |0.154|\n|fr1/plant |156 |0.028 |0.091 |0.026 |0.598|\n|fr2/desk |181 |0.017 |- |0.052 |-|\n|fr3/office |168 |0.035 |- |- |0.064|\n|average | | 0.034 |0.054 |0.043 |0.297|\n\n\u5e73\u5747\u3092\u307f\u308b\u3068\u63d0\u6848\u624b\u6cd5\u304c\u512a\u308c\u3066\u3044\u308b\u3002\n\n# [Dense Tracking and Mapping with a Quadrocopter, UAV-g'13](http://vision.in.tum.de/publications#2013)\n\nUAV\u306b\u5fdc\u7528\n\n# [CopyMe3D: Scanning and Printing Persons in 3D, GCPR'13](http://vision.in.tum.de/publications#2013)\n\n3D\u30b9\u30ad\u30e3\u30f3\u3057\u30663D\u30d7\u30ea\u30f3\u30c8\n\n# [Submap-based Bundle Adjustment for 3D Reconstruction from RGB-D Data, GCPR'14](http://vision.in.tum.de/publications#2014)\n\n\u30de\u30c3\u30d7\u6700\u9069\u5316\u306bBA\u3092\u7528\u3044\u308b\nATE(RMSE)\u306e\u8a55\u4fa1[m]\n\n|Sequence |No BA |Full 2D |Full 3D |Submap-based 3D BA |RGB-D SLAM ICRA'12|KinFu |Direct RSS'13|\n|:-----------:|:------------:|:------------:|:------------:|:-----------:|:-----------:|:-----------:|:-----------:|\n|FR1/360 |0.108 |0.099 |0.077 |0.079 |0.079 |0.591 |0.119|\n|FR1/desk |0.047 |0.021 |0.022 |0.022 |0.023 |0.068 |0.035|\n|FR1/desk2 |0.098 |0.044 |0.030 |0.031 |0.043 |0.635 |0.062|\n|FR1/plant |0.048 |0.023 |0.042 |0.043 |0.091 |0.281 |0.043|\n|FR1/room |0.275 |0.228 |0.085 |0.086 |0.084 |0.304 |0.078|\n|FR1/rpy |0.046 |0.058 |0.027 |0.027 |0.026 |0.081 |0.042|\n|FR1/teddy |0.277 |0.060 |0.056 |0.057 |0.076 |0.337 |0.080|\n|FR1/xyz |0.015 |0.013 |0.013 |0.013 |0.014 |0.025 |0.023|\n|FR2/desk |0.201 |0.080 |0.079 |0.076 |- |- |-|\n|FR3/office |0.176 |0.039 |0.036 |0.035 |- |0.061 |0.040|\n|average |0.129 |0.066 |0.047 |0.047 |0.054 |0.264 |0.058|\n\n# [Towards Illumination-invariant 3D Reconstruction using ToF RGB-D Cameras](http://vision.in.tum.de/publications#2014)\n\nToF\u65b9\u5f0f\u306b\u5bfe\u5fdc\u3002\n\n# Monocular SLAM\u306e\u7d39\u4ecb\nRGB-D SLAM\u306fKinect\u3084Xtion\u3068\u3044\u3063\u305fRGB\u3068Depth\u304c\u5f97\u3089\u308c\u308b\u30bb\u30f3\u30b5\u3092\u7528\u3044\u305fSLAM\u3067\u3042\u308b\u3002\u3053\u3053\u304b\u3089\u306f\u3001\u6700\u8fd1\u306e\u5358\u773c\u30ab\u30e1\u30e9\u306e\u307f\u7528\u3044\u305fSLAM\u3092\u5c11\u3057\u3060\u3051\u7d39\u4ecb\u3059\u308b\u3002\n\n# [Semi-Dense Visual Odometry for AR on a Smartphone, ISMAR'14](http://vision.in.tum.de/publications#2014)\n\nfull Dense \u2192 Semi-Dense VO\n\u30c1\u30e5\u30fc\u30ea\u30c3\u30d2\u5927\u5b66\u306e[SVO](https://github.com/uzh-rpg/rpg_svo)\u306e\u30b3\u30fc\u30c9\u6709\u308a\u3002\n\n| | | |fr2/xyz ||fr2/desk ||\n|:-----------:|:-----------:|:-----------:|:-----------:|:-----------:|:-----------:|:-----------:|\n|method |mapping |tracking |(cm/s) |(deg/s) |(cm/s) |(deg/s)|\n|PTAM |640\u00d7480 |640\u00d7480 |8.2 |3.2 |fail |fail|\n|ours |640\u00d7480 |640\u00d7480 |0.50 |0.31 |2.2 |0.96|\n|ours |640\u00d7480 |320\u00d7240 |0.58 |0.32 |3.6 |1.25|\n|ours |320\u00d7240 |320\u00d7240 |0.58 |0.32 |3.3 |0.96|\n|ours |320\u00d7240 |160\u00d7120 |0.62 |0.33 |4.9 |1.38|\n|ours |160\u00d7120 |160\u00d7120 |0.68 |0.37 |fail |fail|\n|ours |160\u00d7120 |80\u00d760 |1.58 |0.71 |fail |fail|\n\n# [LSD-SLAM: Large-Scale Direct Monocular SLAM, ECCV'14](http://vision.in.tum.de/publications#2014)\n\nSVO\u306eSLAM\u7248\u3001\u3057\u304b\u3082\u5927\u898f\u6a21\u3002[\u30b3\u30fc\u30c9](https://github.com/tum-vision/lsd_slam)\u6709\u308a\u3002\n\nATE(RMSE)\u306e\u8a55\u4fa1[cm]\n\n| Error |LSD-SLAM (#KF) |SVO ICRA'14 |PTAM |Dense Visual SLAM IROS'13|RGB-D SLAM ICRA'12|\n|:-----------:|:-----------:|:-----------:|:-----------:|:-----------:|:-----------:|\n|fr2/desk |4.52 (116) |13.50 |x |1.77 |9.5|\n|fr2/xyz |1.47 (38) |3.79 |24.28 |1.18 |2.6|\n|sim/desk |0.04 (39) |1.53 |- |0.27 |-|\n|sim/slowmo |0.35 (12) |2.21 |- |0.13 |-|\n\n\u5e73\u5747\u306f\u5358\u773cSLAM\u3088\u308a\u3082RGB-D SLAM\u306e\u307b\u3046\u304c\u826f\u3044\u3088\u3046\u3060\u3002\u8aa4\u5dee\u306f5cm\u4ee5\u5185\u3002\n", "tags": ["Kinect", "OpenCV", "\u753b\u50cf\u51e6\u7406", "SLAM", "3D"]}