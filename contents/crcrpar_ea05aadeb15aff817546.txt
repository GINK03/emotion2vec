{"context": "\u3010\u8ffd\u8a18\u3011(2017/03/01)\nchainer\u516c\u5f0f\u306bDCGAN\u306e\u30b5\u30f3\u30d7\u30eb\u304c\u8ffd\u52a0\u3055\u308c\u307e\u3057\u305f\u3002\u3053\u3061\u3089\u3067\u306f\u3001\u30a8\u30ec\u30ac\u30f3\u30c8\u306bUpdater\u304c\u66f8\u304b\u308c\u3066\u3044\u307e\u3059\u306e\u3067\u662f\u975e\u305d\u3061\u3089\u3082\u3054\u89a7\u306b\u306a\u3063\u3066\u304f\u3060\u3055\u3044\u3002\n\u500b\u4eba\u7684\u306b\u4eca\u5e74\u306fGAN\u306b\u95a2\u3059\u308b\u8ad6\u6587\u304c\u304b\u306a\u308a\u591a\u3044\u3068\u611f\u3058\u3066\u3044\u307e\u3059\u3002\nGAN\u3092\u6271\u3046\u3068\u306a\u308b\u3068\u5fc5\u8981\u306a\u30e2\u30c7\u30eb\u306f\u6700\u4f4e2\u3064\u3001\u5834\u5408\u306b\u3088\u3063\u3066\u306f3\u3064\u306e\u3053\u3068\u3082\u3042\u308a\u307e\u3059\u3002\n\u3055\u3066\u3001chainer=1.11\u304b\u3089Trainer\u306a\u3069\u306b\u3088\u308b\u5b66\u7fd2\u30eb\u30fc\u30d7\u304c\u62bd\u8c61\u5316\u3055\u308c\u305f\u4e00\u65b9\u3001Trainer\u3067\u306f\u57fa\u672c\u7684\u306b1\u3064\u306e\u30e2\u30c7\u30eb\u3092\u53d7\u3051\u53d6\u308a\u5b66\u7fd2\u3092\u5b9f\u884c\u3059\u308b\u3088\u3046\u306b\u5b9f\u88c5\u3055\u308c\u3066\u3044\u308b\u305f\u3081GAN\u3092\u5b9f\u88c5\u3059\u308b\u5834\u5408\u306f\u3001\nfor epoch in six.moves.range(n_epoch):\n    perm = np.random.permutation(N)\n\n    for i in six.moves.range(0, N, batch_size):\n        x_batch = x_train[i*batch_size:(i+1)*batch_size]\n        x = chainer.Variable(x_in)\n\n        (\u4e2d\u7565)\n\n        loss_generator += tmp_loss_generator\n        loss_discriminator += tmp_loss_discriminator\n\n    optimizer_generator.zerograds()\n    optimizer.discriminator.zerograds()\n    loss_generator.backward()\n    loss_discriminator.backward()\n    optimizer_generator.update()\n    optimizer_discriminator.update()\n\n\u306e\u3088\u3046\u306a\u66f8\u304d\u65b9\u3092\u3057\u3066\u3044\u308b\u65b9\u3082\u3044\u3089\u3063\u3057\u3083\u308b\u3068\u601d\u3044\u307e\u3059\u3002\n\u3053\u306e\u8a18\u4e8b\u3067\u306f\u3001GAN\u306e\u3088\u3046\u306a\u8907\u6570\u306e\u30e2\u30c7\u30eb\u3092\u540c\u6642\u306b\u5b66\u7fd2\u3055\u305b\u308b\u5834\u5408\u306e\u30e2\u30c0\u30f3\u306a\u66f8\u304d\u65b9\u3092\u7d39\u4ecb\u3057\u307e\u3059\u3002\n\n0. Trainer\u306e\u69cb\u9020\n\u79c1\u306f\u3001Trainer\u306e\u69cb\u9020\u306f\u4ee5\u4e0b\u306e\u56f3\u306e\u3088\u3046\u306b\u306a\u3063\u3066\u3044\u308b\u3068\u6349\u3048\u3066\u3044\u307e\u3059\u3002\n\nTrainer\u3067\u8907\u6570\u306e\u30e2\u30c7\u30eb\u306e\u5b66\u7fd2\u3092\u5b9f\u884c\u3059\u308b\u5834\u5408\u3001\u5b9f\u969b\u306b\u66f8\u304f\u5fc5\u8981\u304c\u3042\u308b\u306e\u306fUpdater\u306e\u90e8\u5206\u3067\u3059\u3002\u4eca\u56de\u306f1\u3064\u306e\uff08\u753b\u50cf\uff09\u30c7\u30fc\u30bf\u30bb\u30c3\u30c8\u306b\u5bfe\u3057\u3066\u8907\u6570\u306e\u30e2\u30c7\u30eb\u5b66\u7fd2\u3059\u308b\u5834\u5408\u306e\u65b9\u91dd\u3092\u66f8\u304d\u307e\u3059\u3002\n\u307e\u305f\u3001\u4ee5\u4e0b\u64ec\u4f3c\u30b3\u30fc\u30c9\u3092\u7528\u3044\u307e\u3059\u304c\u4ee5\u4e0b\u306e\u30e2\u30b8\u30e5\u30fc\u30eb\u304cimport\u3055\u308c\u3066\u3044\u3066\u3001Chain\u304c\u4ee5\u4e0b\u306e\u3088\u3046\u306b\u5b9a\u7fa9\u3055\u308c\u3066\u3044\u308b\u3068\u3057\u307e\u3059\u3002\nimport chainer\nimport chainer.functions as F\nimport chainer.links as L\nfrom chainer import cuda, training, reporter\nfrom chainer.datasets import get_mnist\nfrom chainer.training import trainer, extensions\nfrom chainer.dataset import convert\nfrom chainer.dataset import iterator as iterator_module\nfrom chainer.datasets import get_mnist\nfrom chainer import optimizer as optimizer_module\n\n\nnet.py\nclass Generator(chainer.Chain):\n\n    def __init__(self):\n        super(Generator, self).__init__(self, z_dim, batch_size, ...):\n            \"\"\"\n            \u7573\u307f\u8fbc\u307f\u5c64\u306a\u3069\u306e\u5b9a\u7fa9\n            \"\"\"\n\n    def __call__(self, train=True):\n        \"\"\"\n        feedforward\u3092\u5b9a\u7fa9\n\u3000\u3000\u3000\u3000\u3000\u3000\u3000\u3000\u3000\u3000\u3000\u3000\u3000\u3000\u3000\u3000train=True: volatile='off'\u306echainer.Variable\u3092\u8fd4\u3059\n        train=False: volatile='on'\u306echainer.Variable\u3092\u8fd4\u3059\n        \"\"\"\n        return generated_variable\n\nclass Discriminator(chainer.Chain):\n\n    def __init__(self):\n        super(Discriminator, self).__init__(self, ...):\n            \"\"\"\n            \u7573\u307f\u8fbc\u307f\u5c64\u306a\u3069\u3092\u5b9a\u7fa9\n            \"\"\"\n\n    def __call__(self, x, train=True):\n        \"\"\"\n        feedforward\u3092\u5b9a\u7fa9\n\u3000\u3000\u3000\u3000\u3000\u3000\u3000\u3000\u3000\u3000\u3000\u3000\u3000\u3000\u3000\u3000train=True: volatile='off'\u306echainer.Variable\u3092\u8fd4\u3059\n        train=False: volatile='on'\u306echainer.Variable\u3092\u8fd4\u3059\n        \"\"\"\n        return discriminated_variable\n\n\n\nPoint 1: Updater\u3092\u5b9a\u7fa9\u3059\u308b\nTrainer\u3067\u5b66\u7fd2\u3092\u5b9f\u884c\u3059\u308b\u3068\u306f\u3044\u3048\u3001\u30d1\u30e9\u30e1\u30fc\u30bf\u66f4\u65b0\u3092\u62c5\u3063\u3066\u3044\u308b\u306e\u306f\u305d\u306e\u540d\u306e\u901a\u308aUpdater\u3067\u3059\u3002\nUpdater\u3092\u5b9a\u7fa9\u3059\u308b\u3068\u66f8\u304d\u307e\u3057\u305f\u304c\u3001\u5b9f\u969b\u306b\u306fchainer.training.StandardUpdater\u30af\u30e9\u30b9\u3092\u30aa\u30fc\u30d0\u30fc\u30e9\u30a4\u30c9\u3057\u307e\u3059\u3002\nStandardUpdater\u30af\u30e9\u30b9\u306f\n1. .__init__() \u3067iterator, optimizer\u306a\u3069\u3092\u53d7\u3051\u53d6\u308a\u3001\n2. .update_core() \u3067\u30df\u30cb\u30d0\u30c3\u30c1\u306b\u5bfe\u3059\u308b\u51e6\u7406\u3092\u5b9a\u7fa9\u3057\u3066\u3044\u307e\u3059\u3002\n\u3055\u3066\u3001\u3000GAN\u306eUpdater\u3092\u5b9a\u7fa9\u3059\u308b\u3068\u304d\u306f\u4e0a\u8a18\u30af\u30e9\u30b9\u3092\u4ee5\u4e0b\u306e\u3088\u3046\u306b\u30aa\u30fc\u30d0\u30fc\u30e9\u30a4\u30c9\u3057\u307e\u3059\u3002\n\nGANUpdater.py\nclass GAN_Updater(training.StandardUpdater):\n\n    def __init__(self, iterator, batch_size, generator, discriminator, opt_gen, opt_dis,\nconverter=convert.concat_examples, device=None):\n    if isinstance(iterator, iterator_module.Iterator):\n        iterator = {'main':iterator}\n    self._iterators = iterator\n    self.batch_size = batch_size\n    self.gen = generator\n    self.dis = discriminator\n    self._optimizers = {'gen':optimizer_gen, 'dis':opt_dis}\n    self.converter = converter\n    self.device = device\n    self.iteration = 0\n\n    def update_core(self):\n        batch = self._iterators['main'].next()\n        in_arrays = self.converter(batch, self.device)\n        x_batch = xp.array(x_batch)\n        zero_fake = xp.zeros_lik(x_batch)\n        fake_data = self.gen(train=True)\n        input4dis = F.concat((fake_data, chainer.Variable(x_batch)), axis=0)\n        dis_output = self.dis(input4dis, train=True)\n        (dis_fake, dis_true) = F.split_axis(dis_output, 2, axis=0)\n        dis_tmp = self.dis(chainer.Variable(zero_fake, train=True)\n        zeros = chainer.Variable(xp.zeros(self.batch_size, dtype=np.int32))\n        ones = chainer.Variable(xp.ones(self.batch_size, dtype=np.int32))\n\n        loss_gen = F.softmax_cross_entropy(dis_fake, zeros)\n        loss_dis = F.softmax_cross_entropy(dis_real, ones) + \\\n                   F.softmax_cross_entropy(dis_tmp, zeros)\n\n        reporter.report({'gen/loss':loss_gen, 'dis/loss':loss_dis})\n        loss_dic = {'gen':loss_gen, 'dis':loss_dis}\n\n        for name, optimizer in six.iteritems(self._optimizers):\n            optimizer.target.cleargrads()\n            loss_dic[name].backward()\n            optimizer.update()\n\n\nreporter\u306b\u8f9e\u66f8\u3092\u6e21\u3059\u3053\u3068\u3067Trainer\u306ePrintReport\u3067\u30ed\u30b9\u304c\u8868\u793a\u3067\u304d\u308b\u3088\u3046\u306b\u306a\u308a\u307e\u3059\u3002\n\u307e\u305f\u3001chainer=1.15\u4ee5\u524d\u3067\u306foptimizer.target.cleargrads()\u3067\u306f\u306a\u304foptimizer.zerograds()\u3092\u7528\u3044\u3066\u4e0b\u3055\u3044\u3002\u4e21\u8005\u306f\u524d\u8005\u304cNone\u3067\u3001\u5f8c\u8005\u304c0\u3067\u52fe\u914d\u3092\u57cb\u3081\u308b\u70b9\u3067\u7570\u306a\u308a\u307e\u3059\u3002\n\nPoint 2. Evaluator\u3092\u5b9a\u7fa9\u3059\u308b\nGAN\u306e\u8ad6\u6587\u3067\u306f\u5b66\u7fd2\u6e08\u307f\u30e2\u30c7\u30eb\u306e\u51fa\u529b\u753b\u50cf\u306e\u307f\u304c\u63cf\u304b\u308c\u3066\u3044\u308b\u3053\u3068\u304c\u591a\u3044\u3067\u3059\u304c\u3001\u5b66\u7fd2\u306b\u7528\u3044\u3066\u3044\u306a\u3044\u30e2\u30c7\u30eb\u306b\u5bfe\u3059\u308b\u8a55\u4fa1\u3092\u3057\u305f\u3044\u3053\u3068\u304c\u3042\u308a\u307e\u3059\u3002\u5177\u4f53\u7684\u306b\u306fVAE\u3068GAN\u3092\u7d44\u307f\u5408\u308f\u305b\u3066\u3044\u308b\u5834\u5408\u306a\u3069\u3067\u3059\uff08\u5b9f\u88c5\u4f8b\u306fdsanno\u3055\u3093\u306ehttps://github.com/dsanno/chainer-vae-gan \u304c\u53c2\u8003\u306b\u306a\u308b\u3068\u601d\u3044\u307e\u3059\uff09\u3002\nUpdater\u306e\u6642\u3068\u540c\u69d8\u306bchainer\u306b\u5b9f\u88c5\u3055\u308c\u3066\u3044\u308bEvaluator\u306e.__init__()\u3068.evaluate()\u3092\u4ee5\u4e0b\u306e\u3088\u3046\u306a\u5f62\u3067\u30aa\u30fc\u30d0\u30fc\u30e9\u30a4\u30c9\u3057\u307e\u3059\u3002\n\nGAN_Evaluator.py\nclass GAN_Evaluator(extensions.Evaluator):\n\n    def __init__(self, iterator, generator, discriminator, converter=convert.concat_examples,\ndevice=None, eval_hook=None, eval_func):\n        if isinstance(iterator, iterator_module.Iterator):\n            iterator = {'main': iterator}\n        self._iterators = iterator\n        self._targets = {'gen':generator, 'dis':discriminator}\n\n        self.converter = converter\n        self.device = device\n        self.eval_hook = eval_hook\n\n    def evaluate(self):\n        iterator = self._iterators['main']\n        gen = self._targets['gen']\n        dis = self._targets['dis']\n\n        it = copy.copy(iterator)\n        summary = reporter.DictSummary()\n        for batch in it:\n            observation = {}\n            with reporter.report_scope(observation):\n                in_arrays = self.converter(batch, self.device)\n                batch_size = in_arrays.shape[0]\n\n                x_batch = xp.array(in_arrays)\n                fake_data = gen(train=False)\n                input4dis = F.concat((fake_data, \\\n                              chainer.Variable(x_batch, volatile='on')),axis=0)\n                dis_output = dis(input4dis, train=False)\n                (dis_fake, dis_true) = F.split_axis(dis_output, 2, axis=0)\n                dis_tmp = self.dis(chainer.Variable(zero_fake, train=True)\n                zeros = chainer.Variable(xp.zeros(self.batch_size, dtype=np.int32))\n                ones = chainer.Variable(xp.ones(self.batch_size, dtype=np.int32))\n\n                loss_gen = F.softmax_cross_entropy(dis_fake, zeros)\n                loss_dis = F.softmax_cross_entropy(dis_real, ones) + \\\n                           F.softmax_cross_entropy(dis_tmp, zeros)\n\n                observation['dis/val/loss'] = loss_dis\n                observation['gen/val/loss'] = loss_gen\n\n            summary.add(observation)\n\n        return summary.compute_mean()\n\n\n\u4f7f\u3046\u304b\u308f\u304b\u308a\u307e\u305b\u3093\u304c\u3001Evaluator\u3001Updater\u3068\u3082\u306b\u30a4\u30f3\u30b9\u30bf\u30f3\u30b9\u304c\u4fdd\u6301\u3057\u3066\u3044\u308bChain\u3084optimizer\u3092\u53d6\u5f97\u3059\u308b\u305f\u3081\u306e.get_foo()\u3068\u3044\u3046\u95a2\u6570\u304c\u7528\u610f\u3055\u308c\u3066\u3044\u308b\u305f\u3081\u8f9e\u66f8\u306e\u5f62\u3067\u6e21\u3059\u5fc5\u8981\u304c\u3042\u308a\u4e0a\u306e\u3088\u3046\u306b\u66f8\u304f\u306e\u304c\u826f\u3044\u3068\u601d\u3044\u307e\u3059\u3002\n\u4ed6\u306b\u306fchainer.Variable\u3092volatile\u306b\u3057\u3066\u3044\u308b\u4ee5\u5916\u306b\u7279\u5fb4\u306f\u306a\u3044\u3068\u601d\u3044\u307e\u3059\u3002\n\nPoint 3. \u753b\u50cf\u3092\u4fdd\u5b58\u3059\u308b\nGAN\u306f\u751f\u6210\u30e2\u30c7\u30eb\u3067\u3059\u306e\u3067\u3001Generator\u306e\u51fa\u529b\u3092\u4fdd\u5b58\u3057\u305f\u304f\u306a\u308a\u307e\u3059\u3002\u305d\u3053\u3067Trainer\u306eextension\u3092\u81ea\u4f5c\u3057\u307e\u3059\u3002\u4e00\u822c\u306bextension\u3092\u4f5c\u6210\u3059\u308b\u306b\u306f\n\nmake_extension.py\n@training.make_extension(trigger=(args.interval, 'epoch'))\ndef foo():\n    \"\"\"\n    what you wanna do\n    \"\"\"\n\n\n\u306e\u3088\u3046\u306b\u5b9a\u7fa9\u3059\u308c\u3070\u3001trainer.extend(foo)\u3067\u4f7f\u3048\u307e\u3059\u3002Generator\u306e\u51fa\u529b\u753b\u50cf\u3092\u4fdd\u5b58\u3059\u308bextension\u306f\u4ee5\u4e0b\u306e\u3088\u3046\u306b\u306a\u308b\u304b\u3068\u601d\u3044\u307e\u3059\u3002\n\ngenerator_image.py\n@training.make_extension(trigger=(args.interval, 'epoch'))\ndef save_image(trainer):\n    gen = trainer.updater.gen\n    fake_image = gen(train=False)\n    _, ax = plt.subplots(row, col, sharex=True, sharey=True)\n    for i in range(row):\n        for j in range(col):\n            ax[i,j].imshow(fake_image[i*row+j, 0])\n            ax[i,j].set_axis_off()\n    plt.savefig(os.path.join(dir/to/save/file_name), dpi=600)\n    plt.close('all')\n\n\n\u6700\u5f8c\u306eplt.close('all')\u3092\u5fd8\u308c\u308b\u3068figure\u3092\u4f5c\u308a\u3059\u304e\u305f\u3053\u3068\u306b\u3088\u308bwarning\u304c\u51fa\u3066PrintReport\u304c\u5d29\u308c\u307e\u3059\u3057\u30e1\u30e2\u30ea\u3092\u7bc0\u7d04\u3059\u308b\u305f\u3081\u306b\u3082\u5fc5\u8981\u3067\u3059\u3002\n\u3053\u306e\u8a18\u4e8b\u3067\u306fTrainer\u3067\u8907\u6570\u306eChain\u3001optimizer\u3092\u6271\u3046\u65b9\u6cd5\u306b\u3064\u3044\u3066\u307e\u3068\u3081\u307e\u3057\u305f\u3002Trainer\u306b\u30ad\u30e3\u30c3\u30c1\u30a2\u30c3\u30d7\u3067\u304d\u306a\u3066\u3044\u306a\u304b\u3063\u305f\u306e\u3067\u3001\u4eca\u5f8c\u306e\u305f\u3081\u306b\u81ea\u5206\u306a\u308a\u306b\u516c\u5f0f\u30c9\u30ad\u30e5\u30e1\u30f3\u30c8\u3092\u8aad\u3093\u3067\u66f8\u304d\u307e\u3057\u305f\u3002\n\u81f3\u3089\u306a\u3044\u70b9\u3001\u9593\u9055\u3044\u306a\u3069\u304c\u3042\u308a\u307e\u3057\u305f\u3089\u6c17\u8efd\u306b\u30b3\u30e1\u30f3\u30c8\u3057\u3066\u3044\u305f\u3060\u3051\u308b\u3068\u5e78\u3044\u3067\u3059\u3002\n**\u3010\u8ffd\u8a18\u3011**(2017/03/01)\nchainer\u516c\u5f0f\u306b[DCGAN\u306e\u30b5\u30f3\u30d7\u30eb](https://github.com/pfnet/chainer/blob/master/examples/dcgan/updater.py)\u304c\u8ffd\u52a0\u3055\u308c\u307e\u3057\u305f\u3002\u3053\u3061\u3089\u3067\u306f\u3001\u30a8\u30ec\u30ac\u30f3\u30c8\u306bUpdater\u304c\u66f8\u304b\u308c\u3066\u3044\u307e\u3059\u306e\u3067\u662f\u975e\u305d\u3061\u3089\u3082\u3054\u89a7\u306b\u306a\u3063\u3066\u304f\u3060\u3055\u3044\u3002\n\n\u500b\u4eba\u7684\u306b\u4eca\u5e74\u306fGAN\u306b\u95a2\u3059\u308b\u8ad6\u6587\u304c\u304b\u306a\u308a\u591a\u3044\u3068\u611f\u3058\u3066\u3044\u307e\u3059\u3002\nGAN\u3092\u6271\u3046\u3068\u306a\u308b\u3068\u5fc5\u8981\u306a\u30e2\u30c7\u30eb\u306f\u6700\u4f4e2\u3064\u3001\u5834\u5408\u306b\u3088\u3063\u3066\u306f3\u3064\u306e\u3053\u3068\u3082\u3042\u308a\u307e\u3059\u3002\n\u3055\u3066\u3001chainer=1.11\u304b\u3089Trainer\u306a\u3069\u306b\u3088\u308b\u5b66\u7fd2\u30eb\u30fc\u30d7\u304c\u62bd\u8c61\u5316\u3055\u308c\u305f\u4e00\u65b9\u3001Trainer\u3067\u306f\u57fa\u672c\u7684\u306b1\u3064\u306e\u30e2\u30c7\u30eb\u3092\u53d7\u3051\u53d6\u308a\u5b66\u7fd2\u3092\u5b9f\u884c\u3059\u308b\u3088\u3046\u306b\u5b9f\u88c5\u3055\u308c\u3066\u3044\u308b\u305f\u3081GAN\u3092\u5b9f\u88c5\u3059\u308b\u5834\u5408\u306f\u3001\n\n```py\nfor epoch in six.moves.range(n_epoch):\n    perm = np.random.permutation(N)\n    \n    for i in six.moves.range(0, N, batch_size):\n        x_batch = x_train[i*batch_size:(i+1)*batch_size]\n        x = chainer.Variable(x_in)\n\n        (\u4e2d\u7565)\n       \n        loss_generator += tmp_loss_generator\n        loss_discriminator += tmp_loss_discriminator\n\n    optimizer_generator.zerograds()\n    optimizer.discriminator.zerograds()\n    loss_generator.backward()\n    loss_discriminator.backward()\n    optimizer_generator.update()\n    optimizer_discriminator.update()\n```\n\u306e\u3088\u3046\u306a\u66f8\u304d\u65b9\u3092\u3057\u3066\u3044\u308b\u65b9\u3082\u3044\u3089\u3063\u3057\u3083\u308b\u3068\u601d\u3044\u307e\u3059\u3002\n\n\u3053\u306e\u8a18\u4e8b\u3067\u306f\u3001GAN\u306e\u3088\u3046\u306a\u8907\u6570\u306e\u30e2\u30c7\u30eb\u3092\u540c\u6642\u306b\u5b66\u7fd2\u3055\u305b\u308b\u5834\u5408\u306e\u30e2\u30c0\u30f3\u306a\u66f8\u304d\u65b9\u3092\u7d39\u4ecb\u3057\u307e\u3059\u3002\n\n# 0. Trainer\u306e\u69cb\u9020\n\u79c1\u306f\u3001Trainer\u306e\u69cb\u9020\u306f\u4ee5\u4e0b\u306e\u56f3\u306e\u3088\u3046\u306b\u306a\u3063\u3066\u3044\u308b\u3068\u6349\u3048\u3066\u3044\u307e\u3059\u3002\n\n![image](https://qiita-image-store.s3.amazonaws.com/0/104539/1acbd0ff-504c-0f04-a6fd-a05404f4837b.png)\n\nTrainer\u3067\u8907\u6570\u306e\u30e2\u30c7\u30eb\u306e\u5b66\u7fd2\u3092\u5b9f\u884c\u3059\u308b\u5834\u5408\u3001\u5b9f\u969b\u306b\u66f8\u304f\u5fc5\u8981\u304c\u3042\u308b\u306e\u306fUpdater\u306e\u90e8\u5206\u3067\u3059\u3002\u4eca\u56de\u306f1\u3064\u306e\uff08\u753b\u50cf\uff09\u30c7\u30fc\u30bf\u30bb\u30c3\u30c8\u306b\u5bfe\u3057\u3066\u8907\u6570\u306e\u30e2\u30c7\u30eb\u5b66\u7fd2\u3059\u308b\u5834\u5408\u306e\u65b9\u91dd\u3092\u66f8\u304d\u307e\u3059\u3002\n\n\u307e\u305f\u3001\u4ee5\u4e0b\u64ec\u4f3c\u30b3\u30fc\u30c9\u3092\u7528\u3044\u307e\u3059\u304c\u4ee5\u4e0b\u306e\u30e2\u30b8\u30e5\u30fc\u30eb\u304c`import`\u3055\u308c\u3066\u3044\u3066\u3001`Chain`\u304c\u4ee5\u4e0b\u306e\u3088\u3046\u306b\u5b9a\u7fa9\u3055\u308c\u3066\u3044\u308b\u3068\u3057\u307e\u3059\u3002\n\n```py\nimport chainer\nimport chainer.functions as F\nimport chainer.links as L\nfrom chainer import cuda, training, reporter\nfrom chainer.datasets import get_mnist\nfrom chainer.training import trainer, extensions\nfrom chainer.dataset import convert\nfrom chainer.dataset import iterator as iterator_module\nfrom chainer.datasets import get_mnist\nfrom chainer import optimizer as optimizer_module\n```\n\n```net.py\nclass Generator(chainer.Chain):\n    \n    def __init__(self):\n        super(Generator, self).__init__(self, z_dim, batch_size, ...):\n            \"\"\"\n            \u7573\u307f\u8fbc\u307f\u5c64\u306a\u3069\u306e\u5b9a\u7fa9\n            \"\"\"\n\n    def __call__(self, train=True):\n        \"\"\"\n        feedforward\u3092\u5b9a\u7fa9\n\u3000\u3000\u3000\u3000\u3000\u3000\u3000\u3000\u3000\u3000\u3000\u3000\u3000\u3000\u3000\u3000train=True: volatile='off'\u306echainer.Variable\u3092\u8fd4\u3059\n        train=False: volatile='on'\u306echainer.Variable\u3092\u8fd4\u3059\n        \"\"\"\n        return generated_variable\n\nclass Discriminator(chainer.Chain):\n\n    def __init__(self):\n        super(Discriminator, self).__init__(self, ...):\n            \"\"\"\n            \u7573\u307f\u8fbc\u307f\u5c64\u306a\u3069\u3092\u5b9a\u7fa9\n            \"\"\"\n\n    def __call__(self, x, train=True):\n        \"\"\"\n        feedforward\u3092\u5b9a\u7fa9\n\u3000\u3000\u3000\u3000\u3000\u3000\u3000\u3000\u3000\u3000\u3000\u3000\u3000\u3000\u3000\u3000train=True: volatile='off'\u306echainer.Variable\u3092\u8fd4\u3059\n        train=False: volatile='on'\u306echainer.Variable\u3092\u8fd4\u3059\n        \"\"\"\n        return discriminated_variable\n```\n\n# Point 1: Updater\u3092\u5b9a\u7fa9\u3059\u308b\nTrainer\u3067\u5b66\u7fd2\u3092\u5b9f\u884c\u3059\u308b\u3068\u306f\u3044\u3048\u3001\u30d1\u30e9\u30e1\u30fc\u30bf\u66f4\u65b0\u3092\u62c5\u3063\u3066\u3044\u308b\u306e\u306f\u305d\u306e\u540d\u306e\u901a\u308a`Updater`\u3067\u3059\u3002\n`Updater`\u3092\u5b9a\u7fa9\u3059\u308b\u3068\u66f8\u304d\u307e\u3057\u305f\u304c\u3001\u5b9f\u969b\u306b\u306f`chainer.training.StandardUpdater`\u30af\u30e9\u30b9\u3092\u30aa\u30fc\u30d0\u30fc\u30e9\u30a4\u30c9\u3057\u307e\u3059\u3002\n`StandardUpdater`\u30af\u30e9\u30b9\u306f\n1. `.__init__()` \u3067iterator, optimizer\u306a\u3069\u3092\u53d7\u3051\u53d6\u308a\u3001\n2. `.update_core()` \u3067\u30df\u30cb\u30d0\u30c3\u30c1\u306b\u5bfe\u3059\u308b\u51e6\u7406\u3092\u5b9a\u7fa9\u3057\u3066\u3044\u307e\u3059\u3002\n\n\u3055\u3066\u3001\u3000GAN\u306eUpdater\u3092\u5b9a\u7fa9\u3059\u308b\u3068\u304d\u306f\u4e0a\u8a18\u30af\u30e9\u30b9\u3092\u4ee5\u4e0b\u306e\u3088\u3046\u306b\u30aa\u30fc\u30d0\u30fc\u30e9\u30a4\u30c9\u3057\u307e\u3059\u3002\n\n```GANUpdater.py\nclass GAN_Updater(training.StandardUpdater):\n\n    def __init__(self, iterator, batch_size, generator, discriminator, opt_gen, opt_dis,\nconverter=convert.concat_examples, device=None):\n    if isinstance(iterator, iterator_module.Iterator):\n        iterator = {'main':iterator}\n    self._iterators = iterator\n    self.batch_size = batch_size\n    self.gen = generator\n    self.dis = discriminator\n    self._optimizers = {'gen':optimizer_gen, 'dis':opt_dis}\n    self.converter = converter\n    self.device = device\n    self.iteration = 0\n\n    def update_core(self):\n        batch = self._iterators['main'].next()\n        in_arrays = self.converter(batch, self.device)\n        x_batch = xp.array(x_batch)\n        zero_fake = xp.zeros_lik(x_batch)\n        fake_data = self.gen(train=True)\n        input4dis = F.concat((fake_data, chainer.Variable(x_batch)), axis=0)\n        dis_output = self.dis(input4dis, train=True)\n        (dis_fake, dis_true) = F.split_axis(dis_output, 2, axis=0)\n        dis_tmp = self.dis(chainer.Variable(zero_fake, train=True)\n        zeros = chainer.Variable(xp.zeros(self.batch_size, dtype=np.int32))\n        ones = chainer.Variable(xp.ones(self.batch_size, dtype=np.int32))\n\n        loss_gen = F.softmax_cross_entropy(dis_fake, zeros)\n        loss_dis = F.softmax_cross_entropy(dis_real, ones) + \\\n                   F.softmax_cross_entropy(dis_tmp, zeros)\n\n        reporter.report({'gen/loss':loss_gen, 'dis/loss':loss_dis})\n        loss_dic = {'gen':loss_gen, 'dis':loss_dis}\n\n        for name, optimizer in six.iteritems(self._optimizers):\n            optimizer.target.cleargrads()\n            loss_dic[name].backward()\n            optimizer.update()\n```\n`reporter`\u306b**\u8f9e\u66f8**\u3092\u6e21\u3059\u3053\u3068\u3067Trainer\u306e`PrintReport`\u3067\u30ed\u30b9\u304c\u8868\u793a\u3067\u304d\u308b\u3088\u3046\u306b\u306a\u308a\u307e\u3059\u3002\n\u307e\u305f\u3001chainer=1.15\u4ee5\u524d\u3067\u306f`optimizer.target.cleargrads()`\u3067\u306f\u306a\u304f`optimizer.zerograds()`\u3092\u7528\u3044\u3066\u4e0b\u3055\u3044\u3002\u4e21\u8005\u306f\u524d\u8005\u304c`None`\u3067\u3001\u5f8c\u8005\u304c`0`\u3067\u52fe\u914d\u3092\u57cb\u3081\u308b\u70b9\u3067\u7570\u306a\u308a\u307e\u3059\u3002\n\n# Point 2. Evaluator\u3092\u5b9a\u7fa9\u3059\u308b\nGAN\u306e\u8ad6\u6587\u3067\u306f\u5b66\u7fd2\u6e08\u307f\u30e2\u30c7\u30eb\u306e\u51fa\u529b\u753b\u50cf\u306e\u307f\u304c\u63cf\u304b\u308c\u3066\u3044\u308b\u3053\u3068\u304c\u591a\u3044\u3067\u3059\u304c\u3001\u5b66\u7fd2\u306b\u7528\u3044\u3066\u3044\u306a\u3044\u30e2\u30c7\u30eb\u306b\u5bfe\u3059\u308b\u8a55\u4fa1\u3092\u3057\u305f\u3044\u3053\u3068\u304c\u3042\u308a\u307e\u3059\u3002\u5177\u4f53\u7684\u306b\u306fVAE\u3068GAN\u3092\u7d44\u307f\u5408\u308f\u305b\u3066\u3044\u308b\u5834\u5408\u306a\u3069\u3067\u3059\uff08\u5b9f\u88c5\u4f8b\u306fdsanno\u3055\u3093\u306ehttps://github.com/dsanno/chainer-vae-gan \u304c\u53c2\u8003\u306b\u306a\u308b\u3068\u601d\u3044\u307e\u3059\uff09\u3002\nUpdater\u306e\u6642\u3068\u540c\u69d8\u306bchainer\u306b\u5b9f\u88c5\u3055\u308c\u3066\u3044\u308b[`Evaluator`](http://docs.chainer.org/en/stable/reference/extensions.html#evaluator)\u306e`.__init__()`\u3068`.evaluate()`\u3092\u4ee5\u4e0b\u306e\u3088\u3046\u306a\u5f62\u3067\u30aa\u30fc\u30d0\u30fc\u30e9\u30a4\u30c9\u3057\u307e\u3059\u3002\n\n```GAN_Evaluator.py\nclass GAN_Evaluator(extensions.Evaluator):\n\n    def __init__(self, iterator, generator, discriminator, converter=convert.concat_examples,\ndevice=None, eval_hook=None, eval_func):\n        if isinstance(iterator, iterator_module.Iterator):\n            iterator = {'main': iterator}\n        self._iterators = iterator\n        self._targets = {'gen':generator, 'dis':discriminator}\n        \n        self.converter = converter\n        self.device = device\n        self.eval_hook = eval_hook\n\n    def evaluate(self):\n        iterator = self._iterators['main']\n        gen = self._targets['gen']\n        dis = self._targets['dis']\n\n        it = copy.copy(iterator)\n        summary = reporter.DictSummary()\n        for batch in it:\n            observation = {}\n            with reporter.report_scope(observation):\n                in_arrays = self.converter(batch, self.device)\n                batch_size = in_arrays.shape[0]\n                \n                x_batch = xp.array(in_arrays)\n                fake_data = gen(train=False)\n                input4dis = F.concat((fake_data, \\\n                              chainer.Variable(x_batch, volatile='on')),axis=0)\n                dis_output = dis(input4dis, train=False)\n                (dis_fake, dis_true) = F.split_axis(dis_output, 2, axis=0)\n                dis_tmp = self.dis(chainer.Variable(zero_fake, train=True)\n                zeros = chainer.Variable(xp.zeros(self.batch_size, dtype=np.int32))\n                ones = chainer.Variable(xp.ones(self.batch_size, dtype=np.int32))\n                \n                loss_gen = F.softmax_cross_entropy(dis_fake, zeros)\n                loss_dis = F.softmax_cross_entropy(dis_real, ones) + \\\n                           F.softmax_cross_entropy(dis_tmp, zeros)\n                \n                observation['dis/val/loss'] = loss_dis\n                observation['gen/val/loss'] = loss_gen\n\n            summary.add(observation)\n        \n        return summary.compute_mean()\n```\n\u4f7f\u3046\u304b\u308f\u304b\u308a\u307e\u305b\u3093\u304c\u3001Evaluator\u3001Updater\u3068\u3082\u306b\u30a4\u30f3\u30b9\u30bf\u30f3\u30b9\u304c\u4fdd\u6301\u3057\u3066\u3044\u308bChain\u3084optimizer\u3092\u53d6\u5f97\u3059\u308b\u305f\u3081\u306e`.get_foo()`\u3068\u3044\u3046\u95a2\u6570\u304c\u7528\u610f\u3055\u308c\u3066\u3044\u308b\u305f\u3081\u8f9e\u66f8\u306e\u5f62\u3067\u6e21\u3059\u5fc5\u8981\u304c\u3042\u308a\u4e0a\u306e\u3088\u3046\u306b\u66f8\u304f\u306e\u304c\u826f\u3044\u3068\u601d\u3044\u307e\u3059\u3002\n\u4ed6\u306b\u306fchainer.Variable\u3092`volatile`\u306b\u3057\u3066\u3044\u308b\u4ee5\u5916\u306b\u7279\u5fb4\u306f\u306a\u3044\u3068\u601d\u3044\u307e\u3059\u3002\n\n# Point 3. \u753b\u50cf\u3092\u4fdd\u5b58\u3059\u308b\nGAN\u306f\u751f\u6210\u30e2\u30c7\u30eb\u3067\u3059\u306e\u3067\u3001Generator\u306e\u51fa\u529b\u3092\u4fdd\u5b58\u3057\u305f\u304f\u306a\u308a\u307e\u3059\u3002\u305d\u3053\u3067Trainer\u306eextension\u3092\u81ea\u4f5c\u3057\u307e\u3059\u3002\u4e00\u822c\u306bextension\u3092\u4f5c\u6210\u3059\u308b\u306b\u306f\n\n```make_extension.py\n@training.make_extension(trigger=(args.interval, 'epoch'))\ndef foo():\n    \"\"\"\n    what you wanna do\n    \"\"\"\n```\n\u306e\u3088\u3046\u306b\u5b9a\u7fa9\u3059\u308c\u3070\u3001`trainer.extend(foo)`\u3067\u4f7f\u3048\u307e\u3059\u3002Generator\u306e\u51fa\u529b\u753b\u50cf\u3092\u4fdd\u5b58\u3059\u308bextension\u306f\u4ee5\u4e0b\u306e\u3088\u3046\u306b\u306a\u308b\u304b\u3068\u601d\u3044\u307e\u3059\u3002\n\n```generator_image.py\n@training.make_extension(trigger=(args.interval, 'epoch'))\ndef save_image(trainer):\n    gen = trainer.updater.gen\n    fake_image = gen(train=False)\n    _, ax = plt.subplots(row, col, sharex=True, sharey=True)\n    for i in range(row):\n        for j in range(col):\n            ax[i,j].imshow(fake_image[i*row+j, 0])\n            ax[i,j].set_axis_off()\n    plt.savefig(os.path.join(dir/to/save/file_name), dpi=600)\n    plt.close('all')\n```\n\u6700\u5f8c\u306e`plt.close('all')`\u3092\u5fd8\u308c\u308b\u3068figure\u3092\u4f5c\u308a\u3059\u304e\u305f\u3053\u3068\u306b\u3088\u308bwarning\u304c\u51fa\u3066PrintReport\u304c\u5d29\u308c\u307e\u3059\u3057\u30e1\u30e2\u30ea\u3092\u7bc0\u7d04\u3059\u308b\u305f\u3081\u306b\u3082\u5fc5\u8981\u3067\u3059\u3002\n\n\u3053\u306e\u8a18\u4e8b\u3067\u306fTrainer\u3067\u8907\u6570\u306eChain\u3001optimizer\u3092\u6271\u3046\u65b9\u6cd5\u306b\u3064\u3044\u3066\u307e\u3068\u3081\u307e\u3057\u305f\u3002Trainer\u306b\u30ad\u30e3\u30c3\u30c1\u30a2\u30c3\u30d7\u3067\u304d\u306a\u3066\u3044\u306a\u304b\u3063\u305f\u306e\u3067\u3001\u4eca\u5f8c\u306e\u305f\u3081\u306b\u81ea\u5206\u306a\u308a\u306b\u516c\u5f0f\u30c9\u30ad\u30e5\u30e1\u30f3\u30c8\u3092\u8aad\u3093\u3067\u66f8\u304d\u307e\u3057\u305f\u3002\n\u81f3\u3089\u306a\u3044\u70b9\u3001\u9593\u9055\u3044\u306a\u3069\u304c\u3042\u308a\u307e\u3057\u305f\u3089\u6c17\u8efd\u306b\u30b3\u30e1\u30f3\u30c8\u3057\u3066\u3044\u305f\u3060\u3051\u308b\u3068\u5e78\u3044\u3067\u3059\u3002\n", "tags": ["DeepLearning", "Chainer", "Python", "\u6a5f\u68b0\u5b66\u7fd2", "\u6df1\u5c64\u5b66\u7fd2"]}