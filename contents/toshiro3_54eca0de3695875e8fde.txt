{"context": " More than 1 year has passed since last update.\n\n\u306f\u3058\u3081\u306b\nHadoop Streaming\u3067MapReduce\u3092\u30b7\u30a7\u30eb\u3067\u5b9f\u88c5\u3059\u308b\u65b9\u6cd5\u3092\u8a18\u8ff0\u3057\u307e\u3059\u3002\n\n\u74b0\u5883\n\nCentOS 6.5\nCDH5\n\n\n\u69cb\u6210\n\n\n\n\u30db\u30b9\u30c8\u540d\nIP\u30a2\u30c9\u30ec\u30b9\nResourceManager\nNamenode\nNodeManager\nDatanode\nJobHistoryServer\n\n\n\n\nhadoop-master\n192.168.122.101\n\u25cb\n\u25cb\n-\n-\n\u25cb\n\n\nhadoop-master2\n192.168.122.102\n\u25cb\n\u25cb\n-\n-\n-\n\n\nhadoop-slave\n192.168.122.111\n-\n-\n\u25cb\n\u25cb\n-\n\n\nhadoop-slave2\n192.168.122.112\n-\n-\n\u25cb\n\u25cb\n-\n\n\nhadoop-slave3\n192.168.122.113\n-\n-\n\u25cb\n\u25cb\n-\n\n\nhadoop-client\n192.168.122.201\n-\n-\n-\n-\n-\n\n\n\n\u30af\u30e9\u30b9\u30bf\u306e\u69cb\u7bc9\u65b9\u6cd5\u306f\u3001CDH5\u3067hadoop\u306e\u30af\u30e9\u30b9\u30bf\u3092\u69cb\u7bc9\u3059\u308b\u3092\u3054\u53c2\u7167\u304f\u3060\u3055\u3044\u3002\n\nMapReduce\u306e\u5b9f\u88c5\n\u4eca\u56de\u306f\u3001\u30d5\u30a1\u30a4\u30eb\u306b\u542b\u307e\u308c\u308b\u5358\u8a9e\u306e\u6570\u3092\u30ab\u30a6\u30f3\u30c8\u3059\u308b\u30d7\u30ed\u30b0\u30e9\u30e0\u3092\u4f5c\u6210\u3057\u307e\u3059\u3002\n\nmapper\u306e\u5b9f\u88c5\n\n\nsample_mapper.sh\n#!/bin/bash\n\nwhile read -a words\ndo\n  for word in ${words[*]}\n  do\n    printf \"%s\\t1\\n\" $word\n  done\ndone\n\n\n\nreducer\u306e\u5b9f\u88c5\n\n\nsample_reducer.sh\n#!/bin/bash\n\ncurrent_key=\"\"\ntotal=0\n\nwhile read data\ndo\n  key=$(echo $data | awk '{print $1}')\n  value=$(echo $data | awk '{print $2}')\n  if [ \"$current_key\" != \"\" ] && [ \"$current_key\" != \"$key\" ] ; then\n    printf '%s\\t%d\\n' \"$current_key\" \"$total\"\n    current_key=$key\n    total=$value\n  else\n    current_key=$key\n    total=$((total+value))\n  fi\ndone\nprintf '%s\\t%d\\n' \"$current_key\" \"$total\"\n\n\n\n\u52d5\u4f5c\u78ba\u8a8d\n\u30af\u30e9\u30a4\u30a2\u30f3\u30c8\u3067\u52d5\u4f5c\u78ba\u8a8d\u3092\u3057\u307e\u3059\u3002\n\n\u52d5\u4f5c\u78ba\u8a8d\u7528\u306b\u89e3\u6790\u5bfe\u8c61\u306e\u30d5\u30a1\u30a4\u30eb\u3092HDFS\u3078put\u3057\u307e\u3059\u3002\n\n\nsample.txt\nJava Ruby Python Java Ruby Python Java\n\n\n$ sudo -u hdfs hadoop fs -put sample.txt input/sample.txt\n$ sudo -u hdfs hadoop fs -ls input/\nFound 1 items\n-rw-r--r--   3 hdfs hadoop         39 2014-09-20 06:59 input/sample.txt\n\n\nHadoop Streaming\u3092\u4f7f\u7528\u3057\u3066MapReduce\u3092\u5b9f\u884c\u3057\u307e\u3059\u3002\n\n$ sudo -u hdfs hadoop                                   \\\n  jar /usr/lib/hadoop-mapreduce/hadoop-streaming.jar    \\\n  -files   /tmp/sample_mapper.sh,/tmp/sample_reducer.sh \\\n  -input   input/sample.txt                             \\\n  -output  output/sample                                \\\n  -mapper  sample_mapper.sh                             \\\n  -reducer sample_reducer.sh\n\nHadoop Streaming\u3092\u4f7f\u7528\u3059\u308b\u5834\u5408\u306f\u3001jar\u306b hadoop-streaming.jar \u3092\u6307\u5b9a\u3057\u307e\u3059\u3002\n\u305d\u306e\u4ed6\u306e\u30aa\u30d7\u30b7\u30e7\u30f3\u306f\u4ee5\u4e0b\u306e\u901a\u308a\u3068\u306a\u308a\u307e\u3059\u3002\n\n\n\n\u30aa\u30d7\u30b7\u30e7\u30f3\n\u6982\u8981\n\n\n\n\nfiles\nMap/Reduce\u306e\u30af\u30e9\u30b9\u30bf\u3078\u30b3\u30d4\u30fc\u3059\u308b\u30d5\u30a1\u30a4\u30eb\u3092\u6307\u5b9a\u3057\u307e\u3059\n\n\ninput\n\u89e3\u6790\u306e\u5bfe\u8c61\u3068\u306a\u308b\u30d5\u30a1\u30a4\u30eb\u3092\u6307\u5b9a\u3057\u307e\u3059\n\n\noutput\n\u89e3\u6790\u7d50\u679c\u3092\u4fdd\u5b58\u3059\u308bHDFS\u4e0a\u306e\u30d1\u30b9\u3092\u6307\u5b9a\u3057\u307e\u3059\n\n\nmapper\nmap\u51e6\u7406\u3092\u5b9f\u88c5\u3057\u305f\u30d5\u30a1\u30a4\u30eb\u540d\u3092\u6307\u5b9a\u3057\u307e\u3059\n\n\nreducer\nreduce\u51e6\u7406\u3092\u5b9f\u88c5\u3057\u305f\u30d5\u30a1\u30a4\u30eb\u540d\u3092\u6307\u5b9a\u3057\u307e\u3059\n\n\n\nfiles\u30aa\u30d7\u30b7\u30e7\u30f3\u3067\u6307\u5b9a\u3057\u305f\u30d5\u30a1\u30a4\u30eb\u306f\u3001\u5404\u30ce\u30fc\u30c9\u3078\u30b3\u30d4\u30fc\u3055\u308c\u3001\u305d\u306e\u30b3\u30d4\u30fc\u3078\u306e\u30b7\u30f3\u30dc\u30ea\u30c3\u30af\u30ea\u30f3\u30b0\u304c\u5404\u30bf\u30b9\u30af\u306e\u4f5c\u696d\u7528\u30c7\u30a3\u30ec\u30af\u30c8\u30ea\u306b\u4f5c\u6210\u3055\u308c\u307e\u3059\u3002\n\u4e0a\u8a18\u306e\u5834\u5408\u306f\u3001files\u30aa\u30d7\u30b7\u30e7\u30f3\u3067\u3001 /tmp/sample_mapper.sh /tmp/sample_reducer.sh\u3092\u6307\u5b9a\u3057\u3066\u3044\u308b\u305f\u3081\u3001\uff12\u3064\u306e\u30d5\u30a1\u30a4\u30eb\u304c\u5404\u30ce\u30fc\u30c9\u3078\u30b3\u30d4\u30fc\u3055\u308c\u307e\u3059\u3002\n\u307e\u305f\u3001\u5404\u30bf\u30b9\u30af\u306e\u4f5c\u696d\u7528\u30c7\u30a3\u30ec\u30af\u30c8\u30ea\u306b sample_mapper.sh sample_reducer.sh\u3068\u3044\u3046\u540d\u524d\u306e\u30b7\u30f3\u30dc\u30ea\u30c3\u30af\u30ea\u30f3\u30af\u304c\u4f5c\u6210\u3055\u308c\u307e\u3059\u3002\n\u305d\u306e\u305f\u3081\u3001mapper\u30aa\u30d7\u30b7\u30e7\u30f3\u3078\u3001 sample_mapper.sh reducer\u30aa\u30d7\u30b7\u30e7\u30f3\u3078\u3001 sample_reducer.sh\u3092\u6307\u5b9a\u3059\u308c\u3070\u3088\u3044\u3053\u3068\u306b\u306a\u308a\u307e\u3059\u3002\n\n\u89e3\u6790\u7d50\u679c\u3092\u78ba\u8a8d\u3057\u307e\u3059\u3002\n\n$ sudo -u hdfs hadoop fs -cat 'output/sample/part-*'\nJava    3\nPython  2\nRuby    2\n\n\n\u53c2\u8003\n\nHadoop Streaming\nTips and Guidelines\n\n\n## \u306f\u3058\u3081\u306b\n\nHadoop Streaming\u3067MapReduce\u3092\u30b7\u30a7\u30eb\u3067\u5b9f\u88c5\u3059\u308b\u65b9\u6cd5\u3092\u8a18\u8ff0\u3057\u307e\u3059\u3002\n\n## \u74b0\u5883\n\n* CentOS 6.5\n* CDH5\n\n## \u69cb\u6210\n\n|\u30db\u30b9\u30c8\u540d      |IP\u30a2\u30c9\u30ec\u30b9     |ResourceManager|Namenode|NodeManager|Datanode|JobHistoryServer|\n|:-------------|:--------------|:-------------:|:------:|:---------:|:------:|:--------------:|\n|hadoop-master |192.168.122.101|\u25cb             |\u25cb      |-          |-       |\u25cb              |\n|hadoop-master2|192.168.122.102|\u25cb             |\u25cb      |-          |-       |-               |\n|hadoop-slave  |192.168.122.111|-              |-       |\u25cb         |\u25cb      |-               |\n|hadoop-slave2 |192.168.122.112|-              |-       |\u25cb         |\u25cb      |-               |\n|hadoop-slave3 |192.168.122.113|-              |-       |\u25cb         |\u25cb      |-               |\n|hadoop-client |192.168.122.201|-              |-       |-          |-       |-               |\n\n\u30af\u30e9\u30b9\u30bf\u306e\u69cb\u7bc9\u65b9\u6cd5\u306f\u3001[CDH5\u3067hadoop\u306e\u30af\u30e9\u30b9\u30bf\u3092\u69cb\u7bc9\u3059\u308b](http://qiita.com/toshiro3/items/6e010b837246598a92ee)\u3092\u3054\u53c2\u7167\u304f\u3060\u3055\u3044\u3002\n\n## MapReduce\u306e\u5b9f\u88c5\n\n\u4eca\u56de\u306f\u3001\u30d5\u30a1\u30a4\u30eb\u306b\u542b\u307e\u308c\u308b\u5358\u8a9e\u306e\u6570\u3092\u30ab\u30a6\u30f3\u30c8\u3059\u308b\u30d7\u30ed\u30b0\u30e9\u30e0\u3092\u4f5c\u6210\u3057\u307e\u3059\u3002\n\n* mapper\u306e\u5b9f\u88c5\n\n```bash:sample_mapper.sh\n#!/bin/bash\n\nwhile read -a words\ndo\n  for word in ${words[*]}\n  do\n    printf \"%s\\t1\\n\" $word\n  done\ndone\n```\n\n* reducer\u306e\u5b9f\u88c5\n\n```bash:sample_reducer.sh\n#!/bin/bash\n\ncurrent_key=\"\"\ntotal=0\n\nwhile read data\ndo\n  key=$(echo $data | awk '{print $1}')\n  value=$(echo $data | awk '{print $2}')\n  if [ \"$current_key\" != \"\" ] && [ \"$current_key\" != \"$key\" ] ; then\n    printf '%s\\t%d\\n' \"$current_key\" \"$total\"\n    current_key=$key\n    total=$value\n  else\n    current_key=$key\n    total=$((total+value))\n  fi\ndone\nprintf '%s\\t%d\\n' \"$current_key\" \"$total\"\n```\n\n## \u52d5\u4f5c\u78ba\u8a8d\n\n\u30af\u30e9\u30a4\u30a2\u30f3\u30c8\u3067\u52d5\u4f5c\u78ba\u8a8d\u3092\u3057\u307e\u3059\u3002\n\n* \u52d5\u4f5c\u78ba\u8a8d\u7528\u306b\u89e3\u6790\u5bfe\u8c61\u306e\u30d5\u30a1\u30a4\u30eb\u3092HDFS\u3078put\u3057\u307e\u3059\u3002\n\n```txt:sample.txt\nJava Ruby Python Java Ruby Python Java\n```\n\n```shell\n$ sudo -u hdfs hadoop fs -put sample.txt input/sample.txt\n$ sudo -u hdfs hadoop fs -ls input/\nFound 1 items\n-rw-r--r--   3 hdfs hadoop         39 2014-09-20 06:59 input/sample.txt\n```\n* Hadoop Streaming\u3092\u4f7f\u7528\u3057\u3066MapReduce\u3092\u5b9f\u884c\u3057\u307e\u3059\u3002\n\n```shell\n$ sudo -u hdfs hadoop                                   \\\n  jar /usr/lib/hadoop-mapreduce/hadoop-streaming.jar    \\\n  -files   /tmp/sample_mapper.sh,/tmp/sample_reducer.sh \\\n  -input   input/sample.txt                             \\\n  -output  output/sample                                \\\n  -mapper  sample_mapper.sh                             \\\n  -reducer sample_reducer.sh\n```\n\nHadoop Streaming\u3092\u4f7f\u7528\u3059\u308b\u5834\u5408\u306f\u3001jar\u306b __hadoop-streaming.jar__ \u3092\u6307\u5b9a\u3057\u307e\u3059\u3002\n\n\u305d\u306e\u4ed6\u306e\u30aa\u30d7\u30b7\u30e7\u30f3\u306f\u4ee5\u4e0b\u306e\u901a\u308a\u3068\u306a\u308a\u307e\u3059\u3002\n\n|\u30aa\u30d7\u30b7\u30e7\u30f3|\u6982\u8981                                                |\n|:---------|:---------------------------------------------------|\n|files     |Map/Reduce\u306e\u30af\u30e9\u30b9\u30bf\u3078\u30b3\u30d4\u30fc\u3059\u308b\u30d5\u30a1\u30a4\u30eb\u3092\u6307\u5b9a\u3057\u307e\u3059|\n|input     |\u89e3\u6790\u306e\u5bfe\u8c61\u3068\u306a\u308b\u30d5\u30a1\u30a4\u30eb\u3092\u6307\u5b9a\u3057\u307e\u3059                |\n|output    |\u89e3\u6790\u7d50\u679c\u3092\u4fdd\u5b58\u3059\u308bHDFS\u4e0a\u306e\u30d1\u30b9\u3092\u6307\u5b9a\u3057\u307e\u3059          |\n|mapper    |map\u51e6\u7406\u3092\u5b9f\u88c5\u3057\u305f\u30d5\u30a1\u30a4\u30eb\u540d\u3092\u6307\u5b9a\u3057\u307e\u3059             |\n|reducer   |reduce\u51e6\u7406\u3092\u5b9f\u88c5\u3057\u305f\u30d5\u30a1\u30a4\u30eb\u540d\u3092\u6307\u5b9a\u3057\u307e\u3059          |\n\nfiles\u30aa\u30d7\u30b7\u30e7\u30f3\u3067\u6307\u5b9a\u3057\u305f\u30d5\u30a1\u30a4\u30eb\u306f\u3001\u5404\u30ce\u30fc\u30c9\u3078\u30b3\u30d4\u30fc\u3055\u308c\u3001\u305d\u306e\u30b3\u30d4\u30fc\u3078\u306e\u30b7\u30f3\u30dc\u30ea\u30c3\u30af\u30ea\u30f3\u30b0\u304c\u5404\u30bf\u30b9\u30af\u306e\u4f5c\u696d\u7528\u30c7\u30a3\u30ec\u30af\u30c8\u30ea\u306b\u4f5c\u6210\u3055\u308c\u307e\u3059\u3002\n\u4e0a\u8a18\u306e\u5834\u5408\u306f\u3001files\u30aa\u30d7\u30b7\u30e7\u30f3\u3067\u3001 __/tmp/sample_mapper.sh__ __/tmp/sample_reducer.sh__\u3092\u6307\u5b9a\u3057\u3066\u3044\u308b\u305f\u3081\u3001\uff12\u3064\u306e\u30d5\u30a1\u30a4\u30eb\u304c\u5404\u30ce\u30fc\u30c9\u3078\u30b3\u30d4\u30fc\u3055\u308c\u307e\u3059\u3002\n\u307e\u305f\u3001\u5404\u30bf\u30b9\u30af\u306e\u4f5c\u696d\u7528\u30c7\u30a3\u30ec\u30af\u30c8\u30ea\u306b __sample_mapper.sh__ __sample_reducer.sh__\u3068\u3044\u3046\u540d\u524d\u306e\u30b7\u30f3\u30dc\u30ea\u30c3\u30af\u30ea\u30f3\u30af\u304c\u4f5c\u6210\u3055\u308c\u307e\u3059\u3002\n\u305d\u306e\u305f\u3081\u3001mapper\u30aa\u30d7\u30b7\u30e7\u30f3\u3078\u3001 __sample_mapper.sh__ reducer\u30aa\u30d7\u30b7\u30e7\u30f3\u3078\u3001 __sample_reducer.sh__\u3092\u6307\u5b9a\u3059\u308c\u3070\u3088\u3044\u3053\u3068\u306b\u306a\u308a\u307e\u3059\u3002\n\n* \u89e3\u6790\u7d50\u679c\u3092\u78ba\u8a8d\u3057\u307e\u3059\u3002\n\n```shell\n$ sudo -u hdfs hadoop fs -cat 'output/sample/part-*'\nJava    3\nPython  2\nRuby    2\n```\n\n## \u53c2\u8003\n\n* [Hadoop Streaming](http://hadoop.apache.org/docs/r2.5.1/hadoop-mapreduce-client/hadoop-mapreduce-client-core/HadoopStreaming.html)\n* [Tips and Guidelines](https://www.cloudera.com/content/cloudera-content/cloudera-docs/CDH5/5.0/CDH5-Installation-Guide/cdh5ig_tips_guidelines.html)\n", "tags": ["CDH5", "hadoop", "hadoop-streaming"]}