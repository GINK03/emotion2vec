{"context": "\n\n\u554f\u984c\n\nApache Spark \u3067\u30af\u30e9\u30b9\u306b\u5b9a\u7fa9\u3055\u308c\u305f\u30e1\u30bd\u30c3\u30c9\u3092 map \u3057\u3088\u3046\u3068\u3059\u308b\u3068 Task not serializable \u304c\u767a\u751f\u3059\u308b\n\n$ spark-shell\nscala> import org.apache.spark.sql.SparkSession\nscala> val ss = SparkSession.builder.getOrCreate\n\nscala> val ds = ss.createDataset(Seq(1, 2, 3))\n\nscala> :paste\n\nclass C {\n  def square(i: Int): Int = i * i\n}\n\nscala> val c = new C()\n\nscala> ds.map(c.square).show\norg.apache.spark.SparkException: Task not serializable\n  at org.apache.spark.util.ClosureCleaner$.ensureSerializable(ClosureCleaner.scala:298)\n  at org.apache.spark.util.ClosureCleaner$.org$apache$spark$util$ClosureCleaner$$clean(ClosureCleaner.scala:288)\n  at org.apache.spark.util.ClosureCleaner$.clean(ClosureCleaner.scala:108)\n  at org.apache.spark.SparkContext.clean(SparkContext.scala:2039)\n  at org.apache.spark.rdd.RDD$$anonfun$mapPartitionsWithIndex$1.apply(RDD.scala:817)\n  at org.apache.spark.rdd.RDD$$anonfun$mapPartitionsWithIndex$1.apply(RDD.scala:816)\n  at org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:151)\n  at org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:112)\n  at org.apache.spark.rdd.RDD.withScope(RDD.scala:358)\n  at org.apache.spark.rdd.RDD.mapPartitionsWithIndex(RDD.scala:816)\n  at org.apache.spark.sql.execution.WholeStageCodegenExec.doExecute(WholeStageCodegenExec.scala:364)\n  at org.apache.spark.sql.execution.SparkPlan$$anonfun$execute$1.apply(SparkPlan.scala:115)\n  at org.apache.spark.sql.execution.SparkPlan$$anonfun$execute$1.apply(SparkPlan.scala:115)\n  at org.apache.spark.sql.execution.SparkPlan$$anonfun$executeQuery$1.apply(SparkPlan.scala:136)\n  at org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:151)\n  at org.apache.spark.sql.execution.SparkPlan.executeQuery(SparkPlan.scala:133)\n  at org.apache.spark.sql.execution.SparkPlan.execute(SparkPlan.scala:114)\n  at org.apache.spark.sql.execution.SparkPlan.getByteArrayRdd(SparkPlan.scala:240)\n  at org.apache.spark.sql.execution.SparkPlan.executeTake(SparkPlan.scala:323)\n  at org.apache.spark.sql.execution.CollectLimitExec.executeCollect(limit.scala:39)\n  at org.apache.spark.sql.Dataset$$anonfun$org$apache$spark$sql$Dataset$$execute$1$1.apply(Dataset.scala:2193)\n  at org.apache.spark.sql.execution.SQLExecution$.withNewExecutionId(SQLExecution.scala:57)\n  at org.apache.spark.sql.Dataset.withNewExecutionId(Dataset.scala:2546)\n  at org.apache.spark.sql.Dataset.org$apache$spark$sql$Dataset$$execute$1(Dataset.scala:2192)\n  at org.apache.spark.sql.Dataset.org$apache$spark$sql$Dataset$$collect(Dataset.scala:2199)\n  at org.apache.spark.sql.Dataset$$anonfun$head$1.apply(Dataset.scala:1935)\n  at org.apache.spark.sql.Dataset$$anonfun$head$1.apply(Dataset.scala:1934)\n  at org.apache.spark.sql.Dataset.withTypedCallback(Dataset.scala:2576)\n  at org.apache.spark.sql.Dataset.head(Dataset.scala:1934)\n  at org.apache.spark.sql.Dataset.take(Dataset.scala:2149)\n  at org.apache.spark.sql.Dataset.showString(Dataset.scala:239)\n  at org.apache.spark.sql.Dataset.show(Dataset.scala:526)\n  at org.apache.spark.sql.Dataset.show(Dataset.scala:486)\n  at org.apache.spark.sql.Dataset.show(Dataset.scala:495)\n  ... 48 elided\nCaused by: java.io.NotSerializableException: C\nSerialization stack:\n    - object not serializable (class: C, value: C@440da0cb)\n    - field (class: $iw, name: c, type: class C)\n    - object (class $iw, $iw@63fa7459)\n    - field (class: $iw, name: $iw, type: class $iw)\n    - object (class $iw, $iw@3a04aa02)\n    - field (class: $iw, name: $iw, type: class $iw)\n    - object (class $iw, $iw@4dd42f69)\n    - field (class: $iw, name: $iw, type: class $iw)\n    - object (class $iw, $iw@6b46d353)\n    - field (class: $iw, name: $iw, type: class $iw)\n    - object (class $iw, $iw@61716ddf)\n    - field (class: $iw, name: $iw, type: class $iw)\n    - object (class $iw, $iw@6335b60)\n    - field (class: $iw, name: $iw, type: class $iw)\n    - object (class $iw, $iw@3ed2f699)\n    - field (class: $iw, name: $iw, type: class $iw)\n    - object (class $iw, $iw@12f190db)\n    - field (class: $line60.$read, name: $iw, type: class $iw)\n    - object (class $line60.$read, $line60.$read@3508cc94)\n    - field (class: $iw, name: $line60$read, type: class $line60.$read)\n    - object (class $iw, $iw@38360fc3)\n    - field (class: $iw, name: $outer, type: class $iw)\n    - object (class $iw, $iw@5681c40a)\n    - field (class: $anonfun$1, name: $outer, type: class $iw)\n    - object (class $anonfun$1, <function1>)\n    - field (class: org.apache.spark.sql.catalyst.expressions.Literal, name: value, type: class java.lang.Object)\n    - object (class org.apache.spark.sql.catalyst.expressions.Literal, <function1>)\n    - element of array (index: 0)\n    - array (class [Ljava.lang.Object;, size 1)\n    - field (class: org.apache.spark.sql.execution.WholeStageCodegenExec$$anonfun$8, name: references$1, type: class [Ljava.lang.Object;)\n    - object (class org.apache.spark.sql.execution.WholeStageCodegenExec$$anonfun$8, <function2>)\n  at org.apache.spark.serializer.SerializationDebugger$.improveException(SerializationDebugger.scala:40)\n  at org.apache.spark.serializer.JavaSerializationStream.writeObject(JavaSerializer.scala:46)\n  at org.apache.spark.serializer.JavaSerializerInstance.serialize(JavaSerializer.scala:100)\n  at org.apache.spark.util.ClosureCleaner$.ensureSerializable(ClosureCleaner.scala:295)\n  ... 81 more\n\n\n\u3061\u306a\u307f\u306b class \u3067\u306f\u306a\u304f object \u3067\u30b7\u30f3\u30b0\u30eb\u30c8\u30f3\u306b\u3057\u305f\u5834\u5408\u306f\u767a\u751f\u3057\u306a\u304b\u3063\u305f\n\nscala> :paste\n\nobject O {\n  def square(i: Int): Int = i * i\n}\n\nscala> ds.map(O.square).show\n+-----+\n|value|\n+-----+\n|    1|\n|    4|\n|    9|\n+-----+\n\n\n\u539f\u56e0\n\n\u30e1\u30bd\u30c3\u30c9\u9069\u7528\u304c\u30af\u30ed\u30fc\u30b8\u30e3\u5316\u3055\u308c\u308b\u969b\u306b\u3001\u30e1\u30bd\u30c3\u30c9\u304c\u6240\u5c5e\u3059\u308b\u30af\u30e9\u30b9\u3054\u3068\u30af\u30ed\u30fc\u30b8\u30e3\u304c\u4f5c\u3089\u308c\u308b\n\u5206\u6563\u51e6\u7406\u306e\u305f\u3081\u3001\u30af\u30ed\u30fc\u30b8\u30e3\u306f\u30b7\u30ea\u30a2\u30e9\u30a4\u30ba\u3055\u308c\u3066\u5404\u8a08\u7b97\u30ce\u30fc\u30c9\u306b\u9001\u3089\u308c\u308b\n\u30af\u30e9\u30b9\u306f\u305d\u306e\u307e\u307e\u3067\u306f\u30b7\u30ea\u30a2\u30e9\u30a4\u30ba\u3067\u304d\u306a\u3044\u305f\u3081\u30a8\u30e9\u30fc\u304c\u767a\u751f\u3059\u308b\n\nCaused by: java.io.NotSerializableException: C\nSerialization stack:\n    - object not serializable (class: C, value: C@440da0cb)\n    - field (class: $iw, name: c, type: class C)\n\n\n\u89e3\u6c7a\u7b56\n\n\u6b21\u306e\u3044\u305a\u308c\u304b\u3067\u89e3\u6c7a\u3067\u304d\u308b\n\n\nA. \u30af\u30e9\u30b9\u306b java.io.Serializable \u3092\u7d99\u627f\u3055\u305b\u308b\nscala> :paste\n\nclass C extends java.io.Serializable {\n  def square(i: Int): Int = i * i\n}\n\nscala> val c = new C()\n\nscala> ds.map(c.square).show\n+-----+\n|value|\n+-----+\n|    1|\n|    4|\n|    9|\n+-----+\n\n\n\nobject \u3092\u4f7f\u3046\u3068\u30a8\u30e9\u30fc\u306b\u306a\u3089\u306a\u304b\u3063\u305f\u306e\u3067 object \u306f\u3082\u3068\u3082\u3068Serializable\u306a\u306e\u304b\u3082\u3057\u308c\u306a\u3044\n\n\nB. \u51e6\u7406\u3092\u30e1\u30bd\u30c3\u30c9\u3067\u306f\u306a\u304f\u95a2\u6570\u3068\u3057\u3066\u5b9a\u7fa9\u3059\u308b\nscala> :paste\n\nclass C extends java.io.Serializable {\n  val square: Int => Int = i => i * i\n}\n\nscala> val c = new C()\n\nscala> ds.map(c.square).show\n+-----+\n|value|\n+-----+\n|    1|\n|    4|\n|    9|\n+-----+\n\n\n\u95a2\u6570\u5185\u90e8\u3067C\u306e\u5225\u306e\u30e1\u30f3\u30d0\u3092\u53c2\u7167\u3057\u3066\u305f\u308a\u3059\u308b\u3068\u7121\u7406\u306a\u6c17\u3082\u3059\u308b\n\n\n\u53c2\u8003\n\nscala - Task not serializable: java.io.NotSerializableException when calling function outside closure only on classes not objects - Stack Overflow\n\n## \u554f\u984c\n\n* Apache Spark \u3067\u30af\u30e9\u30b9\u306b\u5b9a\u7fa9\u3055\u308c\u305f\u30e1\u30bd\u30c3\u30c9\u3092 `map` \u3057\u3088\u3046\u3068\u3059\u308b\u3068 `Task not serializable` \u304c\u767a\u751f\u3059\u308b\n\n```scala\n$ spark-shell\nscala> import org.apache.spark.sql.SparkSession\nscala> val ss = SparkSession.builder.getOrCreate\n\nscala> val ds = ss.createDataset(Seq(1, 2, 3))\n\nscala> :paste\n\nclass C {\n  def square(i: Int): Int = i * i\n}\n \nscala> val c = new C()\n\nscala> ds.map(c.square).show\norg.apache.spark.SparkException: Task not serializable\n  at org.apache.spark.util.ClosureCleaner$.ensureSerializable(ClosureCleaner.scala:298)\n  at org.apache.spark.util.ClosureCleaner$.org$apache$spark$util$ClosureCleaner$$clean(ClosureCleaner.scala:288)\n  at org.apache.spark.util.ClosureCleaner$.clean(ClosureCleaner.scala:108)\n  at org.apache.spark.SparkContext.clean(SparkContext.scala:2039)\n  at org.apache.spark.rdd.RDD$$anonfun$mapPartitionsWithIndex$1.apply(RDD.scala:817)\n  at org.apache.spark.rdd.RDD$$anonfun$mapPartitionsWithIndex$1.apply(RDD.scala:816)\n  at org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:151)\n  at org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:112)\n  at org.apache.spark.rdd.RDD.withScope(RDD.scala:358)\n  at org.apache.spark.rdd.RDD.mapPartitionsWithIndex(RDD.scala:816)\n  at org.apache.spark.sql.execution.WholeStageCodegenExec.doExecute(WholeStageCodegenExec.scala:364)\n  at org.apache.spark.sql.execution.SparkPlan$$anonfun$execute$1.apply(SparkPlan.scala:115)\n  at org.apache.spark.sql.execution.SparkPlan$$anonfun$execute$1.apply(SparkPlan.scala:115)\n  at org.apache.spark.sql.execution.SparkPlan$$anonfun$executeQuery$1.apply(SparkPlan.scala:136)\n  at org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:151)\n  at org.apache.spark.sql.execution.SparkPlan.executeQuery(SparkPlan.scala:133)\n  at org.apache.spark.sql.execution.SparkPlan.execute(SparkPlan.scala:114)\n  at org.apache.spark.sql.execution.SparkPlan.getByteArrayRdd(SparkPlan.scala:240)\n  at org.apache.spark.sql.execution.SparkPlan.executeTake(SparkPlan.scala:323)\n  at org.apache.spark.sql.execution.CollectLimitExec.executeCollect(limit.scala:39)\n  at org.apache.spark.sql.Dataset$$anonfun$org$apache$spark$sql$Dataset$$execute$1$1.apply(Dataset.scala:2193)\n  at org.apache.spark.sql.execution.SQLExecution$.withNewExecutionId(SQLExecution.scala:57)\n  at org.apache.spark.sql.Dataset.withNewExecutionId(Dataset.scala:2546)\n  at org.apache.spark.sql.Dataset.org$apache$spark$sql$Dataset$$execute$1(Dataset.scala:2192)\n  at org.apache.spark.sql.Dataset.org$apache$spark$sql$Dataset$$collect(Dataset.scala:2199)\n  at org.apache.spark.sql.Dataset$$anonfun$head$1.apply(Dataset.scala:1935)\n  at org.apache.spark.sql.Dataset$$anonfun$head$1.apply(Dataset.scala:1934)\n  at org.apache.spark.sql.Dataset.withTypedCallback(Dataset.scala:2576)\n  at org.apache.spark.sql.Dataset.head(Dataset.scala:1934)\n  at org.apache.spark.sql.Dataset.take(Dataset.scala:2149)\n  at org.apache.spark.sql.Dataset.showString(Dataset.scala:239)\n  at org.apache.spark.sql.Dataset.show(Dataset.scala:526)\n  at org.apache.spark.sql.Dataset.show(Dataset.scala:486)\n  at org.apache.spark.sql.Dataset.show(Dataset.scala:495)\n  ... 48 elided\nCaused by: java.io.NotSerializableException: C\nSerialization stack:\n    - object not serializable (class: C, value: C@440da0cb)\n    - field (class: $iw, name: c, type: class C)\n    - object (class $iw, $iw@63fa7459)\n    - field (class: $iw, name: $iw, type: class $iw)\n    - object (class $iw, $iw@3a04aa02)\n    - field (class: $iw, name: $iw, type: class $iw)\n    - object (class $iw, $iw@4dd42f69)\n    - field (class: $iw, name: $iw, type: class $iw)\n    - object (class $iw, $iw@6b46d353)\n    - field (class: $iw, name: $iw, type: class $iw)\n    - object (class $iw, $iw@61716ddf)\n    - field (class: $iw, name: $iw, type: class $iw)\n    - object (class $iw, $iw@6335b60)\n    - field (class: $iw, name: $iw, type: class $iw)\n    - object (class $iw, $iw@3ed2f699)\n    - field (class: $iw, name: $iw, type: class $iw)\n    - object (class $iw, $iw@12f190db)\n    - field (class: $line60.$read, name: $iw, type: class $iw)\n    - object (class $line60.$read, $line60.$read@3508cc94)\n    - field (class: $iw, name: $line60$read, type: class $line60.$read)\n    - object (class $iw, $iw@38360fc3)\n    - field (class: $iw, name: $outer, type: class $iw)\n    - object (class $iw, $iw@5681c40a)\n    - field (class: $anonfun$1, name: $outer, type: class $iw)\n    - object (class $anonfun$1, <function1>)\n    - field (class: org.apache.spark.sql.catalyst.expressions.Literal, name: value, type: class java.lang.Object)\n    - object (class org.apache.spark.sql.catalyst.expressions.Literal, <function1>)\n    - element of array (index: 0)\n    - array (class [Ljava.lang.Object;, size 1)\n    - field (class: org.apache.spark.sql.execution.WholeStageCodegenExec$$anonfun$8, name: references$1, type: class [Ljava.lang.Object;)\n    - object (class org.apache.spark.sql.execution.WholeStageCodegenExec$$anonfun$8, <function2>)\n  at org.apache.spark.serializer.SerializationDebugger$.improveException(SerializationDebugger.scala:40)\n  at org.apache.spark.serializer.JavaSerializationStream.writeObject(JavaSerializer.scala:46)\n  at org.apache.spark.serializer.JavaSerializerInstance.serialize(JavaSerializer.scala:100)\n  at org.apache.spark.util.ClosureCleaner$.ensureSerializable(ClosureCleaner.scala:295)\n  ... 81 more\n```\n\n* \u3061\u306a\u307f\u306b `class` \u3067\u306f\u306a\u304f `object` \u3067\u30b7\u30f3\u30b0\u30eb\u30c8\u30f3\u306b\u3057\u305f\u5834\u5408\u306f\u767a\u751f\u3057\u306a\u304b\u3063\u305f\n\n```scala\nscala> :paste\n\nobject O {\n  def square(i: Int): Int = i * i\n}\n \nscala> ds.map(O.square).show\n+-----+\n|value|\n+-----+\n|    1|\n|    4|\n|    9|\n+-----+\n```\n\n## \u539f\u56e0\n\n* \u30e1\u30bd\u30c3\u30c9\u9069\u7528\u304c\u30af\u30ed\u30fc\u30b8\u30e3\u5316\u3055\u308c\u308b\u969b\u306b\u3001\u30e1\u30bd\u30c3\u30c9\u304c\u6240\u5c5e\u3059\u308b\u30af\u30e9\u30b9\u3054\u3068\u30af\u30ed\u30fc\u30b8\u30e3\u304c\u4f5c\u3089\u308c\u308b\n* \u5206\u6563\u51e6\u7406\u306e\u305f\u3081\u3001\u30af\u30ed\u30fc\u30b8\u30e3\u306f\u30b7\u30ea\u30a2\u30e9\u30a4\u30ba\u3055\u308c\u3066\u5404\u8a08\u7b97\u30ce\u30fc\u30c9\u306b\u9001\u3089\u308c\u308b\n* \u30af\u30e9\u30b9\u306f\u305d\u306e\u307e\u307e\u3067\u306f\u30b7\u30ea\u30a2\u30e9\u30a4\u30ba\u3067\u304d\u306a\u3044\u305f\u3081\u30a8\u30e9\u30fc\u304c\u767a\u751f\u3059\u308b\n\n```\nCaused by: java.io.NotSerializableException: C\nSerialization stack:\n    - object not serializable (class: C, value: C@440da0cb)\n    - field (class: $iw, name: c, type: class C)\n```\n\n## \u89e3\u6c7a\u7b56\n\n* \u6b21\u306e\u3044\u305a\u308c\u304b\u3067\u89e3\u6c7a\u3067\u304d\u308b\n\n### A. \u30af\u30e9\u30b9\u306b `java.io.Serializable` \u3092\u7d99\u627f\u3055\u305b\u308b\n\n```scala\nscala> :paste\n\nclass C extends java.io.Serializable {\n  def square(i: Int): Int = i * i\n}\n\nscala> val c = new C()\n\nscala> ds.map(c.square).show\n+-----+\n|value|\n+-----+\n|    1|\n|    4|\n|    9|\n+-----+\n```\n\n* `object` \u3092\u4f7f\u3046\u3068\u30a8\u30e9\u30fc\u306b\u306a\u3089\u306a\u304b\u3063\u305f\u306e\u3067 `object` \u306f\u3082\u3068\u3082\u3068Serializable\u306a\u306e\u304b\u3082\u3057\u308c\u306a\u3044\n\n### B. \u51e6\u7406\u3092\u30e1\u30bd\u30c3\u30c9\u3067\u306f\u306a\u304f\u95a2\u6570\u3068\u3057\u3066\u5b9a\u7fa9\u3059\u308b\n\n```scala\nscala> :paste\n\nclass C extends java.io.Serializable {\n  val square: Int => Int = i => i * i\n}\n\nscala> val c = new C()\n\nscala> ds.map(c.square).show\n+-----+\n|value|\n+-----+\n|    1|\n|    4|\n|    9|\n+-----+\n```\n\n* \u95a2\u6570\u5185\u90e8\u3067C\u306e\u5225\u306e\u30e1\u30f3\u30d0\u3092\u53c2\u7167\u3057\u3066\u305f\u308a\u3059\u308b\u3068\u7121\u7406\u306a\u6c17\u3082\u3059\u308b\n\n### \u53c2\u8003\n\n* [scala - Task not serializable: java.io.NotSerializableException when calling function outside closure only on classes not objects - Stack Overflow](http://stackoverflow.com/questions/22592811/task-not-serializable-java-io-notserializableexception-when-calling-function-ou)\n", "tags": ["Spark"]}