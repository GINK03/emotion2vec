{"context": "\n\nPipeline \u3068 GridSeasrchCV \u306b\u3064\u3044\u3066\u306f\u3001\u4ee5\u4e0b \u3092 \u53c2\u8003\n\n\n\u30aa\u30e9\u30a4\u30ea\u30fc\u672c\u300e\u5b9f\u8df5 \u6a5f\u68b0\u5b66\u7fd2\u30b7\u30b9\u30c6\u30e0\u300f pp.123-124, pp.129-130\n\n\n\n\n\u4f8b\u984c\u30b3\u30fc\u30c9 \u3092 Python3 \u3067\u5b9f\u884c\u3059\u308b\u969b\u306f\u3001\u30d1\u30e9\u30e1\u30fc\u30bf\u30fb\u30ea\u30b9\u30c8 \u306e range() \u3092 list\u306b\u578b\u5909\u63db\u3057\u306a\u3044\u3068\u30a8\u30e9\u30fc\u306b\u306a\u308b\u306e \u3067 \u6ce8\u610f\n\n\n\u4f8b\u3068\u3057\u3066\u3001\u4ee5\u4e0b\u306e\u30a6\u30a7\u30d6\u30b5\u30a4\u30c8 \u6240\u53ce\u306e\u30b5\u30f3\u30d7\u30eb\u30fb\u30b3\u30fc\u30c9 \u3092 \u5b9f\u884c\u3057\u3066\u307f\u308b\n\n\n\u8d74\u304f\u307e\u307e\u306b \uff082014/02/10\uff09\u300cscikit-learn\u3067Pipeline\u300d\n\nsklearn.pipeline.Pipeline\n\nscikit-learn\u3067\u3053\u306e\u4e00\u6c17\u901a\u8cab\u3092\u5b9f\u73fe\u3059\u308b\u30af\u30e9\u30b9\u304cPipeline\u3067\u3059\u3002 \u4f7f\u3063\u3066\u307f\u307e\u3057\u3087\u3046\u3002\n\nPython3\n\nfrom sklearn import svm\nfrom sklearn.grid_search import GridSearchCV\nfrom sklearn.pipeline import Pipeline\nimport sklearn.feature_selection as fs\nimport numpy\n\ntrain_X, train_Y, test_X = load() #\u30c7\u30fc\u30bf\u3092\u8aad\u307f\u8fbc\u3080\n\n#\n# \u4e00\u9023\u306e\u30b9\u30c6\u30c3\u30d7\u3092\u8a18\u8ff0\n#\npl = Pipeline([\n   ('feature_selection', fs.SelectKBest()),#\u6700\u9069\u306a\u6570\u6b21\u5143\u9078\u629e\n   ('classification', svm.SVC()) #\u5206\u985e\u5668\n])\n\n#\n# __\u3092\u3064\u3051\u308b\u3053\u3068\u3067\u5404\u30b9\u30c6\u30c3\u30d7\u306e\u30b3\u30f3\u30b9\u30c8\u30e9\u30af\u30bf\u306b\u6e21\u3059\u30d1\u30e9\u30e1\u30fc\u30bf\u3092\u8a2d\u5b9a\u51fa\u6765\u308b\n#\nparameters = { \n   'feature_selection__k' : range(20, 39), #\u6700\u9069\u306a20~39\u6b21\u5143\u9078\u629e\n   'classification__C': numpy.logspace(0, 4, 100).tolist(),  #C\u309210^0~10^4\u3067100\u5206\u5272\n   'classification__gamma': numpy.logspace(-3, 1, 100).tolist() #gamma\u309210^0~10^4\u3067100\u5206\u5272\n}\n\n#\u30b0\u30ea\u30c3\u30c9\u30b5\u30fc\u30c1\nclf = GridSearchCV(pl, parameters, n_jobs=-1)\n#\u5b66\u7fd2\nclf.fit(train_X, train_Y)\nprint clf.best_estimator_.get_params()\n#\u4e88\u6e2c\nclf.predict(text_X)\n\n\n\n\n\n\uff08 Python3 \u3067\u306e \u5b9f\u884c\u7d50\u679c \uff09\n\n\n\nPython3 (Anaconda jupyter)\n---------------------------------------------------------------------------\nValueError                                Traceback (most recent call last)\n<ipython-input-12-c73775cc4951> in <module>()\n----> 1 clf = GridSearchCV(pl, parameters, n_jobs=-1)\n\n/Users/hirofumi.yashima/anaconda/lib/python3.5/site->packages/sklearn/grid_search.py in __init__(self, estimator, param_grid, scoring, >fit_params, n_jobs, iid, refit, cv, verbose, pre_dispatch, error_score)\n   785             refit, cv, verbose, pre_dispatch, error_score)\n   786         self.param_grid = param_grid\n--> 787         _check_param_grid(param_grid)\n   788 \n   789     def fit(self, X, y=None):\n\n/Users/hirofumi.yashima/anaconda/lib/python3.5/site->packages/sklearn/grid_search.py in _check_param_grid(param_grid)\n   326             check = [isinstance(v, k) for k in (list, tuple, np.ndarray)]\n   327             if True not in check:\n--> 328                 raise ValueError(\"Parameter values should be a list.\")\n   329 \n   330             if len(v) == 0:\n\nValueError: Parameter values should be a list.\n\nIn [ ]:\n\n\n\n\n\n\uff08 \u4ee5\u4e0b \u3067 OK )\n\n\nPython3 \u3067\u884c\u3046\u5834\u5408\u306f\u3001range() \u3092 list \u3067\u30ea\u30b9\u30c8\u578b\u306b\u578b\u5909\u63db\u3059\u308c\u3070 OK\n\n\nPython3 (Anaconda jupyter)\n'feature_selection__k' : list(range(20, 39)),\n\n\n\n\n\u3010 \u5b9f\u884c\u7d50\u679c \u3011\n\n\nPython3 (Anaconda jupyter)\nparameters = [{\n    'feature_selection__k' : list(range(20, 39)), #\u6700\u9069\u306a20~39\u6b21\u5143\u9078\u629e\n    'classification__C': numpy.logspace(0, 4, 100).tolist(),  #C\u309210^0~10^4\u3067100\u5206\u5272\n    'classification__gamma': numpy.logspace(-3, 1, 100).tolist() #gamma\u309210^0~10^4\u3067100\u5206\u5272\n}]\n\nclf = GridSearchCV(pl, parameters, n_jobs=-1)\n\nprint(clf)\n\n\n\n\uff08 \u5b9f\u884c\u7d50\u679c \uff09\n\n\n\nscoring=None \n\nGridSearchCV(cv=None, error_score='raise',\n       estimator=Pipeline(steps=[('feature_selection', SelectKBest(k=10, score_func=<function f_classif at 0x1067fe950>)), ('classification', SVC(C=1.0, cache_size=200, class_weight=None, coef0=0.0,\n  decision_function_shape=None, degree=3, gamma='auto', kernel='rbf',\n  max_iter=-1, probability=False, random_state=None, shrinking=True,\n  tol=0.001, verbose=False))]),\n       fit_params={}, iid=True, n_jobs=-1,\n       param_grid=[{'feature_selection__k': [20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38], 'classification__gamma': [0.001, 0.0010974987654930556, 0.0012045035402587824, 0.0013219411484660286, 0.0014508287784959402, 0.0015922827933410922, 0.001747528400007683, 0.0019179102616....29144183426, 6892.612104349702, 7564.633275546291, 8302.175681319752, 9111.627561154895, 10000.0]}],\n       pre_dispatch='2*n_jobs', refit=True, scoring=None, verbose=0)\n\n\n\n\u30d1\u30e9\u30e1\u30fc\u30bf\u30fb\u30ea\u30b9\u30c8\uff08pl \u53ca\u3073 parameters\uff09 \u306e\u4e2d\u3067 \u5b9a\u7fa9\u3057\u3066\u3044\u308b SVM \u306e \u5404\u30d1\u30e9\u30e1\u30fc\u30bf \u306b\u3064\u3044\u3066\u306f\u3001\u4ee5\u4e0b \u3092 \u53c2\u8003\n\n\n\uff08\uff11\uff09SelectKBest\n\npl = Pipeline([\n   ('feature_selection', fs.SelectKBest()),#\u6700\u9069\u306a\u6570\u6b21\u5143\u9078\u629e\n   ('classification', svm.SVC()) #\u5206\u985e\u5668\n])\n\n\u30d7\u30ed\u30b0\u30e9\u30de\u30fc\u793e\u9577\u306e\u300c\u65e5\u3005\u767a\u898b\u300d \uff082015/05/20\uff09\u300c\u6a5f\u68b0\u5b66\u7fd2\u3000feature selection\u3000\u7279\u5fb4\u9078\u629e\u300d\n\n\u30fb\u30c7\u30fc\u30bf\u9078\u629e\u65b9\u6cd5\n\u30c6\u30ad\u30b9\u30c8\u5206\u985e\u3068\u3001\u7279\u5fb4\u304c\u81a8\u5927\u306a\u3082\u306e\u306f\u81ea\u52d5\u7684\u306b\u30c7\u30fc\u30bf\u3092\u9078\u629e\u3055\u305b\u308b\u5fc5\u8981\u304c\u3042\u308b\u3002\nsckit\u3067\u9078\u629e\u3059\u308b\u65b9\u6cd5\u3068\u3057\u3066\u3001SelectPercentile\u3000\u3068\u3000SelectKBest\u3000\u306e\u4e8c\u3064\u304c\u3042\u308b\u3002\nSelectPercentile\u30fb\u30fb\u30fb\u3000\u91cd\u8981\u306a\u7279\u5fb4\u306e\u4e0a\u4f4dX%\u3092\u9078\u629e\u3059\u308b\u3002\nSelectKBest\u3000\u30fb\u30fb\u30fb\u3000\u3000\u91cd\u8981\u306a\u7279\u5fb4\u3092K\u500b\u9078\u629e\u3059\u308b\n\n\nRisky Dune \uff082013/02/25\uff09\u300cscikit.learn\u624b\u6cd5\u5fb9\u5e95\u6bd4\u8f03\uff01 \u6c7a\u5b9a\u6728\u7de8\u300d\n\n\n\u304a\u307e\u3051\u5b9f\u9a13\n\u516c\u5f0f\u30d8\u30eb\u30d7\u306b\u306f\u300c\u6b21\u5143\u524a\u6e1b\u624b\u6cd5\u3092\u8a66\u3057\u3066\u307f\u308d\u300d\u3068\u3042\u308b\u306e\u3067, \u6b21\u5143\u524a\u6e1b\u624b\u6cd5\u3068\u3057\u3066\u78ba\u7387\u7684PCA(\u4e3b\u6210\u5206\u5206\u6790)\u3068, \u5165\u529b\u30d9\u30af\u30c8\u30eb\u306e\u5404\u6b21\u5143\u3054\u3068\u306b\u30e9\u30d9\u30eb\u3068\u306e\u95a2\u9023\u5ea6(\u672c\u5f53\u306f\u3061\u3087\u3063\u3068\u9055\u3046\u304c)\u3092\u8abf\u3079\u4e0a\u4f4d\u306e\u3082\u306e\u306e\u307f\u3092\u6b8b\u3059SelectKBest\u3092\u7528\u3044\u3066\u5b9f\u9a13\u3092\u884c\u306a\u3063\u3066\u307f\u305f. \u306a\u304a, criteria=entropy, \u30c7\u30fc\u30bf\u65701\u4e07\u3068\u3059\u308b.\n\n\n\uff08\uff12\uff09RBF\u30ab\u30fc\u30cd\u30eb(Gaussian \u30ab\u30fc\u30cd\u30eb / \u30e9\u30b8\u30a2\u30eb\u57fa\u5e95\u95a2\u6570\u30ab\u30fc\u30cd\u30eb)\n\nparameters = { \n   'feature_selection__k' : range(20, 39), #\u6700\u9069\u306a20~39\u6b21\u5143\u9078\u629e\n   'classification__C': numpy.logspace(0, 4, 100).tolist(),  #C\u309210^0~10^4\u3067100\u5206\u5272\n   'classification__gamma': numpy.logspace(-3, 1, 100).tolist() #gamma\u309210^0~10^4\u3067100\u5206\u5272\n}\n\nMy Life as a Mock Quant \uff082013-08-25\uff09 \u300cscikit-learn\u3067\u30b5\u30dd\u30fc\u30c8\u30d9\u30af\u30c8\u30eb\u56de\u5e30\u3001\u53ca\u3073\u305d\u306e\u30d1\u30e9\u30e1\u30fc\u30bf\u30fc\u63a8\u8a08 with \u30af\u30ed\u30b9\u30d0\u30ea\u30c7\u30fc\u30b7\u30e7\u30f3\u3084\u3063\u3066\u307f\u308b\u300d\n\n\u30af\u30ed\u30b9\u30d0\u30ea\u30c7\u30fc\u30b7\u30e7\u30f3\u3068\u30b0\u30ea\u30c3\u30c9\u30b5\u30fc\u30c1\u3092\u4f7f\u3063\u3066SVR\u306e\u30d1\u30e9\u30e1\u30fc\u30bf\u3092\u6c7a\u3081\u308b\n\u5358\u7d14\u306bCV\u3084\u308b\u3060\u3051\u306a\u3089\u4e0a\u3067\u3044\u3044\u304c\u3001\u4eca\u307e\u3067\u6240\u4e0e\u3060\u3068\u601d\u3063\u3066\u653e\u7f6e\u3057\u3066\u3044\u305f\u30e2\u30c7\u30eb\u30d1\u30e9\u30e1\u30fc\u30bf\u3001\u3053\u306e\u4f8b\u3060\u3068\n\u7f70\u5247\u306e\u5f37\u3055\u3092\u8868\u3059:C\n\u30ac\u30a6\u30b7\u30a2\u30f3\u30ab\u30fc\u30cd\u30eb\u306e\u5e83\u304c\u308a\u3092\u8868\u3059:\u03b3\n\u3092\u6c7a\u3081\u3066\u3084\u308a\u305f\u3044\u3002\u305d\u306e\u305f\u3081\u306b\u306fGridSearchCV\u95a2\u6570\u3092\u7528\u3044\u308b\u3002\n\u9069\u5f53\u306a\u30d1\u30e9\u30e1\u30fc\u30bf\u30fc\u30b0\u30ea\u30c3\u30c9\uff08\u7d44\uff09\u306b\u5bfe\u3057\u3066K-fold CV(\u3053\u3053\u3067\u306f5-fold\uff09\u3092\u7e70\u308a\u8fd4\u3057\u3001\u30b9\u30b3\u30a2(\u3053\u3053\u3067\u306fMSE)\u304c\u6700\u3082\u826f\u304f\u306a\u308b\u30d1\u30e9\u30e1\u30fc\u30bf\u30fc\u306eSVR\u3092\u51fa\u529b\u3059\u308b\u4e8b\u304c\u3067\u304d\u308b\u3002\n\u3061\u306a\u307f\u306b\u4ee5\u4e0b\u306e\u30b3\u30fc\u30c9\u3067\ntuned_parameters = [{'kernel': ['rbf'], 'gamma': [10**i for i in range(-4,0)], 'C': [10**i for i in range(1,4)]}]\n\n\u3068\u66f8\u3044\u3066\u3044\u308b\u7b87\u6240\u3092\ntuned_parameters = [\n   {'kernel': ['rbf'], 'gamma': [10**i for i in range(-4,3)], 'C': [10**i for i in range(-3, 4)]},\n   {'kernel': ['linear'], 'C': [1, 10, 100, 1000]}\n]\n\n\u3068\u3059\u308b\u3068\u3001\u30ab\u30fc\u30cd\u30eb\u3082\u540c\u6642\u306b\u201d\u30d1\u30e9\u30e1\u30fc\u30bf\u30fc\u201d\u3068\u3057\u3066\u8a55\u4fa1\u3055\u308c\u3001\u4e0a\u8a18\u306e\u901a\u5e38\u8a00\u3046\u3088\u3046\u306a\u30d1\u30e9\u30e1\u30fc\u30bf\u30fc\u3060\u3051\u3067\u306f\u306a\u304f\u3001\u7570\u306a\u308b\u30ab\u30fc\u30cd\u30eb\u9593\u3067\u306e\u7d50\u679c\u6bd4\u8f03\u3082\u51fa\u6765\u308b\u306e\u304c\u7d20\u6674\u3089\u3057\u3044*4\u3002\n\nsleepy_yoshi\u3055\u3093 SlideShare \u300cSVM\u5b9f\u8df5\u30ac\u30a4\u30c9 (A Practical Guide to Support Vector Classification)\u300d\nsz_dr\u3055\u3093 \uff082014/12/18\uff09 \u300cSVM(RBF\u30ab\u30fc\u30cd\u30eb)\u306e\u30cf\u30a4\u30d1\u30fc\u30d1\u30e9\u30e1\u30fc\u30bf\u3092\u5909\u3048\u308b\u3068\u4f55\u304c\u8d77\u3053\u308b\u306e?\u300d\npika_shi\u3055\u3093 \uff082014/12/16\uff09 \u300cSVM\u3092\u4f7f\u3044\u3053\u306a\u3059\uff01\u30c1\u30a7\u30c3\u30af\u30dd\u30a4\u30f3\u30c88\u3064\u300d\n\n3. \u30ab\u30fc\u30cd\u30eb\u95a2\u6570\n\u30ab\u30fc\u30cd\u30eb\u95a2\u6570\u306f\uff0c\u7dda\u5f62\u30ab\u30fc\u30cd\u30eb\uff0c\u591a\u9805\u5f0f\u30ab\u30fc\u30cd\u30eb\uff0cRBF\u30ab\u30fc\u30cd\u30eb\uff0c\u30b7\u30b0\u30e2\u30a4\u30c9\u30ab\u30fc\u30cd\u30eb\u2026 \u3068\u6570\u591a\u304f\u3042\u308a\u307e\u3059\u304c\uff0c\u57fa\u672c\u7684\u306b\u306fRBF\u30ab\u30fc\u30cd\u30eb\u4e00\u629e\u3060\u3068\u601d\u3063\u3066\u5927\u4e08\u592b\u3067\u3059\uff0e\n\u305f\u3060\uff0c\u3082\u3061\u308d\u3093\u4ed6\u306e\u30ab\u30fc\u30cd\u30eb\u3092\u4f7f\u3046\u3068\u3082\u3063\u3068\u3046\u307e\u304f\u3044\u304f\u3053\u3068\u3082\u3042\u308a\u307e\u3059\uff0e\u4f8b\u3048\u3070\uff0c\u30c7\u30fc\u30bf\u6570\u3068\u6bd4\u3079\u3066\u7279\u5fb4\u91cf\u306e\u6570\u304c\u5727\u5012\u7684\u306b\u591a\u3044\u3088\u3046\u306a\u5834\u5408\u306f\uff0c\u7dda\u5f62\u30ab\u30fc\u30cd\u30eb\u304c\u3046\u307e\u304f\u3044\u304d\u3084\u3059\u3044\u3067\u3059\uff0e\n\nverum ipsum factum \uff082013-04-08\uff09\u300c\u30b5\u30dd\u30fc\u30c8\u30d9\u30af\u30bf\u30fc\u30de\u30b7\u30f3\u3068\u306f\uff3b\u30ab\u30fc\u30cd\u30eb\u6cd5\u306b\u3088\u308b\u975e\u7dda\u5f62\u30b5\u30dd\u30fc\u30c8\u30d9\u30af\u30bf\u30fc\u30de\u30b7\u30f3\uff3d \n\n\u30ab\u30fc\u30cd\u30eb\u306e\u4f8b\n\u30b5\u30dd\u30fc\u30c8\u30d9\u30af\u30bf\u30fc\u30de\u30b7\u30f3\u306e\u7279\u5fb4\u306e\u4e00\u3064\u306f\u3001\u89e3\u304d\u305f\u3044\u554f\u984c\u306b\u5fdc\u3058\u3066\u30ab\u30fc\u30cd\u30eb\u3092\u9069\u5207\u306b\u9078\u3073\u6c4e\u5316\u80fd\u529b\u3092\u5411\u4e0a\u3067\u304d\u308b\u3053\u3068\u3067\u3059\u3002\u5b9f\u969b\u3001\u554f\u984c\u306e\u7a2e\u985e\u306b\u5fdc\u3058\u3066\u69d8\u3005\u306a\u30ab\u30fc\u30cd\u30eb\u304c\u958b\u767a\u3055\u308c\u3066\u3044\u307e\u3059\u3002\n\u3053\u3053\u3067\u3088\u304f\u7528\u3044\u3089\u308c\u308b\u30ab\u30fc\u30cd\u30ebK(x,x\u2032)K(x,x\u2032)\u3092\u3044\u304f\u3064\u304b\u7d39\u4ecb\u3057\u307e\u3059\u3002\n\u7dda\u5f62\u30ab\u30fc\u30cd\u30eb\n\n\uff08 \u4e2d\u7565 \uff09\n\n\u591a\u9805\u5f0f\u30ab\u30fc\u30cd\u30eb\n\n\uff08 \u4e2d\u7565 \uff09\n\n\u53cc\u66f2\u7dda\u6b63\u63a5\u30ab\u30fc\u30cd\u30eb\n\nYukara Ikemiya\u3055\u3093 Qiita\u8a18\u4e8b\u300c\u30d1\u30bf\u30fc\u30f3\u8a8d\u8b58\u3068\u6a5f\u68b0\u5b66\u7fd26\u7ae0\uff08\u30ab\u30fc\u30cd\u30eb\u6cd5\uff09\u300d\nGitHub levelfour/machine-learning-2014 \u7b2c4\u56de \u975e\u7dda\u5f62\u5199\u50cf\u3068\u30ab\u30fc\u30cd\u30eb\u95a2\u6570\n\n\u52d5\u5f84\u57fa\u5e95\u95a2\u6570\u30ab\u30fc\u30cd\u30eb(RBF\u30ab\u30fc\u30cd\u30eb)\nRBF\u30ab\u30fc\u30cd\u30eb(radial bases function kernel)\u306f\u3001\u304a\u305d\u3089\u304f\u6700\u3082\u5e83\u304f\u5229\u7528\u3055\u308c\u3066\u3044\u308b\u30ab\u30fc\u30cd\u30eb\u95a2\u6570\u3067\u3042\u308b\u3002 \n\u30ac\u30a6\u30b9\u5206\u5e03\u95a2\u6570\u306e\u95a2\u6570\u7cfb\u3092\u3057\u3066\u3044\u308b\u305f\u3081\u3001\u30ac\u30a6\u30b7\u30a2\u30f3\u30ab\u30fc\u30cd\u30eb(Gaussian kernel)\u3068\u547c\u3070\u308c\u308b\u3053\u3068\u3082\u3042\u308b\u3002\nscikit-learn\u306esvm.SVC\u3082\u3001\u30c7\u30d5\u30a9\u30eb\u30c8\u3067\u306fRBF\u30ab\u30fc\u30cd\u30eb\u3092\u63a1\u7528\u3057\u3066\u3044\u308b\u3002\n\nteratail\u3078\u3088\u3046\u3053\u305d \u300c\u53d7\u4ed8\u4e2d RBF\u30ab\u30fc\u30cd\u30eb\u3092\u7528\u3044\u305fSVM\u306e\u30cf\u30a4\u30d1\u30fc\u30d1\u30e9\u30e1\u30fc\u30bf\u300d\n\n\n\u3010 \u305d\u306e\u4ed6 \u53c2\u8003 \u3011\n\n\n\u8d74\u304f\u307e\u307e\u306b \uff082014/02/08\uff09 \u300cscikit-learn\u3067SVM\u30c1\u30e5\u30fc\u30cb\u30f3\u30b0\u300d\nTakahiro Kubo\u3055\u3093 SlideShare \u300c\u5b9f\u6226\u6295\u5165\u3059\u308b\u6a5f\u68b0\u5b66\u7fd2\u300d\n\u30c8\u30d4\u30c3\u30af\u30e2\u30c7\u30eb\u306b\u57fa\u3065\u304f\u591a\u69d8\u6027\u306e\u5b9a\u91cf\u5316\n\n\n\n\u3010 \u88dc\u8db3 \u3011pipes\u30e2\u30b8\u30e5\u30fc\u30eb \u3068\u306f \u5225\n\n\nPython 2.7 Documentation 36.11. pipes \u2014 \u30b7\u30a7\u30eb\u30d1\u30a4\u30d7\u30e9\u30a4\u30f3\u3078\u306e\u30a4\u30f3\u30bf\u30d5\u30a7\u30fc\u30b9\n\n\n\nGridSeasrchCV \u304c \u898b\u51fa\u3057\u305f \u30d1\u30e9\u30e1\u30fc\u30bf\u306e\u6700\u9069\u306a\u7d44\u307f\u5408\u308f\u305b\u7d50\u679c \u306f\u3001\u8fd4\u308a\u5024.best_estimator_ \u306b \u683c\u7d0d\u3055\u308c\u308b\n\n\n\u3010 \u53c2\u8003 \u3011\n\nscikit learn sklearn.grid_search.GridSearchCV\n\n\n\u7701\u7565\u53ef\u80fd\u306a\u5f15\u6570 cv \u306b\u3001\u4ea4\u5dee\u691c\u5b9a\u6cd5\u3067\u3001\u30c7\u30fc\u30bf\u3092\u4f55\u5206\u5272\u3059\u308b\u304b\u3092\u6307\u5b9a\u3067\u304d\u308b\u3002\uff08\u7701\u7565\u6642\u306f\u3001K=\uff13 \u3067 \u30c7\u30d5\u30a9\u30eb\u30c8\u8a2d\u5b9a\u3055\u308c\u308b\uff09\n\n\n\n\n\n\u4ee5\u4e0b\u3001GridSearch\u3092\u5229\u7528\u3057\u305f\u30b3\u30fc\u30c9\u4e8b\u4f8b\u306e\u306a\u304b\u3067\u3001.best_estimator \u3092 \u51fa\u529b\u3057\u3066\u3044\u308b\u30b3\u30fc\u30c9\u90e8\u5206\n\n\u8d74\u304f\u307e\u307e\u306b \uff082014/02/10\uff09 \u300cscikit-learn\u3067Pipeline\u300d\n\uff08\u4ee5\u4e0b\u30b3\u30fc\u30c9\u4e2d\u3001\u30a2\u30f3\u30c0\u30fc\u30b9\u30b3\u30a2\uff12\u3064 \u3067\u56f2\u3063\u305f\u90e8\u5206\uff09 \u203b \u30a2\u30f3\u30c0\u30fc\u30b9\u30b3\u30a2\uff12\u3064 \u306f\u3001\u672c\u8a18\u4e8b\u57f7\u7b46\u8005\u306b\u3088\u308b\n\n\u2265#\u30b0\u30ea\u30c3\u30c9\u30b5\u30fc\u30c1\nclf = GridSearchCV(pl, parameters, n_jobs=-1)\n#\u5b66\u7fd2\nclf.fit(train_X, train_Y)\n__print clf.best_estimator_.get_params()__\n#\u4e88\u6e2c\nclf.predict(text_X)\n\n\nPygments Demo entry 149057, Restricted Boltzmann Machine features for digit classification\n\uff08\u4ee5\u4e0b\u30b3\u30fc\u30c9\u4e2d\u3001\u30a2\u30f3\u30c0\u30fc\u30b9\u30b3\u30a2\uff12\u3064 \u3067\u56f2\u3063\u305f\u90e8\u5206\uff09 \u203b \u30a2\u30f3\u30c0\u30fc\u30b9\u30b3\u30a2\uff12\u3064 \u306f\u3001\u672c\u8a18\u4e8b\u57f7\u7b46\u8005\u306b\u3088\u308b\n\ndef gridsearch(classifier, param_grid):\n   scores = ['precision', 'recall'] # training evaluation metrics\n\n   for score in scores:\n       print(\"# Tuning hyper-parameters for %s\\n\" % score)\n       clf = GridSearchCV(classifier, param_grid=param_grid, cv=5, scoring=score, verbose=1)\n       clf.fit(X_train, y_train)\n       __print(\"Best parameters set found on development set:\\n\")__\n       __print(clf.best_estimator_)__\n       print(\"\\nGrid scores on development set:\\n\")\n       for params, mean_score, scores in clf.grid_scores_:\n           print(\"%0.3f (+/-%0.03f) for %r\\n\"\n               % (mean_score, scores.std() / 2, params))\n\n       print(\"Detailed classification report:\\n\")\n       print(\"The model is trained on the full development set.\")\n       print(\"The scores are computed on the full evaluation set.\\n\")\n       y_true, y_pred = y_test, clf.predict(X_test)\n       print(classification_report(y_true, y_pred))\n       print()\n       clist.append(clf)\n\n\n\n\n\u516c\u5f0f\u30ea\u30d5\u30a1\u30ec\u30f3\u30b9\u30fb\u30da\u30fc\u30b8\uff08\u4ee5\u4e0b\uff09 \u306e Examples\u30b3\u30fc\u30c9 \u3092 \u5b9f\u884c\u3057\u3066\u3001GridSearch \u304c \u898b\u51fa\u3057\u305f \u6700\u9069\u306a\u30d1\u30e9\u30e1\u30fc\u30bf \u306e \u7d44\u307f\u5408\u308f\u305b \u306e \u7d50\u679c \u3092 \u51fa\u529b\u3057\u3066\u307f\u308b\n\nscikit learn sklearn.grid_search.GridSearchCV\n\nPython3 Anaconda jupyter\nfrom sklearn import svm, grid_search, datasets\n\niris = datasets.load_iris()\n\nparameters = {'kernel':('linear', 'rbf'), 'C':[1, 10]}\nsvr = svm.SVC()\n\nclf = grid_search.GridSearchCV(svr, parameters)\nprint(clf)\n\n\n\uff08 \u5b9f\u884c\u7d50\u679c \uff09\n\nscoring=None\n\nGridSearchCV(cv=None, error_score='raise',\n       estimator=SVC(C=1.0, cache_size=200, class_weight=None, coef0=0.0,\n  decision_function_shape=None, degree=3, gamma='auto', kernel='rbf',\n  max_iter=-1, probability=False, random_state=None, shrinking=True,\n  tol=0.001, verbose=False),\n       fit_params={}, iid=True, n_jobs=1,\n       param_grid={'C': [1, 10], 'kernel': ('linear', 'rbf')},\n       pre_dispatch='2*n_jobs', refit=True, scoring=None, verbose=0)\n\n\nPython3 Anaconda jupyter\nclf.fit(iris.data, iris.target)\n\n\n\uff08 \u5b9f\u884c\u7d50\u679c \uff09\nGridSearchCV(cv=None, error_score='raise',\n       estimator=SVC(C=1.0, cache_size=200, class_weight=None, coef0=0.0,\n  decision_function_shape=None, degree=3, gamma='auto', kernel='rbf',\n  max_iter=-1, probability=False, random_state=None, shrinking=True,\n  tol=0.001, verbose=False),\n       fit_params={}, iid=True, n_jobs=1,\n       param_grid={'C': [1, 10], 'kernel': ('linear', 'rbf')},\n       pre_dispatch='2*n_jobs', refit=True, scoring=None, verbose=0)\n\n\nPython3 Anaconda jupyter\nprint(\"clf.best_estimator_\\n\", clf.best_estimator_)\nprint(\"===========================================\")\nprint(\"clf.best_estimator_.get_params()\\n\", clf.best_estimator_.get_params())\n\n\n\uff08 \u5b9f\u884c\u7d50\u679c \uff09\nclf.best_estimator_\n SVC(C=1, cache_size=200, class_weight=None, coef0=0.0,\n  decision_function_shape=None, degree=3, gamma='auto', kernel='linear',\n  max_iter=-1, probability=False, random_state=None, shrinking=True,\n  tol=0.001, verbose=False)\n===========================================\nclf.best_estimator_.get_params()\n {'coef0': 0.0, 'tol': 0.001, 'degree': 3, 'gamma': 'auto', 'random_state': None, 'probability': False, 'class_weight': None, 'max_iter': -1, 'verbose': False, 'decision_function_shape': None, 'cache_size': 200, 'shrinking': True, 'kernel': 'linear', 'C': 1}\n\n\nPython3 Anaconda jupyter\nchosen_parameters_dict = clf.best_estimator_.get_params()\nprint(\"C : \", chosen_parameters_dict[\"C\"])\nprint(\"kernel : \", chosen_parameters_dict[\"kernel\"])\n\n\n\uff08 \u5b9f\u884c\u7d50\u679c \uff09\nC :  1\nkernel :  linear\n\n\n\n\ngrid_scores_\u306b\u306f\u3001\u4e0e\u3048\u305f\u30d1\u30e9\u30e1\u30fc\u30bf\u9078\u629e\u30ea\u30b9\u30c8 \u304b\u3089\u751f\u6210\u53ef\u80fd\u306a \u30d1\u30e9\u30e1\u30fc\u30bf\u7d44\u307f\u5408\u308f\u305b\u5168 \u30d1\u30bf\u30fc\u30f3 \u306b\u3064\u3044\u3066\u3001\u305d\u308c\u305e\u308c\u500b\u3005\u306e\u30d1\u30e9\u30e1\u30fc\u30bf\u7d44\u307f\u5408\u308f\u305b\u3067\u5206\u985e\u5668\u3092\u751f\u6210\u3057\u305f\u969b \u306e Cross-Validation\u30c6\u30b9\u30c8\u306e\u7d50\u679c\uff08\u4ea4\u5dee\u691c\u5b9a\u6cd5\u3067\u8a66\u3057\u305f\u5168\u8a66\u884c \u306e \u7d50\u679c\u5024 \u306e \u5e73\u5747\u5024 \u3068 \u6a19\u6e96\u504f\u5dee\uff09\u304c\u683c\u7d0d\u3055\u308c\u3066\u3044\u308b\n\n\nPython3 Anaconda jupyter\nprint(clf.grid_scores_)\n\n\n\nPython3 Anaconda jupyter\n[mean: 0.98000, std: 0.01602, params: {'kernel': 'linear', 'C': 1}, mean: 0.97333, std: 0.00897, params: {'kernel': 'rbf', 'C': 1}, mean: 0.97333, std: 0.03697, params: {'kernel': 'linear', 'C': 10}, mean: 0.98000, std: 0.01601, params: {'kernel': 'rbf', 'C': 10}]\n\n\n\n\uff08 \u898b\u3084\u3059\u304f\u6539\u884c\u3057\u3066\u51fa\u529b \uff09\n\n\nPython3 Anaconda jupyter\nfrom pprint import pprint\npprint(clf.grid_scores_)\n\n\n\nkernel\u95a2\u6570\u306e\u7a2e\u985e \u3068 \u30d1\u30e9\u30e1\u30fc\u30bfC\u306e\u5024 \u306e \u5168\u7d44\u307f\u5408\u308f\u305b\u30d1\u30bf\u30fc\u30f3\uff08\u5408\u8a08\uff14\u30d1\u30bf\u30fc\u30f3\uff09\u306b\u3064\u3044\u3066\n\u5404\u7d44\u307f\u5408\u308f\u305b\u3054\u3068 \u306b \u5b9f\u884c\u3057\u305f \u4ea4\u5dee\u691c\u5b9a\u6cd5 \u306e \u7d50\u679c\uff08\u306e\u5e73\u5747\u5024\u3068\u6a19\u6e96\u504f\u5dee\uff09 \u3092 \u78ba\u8a8d\u3067\u304d\u308b\n\n\nPython3 Anaconda jupyter\n[mean: 0.98000, std: 0.01602, params: {'kernel': 'linear', 'C': 1},\n mean: 0.97333, std: 0.00897, params: {'kernel': 'rbf', 'C': 1},\n mean: 0.97333, std: 0.03697, params: {'kernel': 'linear', 'C': 10},\n mean: 0.98000, std: 0.01601, params: {'kernel': 'rbf', 'C': 10}]\n\n\n\n\n\nsklearn.pipeline.Pipeline \u3068  GridSeasrchCV \u3092 \u7d44\u307f\u5408\u308f\u305b\u3066\u5b9f\u884c\u3057\u3066\u307f\u305f\u4f8b\n\n\niris\u30c7\u30fc\u30bf \u306e 8\u5272 \u3092\u5b66\u7fd2\u7528\u306b\u3001\u6b8b\u308a\uff12\u5272 \u3092 \u30c6\u30b9\u30c8\u7528 \u30c7\u30fc\u30bf\u306b\u4f7f\u7528\uff08\u4f46\u3057\u3001\u30e9\u30f3\u30c0\u30e0\u30b5\u30f3\u30d7\u30ea\u30f3\u30b0\u305b\u305a\u306b\u3001\u884c\u306e\u982d \u304b\u3089 \uff18\u5272\u5206 \u3092 \u5b66\u7fd2\u7528 \u306b\u3057\u305f\u305f\u3081\u3001\u30c7\u30fc\u30bf\u5206\u5e03\u306b\u504f\u308a\u304c\u3042\u308b \uff09\n\u30d1\u30e9\u30e1\u30fc\u30bf\u5024 K \u306e\u5024 \u306f\u3001\u5b66\u7fd2\u7528\u30c7\u30fc\u30bf\u306b\u5b9a\u7fa9\u3055\u308c\u305f\u7279\u5fb4\u91cf\u306e\u6570\u4ee5\u4e0b \u3067\u306a\u3044\u3068\u3044\u3051\u306a\u3044\u3001\u3068\u30a8\u30e9\u30fc\u8868\u793a\u3055\u308c\u308b\u3002\niris\u30c7\u30fc\u30bf\u306e\u7279\u5fb4\u91cf\u306e\u6570\u306f\uff14\uff08Sepal.length\u7b49\uff09\u306a\u306e\u3067\u3001k \u306e \u30d1\u30e9\u30e1\u30fc\u30bf\u306e\u5024\u5019\u88dc\u7bc4\u56f2 \u3092 1\u301c4 \u306b\u3059\u308b\u3068\u3001\u30a8\u30e9\u30fc\u6d88\u3048\u305f\u3002\n\n\nPython3\nfrom sklearn import svm\nfrom sklearn.grid_search import GridSearchCV\nfrom sklearn.pipeline import Pipeline\nimport sklearn.feature_selection as fs\nimport numpy\n\n\n#\n# \u4e00\u9023\u306e\u30b9\u30c6\u30c3\u30d7\u3092\u8a18\u8ff0\n#\npl = Pipeline([\n   ('feature_selection', fs.SelectKBest()),#\u6700\u9069\u306a\u6570\u6b21\u5143\u9078\u629e\n   ('classification', svm.SVC()) #\u5206\u985e\u5668\n])\n\nprint(pl)\n\n\n\uff08 \u5b9f\u884c\u7d50\u679c \uff09\nPipeline(steps=[('feature_selection', SelectKBest(k=10, score_func=<function f_classif at 0x1068fa950>)), ('classification', SVC(C=1.0, cache_size=200, class_weight=None, coef0=0.0,\n  decision_function_shape=None, degree=3, gamma='auto', kernel='rbf',\n  max_iter=-1, probability=False, random_state=None, shrinking=True,\n  tol=0.001, verbose=False))])\n\n\nPython3\nfrom sklearn import svm\nfrom sklearn.grid_search import GridSearchCV\nfrom sklearn.pipeline import Pipeline\nimport sklearn.feature_selection as fs\nimport numpy\n\n\n#\n# \u4e00\u9023\u306e\u30b9\u30c6\u30c3\u30d7\u3092\u8a18\u8ff0\n#\npl = Pipeline([\n   ('feature_selection', fs.SelectKBest()),#\u6700\u9069\u306a\u6570\u6b21\u5143\u9078\u629e\n   ('classification', svm.SVC()) #\u5206\u985e\u5668\n])\n\n#\n# __\u3092\u3064\u3051\u308b\u3053\u3068\u3067\u5404\u30b9\u30c6\u30c3\u30d7\u306e\u30b3\u30f3\u30b9\u30c8\u30e9\u30af\u30bf\u306b\u6e21\u3059\u30d1\u30e9\u30e1\u30fc\u30bf\u3092\u8a2d\u5b9a\u51fa\u6765\u308b\n#\nparameters = { \n   'feature_selection__k' : list(range(20, 39)), #\u6700\u9069\u306a20~39\u6b21\u5143\u9078\u629e\n   'classification__C': numpy.logspace(0, 4, 100).tolist(),  #C\u309210^0~10^4\u3067100\u5206\u5272\n   'classification__gamma': numpy.logspace(-3, 1, 100).tolist() #gamma\u309210^0~10^4\u3067100\u5206\u5272\n}\n\n#\u30b0\u30ea\u30c3\u30c9\u30b5\u30fc\u30c1\nclf = GridSearchCV(pl, parameters, n_jobs=-1)\nprint(clf)\n\n\n\uff08 \u5b9f\u884c\u7d50\u679c \uff09\nGridSearchCV(cv=None, error_score='raise',\n       estimator=Pipeline(steps=[('feature_selection', SelectKBest(k=10, score_func=<function f_classif at 0x1068fa950>)), ('classification', SVC(C=1.0, cache_size=200, class_weight=None, coef0=0.0,\n  decision_function_shape=None, degree=3, gamma='auto', kernel='rbf',\n  max_iter=-1, probability=False, random_state=None, shrinking=True,\n  tol=0.001, verbose=False))]),\n       fit_params={}, iid=True, n_jobs=-1,\n       param_grid={'feature_selection__k': [20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38], 'classification__gamma': [0.001, 0.0010974987654930556, 0.0012045035402587824, 0.0013219411484660286, 0.0014508287784959402, 0.0015922827933410922, 0.001747528400007683, 0.00191791026167...0.29144183426, 6892.612104349702, 7564.633275546291, 8302.175681319752, 9111.627561154895, 10000.0]},\n       pre_dispatch='2*n_jobs', refit=True, scoring=None, verbose=0)\n\n\nPython3\nfrom sklearn import datasets\n\niris = datasets.load_iris()\n\ntrain_X, train_Y = iris.data[:0.8*len(iris.data)], iris.target[:0.8*len(iris.target)]\nprint(len(train_X), len(train_Y))\n\n\n120 120\n/Users/hirofumi.yashima/anaconda/lib/python3.5/site-packages/ipykernel/__main__.py:5: DeprecationWarning: using a non-integer number instead of an integer will result in an error in the future\n\n\nPython3\nclf.fit(train_X, train_Y)\n\n\n\n\u5b9f\u884c\u30a8\u30e9\u30fc\n\n---------------------------------------------------------------------------\nRemoteTraceback                           Traceback (most recent call last)\nRemoteTraceback: \n\"\"\"\nTraceback (most recent call last):\n  File \"/Users/hirofumi.yashima/anaconda/lib/python3.5/site-packages/sklearn/externals/joblib/parallel.py\", line 130, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/hirofumi.yashima/anaconda/lib/python3.5/site-packages/sklearn/externals/joblib/parallel.py\", line 72, in __call__\n    return [func(*args, **kwargs) for func, args, kwargs in self.items]\n  File \"/Users/hirofumi.yashima/anaconda/lib/python3.5/site-packages/sklearn/externals/joblib/parallel.py\", line 72, in <listcomp>\n    return [func(*args, **kwargs) for func, args, kwargs in self.items]\n  File \"/Users/hirofumi.yashima/anaconda/lib/python3.5/site-packages/sklearn/cross_validation.py\", line 1531, in _fit_and_score\n    estimator.fit(X_train, y_train, **fit_params)\n  File \"/Users/hirofumi.yashima/anaconda/lib/python3.5/site-packages/sklearn/pipeline.py\", line 164, in fit\n    Xt, fit_params = self._pre_transform(X, y, **fit_params)\n  File \"/Users/hirofumi.yashima/anaconda/lib/python3.5/site-packages/sklearn/pipeline.py\", line 145, in _pre_transform\n    Xt = transform.fit_transform(Xt, y, **fit_params_steps[name])\n\n\n    \uff08 \u4e2d\u7565 \uff09\n\n\n    332         self.scores_ = np.asarray(self.scores_)\n    333         self.pvalues_ = np.asarray(self.pvalues_)\n\n...........................................................................\n/Users/hirofumi.yashima/anaconda/lib/python3.5/site-packages/sklearn/feature_selection/univariate_selection.py in _check_params(self=SelectKBest(k=20, score_func=<function f_classif at 0x1068fa950>), X=array([[ 5.1,  3.5,  1.4,  0.3],\n       [ 5.7,  ...6,  6.9,  2.3],\n       [ 6. ,  2.2,  5. ,  1.5]]), y=array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,...1, 2, 2, 2,\n       2, 2, 2, 2, 2, 2, 2, 2, 2, 2]))\n    455 \n    456     def _check_params(self, X, y):\n    457         if not (self.k == \"all\" or 0 <= self.k <= X.shape[1]):\n    458             raise ValueError(\"k should be >=0, <= n_features; got %r.\"\n    459                              \"Use k='all' to return all features.\"\n--> 460                              % self.k)\n        self.k = 20\n    461 \n    462     def _get_support_mask(self):\n    463         check_is_fitted(self, 'scores_')\n    464 \n\nValueError: k should be >=0, <= n_features; got 20.Use k='all' to return all features.\n___________________________________________________________________________\n\n# ValueError: k should be >=0, <= n_features; got 20.Use k='all' to return all features. __\n__ \u3068 \u8868\u793a\u3055\u308c\u305f \u306e\u3067\u3001\nk \u306e\u5024 \u3092 iris\u30c7\u30fc\u30bf\u30bb\u30c3\u30c8\u306e\u7279\u5fb4\u91cf\uff08\uff1d\uff14\uff09\u4ee5\u4e0b\u306e\u7bc4\u56f2\u3067\u3001\uff11\u301c\uff14\u306e\u7bc4\u56f2\u3067\u5019\u88dc\u6307\u5b9a\u3059\u308b\n\nPython3\n# ValueError: k should be >=0, <= n_features; got 20.Use k='all' to return all features. \n# \u3068\u8868\u793a\u3055\u308c\u305f\u306e\u3067\u3001\n# k \u306e\u5024 \u3092 iris\u30c7\u30fc\u30bf\u30bb\u30c3\u30c8\u306e\u7279\u5fb4\u91cf\uff08\uff1d\uff14\uff09\u4ee5\u4e0b\u306e\u7bc4\u56f2\u3067\u3001\uff11\u301c\uff14\u306e\u7bc4\u56f2\u3067\u5019\u88dc\u6307\u5b9a\u3059\u308b\n\nfrom sklearn import svm\nfrom sklearn.grid_search import GridSearchCV\nfrom sklearn.pipeline import Pipeline\nimport sklearn.feature_selection as fs\nimport numpy\n\n\npl = Pipeline([\n   ('feature_selection', fs.SelectKBest()),#\u6700\u9069\u306a\u6570\u6b21\u5143\u9078\u629e\n   ('classification', svm.SVC()) #\u5206\u985e\u5668\n])\n\n\nparameters = {\n   'feature_selection__k' : list(range(1, 4)), #\u6700\u9069\u306a1~4\u6b21\u5143\u9078\u629e\n   'classification__C': numpy.logspace(0, 4, 100).tolist(),  #C\u309210^0~10^4\u3067100\u5206\u5272\n   'classification__gamma': numpy.logspace(-3, 1, 100).tolist() #gamma\u309210^0~10^4\u3067100\u5206\u5272\n}\n\nclf = GridSearchCV(pl, parameters, n_jobs=-1)\nprint(clf)\n\n\nGridSearchCV(cv=None, error_score='raise',\n       estimator=Pipeline(steps=[('feature_selection', SelectKBest(k=10, score_func=<function f_classif at 0x1068fa950>)), ('classification', SVC(C=1.0, cache_size=200, class_weight=None, coef0=0.0,\n  decision_function_shape=None, degree=3, gamma='auto', kernel='rbf',\n  max_iter=-1, probability=False, random_state=None, shrinking=True,\n  tol=0.001, verbose=False))]),\n       fit_params={}, iid=True, n_jobs=-1,\n       param_grid={'feature_selection__k': [1, 2, 3], 'classification__gamma': [0.001, 0.0010974987654930556, 0.0012045035402587824, 0.0013219411484660286, 0.0014508287784959402, 0.0015922827933410922, 0.001747528400007683, 0.0019179102616724887, 0.00210490414451202, 0.0023101297000831605, 0.00253536449397...0.29144183426, 6892.612104349702, 7564.633275546291, 8302.175681319752, 9111.627561154895, 10000.0]},\n       pre_dispatch='2*n_jobs', refit=True, scoring=None, verbose=0)\nIn [6]:\n\n\nPython3\nclf.fit(train_X, train_Y)\n\n\n\uff08 \u5b9f\u884c\u7d50\u679c \uff09\nGridSearchCV(cv=None, error_score='raise',\n       estimator=Pipeline(steps=[('feature_selection', SelectKBest(k=10, score_func=<function f_classif at 0x1068fa950>)), ('classification', SVC(C=1.0, cache_size=200, class_weight=None, coef0=0.0,\n  decision_function_shape=None, degree=3, gamma='auto', kernel='rbf',\n  max_iter=-1, probability=False, random_state=None, shrinking=True,\n  tol=0.001, verbose=False))]),\n       fit_params={}, iid=True, n_jobs=-1,\n       param_grid={'feature_selection__k': [1, 2, 3], 'classification__gamma': [0.001, 0.0010974987654930556, 0.0012045035402587824, 0.0013219411484660286, 0.0014508287784959402, 0.0015922827933410922, 0.001747528400007683, 0.0019179102616724887, 0.00210490414451202, 0.0023101297000831605, 0.00253536449397...0.29144183426, 6892.612104349702, 7564.633275546291, 8302.175681319752, 9111.627561154895, 10000.0]},\n       pre_dispatch='2*n_jobs', refit=True, scoring=None, verbose=0)\n\n\nPython3\nprint(\"clf.best_estimator_\\n\", \"------------------------\\n\", clf.best_estimator_)\nprint(\"===========================================\")\nprint(\"clf.best_estimator_.get_params()\\n\", \"------------------------\\n\", clf.best_estimator_.get_params())\n\n\nclf.best_estimator_\n ------------------------\n Pipeline(steps=[('feature_selection', SelectKBest(k=3, score_func=<function f_classif at 0x1068fa950>)), ('classification', SVC(C=1.0, cache_size=200, class_weight=None, coef0=0.0,\n  decision_function_shape=None, degree=3, gamma=0.1384886371393873,\n  kernel='rbf', max_iter=-1, probability=False, random_state=None,\n  shrinking=True, tol=0.001, verbose=False))])\n===========================================\nclf.best_estimator_.get_params()\n ------------------------\n {'feature_selection__score_func': <function f_classif at 0x1068fa950>, 'classification__cache_size': 200, 'classification__probability': False, 'classification__shrinking': True, 'classification__verbose': False, 'classification__degree': 3, 'classification__coef0': 0.0, 'classification__decision_function_shape': None, 'classification__max_iter': -1, 'classification__random_state': None, 'feature_selection': SelectKBest(k=3, score_func=<function f_classif at 0x1068fa950>), 'feature_selection__k': 3, 'classification__kernel': 'rbf', 'steps': [('feature_selection', SelectKBest(k=3, score_func=<function f_classif at 0x1068fa950>)), ('classification', SVC(C=1.0, cache_size=200, class_weight=None, coef0=0.0,\n  decision_function_shape=None, degree=3, gamma=0.1384886371393873,\n  kernel='rbf', max_iter=-1, probability=False, random_state=None,\n  shrinking=True, tol=0.001, verbose=False))], 'classification': SVC(C=1.0, cache_size=200, class_weight=None, coef0=0.0,\n  decision_function_shape=None, degree=3, gamma=0.1384886371393873,\n  kernel='rbf', max_iter=-1, probability=False, random_state=None,\n  shrinking=True, tol=0.001, verbose=False), 'classification__C': 1.0, 'classification__tol': 0.001, 'classification__gamma': 0.1384886371393873, 'classification__class_weight': None}\n\n\n\n\n\n\n\n\nGridSearch \u304c \u767a\u898b\u3057\u305f\u6700\u9069\u306a\u30d1\u30e9\u30e1\u30fc\u30bf\u306e\u7d44\u307f\u5408\u308f\u305b \u306f\u3001\u4ee5\u4e0b\u306b\u306a\u3063\u305f\u3002\n\nPython3\nchosen_parameters_dict = clf.best_estimator_.get_params()\nprint(\"feature_selection__k : \", chosen_parameters_dict[\"feature_selection__k\"])\nprint(\"classification__C : \", chosen_parameters_dict[\"classification__C\"])\nprint(\"classification__gamma : \", chosen_parameters_dict[\"classification__gamma\"])\n\n\nfeature_selection__k :  3\nclassification__C :  1.0\nclassification__gamma :  0.1384886371393873\n\n\n\uff08\u8ffd\u8a18\uff09\n\nPython3\nprint(clf.best_score_)\n\n\n0.983333333333\n\n\n\n\u65b0\u898f\uff08\u691c\u8a3c\u7528\uff09\u30c7\u30fc\u30bf \u306e \u30e9\u30d9\u30eb\u4e88\u6e2c\n\n\n\u691c\u8a3c\u7528\u30c7\u30fc\u30bf \u3092 \u7528\u610f\n\n\nPython3\ntest_X  = iris.data[0.8*len(iris.data): ]\n\n\n\uff08 \u5b9f\u884c\u7d50\u679c \uff09\n/Users/hirofumi.yashima/anaconda/lib/python3.5/site-packages/ipykernel/__main__.py:1: DeprecationWarning: using a non-integer number instead of an integer will result in an error in the future\n  if __name__ == '__main__':\n\n\nPython3\nprint(len(test_X))\n# 30\n\n\n\n\u691c\u8a3c\u7528\u30c7\u30fc\u30bf \u306e \u30e9\u30d9\u30eb \u3092 \u63a8\u5b9a\n\n\nPython3\n#\u4e88\u6e2c\nclf.predict(test_X)\n\n\n\uff08 \u5b9f\u884c\u7d50\u679c \uff09\narray([2, 2, 2, 1, 2, 2, 1, 1, 2, 2, 2, 2, 2, 1, 2, 2, 2, 2, 1, 2, 2, 2, 2,\n       2, 2, 2, 2, 2, 2, 2])\n\n\n\u6b63\u89e3\u7387\uff08\u6b63\u8aa4\u8868\uff09 \u3092 \u96c6\u8a08\n\n\n\uff08 \u3053\u306e\u5148\u3001\u4ee5\u4e0b\u306e\u30a6\u30a7\u30d6\u30b5\u30a4\u30c8\u3092\u53c2\u8003\u306b\u3057\u307e\u3057\u305f \uff09\n\n\n\nJamie A Dean, Liam C Welsh\u307b\u304b, Predictive Modelling of Toxicity Resulting from Radiotherapy Treatments of Head and Neck Cancer, PROC. OF THE 7th EUR. CONF. ON PYTHON IN SCIENCE (EUROSCIPY 2014)\n\u306e\u3093\u3073\u308a\u3057\u3066\u3044\u308b\u30a8\u30f3\u30b8\u30cb\u30a2\u306e\u65e5\u8a18 \uff082014/08/07\uff09\u300cSklearn\u3092\u4f7f\u3063\u305f\u6a5f\u68b0\u5b66\u7fd2\u300d\n\u552f\u7269\u662f\u771f @Scaled_Wurm \uff082013/05/25\uff09 \u300cpython\u306e\u6a5f\u68b0\u5b66\u7fd2\u30e9\u30a4\u30d6\u30e9\u30eascikit-learn\u306e\u7d39\u4ecb\u300d\nHatena Blog \u4eba\u5de5\u77e5\u80fd\u306b\u95a2\u3059\u308b\u65ad\u5275\u9332 \uff082015/08/26\uff09 \u300cMachine Learning with Scikit Learn (Part II)\u300d\n\n\nClassification Report\n8.19.1.5. sklearn.metrics.classification_report \u2014 scikit-learn 0.13.1 documentation\n\u3053\u306e\u95a2\u6570\u306fPrecision\u3001Recall\u3068F\u5024\u3068support(\u6b63\u89e3\u30e9\u30d9\u30eb\u306e\u30c7\u30fc\u30bf\u306e\u6570)\u3092\u6559\u3048\u3066\u304f\u308c\u307e\u3059\nPrecision\u3001Recall\u3001F\u5024\u306f\u8a55\u4fa1\u306b\u975e\u5e38\u306b\u3088\u304f\u4f7f\u308f\u308c\u3066\u3044\u307e\u3059\u3002\nPrecision\u3001Recall\u3001F\u5024\u306e\u8aac\u660e\u306b\u3064\u3044\u3066\u306f\u4ee5\u4e0b\u306eURL\u3092\u53c2\u7167\n\n\n\nPython3\nfrom sklearn.metrics import classification_report\n\ny_true = iris.target[0.8*len(iris.data): ]\ny_pred = clf.predict(test_X)\n\nprint(classification_report(y_true, y_pred))\n\n\n\uff08 \u5b9f\u884c\u7d50\u679c \uff09\n             precision    recall  f1-score   support\n\n          1       0.00      0.00      0.00         0\n          2       1.00      0.83      0.91        30\n\navg / total       1.00      0.83      0.91        30\n\n/Users/hirofumi.yashima/anaconda/lib/python3.5/site-packages/ipykernel/__main__.py:3: DeprecationWarning: using a non-integer number instead of an integer will result in an error in the future\n  app.launch_new_instance()\n/Users/hirofumi.yashima/anaconda/lib/python3.5/site-packages/sklearn/metrics/classification.py:1076: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples.\n  'recall', 'true', average, warn_for)\n\n\nPython3\nprint(y_true)\n\n\n\uff08 \u5b9f\u884c\u7d50\u679c \uff09\n[2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2]\n\n\nPython3\nprint(y_pred)\n\n\n\uff08 \u5b9f\u884c\u7d50\u679c \uff09\n[2 2 2 1 2 2 1 1 2 2 2 2 2 1 2 2 2 2 1 2 2 2 2 2 2 2 2 2 2 2]\n\n\n\n\n\nPython3\nfrom sklearn.metrics import precision_recall_score_support\np, r, f, s = precision_recall_fscore_support(y_true, y_pred, beta=0.5)\n\nprint(p)\n# [ 0.  1.]\n\nprint(r)\n# [ 0.          0.83333333]\n\nprint(f)\n# [ 0.          0.96153846]\n\nprint(s)\n# [ 0 30]\n\n\n\n\n\nGridSeasrchCV \u3067 \u6700\u9069\u30d1\u30e9\u30e1\u30fc\u30bf\u7d44\u307f\u5408\u308f\u305b\u3092\u63a2\u7d22\u3059\u308b\u3068\u304d\u306b\u3001scoring='rco_auc' \u306b\u3057\u3066\u3082\u3001\u7d50\u679c\u306f\u540c\u3058\u306b\u306a\u3063\u305f\u3002\n\n\nPython3\n#\u30b0\u30ea\u30c3\u30c9\u30b5\u30fc\u30c1\nclf2 = GridSearchCV(pl, parameters, n_jobs=-1, scoring='roc_auc')\n\n\n\nPython3\nprint(clf2)\n\n\n\nscoring='roc_auc' \u306b\u306a\u3063\u3066\u3044\u308b\n\nGridSearchCV(cv=None, error_score='raise',\n       estimator=Pipeline(steps=[('feature_selection', SelectKBest(k=10, score_func=<function f_classif at 0x106938950>)), ('classification', SVC(C=1.0, cache_size=200, class_weight=None, coef0=0.0,\n  decision_function_shape=None, degree=3, gamma='auto', kernel='rbf',\n  max_iter=-1, probability=False, random_state=None, shrinking=True,\n  tol=0.001, verbose=False))]),\n       fit_params={}, iid=True, n_jobs=-1,\n       param_grid={'classification__gamma': [0.001, 0.0010974987654930556, 0.0012045035402587824, 0.0013219411484660286, 0.0014508287784959402, 0.0015922827933410922, 0.001747528400007683, 0.0019179102616724887, 0.00210490414451202, 0.0023101297000831605, 0.0025353644939701114, 0.0027825594022071257, 0.003...564.633275546291, 8302.175681319752, 9111.627561154895, 10000.0], 'feature_selection__k': [1, 2, 3]},\n       pre_dispatch='2*n_jobs', refit=True, scoring='roc_auc', verbose=0)\n\n\nPython3\nclf2.fit(train_X, train_Y)\n\nchosen_parameters_dict2 = clf2.best_estimator_.get_params()\nprint(\"feature_selection__k : \", chosen_parameters_dict2[\"feature_selection__k\"])\nprint(\"classification__C : \", chosen_parameters_dict2[\"classification__C\"])\nprint(\"classification__gamma : \", chosen_parameters_dict2[\"classification__gamma\"])\n\n\n\nPython3\nprint(\"clf.best_estimator_\\n\", \"------------------------\\n\", clf.best_estimator_)\nprint(\"===========================================\")\nprint(\"clf.best_estimator_.get_params()\\n\", \"------------------------\\n\", clf.best_estimator_.get_params())\n\n\n\n\n\u3010 \u305d\u306e\u4ed6\u3001\u53c2\u8003 \u3011\n\n\u8a18\u4e8b\u4e2d\u3001\u53c2\u8003\u30a6\u30a7\u30d6\u30b5\u30a4\u30c8\u3068\u3057\u3066\u7d39\u4ecb\u3055\u305b\u3066\u9802\u3044\u305f\u4ee5\u4e0b\u306e\u30a6\u30a7\u30d6\u30b5\u30a4\u30c8\u3067\u306f\u3001\nGridSearchCV \u304b\u3089\u3001\u691c\u51fa\u3055\u308c\u305f\u6700\u826f\u306a\u30d1\u30e9\u30e1\u30fc\u30bf\u7d44\u307f\u5408\u308f\u305b\u3068\u3001\u6700\u3082\u826f\u304f\u306a\u3044\u30d1\u30e9\u30e1\u30fc\u30bf\u7d44\u307f\u5408\u308f\u305b\u3092\u53d6\u308a\u51fa\u3057\u3066\u3001\u305d\u308c\u305e\u308c\u306e\u30d1\u30e9\u30e1\u30fc\u30bf\u306e\u4e0b\u3067\u306e\u5206\u985e\u7d50\u679c\u3092\u3001\u6b63\u89e3\u30c7\u30fc\u30bf\u3068\u3042\u308f\u305b\u3066\u3001\u30b0\u30e9\u30d5\u51fa\u529b\u3057\u3066\u3044\u307e\u3059\u3002\n\nMy Life as a Mock Quant \uff082013-08-25\uff09 \u300cscikit-learn\u3067\u30b5\u30dd\u30fc\u30c8\u30d9\u30af\u30c8\u30eb\u56de\u5e30\u3001\u53ca\u3073\u305d\u306e\u30d1\u30e9\u30e1\u30fc\u30bf\u30fc\u63a8\u8a08 with \u30af\u30ed\u30b9\u30d0\u30ea\u30c7\u30fc\u30b7\u30e7\u30f3\u3084\u3063\u3066\u307f\u308b\u300d\n\n\uff08\u4ee5\u4e0b\u3001\u540c\u30b5\u30a4\u30c8\u304b\u3089\u305d\u306e\u90e8\u5206\u306e\u30b3\u30fc\u30c9\u3092\u8ee2\u8f09\uff09\n\u4f46\u3057\u3001\u4ee5\u4e0b\u306e\u30b3\u30e1\u30f3\u30c8\u90e8\u5206\u306f\u3001\u672c\u8a18\u4e8b\u6295\u7a3f\u8005\u306b\u3088\u308b\n# \u6b63\u3057\u304f\u306f\u3001reg_max \uff1f\n\n\n\u30b3\u30fc\u30c9\u306f\u2193\u306a\u611f\u3058\u3002\u4e00\u756a\u30b9\u30b3\u30a2\u306e\u826f\u3044\u30e2\u30c7\u30eb\u306f\nbest_estimator_\n\u3068\u3044\u3046\u30d7\u30ed\u30d1\u30c6\u30a3\u306b\u683c\u7d0d\u3055\u308c\u3066\u3044\u308b\u306e\u3067\u7c21\u5358\u306b\u53d6\u5f97\u3067\u304d\u308b\u304c\u3001\uff08\u666e\u901a\u306f\u7528\u9014\u306e\u306a\u3044\uff09\u4e00\u756a\u30b9\u30b3\u30a2\u306e\u60aa\u3044\u30e2\u30c7\u30eb\u3092\u51fa\u3059\u306e\u306b\u82e6\u52b4\u3057\u305f\u3002\n\nPython\nfrom sklearn.grid_search import GridSearchCV\n#RBF\u30ab\u30fc\u30cd\u30eb\u306e\u30d1\u30e9\u30e1\u30fc\u30bf\u30fc\u03b3\u3068\u7f70\u5247C\u3092\u8907\u6570\u500b\u4f5c\u3063\u3066\u305d\u306e\u4e2d\u3067(\u30b9\u30b3\u30a2\u306e\u610f\u5473\u3067\uff09\u826f\u3044\u7269\u3092\u63a2\u7d22(\u30ab\u30fc\u30cd\u30eb\u3082\u30d1\u30e9\u30e1\u30fc\u30bf\u30fc\u3068\u3057\u3066\u4f7f\u7528\u53ef\u80fd)\ntuned_parameters = [{'kernel': ['rbf'], 'gamma': [10**i for i in range(-4,0)], 'C': [10**i for i in range(1,4)]}]\ngscv = GridSearchCV(svm.SVR(), tuned_parameters, cv=5, scoring=\"mean_squared_error\")\ngscv.fit(x_train, y_train)\n\n#\u4e00\u756a\u30b9\u30b3\u30a2\u60aa\u3044&\u826f\u3044\u5974\u3092\u51fa\u3059\nparams_min,_,_ = gscv.grid_scores_[np.argmin([x[1] for x in gscv.grid_scores_])]\nreg_min = svm.SVR(kernel=params_min['kernel'], C=params_min['C'], gamma=params_min['gamma'])\nreg_max = gscv.best_estimator_\n\n#\u5168\u30c8\u30ec\u30fc\u30cb\u30f3\u30b0\u30c7\u30fc\u30bf\u3092\u4f7f\u3063\u3066\u518d\u63a8\u8a08\nreg_min.fit(x_train, y_train)\nreg_min.fit(x_train, y_train) # \u6b63\u3057\u304f\u306f\u3001reg_max \uff1f\n\n#\u6b63\u7b54(\u9752)\uff06\u826f\u3044(\u8d64)\uff06\u60aa\u3044(\u7dd1)\u306e\u7d50\u679c\u3092PLOT\nplt.plot(x_test, y_test, 'bo-',x_test, reg_max.predict(x_test), 'ro-',x_test, reg_min.predict(x_test), 'go-')\nplt.show()\n\n\n\n\n###__Pipeline \u3068 GridSeasrchCV \u306b\u3064\u3044\u3066\u306f\u3001\u4ee5\u4e0b \u3092 \u53c2\u8003__\n\n* \u30aa\u30e9\u30a4\u30ea\u30fc\u672c\u300e\u5b9f\u8df5 \u6a5f\u68b0\u5b66\u7fd2\u30b7\u30b9\u30c6\u30e0\u300f _pp.123-124, pp.129-130_\n\n___\n\n###__\u4f8b\u984c\u30b3\u30fc\u30c9 \u3092 Python3 \u3067\u5b9f\u884c\u3059\u308b\u969b\u306f\u3001\u30d1\u30e9\u30e1\u30fc\u30bf\u30fb\u30ea\u30b9\u30c8 \u306e range() \u3092 list\u306b\u578b\u5909\u63db\u3057\u306a\u3044\u3068\u30a8\u30e9\u30fc\u306b\u306a\u308b\u306e \u3067 \u6ce8\u610f__\n\n####__\u4f8b\u3068\u3057\u3066\u3001\u4ee5\u4e0b\u306e\u30a6\u30a7\u30d6\u30b5\u30a4\u30c8 \u6240\u53ce\u306e\u30b5\u30f3\u30d7\u30eb\u30fb\u30b3\u30fc\u30c9 \u3092 \u5b9f\u884c\u3057\u3066\u307f\u308b__\n\n* [\u8d74\u304f\u307e\u307e\u306b \uff082014/02/10\uff09\u300cscikit-learn\u3067Pipeline\u300d](http://xargs.hateblo.jp/entry/2014/02/10/221212)\n\n__sklearn.pipeline.Pipeline__\n\n>scikit-learn\u3067\u3053\u306e\u4e00\u6c17\u901a\u8cab\u3092\u5b9f\u73fe\u3059\u308b\u30af\u30e9\u30b9\u304cPipeline\u3067\u3059\u3002 \u4f7f\u3063\u3066\u307f\u307e\u3057\u3087\u3046\u3002\n>\n>\n>```{python:Python3}\n>\n>from sklearn import svm\n>from sklearn.grid_search import GridSearchCV\n>from sklearn.pipeline import Pipeline\n>import sklearn.feature_selection as fs\n>import numpy\n>\n>train_X, train_Y, test_X = load() #\u30c7\u30fc\u30bf\u3092\u8aad\u307f\u8fbc\u3080\n>\n>#\n># \u4e00\u9023\u306e\u30b9\u30c6\u30c3\u30d7\u3092\u8a18\u8ff0\n>#\n>pl = Pipeline([\n>    ('feature_selection', fs.SelectKBest()),#\u6700\u9069\u306a\u6570\u6b21\u5143\u9078\u629e\n>    ('classification', svm.SVC()) #\u5206\u985e\u5668\n>])\n>\n>#\n># __\u3092\u3064\u3051\u308b\u3053\u3068\u3067\u5404\u30b9\u30c6\u30c3\u30d7\u306e\u30b3\u30f3\u30b9\u30c8\u30e9\u30af\u30bf\u306b\u6e21\u3059\u30d1\u30e9\u30e1\u30fc\u30bf\u3092\u8a2d\u5b9a\u51fa\u6765\u308b\n>#\n>parameters = { \n>    'feature_selection__k' : range(20, 39), #\u6700\u9069\u306a20~39\u6b21\u5143\u9078\u629e\n>    'classification__C': numpy.logspace(0, 4, 100).tolist(),  #C\u309210^0~10^4\u3067100\u5206\u5272\n>    'classification__gamma': numpy.logspace(-3, 1, 100).tolist() #gamma\u309210^0~10^4\u3067100\u5206\u5272\n>}\n>\n>#\u30b0\u30ea\u30c3\u30c9\u30b5\u30fc\u30c1\n>clf = GridSearchCV(pl, parameters, n_jobs=-1)\n>#\u5b66\u7fd2\n>clf.fit(train_X, train_Y)\n>print clf.best_estimator_.get_params()\n>#\u4e88\u6e2c\n>clf.predict(text_X)\n>```\n\n___\n\n##__\uff08 Python3 \u3067\u306e \u5b9f\u884c\u7d50\u679c \uff09__\n\n>```{python:Python3 (Anaconda jupyter)}\n> ---------------------------------------------------------------------------\n>ValueError                                Traceback (most recent call last)\n><ipython-input-12-c73775cc4951> in <module>()\n>----> 1 clf = GridSearchCV(pl, parameters, n_jobs=-1)\n>\n>/Users/hirofumi.yashima/anaconda/lib/python3.5/site->packages/sklearn/grid_search.py in __init__(self, estimator, param_grid, scoring, >fit_params, n_jobs, iid, refit, cv, verbose, pre_dispatch, error_score)\n>    785             refit, cv, verbose, pre_dispatch, error_score)\n>    786         self.param_grid = param_grid\n>--> 787         _check_param_grid(param_grid)\n>    788 \n>    789     def fit(self, X, y=None):\n>\n>/Users/hirofumi.yashima/anaconda/lib/python3.5/site->packages/sklearn/grid_search.py in _check_param_grid(param_grid)\n>    326             check = [isinstance(v, k) for k in (list, tuple, np.ndarray)]\n>    327             if True not in check:\n>--> 328                 raise ValueError(\"Parameter values should be a list.\")\n>    329 \n>    330             if len(v) == 0:\n>\n>ValueError: Parameter values should be a list.\n>\n>In [ ]:\n>```\n\n___\n\n\n##__\uff08 \u4ee5\u4e0b \u3067 OK )__\n\n###__Python3 \u3067\u884c\u3046\u5834\u5408\u306f\u3001range() \u3092 list \u3067\u30ea\u30b9\u30c8\u578b\u306b\u578b\u5909\u63db\u3059\u308c\u3070 OK__\n\n```{python:Python3 (Anaconda jupyter)}\n'feature_selection__k' : list(range(20, 39)),\n```\n\n___\n\n###__\u3010 \u5b9f\u884c\u7d50\u679c \u3011__\n\n```{python:Python3 (Anaconda jupyter)}\nparameters = [{\n    'feature_selection__k' : list(range(20, 39)), #\u6700\u9069\u306a20~39\u6b21\u5143\u9078\u629e\n    'classification__C': numpy.logspace(0, 4, 100).tolist(),  #C\u309210^0~10^4\u3067100\u5206\u5272\n    'classification__gamma': numpy.logspace(-3, 1, 100).tolist() #gamma\u309210^0~10^4\u3067100\u5206\u5272\n}]\n\nclf = GridSearchCV(pl, parameters, n_jobs=-1)\n\nprint(clf)\n```\n\n####__\uff08 \u5b9f\u884c\u7d50\u679c \uff09__\n\n* _scoring=None_ \n\n```\nGridSearchCV(cv=None, error_score='raise',\n       estimator=Pipeline(steps=[('feature_selection', SelectKBest(k=10, score_func=<function f_classif at 0x1067fe950>)), ('classification', SVC(C=1.0, cache_size=200, class_weight=None, coef0=0.0,\n  decision_function_shape=None, degree=3, gamma='auto', kernel='rbf',\n  max_iter=-1, probability=False, random_state=None, shrinking=True,\n  tol=0.001, verbose=False))]),\n       fit_params={}, iid=True, n_jobs=-1,\n       param_grid=[{'feature_selection__k': [20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38], 'classification__gamma': [0.001, 0.0010974987654930556, 0.0012045035402587824, 0.0013219411484660286, 0.0014508287784959402, 0.0015922827933410922, 0.001747528400007683, 0.0019179102616....29144183426, 6892.612104349702, 7564.633275546291, 8302.175681319752, 9111.627561154895, 10000.0]}],\n       pre_dispatch='2*n_jobs', refit=True, scoring=None, verbose=0)\n```\n\n___\n\n###__\u30d1\u30e9\u30e1\u30fc\u30bf\u30fb\u30ea\u30b9\u30c8\uff08pl \u53ca\u3073 parameters\uff09 \u306e\u4e2d\u3067 \u5b9a\u7fa9\u3057\u3066\u3044\u308b SVM \u306e \u5404\u30d1\u30e9\u30e1\u30fc\u30bf \u306b\u3064\u3044\u3066\u306f\u3001\u4ee5\u4e0b \u3092 \u53c2\u8003__\n\n\n####__\uff08\uff11\uff09SelectKBest__\n\n```\npl = Pipeline([\n   ('feature_selection', fs.SelectKBest()),#\u6700\u9069\u306a\u6570\u6b21\u5143\u9078\u629e\n   ('classification', svm.SVC()) #\u5206\u985e\u5668\n])\n```\n\n[\u30d7\u30ed\u30b0\u30e9\u30de\u30fc\u793e\u9577\u306e\u300c\u65e5\u3005\u767a\u898b\u300d \uff082015/05/20\uff09\u300c\u6a5f\u68b0\u5b66\u7fd2\u3000feature selection\u3000\u7279\u5fb4\u9078\u629e\u300d](http://blog.livedoor.jp/kmiwa_project/archives/cat_877408.html?p=6)\n\n>__\u30fb\u30c7\u30fc\u30bf\u9078\u629e\u65b9\u6cd5__\n>\n>\u30c6\u30ad\u30b9\u30c8\u5206\u985e\u3068\u3001\u7279\u5fb4\u304c\u81a8\u5927\u306a\u3082\u306e\u306f\u81ea\u52d5\u7684\u306b\u30c7\u30fc\u30bf\u3092\u9078\u629e\u3055\u305b\u308b\u5fc5\u8981\u304c\u3042\u308b\u3002\n>sckit\u3067\u9078\u629e\u3059\u308b\u65b9\u6cd5\u3068\u3057\u3066\u3001SelectPercentile\u3000\u3068\u3000SelectKBest\u3000\u306e\u4e8c\u3064\u304c\u3042\u308b\u3002\n>\n>SelectPercentile\u30fb\u30fb\u30fb\u3000\u91cd\u8981\u306a\u7279\u5fb4\u306e\u4e0a\u4f4dX%\u3092\u9078\u629e\u3059\u308b\u3002\n>SelectKBest\u3000\u30fb\u30fb\u30fb\u3000\u3000\u91cd\u8981\u306a\u7279\u5fb4\u3092K\u500b\u9078\u629e\u3059\u308b\n\n\n* [Risky Dune \uff082013/02/25\uff09\u300cscikit.learn\u624b\u6cd5\u5fb9\u5e95\u6bd4\u8f03\uff01 \u6c7a\u5b9a\u6728\u7de8\u300d](http://d.hatena.ne.jp/saket/20130225/1361778033)\n\n>__\u304a\u307e\u3051\u5b9f\u9a13__\n>\n>\u516c\u5f0f\u30d8\u30eb\u30d7\u306b\u306f\u300c\u6b21\u5143\u524a\u6e1b\u624b\u6cd5\u3092\u8a66\u3057\u3066\u307f\u308d\u300d\u3068\u3042\u308b\u306e\u3067, \u6b21\u5143\u524a\u6e1b\u624b\u6cd5\u3068\u3057\u3066\u78ba\u7387\u7684PCA(\u4e3b\u6210\u5206\u5206\u6790)\u3068, \u5165\u529b\u30d9\u30af\u30c8\u30eb\u306e\u5404\u6b21\u5143\u3054\u3068\u306b\u30e9\u30d9\u30eb\u3068\u306e\u95a2\u9023\u5ea6(\u672c\u5f53\u306f\u3061\u3087\u3063\u3068\u9055\u3046\u304c)\u3092\u8abf\u3079\u4e0a\u4f4d\u306e\u3082\u306e\u306e\u307f\u3092\u6b8b\u3059SelectKBest\u3092\u7528\u3044\u3066\u5b9f\u9a13\u3092\u884c\u306a\u3063\u3066\u307f\u305f. \u306a\u304a, criteria=entropy, \u30c7\u30fc\u30bf\u65701\u4e07\u3068\u3059\u308b.\n\n\n####__\uff08\uff12\uff09RBF\u30ab\u30fc\u30cd\u30eb(Gaussian \u30ab\u30fc\u30cd\u30eb / \u30e9\u30b8\u30a2\u30eb\u57fa\u5e95\u95a2\u6570\u30ab\u30fc\u30cd\u30eb)__\n\n```\nparameters = { \n   'feature_selection__k' : range(20, 39), #\u6700\u9069\u306a20~39\u6b21\u5143\u9078\u629e\n   'classification__C': numpy.logspace(0, 4, 100).tolist(),  #C\u309210^0~10^4\u3067100\u5206\u5272\n   'classification__gamma': numpy.logspace(-3, 1, 100).tolist() #gamma\u309210^0~10^4\u3067100\u5206\u5272\n}\n```\n\n\n[My Life as a Mock Quant \uff082013-08-25\uff09 \u300cscikit-learn\u3067\u30b5\u30dd\u30fc\u30c8\u30d9\u30af\u30c8\u30eb\u56de\u5e30\u3001\u53ca\u3073\u305d\u306e\u30d1\u30e9\u30e1\u30fc\u30bf\u30fc\u63a8\u8a08 with \u30af\u30ed\u30b9\u30d0\u30ea\u30c7\u30fc\u30b7\u30e7\u30f3\u3084\u3063\u3066\u307f\u308b\u300d](http://d.hatena.ne.jp/teramonagi/20130825/1377434479)\n\n>\u30af\u30ed\u30b9\u30d0\u30ea\u30c7\u30fc\u30b7\u30e7\u30f3\u3068\u30b0\u30ea\u30c3\u30c9\u30b5\u30fc\u30c1\u3092\u4f7f\u3063\u3066SVR\u306e\u30d1\u30e9\u30e1\u30fc\u30bf\u3092\u6c7a\u3081\u308b\n>\u5358\u7d14\u306bCV\u3084\u308b\u3060\u3051\u306a\u3089\u4e0a\u3067\u3044\u3044\u304c\u3001\u4eca\u307e\u3067\u6240\u4e0e\u3060\u3068\u601d\u3063\u3066\u653e\u7f6e\u3057\u3066\u3044\u305f\u30e2\u30c7\u30eb\u30d1\u30e9\u30e1\u30fc\u30bf\u3001\u3053\u306e\u4f8b\u3060\u3068\n>\n>__\u7f70\u5247\u306e\u5f37\u3055\u3092\u8868\u3059:C__\n>__\u30ac\u30a6\u30b7\u30a2\u30f3\u30ab\u30fc\u30cd\u30eb\u306e\u5e83\u304c\u308a\u3092\u8868\u3059:\u03b3__\n>\n>\u3092\u6c7a\u3081\u3066\u3084\u308a\u305f\u3044\u3002\u305d\u306e\u305f\u3081\u306b\u306fGridSearchCV\u95a2\u6570\u3092\u7528\u3044\u308b\u3002\n>\n>\u9069\u5f53\u306a\u30d1\u30e9\u30e1\u30fc\u30bf\u30fc\u30b0\u30ea\u30c3\u30c9\uff08\u7d44\uff09\u306b\u5bfe\u3057\u3066K-fold CV(\u3053\u3053\u3067\u306f5-fold\uff09\u3092\u7e70\u308a\u8fd4\u3057\u3001\u30b9\u30b3\u30a2(\u3053\u3053\u3067\u306fMSE)\u304c\u6700\u3082\u826f\u304f\u306a\u308b\u30d1\u30e9\u30e1\u30fc\u30bf\u30fc\u306eSVR\u3092\u51fa\u529b\u3059\u308b\u4e8b\u304c\u3067\u304d\u308b\u3002\n>\n>\u3061\u306a\u307f\u306b\u4ee5\u4e0b\u306e\u30b3\u30fc\u30c9\u3067\n>\n>```\n>tuned_parameters = [{'kernel': ['rbf'], 'gamma': [10**i for i in range(-4,0)], 'C': [10**i for i in range(1,4)]}]\n>```\n>\n>\u3068\u66f8\u3044\u3066\u3044\u308b\u7b87\u6240\u3092\n>\n>```\n>tuned_parameters = [\n>    {'kernel': ['rbf'], 'gamma': [10**i for i in range(-4,3)], 'C': [10**i for i in range(-3, 4)]},\n>    {'kernel': ['linear'], 'C': [1, 10, 100, 1000]}\n>]\n>```\n>\n>\u3068\u3059\u308b\u3068\u3001\u30ab\u30fc\u30cd\u30eb\u3082\u540c\u6642\u306b\u201d\u30d1\u30e9\u30e1\u30fc\u30bf\u30fc\u201d\u3068\u3057\u3066\u8a55\u4fa1\u3055\u308c\u3001\u4e0a\u8a18\u306e\u901a\u5e38\u8a00\u3046\u3088\u3046\u306a\u30d1\u30e9\u30e1\u30fc\u30bf\u30fc\u3060\u3051\u3067\u306f\u306a\u304f\u3001\u7570\u306a\u308b\u30ab\u30fc\u30cd\u30eb\u9593\u3067\u306e\u7d50\u679c\u6bd4\u8f03\u3082\u51fa\u6765\u308b\u306e\u304c\u7d20\u6674\u3089\u3057\u3044*4\u3002\n\n\n[sleepy_yoshi\u3055\u3093 SlideShare \u300cSVM\u5b9f\u8df5\u30ac\u30a4\u30c9 (A Practical Guide to Support Vector Classification)\u300d](http://www.slideshare.net/sleepy_yoshi/svm-13435949)\n[sz_dr\u3055\u3093 \uff082014/12/18\uff09 \u300cSVM(RBF\u30ab\u30fc\u30cd\u30eb)\u306e\u30cf\u30a4\u30d1\u30fc\u30d1\u30e9\u30e1\u30fc\u30bf\u3092\u5909\u3048\u308b\u3068\u4f55\u304c\u8d77\u3053\u308b\u306e?\u300d](http://qiita.com/sz_dr/items/f3d6630137b184156a67)\n[pika_shi\u3055\u3093 \uff082014/12/16\uff09 \u300cSVM\u3092\u4f7f\u3044\u3053\u306a\u3059\uff01\u30c1\u30a7\u30c3\u30af\u30dd\u30a4\u30f3\u30c88\u3064\u300d](http://qiita.com/pika_shi/items/5e59bcf69e85fdd9edb2)\n\n>__3. \u30ab\u30fc\u30cd\u30eb\u95a2\u6570__\n>\n>\u30ab\u30fc\u30cd\u30eb\u95a2\u6570\u306f\uff0c\u7dda\u5f62\u30ab\u30fc\u30cd\u30eb\uff0c\u591a\u9805\u5f0f\u30ab\u30fc\u30cd\u30eb\uff0cRBF\u30ab\u30fc\u30cd\u30eb\uff0c\u30b7\u30b0\u30e2\u30a4\u30c9\u30ab\u30fc\u30cd\u30eb\u2026 \u3068\u6570\u591a\u304f\u3042\u308a\u307e\u3059\u304c\uff0c\u57fa\u672c\u7684\u306b\u306fRBF\u30ab\u30fc\u30cd\u30eb\u4e00\u629e\u3060\u3068\u601d\u3063\u3066\u5927\u4e08\u592b\u3067\u3059\uff0e\n>\u305f\u3060\uff0c\u3082\u3061\u308d\u3093\u4ed6\u306e\u30ab\u30fc\u30cd\u30eb\u3092\u4f7f\u3046\u3068\u3082\u3063\u3068\u3046\u307e\u304f\u3044\u304f\u3053\u3068\u3082\u3042\u308a\u307e\u3059\uff0e\u4f8b\u3048\u3070\uff0c\u30c7\u30fc\u30bf\u6570\u3068\u6bd4\u3079\u3066\u7279\u5fb4\u91cf\u306e\u6570\u304c\u5727\u5012\u7684\u306b\u591a\u3044\u3088\u3046\u306a\u5834\u5408\u306f\uff0c\u7dda\u5f62\u30ab\u30fc\u30cd\u30eb\u304c\u3046\u307e\u304f\u3044\u304d\u3084\u3059\u3044\u3067\u3059\uff0e\n\n[verum ipsum factum \uff082013-04-08\uff09\u300c\u30b5\u30dd\u30fc\u30c8\u30d9\u30af\u30bf\u30fc\u30de\u30b7\u30f3\u3068\u306f\uff3b\u30ab\u30fc\u30cd\u30eb\u6cd5\u306b\u3088\u308b\u975e\u7dda\u5f62\u30b5\u30dd\u30fc\u30c8\u30d9\u30af\u30bf\u30fc\u30de\u30b7\u30f3\uff3d ](http://sudillap.hatenablog.com/entry/2013/04/08/235610)\n\n>__\u30ab\u30fc\u30cd\u30eb\u306e\u4f8b__\n>\n>\u30b5\u30dd\u30fc\u30c8\u30d9\u30af\u30bf\u30fc\u30de\u30b7\u30f3\u306e\u7279\u5fb4\u306e\u4e00\u3064\u306f\u3001\u89e3\u304d\u305f\u3044\u554f\u984c\u306b\u5fdc\u3058\u3066\u30ab\u30fc\u30cd\u30eb\u3092\u9069\u5207\u306b\u9078\u3073\u6c4e\u5316\u80fd\u529b\u3092\u5411\u4e0a\u3067\u304d\u308b\u3053\u3068\u3067\u3059\u3002\u5b9f\u969b\u3001\u554f\u984c\u306e\u7a2e\u985e\u306b\u5fdc\u3058\u3066\u69d8\u3005\u306a\u30ab\u30fc\u30cd\u30eb\u304c\u958b\u767a\u3055\u308c\u3066\u3044\u307e\u3059\u3002\n>\n>\u3053\u3053\u3067\u3088\u304f\u7528\u3044\u3089\u308c\u308b\u30ab\u30fc\u30cd\u30ebK(x,x\u2032)K(x,x\u2032)\u3092\u3044\u304f\u3064\u304b\u7d39\u4ecb\u3057\u307e\u3059\u3002\n>\n>__\u7dda\u5f62\u30ab\u30fc\u30cd\u30eb__\n\n\uff08 \u4e2d\u7565 \uff09\n\n>\n>__\u591a\u9805\u5f0f\u30ab\u30fc\u30cd\u30eb__\n\n\uff08 \u4e2d\u7565 \uff09\n\n>\n>__\u53cc\u66f2\u7dda\u6b63\u63a5\u30ab\u30fc\u30cd\u30eb__\n\n[Yukara Ikemiya\u3055\u3093 Qiita\u8a18\u4e8b\u300c\u30d1\u30bf\u30fc\u30f3\u8a8d\u8b58\u3068\u6a5f\u68b0\u5b66\u7fd26\u7ae0\uff08\u30ab\u30fc\u30cd\u30eb\u6cd5\uff09\u300d](http://www.slideshare.net/yukaraikemiya/6-15415589)\n\n[GitHub levelfour/machine-learning-2014 \u7b2c4\u56de \u975e\u7dda\u5f62\u5199\u50cf\u3068\u30ab\u30fc\u30cd\u30eb\u95a2\u6570](https://github.com/levelfour/machine-learning-2014/wiki/%E7%AC%AC4%E5%9B%9E---%E9%9D%9E%E7%B7%9A%E5%BD%A2%E5%86%99%E5%83%8F%E3%81%A8%E3%82%AB%E3%83%BC%E3%83%8D%E3%83%AB%E9%96%A2%E6%95%B0)\n\n>__\u52d5\u5f84\u57fa\u5e95\u95a2\u6570\u30ab\u30fc\u30cd\u30eb(RBF\u30ab\u30fc\u30cd\u30eb)__\n>\n>RBF\u30ab\u30fc\u30cd\u30eb(radial bases function kernel)\u306f\u3001\u304a\u305d\u3089\u304f\u6700\u3082\u5e83\u304f\u5229\u7528\u3055\u308c\u3066\u3044\u308b\u30ab\u30fc\u30cd\u30eb\u95a2\u6570\u3067\u3042\u308b\u3002 \n>\u30ac\u30a6\u30b9\u5206\u5e03\u95a2\u6570\u306e\u95a2\u6570\u7cfb\u3092\u3057\u3066\u3044\u308b\u305f\u3081\u3001\u30ac\u30a6\u30b7\u30a2\u30f3\u30ab\u30fc\u30cd\u30eb(Gaussian kernel)\u3068\u547c\u3070\u308c\u308b\u3053\u3068\u3082\u3042\u308b\u3002\n>\n>scikit-learn\u306esvm.SVC\u3082\u3001\u30c7\u30d5\u30a9\u30eb\u30c8\u3067\u306fRBF\u30ab\u30fc\u30cd\u30eb\u3092\u63a1\u7528\u3057\u3066\u3044\u308b\u3002\n\n[teratail\u3078\u3088\u3046\u3053\u305d \u300c\u53d7\u4ed8\u4e2d RBF\u30ab\u30fc\u30cd\u30eb\u3092\u7528\u3044\u305fSVM\u306e\u30cf\u30a4\u30d1\u30fc\u30d1\u30e9\u30e1\u30fc\u30bf\u300d](https://teratail.com/questions/22156)\n\n___\n\n##__\u3010 \u305d\u306e\u4ed6 \u53c2\u8003 \u3011__\n\n* [\u8d74\u304f\u307e\u307e\u306b \uff082014/02/08\uff09 \u300cscikit-learn\u3067SVM\u30c1\u30e5\u30fc\u30cb\u30f3\u30b0\u300d](http://xargs.hateblo.jp/entry/2014/02/08/210620)\n\n* [Takahiro Kubo\u3055\u3093 SlideShare \u300c\u5b9f\u6226\u6295\u5165\u3059\u308b\u6a5f\u68b0\u5b66\u7fd2\u300d](http://www.slideshare.net/takahirokubo7792/ss-46471269)\n\n* [\u30c8\u30d4\u30c3\u30af\u30e2\u30c7\u30eb\u306b\u57fa\u3065\u304f\u591a\u69d8\u6027\u306e\u5b9a\u91cf\u5316](http://aial.shiroyagi.co.jp/2014/12/%E3%83%88%E3%83%94%E3%83%83%E3%82%AF%E3%83%A2%E3%83%87%E3%83%AB%E3%81%AB%E5%9F%BA%E3%81%A5%E3%81%8F%E5%A4%9A%E6%A7%98%E6%80%A7%E3%81%AE%E5%AE%9A%E9%87%8F%E5%8C%96/)\n\n___\n\n##__\u3010 \u88dc\u8db3 \u3011pipes\u30e2\u30b8\u30e5\u30fc\u30eb \u3068\u306f \u5225__\n\n* [Python 2.7 Documentation 36.11. pipes \u2014 \u30b7\u30a7\u30eb\u30d1\u30a4\u30d7\u30e9\u30a4\u30f3\u3078\u306e\u30a4\u30f3\u30bf\u30d5\u30a7\u30fc\u30b9](http://docs.python.jp/2/library/pipes.html)\n\n___\n\n\n###__GridSeasrchCV \u304c \u898b\u51fa\u3057\u305f \u30d1\u30e9\u30e1\u30fc\u30bf\u306e\u6700\u9069\u306a\u7d44\u307f\u5408\u308f\u305b\u7d50\u679c \u306f\u3001\u8fd4\u308a\u5024.best_estimator_ \u306b \u683c\u7d0d\u3055\u308c\u308b__\n\n####__\u3010 \u53c2\u8003 \u3011__\n\n[scikit learn sklearn.grid_search.GridSearchCV](http://scikit-learn.org/stable/modules/generated/sklearn.grid_search.GridSearchCV.html#sklearn.grid_search.GridSearchCV.get_params)\n\n<img width=\"1227\" alt=\"\u30b9\u30af\u30ea\u30fc\u30f3\u30b7\u30e7\u30c3\u30c8 2016-03-25 17.07.06.png\" src=\"https://qiita-image-store.s3.amazonaws.com/0/43487/4c399249-8498-7fc7-11c1-2930b83af6e7.png\">\n\n\n* __\u7701\u7565\u53ef\u80fd\u306a\u5f15\u6570 _cv_ \u306b\u3001\u4ea4\u5dee\u691c\u5b9a\u6cd5\u3067\u3001\u30c7\u30fc\u30bf\u3092\u4f55\u5206\u5272\u3059\u308b\u304b\u3092\u6307\u5b9a\u3067\u304d\u308b\u3002\uff08\u7701\u7565\u6642\u306f\u3001K=\uff13 \u3067 \u30c7\u30d5\u30a9\u30eb\u30c8\u8a2d\u5b9a\u3055\u308c\u308b\uff09__\n\n<img width=\"859\" alt=\"\u30b9\u30af\u30ea\u30fc\u30f3\u30b7\u30e7\u30c3\u30c8 2016-04-13 10.40.32.png\" src=\"https://qiita-image-store.s3.amazonaws.com/0/43487/b88fdfd6-2f00-2c2c-0a3c-a51f0e223b27.png\">\n\n\n\n<img width=\"832\" alt=\"\u30b9\u30af\u30ea\u30fc\u30f3\u30b7\u30e7\u30c3\u30c8 2016-03-25 17.05.14.png\" src=\"https://qiita-image-store.s3.amazonaws.com/0/43487/9ae8f076-4c8f-e17b-0325-41d2d0cca67b.png\">\n\n<img width=\"918\" alt=\"\u30b9\u30af\u30ea\u30fc\u30f3\u30b7\u30e7\u30c3\u30c8 2016-03-25 17.06.47.png\" src=\"https://qiita-image-store.s3.amazonaws.com/0/43487/3720ce4a-0ab8-cef6-6e88-2a0e2eb21773.png\">\n\n\n####__\u4ee5\u4e0b\u3001GridSearch\u3092\u5229\u7528\u3057\u305f\u30b3\u30fc\u30c9\u4e8b\u4f8b\u306e\u306a\u304b\u3067\u3001.best_estimator \u3092 \u51fa\u529b\u3057\u3066\u3044\u308b\u30b3\u30fc\u30c9\u90e8\u5206__\n\n\n[\u8d74\u304f\u307e\u307e\u306b \uff082014/02/10\uff09 \u300cscikit-learn\u3067Pipeline\u300d](http://xargs.hateblo.jp/entry/2014/02/10/221212)\n\n__\uff08\u4ee5\u4e0b\u30b3\u30fc\u30c9\u4e2d\u3001\u30a2\u30f3\u30c0\u30fc\u30b9\u30b3\u30a2\uff12\u3064 \u3067\u56f2\u3063\u305f\u90e8\u5206\uff09 \u203b \u30a2\u30f3\u30c0\u30fc\u30b9\u30b3\u30a2\uff12\u3064 \u306f\u3001\u672c\u8a18\u4e8b\u57f7\u7b46\u8005\u306b\u3088\u308b__\n\n>```\n\u2265#\u30b0\u30ea\u30c3\u30c9\u30b5\u30fc\u30c1\n>clf = GridSearchCV(pl, parameters, n_jobs=-1)\n>#\u5b66\u7fd2\n>clf.fit(train_X, train_Y)\n>__print clf.best_estimator_.get_params()__\n>#\u4e88\u6e2c\n>clf.predict(text_X)\n>```\n\n\n[Pygments Demo entry 149057, _Restricted Boltzmann Machine features for digit classification_](http://pygments.org/demo/149057/)\n\n__\uff08\u4ee5\u4e0b\u30b3\u30fc\u30c9\u4e2d\u3001\u30a2\u30f3\u30c0\u30fc\u30b9\u30b3\u30a2\uff12\u3064 \u3067\u56f2\u3063\u305f\u90e8\u5206\uff09 \u203b \u30a2\u30f3\u30c0\u30fc\u30b9\u30b3\u30a2\uff12\u3064 \u306f\u3001\u672c\u8a18\u4e8b\u57f7\u7b46\u8005\u306b\u3088\u308b__\n\n>```\n>def gridsearch(classifier, param_grid):\n>    scores = ['precision', 'recall'] # training evaluation metrics\n>    \n>    for score in scores:\n>        print(\"# Tuning hyper-parameters for %s\\n\" % score)\n>        clf = GridSearchCV(classifier, param_grid=param_grid, cv=5, scoring=score, verbose=1)\n>        clf.fit(X_train, y_train)\n>        __print(\"Best parameters set found on development set:\\n\")__\n>        __print(clf.best_estimator_)__\n>        print(\"\\nGrid scores on development set:\\n\")\n>        for params, mean_score, scores in clf.grid_scores_:\n>            print(\"%0.3f (+/-%0.03f) for %r\\n\"\n>                % (mean_score, scores.std() / 2, params))\n>    \n>        print(\"Detailed classification report:\\n\")\n>        print(\"The model is trained on the full development set.\")\n>        print(\"The scores are computed on the full evaluation set.\\n\")\n>        y_true, y_pred = y_test, clf.predict(X_test)\n>        print(classification_report(y_true, y_pred))\n>        print()\n>        clist.append(clf)\n>```\n\n___\n\n####__\u516c\u5f0f\u30ea\u30d5\u30a1\u30ec\u30f3\u30b9\u30fb\u30da\u30fc\u30b8\uff08\u4ee5\u4e0b\uff09 \u306e Examples\u30b3\u30fc\u30c9 \u3092 \u5b9f\u884c\u3057\u3066\u3001GridSearch \u304c \u898b\u51fa\u3057\u305f \u6700\u9069\u306a\u30d1\u30e9\u30e1\u30fc\u30bf \u306e \u7d44\u307f\u5408\u308f\u305b \u306e \u7d50\u679c \u3092 \u51fa\u529b\u3057\u3066\u307f\u308b__\n\n[scikit learn sklearn.grid_search.GridSearchCV](http://scikit-learn.org/stable/modules/generated/sklearn.grid_search.GridSearchCV.html#sklearn.grid_search.GridSearchCV.get_params)\n\n\n\n```{python:Python3 Anaconda jupyter}\nfrom sklearn import svm, grid_search, datasets\n\niris = datasets.load_iris()\n\nparameters = {'kernel':('linear', 'rbf'), 'C':[1, 10]}\nsvr = svm.SVC()\n\nclf = grid_search.GridSearchCV(svr, parameters)\nprint(clf)\n```\n\n__\uff08 \u5b9f\u884c\u7d50\u679c \uff09__\n\n* _scoring=None_\n\n```\nGridSearchCV(cv=None, error_score='raise',\n       estimator=SVC(C=1.0, cache_size=200, class_weight=None, coef0=0.0,\n  decision_function_shape=None, degree=3, gamma='auto', kernel='rbf',\n  max_iter=-1, probability=False, random_state=None, shrinking=True,\n  tol=0.001, verbose=False),\n       fit_params={}, iid=True, n_jobs=1,\n       param_grid={'C': [1, 10], 'kernel': ('linear', 'rbf')},\n       pre_dispatch='2*n_jobs', refit=True, scoring=None, verbose=0)\n```\n\n```{python:Python3 Anaconda jupyter}\nclf.fit(iris.data, iris.target)\n```\n\n__\uff08 \u5b9f\u884c\u7d50\u679c \uff09__\n\n```\nGridSearchCV(cv=None, error_score='raise',\n       estimator=SVC(C=1.0, cache_size=200, class_weight=None, coef0=0.0,\n  decision_function_shape=None, degree=3, gamma='auto', kernel='rbf',\n  max_iter=-1, probability=False, random_state=None, shrinking=True,\n  tol=0.001, verbose=False),\n       fit_params={}, iid=True, n_jobs=1,\n       param_grid={'C': [1, 10], 'kernel': ('linear', 'rbf')},\n       pre_dispatch='2*n_jobs', refit=True, scoring=None, verbose=0)\n```\n\n```{python:Python3 Anaconda jupyter}\nprint(\"clf.best_estimator_\\n\", clf.best_estimator_)\nprint(\"===========================================\")\nprint(\"clf.best_estimator_.get_params()\\n\", clf.best_estimator_.get_params())\n```\n\n__\uff08 \u5b9f\u884c\u7d50\u679c \uff09__\n\n```\nclf.best_estimator_\n SVC(C=1, cache_size=200, class_weight=None, coef0=0.0,\n  decision_function_shape=None, degree=3, gamma='auto', kernel='linear',\n  max_iter=-1, probability=False, random_state=None, shrinking=True,\n  tol=0.001, verbose=False)\n===========================================\nclf.best_estimator_.get_params()\n {'coef0': 0.0, 'tol': 0.001, 'degree': 3, 'gamma': 'auto', 'random_state': None, 'probability': False, 'class_weight': None, 'max_iter': -1, 'verbose': False, 'decision_function_shape': None, 'cache_size': 200, 'shrinking': True, 'kernel': 'linear', 'C': 1}\n```\n\n```{python:Python3 Anaconda jupyter}\nchosen_parameters_dict = clf.best_estimator_.get_params()\nprint(\"C : \", chosen_parameters_dict[\"C\"])\nprint(\"kernel : \", chosen_parameters_dict[\"kernel\"])\n```\n\n__\uff08 \u5b9f\u884c\u7d50\u679c \uff09__\n\n```\nC :  1\nkernel :  linear\n```\n\n\n<img width=\"1224\" alt=\"\u30b9\u30af\u30ea\u30fc\u30f3\u30b7\u30e7\u30c3\u30c8 2016-03-25 17.44.52.png\" src=\"https://qiita-image-store.s3.amazonaws.com/0/43487/831f7289-b995-c4f6-562d-38a2a6c0d33d.png\">\n<img width=\"1224\" alt=\"\u30b9\u30af\u30ea\u30fc\u30f3\u30b7\u30e7\u30c3\u30c8 2016-03-25 17.45.08.png\" src=\"https://qiita-image-store.s3.amazonaws.com/0/43487/1eeb08c3-05f8-5a60-d82c-eb811422ddc9.png\">\n\n___\n\n**grid_scores_\u306b\u306f\u3001\u4e0e\u3048\u305f\u30d1\u30e9\u30e1\u30fc\u30bf\u9078\u629e\u30ea\u30b9\u30c8 \u304b\u3089\u751f\u6210\u53ef\u80fd\u306a \u30d1\u30e9\u30e1\u30fc\u30bf\u7d44\u307f\u5408\u308f\u305b\u5168 \u30d1\u30bf\u30fc\u30f3 \u306b\u3064\u3044\u3066\u3001\u305d\u308c\u305e\u308c\u500b\u3005\u306e\u30d1\u30e9\u30e1\u30fc\u30bf\u7d44\u307f\u5408\u308f\u305b\u3067\u5206\u985e\u5668\u3092\u751f\u6210\u3057\u305f\u969b \u306e Cross-Validation\u30c6\u30b9\u30c8\u306e\u7d50\u679c\uff08\u4ea4\u5dee\u691c\u5b9a\u6cd5\u3067\u8a66\u3057\u305f\u5168\u8a66\u884c \u306e \u7d50\u679c\u5024 \u306e \u5e73\u5747\u5024 \u3068 \u6a19\u6e96\u504f\u5dee\uff09\u304c\u683c\u7d0d\u3055\u308c\u3066\u3044\u308b**\n\n<img width=\"881\" alt=\"\u30b9\u30af\u30ea\u30fc\u30f3\u30b7\u30e7\u30c3\u30c8 2016-03-25 18.18.39.png\" src=\"https://qiita-image-store.s3.amazonaws.com/0/43487/81de3378-5147-68f6-3786-76bb3ee118ae.png\">\n\n\n```{python:Python3 Anaconda jupyter}\nprint(clf.grid_scores_)\n```\n\n```{python:Python3 Anaconda jupyter}\n[mean: 0.98000, std: 0.01602, params: {'kernel': 'linear', 'C': 1}, mean: 0.97333, std: 0.00897, params: {'kernel': 'rbf', 'C': 1}, mean: 0.97333, std: 0.03697, params: {'kernel': 'linear', 'C': 10}, mean: 0.98000, std: 0.01601, params: {'kernel': 'rbf', 'C': 10}]\n```\n\n* __\uff08 \u898b\u3084\u3059\u304f\u6539\u884c\u3057\u3066\u51fa\u529b \uff09__\n\n```{python:Python3 Anaconda jupyter}\nfrom pprint import pprint\npprint(clf.grid_scores_)\n```\n\n* kernel\u95a2\u6570\u306e\u7a2e\u985e \u3068 \u30d1\u30e9\u30e1\u30fc\u30bfC\u306e\u5024 \u306e \u5168\u7d44\u307f\u5408\u308f\u305b\u30d1\u30bf\u30fc\u30f3\uff08\u5408\u8a08\uff14\u30d1\u30bf\u30fc\u30f3\uff09\u306b\u3064\u3044\u3066\n* \u5404\u7d44\u307f\u5408\u308f\u305b\u3054\u3068 \u306b \u5b9f\u884c\u3057\u305f \u4ea4\u5dee\u691c\u5b9a\u6cd5 \u306e \u7d50\u679c\uff08\u306e\u5e73\u5747\u5024\u3068\u6a19\u6e96\u504f\u5dee\uff09 \u3092 \u78ba\u8a8d\u3067\u304d\u308b\n\n```{python:Python3 Anaconda jupyter}\n[mean: 0.98000, std: 0.01602, params: {'kernel': 'linear', 'C': 1},\n mean: 0.97333, std: 0.00897, params: {'kernel': 'rbf', 'C': 1},\n mean: 0.97333, std: 0.03697, params: {'kernel': 'linear', 'C': 10},\n mean: 0.98000, std: 0.01601, params: {'kernel': 'rbf', 'C': 10}]\n```\n\n<img width=\"1051\" alt=\"\u30b9\u30af\u30ea\u30fc\u30f3\u30b7\u30e7\u30c3\u30c8 2016-03-25 18.18.54.png\" src=\"https://qiita-image-store.s3.amazonaws.com/0/43487/70a57926-41c7-63f5-7ff9-6deb10f7bb08.png\">\n\n___\n\n###__sklearn.pipeline.Pipeline \u3068  GridSeasrchCV \u3092 \u7d44\u307f\u5408\u308f\u305b\u3066\u5b9f\u884c\u3057\u3066\u307f\u305f\u4f8b__\n\n* iris\u30c7\u30fc\u30bf \u306e 8\u5272 \u3092\u5b66\u7fd2\u7528\u306b\u3001\u6b8b\u308a\uff12\u5272 \u3092 \u30c6\u30b9\u30c8\u7528 \u30c7\u30fc\u30bf\u306b\u4f7f\u7528\uff08\u4f46\u3057\u3001\u30e9\u30f3\u30c0\u30e0\u30b5\u30f3\u30d7\u30ea\u30f3\u30b0\u305b\u305a\u306b\u3001\u884c\u306e\u982d \u304b\u3089 \uff18\u5272\u5206 \u3092 \u5b66\u7fd2\u7528 \u306b\u3057\u305f\u305f\u3081\u3001\u30c7\u30fc\u30bf\u5206\u5e03\u306b\u504f\u308a\u304c\u3042\u308b \uff09\n* \u30d1\u30e9\u30e1\u30fc\u30bf\u5024 K \u306e\u5024 \u306f\u3001\u5b66\u7fd2\u7528\u30c7\u30fc\u30bf\u306b\u5b9a\u7fa9\u3055\u308c\u305f\u7279\u5fb4\u91cf\u306e\u6570\u4ee5\u4e0b \u3067\u306a\u3044\u3068\u3044\u3051\u306a\u3044\u3001\u3068\u30a8\u30e9\u30fc\u8868\u793a\u3055\u308c\u308b\u3002\n* iris\u30c7\u30fc\u30bf\u306e\u7279\u5fb4\u91cf\u306e\u6570\u306f\uff14\uff08Sepal.length\u7b49\uff09\u306a\u306e\u3067\u3001k \u306e \u30d1\u30e9\u30e1\u30fc\u30bf\u306e\u5024\u5019\u88dc\u7bc4\u56f2 \u3092 1\u301c4 \u306b\u3059\u308b\u3068\u3001\u30a8\u30e9\u30fc\u6d88\u3048\u305f\u3002\n\n```{python:Python3}\nfrom sklearn import svm\nfrom sklearn.grid_search import GridSearchCV\nfrom sklearn.pipeline import Pipeline\nimport sklearn.feature_selection as fs\nimport numpy\n\n\n#\n# \u4e00\u9023\u306e\u30b9\u30c6\u30c3\u30d7\u3092\u8a18\u8ff0\n#\npl = Pipeline([\n   ('feature_selection', fs.SelectKBest()),#\u6700\u9069\u306a\u6570\u6b21\u5143\u9078\u629e\n   ('classification', svm.SVC()) #\u5206\u985e\u5668\n])\n\nprint(pl)\n```\n\n\uff08 \u5b9f\u884c\u7d50\u679c \uff09\n\n```\nPipeline(steps=[('feature_selection', SelectKBest(k=10, score_func=<function f_classif at 0x1068fa950>)), ('classification', SVC(C=1.0, cache_size=200, class_weight=None, coef0=0.0,\n  decision_function_shape=None, degree=3, gamma='auto', kernel='rbf',\n  max_iter=-1, probability=False, random_state=None, shrinking=True,\n  tol=0.001, verbose=False))])\n```\n\n```{python:Python3}\nfrom sklearn import svm\nfrom sklearn.grid_search import GridSearchCV\nfrom sklearn.pipeline import Pipeline\nimport sklearn.feature_selection as fs\nimport numpy\n\n\n#\n# \u4e00\u9023\u306e\u30b9\u30c6\u30c3\u30d7\u3092\u8a18\u8ff0\n#\npl = Pipeline([\n   ('feature_selection', fs.SelectKBest()),#\u6700\u9069\u306a\u6570\u6b21\u5143\u9078\u629e\n   ('classification', svm.SVC()) #\u5206\u985e\u5668\n])\n\n#\n# __\u3092\u3064\u3051\u308b\u3053\u3068\u3067\u5404\u30b9\u30c6\u30c3\u30d7\u306e\u30b3\u30f3\u30b9\u30c8\u30e9\u30af\u30bf\u306b\u6e21\u3059\u30d1\u30e9\u30e1\u30fc\u30bf\u3092\u8a2d\u5b9a\u51fa\u6765\u308b\n#\nparameters = { \n   'feature_selection__k' : list(range(20, 39)), #\u6700\u9069\u306a20~39\u6b21\u5143\u9078\u629e\n   'classification__C': numpy.logspace(0, 4, 100).tolist(),  #C\u309210^0~10^4\u3067100\u5206\u5272\n   'classification__gamma': numpy.logspace(-3, 1, 100).tolist() #gamma\u309210^0~10^4\u3067100\u5206\u5272\n}\n\n#\u30b0\u30ea\u30c3\u30c9\u30b5\u30fc\u30c1\nclf = GridSearchCV(pl, parameters, n_jobs=-1)\nprint(clf)\n```\n\n\uff08 \u5b9f\u884c\u7d50\u679c \uff09\n\n```\nGridSearchCV(cv=None, error_score='raise',\n       estimator=Pipeline(steps=[('feature_selection', SelectKBest(k=10, score_func=<function f_classif at 0x1068fa950>)), ('classification', SVC(C=1.0, cache_size=200, class_weight=None, coef0=0.0,\n  decision_function_shape=None, degree=3, gamma='auto', kernel='rbf',\n  max_iter=-1, probability=False, random_state=None, shrinking=True,\n  tol=0.001, verbose=False))]),\n       fit_params={}, iid=True, n_jobs=-1,\n       param_grid={'feature_selection__k': [20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38], 'classification__gamma': [0.001, 0.0010974987654930556, 0.0012045035402587824, 0.0013219411484660286, 0.0014508287784959402, 0.0015922827933410922, 0.001747528400007683, 0.00191791026167...0.29144183426, 6892.612104349702, 7564.633275546291, 8302.175681319752, 9111.627561154895, 10000.0]},\n       pre_dispatch='2*n_jobs', refit=True, scoring=None, verbose=0)\n```\n\n\n```{python:Python3}\nfrom sklearn import datasets\n\niris = datasets.load_iris()\n\ntrain_X, train_Y = iris.data[:0.8*len(iris.data)], iris.target[:0.8*len(iris.target)]\nprint(len(train_X), len(train_Y))\n```\n\n```\n120 120\n/Users/hirofumi.yashima/anaconda/lib/python3.5/site-packages/ipykernel/__main__.py:5: DeprecationWarning: using a non-integer number instead of an integer will result in an error in the future\n```\n\n\n```{python:Python3}\nclf.fit(train_X, train_Y)\n```\n\n####__\u5b9f\u884c\u30a8\u30e9\u30fc__\n\n```\n---------------------------------------------------------------------------\nRemoteTraceback                           Traceback (most recent call last)\nRemoteTraceback: \n\"\"\"\nTraceback (most recent call last):\n  File \"/Users/hirofumi.yashima/anaconda/lib/python3.5/site-packages/sklearn/externals/joblib/parallel.py\", line 130, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/hirofumi.yashima/anaconda/lib/python3.5/site-packages/sklearn/externals/joblib/parallel.py\", line 72, in __call__\n    return [func(*args, **kwargs) for func, args, kwargs in self.items]\n  File \"/Users/hirofumi.yashima/anaconda/lib/python3.5/site-packages/sklearn/externals/joblib/parallel.py\", line 72, in <listcomp>\n    return [func(*args, **kwargs) for func, args, kwargs in self.items]\n  File \"/Users/hirofumi.yashima/anaconda/lib/python3.5/site-packages/sklearn/cross_validation.py\", line 1531, in _fit_and_score\n    estimator.fit(X_train, y_train, **fit_params)\n  File \"/Users/hirofumi.yashima/anaconda/lib/python3.5/site-packages/sklearn/pipeline.py\", line 164, in fit\n    Xt, fit_params = self._pre_transform(X, y, **fit_params)\n  File \"/Users/hirofumi.yashima/anaconda/lib/python3.5/site-packages/sklearn/pipeline.py\", line 145, in _pre_transform\n    Xt = transform.fit_transform(Xt, y, **fit_params_steps[name])\n\n\n\t\uff08 \u4e2d\u7565 \uff09\n\t\n\t\n    332         self.scores_ = np.asarray(self.scores_)\n    333         self.pvalues_ = np.asarray(self.pvalues_)\n\n...........................................................................\n/Users/hirofumi.yashima/anaconda/lib/python3.5/site-packages/sklearn/feature_selection/univariate_selection.py in _check_params(self=SelectKBest(k=20, score_func=<function f_classif at 0x1068fa950>), X=array([[ 5.1,  3.5,  1.4,  0.3],\n       [ 5.7,  ...6,  6.9,  2.3],\n       [ 6. ,  2.2,  5. ,  1.5]]), y=array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,...1, 2, 2, 2,\n       2, 2, 2, 2, 2, 2, 2, 2, 2, 2]))\n    455 \n    456     def _check_params(self, X, y):\n    457         if not (self.k == \"all\" or 0 <= self.k <= X.shape[1]):\n    458             raise ValueError(\"k should be >=0, <= n_features; got %r.\"\n    459                              \"Use k='all' to return all features.\"\n--> 460                              % self.k)\n        self.k = 20\n    461 \n    462     def _get_support_mask(self):\n    463         check_is_fitted(self, 'scores_')\n    464 \n\nValueError: k should be >=0, <= n_features; got 20.Use k='all' to return all features.\n___________________________________________________________________________\n```\n\n\n__# ValueError: k should be >=0, <= n_features; got 20.Use k='all' to return all features. __\n__ \u3068 \u8868\u793a\u3055\u308c\u305f \u306e\u3067\u3001__\n__k \u306e\u5024 \u3092 iris\u30c7\u30fc\u30bf\u30bb\u30c3\u30c8\u306e\u7279\u5fb4\u91cf\uff08\uff1d\uff14\uff09\u4ee5\u4e0b\u306e\u7bc4\u56f2\u3067\u3001\uff11\u301c\uff14\u306e\u7bc4\u56f2\u3067\u5019\u88dc\u6307\u5b9a\u3059\u308b__\n\n\n```{python:Python3}\n# ValueError: k should be >=0, <= n_features; got 20.Use k='all' to return all features. \n# \u3068\u8868\u793a\u3055\u308c\u305f\u306e\u3067\u3001\n# k \u306e\u5024 \u3092 iris\u30c7\u30fc\u30bf\u30bb\u30c3\u30c8\u306e\u7279\u5fb4\u91cf\uff08\uff1d\uff14\uff09\u4ee5\u4e0b\u306e\u7bc4\u56f2\u3067\u3001\uff11\u301c\uff14\u306e\u7bc4\u56f2\u3067\u5019\u88dc\u6307\u5b9a\u3059\u308b\n\nfrom sklearn import svm\nfrom sklearn.grid_search import GridSearchCV\nfrom sklearn.pipeline import Pipeline\nimport sklearn.feature_selection as fs\nimport numpy\n\n\npl = Pipeline([\n   ('feature_selection', fs.SelectKBest()),#\u6700\u9069\u306a\u6570\u6b21\u5143\u9078\u629e\n   ('classification', svm.SVC()) #\u5206\u985e\u5668\n])\n\n\nparameters = {\n   'feature_selection__k' : list(range(1, 4)), #\u6700\u9069\u306a1~4\u6b21\u5143\u9078\u629e\n   'classification__C': numpy.logspace(0, 4, 100).tolist(),  #C\u309210^0~10^4\u3067100\u5206\u5272\n   'classification__gamma': numpy.logspace(-3, 1, 100).tolist() #gamma\u309210^0~10^4\u3067100\u5206\u5272\n}\n\nclf = GridSearchCV(pl, parameters, n_jobs=-1)\nprint(clf)\n```\n\n```\nGridSearchCV(cv=None, error_score='raise',\n       estimator=Pipeline(steps=[('feature_selection', SelectKBest(k=10, score_func=<function f_classif at 0x1068fa950>)), ('classification', SVC(C=1.0, cache_size=200, class_weight=None, coef0=0.0,\n  decision_function_shape=None, degree=3, gamma='auto', kernel='rbf',\n  max_iter=-1, probability=False, random_state=None, shrinking=True,\n  tol=0.001, verbose=False))]),\n       fit_params={}, iid=True, n_jobs=-1,\n       param_grid={'feature_selection__k': [1, 2, 3], 'classification__gamma': [0.001, 0.0010974987654930556, 0.0012045035402587824, 0.0013219411484660286, 0.0014508287784959402, 0.0015922827933410922, 0.001747528400007683, 0.0019179102616724887, 0.00210490414451202, 0.0023101297000831605, 0.00253536449397...0.29144183426, 6892.612104349702, 7564.633275546291, 8302.175681319752, 9111.627561154895, 10000.0]},\n       pre_dispatch='2*n_jobs', refit=True, scoring=None, verbose=0)\nIn [6]:\n```\n\n```{python:Python3}\nclf.fit(train_X, train_Y)\n```\n\n\uff08 \u5b9f\u884c\u7d50\u679c \uff09\n\n```\nGridSearchCV(cv=None, error_score='raise',\n       estimator=Pipeline(steps=[('feature_selection', SelectKBest(k=10, score_func=<function f_classif at 0x1068fa950>)), ('classification', SVC(C=1.0, cache_size=200, class_weight=None, coef0=0.0,\n  decision_function_shape=None, degree=3, gamma='auto', kernel='rbf',\n  max_iter=-1, probability=False, random_state=None, shrinking=True,\n  tol=0.001, verbose=False))]),\n       fit_params={}, iid=True, n_jobs=-1,\n       param_grid={'feature_selection__k': [1, 2, 3], 'classification__gamma': [0.001, 0.0010974987654930556, 0.0012045035402587824, 0.0013219411484660286, 0.0014508287784959402, 0.0015922827933410922, 0.001747528400007683, 0.0019179102616724887, 0.00210490414451202, 0.0023101297000831605, 0.00253536449397...0.29144183426, 6892.612104349702, 7564.633275546291, 8302.175681319752, 9111.627561154895, 10000.0]},\n       pre_dispatch='2*n_jobs', refit=True, scoring=None, verbose=0)\n```\n\n\n```{python:Python3}\nprint(\"clf.best_estimator_\\n\", \"------------------------\\n\", clf.best_estimator_)\nprint(\"===========================================\")\nprint(\"clf.best_estimator_.get_params()\\n\", \"------------------------\\n\", clf.best_estimator_.get_params())\n```\n\n```\nclf.best_estimator_\n ------------------------\n Pipeline(steps=[('feature_selection', SelectKBest(k=3, score_func=<function f_classif at 0x1068fa950>)), ('classification', SVC(C=1.0, cache_size=200, class_weight=None, coef0=0.0,\n  decision_function_shape=None, degree=3, gamma=0.1384886371393873,\n  kernel='rbf', max_iter=-1, probability=False, random_state=None,\n  shrinking=True, tol=0.001, verbose=False))])\n===========================================\nclf.best_estimator_.get_params()\n ------------------------\n {'feature_selection__score_func': <function f_classif at 0x1068fa950>, 'classification__cache_size': 200, 'classification__probability': False, 'classification__shrinking': True, 'classification__verbose': False, 'classification__degree': 3, 'classification__coef0': 0.0, 'classification__decision_function_shape': None, 'classification__max_iter': -1, 'classification__random_state': None, 'feature_selection': SelectKBest(k=3, score_func=<function f_classif at 0x1068fa950>), 'feature_selection__k': 3, 'classification__kernel': 'rbf', 'steps': [('feature_selection', SelectKBest(k=3, score_func=<function f_classif at 0x1068fa950>)), ('classification', SVC(C=1.0, cache_size=200, class_weight=None, coef0=0.0,\n  decision_function_shape=None, degree=3, gamma=0.1384886371393873,\n  kernel='rbf', max_iter=-1, probability=False, random_state=None,\n  shrinking=True, tol=0.001, verbose=False))], 'classification': SVC(C=1.0, cache_size=200, class_weight=None, coef0=0.0,\n  decision_function_shape=None, degree=3, gamma=0.1384886371393873,\n  kernel='rbf', max_iter=-1, probability=False, random_state=None,\n  shrinking=True, tol=0.001, verbose=False), 'classification__C': 1.0, 'classification__tol': 0.001, 'classification__gamma': 0.1384886371393873, 'classification__class_weight': None}\n```\n\n\n<img width=\"1220\" alt=\"\u30b9\u30af\u30ea\u30fc\u30f3\u30b7\u30e7\u30c3\u30c8 2016-03-25 19.31.22.png\" src=\"https://qiita-image-store.s3.amazonaws.com/0/43487/b5c425cd-a13e-7e9a-e69b-ca579e62327e.png\">\n<img width=\"1224\" alt=\"\u30b9\u30af\u30ea\u30fc\u30f3\u30b7\u30e7\u30c3\u30c8 2016-03-25 19.31.33.png\" src=\"https://qiita-image-store.s3.amazonaws.com/0/43487/92d98d8b-d38a-b2ae-0ce8-114b1aaf19d9.png\">\n<img width=\"1220\" alt=\"\u30b9\u30af\u30ea\u30fc\u30f3\u30b7\u30e7\u30c3\u30c8 2016-03-25 19.31.47.png\" src=\"https://qiita-image-store.s3.amazonaws.com/0/43487/acde3c88-4657-7d01-5faf-81988d867c17.png\">\n<img width=\"1220\" alt=\"\u30b9\u30af\u30ea\u30fc\u30f3\u30b7\u30e7\u30c3\u30c8 2016-03-25 19.32.05.png\" src=\"https://qiita-image-store.s3.amazonaws.com/0/43487/db2303f7-999e-309a-ba06-b8c1d77cb4a0.png\">\n<img width=\"1224\" alt=\"\u30b9\u30af\u30ea\u30fc\u30f3\u30b7\u30e7\u30c3\u30c8 2016-03-25 19.32.25.png\" src=\"https://qiita-image-store.s3.amazonaws.com/0/43487/1f56354b-ff1e-7b87-028a-e4ab7b5e56cf.png\">\n<img width=\"1223\" alt=\"\u30b9\u30af\u30ea\u30fc\u30f3\u30b7\u30e7\u30c3\u30c8 2016-03-25 19.32.39.png\" src=\"https://qiita-image-store.s3.amazonaws.com/0/43487/36fd6b67-8210-4bed-2e10-e5f13fab0f5b.png\">\n<img width=\"1231\" alt=\"\u30b9\u30af\u30ea\u30fc\u30f3\u30b7\u30e7\u30c3\u30c8 2016-03-25 19.34.54.png\" src=\"https://qiita-image-store.s3.amazonaws.com/0/43487/6509f705-1a5a-2124-aff0-fe56d83cf952.png\">\n\nGridSearch \u304c \u767a\u898b\u3057\u305f\u6700\u9069\u306a\u30d1\u30e9\u30e1\u30fc\u30bf\u306e\u7d44\u307f\u5408\u308f\u305b \u306f\u3001\u4ee5\u4e0b\u306b\u306a\u3063\u305f\u3002\n\n```{python:Python3}\nchosen_parameters_dict = clf.best_estimator_.get_params()\nprint(\"feature_selection__k : \", chosen_parameters_dict[\"feature_selection__k\"])\nprint(\"classification__C : \", chosen_parameters_dict[\"classification__C\"])\nprint(\"classification__gamma : \", chosen_parameters_dict[\"classification__gamma\"])\n````\n\n```\nfeature_selection__k :  3\nclassification__C :  1.0\nclassification__gamma :  0.1384886371393873\n```\n\n<img width=\"1225\" alt=\"\u30b9\u30af\u30ea\u30fc\u30f3\u30b7\u30e7\u30c3\u30c8 2016-03-25 19.35.04.png\" src=\"https://qiita-image-store.s3.amazonaws.com/0/43487/4eff22da-baf9-126d-6544-a22878e1ccf5.png\">\n\n\n__\uff08\u8ffd\u8a18\uff09__\n\n```{python:Python3}\nprint(clf.best_score_)\n```\n\n```\n0.983333333333\n```\n\n<img width=\"1060\" alt=\"\u30b9\u30af\u30ea\u30fc\u30f3\u30b7\u30e7\u30c3\u30c8 2016-03-28 12.31.59.png\" src=\"https://qiita-image-store.s3.amazonaws.com/0/43487/a69ae366-fe2d-3518-f6e2-75bd77ed1c2f.png\">\n\n\n###__\u65b0\u898f\uff08\u691c\u8a3c\u7528\uff09\u30c7\u30fc\u30bf \u306e \u30e9\u30d9\u30eb\u4e88\u6e2c__\n\n* __\u691c\u8a3c\u7528\u30c7\u30fc\u30bf \u3092 \u7528\u610f__\n\n```{python:Python3}\ntest_X  = iris.data[0.8*len(iris.data): ]\n```\n\n\uff08 \u5b9f\u884c\u7d50\u679c \uff09\n\n```\n/Users/hirofumi.yashima/anaconda/lib/python3.5/site-packages/ipykernel/__main__.py:1: DeprecationWarning: using a non-integer number instead of an integer will result in an error in the future\n  if __name__ == '__main__':\n```\n\n```{python:Python3}\nprint(len(test_X))\n# 30\n```\n\n\n* __\u691c\u8a3c\u7528\u30c7\u30fc\u30bf \u306e \u30e9\u30d9\u30eb \u3092 \u63a8\u5b9a__\n\n```{python:Python3}\n#\u4e88\u6e2c\nclf.predict(test_X)\n```\n\n\uff08 \u5b9f\u884c\u7d50\u679c \uff09\n\n```\narray([2, 2, 2, 1, 2, 2, 1, 1, 2, 2, 2, 2, 2, 1, 2, 2, 2, 2, 1, 2, 2, 2, 2,\n       2, 2, 2, 2, 2, 2, 2])\n```\n\n####__\u6b63\u89e3\u7387\uff08\u6b63\u8aa4\u8868\uff09 \u3092 \u96c6\u8a08__\n\n\n* __\uff08 \u3053\u306e\u5148\u3001\u4ee5\u4e0b\u306e\u30a6\u30a7\u30d6\u30b5\u30a4\u30c8\u3092\u53c2\u8003\u306b\u3057\u307e\u3057\u305f \uff09__\n\n___\n\n* [Jamie A Dean, Liam C Welsh\u307b\u304b, _Predictive Modelling of Toxicity Resulting from Radiotherapy Treatments of Head and Neck Cancer_, PROC. OF THE 7th EUR. CONF. ON PYTHON IN SCIENCE (EUROSCIPY 2014)](http://arxiv.org/pdf/1412.6399.pdf)\n* [\u306e\u3093\u3073\u308a\u3057\u3066\u3044\u308b\u30a8\u30f3\u30b8\u30cb\u30a2\u306e\u65e5\u8a18 \uff082014/08/07\uff09\u300cSklearn\u3092\u4f7f\u3063\u305f\u6a5f\u68b0\u5b66\u7fd2\u300d](http://nonbiri-tereka.hatenablog.com/entry/2014/08/07/100152)\n* [\u552f\u7269\u662f\u771f @Scaled_Wurm \uff082013/05/25\uff09 \u300cpython\u306e\u6a5f\u68b0\u5b66\u7fd2\u30e9\u30a4\u30d6\u30e9\u30eascikit-learn\u306e\u7d39\u4ecb\u300d](http://sucrose.hatenablog.com/entry/2013/05/25/133021)\n* [Hatena Blog \u4eba\u5de5\u77e5\u80fd\u306b\u95a2\u3059\u308b\u65ad\u5275\u9332 \uff082015/08/26\uff09 \u300cMachine Learning with Scikit Learn (Part II)\u300d](http://aidiary.hatenablog.com/entry/20150826/1440596779)\n\n>__Classification Report__\n>\n>8.19.1.5. sklearn.metrics.classification_report \u2014 scikit-learn 0.13.1 documentation\n>\n>\u3053\u306e\u95a2\u6570\u306fPrecision\u3001Recall\u3068F\u5024\u3068support(\u6b63\u89e3\u30e9\u30d9\u30eb\u306e\u30c7\u30fc\u30bf\u306e\u6570)\u3092\u6559\u3048\u3066\u304f\u308c\u307e\u3059\n>Precision\u3001Recall\u3001F\u5024\u306f\u8a55\u4fa1\u306b\u975e\u5e38\u306b\u3088\u304f\u4f7f\u308f\u308c\u3066\u3044\u307e\u3059\u3002\n>Precision\u3001Recall\u3001F\u5024\u306e\u8aac\u660e\u306b\u3064\u3044\u3066\u306f\u4ee5\u4e0b\u306eURL\u3092\u53c2\u7167\n\n___\n\n\n```{python:Python3}\nfrom sklearn.metrics import classification_report\n\ny_true = iris.target[0.8*len(iris.data): ]\ny_pred = clf.predict(test_X)\n\nprint(classification_report(y_true, y_pred))\n```\n\n\uff08 \u5b9f\u884c\u7d50\u679c \uff09\n\n```\n             precision    recall  f1-score   support\n\n          1       0.00      0.00      0.00         0\n          2       1.00      0.83      0.91        30\n\navg / total       1.00      0.83      0.91        30\n\n/Users/hirofumi.yashima/anaconda/lib/python3.5/site-packages/ipykernel/__main__.py:3: DeprecationWarning: using a non-integer number instead of an integer will result in an error in the future\n  app.launch_new_instance()\n/Users/hirofumi.yashima/anaconda/lib/python3.5/site-packages/sklearn/metrics/classification.py:1076: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples.\n  'recall', 'true', average, warn_for)\n```\n\n\n```{python:Python3}\nprint(y_true)\n```\n\n\uff08 \u5b9f\u884c\u7d50\u679c \uff09\n\n```\n[2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2]\n```\n\n```{python:Python3}\nprint(y_pred)\n```\n\n\uff08 \u5b9f\u884c\u7d50\u679c \uff09\n\n```\n[2 2 2 1 2 2 1 1 2 2 2 2 2 1 2 2 2 2 1 2 2 2 2 2 2 2 2 2 2 2]\n```\n\n<img width=\"1226\" alt=\"\u30b9\u30af\u30ea\u30fc\u30f3\u30b7\u30e7\u30c3\u30c8 2016-03-25 19.47.46.png\" src=\"https://qiita-image-store.s3.amazonaws.com/0/43487/64b0140f-dffb-ac7e-11fc-8b7909b62a50.png\">\n<img width=\"1225\" alt=\"\u30b9\u30af\u30ea\u30fc\u30f3\u30b7\u30e7\u30c3\u30c8 2016-03-25 19.47.57.png\" src=\"https://qiita-image-store.s3.amazonaws.com/0/43487/a4ced744-1f51-92f1-f6ad-ffd7d0664a4a.png\">\n<img width=\"1226\" alt=\"\u30b9\u30af\u30ea\u30fc\u30f3\u30b7\u30e7\u30c3\u30c8 2016-03-25 20.17.47.png\" src=\"https://qiita-image-store.s3.amazonaws.com/0/43487/d90d679f-9ae1-0846-0af3-d09da69557d5.png\">\n\n```{python:Python3}\nfrom sklearn.metrics import precision_recall_score_support\np, r, f, s = precision_recall_fscore_support(y_true, y_pred, beta=0.5)\n\nprint(p)\n# [ 0.  1.]\n\nprint(r)\n# [ 0.          0.83333333]\n\nprint(f)\n# [ 0.          0.96153846]\n\nprint(s)\n# [ 0 30]\n```\n\n<img width=\"1202\" alt=\"\u30b9\u30af\u30ea\u30fc\u30f3\u30b7\u30e7\u30c3\u30c8 2016-03-28 16.45.26.png\" src=\"https://qiita-image-store.s3.amazonaws.com/0/43487/083f954b-7297-06f7-4d5e-a85f7fdc16d0.png\">\n\n___\n\n####__GridSeasrchCV \u3067 \u6700\u9069\u30d1\u30e9\u30e1\u30fc\u30bf\u7d44\u307f\u5408\u308f\u305b\u3092\u63a2\u7d22\u3059\u308b\u3068\u304d\u306b\u3001scoring='rco_auc' \u306b\u3057\u3066\u3082\u3001\u7d50\u679c\u306f\u540c\u3058\u306b\u306a\u3063\u305f\u3002__\n\n```{python:Python3}\n#\u30b0\u30ea\u30c3\u30c9\u30b5\u30fc\u30c1\nclf2 = GridSearchCV(pl, parameters, n_jobs=-1, scoring='roc_auc')\n```\n\n```{python:Python3}\nprint(clf2)\n```\n\n* __scoring='roc_auc' \u306b\u306a\u3063\u3066\u3044\u308b__\n\n```\nGridSearchCV(cv=None, error_score='raise',\n       estimator=Pipeline(steps=[('feature_selection', SelectKBest(k=10, score_func=<function f_classif at 0x106938950>)), ('classification', SVC(C=1.0, cache_size=200, class_weight=None, coef0=0.0,\n  decision_function_shape=None, degree=3, gamma='auto', kernel='rbf',\n  max_iter=-1, probability=False, random_state=None, shrinking=True,\n  tol=0.001, verbose=False))]),\n       fit_params={}, iid=True, n_jobs=-1,\n       param_grid={'classification__gamma': [0.001, 0.0010974987654930556, 0.0012045035402587824, 0.0013219411484660286, 0.0014508287784959402, 0.0015922827933410922, 0.001747528400007683, 0.0019179102616724887, 0.00210490414451202, 0.0023101297000831605, 0.0025353644939701114, 0.0027825594022071257, 0.003...564.633275546291, 8302.175681319752, 9111.627561154895, 10000.0], 'feature_selection__k': [1, 2, 3]},\n       pre_dispatch='2*n_jobs', refit=True, scoring='roc_auc', verbose=0)\n```\n\n\n```{python:Python3}\nclf2.fit(train_X, train_Y)\n\nchosen_parameters_dict2 = clf2.best_estimator_.get_params()\nprint(\"feature_selection__k : \", chosen_parameters_dict2[\"feature_selection__k\"])\nprint(\"classification__C : \", chosen_parameters_dict2[\"classification__C\"])\nprint(\"classification__gamma : \", chosen_parameters_dict2[\"classification__gamma\"])\n```\n\n```{python:Python3}\nprint(\"clf.best_estimator_\\n\", \"------------------------\\n\", clf.best_estimator_)\nprint(\"===========================================\")\nprint(\"clf.best_estimator_.get_params()\\n\", \"------------------------\\n\", clf.best_estimator_.get_params())\n``` \n\n___\n\n##__\u3010 \u305d\u306e\u4ed6\u3001\u53c2\u8003 \u3011__\n\n\n\n\u8a18\u4e8b\u4e2d\u3001\u53c2\u8003\u30a6\u30a7\u30d6\u30b5\u30a4\u30c8\u3068\u3057\u3066\u7d39\u4ecb\u3055\u305b\u3066\u9802\u3044\u305f\u4ee5\u4e0b\u306e\u30a6\u30a7\u30d6\u30b5\u30a4\u30c8\u3067\u306f\u3001\nGridSearchCV \u304b\u3089\u3001\u691c\u51fa\u3055\u308c\u305f\u6700\u826f\u306a\u30d1\u30e9\u30e1\u30fc\u30bf\u7d44\u307f\u5408\u308f\u305b\u3068\u3001\u6700\u3082\u826f\u304f\u306a\u3044\u30d1\u30e9\u30e1\u30fc\u30bf\u7d44\u307f\u5408\u308f\u305b\u3092\u53d6\u308a\u51fa\u3057\u3066\u3001\u305d\u308c\u305e\u308c\u306e\u30d1\u30e9\u30e1\u30fc\u30bf\u306e\u4e0b\u3067\u306e\u5206\u985e\u7d50\u679c\u3092\u3001\u6b63\u89e3\u30c7\u30fc\u30bf\u3068\u3042\u308f\u305b\u3066\u3001\u30b0\u30e9\u30d5\u51fa\u529b\u3057\u3066\u3044\u307e\u3059\u3002\n\n* [My Life as a Mock Quant \uff082013-08-25\uff09 \u300cscikit-learn\u3067\u30b5\u30dd\u30fc\u30c8\u30d9\u30af\u30c8\u30eb\u56de\u5e30\u3001\u53ca\u3073\u305d\u306e\u30d1\u30e9\u30e1\u30fc\u30bf\u30fc\u63a8\u8a08 with \u30af\u30ed\u30b9\u30d0\u30ea\u30c7\u30fc\u30b7\u30e7\u30f3\u3084\u3063\u3066\u307f\u308b\u300d](http://d.hatena.ne.jp/teramonagi/20130825/1377434479)\n\n\uff08\u4ee5\u4e0b\u3001\u540c\u30b5\u30a4\u30c8\u304b\u3089\u305d\u306e\u90e8\u5206\u306e\u30b3\u30fc\u30c9\u3092\u8ee2\u8f09\uff09\n\u4f46\u3057\u3001\u4ee5\u4e0b\u306e\u30b3\u30e1\u30f3\u30c8\u90e8\u5206\u306f\u3001\u672c\u8a18\u4e8b\u6295\u7a3f\u8005\u306b\u3088\u308b\n\n```\n# \u6b63\u3057\u304f\u306f\u3001reg_max \uff1f\n```\n\n\n>\u30b3\u30fc\u30c9\u306f\u2193\u306a\u611f\u3058\u3002\u4e00\u756a\u30b9\u30b3\u30a2\u306e\u826f\u3044\u30e2\u30c7\u30eb\u306f\n>\n>best_estimator_\n>\u3068\u3044\u3046\u30d7\u30ed\u30d1\u30c6\u30a3\u306b\u683c\u7d0d\u3055\u308c\u3066\u3044\u308b\u306e\u3067\u7c21\u5358\u306b\u53d6\u5f97\u3067\u304d\u308b\u304c\u3001\uff08\u666e\u901a\u306f\u7528\u9014\u306e\u306a\u3044\uff09\u4e00\u756a\u30b9\u30b3\u30a2\u306e\u60aa\u3044\u30e2\u30c7\u30eb\u3092\u51fa\u3059\u306e\u306b\u82e6\u52b4\u3057\u305f\u3002\n>\n>\n>```{python:Python}\n>from sklearn.grid_search import GridSearchCV\n>#RBF\u30ab\u30fc\u30cd\u30eb\u306e\u30d1\u30e9\u30e1\u30fc\u30bf\u30fc\u03b3\u3068\u7f70\u5247C\u3092\u8907\u6570\u500b\u4f5c\u3063\u3066\u305d\u306e\u4e2d\u3067(\u30b9\u30b3\u30a2\u306e\u610f\u5473\u3067\uff09\u826f\u3044\u7269\u3092\u63a2\u7d22(\u30ab\u30fc\u30cd\u30eb\u3082\u30d1\u30e9\u30e1\u30fc\u30bf\u30fc\u3068\u3057\u3066\u4f7f\u7528\u53ef\u80fd)\n>tuned_parameters = [{'kernel': ['rbf'], 'gamma': [10**i for i in range(-4,0)], 'C': [10**i for i in range(1,4)]}]\n>gscv = GridSearchCV(svm.SVR(), tuned_parameters, cv=5, scoring=\"mean_squared_error\")\n>gscv.fit(x_train, y_train)\n>\n>#\u4e00\u756a\u30b9\u30b3\u30a2\u60aa\u3044&\u826f\u3044\u5974\u3092\u51fa\u3059\n>params_min,_,_ = gscv.grid_scores_[np.argmin([x[1] for x in gscv.grid_scores_])]\n>reg_min = svm.SVR(kernel=params_min['kernel'], C=params_min['C'], gamma=params_min['gamma'])\n>reg_max = gscv.best_estimator_\n>\n>#\u5168\u30c8\u30ec\u30fc\u30cb\u30f3\u30b0\u30c7\u30fc\u30bf\u3092\u4f7f\u3063\u3066\u518d\u63a8\u8a08\n>reg_min.fit(x_train, y_train)\n>reg_min.fit(x_train, y_train) # \u6b63\u3057\u304f\u306f\u3001reg_max \uff1f\n>\n>#\u6b63\u7b54(\u9752)\uff06\u826f\u3044(\u8d64)\uff06\u60aa\u3044(\u7dd1)\u306e\u7d50\u679c\u3092PLOT\n>plt.plot(x_test, y_test, 'bo-',x_test, reg_max.predict(x_test), 'ro-',x_test, reg_min.predict(x_test), 'go-')\n>plt.show()\n>```\n>\n", "tags": ["Python", "python3", "MachineLearning", "\u6a5f\u68b0\u5b66\u7fd2", "sklearn"]}