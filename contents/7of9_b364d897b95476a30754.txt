{"context": "\n\u52d5\u4f5c\u74b0\u5883\nGeForce GTX 1070 (8GB)\nASRock Z170M Pro4S [Intel Z170chipset]\nUbuntu 14.04 LTS desktop amd64\nTensorFlow v0.11\ncuDNN v5.1 for Linux\nCUDA v8.0\nPython 2.7.6\nIPython 5.1.0 -- An enhanced Interactive Python.\n\n\nsine curve\u3092\u8fd1\u4f3c\u3059\u308b\u3002\n\n\u30c7\u30fc\u30bf\u751f\u6210\u90e8\n\u4ed6\u306e\u95a2\u6570\u3092\u8fd1\u4f3c\u3059\u308b\u4e88\u5b9a\u306a\u306e\u3067\u3001\u30c7\u30fc\u30bf\u306f\u5225\u306e\u30b3\u30fc\u30c9\u3067\u751f\u6210\u3059\u308b\u3002\n\nprep_data.py\nimport numpy as np\nimport random\n\nnumdata=100\nx_data = np.random.rand(numdata)\ny_data = np.sin(2*np.pi*x_data) + 0.3 * np.random.rand()\n\nfor xs, ys in zip(x_data, y_data):\n    print '%.5f, %.5f' % (xs, ys)\n\n\n\ncsv\u30d5\u30a1\u30a4\u30eb\n$python prep_data.py > input.csv\n\ninput.csv(\u4f8b)\n0.74597, -0.91122\n0.33339, 0.95432\n0.03281, 0.29314\n0.49378, 0.12754\n0.59515, -0.47443\n0.19094, 1.02040\n0.04446, 0.36420\n0.02983, 0.27479\n...\n\n\n\n\u5b66\u7fd2\u30b3\u30fc\u30c9\n\u53c2\u8003\u3000http://qiita.com/learn_tensorflow/items/3e46b2512a1bab73f5b2\n\u4e0a\u8a18\u306etrain.py\u3092\u30d9\u30fc\u30b9\u3068\u3057\u305f\u3002\n\u4ee5\u4e0b\u306e\u5909\u66f4\u3092\u3057\u3066\u3044\u308b\u3002\n\ninput.csv\u306e\u5f62\u5f0f\u3092\u5909\u66f4\nhiddens\u306e\u5b9a\u7fa9\u3092[2,2]\u304b\u3089[1,7,7,7]\u306b\u5909\u66f4\nprint\u66f8\u5f0f\u3092\u5909\u66f4\n\n\nlinreg2.py\n#!/usr/bin/env python\n# -*- coding: utf-8 -*-\n\nimport tensorflow as tf\nimport tensorflow.contrib.slim as slim\n\n# \u30d5\u30a1\u30a4\u30eb\u540d\u306e Queue \u3092\u4f5c\u6210\nfilename_queue = tf.train.string_input_producer([\"input.csv\"])\n\n# CSV \u3092 parse\nreader = tf.TextLineReader()\nkey, value = reader.read(filename_queue)\ninput1, output = tf.decode_csv(value, record_defaults=[[0.], [0.]])\ninputs = tf.pack([input1])\noutput = tf.pack([output])\n\n# 4\u30b5\u30f3\u30d7\u30eb\u6bce\u306e Batch \u5316\ninputs_batch, output_batch = tf.train.shuffle_batch([inputs, output], 4, capacity=40, min_after_dequeue=4)\n\n## NN \u306e\u30b0\u30e9\u30d5\u751f\u6210\nhiddens = slim.stack(inputs_batch, slim.fully_connected, [1,7,7,7], \n  activation_fn=tf.nn.sigmoid, scope=\"hidden\")\nprediction = slim.fully_connected(hiddens, 1, activation_fn=tf.nn.sigmoid, scope=\"output\")\n\nloss = tf.contrib.losses.mean_squared_error(prediction, output_batch)\ntrain_op = slim.learning.create_train_op(loss, tf.train.AdamOptimizer(0.01))\n\ninit_op = tf.initialize_all_variables()\n\nwith tf.Session() as sess:\n  coord = tf.train.Coordinator()\n  threads = tf.train.start_queue_runners(sess=sess, coord=coord)\n\n  try:\n    sess.run(init_op)\n    for i in range(10000):\n      _, t_loss = sess.run([train_op, loss])\n      if (i+1) % 100 == 0:\n        print(\"%d,%f\" % (i+1, t_loss)) #step, loss\n  finally:\n    coord.request_stop()\n\n  coord.join(threads)\n\n\n$ python linreg2.py\n...\n8200 0.197571 #step, loss\n8300 0.197723 #step, loss\n8400 0.369575 #step, loss\n8500 0.014792 #step, loss\n8600 0.115452 #step, loss\n8700 0.013261 #step, loss\n8800 0.078891 #step, loss\n8900 0.350682 #step, loss\n9000 0.349131 #step, loss\n9100 0.167577 #step, loss\n9200 0.141080 #step, loss\n9300 0.211734 #step, loss\n9400 0.413739 #step, loss\n9500 0.133878 #step, loss\n9600 0.293956 #step, loss\n9700 0.449871 #step, loss\n9800 0.355519 #step, loss\n9900 0.020344 #step, loss\n10000 0.198887 #step, loss\n\n\nloss for step\n$python linreg2.py > log.learn\n%matplotlib inline\n\nimport numpy as np\nimport matplotlib.pyplot as plt\n\ndata = np.loadtxt('log.learn', delimiter=',')\ninput1 = data[:,0]\noutput = data[:,1]\n\nfig = plt.figure()\nax = fig.add_subplot(1,1,1)\n\nx = np.linspace(-6,6,1000)\n\nax.plot(input1, output, color='black', linestyle='solid')\n\nax.set_title('loss')\nax.set_xlabel('step')\nax.set_ylabel('loss')\nax.grid(True)\nfig.show()\n\n\n\u53ce\u675f\u3059\u308b\u6c17\u914d\u304c\u306a\u3044\u3002\n\u30cd\u30c3\u30c8\u306e\u5b9a\u7fa9\u306a\u3069\u691c\u8a0e\u8ab2\u984c\u306f\u591a\u3044\u3002\n```txt:\u52d5\u4f5c\u74b0\u5883\nGeForce GTX 1070 (8GB)\nASRock Z170M Pro4S [Intel Z170chipset]\nUbuntu 14.04 LTS desktop amd64\nTensorFlow v0.11\ncuDNN v5.1 for Linux\nCUDA v8.0\nPython 2.7.6\nIPython 5.1.0 -- An enhanced Interactive Python.\n```\n\nsine curve\u3092\u8fd1\u4f3c\u3059\u308b\u3002\n\n\n### \u30c7\u30fc\u30bf\u751f\u6210\u90e8\n\n\u4ed6\u306e\u95a2\u6570\u3092\u8fd1\u4f3c\u3059\u308b\u4e88\u5b9a\u306a\u306e\u3067\u3001\u30c7\u30fc\u30bf\u306f\u5225\u306e\u30b3\u30fc\u30c9\u3067\u751f\u6210\u3059\u308b\u3002\n\n```prep_data.py\nimport numpy as np\nimport random\n\nnumdata=100\nx_data = np.random.rand(numdata)\ny_data = np.sin(2*np.pi*x_data) + 0.3 * np.random.rand()\n\nfor xs, ys in zip(x_data, y_data):\n\tprint '%.5f, %.5f' % (xs, ys)\n```\n\n### csv\u30d5\u30a1\u30a4\u30eb\n\n`$python prep_data.py > input.csv`\n\n```input.csv(\u4f8b)\n0.74597, -0.91122\n0.33339, 0.95432\n0.03281, 0.29314\n0.49378, 0.12754\n0.59515, -0.47443\n0.19094, 1.02040\n0.04446, 0.36420\n0.02983, 0.27479\n...\n```\n\n\n### \u5b66\u7fd2\u30b3\u30fc\u30c9\n\n\u53c2\u8003\u3000http://qiita.com/learn_tensorflow/items/3e46b2512a1bab73f5b2\n\n\u4e0a\u8a18\u306etrain.py\u3092\u30d9\u30fc\u30b9\u3068\u3057\u305f\u3002\n\n\u4ee5\u4e0b\u306e\u5909\u66f4\u3092\u3057\u3066\u3044\u308b\u3002\n\n- input.csv\u306e\u5f62\u5f0f\u3092\u5909\u66f4\n- hiddens\u306e\u5b9a\u7fa9\u3092[2,2]\u304b\u3089[1,7,7,7]\u306b\u5909\u66f4\n- print\u66f8\u5f0f\u3092\u5909\u66f4\n\n```linreg2.py\n#!/usr/bin/env python\n# -*- coding: utf-8 -*-\n\nimport tensorflow as tf\nimport tensorflow.contrib.slim as slim\n\n# \u30d5\u30a1\u30a4\u30eb\u540d\u306e Queue \u3092\u4f5c\u6210\nfilename_queue = tf.train.string_input_producer([\"input.csv\"])\n\n# CSV \u3092 parse\nreader = tf.TextLineReader()\nkey, value = reader.read(filename_queue)\ninput1, output = tf.decode_csv(value, record_defaults=[[0.], [0.]])\ninputs = tf.pack([input1])\noutput = tf.pack([output])\n\n# 4\u30b5\u30f3\u30d7\u30eb\u6bce\u306e Batch \u5316\ninputs_batch, output_batch = tf.train.shuffle_batch([inputs, output], 4, capacity=40, min_after_dequeue=4)\n\n## NN \u306e\u30b0\u30e9\u30d5\u751f\u6210\nhiddens = slim.stack(inputs_batch, slim.fully_connected, [1,7,7,7], \n  activation_fn=tf.nn.sigmoid, scope=\"hidden\")\nprediction = slim.fully_connected(hiddens, 1, activation_fn=tf.nn.sigmoid, scope=\"output\")\n\nloss = tf.contrib.losses.mean_squared_error(prediction, output_batch)\ntrain_op = slim.learning.create_train_op(loss, tf.train.AdamOptimizer(0.01))\n\ninit_op = tf.initialize_all_variables()\n\nwith tf.Session() as sess:\n  coord = tf.train.Coordinator()\n  threads = tf.train.start_queue_runners(sess=sess, coord=coord)\n\n  try:\n    sess.run(init_op)\n    for i in range(10000):\n      _, t_loss = sess.run([train_op, loss])\n      if (i+1) % 100 == 0:\n        print(\"%d,%f\" % (i+1, t_loss)) #step, loss\n  finally:\n    coord.request_stop()\n\n  coord.join(threads)\n```\n\n```\n$ python linreg2.py\n...\n8200 0.197571 #step, loss\n8300 0.197723 #step, loss\n8400 0.369575 #step, loss\n8500 0.014792 #step, loss\n8600 0.115452 #step, loss\n8700 0.013261 #step, loss\n8800 0.078891 #step, loss\n8900 0.350682 #step, loss\n9000 0.349131 #step, loss\n9100 0.167577 #step, loss\n9200 0.141080 #step, loss\n9300 0.211734 #step, loss\n9400 0.413739 #step, loss\n9500 0.133878 #step, loss\n9600 0.293956 #step, loss\n9700 0.449871 #step, loss\n9800 0.355519 #step, loss\n9900 0.020344 #step, loss\n10000 0.198887 #step, loss\n```\n\n### loss for step\n\n`$python linreg2.py > log.learn`\n\n```py\n%matplotlib inline\n\nimport numpy as np\nimport matplotlib.pyplot as plt\n\ndata = np.loadtxt('log.learn', delimiter=',')\ninput1 = data[:,0]\noutput = data[:,1]\n\nfig = plt.figure()\nax = fig.add_subplot(1,1,1)\n\nx = np.linspace(-6,6,1000)\n\nax.plot(input1, output, color='black', linestyle='solid')\n\nax.set_title('loss')\nax.set_xlabel('step')\nax.set_ylabel('loss')\nax.grid(True)\nfig.show()\n```\n\n![qiita.png](https://qiita-image-store.s3.amazonaws.com/0/32870/324eadb6-2a31-7f6c-883a-f214bb937764.png)\n\n\u53ce\u675f\u3059\u308b\u6c17\u914d\u304c\u306a\u3044\u3002\n\u30cd\u30c3\u30c8\u306e\u5b9a\u7fa9\u306a\u3069\u691c\u8a0e\u8ab2\u984c\u306f\u591a\u3044\u3002\n\n", "tags": ["TensorFlow", "regression", "borgWarp", "Primer"]}