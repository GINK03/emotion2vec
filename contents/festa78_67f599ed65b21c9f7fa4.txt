{"context": "Variational Information Maximizing Exploration\n\u30b9\u30b1\u30fc\u30e9\u30d6\u30eb\u304b\u3064\u52b9\u7387\u7684\u306a\u63a2\u7d22\u306freinforcement learning\u306b\u304a\u3044\u3066\u91cd\u8981\u3067\u3042\u308b\u3002\n\u3057\u304b\u3057\u5f93\u6765\u624b\u6cd5\u306f\u03b5 greedy\u3084gauss\u30ce\u30a4\u30ba\u306e\u4ed8\u4e0e\u306a\u3069\u3001\u30d2\u30e5\u30fc\u30ea\u30b9\u30c6\u30a3\u30af\u30b9\u306b\u983c\u3063\u3066\u3044\u308b\u3002\n\u672c\u8ad6\u3067\u63d0\u6848\u3059\u308b\u624b\u6cd5\u306f\u3001agent\u3068\u306e\u74b0\u5883\u306b\u5bfe\u3059\u308bbelief\u306e\u60c5\u5831\u5229\u5f97\u3092\u6700\u5927\u5316\u3055\u305b\u308b\u3088\u3046\u306a\u63a2\u7d22\u3092\u884c\u3046\u3002\n\u3053\u308c\u306f\u5f93\u6765curiosity\u3084surprise\u3068\u547c\u3070\u308c\u308b\u6982\u5ff5\u3067\u3001\u74b0\u5883\u306euncertainty\u3092\u6700\u3082\u6e1b\u5c11\u3055\u305b\u308b\uff08\u60c5\u5831\u5229\u5f97\u6700\u5927\uff09\u3088\u3046\u306a\u72b6\u614b\u3092\u9078\u629e\u3057\u3066\u3044\u304f\u3002\n\u3053\u306e\u60c5\u5831\u5229\u5f97\u306f\u30d9\u30a4\u30b8\u30a2\u30f3NN\u306b\u95a2\u3059\u308b\u5909\u5206\u63a8\u8ad6\u306b\u3088\u308a\u89e3\u304f\u3002\n\u3053\u306e\u624b\u6cd5\u306freinforcement learning\u306e\u624b\u6cd5\u306b\u5e83\u304f\u9069\u7528\u53ef\u80fd\u3067\u3042\u308b\u3002\nGuided Policy Search, ICML2013\nReinforcement learning\u306b\u304a\u3044\u3066\u76f4\u63a5policy\u95a2\u6570\u3092\u6700\u9069\u5316\u3059\u308bDirect policy search\uff08\u4f8b\u3048\u3070policy gradient\uff09\u306f\u9ad8\u6b21\u5143\u306e\u30b7\u30b9\u30c6\u30e0\u306b\u5bfe\u3057\u3066\u3082\u30b9\u30b1\u30fc\u30eb\u3059\u308b\u624b\u6cd5\u3067\u3042\u308b\u304c\u3001\u4f55\u767e\u3082\u306e\u30d1\u30e9\u30e1\u30fc\u30bf\u304c\u5b58\u5728\u3059\u308b\u3088\u3046\u306a\u8907\u96d1\u306a\u30dd\u30ea\u30b7\u30fc\u306b\u5bfe\u3057\u3066\u5b66\u7fd2\u3092\u884c\u3046\u4e8b\u306f\u96e3\u3057\u304f\u3001\u5c40\u6240\u89e3\u306b\u9665\u308a\u3084\u3059\u3044\u3002\n\u672c\u8ad6\u3067\u306f\u3001trajectory optimization\u3092\u7528\u3044\u308b\u4e8b\u3067\u5c40\u6240\u89e3\u3092\u56de\u907f\u3059\u308b\u624b\u6cd5\u3092\u63d0\u6848\u3059\u308b\u3002\n\u3053\u306e\u624b\u6cd5\u306f\uff12\u6b21\u5fae\u5206\u307e\u3067\u3092\u7528\u3044\u308bdifferential dynamic programming\u306e\u8003\u3048\u65b9\u3092\u7528\u3044\u308b\u4e8b\u3067\u3001\u5b66\u7fd2\u306b\u6700\u9069\u306a\u30b5\u30f3\u30d7\u30eb\uff08guided sample\uff09\u3092\u751f\u6210\u3059\u308b\u3002\n\u3053\u308c\u3089\u306e\u30b5\u30f3\u30d7\u30eb\u3092\u7528\u3044\u305f\u5b66\u7fd2\u3092\u884c\u3046\u4e8b\u3067\u6700\u9069\u5316\u6027\u80fd\u3092\u6539\u5584\u53ef\u80fd\u3067\u3042\u308b\u3002\nFLAG: Fast Linearly-Coupled Adaptive Gradient Method\nNesterov\u2019s accelerated gradient method\u306f\uff11\u6b21\u30aa\u30fc\u30c0\u30fc\u306b\u304a\u3044\u3066\u6700\u9069\u306acomplexity\u3092\u7dad\u6301\u53ef\u80fd\u3067\u3001\u901a\u5e38\u306egradient descent\u3068\u6bd4\u8f03\u3057\u3066\u9ad8\u901f\u5316\u304c\u53ef\u80fd\u306a\u624b\u6cd5\u3067\u3042\u308b\u3002\n\u4e00\u65b9\u3067\u826f\u3044regularizer\u3068\u3057\u3066mirror descent\u3068\u53cc\u74a7\u3092\u306a\u3059AdaGrad\u306f\u3001gradient\u3092\u9069\u5fdc\u7684\u30ea\u30b9\u30b1\u30fc\u30eb\u3092\u884c\u3046\u3002\n\u6700\u8fd1\u306b\u304a\u3044\u3066\u306f\u3001accelerated gradient\u306fgradient descent\u3068mirror descent\u306e\u7dda\u5f62\u548c\u3068\u307f\u306a\u305b\u308b\u4e8b\u304c\u308f\u304b\u3063\u3066\u304d\u305f\u3002\n\u3053\u306e\u4e8b\u5b9f\u306b\u6ce8\u76ee\u3057\u3001\u672c\u8ad6\u3067\u306faccelerated\u3055\u308c\u305fAdaGrad\u3092\u63d0\u6848\u3059\u308b\u3002\n\u3053\u306e\u624b\u6cd5\u306fT iteration\u306b\u5bfe\u3057\u30661/T^2\u306e\u53ce\u675f\u30ec\u30fc\u30c8\u3092\u5b9f\u73fe\u53ef\u80fd\u3067\u3042\u308b\u3002\n\n[Variational Information Maximizing Exploration](https://arxiv.org/pdf/1605.09674.pdf)\n\u30b9\u30b1\u30fc\u30e9\u30d6\u30eb\u304b\u3064\u52b9\u7387\u7684\u306a\u63a2\u7d22\u306freinforcement learning\u306b\u304a\u3044\u3066\u91cd\u8981\u3067\u3042\u308b\u3002\n\u3057\u304b\u3057\u5f93\u6765\u624b\u6cd5\u306f\u03b5 greedy\u3084gauss\u30ce\u30a4\u30ba\u306e\u4ed8\u4e0e\u306a\u3069\u3001\u30d2\u30e5\u30fc\u30ea\u30b9\u30c6\u30a3\u30af\u30b9\u306b\u983c\u3063\u3066\u3044\u308b\u3002\n\u672c\u8ad6\u3067\u63d0\u6848\u3059\u308b\u624b\u6cd5\u306f\u3001agent\u3068\u306e\u74b0\u5883\u306b\u5bfe\u3059\u308bbelief\u306e\u60c5\u5831\u5229\u5f97\u3092\u6700\u5927\u5316\u3055\u305b\u308b\u3088\u3046\u306a\u63a2\u7d22\u3092\u884c\u3046\u3002\n\u3053\u308c\u306f\u5f93\u6765curiosity\u3084surprise\u3068\u547c\u3070\u308c\u308b\u6982\u5ff5\u3067\u3001\u74b0\u5883\u306euncertainty\u3092\u6700\u3082\u6e1b\u5c11\u3055\u305b\u308b\uff08\u60c5\u5831\u5229\u5f97\u6700\u5927\uff09\u3088\u3046\u306a\u72b6\u614b\u3092\u9078\u629e\u3057\u3066\u3044\u304f\u3002\n\u3053\u306e\u60c5\u5831\u5229\u5f97\u306f\u30d9\u30a4\u30b8\u30a2\u30f3NN\u306b\u95a2\u3059\u308b\u5909\u5206\u63a8\u8ad6\u306b\u3088\u308a\u89e3\u304f\u3002\n\u3053\u306e\u624b\u6cd5\u306freinforcement learning\u306e\u624b\u6cd5\u306b\u5e83\u304f\u9069\u7528\u53ef\u80fd\u3067\u3042\u308b\u3002\n\n[Guided Policy Search](https://graphics.stanford.edu/projects/gpspaper/gps_full.pdf), ICML2013\nReinforcement learning\u306b\u304a\u3044\u3066\u76f4\u63a5policy\u95a2\u6570\u3092\u6700\u9069\u5316\u3059\u308bDirect policy search\uff08\u4f8b\u3048\u3070policy gradient\uff09\u306f\u9ad8\u6b21\u5143\u306e\u30b7\u30b9\u30c6\u30e0\u306b\u5bfe\u3057\u3066\u3082\u30b9\u30b1\u30fc\u30eb\u3059\u308b\u624b\u6cd5\u3067\u3042\u308b\u304c\u3001\u4f55\u767e\u3082\u306e\u30d1\u30e9\u30e1\u30fc\u30bf\u304c\u5b58\u5728\u3059\u308b\u3088\u3046\u306a\u8907\u96d1\u306a\u30dd\u30ea\u30b7\u30fc\u306b\u5bfe\u3057\u3066\u5b66\u7fd2\u3092\u884c\u3046\u4e8b\u306f\u96e3\u3057\u304f\u3001\u5c40\u6240\u89e3\u306b\u9665\u308a\u3084\u3059\u3044\u3002\n\u672c\u8ad6\u3067\u306f\u3001trajectory optimization\u3092\u7528\u3044\u308b\u4e8b\u3067\u5c40\u6240\u89e3\u3092\u56de\u907f\u3059\u308b\u624b\u6cd5\u3092\u63d0\u6848\u3059\u308b\u3002\n\u3053\u306e\u624b\u6cd5\u306f\uff12\u6b21\u5fae\u5206\u307e\u3067\u3092\u7528\u3044\u308bdifferential dynamic programming\u306e\u8003\u3048\u65b9\u3092\u7528\u3044\u308b\u4e8b\u3067\u3001\u5b66\u7fd2\u306b\u6700\u9069\u306a\u30b5\u30f3\u30d7\u30eb\uff08guided sample\uff09\u3092\u751f\u6210\u3059\u308b\u3002\n\u3053\u308c\u3089\u306e\u30b5\u30f3\u30d7\u30eb\u3092\u7528\u3044\u305f\u5b66\u7fd2\u3092\u884c\u3046\u4e8b\u3067\u6700\u9069\u5316\u6027\u80fd\u3092\u6539\u5584\u53ef\u80fd\u3067\u3042\u308b\u3002\n\n[FLAG: Fast Linearly-Coupled Adaptive Gradient Method](https://arxiv.org/pdf/1605.08108.pdf)\nNesterov\u2019s accelerated gradient method\u306f\uff11\u6b21\u30aa\u30fc\u30c0\u30fc\u306b\u304a\u3044\u3066\u6700\u9069\u306acomplexity\u3092\u7dad\u6301\u53ef\u80fd\u3067\u3001\u901a\u5e38\u306egradient descent\u3068\u6bd4\u8f03\u3057\u3066\u9ad8\u901f\u5316\u304c\u53ef\u80fd\u306a\u624b\u6cd5\u3067\u3042\u308b\u3002\n\u4e00\u65b9\u3067\u826f\u3044regularizer\u3068\u3057\u3066mirror descent\u3068\u53cc\u74a7\u3092\u306a\u3059AdaGrad\u306f\u3001gradient\u3092\u9069\u5fdc\u7684\u30ea\u30b9\u30b1\u30fc\u30eb\u3092\u884c\u3046\u3002\n\u6700\u8fd1\u306b\u304a\u3044\u3066\u306f\u3001accelerated gradient\u306fgradient descent\u3068mirror descent\u306e\u7dda\u5f62\u548c\u3068\u307f\u306a\u305b\u308b\u4e8b\u304c\u308f\u304b\u3063\u3066\u304d\u305f\u3002\n\u3053\u306e\u4e8b\u5b9f\u306b\u6ce8\u76ee\u3057\u3001\u672c\u8ad6\u3067\u306faccelerated\u3055\u308c\u305fAdaGrad\u3092\u63d0\u6848\u3059\u308b\u3002\n\u3053\u306e\u624b\u6cd5\u306fT iteration\u306b\u5bfe\u3057\u30661/T^2\u306e\u53ce\u675f\u30ec\u30fc\u30c8\u3092\u5b9f\u73fe\u53ef\u80fd\u3067\u3042\u308b\u3002\n", "tags": ["\u8ad6\u6587\u8aad\u307f", "\u6a5f\u68b0\u5b66\u7fd2", "MachineLearning"]}