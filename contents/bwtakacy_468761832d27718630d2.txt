{"tags": ["hadoop", "Kerberos"], "context": "\u524d\u56de\u306e\u300cKerberos\u30a4\u30f3\u30b9\u30c8\u30fc\u30eb\u624b\u9806\u300d\u306e\u7d9a\u304d\u3002\n\u5f53\u521d\u306e\u76ee\u7684\u3067\u3042\u308bHadoop\u306eKerberos\u5316\u3092\u884c\u3046\u624b\u9806\u3092\u6574\u7406\u3059\u308b\u3002\n\nHadoop\u306e\u30a4\u30f3\u30b9\u30c8\u30fc\u30eb\n\u904e\u53bb\u8a18\u4e8b\u53c2\u7167\u3002\n\u4eca\u56de\u5229\u7528\u3059\u308b\u306e\u306fCDH5.6.0\u3002\n\nJCE Policy\u306e\u30a4\u30f3\u30b9\u30c8\u30fc\u30eb\nAES\u6697\u53f7\u5316\u3092Java\u304b\u3089\u5229\u7528\u3059\u308b\u305f\u3081\u306b\u3001Java Cryptography Extension (JCE) Unlimited Strength Jurisdiction Policy Files\u3092Oracle\u304b\u3089\u30c0\u30a6\u30f3\u30ed\u30fc\u30c9\u3057\u3066\u30a4\u30f3\u30b9\u30c8\u30fc\u30eb\u3059\u308b\u3002\n\u30a4\u30f3\u30b9\u30c8\u30fc\u30eb\u65b9\u6cd5\u306f\u6dfb\u4ed8\u306eREADME.txt\u306b\u5f93\u3046\u3002\n# cd UnlimitedJCEPolicyJDK8-2/\n# ls\nREADME.txt  US_export_policy.jar  local_policy.jar\n# ll /usr/java/latest/jre/lib/security/\n\u5408\u8a08 152\n-rw-r--r-- 1 root root  2920  1\u6708 30 11:00 US_export_policy.jar\n-rw-r--r-- 1 root root  4054  1\u6708 30 10:49 blacklist\n-rw-r--r-- 1 root root  1273  1\u6708 30 10:49 blacklisted.certs\n-rw-r--r-- 1 root root 99954  1\u6708 30 10:49 cacerts\n-rw-r--r-- 1 root root  2466  1\u6708 30 10:49 java.policy\n-rw-r--r-- 1 root root 26224  1\u6708 30 10:49 java.security\n-rw-r--r-- 1 root root    98  1\u6708 30 10:49 javaws.policy\n-rw-r--r-- 1 root root  3405  1\u6708 30 11:00 local_policy.jar\n-rw-r--r-- 1 root root     0  1\u6708 30 10:49 trusted.libraries\n# mkdir default_jars\n# mv /usr/java/latest/jre/lib/security/*.jar default_jars/\n# cp *.jar /usr/java/latest/jre/lib/security/\n# ll /usr/java/latest/jre/lib/security/\n\u5408\u8a08 152\n-rw-r--r-- 1 root root  3023  3\u6708 17 00:52 US_export_policy.jar\n-rw-r--r-- 1 root root  4054  1\u6708 30 10:49 blacklist\n-rw-r--r-- 1 root root  1273  1\u6708 30 10:49 blacklisted.certs\n-rw-r--r-- 1 root root 99954  1\u6708 30 10:49 cacerts\n-rw-r--r-- 1 root root  2466  1\u6708 30 10:49 java.policy\n-rw-r--r-- 1 root root 26224  1\u6708 30 10:49 java.security\n-rw-r--r-- 1 root root    98  1\u6708 30 10:49 javaws.policy\n-rw-r--r-- 1 root root  3035  3\u6708 17 00:52 local_policy.jar\n-rw-r--r-- 1 root root     0  1\u6708 30 10:49 trusted.libraries\n\n\nHadoop\u30d7\u30ed\u30bb\u30b9\u5411\u3051\u306eKerberos\u30d7\u30ea\u30f3\u30b7\u30d1\u30eb\u306e\u4f5c\u6210\n\u5fc5\u8981\u306a\u306e\u306f\u3001hdfs/[FQDN], mapred/[FQDN], yarn/[FQDN], HTTP/[FQDN]\u3002\n\u4eca\u56de\u306f\u64ec\u4f3c\u5206\u6563\u74b0\u5883\u306a\u306e\u3067\u305d\u308c\u305e\u308c1\u3064\u305a\u3064\u3060\u304c\u3001\u5b8c\u5168\u5206\u6563\u74b0\u5883\u3060\u3068\u30b5\u30fc\u30d0\u6bce\u306b1\u3064\u305a\u3064\u4f5c\u6210\u3059\u308b\u5fc5\u8981\u304c\u3042\u308b\u3002\n# kadmin.local \nAuthenticating as principal root/admin@EXAMPLE.COM with password.\nkadmin.local:  addprinc -randkey hdfs/locke.example.com@EXAMPLE.COM\nWARNING: no policy specified for hdfs/locke.example.com@EXAMPLE.COM; defaulting to no policy\nPrincipal \"hdfs/locke.example.com@EXAMPLE.COM\" created.\nkadmin.local:  addprinc -randkey mapred/locke.example.com@EXAMPLE.COM\nWARNING: no policy specified for mapred/locke.example.com@EXAMPLE.COM; defaulting to no policy\nPrincipal \"mapred/locke.example.com@EXAMPLE.COM\" created.\nkadmin.local:  addprinc -randkey yarn/locke.example.com@EXAMPLE.COM\nWARNING: no policy specified for yarn/locke.example.com@EXAMPLE.COM; defaulting to no policy\nPrincipal \"yarn/locke.example.com@EXAMPLE.COM\" created.\nkadmin.local:  addprinc -randkey HTTP/locke.example.com@EXAMPLE.COM\nWARNING: no policy specified for HTTP/locke.example.com@EXAMPLE.COM; defaulting to no policy\nPrincipal \"HTTP/locke.example.com@EXAMPLE.COM\" created.\nkadmin.local:  listprincs \nHTTP/locke.example.com@EXAMPLE.COM\nK/M@EXAMPLE.COM\nalice/locke.example.com@EXAMPLE.COM\nhdfs/locke.example.com@EXAMPLE.COM\nkadmin/admin@EXAMPLE.COM\nkadmin/changepw@EXAMPLE.COM\nkadmin/locke.example.com@EXAMPLE.COM\nkiprop/locke.example.com@EXAMPLE.COM\nkrbtgt/EXAMPLE.COM@EXAMPLE.COM\nmapred/locke.example.com@EXAMPLE.COM\nyarn/locke.example.com@EXAMPLE.COM\n\n\nKeytab\u30d5\u30a1\u30a4\u30eb\u306e\u4f5c\u6210\n\u5404Hadoop\u30d7\u30ed\u30bb\u30b9\u306e\u8a8d\u8a3c\u7528\u306ekeytab\u30d5\u30a1\u30a4\u30eb\u3092\u4f5c\u6210\u3059\u308b\u3002\u3053\u308c\u307e\u305f\u30b5\u30fc\u30d0\u500b\u5225\u306b\u30d5\u30a1\u30a4\u30eb\u3092\u4f5c\u6210\u3059\u308b\u5fc5\u8981\u304c\u3042\u308b\u3002\u4eca\u56de\u306f\u64ec\u4f3c\u5206\u6563\u306a\u306e\u30671\u3064\u305a\u3064\u3067OK\u3002\nkadmin.local:  ktadd -norandkey -k hdfs.keytab hdfs/locke.example.com@EXAMPLE.COM HTTP/locke.example.com@EXAMPLE.COM\nEntry for principal hdfs/locke.example.com@EXAMPLE.COM with kvno 1, encryption type aes256-cts-hmac-sha1-96 added to keytab WRFILE:hdfs.keytab.\nEntry for principal hdfs/locke.example.com@EXAMPLE.COM with kvno 1, encryption type aes128-cts-hmac-sha1-96 added to keytab WRFILE:hdfs.keytab.\nEntry for principal hdfs/locke.example.com@EXAMPLE.COM with kvno 1, encryption type arcfour-hmac added to keytab WRFILE:hdfs.keytab.\nEntry for principal HTTP/locke.example.com@EXAMPLE.COM with kvno 1, encryption type aes256-cts-hmac-sha1-96 added to keytab WRFILE:hdfs.keytab.\nEntry for principal HTTP/locke.example.com@EXAMPLE.COM with kvno 1, encryption type aes128-cts-hmac-sha1-96 added to keytab WRFILE:hdfs.keytab.\nEntry for principal HTTP/locke.example.com@EXAMPLE.COM with kvno 1, encryption type arcfour-hmac added to keytab WRFILE:hdfs.keytab.\nkadmin.local:  ktadd -norandkey -k mapred.keytab mapred/locke.example.com@EXAMPLE.COM HTTP/locke.example.com@EXAMPLE.COM\nEntry for principal mapred/locke.example.com@EXAMPLE.COM with kvno 1, encryption type aes256-cts-hmac-sha1-96 added to keytab WRFILE:mapred.keytab.\nEntry for principal mapred/locke.example.com@EXAMPLE.COM with kvno 1, encryption type aes128-cts-hmac-sha1-96 added to keytab WRFILE:mapred.keytab.\nEntry for principal mapred/locke.example.com@EXAMPLE.COM with kvno 1, encryption type arcfour-hmac added to keytab WRFILE:mapred.keytab.\nEntry for principal HTTP/locke.example.com@EXAMPLE.COM with kvno 1, encryption type aes256-cts-hmac-sha1-96 added to keytab WRFILE:mapred.keytab.\nEntry for principal HTTP/locke.example.com@EXAMPLE.COM with kvno 1, encryption type aes128-cts-hmac-sha1-96 added to keytab WRFILE:mapred.keytab.\nEntry for principal HTTP/locke.example.com@EXAMPLE.COM with kvno 1, encryption type arcfour-hmac added to keytab WRFILE:mapred.keytab.\nkadmin.local:  ktadd -norandkey -k yarn.keytab yarn/locke.example.com@EXAMPLE.COM HTTP/locke.example.com@EXAMPLE.COM\nEntry for principal yarn/locke.example.com@EXAMPLE.COM with kvno 1, encryption type aes256-cts-hmac-sha1-96 added to keytab WRFILE:yarn.keytab.\nEntry for principal yarn/locke.example.com@EXAMPLE.COM with kvno 1, encryption type aes128-cts-hmac-sha1-96 added to keytab WRFILE:yarn.keytab.\nEntry for principal yarn/locke.example.com@EXAMPLE.COM with kvno 1, encryption type arcfour-hmac added to keytab WRFILE:yarn.keytab.\nEntry for principal HTTP/locke.example.com@EXAMPLE.COM with kvno 1, encryption type aes256-cts-hmac-sha1-96 added to keytab WRFILE:yarn.keytab.\nEntry for principal HTTP/locke.example.com@EXAMPLE.COM with kvno 1, encryption type aes128-cts-hmac-sha1-96 added to keytab WRFILE:yarn.keytab.\nEntry for principal HTTP/locke.example.com@EXAMPLE.COM with kvno 1, encryption type arcfour-hmac added to keytab WRFILE:yarn.keytab.\n\n\nKeytab\u30d5\u30a1\u30a4\u30eb\u306e\u914d\u7f6e\n\u4f5c\u6210\u3057\u305fkeytab\u30d5\u30a1\u30a4\u30eb\u3092Hadoop\u306e\u8a2d\u5b9a\u30d5\u30a1\u30a4\u30eb\u3092\u914d\u7f6e\u3057\u305f\u30c7\u30a3\u30ec\u30af\u30c8\u30ea\u306b\u7f6e\u304f\u3002\n\u30d1\u30fc\u30df\u30c3\u30b7\u30e7\u30f3\u3092\u5404\u30e6\u30fc\u30b6\u5411\u3051\u306b\u3059\u308b\u3053\u3068\u3092\u5fd8\u308c\u306a\u3044\u3088\u3046\u306b\u3002\n# ls\nhdfs.keytab  mapred.keytab  yarn.keytab\n# cp * /etc/hadoop/conf/\n# chown hdfs:hadoop /etc/hadoop/conf/hdfs.keytab \n# chown mapred:hadoop /etc/hadoop/conf/mapred.keytab \n# chown yarn:hadoop /etc/hadoop/conf/yarn.keytab \n# ll /etc/hadoop/conf/\n\u5408\u8a08 52\n-rwxr-xr-x 1 root   root    1104 11\u6708 27 03:20 README\n-rwxr-xr-x 1 root   root    2133 11\u6708 27 03:20 core-site.xml\n-rwxr-xr-x 1 root   root    1366 11\u6708 27 03:20 hadoop-env.sh\n-rwxr-xr-x 1 root   root    2890 11\u6708 27 03:20 hadoop-metrics.properties\n-rwxr-xr-x 1 root   root    2324  1\u6708 29 15:08 hdfs-site.xml\n-rw------- 1 hdfs   hadoop   707  3\u6708 17 01:02 hdfs.keytab\n-rwxr-xr-x 1 root   root   11291  1\u6708 29 15:08 log4j.properties\n-rwxr-xr-x 1 root   root    1549 11\u6708 27 03:20 mapred-site.xml\n-rw------- 1 mapred hadoop   478  3\u6708 17 01:02 mapred.keytab\n-rwxr-xr-x 1 root   root    2375 11\u6708 27 03:20 yarn-site.xml\n-rw------- 1 yarn   hadoop   472  3\u6708 17 01:02 yarn.keytab\n\n\nHDFS\u306eKerberos\u5316\n\n\u8a2d\u5b9a\u30d5\u30a1\u30a4\u30eb\u306e\u5909\u66f4\n\u4ee5\u4e0b\u306e\u9805\u76ee\u3092\u8ffd\u52a0\u3059\u308b\u3002\n\ncore-site.xml\n  <!-- For Kerberos -->\n  <property>\n    <name>hadoop.security.authentication</name>\n    <value>kerberos</value> \n  </property>\n\n  <property>\n    <name>hadoop.security.authorization</name>\n    <value>true</value>\n  </property>\n\n\n\nhdfs-site.xml\n  <!-- For Kerberos -->\n  <!-- General HDFS security config -->\n  <property>\n    <name>dfs.block.access.token.enable</name>\n    <value>true</value>\n  </property>\n\n  <!-- NameNode security config -->\n  <property>\n    <name>dfs.namenode.keytab.file</name>\n    <value>/etc/hadoop/conf/hdfs.keytab</value> <!-- path to the HDFS keytab -->\n  </property>\n  <property>\n    <name>dfs.namenode.kerberos.principal</name>\n    <value>hdfs/_HOST@EXAMPLE.COM</value>\n  </property>\n  <property>\n    <name>dfs.namenode.kerberos.internal.spnego.principal</name>\n    <value>HTTP/_HOST@EXAMPLE.COM</value>\n  </property>\n\n  <!-- Secondary NameNode security config -->\n  <property>\n    <name>dfs.secondary.namenode.keytab.file</name>\n    <value>/etc/hadoop/conf/hdfs.keytab</value> <!-- path to the HDFS keytab -->\n  </property>\n  <property>\n    <name>dfs.secondary.namenode.kerberos.principal</name>\n    <value>hdfs/_HOST@EXAMPLE.COM</value>\n  </property>\n  <property>\n    <name>dfs.secondary.namenode.kerberos.internal.spnego.principal</name>\n    <value>HTTP/_HOST@EXAMPLE.COM</value>\n  </property>\n\n  <!-- DataNode security config -->\n  <property>\n    <name>dfs.datanode.data.dir.perm</name>\n    <value>700</value> \n  </property>\n  <property>\n    <name>dfs.datanode.address</name>\n    <value>0.0.0.0:1004</value>\n  </property>\n  <property>\n    <name>dfs.datanode.http.address</name>\n    <value>0.0.0.0:1006</value>\n  </property>\n  <property>\n    <name>dfs.datanode.keytab.file</name>\n    <value>/etc/hadoop/conf/hdfs.keytab</value> <!-- path to the HDFS keytab -->\n  </property>\n  <property>\n    <name>dfs.datanode.kerberos.principal</name>\n    <value>hdfs/_HOST@EXAMPLE.COM</value>\n  </property>\n\n  <!-- Web Authentication config -->\n  <property>\n    <name>dfs.web.authentication.kerberos.principal</name>\n    <value>HTTP/_HOST@EXAMPLE.COM</value>\n  </property>\n\n\n\u4eca\u56de\u306fSecondaryNameNode\u3092\u5229\u7528\u3057\u3066\u3044\u308b\u304c\u3001JournalNode\u3092\u4f7f\u3063\u3066\u3044\u308b\u5834\u5408\u306fJournalNode\u5411\u3051\u306e\u8a2d\u5b9a\u304c\u5fc5\u8981\u3068\u306a\u308b\u3002\u305d\u306e\u5834\u5408\u306f\u3001\u4ee5\u4e0b\u306e\u3088\u3046\u306a\u9805\u76ee\u3092\u6307\u5b9a\u3059\u308b\u3002\n<property>\n  <name>dfs.journalnode.keytab.file</name>\n  <value>/etc/hadoop/conf/hdfs.keytab</value> <!-- path to the HDFS keytab -->\n</property>\n<property>\n  <name>dfs.journalnode.kerberos.principal</name>\n  <value>hdfs/_HOST@EXAMPLE.COM</value>\n</property>\n<property>\n  <name>dfs.journalnode.kerberos.internal.spnego.principal</name>\n  <value>HTTP/_HOST@EXAMPLE.COM</value>\n</property>\n\n\nDataNode\u306e\u74b0\u5883\u5909\u6570\u306e\u8a2d\u5b9a\u5909\u66f4\n\u4ee5\u4e0b\u3092\u8a2d\u5b9a\u3059\u308b\u3002JSVC_HOME\u4ee5\u5916\u306f\u30b3\u30e1\u30f3\u30c8\u30a2\u30a6\u30c8\u3092\u5916\u3059\u3060\u3051\u3002\nexport HADOOP_SECURE_DN_USER=hdfs\nexport HADOOP_SECURE_DN_PID_DIR=/var/run/hadoop-hdfs\nexport HADOOP_SECURE_DN_LOG_DIR=/var/log/hadoop-hdfs\nexport JSVC_HOME=/usr/lib/bigtop-utils/\n\n\nNameNode\u306e\u8d77\u52d5\n\u6700\u521d\u306e\u95a2\u9580\u3067\u3042\u308b\u3002\n\u7948\u308a\u306a\u304c\u3089\u8d77\u52d5\u3059\u308b\u3002\n# systemctl start hadoop-hdfs-namenode.service\n# jps\n8053 Jps\n7976 NameNode\n\n\u5ff5\u306e\u305f\u3081\u30ed\u30b0\u3092\u898b\u3066Kerberos\u8a8d\u8a3c\u306b\u6210\u529f\u3057\u3066\u3044\u308b\u304b\u3069\u3046\u304b\u3092\u78ba\u8a8d\u3059\u308b\u3002\n2016-03-17 01:21:52,803 INFO org.apache.hadoop.security.UserGroupInformation: Login successful for user hdfs/locke.example.com@EXAMPLE.COM using keytab file /etc/hadoop/conf/hdfs.keytab\n\n\n\u3046\u307e\u304f\u3044\u304b\u306a\u3044\u6642\n\u60b2\u5287\u306e\u59cb\u307e\u308a\u3002\u4eca\u307e\u3067\u306e\u624b\u9806\u3067\u4f55\u304b\u3057\u3089\u9593\u9055\u3063\u3066\u3044\u308b\u3068\u3053\u308d\u304c\u3042\u308b\u306f\u305a\u306a\u306e\u3067\u3001\u771f\u646f\u306b\u632f\u308a\u8fd4\u308b\u3002SAN\u5024\u304c\u30e2\u30ea\u30e2\u30ea\u4e0b\u304c\u308b\u306e\u3067\u3001\u7cbe\u795e\u306e\u5b89\u5b9a\u3092\u56f3\u308b\u624b\u6bb5\u306f\u5fc5\u9808\u3067\u3042\u308b\u3002\n\u7b2c\u4e00\u6b69\u3068\u3057\u3066\u3001Java\u304b\u3089Kerberos\u5468\u308a\u306eDEBUG\u30ed\u30b0\u3092\u51fa\u3059\u3088\u3046\u306b\u3059\u308b\u3068\u826f\u304b\u3063\u305f\u3002\n\nhadoop-env.sh\nexport HADOOP_OPTS=\"-Dsun.security.krb5.debug=true -Djava.net.preferIPv4Stack=true $HADOOP_CLIENT_OPTS\"\n\n\n\u305d\u306e\u4ed6\u3001Cloudera\u306e\u30c9\u30ad\u30e5\u30e1\u30f3\u30c8\u306bFAQ\u7684\u306a\u60c5\u5831\u304c\u3042\u308b\u306e\u3067\u3001\u53c2\u8003\u306b\u3059\u308b\u3002\n\u81ea\u5206\u304c\u30cf\u30de\u3063\u305f\u70b9\u3092\u6319\u3052\u3066\u304a\u304f\u3068\n\nKerberos\u306e\u8a2d\u5b9a\u30df\u30b9(kdc.conf, krb.conf)\nJCE\u306e\u30a4\u30f3\u30b9\u30c8\u30fc\u30eb\u5fd8\u308c\nkeytab\u30d5\u30a1\u30a4\u30eb\u306e\u30d1\u30fc\u30df\u30c3\u30b7\u30e7\u30f3\u8a2d\u5b9a\u30df\u30b9\nkeytab\u30d5\u30a1\u30a4\u30eb\u306bHTTP\u30d7\u30ea\u30f3\u30b7\u30d1\u30eb\u3092\u5165\u308c\u5fd8\u308c\u3066\u3044\u308b\n\n\u3042\u305f\u308a\u3092\u5f15\u3044\u305f\u3002\n\nSecondaryNameNode\u306e\u8d77\u52d5\n# systemctl start hadoop-hdfs-secondarynamenode.service\n\n\nDataNode\u306e\u8d77\u52d5\n# systemctl start hadoop-hdfs-datanode.service\n\n\nhdfs\u30e6\u30fc\u30b6\u306b\u3088\u308b\u8d77\u52d5\u78ba\u8a8d\nhdfs\u30e6\u30fc\u30b6\u3067key tab\u3092\u4f7f\u3063\u3066\u8a8d\u8a3c\u3057\u3066\u3001hdfs\u30b3\u30de\u30f3\u30c9\u3092\u6253\u3063\u3066\u307f\u308b\u3002\n# su - hdfs\n-bash-4.2$ kinit hdfs/locke.example.com@EXAMPLE.COM -kt /etc/hadoop/conf/hdfs.keytab \n-bash-4.2$ klist -e\nTicket cache: FILE:/tmp/krb5cc_993\nDefault principal: hdfs/locke.example.com@EXAMPLE.COM\n\nValid starting       Expires              Service principal\n2016-03-17T02:42:54  2016-03-18T02:42:54  krbtgt/EXAMPLE.COM@EXAMPLE.COM\n    Etype (skey, tkt): aes256-cts-hmac-sha1-96, aes256-cts-hmac-sha1-96 \n-bash-4.2$ hdfs dfsadmin -report\nConfigured Capacity: 9082765312 (8.46 GB)\nPresent Capacity: 6496538624 (6.05 GB)\nDFS Remaining: 6496038912 (6.05 GB)\nDFS Used: 499712 (488 KB)\nDFS Used%: 0.01%\nUnder replicated blocks: 0\nBlocks with corrupt replicas: 0\nMissing blocks: 0\nMissing blocks (with replication factor 1): 0\n\n-------------------------------------------------\nLive datanodes (1):\n\nName: 192.168.56.101:1004 (locke.example.com)\nHostname: locke.example.com\nDecommission Status : Normal\nConfigured Capacity: 9082765312 (8.46 GB)\nDFS Used: 499712 (488 KB)\nNon DFS Used: 2586226688 (2.41 GB)\nDFS Remaining: 6496038912 (6.05 GB)\nDFS Used%: 0.01%\nDFS Remaining%: 71.52%\nConfigured Cache Capacity: 0 (0 B)\nCache Used: 0 (0 B)\nCache Remaining: 0 (0 B)\nCache Used%: 100.00%\nCache Remaining%: 0.00%\nXceivers: 2\nLast contact: Thu Mar 17 02:43:06 JST 2016\n\n\n-bash-4.2$ hdfs dfs -ls /\nFound 5 items\ndrwxrwxrwx   - hdfs  supergroup          0 2016-03-17 00:37 /benchmarks\ndrwxr-xr-x   - hbase supergroup          0 2016-03-17 00:37 /hbase\ndrwxrwxrwt   - hdfs  supergroup          0 2016-03-17 00:37 /tmp\ndrwxr-xr-x   - hdfs  supergroup          0 2016-03-17 00:38 /user\ndrwxr-xr-x   - hdfs  supergroup          0 2016-03-17 00:38 /var\n\n\nYARN\u306eKerberos\u5316\n\n\u8a2d\u5b9a\u30d5\u30a1\u30a4\u30eb\u306e\u5909\u66f4\n\nyarn-site.xml\n  <!-- For Kerberos -->\n  <!-- ResourceManager security configs -->\n  <property>\n    <name>yarn.resourcemanager.keytab</name>\n    <value>/etc/hadoop/conf/yarn.keytab</value>       <!-- path to the YARN keytab -->\n  </property>\n  <property>\n    <name>yarn.resourcemanager.principal</name>\n    <value>yarn/_HOST@EXAMPLE.COM</value>\n  </property>\n\n  <!-- NodeManager security configs -->\n  <property>\n    <name>yarn.nodemanager.keytab</name>\n    <value>/etc/hadoop/conf/yarn.keytab</value>       <!-- path to the YARN keytab -->\n  </property>\n  <property>\n    <name>yarn.nodemanager.principal</name>\n    <value>yarn/_HOST@EXAMPLE.COM</value>\n  </property>\n  <property>\n    <name>yarn.nodemanager.container-executor.class</name>\n    <value>org.apache.hadoop.yarn.server.nodemanager.LinuxContainerExecutor</value>\n  </property>\n  <property>\n    <name>yarn.nodemanager.linux-container-executor.group</name>\n    <value>yarn</value>\n  </property>\n\n\n\nmapped-site.xml\n  <!-- MapReduce Job History Server security configs -->\n  <property>\n    <name>mapreduce.jobhistory.address</name>\n    <value>locke.example.com:10020</value> <!-- Host and port of the MapReduce Job History Server; default port is 10020  -->\n  </property>\n  <property>\n    <name>mapreduce.jobhistory.keytab</name>\n    <value>/etc/hadoop/conf/mapred.keytab</value>     <!-- path to the MAPRED keytab for the Job History Server -->\n  </property>\n  <property>\n    <name>mapreduce.jobhistory.principal</name>\n    <value>mapred/_HOST@EXAMPLE.COM</value>\n  </property>\n\n\nContainerExecutor\u3092LinuxContainerExecutor\u306b\u8a2d\u5b9a\u3057\u3066\u3044\u308b\u306e\u3067\u3001container-executor.cfg\u3082\u5fc5\u8981\u3068\u306a\u308b\u3002\u8a2d\u5b9a\u5185\u5bb9\u306f\u3053\u3093\u306a\u611f\u3058\u3002\u74b0\u5883\u306b\u5408\u308f\u305b\u3066\u8a2d\u5b9a\u5024\u306f\u5909\u3048\u308b\u3002\n\ncontainer-executor.cfg\nyarn.nodemanager.local-dirs=/var/lib/hadoop-yarn/cache/yarn/nm-local-dir\nyarn.nodemanager.linux-container-executor.group=yarn\nyarn.nodemanager.log-dirs=/var/log/hadoop-yarn/containers\nbanned.users=hdfs,yarn,mapred,bin       \nmin.user.id=500\n\n\n\u6ce8\u610f\u3059\u308b\u70b9\u3068\u3057\u3066\u3001\u304d\u3082\u3044\u30d1\u30fc\u30df\u30c3\u30b7\u30e7\u30f3\u306b\u3059\u308b\u5fc5\u8981\u304c\u3042\u308b\u3002\n chown root:yarn /etc/hadoop/conf/container-executor.cfg \n# chmod 040 /etc/hadoop/conf/container-executor.cfg \n# chmod +s /etc/hadoop/conf/container-executor.cfg \n# ll /etc/hadoop/conf/container-executor.cfg \n---Sr-S--- 1 root yarn 241  3\u6708 17 02:59 /etc/hadoop/conf/container-executor.cfg\n\n\nYARN\u306e\u8d77\u52d5\n# systemctl start hadoop-yarn-resourcemanager.service\n# systemctl start hadoop-yarn-nodemanager.service\n\n\nyarn\u30e6\u30fc\u30b6\u306b\u3088\u308b\u78ba\u8a8d\n# su - yarn\n-bash-4.2$ kinit yarn/locke.example.com@EXAMPLE.COM -kt /etc/hadoop/conf/yarn.keytab \n-bash-4.2$ klist -e\nTicket cache: FILE:/tmp/krb5cc_992\nDefault principal: yarn/locke.example.com@EXAMPLE.COM\n\nValid starting       Expires              Service principal\n2016-03-17T03:06:40  2016-03-18T03:06:40  krbtgt/EXAMPLE.COM@EXAMPLE.COM\n    Etype (skey, tkt): aes256-cts-hmac-sha1-96, aes256-cts-hmac-sha1-96 \n-bash-4.2$ yarn node -list \n16/03/17 03:06:45 INFO client.RMProxy: Connecting to ResourceManager at /0.0.0.0:8032\nTotal Nodes:1\n         Node-Id         Node-State Node-Http-Address   Number-of-Running-Containers\nlocke.example.com:46070         RUNNING locke.example.com:8042                             0\n\n\nMapReduce JobHistoryServer\u306e\u8d77\u52d5\n# systemctl start hadoop-mapreduce-historyserver.service\n\n\nMapReduce\u30b8\u30e7\u30d6\u306e\u5b9f\u884c\u78ba\u8a8d\nalice\u30e6\u30fc\u30b6\u3067MapReduce\u30b8\u30e7\u30d6\u3092\u5b9f\u884c\u3057\u3066\u307f\u308b\u3002\u307e\u305a\u306fHDFS\u4e0a\u306b\u30e6\u30fc\u30b6\u30c7\u30a3\u30ec\u30af\u30c8\u30ea\u3092\u4f5c\u6210\u3059\u308b\u3002\n# su - hdfs\n-bash-4.2$ hdfs dfs -mkdir /user/alice\n-bash-4.2$ hdfs dfs -chown alice /user/alice\n\nalice\u30e6\u30fc\u30b6\u3067\u30b5\u30f3\u30d7\u30ebMapReduce\u3092\u5b9f\u884c\u3057\u3066\u307f\u308b\u3002\n# su - alice\n$ hadoop jar /usr/lib/hadoop-mapreduce/hadoop-mapreduce-examples-2.6.0-cdh5.6.0.jar pi 1 1000\nNumber of Maps  = 1\nSamples per Map = 1000\nWrote input for Map #0\nStarting Job\n16/03/17 03:10:55 INFO client.RMProxy: Connecting to ResourceManager at /0.0.0.0:8032\n16/03/17 03:10:55 INFO hdfs.DFSClient: Created HDFS_DELEGATION_TOKEN token 1 for alice on 192.168.56.101:8020\n16/03/17 03:10:55 INFO security.TokenCache: Got dt for hdfs://locke.example.com:8020; Kind: HDFS_DELEGATION_TOKEN, Service: 192.168.56.101:8020, Ident: (HDFS_DELEGATION_TOKEN token 1 for alice)\n16/03/17 03:10:55 INFO input.FileInputFormat: Total input paths to process : 1\n16/03/17 03:10:55 INFO mapreduce.JobSubmitter: number of splits:1\n16/03/17 03:10:55 INFO mapreduce.JobSubmitter: Submitting tokens for job: job_1458151346929_0001\n16/03/17 03:10:55 INFO mapreduce.JobSubmitter: Kind: HDFS_DELEGATION_TOKEN, Service: 192.168.56.101:8020, Ident: (HDFS_DELEGATION_TOKEN token 1 for alice)\n16/03/17 03:10:56 INFO impl.YarnClientImpl: Submitted application application_1458151346929_0001\n16/03/17 03:10:56 INFO mapreduce.Job: The url to track the job: http://locke.example.com:8088/proxy/application_1458151346929_0001/\n16/03/17 03:10:56 INFO mapreduce.Job: Running job: job_1458151346929_0001\n16/03/17 03:11:05 INFO mapreduce.Job: Job job_1458151346929_0001 running in uber mode : false\n16/03/17 03:11:05 INFO mapreduce.Job:  map 0% reduce 0%\n16/03/17 03:11:10 INFO mapreduce.Job:  map 100% reduce 0%\n16/03/17 03:11:15 INFO mapreduce.Job:  map 100% reduce 100%\n16/03/17 03:11:16 INFO mapreduce.Job: Job job_1458151346929_0001 completed successfully\n16/03/17 03:11:16 INFO mapreduce.Job: Counters: 49\n    File System Counters\n        FILE: Number of bytes read=28\n        FILE: Number of bytes written=227605\n        FILE: Number of read operations=0\n        FILE: Number of large read operations=0\n        FILE: Number of write operations=0\n        HDFS: Number of bytes read=273\n        HDFS: Number of bytes written=215\n        HDFS: Number of read operations=7\n        HDFS: Number of large read operations=0\n        HDFS: Number of write operations=3\n    Job Counters \n        Launched map tasks=1\n        Launched reduce tasks=1\n        Data-local map tasks=1\n        Total time spent by all maps in occupied slots (ms)=2352\n        Total time spent by all reduces in occupied slots (ms)=2775\n        Total time spent by all map tasks (ms)=2352\n        Total time spent by all reduce tasks (ms)=2775\n        Total vcore-seconds taken by all map tasks=2352\n        Total vcore-seconds taken by all reduce tasks=2775\n        Total megabyte-seconds taken by all map tasks=2408448\n        Total megabyte-seconds taken by all reduce tasks=2841600\n    Map-Reduce Framework\n        Map input records=1\n        Map output records=2\n        Map output bytes=18\n        Map output materialized bytes=28\n        Input split bytes=155\n        Combine input records=0\n        Combine output records=0\n        Reduce input groups=2\n        Reduce shuffle bytes=28\n        Reduce input records=2\n        Reduce output records=0\n        Spilled Records=4\n        Shuffled Maps =1\n        Failed Shuffles=0\n        Merged Map outputs=1\n        GC time elapsed (ms)=136\n        CPU time spent (ms)=1050\n        Physical memory (bytes) snapshot=503672832\n        Virtual memory (bytes) snapshot=5563736064\n        Total committed heap usage (bytes)=445644800\n    Shuffle Errors\n        BAD_ID=0\n        CONNECTION=0\n        IO_ERROR=0\n        WRONG_LENGTH=0\n        WRONG_MAP=0\n        WRONG_REDUCE=0\n    File Input Format Counters \n        Bytes Read=118\n    File Output Format Counters \n        Bytes Written=97\nJob Finished in 21.452 seconds\nEstimated value of Pi is 3.14800000000000000000\n\n\u3084\u3063\u305f\uff01\n\u6b63\u76f4\u3001\u624b\u3067\u8a2d\u5b9a\u3059\u308b\u306e\u306f\u3064\u3089\u3044\u306e\u3067\u3001\u7d20\u76f4\u306bClouderaManager\u3084Ambari\u3092\u5229\u7528\u3057\u305f\u65b9\u304c\u826f\u3044\u3068\u601d\u308f\u308c\u308b\u3002\n\u4e00\u5ea6\u306f\u624b\u3067\u3084\u3063\u3066\u304a\u304f\u3068\u308f\u304b\u3063\u305f\u6c17\u306b\u306a\u308b\u3068\u3044\u3046\u5229\u70b9\u306f\u3042\u308b\u3002\u6570\u5b66\u306e\u5b9a\u7406\u306e\u8a3c\u660e\u307f\u305f\u3044\u306a\u3082\u306e\u304b\u3002\u3002\u3002\n\n2016/03/25 \u8ffd\u8a18\n\u4e00\u90e8\u74b0\u5883\u3067hdfs\u30b3\u30de\u30f3\u30c9\u5b9f\u884c\u6642\u306b\u4ee5\u4e0b\u306e\u3088\u3046\u306a\u30a8\u30e9\u30fc\u304c\u51fa\u308b\u3053\u3068\u304c\u3042\u3063\u305f\u3002\n16/03/25 12:09:10 WARN security.UserGroupInformation: Exception encountered while running the renewal command. Aborting renew thread. ExitCodeException exitCode=1: kinit: Ticket expired while renewing credentials\n\n\u3053\u308c\u306f\u3001hdfs\u30b3\u30de\u30f3\u30c9\u304c\u5185\u90e8\u3067Kerberos\u306e\u30c1\u30b1\u30c3\u30c8\u306erenew\u3092\u3057\u3088\u3046\u3068\u3057\u3066\u5931\u6557\u3057\u3066\u3044\u308b\u305f\u3081\u306b\u51fa\u529b\u3055\u308c\u3066\u3044\u308b\u3002\n\u76f4\u63a5\u7684\u306b\u78ba\u8a8d\u3059\u308b\u306b\u306f\u3001kinit -R\u3092\u5b9f\u884c\u3057\u3066\u307f\u308b\u3002\n$ kinit -R\nkinit: Ticket expired while renewing credentials\n\n\u539f\u56e0\u3068\u3057\u3066\u306f\u3001Kerberos\u5074\u3067\u4f5c\u6210\u3057\u305f\u30d7\u30ea\u30f3\u30b7\u30d1\u30eb\u306emaxrenewlife\u304c\u30c7\u30d5\u30a9\u30eb\u30c8\u306e0\u3068\u306a\u3063\u3066\u3044\u3066\u3001renew\u3057\u3088\u3046\u3068\u3057\u3066\u3082\u4f38\u3070\u305b\u306a\u304f\u306a\u3063\u3066\u3044\u308b\u3053\u3068\u304c\u591a\u3044\u3002\n\u3053\u306e\u72b6\u614b\u306b\u306a\u3063\u3066\u3044\u308b\u3053\u3068\u3092\u78ba\u8a8d\u3059\u308b\u306b\u306f\u3001kadmin\u3067KDC\u306b\u63a5\u7d9a\u3057\u3066\u4ee5\u4e0b\u306e\u30b3\u30de\u30f3\u30c9\u3092\u5b9f\u884c\u3059\u308b\u3002\nkadmin.local:  getprinc alice/locke.example.com@EXAMPLE.COM\nPrincipal: alice/locke.example.com@EXAMPLE.COM\nExpiration date: [never]\nLast password change: Tue Mar 15 17:09:55 JST 2016\nPassword expiration date: [none]\nMaximum ticket life: 1 day 00:00:00\nMaximum renewable life: 0 days 00:00:00   \u2605\u3053\u3053\u304c0 days\u306b\u306a\u3063\u3066\u3044\u308b\u304b\u3069\u3046\u304b\u3002\nLast modified: Tue Mar 15 17:09:55 JST 2016 (root/admin@EXAMPLE.COM)\nLast successful authentication: [never]\nLast failed authentication: [never]\nFailed password attempts: 0\nNumber of keys: 3\nKey: vno 1, aes256-cts-hmac-sha1-96, no salt\nKey: vno 1, aes128-cts-hmac-sha1-96, no salt\nKey: vno 1, arcfour-hmac, no salt\nMKey: vno 1\nAttributes:\nPolicy: [none]\n\nmodprinc\u3067\u30d7\u30ea\u30f3\u30b7\u30d1\u30eb\u306emaxrenewlife\u3092\u5909\u66f4\u3067\u304d\u308b\u3002\nkadmin.local:   modprinc -maxrenewlife 1week\n\n\u306a\u304a\u3001\u4eca\u5f8c\u65b0\u3057\u304f\u4f5c\u3089\u308c\u308b\u30d7\u30ea\u30f3\u30b7\u30d1\u30eb\u306b\u5bfe\u3057\u3066\u306e\u30c7\u30d5\u30a9\u30eb\u30c8\u8a2d\u5b9a\u3092\u5909\u66f4\u3059\u308b\u5834\u5408\u3001krbtgt/EXAMPLE.COM@EXAMPLE.COM\u306emaxrenewlife\u3092\u5909\u66f4\u3057\u3066\u304a\u304f\u3068\u826f\u3044\u3089\u3057\u3044\u3002\n\u4ee5\u4e0b\u306e\u30da\u30fc\u30b8\u304c\u53c2\u8003\u306b\u306a\u3063\u305f\u3002\nhttp://championofcyrodiil.blogspot.jp/2014/01/kinit-ticket-expired-while-renewing.html\n\u524d\u56de\u306e[\u300cKerberos\u30a4\u30f3\u30b9\u30c8\u30fc\u30eb\u624b\u9806\u300d](http://qiita.com/bwtakacy/items/a8cd1349a9d150f65eb3)\u306e\u7d9a\u304d\u3002\n\u5f53\u521d\u306e\u76ee\u7684\u3067\u3042\u308bHadoop\u306eKerberos\u5316\u3092\u884c\u3046\u624b\u9806\u3092\u6574\u7406\u3059\u308b\u3002\n\n# Hadoop\u306e\u30a4\u30f3\u30b9\u30c8\u30fc\u30eb\n\n[\u904e\u53bb\u8a18\u4e8b](http://qiita.com/bwtakacy/items/306afa1b8261f2d4d76e)\u53c2\u7167\u3002\n\u4eca\u56de\u5229\u7528\u3059\u308b\u306e\u306fCDH5.6.0\u3002\n\n# JCE Policy\u306e\u30a4\u30f3\u30b9\u30c8\u30fc\u30eb\n\nAES\u6697\u53f7\u5316\u3092Java\u304b\u3089\u5229\u7528\u3059\u308b\u305f\u3081\u306b\u3001Java Cryptography Extension (JCE) Unlimited Strength Jurisdiction Policy Files\u3092Oracle\u304b\u3089\u30c0\u30a6\u30f3\u30ed\u30fc\u30c9\u3057\u3066\u30a4\u30f3\u30b9\u30c8\u30fc\u30eb\u3059\u308b\u3002\n\u30a4\u30f3\u30b9\u30c8\u30fc\u30eb\u65b9\u6cd5\u306f\u6dfb\u4ed8\u306eREADME.txt\u306b\u5f93\u3046\u3002\n\n```\n# cd UnlimitedJCEPolicyJDK8-2/\n# ls\nREADME.txt  US_export_policy.jar  local_policy.jar\n# ll /usr/java/latest/jre/lib/security/\n\u5408\u8a08 152\n-rw-r--r-- 1 root root  2920  1\u6708 30 11:00 US_export_policy.jar\n-rw-r--r-- 1 root root  4054  1\u6708 30 10:49 blacklist\n-rw-r--r-- 1 root root  1273  1\u6708 30 10:49 blacklisted.certs\n-rw-r--r-- 1 root root 99954  1\u6708 30 10:49 cacerts\n-rw-r--r-- 1 root root  2466  1\u6708 30 10:49 java.policy\n-rw-r--r-- 1 root root 26224  1\u6708 30 10:49 java.security\n-rw-r--r-- 1 root root    98  1\u6708 30 10:49 javaws.policy\n-rw-r--r-- 1 root root  3405  1\u6708 30 11:00 local_policy.jar\n-rw-r--r-- 1 root root     0  1\u6708 30 10:49 trusted.libraries\n# mkdir default_jars\n# mv /usr/java/latest/jre/lib/security/*.jar default_jars/\n# cp *.jar /usr/java/latest/jre/lib/security/\n# ll /usr/java/latest/jre/lib/security/\n\u5408\u8a08 152\n-rw-r--r-- 1 root root  3023  3\u6708 17 00:52 US_export_policy.jar\n-rw-r--r-- 1 root root  4054  1\u6708 30 10:49 blacklist\n-rw-r--r-- 1 root root  1273  1\u6708 30 10:49 blacklisted.certs\n-rw-r--r-- 1 root root 99954  1\u6708 30 10:49 cacerts\n-rw-r--r-- 1 root root  2466  1\u6708 30 10:49 java.policy\n-rw-r--r-- 1 root root 26224  1\u6708 30 10:49 java.security\n-rw-r--r-- 1 root root    98  1\u6708 30 10:49 javaws.policy\n-rw-r--r-- 1 root root  3035  3\u6708 17 00:52 local_policy.jar\n-rw-r--r-- 1 root root     0  1\u6708 30 10:49 trusted.libraries\n```\n\n# Hadoop\u30d7\u30ed\u30bb\u30b9\u5411\u3051\u306eKerberos\u30d7\u30ea\u30f3\u30b7\u30d1\u30eb\u306e\u4f5c\u6210\n\n\u5fc5\u8981\u306a\u306e\u306f\u3001hdfs/[FQDN], mapred/[FQDN], yarn/[FQDN], HTTP/[FQDN]\u3002\n\u4eca\u56de\u306f\u64ec\u4f3c\u5206\u6563\u74b0\u5883\u306a\u306e\u3067\u305d\u308c\u305e\u308c1\u3064\u305a\u3064\u3060\u304c\u3001\u5b8c\u5168\u5206\u6563\u74b0\u5883\u3060\u3068\u30b5\u30fc\u30d0\u6bce\u306b1\u3064\u305a\u3064\u4f5c\u6210\u3059\u308b\u5fc5\u8981\u304c\u3042\u308b\u3002\n\n```\n# kadmin.local \nAuthenticating as principal root/admin@EXAMPLE.COM with password.\nkadmin.local:  addprinc -randkey hdfs/locke.example.com@EXAMPLE.COM\nWARNING: no policy specified for hdfs/locke.example.com@EXAMPLE.COM; defaulting to no policy\nPrincipal \"hdfs/locke.example.com@EXAMPLE.COM\" created.\nkadmin.local:  addprinc -randkey mapred/locke.example.com@EXAMPLE.COM\nWARNING: no policy specified for mapred/locke.example.com@EXAMPLE.COM; defaulting to no policy\nPrincipal \"mapred/locke.example.com@EXAMPLE.COM\" created.\nkadmin.local:  addprinc -randkey yarn/locke.example.com@EXAMPLE.COM\nWARNING: no policy specified for yarn/locke.example.com@EXAMPLE.COM; defaulting to no policy\nPrincipal \"yarn/locke.example.com@EXAMPLE.COM\" created.\nkadmin.local:  addprinc -randkey HTTP/locke.example.com@EXAMPLE.COM\nWARNING: no policy specified for HTTP/locke.example.com@EXAMPLE.COM; defaulting to no policy\nPrincipal \"HTTP/locke.example.com@EXAMPLE.COM\" created.\nkadmin.local:  listprincs \nHTTP/locke.example.com@EXAMPLE.COM\nK/M@EXAMPLE.COM\nalice/locke.example.com@EXAMPLE.COM\nhdfs/locke.example.com@EXAMPLE.COM\nkadmin/admin@EXAMPLE.COM\nkadmin/changepw@EXAMPLE.COM\nkadmin/locke.example.com@EXAMPLE.COM\nkiprop/locke.example.com@EXAMPLE.COM\nkrbtgt/EXAMPLE.COM@EXAMPLE.COM\nmapred/locke.example.com@EXAMPLE.COM\nyarn/locke.example.com@EXAMPLE.COM\n```\n\n# Keytab\u30d5\u30a1\u30a4\u30eb\u306e\u4f5c\u6210\n\n\u5404Hadoop\u30d7\u30ed\u30bb\u30b9\u306e\u8a8d\u8a3c\u7528\u306ekeytab\u30d5\u30a1\u30a4\u30eb\u3092\u4f5c\u6210\u3059\u308b\u3002\u3053\u308c\u307e\u305f\u30b5\u30fc\u30d0\u500b\u5225\u306b\u30d5\u30a1\u30a4\u30eb\u3092\u4f5c\u6210\u3059\u308b\u5fc5\u8981\u304c\u3042\u308b\u3002\u4eca\u56de\u306f\u64ec\u4f3c\u5206\u6563\u306a\u306e\u30671\u3064\u305a\u3064\u3067OK\u3002\n\n```\nkadmin.local:  ktadd -norandkey -k hdfs.keytab hdfs/locke.example.com@EXAMPLE.COM HTTP/locke.example.com@EXAMPLE.COM\nEntry for principal hdfs/locke.example.com@EXAMPLE.COM with kvno 1, encryption type aes256-cts-hmac-sha1-96 added to keytab WRFILE:hdfs.keytab.\nEntry for principal hdfs/locke.example.com@EXAMPLE.COM with kvno 1, encryption type aes128-cts-hmac-sha1-96 added to keytab WRFILE:hdfs.keytab.\nEntry for principal hdfs/locke.example.com@EXAMPLE.COM with kvno 1, encryption type arcfour-hmac added to keytab WRFILE:hdfs.keytab.\nEntry for principal HTTP/locke.example.com@EXAMPLE.COM with kvno 1, encryption type aes256-cts-hmac-sha1-96 added to keytab WRFILE:hdfs.keytab.\nEntry for principal HTTP/locke.example.com@EXAMPLE.COM with kvno 1, encryption type aes128-cts-hmac-sha1-96 added to keytab WRFILE:hdfs.keytab.\nEntry for principal HTTP/locke.example.com@EXAMPLE.COM with kvno 1, encryption type arcfour-hmac added to keytab WRFILE:hdfs.keytab.\nkadmin.local:  ktadd -norandkey -k mapred.keytab mapred/locke.example.com@EXAMPLE.COM HTTP/locke.example.com@EXAMPLE.COM\nEntry for principal mapred/locke.example.com@EXAMPLE.COM with kvno 1, encryption type aes256-cts-hmac-sha1-96 added to keytab WRFILE:mapred.keytab.\nEntry for principal mapred/locke.example.com@EXAMPLE.COM with kvno 1, encryption type aes128-cts-hmac-sha1-96 added to keytab WRFILE:mapred.keytab.\nEntry for principal mapred/locke.example.com@EXAMPLE.COM with kvno 1, encryption type arcfour-hmac added to keytab WRFILE:mapred.keytab.\nEntry for principal HTTP/locke.example.com@EXAMPLE.COM with kvno 1, encryption type aes256-cts-hmac-sha1-96 added to keytab WRFILE:mapred.keytab.\nEntry for principal HTTP/locke.example.com@EXAMPLE.COM with kvno 1, encryption type aes128-cts-hmac-sha1-96 added to keytab WRFILE:mapred.keytab.\nEntry for principal HTTP/locke.example.com@EXAMPLE.COM with kvno 1, encryption type arcfour-hmac added to keytab WRFILE:mapred.keytab.\nkadmin.local:  ktadd -norandkey -k yarn.keytab yarn/locke.example.com@EXAMPLE.COM HTTP/locke.example.com@EXAMPLE.COM\nEntry for principal yarn/locke.example.com@EXAMPLE.COM with kvno 1, encryption type aes256-cts-hmac-sha1-96 added to keytab WRFILE:yarn.keytab.\nEntry for principal yarn/locke.example.com@EXAMPLE.COM with kvno 1, encryption type aes128-cts-hmac-sha1-96 added to keytab WRFILE:yarn.keytab.\nEntry for principal yarn/locke.example.com@EXAMPLE.COM with kvno 1, encryption type arcfour-hmac added to keytab WRFILE:yarn.keytab.\nEntry for principal HTTP/locke.example.com@EXAMPLE.COM with kvno 1, encryption type aes256-cts-hmac-sha1-96 added to keytab WRFILE:yarn.keytab.\nEntry for principal HTTP/locke.example.com@EXAMPLE.COM with kvno 1, encryption type aes128-cts-hmac-sha1-96 added to keytab WRFILE:yarn.keytab.\nEntry for principal HTTP/locke.example.com@EXAMPLE.COM with kvno 1, encryption type arcfour-hmac added to keytab WRFILE:yarn.keytab.\n```\n\n# Keytab\u30d5\u30a1\u30a4\u30eb\u306e\u914d\u7f6e\n\n\u4f5c\u6210\u3057\u305fkeytab\u30d5\u30a1\u30a4\u30eb\u3092Hadoop\u306e\u8a2d\u5b9a\u30d5\u30a1\u30a4\u30eb\u3092\u914d\u7f6e\u3057\u305f\u30c7\u30a3\u30ec\u30af\u30c8\u30ea\u306b\u7f6e\u304f\u3002\n\u30d1\u30fc\u30df\u30c3\u30b7\u30e7\u30f3\u3092\u5404\u30e6\u30fc\u30b6\u5411\u3051\u306b\u3059\u308b\u3053\u3068\u3092\u5fd8\u308c\u306a\u3044\u3088\u3046\u306b\u3002\n\n```\n# ls\nhdfs.keytab  mapred.keytab  yarn.keytab\n# cp * /etc/hadoop/conf/\n# chown hdfs:hadoop /etc/hadoop/conf/hdfs.keytab \n# chown mapred:hadoop /etc/hadoop/conf/mapred.keytab \n# chown yarn:hadoop /etc/hadoop/conf/yarn.keytab \n# ll /etc/hadoop/conf/\n\u5408\u8a08 52\n-rwxr-xr-x 1 root   root    1104 11\u6708 27 03:20 README\n-rwxr-xr-x 1 root   root    2133 11\u6708 27 03:20 core-site.xml\n-rwxr-xr-x 1 root   root    1366 11\u6708 27 03:20 hadoop-env.sh\n-rwxr-xr-x 1 root   root    2890 11\u6708 27 03:20 hadoop-metrics.properties\n-rwxr-xr-x 1 root   root    2324  1\u6708 29 15:08 hdfs-site.xml\n-rw------- 1 hdfs   hadoop   707  3\u6708 17 01:02 hdfs.keytab\n-rwxr-xr-x 1 root   root   11291  1\u6708 29 15:08 log4j.properties\n-rwxr-xr-x 1 root   root    1549 11\u6708 27 03:20 mapred-site.xml\n-rw------- 1 mapred hadoop   478  3\u6708 17 01:02 mapred.keytab\n-rwxr-xr-x 1 root   root    2375 11\u6708 27 03:20 yarn-site.xml\n-rw------- 1 yarn   hadoop   472  3\u6708 17 01:02 yarn.keytab\n```\n\n# HDFS\u306eKerberos\u5316\n\n## \u8a2d\u5b9a\u30d5\u30a1\u30a4\u30eb\u306e\u5909\u66f4\n\n\u4ee5\u4e0b\u306e\u9805\u76ee\u3092\u8ffd\u52a0\u3059\u308b\u3002\n\n```core-site.xml\n  <!-- For Kerberos -->\n  <property>\n    <name>hadoop.security.authentication</name>\n    <value>kerberos</value> \n  </property>\n\n  <property>\n    <name>hadoop.security.authorization</name>\n    <value>true</value>\n  </property>\n```\n\n```hdfs-site.xml\n  <!-- For Kerberos -->\n  <!-- General HDFS security config -->\n  <property>\n    <name>dfs.block.access.token.enable</name>\n    <value>true</value>\n  </property>\n  \n  <!-- NameNode security config -->\n  <property>\n    <name>dfs.namenode.keytab.file</name>\n    <value>/etc/hadoop/conf/hdfs.keytab</value> <!-- path to the HDFS keytab -->\n  </property>\n  <property>\n    <name>dfs.namenode.kerberos.principal</name>\n    <value>hdfs/_HOST@EXAMPLE.COM</value>\n  </property>\n  <property>\n    <name>dfs.namenode.kerberos.internal.spnego.principal</name>\n    <value>HTTP/_HOST@EXAMPLE.COM</value>\n  </property>\n  \n  <!-- Secondary NameNode security config -->\n  <property>\n    <name>dfs.secondary.namenode.keytab.file</name>\n    <value>/etc/hadoop/conf/hdfs.keytab</value> <!-- path to the HDFS keytab -->\n  </property>\n  <property>\n    <name>dfs.secondary.namenode.kerberos.principal</name>\n    <value>hdfs/_HOST@EXAMPLE.COM</value>\n  </property>\n  <property>\n    <name>dfs.secondary.namenode.kerberos.internal.spnego.principal</name>\n    <value>HTTP/_HOST@EXAMPLE.COM</value>\n  </property>\n  \n  <!-- DataNode security config -->\n  <property>\n    <name>dfs.datanode.data.dir.perm</name>\n    <value>700</value> \n  </property>\n  <property>\n    <name>dfs.datanode.address</name>\n    <value>0.0.0.0:1004</value>\n  </property>\n  <property>\n    <name>dfs.datanode.http.address</name>\n    <value>0.0.0.0:1006</value>\n  </property>\n  <property>\n    <name>dfs.datanode.keytab.file</name>\n    <value>/etc/hadoop/conf/hdfs.keytab</value> <!-- path to the HDFS keytab -->\n  </property>\n  <property>\n    <name>dfs.datanode.kerberos.principal</name>\n    <value>hdfs/_HOST@EXAMPLE.COM</value>\n  </property>\n  \n  <!-- Web Authentication config -->\n  <property>\n    <name>dfs.web.authentication.kerberos.principal</name>\n    <value>HTTP/_HOST@EXAMPLE.COM</value>\n  </property>\n```\n\n\u4eca\u56de\u306fSecondaryNameNode\u3092\u5229\u7528\u3057\u3066\u3044\u308b\u304c\u3001JournalNode\u3092\u4f7f\u3063\u3066\u3044\u308b\u5834\u5408\u306fJournalNode\u5411\u3051\u306e\u8a2d\u5b9a\u304c\u5fc5\u8981\u3068\u306a\u308b\u3002\u305d\u306e\u5834\u5408\u306f\u3001\u4ee5\u4e0b\u306e\u3088\u3046\u306a\u9805\u76ee\u3092\u6307\u5b9a\u3059\u308b\u3002\n\n```\n<property>\n  <name>dfs.journalnode.keytab.file</name>\n  <value>/etc/hadoop/conf/hdfs.keytab</value> <!-- path to the HDFS keytab -->\n</property>\n<property>\n  <name>dfs.journalnode.kerberos.principal</name>\n  <value>hdfs/_HOST@EXAMPLE.COM</value>\n</property>\n<property>\n  <name>dfs.journalnode.kerberos.internal.spnego.principal</name>\n  <value>HTTP/_HOST@EXAMPLE.COM</value>\n</property>\n```\n\n## DataNode\u306e\u74b0\u5883\u5909\u6570\u306e\u8a2d\u5b9a\u5909\u66f4\n\n\u4ee5\u4e0b\u3092\u8a2d\u5b9a\u3059\u308b\u3002JSVC_HOME\u4ee5\u5916\u306f\u30b3\u30e1\u30f3\u30c8\u30a2\u30a6\u30c8\u3092\u5916\u3059\u3060\u3051\u3002\n\n```/etc/default/hadoop-hdfs-datanode\nexport HADOOP_SECURE_DN_USER=hdfs\nexport HADOOP_SECURE_DN_PID_DIR=/var/run/hadoop-hdfs\nexport HADOOP_SECURE_DN_LOG_DIR=/var/log/hadoop-hdfs\nexport JSVC_HOME=/usr/lib/bigtop-utils/\n```\n\n## NameNode\u306e\u8d77\u52d5\n\n\u6700\u521d\u306e\u95a2\u9580\u3067\u3042\u308b\u3002\n\u7948\u308a\u306a\u304c\u3089\u8d77\u52d5\u3059\u308b\u3002\n\n```\n# systemctl start hadoop-hdfs-namenode.service\n# jps\n8053 Jps\n7976 NameNode\n```\n\n\u5ff5\u306e\u305f\u3081\u30ed\u30b0\u3092\u898b\u3066Kerberos\u8a8d\u8a3c\u306b\u6210\u529f\u3057\u3066\u3044\u308b\u304b\u3069\u3046\u304b\u3092\u78ba\u8a8d\u3059\u308b\u3002\n\n```\n2016-03-17 01:21:52,803 INFO org.apache.hadoop.security.UserGroupInformation: Login successful for user hdfs/locke.example.com@EXAMPLE.COM using keytab file /etc/hadoop/conf/hdfs.keytab\n```\n\n### \u3046\u307e\u304f\u3044\u304b\u306a\u3044\u6642\n\n\u60b2\u5287\u306e\u59cb\u307e\u308a\u3002\u4eca\u307e\u3067\u306e\u624b\u9806\u3067\u4f55\u304b\u3057\u3089\u9593\u9055\u3063\u3066\u3044\u308b\u3068\u3053\u308d\u304c\u3042\u308b\u306f\u305a\u306a\u306e\u3067\u3001\u771f\u646f\u306b\u632f\u308a\u8fd4\u308b\u3002SAN\u5024\u304c\u30e2\u30ea\u30e2\u30ea\u4e0b\u304c\u308b\u306e\u3067\u3001\u7cbe\u795e\u306e\u5b89\u5b9a\u3092\u56f3\u308b\u624b\u6bb5\u306f\u5fc5\u9808\u3067\u3042\u308b\u3002\n\n\u7b2c\u4e00\u6b69\u3068\u3057\u3066\u3001Java\u304b\u3089Kerberos\u5468\u308a\u306eDEBUG\u30ed\u30b0\u3092\u51fa\u3059\u3088\u3046\u306b\u3059\u308b\u3068\u826f\u304b\u3063\u305f\u3002\n\n```hadoop-env.sh\nexport HADOOP_OPTS=\"-Dsun.security.krb5.debug=true -Djava.net.preferIPv4Stack=true $HADOOP_CLIENT_OPTS\"\n```\n\n\u305d\u306e\u4ed6\u3001[Cloudera\u306e\u30c9\u30ad\u30e5\u30e1\u30f3\u30c8](http://www.cloudera.com/documentation/enterprise/latest/topics/cm_sg_sec_troubleshooting.html)\u306bFAQ\u7684\u306a\u60c5\u5831\u304c\u3042\u308b\u306e\u3067\u3001\u53c2\u8003\u306b\u3059\u308b\u3002\n\n\u81ea\u5206\u304c\u30cf\u30de\u3063\u305f\u70b9\u3092\u6319\u3052\u3066\u304a\u304f\u3068\n\n* Kerberos\u306e\u8a2d\u5b9a\u30df\u30b9(kdc.conf, krb.conf)\n* JCE\u306e\u30a4\u30f3\u30b9\u30c8\u30fc\u30eb\u5fd8\u308c\n* keytab\u30d5\u30a1\u30a4\u30eb\u306e\u30d1\u30fc\u30df\u30c3\u30b7\u30e7\u30f3\u8a2d\u5b9a\u30df\u30b9\n* keytab\u30d5\u30a1\u30a4\u30eb\u306bHTTP\u30d7\u30ea\u30f3\u30b7\u30d1\u30eb\u3092\u5165\u308c\u5fd8\u308c\u3066\u3044\u308b\n\n\u3042\u305f\u308a\u3092\u5f15\u3044\u305f\u3002\n\n\n## SecondaryNameNode\u306e\u8d77\u52d5\n\n```\n# systemctl start hadoop-hdfs-secondarynamenode.service\n```\n\n## DataNode\u306e\u8d77\u52d5\n\n```\n# systemctl start hadoop-hdfs-datanode.service\n```\n\n## hdfs\u30e6\u30fc\u30b6\u306b\u3088\u308b\u8d77\u52d5\u78ba\u8a8d\n\nhdfs\u30e6\u30fc\u30b6\u3067key tab\u3092\u4f7f\u3063\u3066\u8a8d\u8a3c\u3057\u3066\u3001hdfs\u30b3\u30de\u30f3\u30c9\u3092\u6253\u3063\u3066\u307f\u308b\u3002\n\n```\n# su - hdfs\n-bash-4.2$ kinit hdfs/locke.example.com@EXAMPLE.COM -kt /etc/hadoop/conf/hdfs.keytab \n-bash-4.2$ klist -e\nTicket cache: FILE:/tmp/krb5cc_993\nDefault principal: hdfs/locke.example.com@EXAMPLE.COM\n\nValid starting       Expires              Service principal\n2016-03-17T02:42:54  2016-03-18T02:42:54  krbtgt/EXAMPLE.COM@EXAMPLE.COM\n\tEtype (skey, tkt): aes256-cts-hmac-sha1-96, aes256-cts-hmac-sha1-96 \n-bash-4.2$ hdfs dfsadmin -report\nConfigured Capacity: 9082765312 (8.46 GB)\nPresent Capacity: 6496538624 (6.05 GB)\nDFS Remaining: 6496038912 (6.05 GB)\nDFS Used: 499712 (488 KB)\nDFS Used%: 0.01%\nUnder replicated blocks: 0\nBlocks with corrupt replicas: 0\nMissing blocks: 0\nMissing blocks (with replication factor 1): 0\n\n-------------------------------------------------\nLive datanodes (1):\n\nName: 192.168.56.101:1004 (locke.example.com)\nHostname: locke.example.com\nDecommission Status : Normal\nConfigured Capacity: 9082765312 (8.46 GB)\nDFS Used: 499712 (488 KB)\nNon DFS Used: 2586226688 (2.41 GB)\nDFS Remaining: 6496038912 (6.05 GB)\nDFS Used%: 0.01%\nDFS Remaining%: 71.52%\nConfigured Cache Capacity: 0 (0 B)\nCache Used: 0 (0 B)\nCache Remaining: 0 (0 B)\nCache Used%: 100.00%\nCache Remaining%: 0.00%\nXceivers: 2\nLast contact: Thu Mar 17 02:43:06 JST 2016\n\n\n-bash-4.2$ hdfs dfs -ls /\nFound 5 items\ndrwxrwxrwx   - hdfs  supergroup          0 2016-03-17 00:37 /benchmarks\ndrwxr-xr-x   - hbase supergroup          0 2016-03-17 00:37 /hbase\ndrwxrwxrwt   - hdfs  supergroup          0 2016-03-17 00:37 /tmp\ndrwxr-xr-x   - hdfs  supergroup          0 2016-03-17 00:38 /user\ndrwxr-xr-x   - hdfs  supergroup          0 2016-03-17 00:38 /var\n```\n\n# YARN\u306eKerberos\u5316\n\n## \u8a2d\u5b9a\u30d5\u30a1\u30a4\u30eb\u306e\u5909\u66f4\n\n```yarn-site.xml\n  <!-- For Kerberos -->\n  <!-- ResourceManager security configs -->\n  <property>\n    <name>yarn.resourcemanager.keytab</name>\n    <value>/etc/hadoop/conf/yarn.keytab</value>       <!-- path to the YARN keytab -->\n  </property>\n  <property>\n    <name>yarn.resourcemanager.principal</name>\n    <value>yarn/_HOST@EXAMPLE.COM</value>\n  </property>\n \n  <!-- NodeManager security configs -->\n  <property>\n    <name>yarn.nodemanager.keytab</name>\n    <value>/etc/hadoop/conf/yarn.keytab</value>       <!-- path to the YARN keytab -->\n  </property>\n  <property>\n    <name>yarn.nodemanager.principal</name>\n    <value>yarn/_HOST@EXAMPLE.COM</value>\n  </property>\n  <property>\n    <name>yarn.nodemanager.container-executor.class</name>\n    <value>org.apache.hadoop.yarn.server.nodemanager.LinuxContainerExecutor</value>\n  </property>\n  <property>\n    <name>yarn.nodemanager.linux-container-executor.group</name>\n    <value>yarn</value>\n  </property>\n```\n\n```mapped-site.xml\n  <!-- MapReduce Job History Server security configs -->\n  <property>\n    <name>mapreduce.jobhistory.address</name>\n    <value>locke.example.com:10020</value> <!-- Host and port of the MapReduce Job History Server; default port is 10020  -->\n  </property>\n  <property>\n    <name>mapreduce.jobhistory.keytab</name>\n    <value>/etc/hadoop/conf/mapred.keytab</value>     <!-- path to the MAPRED keytab for the Job History Server -->\n  </property>\n  <property>\n    <name>mapreduce.jobhistory.principal</name>\n    <value>mapred/_HOST@EXAMPLE.COM</value>\n  </property>\n```\n\nContainerExecutor\u3092LinuxContainerExecutor\u306b\u8a2d\u5b9a\u3057\u3066\u3044\u308b\u306e\u3067\u3001container-executor.cfg\u3082\u5fc5\u8981\u3068\u306a\u308b\u3002\u8a2d\u5b9a\u5185\u5bb9\u306f\u3053\u3093\u306a\u611f\u3058\u3002\u74b0\u5883\u306b\u5408\u308f\u305b\u3066\u8a2d\u5b9a\u5024\u306f\u5909\u3048\u308b\u3002\n\n```container-executor.cfg\nyarn.nodemanager.local-dirs=/var/lib/hadoop-yarn/cache/yarn/nm-local-dir\nyarn.nodemanager.linux-container-executor.group=yarn\nyarn.nodemanager.log-dirs=/var/log/hadoop-yarn/containers\nbanned.users=hdfs,yarn,mapred,bin       \nmin.user.id=500\n```\n\n\u6ce8\u610f\u3059\u308b\u70b9\u3068\u3057\u3066\u3001\u304d\u3082\u3044\u30d1\u30fc\u30df\u30c3\u30b7\u30e7\u30f3\u306b\u3059\u308b\u5fc5\u8981\u304c\u3042\u308b\u3002\n\n```\n chown root:yarn /etc/hadoop/conf/container-executor.cfg \n# chmod 040 /etc/hadoop/conf/container-executor.cfg \n# chmod +s /etc/hadoop/conf/container-executor.cfg \n# ll /etc/hadoop/conf/container-executor.cfg \n---Sr-S--- 1 root yarn 241  3\u6708 17 02:59 /etc/hadoop/conf/container-executor.cfg\n```\n\n## YARN\u306e\u8d77\u52d5\n\n```\n# systemctl start hadoop-yarn-resourcemanager.service\n# systemctl start hadoop-yarn-nodemanager.service\n```\n\n## yarn\u30e6\u30fc\u30b6\u306b\u3088\u308b\u78ba\u8a8d\n\n```\n# su - yarn\n-bash-4.2$ kinit yarn/locke.example.com@EXAMPLE.COM -kt /etc/hadoop/conf/yarn.keytab \n-bash-4.2$ klist -e\nTicket cache: FILE:/tmp/krb5cc_992\nDefault principal: yarn/locke.example.com@EXAMPLE.COM\n\nValid starting       Expires              Service principal\n2016-03-17T03:06:40  2016-03-18T03:06:40  krbtgt/EXAMPLE.COM@EXAMPLE.COM\n\tEtype (skey, tkt): aes256-cts-hmac-sha1-96, aes256-cts-hmac-sha1-96 \n-bash-4.2$ yarn node -list \n16/03/17 03:06:45 INFO client.RMProxy: Connecting to ResourceManager at /0.0.0.0:8032\nTotal Nodes:1\n         Node-Id\t     Node-State\tNode-Http-Address\tNumber-of-Running-Containers\nlocke.example.com:46070\t        RUNNING\tlocke.example.com:8042\t                           0\n```\n\n## MapReduce JobHistoryServer\u306e\u8d77\u52d5\n\n```\n# systemctl start hadoop-mapreduce-historyserver.service\n```\n\n## MapReduce\u30b8\u30e7\u30d6\u306e\u5b9f\u884c\u78ba\u8a8d\n\nalice\u30e6\u30fc\u30b6\u3067MapReduce\u30b8\u30e7\u30d6\u3092\u5b9f\u884c\u3057\u3066\u307f\u308b\u3002\u307e\u305a\u306fHDFS\u4e0a\u306b\u30e6\u30fc\u30b6\u30c7\u30a3\u30ec\u30af\u30c8\u30ea\u3092\u4f5c\u6210\u3059\u308b\u3002\n\n```\n# su - hdfs\n-bash-4.2$ hdfs dfs -mkdir /user/alice\n-bash-4.2$ hdfs dfs -chown alice /user/alice\n```\n\nalice\u30e6\u30fc\u30b6\u3067\u30b5\u30f3\u30d7\u30ebMapReduce\u3092\u5b9f\u884c\u3057\u3066\u307f\u308b\u3002\n\n```\n# su - alice\n$ hadoop jar /usr/lib/hadoop-mapreduce/hadoop-mapreduce-examples-2.6.0-cdh5.6.0.jar pi 1 1000\nNumber of Maps  = 1\nSamples per Map = 1000\nWrote input for Map #0\nStarting Job\n16/03/17 03:10:55 INFO client.RMProxy: Connecting to ResourceManager at /0.0.0.0:8032\n16/03/17 03:10:55 INFO hdfs.DFSClient: Created HDFS_DELEGATION_TOKEN token 1 for alice on 192.168.56.101:8020\n16/03/17 03:10:55 INFO security.TokenCache: Got dt for hdfs://locke.example.com:8020; Kind: HDFS_DELEGATION_TOKEN, Service: 192.168.56.101:8020, Ident: (HDFS_DELEGATION_TOKEN token 1 for alice)\n16/03/17 03:10:55 INFO input.FileInputFormat: Total input paths to process : 1\n16/03/17 03:10:55 INFO mapreduce.JobSubmitter: number of splits:1\n16/03/17 03:10:55 INFO mapreduce.JobSubmitter: Submitting tokens for job: job_1458151346929_0001\n16/03/17 03:10:55 INFO mapreduce.JobSubmitter: Kind: HDFS_DELEGATION_TOKEN, Service: 192.168.56.101:8020, Ident: (HDFS_DELEGATION_TOKEN token 1 for alice)\n16/03/17 03:10:56 INFO impl.YarnClientImpl: Submitted application application_1458151346929_0001\n16/03/17 03:10:56 INFO mapreduce.Job: The url to track the job: http://locke.example.com:8088/proxy/application_1458151346929_0001/\n16/03/17 03:10:56 INFO mapreduce.Job: Running job: job_1458151346929_0001\n16/03/17 03:11:05 INFO mapreduce.Job: Job job_1458151346929_0001 running in uber mode : false\n16/03/17 03:11:05 INFO mapreduce.Job:  map 0% reduce 0%\n16/03/17 03:11:10 INFO mapreduce.Job:  map 100% reduce 0%\n16/03/17 03:11:15 INFO mapreduce.Job:  map 100% reduce 100%\n16/03/17 03:11:16 INFO mapreduce.Job: Job job_1458151346929_0001 completed successfully\n16/03/17 03:11:16 INFO mapreduce.Job: Counters: 49\n\tFile System Counters\n\t\tFILE: Number of bytes read=28\n\t\tFILE: Number of bytes written=227605\n\t\tFILE: Number of read operations=0\n\t\tFILE: Number of large read operations=0\n\t\tFILE: Number of write operations=0\n\t\tHDFS: Number of bytes read=273\n\t\tHDFS: Number of bytes written=215\n\t\tHDFS: Number of read operations=7\n\t\tHDFS: Number of large read operations=0\n\t\tHDFS: Number of write operations=3\n\tJob Counters \n\t\tLaunched map tasks=1\n\t\tLaunched reduce tasks=1\n\t\tData-local map tasks=1\n\t\tTotal time spent by all maps in occupied slots (ms)=2352\n\t\tTotal time spent by all reduces in occupied slots (ms)=2775\n\t\tTotal time spent by all map tasks (ms)=2352\n\t\tTotal time spent by all reduce tasks (ms)=2775\n\t\tTotal vcore-seconds taken by all map tasks=2352\n\t\tTotal vcore-seconds taken by all reduce tasks=2775\n\t\tTotal megabyte-seconds taken by all map tasks=2408448\n\t\tTotal megabyte-seconds taken by all reduce tasks=2841600\n\tMap-Reduce Framework\n\t\tMap input records=1\n\t\tMap output records=2\n\t\tMap output bytes=18\n\t\tMap output materialized bytes=28\n\t\tInput split bytes=155\n\t\tCombine input records=0\n\t\tCombine output records=0\n\t\tReduce input groups=2\n\t\tReduce shuffle bytes=28\n\t\tReduce input records=2\n\t\tReduce output records=0\n\t\tSpilled Records=4\n\t\tShuffled Maps =1\n\t\tFailed Shuffles=0\n\t\tMerged Map outputs=1\n\t\tGC time elapsed (ms)=136\n\t\tCPU time spent (ms)=1050\n\t\tPhysical memory (bytes) snapshot=503672832\n\t\tVirtual memory (bytes) snapshot=5563736064\n\t\tTotal committed heap usage (bytes)=445644800\n\tShuffle Errors\n\t\tBAD_ID=0\n\t\tCONNECTION=0\n\t\tIO_ERROR=0\n\t\tWRONG_LENGTH=0\n\t\tWRONG_MAP=0\n\t\tWRONG_REDUCE=0\n\tFile Input Format Counters \n\t\tBytes Read=118\n\tFile Output Format Counters \n\t\tBytes Written=97\nJob Finished in 21.452 seconds\nEstimated value of Pi is 3.14800000000000000000\n```\n\n\u3084\u3063\u305f\uff01\n\n\u6b63\u76f4\u3001\u624b\u3067\u8a2d\u5b9a\u3059\u308b\u306e\u306f\u3064\u3089\u3044\u306e\u3067\u3001\u7d20\u76f4\u306bClouderaManager\u3084Ambari\u3092\u5229\u7528\u3057\u305f\u65b9\u304c\u826f\u3044\u3068\u601d\u308f\u308c\u308b\u3002\n\u4e00\u5ea6\u306f\u624b\u3067\u3084\u3063\u3066\u304a\u304f\u3068\u308f\u304b\u3063\u305f\u6c17\u306b\u306a\u308b\u3068\u3044\u3046\u5229\u70b9\u306f\u3042\u308b\u3002\u6570\u5b66\u306e\u5b9a\u7406\u306e\u8a3c\u660e\u307f\u305f\u3044\u306a\u3082\u306e\u304b\u3002\u3002\u3002\n\n# 2016/03/25 \u8ffd\u8a18\n\n\u4e00\u90e8\u74b0\u5883\u3067hdfs\u30b3\u30de\u30f3\u30c9\u5b9f\u884c\u6642\u306b\u4ee5\u4e0b\u306e\u3088\u3046\u306a\u30a8\u30e9\u30fc\u304c\u51fa\u308b\u3053\u3068\u304c\u3042\u3063\u305f\u3002\n\n```\n16/03/25 12:09:10 WARN security.UserGroupInformation: Exception encountered while running the renewal command. Aborting renew thread. ExitCodeException exitCode=1: kinit: Ticket expired while renewing credentials\n```\n\n\u3053\u308c\u306f\u3001hdfs\u30b3\u30de\u30f3\u30c9\u304c\u5185\u90e8\u3067Kerberos\u306e\u30c1\u30b1\u30c3\u30c8\u306erenew\u3092\u3057\u3088\u3046\u3068\u3057\u3066\u5931\u6557\u3057\u3066\u3044\u308b\u305f\u3081\u306b\u51fa\u529b\u3055\u308c\u3066\u3044\u308b\u3002\n\n\u76f4\u63a5\u7684\u306b\u78ba\u8a8d\u3059\u308b\u306b\u306f\u3001`kinit -R`\u3092\u5b9f\u884c\u3057\u3066\u307f\u308b\u3002\n\n```\n$ kinit -R\nkinit: Ticket expired while renewing credentials\n```\n\n\u539f\u56e0\u3068\u3057\u3066\u306f\u3001Kerberos\u5074\u3067\u4f5c\u6210\u3057\u305f\u30d7\u30ea\u30f3\u30b7\u30d1\u30eb\u306emaxrenewlife\u304c\u30c7\u30d5\u30a9\u30eb\u30c8\u306e0\u3068\u306a\u3063\u3066\u3044\u3066\u3001renew\u3057\u3088\u3046\u3068\u3057\u3066\u3082\u4f38\u3070\u305b\u306a\u304f\u306a\u3063\u3066\u3044\u308b\u3053\u3068\u304c\u591a\u3044\u3002\n\n\u3053\u306e\u72b6\u614b\u306b\u306a\u3063\u3066\u3044\u308b\u3053\u3068\u3092\u78ba\u8a8d\u3059\u308b\u306b\u306f\u3001kadmin\u3067KDC\u306b\u63a5\u7d9a\u3057\u3066\u4ee5\u4e0b\u306e\u30b3\u30de\u30f3\u30c9\u3092\u5b9f\u884c\u3059\u308b\u3002\n\n```\nkadmin.local:  getprinc alice/locke.example.com@EXAMPLE.COM\nPrincipal: alice/locke.example.com@EXAMPLE.COM\nExpiration date: [never]\nLast password change: Tue Mar 15 17:09:55 JST 2016\nPassword expiration date: [none]\nMaximum ticket life: 1 day 00:00:00\nMaximum renewable life: 0 days 00:00:00   \u2605\u3053\u3053\u304c0 days\u306b\u306a\u3063\u3066\u3044\u308b\u304b\u3069\u3046\u304b\u3002\nLast modified: Tue Mar 15 17:09:55 JST 2016 (root/admin@EXAMPLE.COM)\nLast successful authentication: [never]\nLast failed authentication: [never]\nFailed password attempts: 0\nNumber of keys: 3\nKey: vno 1, aes256-cts-hmac-sha1-96, no salt\nKey: vno 1, aes128-cts-hmac-sha1-96, no salt\nKey: vno 1, arcfour-hmac, no salt\nMKey: vno 1\nAttributes:\nPolicy: [none]\n```\n\nmodprinc\u3067\u30d7\u30ea\u30f3\u30b7\u30d1\u30eb\u306emaxrenewlife\u3092\u5909\u66f4\u3067\u304d\u308b\u3002\n\n```\nkadmin.local:   modprinc -maxrenewlife 1week\n```\n\n\u306a\u304a\u3001\u4eca\u5f8c\u65b0\u3057\u304f\u4f5c\u3089\u308c\u308b\u30d7\u30ea\u30f3\u30b7\u30d1\u30eb\u306b\u5bfe\u3057\u3066\u306e\u30c7\u30d5\u30a9\u30eb\u30c8\u8a2d\u5b9a\u3092\u5909\u66f4\u3059\u308b\u5834\u5408\u3001krbtgt/EXAMPLE.COM@EXAMPLE.COM\u306emaxrenewlife\u3092\u5909\u66f4\u3057\u3066\u304a\u304f\u3068\u826f\u3044\u3089\u3057\u3044\u3002\n\n\u4ee5\u4e0b\u306e\u30da\u30fc\u30b8\u304c\u53c2\u8003\u306b\u306a\u3063\u305f\u3002\nhttp://championofcyrodiil.blogspot.jp/2014/01/kinit-ticket-expired-while-renewing.html\n"}