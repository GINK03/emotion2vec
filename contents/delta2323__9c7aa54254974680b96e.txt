{"context": " More than 1 year has passed since last update.\n\nIntroduction\nThanks to many contributors, Chainer has been developed greatly. But as we review the PRs, we noticed there are limited guidelines on how to test the implementation. So those who tries to send PR must make test cases by imitating the existing test cases or read the code directly. In this article, I will briefly review the testing modules in Chainer and CuPy. As Chainer's testing modules are subset of CuPy's ones, I will focus on CuPy.\nCuPy's (resp. Chainer's) testing tools are located in cupy.testing (resp. chainer.testing) and consists of the following modules (* indicates that Chainer also has this module in chainer.testing) :\n\narray\nattr (*)\ncondition (*)\nhelper\nhypothesis\nparameterized (*)\n\nNote that this article is based on v1.5.0.3\n\narray module\ncupy.testing.array module implements NumPy-like assertion functions. These functions accept both NumPy and CuPy ndarrays. The implemented assertions are as follows:\n\nassert_arrays_almost_equal_nulp\nassert_array_max_ulp\nassert_array_equal\nassert_array_list_equal\nassert_array_less\n\nThese assertions are used in NumPy-CuPy consistency check decorators  explained in helper module. As we use this decorators more often, we do not expect testers use these assertions directly (of course we can  choose to use them).\n\nattr module\ncupy.testing.attr contains several decorators that enable/disable test cases and test fixtures1.\n\n\n@attr.gpu specifies that the test uses single GPU.\n\n@attr.multi_gpu(N) specifies this test requires N GPUs. @attr.gpu is equivalent to @attr.multi_gpu(1)\n\n\n@attr.cudnn specifies this test uses cuDNN module.\n\nFor more details, please see the testing guideline.\n\nhypothesis module\ncupy.testing.hypothesis module contains hypothesis testing tools, to test statistical behaviors. For now, it has simple goodness-of-fit test with Peason's Chi-squared test only. We use it for testing random generator of ints like cupy.randint or cupy.random_integers.\n\nparameterized module\ncupy.testing.parameterized module offers the standard way of parameterized tests. Basic usage is as follows.\n\nusage_of_parameterized_module.py\n@testing.parameterize(\n    {'height': 150, 'weight': 45},\n    {'height': 180, 'weight': 80})\nclass BMITest(unittest.TestCase):\n    def test_bmi(self):\n        self.assertLessEqual(\n             calculate_bmi(self.height, self.weight), 25.0)\n\n\nThis test calculates BMI(Body Mass Index) based on the height and weight and checks if it is less than the threshold. height and weight are parameters in this test. We can access them as attributes of the test case.\nparameterized decorator automatically generates the test case for each set of parameters. The naming convention of generated test cases is <original class name>_param_<n> where <n> is the index number of the set parameters. In this example, BMITest_param_0 and BMITest_param_1 are generated. Note that original test case (BMITest in the example) is not executed.\nWe have an utility that makes the product set of parameter set. For example, testing.product({\u2018a': [1, 2]}, {\u2018b\u2019: [3, 4]}) is equivalent to [{\u2018a\u2019: 1, \u2018b\u2019: 3}, {\u2018a\u2019: 1, \u2018b\u2019: 4}, {\u2018a\u2019: 2, \u2018b\u2019: 3}, {\u2018a\u2019: 2, \u2018b\u2019: 4}]\n\ncondition module\nDecorators in cupy.testing.condition module customize the condition test fixtures are regarded as \"success\". For now, we have decorators for running test fixtures multiple times.\n\n\n@attr.retry(N) tries the decorated fixture N times and considers success if at least one of the trial is successful.\n\n@attr.repeat(N) tries the decorated fixture N times and considers success if all trials are successful.\n\nDecorators abort the trials if we can judge the final result before we do execute remaining trials. If the decorated test fixture is considered failed, it shows the number of failed and successful trials and error message of first failed trial.\n\nhelper module\ncupy.testing.helper consists of some utility decorators for test cases and fixtures. Currently there are two types of decorators, namely, NumPy-CuPy consistency check and parameterized dtype test2\n\nNumPy-CuPy consistency check\ncupy.ndarray is designed so that most of its API (method name and arguments) is identical to corresponding ones in numpy.ndarray.  NumPy-CuPy consistency check decorators offer easy way to check the consistency of these APIs.\nTake testing.numpy_cupy_allclose decorator for example. The typical usage is as follows (we modified slightly from the original code):\n\nusage_of_numpy_cupy_consistency_decorator.py\n@testing.gpu\nclass TestFoo(unittest.TestCase):\n\n    @testing.numpy_cupy_allclose()\n    def test_mean_all(self, xp):\n        a = testing.shaped_arange((2, 3), xp)\n        return a.mean()\n\n\nThis test fixture checks numpy.mean() and cupy.mean() should be the same result. xp is an additional argument inserted by the decorator. It takes either numpy or cupy. Decorated function is required to return the same value3 even if xp is numpy or cupy. We can change the argument name from xp by name argument.\n\nParameterized dtype test\nThis kind of decorators makes decorated test fixture parameterized with respect to dtype. Of course, we can do the parameterized test with respect to dtype with @testing.parameterized decorator. But parameterized dtype test decorators offer easier way. Let's look at the example in CuPy test code.\n\ntests/cupy_tests/io_tests/test_npz.py\n@testing.gpu\nclass TestNpz(unittest.TestCase):\n...\n    @testing.for_all_dtypes()\n    def test_pickle(self, dtype):\n        a = testing.shaped_arange((2, 3, 4), dtype=dtype)\n        s = six.moves.cPickle.dumps(a)\n        b = six.moves.cPickle.loads(s)\n        testing.assert_array_equal(a, b)\n\n\nThis test fixture checks if cPickle successfully reconstructs cupy.ndarray for various dtypes. dtype is an argument inserted by the decorator as with the NumPy-CuPy consistency check decorator's case. We can change the argument name by name argument of the decorator.\nHere is the correspondence table of decorators and dtypes to be checked.\n\n\n\n\nbool\nfloat[16, 32, 64]\nint[8, 16, 32, 64]\nuint[8, 16, 32, 64]\n\n\n\n\nfor_all_dtypes\n\u25cb\n\u25cb\n\u25cb\n\u25cb\n\n\nfor_float_dtypes\n\n\u25cb\n\n\n\n\nfor_signed_dtypes\n\n\n\u25cb\n\n\n\nfor_unsigned_dtypes\n\n\n\n\u25cb\n\n\nfor_int_dtypes\n\u25cb\n\n\u25cb\n\u25cb\n\n\n\nnumpy.bool_ and numpy.float16 are optional. If no_float16 (resp. no_bool) option set True, numpy.float16 (resp. numpy.bool_ ) is disabled.\n\ncombinatorial dtype test\nSome test fixtures require parameterization with respect to the product of dtypes. Decorators named as for_***_dtypes_combination  offer this functionality.\n\nusage_of_combinatorial_dtype_test.py\n@testing.gpu\nclass TestFoo(unittest.TestCase):\n    @testing.for_all_dtypes_combination(dtypes=['a_type', 'b_type'], full=True)\n    def test_foo(self, dtype):\n         a = cupy.arange(10, dtype=a_type)\n         b = cupy.arange(20, dtype=b_type)\n         # (some assertions with a and b)\n\n\nLet N be the number of dtypes and M be the number of values each dtype can take. This decorator exexutes N**M tests if full option is set True. In some case, this can be costly, so we only check selected M tests only if full is False. If full argument is not specified, the default behavior depends on the environment variable CUPY_TEST_FULL_COMBINATION.\nWe can (and in most case do) use both of NumPy-CuPy consistency check decorator and Parameterized dtype test decorator simultaneously. Here is the example of unittests for cupy.mean\n\ntests/cupy_tests/statics_tests/test_meanvar.py\n    @testing.for_all_dtypes()\n    @testing.numpy_cupy_allclose()\n    def test_mean_all(self, xp, dtype):\n        a = testing.shaped_arange((2, 3), xp, dtype)\n        return a.mean()\n\n\nNote that for implementation reason, Parameterized dtype decorators must be preceded by NumPy-CuPy consistency check decorators.\n\nConclusion\nAs we have seen in this article, Chainer and CuPy have various kind of utility that make the test cases easier. We briefly review the function and basic usage of them. I hope this article helps to promote the user to contribute to Chainer.\nAfter we finish writing the article, I noticed that I forget to write about chainer.gradient_check, which is one of the most important testing tool in Chainer. I will write it in another article (or I hope someone write about it).\nThis article resolves issue #714 :)\n\n\n\n\nIn this article, test case denotes the subclass of unittest.TestCase, while test fixture the method of the test case.\u00a0\u21a9\n\n\nThese names are not official.\u00a0\u21a9\n\n\nOf course, the type of array module(numpy/cupy) is different the decorator checks cupy.asnumpy(cupy_result) is equivalent to numpy's result.\u00a0\u21a9\n\n\n\n# Introduction\n\nThanks to many contributors, [Chainer](http://chainer.org) has been developed greatly. But as we review the PRs, we noticed there are limited guidelines on how to test the implementation. So those who tries to send PR must make test cases by imitating the existing test cases or read the code directly. In this article, I will briefly review the testing modules in Chainer and CuPy. As Chainer's testing modules are subset of CuPy's ones, I will focus on CuPy.\n\nCuPy's (resp. Chainer's) testing tools are located in `cupy.testing` (resp. `chainer.testing`) and consists of the following modules (* indicates that Chainer also has this module in `chainer.testing`) :\n\n- array\n- attr (*)\n- condition (*)\n- helper\n- hypothesis\n- parameterized (*)\n\nNote that this article is based on v1.5.0.3\n\n# array module\n\n`cupy.testing.array` module implements NumPy-like assertion functions. These functions accept both NumPy and CuPy ndarrays. The implemented assertions are as follows:\n\n* assert_arrays_almost_equal_nulp\n* assert_array_max_ulp\n* assert_array_equal\n* assert_array_list_equal\n* assert_array_less\n\nThese assertions are used in **NumPy-CuPy consistency check decorators**  explained in `helper` module. As we use this decorators more often, we do not expect testers use these assertions directly (of course we can  choose to use them).\n\n# attr module\n\n`cupy.testing.attr` contains several decorators that enable/disable test cases and test fixtures[^1].\n\n* `@attr.gpu` specifies that the test uses single GPU.\n* `@attr.multi_gpu(N)` specifies this test requires N GPUs. `@attr.gpu` is equivalent to `@attr.multi_gpu(1)`\n* `@attr.cudnn` specifies this test uses cuDNN module.\n\nFor more details, please see the [testing guideline](http://docs.chainer.org/en/stable/contribution.html#testing-guidelines).\n\n[^1]: In this article, **test case** denotes the subclass of `unittest.TestCase`, while **test fixture** the method of the test case.\n\n# hypothesis module\n\n`cupy.testing.hypothesis` module contains hypothesis testing tools, to test statistical behaviors. For now, it has simple goodness-of-fit test with Peason's Chi-squared test only. We use it for testing random generator of ints like `cupy.randint` or `cupy.random_integers`.\n\n# parameterized module\n\n`cupy.testing.parameterized` module offers the standard way of parameterized tests. Basic usage is as follows.\n\n```py:usage_of_parameterized_module.py\n@testing.parameterize(\n    {'height': 150, 'weight': 45},\n    {'height': 180, 'weight': 80})\nclass BMITest(unittest.TestCase):\n    def test_bmi(self):\n        self.assertLessEqual(\n             calculate_bmi(self.height, self.weight), 25.0)\n```\n\nThis test calculates BMI(Body Mass Index) based on the height and weight and checks if it is less than the threshold. `height` and `weight` are parameters in this test. We can access them as attributes of the test case.\n\n`parameterized` decorator automatically generates the test case for each set of parameters. The naming convention of generated test cases is `<original class name>_param_<n>` where `<n>` is the index number of the set parameters. In this example, `BMITest_param_0` and `BMITest_param_1` are generated. Note that original test case (`BMITest` in the example) is not executed.\n\nWe have an utility that makes the product set of parameter set. For example, `testing.product({\u2018a': [1, 2]}, {\u2018b\u2019: [3, 4]})` is equivalent to `[{\u2018a\u2019: 1, \u2018b\u2019: 3}, {\u2018a\u2019: 1, \u2018b\u2019: 4}, {\u2018a\u2019: 2, \u2018b\u2019: 3}, {\u2018a\u2019: 2, \u2018b\u2019: 4}]`\n\n# condition module\n\nDecorators in `cupy.testing.condition` module customize the condition test fixtures are regarded as \"success\". For now, we have decorators for running test fixtures multiple times.\n\n* `@attr.retry(N)` tries the decorated fixture N times and considers success if **at least one** of the trial is successful.\n* `@attr.repeat(N)` tries the decorated fixture N times and considers success if **all** trials are successful.\n\nDecorators abort the trials if we can judge the final result before we do execute remaining trials. If the decorated test fixture is considered failed, it shows the number of failed and successful trials and error message of first failed trial.\n\n# helper module\n\n`cupy.testing.helper` consists of some utility decorators for test cases and fixtures. Currently there are two types of decorators, namely, **NumPy-CuPy consistency check** and **parameterized dtype test**[^2]\n\n[^2]: These names are not official.\n\n### NumPy-CuPy consistency check\n\n`cupy.ndarray` is designed so that most of its API (method name and arguments) is identical to corresponding ones in `numpy.ndarray`.  NumPy-CuPy consistency check decorators offer easy way to check the consistency of these APIs.\n\nTake `testing.numpy_cupy_allclose` decorator for example. The typical usage is as follows (we modified slightly from the original code):\n\n```py:usage_of_numpy_cupy_consistency_decorator.py\n@testing.gpu\nclass TestFoo(unittest.TestCase):\n\n    @testing.numpy_cupy_allclose()\n    def test_mean_all(self, xp):\n        a = testing.shaped_arange((2, 3), xp)\n        return a.mean()\n```\n\nThis test fixture checks `numpy.mean()` and `cupy.mean()` should be the same result. `xp` is an additional argument inserted by the decorator. It takes either `numpy` or `cupy`. Decorated function is required to return the same value[^3] even if `xp` is `numpy` or `cupy`. We can change the argument name from `xp` by `name` argument.\n\n[^3]: Of course, the type of array module(`numpy`/`cupy`) is different the decorator checks `cupy.asnumpy(cupy_result)` is equivalent to `numpy`'s result.\n\n### Parameterized dtype test\n\nThis kind of decorators makes decorated test fixture parameterized with respect to dtype. Of course, we can do the parameterized test with respect to dtype with `@testing.parameterized` decorator. But parameterized dtype test decorators offer easier way. Let's look at the example in CuPy test code.\n\n```py:tests/cupy_tests/io_tests/test_npz.py\n@testing.gpu\nclass TestNpz(unittest.TestCase):\n...\n    @testing.for_all_dtypes()\n    def test_pickle(self, dtype):\n        a = testing.shaped_arange((2, 3, 4), dtype=dtype)\n        s = six.moves.cPickle.dumps(a)\n        b = six.moves.cPickle.loads(s)\n        testing.assert_array_equal(a, b)\n```\n\nThis test fixture checks if `cPickle` successfully reconstructs `cupy.ndarray` for various dtypes. `dtype` is an argument inserted by the decorator as with the NumPy-CuPy consistency check decorator's case. We can change the argument name by `name` argument of the decorator.\n\nHere is the correspondence table of decorators and dtypes to be checked.\n \n||bool|float[16, 32, 64]|int[8, 16, 32, 64]|uint[8, 16, 32, 64]|\n|-----|:-----:|:-----:|:-----:|:-----:|:-----:|\n|`for_all_dtypes`|\u25cb|\u25cb|\u25cb|\u25cb|\n|`for_float_dtypes`||\u25cb|||\n|`for_signed_dtypes`|||\u25cb||\n|`for_unsigned_dtypes`||||\u25cb|\n|`for_int_dtypes`|\u25cb||\u25cb|\u25cb|\n\n`numpy.bool_` and `numpy.float16` are optional. If `no_float16` (resp. `no_bool`) option set `True`, `numpy.float16` (resp. `numpy.bool_` ) is disabled.\n\n##### combinatorial dtype test\n\nSome test fixtures require parameterization with respect to the **product** of dtypes. Decorators named as `for_***_dtypes_combination`  offer this functionality.\n\n```py:usage_of_combinatorial_dtype_test.py\n@testing.gpu\nclass TestFoo(unittest.TestCase):\n    @testing.for_all_dtypes_combination(dtypes=['a_type', 'b_type'], full=True)\n    def test_foo(self, dtype):\n         a = cupy.arange(10, dtype=a_type)\n         b = cupy.arange(20, dtype=b_type)\n         # (some assertions with a and b)\n```\n\nLet N be the number of dtypes and M be the number of values each dtype can take. This decorator exexutes N**M tests if `full` option is set `True`. In some case, this can be costly, so we only check selected M tests only if `full` is `False`. If `full` argument is not specified, the default behavior depends on the environment variable `CUPY_TEST_FULL_COMBINATION`.\n\nWe can (and in most case do) use both of NumPy-CuPy consistency check decorator and Parameterized dtype test decorator simultaneously. Here is the example of unittests for `cupy.mean`\n\n```py:tests/cupy_tests/statics_tests/test_meanvar.py\n    @testing.for_all_dtypes()\n    @testing.numpy_cupy_allclose()\n    def test_mean_all(self, xp, dtype):\n        a = testing.shaped_arange((2, 3), xp, dtype)\n        return a.mean()\n```\nNote that for implementation reason, Parameterized dtype decorators must be preceded by NumPy-CuPy consistency check decorators.\n\n# Conclusion\n\nAs we have seen in this article, Chainer and CuPy have various kind of utility that make the test cases easier. We briefly review the function and basic usage of them. I hope this article helps to promote the user to contribute to Chainer.\n\nAfter we finish writing the article, I noticed that I forget to write about `chainer.gradient_check`, which is one of the most important testing tool in Chainer. I will write it in another article (or I hope someone write about it).\n\nThis article resolves issue [#714](https://github.com/pfnet/chainer/issues/714) :)\n", "tags": ["Chainer", "MachineLearning", "DeepLearning"]}