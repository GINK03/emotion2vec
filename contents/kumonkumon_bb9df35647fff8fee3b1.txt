{"context": "(\u76ee\u6b21\u306f\u3053\u3061\u3089)\n\n\u306f\u3058\u3081\u306b\n\u524d\u56de\u306e\u8a18\u4e8b\u3067\u306f\u3001\u30d5\u30a3\u30eb\u30bf\u3092\u56fa\u5b9a\u3057\u305f\u7573\u307f\u8fbc\u307f\u30cb\u30e5\u30fc\u30e9\u30eb\u30cd\u30c3\u30c8\u30ef\u30fc\u30af\u306b\u30c9\u30ed\u30c3\u30d7\u30a2\u30a6\u30c8\u5c64\u3092\u8ffd\u52a0\u3057\u305f\u3002\u4eca\u56de\u306f\u3001Prewitte filter\u3067\u56fa\u5b9a\u3057\u3066\u3044\u305f\u7573\u307f\u8fbc\u307f\u5c64\u306e\u30a6\u30a7\u30a4\u30c8\u3082\u5b66\u7fd2\u306b\u3088\u3063\u3066\u63a8\u5b9a\u3059\u308b\u3088\u3046\u306b\u3057\u3066\u307f\u308b\u3002\n\n\u7573\u307f\u8fbc\u307f\u5c64\u306e\u30d1\u30e9\u30e1\u30fc\u30bf\u63a8\u5b9a\n\u30d5\u30a3\u30eb\u30bf\u3092\u56fa\u5b9a\u3057\u305f\u7573\u307f\u8fbc\u307f\u30cb\u30e5\u30fc\u30e9\u30eb\u30cd\u30c3\u30c8\u30ef\u30fc\u30af\u3092\u3001\u30d5\u30a3\u30eb\u30bf\u306b\u3064\u3044\u3066\u3082\u63a8\u5b9a\u3059\u308b\uff08\u5b66\u7fd2\u3059\u308b\uff09\u524d\u63d0\u3067\u5b9f\u88c5\u3057\u3066\u3044\u305f\u305f\u3081\u3001\u62e1\u5f35\u306f\u5bb9\u6613\u3002\u5177\u4f53\u7684\u306b\u306f\u3001\u30a6\u30a7\u30a4\u30c8\uff08\u30d5\u30a3\u30eb\u30bf\uff09\u3068\u30d0\u30a4\u30a2\u30b9\u3092\u5b9a\u6570\u304b\u3089\u5909\u6570\u306b\u5909\u66f4\u3059\u308b\u3060\u3051\u3002\n\n\n\u30b3\u30fc\u30c9\nmnist_cnn_sl.py\n\nmnist_cnn_sl.py\nfrom helper import *\n\nIMAGE_WIDTH = 28\nIMAGE_HEIGHT = 28\nIMAGE_SIZE = IMAGE_WIDTH * IMAGE_HEIGHT\nCATEGORY_NUM = 10\nLEARNING_RATE = 0.01\nFILTER_SIZE = 5\nFILTER_NUM = 32\nFEATURE_DIM = 1024\nKEEP_PROB = 0.5\nTRAINING_LOOP = 20000\nBATCH_SIZE = 100\nSUMMARY_DIR = 'log_cnn_sl'\nSUMMARY_INTERVAL = 100\n\nmnist = input_data.read_data_sets('data', one_hot=True)\n\nwith tf.Graph().as_default():\n    with tf.name_scope('input'):\n        y_ = tf.placeholder(tf.float32, [None, CATEGORY_NUM], name='labels')\n        x = tf.placeholder(tf.float32, [None, IMAGE_SIZE], name='input_images')\n\n    with tf.name_scope('convolution'):\n        W_conv = weight_variable([FILTER_SIZE, FILTER_SIZE, 1, FILTER_NUM], name='weight_conv')\n        b_conv = bias_variable([FILTER_NUM], name='bias_conv')\n        x_image = tf.reshape(x, [-1, IMAGE_WIDTH, IMAGE_HEIGHT, 1])\n        h_conv = tf.nn.relu(conv2d(x_image, W_conv) + b_conv)\n\n    with tf.name_scope('pooling'):\n        scale = 1 / 4.0\n        h_pool = max_pool_2x2(h_conv)\n\n    with tf.name_scope('fully-connected'):\n        W_fc = weight_variable([int(IMAGE_SIZE * scale * FILTER_NUM), FEATURE_DIM], name='weight_fc')\n        b_fc = bias_variable([FEATURE_DIM], name='bias_fc')\n        h_pool_flat = tf.reshape(h_pool, [-1, int(IMAGE_SIZE * scale * FILTER_NUM)])\n        h_fc = tf.nn.relu(tf.matmul(h_pool_flat, W_fc) + b_fc)\n\n    with tf.name_scope('dropout'):\n        keep_prob = tf.placeholder(tf.float32)\n        h_drop = tf.nn.dropout(h_fc, keep_prob)\n\n    with tf.name_scope('readout'):\n        W = weight_variable([FEATURE_DIM, CATEGORY_NUM], name='weight')\n        b = bias_variable([CATEGORY_NUM], name='bias')\n        y = tf.nn.softmax(tf.matmul(h_drop, W) + b)\n\n    with tf.name_scope('optimize'):\n        cross_entropy = tf.reduce_mean(-tf.reduce_sum(y_ * tf.log(y), reduction_indices=[1]))\n        train_step = tf.train.GradientDescentOptimizer(LEARNING_RATE).minimize(cross_entropy)\n\n    with tf.Session() as sess:\n        train_writer = tf.train.SummaryWriter(SUMMARY_DIR + '/train', sess.graph)\n        test_writer = tf.train.SummaryWriter(SUMMARY_DIR + '/test', sess.graph)\n\n        correct_prediction = tf.equal(tf.argmax(y, 1), tf.argmax(y_, 1))\n        accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))\n        train_accuracy_summary = tf.scalar_summary('accuracy', accuracy)\n        test_accuracy_summary = tf.scalar_summary('accuracy', accuracy)\n\n        sess.run(tf.initialize_all_variables())\n        for i in range(TRAINING_LOOP + 1):\n            batch = mnist.train.next_batch(BATCH_SIZE)\n            sess.run(train_step, {x: batch[0], y_: batch[1], keep_prob: KEEP_PROB})\n\n            if i % SUMMARY_INTERVAL == 0:\n                print('step %d' % i)\n                summary = sess.run(tf.merge_summary([train_accuracy_summary]), {x: batch[0], y_: batch[1], keep_prob: 1.0})\n                train_writer.add_summary(summary, i)\n                summary = sess.run(tf.merge_summary([test_accuracy_summary]), {x: mnist.test.images, y_: mnist.test.labels, keep_prob: 1.0})\n                test_writer.add_summary(summary, i)\n\n\n\n\u30b3\u30fc\u30c9\u306e\u8aac\u660e\n\u5909\u66f4\u70b9\u3092\u3002\n\n\u7573\u307f\u8fbc\u307f\u5c64\n\u5909\u66f4\u306f\u3053\u3053\u3060\u3051\u3002W_conv\u3068b_conv\u304c\u5b9a\u6570\u304b\u3089\u5909\u6570\u306b\u306a\u3063\u3066\u3044\u308b\u3060\u3051\u3002\n    with tf.name_scope('convolution'):\n        W_conv = weight_variable([FILTER_SIZE, FILTER_SIZE, 1, FILTER_NUM], name='weight_conv')\n        b_conv = bias_variable([FILTER_NUM], name='bias_conv')\n        x_image = tf.reshape(x, [-1, IMAGE_WIDTH, IMAGE_HEIGHT, 1])\n        h_conv = tf.nn.relu(conv2d(x_image, W_conv) + b_conv)\n\n\n\u7d50\u679c\n\u30c6\u30b9\u30c8\u30c7\u30fc\u30bf\uff08\u9752\u7dda\uff09\u3067\u306e\u8b58\u5225\u7387\u306f\u300199.1%\u7a0b\u5ea6\u3002\u306a\u3093\u306899%\u5927\u53f0\u306b\u3002\n\n\n\u3042\u3068\u304c\u304d\n\u4eca\u56de\u306f\u3001\u56fa\u5b9a\u3057\u3066\u3044\u305f\u7573\u307f\u8fbc\u307f\u5c64\u306e\u30a6\u30a7\u30a4\u30c8\u3082\u5b66\u7fd2\u306b\u3088\u3063\u3066\u63a8\u5b9a\u3059\u308b\u3088\u3046\u306b\u3057\u3066\u307f\u307e\u3057\u305f\u3002\u6b21\u56de\u306e\u8a18\u4e8b\u3067\u306f\u3001\u3088\u308a\u30c7\u30a3\u30fc\u30d7\u30e9\u30fc\u30cb\u30f3\u30b0\u3089\u3057\u304f\u3057\u3066\u307f\u307e\u3059\u3002\u3068\u3044\u3063\u3066\u3082\u3001TensorFlow\u306eTutorial\u306eDeep MNIST for Experts\u307b\u307c\u305d\u306e\u3082\u306e\u306a\u3093\u3067\u3059\u3051\u3069\u3002\n([\u76ee\u6b21\u306f\u3053\u3061\u3089](http://qiita.com/kumonkumon/items/6fd05963df92e9eec8c0))\n\n#\u306f\u3058\u3081\u306b\n[\u524d\u56de\u306e\u8a18\u4e8b](http://qiita.com/kumonkumon/items/6fab067bf06da9feaa9f)\u3067\u306f\u3001\u30d5\u30a3\u30eb\u30bf\u3092\u56fa\u5b9a\u3057\u305f\u7573\u307f\u8fbc\u307f\u30cb\u30e5\u30fc\u30e9\u30eb\u30cd\u30c3\u30c8\u30ef\u30fc\u30af\u306b\u30c9\u30ed\u30c3\u30d7\u30a2\u30a6\u30c8\u5c64\u3092\u8ffd\u52a0\u3057\u305f\u3002\u4eca\u56de\u306f\u3001Prewitte filter\u3067\u56fa\u5b9a\u3057\u3066\u3044\u305f\u7573\u307f\u8fbc\u307f\u5c64\u306e\u30a6\u30a7\u30a4\u30c8\u3082\u5b66\u7fd2\u306b\u3088\u3063\u3066\u63a8\u5b9a\u3059\u308b\u3088\u3046\u306b\u3057\u3066\u307f\u308b\u3002\n\n#\u7573\u307f\u8fbc\u307f\u5c64\u306e\u30d1\u30e9\u30e1\u30fc\u30bf\u63a8\u5b9a\n\u30d5\u30a3\u30eb\u30bf\u3092\u56fa\u5b9a\u3057\u305f\u7573\u307f\u8fbc\u307f\u30cb\u30e5\u30fc\u30e9\u30eb\u30cd\u30c3\u30c8\u30ef\u30fc\u30af\u3092\u3001\u30d5\u30a3\u30eb\u30bf\u306b\u3064\u3044\u3066\u3082\u63a8\u5b9a\u3059\u308b\uff08\u5b66\u7fd2\u3059\u308b\uff09\u524d\u63d0\u3067\u5b9f\u88c5\u3057\u3066\u3044\u305f\u305f\u3081\u3001\u62e1\u5f35\u306f\u5bb9\u6613\u3002\u5177\u4f53\u7684\u306b\u306f\u3001\u30a6\u30a7\u30a4\u30c8\uff08\u30d5\u30a3\u30eb\u30bf\uff09\u3068\u30d0\u30a4\u30a2\u30b9\u3092\u5b9a\u6570\u304b\u3089\u5909\u6570\u306b\u5909\u66f4\u3059\u308b\u3060\u3051\u3002\n\n![mnist_cnn_sl](https://qiita-image-store.s3.amazonaws.com/0/127038/5585c0c1-f79f-25f5-87ba-660d03f11e8b.png)\n\n##\u30b3\u30fc\u30c9\n[mnist_cnn_sl.py](https://github.com/kumon/DeepLearningExercise/blob/master/src/tensorflow/mnist_cnn_sl.py)\n\n```py:mnist_cnn_sl.py\nfrom helper import *\n\nIMAGE_WIDTH = 28\nIMAGE_HEIGHT = 28\nIMAGE_SIZE = IMAGE_WIDTH * IMAGE_HEIGHT\nCATEGORY_NUM = 10\nLEARNING_RATE = 0.01\nFILTER_SIZE = 5\nFILTER_NUM = 32\nFEATURE_DIM = 1024\nKEEP_PROB = 0.5\nTRAINING_LOOP = 20000\nBATCH_SIZE = 100\nSUMMARY_DIR = 'log_cnn_sl'\nSUMMARY_INTERVAL = 100\n\nmnist = input_data.read_data_sets('data', one_hot=True)\n\nwith tf.Graph().as_default():\n    with tf.name_scope('input'):\n        y_ = tf.placeholder(tf.float32, [None, CATEGORY_NUM], name='labels')\n        x = tf.placeholder(tf.float32, [None, IMAGE_SIZE], name='input_images')\n\n    with tf.name_scope('convolution'):\n        W_conv = weight_variable([FILTER_SIZE, FILTER_SIZE, 1, FILTER_NUM], name='weight_conv')\n        b_conv = bias_variable([FILTER_NUM], name='bias_conv')\n        x_image = tf.reshape(x, [-1, IMAGE_WIDTH, IMAGE_HEIGHT, 1])\n        h_conv = tf.nn.relu(conv2d(x_image, W_conv) + b_conv)\n\n    with tf.name_scope('pooling'):\n        scale = 1 / 4.0\n        h_pool = max_pool_2x2(h_conv)\n\n    with tf.name_scope('fully-connected'):\n        W_fc = weight_variable([int(IMAGE_SIZE * scale * FILTER_NUM), FEATURE_DIM], name='weight_fc')\n        b_fc = bias_variable([FEATURE_DIM], name='bias_fc')\n        h_pool_flat = tf.reshape(h_pool, [-1, int(IMAGE_SIZE * scale * FILTER_NUM)])\n        h_fc = tf.nn.relu(tf.matmul(h_pool_flat, W_fc) + b_fc)\n\n    with tf.name_scope('dropout'):\n        keep_prob = tf.placeholder(tf.float32)\n        h_drop = tf.nn.dropout(h_fc, keep_prob)\n\n    with tf.name_scope('readout'):\n        W = weight_variable([FEATURE_DIM, CATEGORY_NUM], name='weight')\n        b = bias_variable([CATEGORY_NUM], name='bias')\n        y = tf.nn.softmax(tf.matmul(h_drop, W) + b)\n\n    with tf.name_scope('optimize'):\n        cross_entropy = tf.reduce_mean(-tf.reduce_sum(y_ * tf.log(y), reduction_indices=[1]))\n        train_step = tf.train.GradientDescentOptimizer(LEARNING_RATE).minimize(cross_entropy)\n\n    with tf.Session() as sess:\n        train_writer = tf.train.SummaryWriter(SUMMARY_DIR + '/train', sess.graph)\n        test_writer = tf.train.SummaryWriter(SUMMARY_DIR + '/test', sess.graph)\n\n        correct_prediction = tf.equal(tf.argmax(y, 1), tf.argmax(y_, 1))\n        accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))\n        train_accuracy_summary = tf.scalar_summary('accuracy', accuracy)\n        test_accuracy_summary = tf.scalar_summary('accuracy', accuracy)\n\n        sess.run(tf.initialize_all_variables())\n        for i in range(TRAINING_LOOP + 1):\n            batch = mnist.train.next_batch(BATCH_SIZE)\n            sess.run(train_step, {x: batch[0], y_: batch[1], keep_prob: KEEP_PROB})\n\n            if i % SUMMARY_INTERVAL == 0:\n                print('step %d' % i)\n                summary = sess.run(tf.merge_summary([train_accuracy_summary]), {x: batch[0], y_: batch[1], keep_prob: 1.0})\n                train_writer.add_summary(summary, i)\n                summary = sess.run(tf.merge_summary([test_accuracy_summary]), {x: mnist.test.images, y_: mnist.test.labels, keep_prob: 1.0})\n                test_writer.add_summary(summary, i)\n```\n\n##\u30b3\u30fc\u30c9\u306e\u8aac\u660e\n\u5909\u66f4\u70b9\u3092\u3002\n\n###\u7573\u307f\u8fbc\u307f\u5c64\n\u5909\u66f4\u306f\u3053\u3053\u3060\u3051\u3002`W_conv`\u3068`b_conv`\u304c\u5b9a\u6570\u304b\u3089\u5909\u6570\u306b\u306a\u3063\u3066\u3044\u308b\u3060\u3051\u3002\n\n```py\n    with tf.name_scope('convolution'):\n        W_conv = weight_variable([FILTER_SIZE, FILTER_SIZE, 1, FILTER_NUM], name='weight_conv')\n        b_conv = bias_variable([FILTER_NUM], name='bias_conv')\n        x_image = tf.reshape(x, [-1, IMAGE_WIDTH, IMAGE_HEIGHT, 1])\n        h_conv = tf.nn.relu(conv2d(x_image, W_conv) + b_conv)\n```\n\n##\u7d50\u679c\n\u30c6\u30b9\u30c8\u30c7\u30fc\u30bf\uff08\u9752\u7dda\uff09\u3067\u306e\u8b58\u5225\u7387\u306f\u300199.1%\u7a0b\u5ea6\u3002\u306a\u3093\u306899%\u5927\u53f0\u306b\u3002\n\n![result mnist_cnn_sl](https://qiita-image-store.s3.amazonaws.com/0/127038/becb6a4d-4253-b169-874f-ed7650b122e7.png)\n\n#\u3042\u3068\u304c\u304d\n\u4eca\u56de\u306f\u3001\u56fa\u5b9a\u3057\u3066\u3044\u305f\u7573\u307f\u8fbc\u307f\u5c64\u306e\u30a6\u30a7\u30a4\u30c8\u3082\u5b66\u7fd2\u306b\u3088\u3063\u3066\u63a8\u5b9a\u3059\u308b\u3088\u3046\u306b\u3057\u3066\u307f\u307e\u3057\u305f\u3002[\u6b21\u56de\u306e\u8a18\u4e8b](http://qiita.com/kumonkumon/items/9074d89d8c6c23570db4)\u3067\u306f\u3001\u3088\u308a\u30c7\u30a3\u30fc\u30d7\u30e9\u30fc\u30cb\u30f3\u30b0\u3089\u3057\u304f\u3057\u3066\u307f\u307e\u3059\u3002\u3068\u3044\u3063\u3066\u3082\u3001TensorFlow\u306eTutorial\u306e[Deep MNIST for Experts](https://www.tensorflow.org/versions/r0.8/tutorials/mnist/pros/index.html#deep-mnist-for-experts)\u307b\u307c\u305d\u306e\u3082\u306e\u306a\u3093\u3067\u3059\u3051\u3069\u3002\n", "tags": ["TensorFlow", "DeepLearning", "CNN", "ConvolutionalNeuralNetworks", "\u6df1\u5c64\u5b66\u7fd2"]}