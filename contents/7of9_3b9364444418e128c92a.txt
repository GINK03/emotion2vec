{"context": "\n\nTensorFlow\n\n\u52d5\u4f5c\u74b0\u5883\nGeForce GTX 1070 (8GB)\nASRock Z170M Pro4S [Intel Z170chipset]\nUbuntu 14.04 LTS desktop amd64\nTensorFlow v0.11\ncuDNN v5.1 for Linux\nCUDA v8.0\nPython 2.7.6\nIPython 5.1.0 -- An enhanced Interactive Python.\ngcc (Ubuntu 4.8.4-2ubuntu1~14.04.3) 4.8.4\n\n\nTensorFlow\u3092\u4f7f\u3063\u3066\u3001input:100, output:100\u7a0b\u5ea6\u306e\u30cd\u30c3\u30c8\u30ef\u30fc\u30af\u306e\u5b66\u7fd2\u3092\u3057\u3088\u3046\u304b\u3068\u4f5c\u696d\u4e2d\u3002\n\n\u30a8\u30e9\u30fc\u3092\u767a\u751f\u3059\u308b\u30b3\u30fc\u30c9\ntest_in.csv, test_out.csv\u306e\u30d5\u30a1\u30a4\u30eb\u3092\u7528\u610f\u3057\u3066\u3001\u4ee5\u4e0b\u3092\u5b9f\u884c\u3057\u3066\u307f\u305f\u3002\n\nlearn_in100out100.py\n#!/usr/bin/env python\n# -*- coding: utf-8 -*-\nimport sys\nimport tensorflow as tf\nimport tensorflow.contrib.slim as slim\nimport numpy as np\n\n'''\nv0.2 Feb. 15, 2017\n    - fix bug > different dimensions for placeholder and network\nv0.1 Feb. 06, 2017\n    - read [test_in.csv],[test_out.csv]\n'''\n\n'''\ncodingrule:PEP8\n'''\n\nfilename_inp = tf.train.string_input_producer([\"test_in.csv\"])\nfilename_out = tf.train.string_input_producer([\"test_out.csv\"])\nNUM_INP_NODE = 100\nNUM_OUT_NODE = 100\n\n# parse csv\n# a. input node\nreader = tf.TextLineReader()\nkey, value = reader.read(filename_inp)\ndeflist = [[0.] for idx in range(NUM_INP_NODE)]\ninput1 = tf.decode_csv(value, record_defaults=deflist)\n# b. output node\nkey, value = reader.read(filename_out)\ndeflist = [[0.] for idx in range(NUM_OUT_NODE)]\noutput1 = tf.decode_csv(value, record_defaults=deflist)\n# c. pack\n# inputs = tf.pack([input1])\ninputs = input1\n# outputs = tf.pack([output1])\noutputs = output1\n\nbatch_size = 1\ninputs_batch, output_batch = tf.train.shuffle_batch(\n    [inputs, outputs], batch_size, capacity=2, min_after_dequeue=batch_size)\n\ninput_ph = tf.placeholder(\"float\", [None, 100])\noutput_ph = tf.placeholder(\"float\", [None, 100])\n\n# network\nhiddens = slim.stack(input_ph, slim.fully_connected, [7, 7, 7],\n                     activation_fn=tf.nn.sigmoid, scope=\"hidden\")\nprediction = slim.fully_connected(\n    hiddens, 100, activation_fn=None, scope=\"output\")\nloss = tf.contrib.losses.mean_squared_error(prediction, output_ph)\n\ntrain_op = slim.learning.create_train_op(loss, tf.train.AdamOptimizer(0.001))\n\ninit_op = tf.initialize_all_variables()\n\nwith tf.Session() as sess:\n    coord = tf.train.Coordinator()\n    threads = tf.train.start_queue_runners(sess=sess, coord=coord)\n\n    try:\n        sess.run(init_op)\n        for idx in range(10):\n            inpbt, outbt = sess.run([inputs_batch, output_batch])\n            _, t_loss = sess.run(\n                [train_op, loss],\n                feed_dict={input_ph: inpbt, output_ph: outbt})\n\n            if (idx+1) % 100 == 0:\n                print(\"%d,%f\" % (idx+1, t_loss))\n    finally:\n        coord.request_stop()\n\n\n\n\u30a8\u30e9\u30fc\n\nW tensorflow/core/kernels/queue_base.cc:294] 1_input_producer_1: Skipping cancelled enqueue attempt with queue not closed\nW tensorflow/core/kernels/queuebase.cc:294] _0_input_producer: Skipping cancelled enqueue attempt with queue not closed\n\n\n\u30b3\u30fc\u30c9\u4fee\u6b63\n\u7d42\u4e86\u51e6\u7406\u306ecoord.join(threads)\u3092\u5165\u308c\u308b\u3053\u3068\u3067\u30a8\u30e9\u30fc\u304c\u51fa\u306a\u304f\u306a\u3063\u305f\u3002\nas sess\u914d\u4e0b\u306e\u5834\u6240\u306b\u5165\u308c\u305f\u3002\n### TensorFlow\n\n```txt:\u52d5\u4f5c\u74b0\u5883\nGeForce GTX 1070 (8GB)\nASRock Z170M Pro4S [Intel Z170chipset]\nUbuntu 14.04 LTS desktop amd64\nTensorFlow v0.11\ncuDNN v5.1 for Linux\nCUDA v8.0\nPython 2.7.6\nIPython 5.1.0 -- An enhanced Interactive Python.\ngcc (Ubuntu 4.8.4-2ubuntu1~14.04.3) 4.8.4\n```\n\nTensorFlow\u3092\u4f7f\u3063\u3066\u3001input:100, output:100\u7a0b\u5ea6\u306e\u30cd\u30c3\u30c8\u30ef\u30fc\u30af\u306e\u5b66\u7fd2\u3092\u3057\u3088\u3046\u304b\u3068\u4f5c\u696d\u4e2d\u3002\n\n### \u30a8\u30e9\u30fc\u3092\u767a\u751f\u3059\u308b\u30b3\u30fc\u30c9\n\ntest_in.csv, test_out.csv\u306e\u30d5\u30a1\u30a4\u30eb\u3092\u7528\u610f\u3057\u3066\u3001\u4ee5\u4e0b\u3092\u5b9f\u884c\u3057\u3066\u307f\u305f\u3002\n\n```learn_in100out100.py\n#!/usr/bin/env python\n# -*- coding: utf-8 -*-\nimport sys\nimport tensorflow as tf\nimport tensorflow.contrib.slim as slim\nimport numpy as np\n\n'''\nv0.2 Feb. 15, 2017\n    - fix bug > different dimensions for placeholder and network\nv0.1 Feb. 06, 2017\n    - read [test_in.csv],[test_out.csv]\n'''\n\n'''\ncodingrule:PEP8\n'''\n\nfilename_inp = tf.train.string_input_producer([\"test_in.csv\"])\nfilename_out = tf.train.string_input_producer([\"test_out.csv\"])\nNUM_INP_NODE = 100\nNUM_OUT_NODE = 100\n\n# parse csv\n# a. input node\nreader = tf.TextLineReader()\nkey, value = reader.read(filename_inp)\ndeflist = [[0.] for idx in range(NUM_INP_NODE)]\ninput1 = tf.decode_csv(value, record_defaults=deflist)\n# b. output node\nkey, value = reader.read(filename_out)\ndeflist = [[0.] for idx in range(NUM_OUT_NODE)]\noutput1 = tf.decode_csv(value, record_defaults=deflist)\n# c. pack\n# inputs = tf.pack([input1])\ninputs = input1\n# outputs = tf.pack([output1])\noutputs = output1\n\nbatch_size = 1\ninputs_batch, output_batch = tf.train.shuffle_batch(\n    [inputs, outputs], batch_size, capacity=2, min_after_dequeue=batch_size)\n\ninput_ph = tf.placeholder(\"float\", [None, 100])\noutput_ph = tf.placeholder(\"float\", [None, 100])\n\n# network\nhiddens = slim.stack(input_ph, slim.fully_connected, [7, 7, 7],\n                     activation_fn=tf.nn.sigmoid, scope=\"hidden\")\nprediction = slim.fully_connected(\n    hiddens, 100, activation_fn=None, scope=\"output\")\nloss = tf.contrib.losses.mean_squared_error(prediction, output_ph)\n\ntrain_op = slim.learning.create_train_op(loss, tf.train.AdamOptimizer(0.001))\n\ninit_op = tf.initialize_all_variables()\n\nwith tf.Session() as sess:\n    coord = tf.train.Coordinator()\n    threads = tf.train.start_queue_runners(sess=sess, coord=coord)\n\n    try:\n        sess.run(init_op)\n        for idx in range(10):\n            inpbt, outbt = sess.run([inputs_batch, output_batch])\n            _, t_loss = sess.run(\n                [train_op, loss],\n                feed_dict={input_ph: inpbt, output_ph: outbt})\n\n            if (idx+1) % 100 == 0:\n                print(\"%d,%f\" % (idx+1, t_loss))\n    finally:\n        coord.request_stop()\n```\n\n### \u30a8\u30e9\u30fc\n\n> W tensorflow/core/kernels/queue_base.cc:294] _1_input_producer_1: Skipping cancelled enqueue attempt with queue not closed\nW tensorflow/core/kernels/queue_base.cc:294] _0_input_producer: Skipping cancelled enqueue attempt with queue not closed\n\n\n### \u30b3\u30fc\u30c9\u4fee\u6b63\n\n\u7d42\u4e86\u51e6\u7406\u306e`coord.join(threads)`\u3092\u5165\u308c\u308b\u3053\u3068\u3067\u30a8\u30e9\u30fc\u304c\u51fa\u306a\u304f\u306a\u3063\u305f\u3002\n`as sess`\u914d\u4e0b\u306e\u5834\u6240\u306b\u5165\u308c\u305f\u3002\n", "tags": ["borgWarp", "TensorFlow"]}