{"context": "\n\nLinear Regression with multiple variables\n\n\u524d\u56de\u306e\u304a\u3055\u3089\u3044\n\u5bb6\u306e\u30b5\u30a4\u30ba\u304b\u3089\u4fa1\u683c\u3092\u4e88\u6e2c\u3057\u305f\u3044\n\nmultiple vriables\n\u30d9\u30c3\u30c8\u30eb\u30fc\u30e0\u306e\u6570, \u4f55\u968e\u5efa\u3066\uff1f, \u7bc9\u5e74\u6570, ....\n\n\n\n\n\u4eee\u8aac\u95a2\u6570\n\n\u3053\u308c\u307e\u3067\nh\u03b8(x)=\u03b80+\u03b81xh\u03b8(x)=\u03b80+\u03b81x{h_\\theta(x) = \\theta_0 + \\theta_1x\n}\n\n\u4eca\u56de\nh\u03b8(x)=\u03b80+\u03b81x1+\u03b82x2+...h\u03b8(x)=\u03b80+\u03b81x1+\u03b82x2+...{h_\\theta(x) = \\theta_0 + \\theta_1x_1 + \\theta_2x_2 + ...\n}\n\n\u3053\u308c\u3092\u3082\u3063\u3068\u7c21\u5358\u306b\u66f8\u304d\u305f\u3044\nx(i)0=1x0(i)=1x_0^{(i)}=1\u3068\u3059\u308b\u3002\nx=\u239b\u239d\u239c\u239c\u239c\u239cx0x1\u22eexn\u239e\u23a0\u239f\u239f\u239f\u239f\u03b8=\u239b\u239d\u239c\u239c\u239c\u239c\u03b80\u03b81\u22ee\u03b8n\u239e\u23a0\u239f\u239f\u239f\u239fx=(x0x1\u22eexn)\u03b8=(\u03b80\u03b81\u22ee\u03b8n){\\boldsymbol{x}\n=\n\\left(\n\\begin{array}{c}\nx_0 \\\\\nx_1 \\\\\n\\vdots \\\\\nx_n\n\\end{array}\n\\right) \\\\\n\n\\boldsymbol{\\theta}\n=\n\\left(\n\\begin{array}{c}\n\\theta_0 \\\\\n\\theta_1 \\\\\n\\vdots \\\\\n\\theta_n\n\\end{array}\n\\right)\n}\n\u4e0a\u306e\u4eee\u8aac\u95a2\u6570\u306f,\nh\u03b8(x)=\u03b80x0+\u03b81x1+\u03b82x2+....h\u03b8(x)=\u03b80x0+\u03b81x1+\u03b82x2+....{\nh_\\theta(x) = \\theta_0x_0 + \\theta_1x_1 + \\theta_2x_2 + ....\n\n}\nh\u03b8(x)=\u03b8Txh\u03b8(x)=\u03b8Tx{\nh_\\theta(x) = \\boldsymbol{\\theta^{T}}\\boldsymbol{x}\n\n}\nmultiple linear regression\n\n\ngradient descent\nJ(\u03b80,\u03b81,...,\u03b8n)=12m\u03a3mi=1(h\u03b8(x(i))\u2212y(i))2J(\u03b80,\u03b81,...,\u03b8n)=12m\u03a3i=1m(h\u03b8(x(i))\u2212y(i))2{J(\\theta_0, \\theta_1, ..., \\theta_n) = \\frac{1}{2m}\\Sigma_{i=1}^{m}(h_\\theta(x^{(i)}) - y^{(i)})^2\n}\ngradient descent\n\u03b8j:=\u03b8j\u2212\u03b11m\u03a3mi=1(h\u03b8(x(i))\u2212y(i))x(i)j\u03b8j:=\u03b8j\u2212\u03b11m\u03a3i=1m(h\u03b8(x(i))\u2212y(i))xj(i){\\theta_j := \\theta_j - \\alpha\\frac{1}{m}\\Sigma_{i=1}^m(h_\\theta(x^{(i)})-y^{(i)})x_j^{(i)}\n}\n\n\nFeature Scaling\n\nidea: Make sure features are on a similar scale.\nx1 = size (0 ~ 2000 feet*feet)\nx2 = number of bedroom(s) (1~5)\n\u03b81\u03b81\\theta_1&\u3068\u03b82\u03b82\\theta_2\u3067\u30b0\u30e9\u30d5\u3092\u66f8\u304f\u3068,\u3068\u3066\u3082\u9577\u3044\u6955\u5186\u306b\n\u53ce\u675f\u3059\u308b\u306e\u306b\u6642\u9593\u304c\u304b\u304b\u308b\nx1 = size (0 ~ 2000 feet*feet) / 2000\nx2 = number of bedroom(s) (1~5) / 5\n\u53ce\u675f\u304c\u65e9\u304f\u306a\u308b\nGet every feature into approximately a \u22121<xi<1\u22121<xi<1-1 < x_i < 1 range.\n\u3064\u307e\u308a\u3001\u5927\u304d\u3059\u304e\u305f\u308a\u5c0f\u3055\u3059\u304e\u308b\u6570\u5b57\u304c\u3042\u308b\u306e\u306f\u3088\u304f\u306a\u3044\u3002\nAndrew Ng\u306e\u7d4c\u9a13\u5247\u306f\n\u22123to3\u22121/3to1/3\u22123to3\u22121/3to1/3{-3 to 3 \\\\\n-1/3 to 1/3\n}\n\n\nlearning rate\ncost funciton\u304c\u53ce\u675f\u3059\u308b\u306e\u3092\u3069\u3046\u3084\u3063\u3066\u5224\u65ad\u3059\u308b\u304b\n\n\u30b0\u30e9\u30d5\u3092\u898b\u3066\u6c7a\u3081\u308b\n\n\u7e26\u8ef8: J(\u03b8)J(\u03b8)J(\\theta)\n\u6a2a\u8ef8: No. of iterations\n\n\n\u53ce\u675f\u3057\u305f\u304b\u306e\u30c6\u30b9\u30c8\u3082\u3067\u304d\u308b\n\n\u3042\u308b\u4e00\u56de\u306e\u30a4\u30c6\u30ec\u30fc\u30b7\u30e7\u30f3\u3067\u3069\u308c\u3060\u3051\u6e1b\u5c11\u3059\u308b\u304b\n\u95be\u5024\u81ea\u4f53\u3092\u6c7a\u3081\u308b\u306e\u304c\u96e3\u3057\u3044\n\n\n\u8aa4\u5dee\u95a2\u6570\u304c\u5897\u52a0\u3057\u3066\u3044\u305f\u3089\u307e\u305a\u3044\n\n\u3082\u3063\u3068\u5c0f\u3055\u306a\u03b1\u03b1\\alpha\u3092\u4f7f\u3048\u3068\u3044\u3046\u3053\u3068\n\n\n\nFeatures and polynomial regression\n\n\u4f7f\u3046feature\u306e\u9078\u629e\u306b\u3064\u3044\u3066\n\u9069\u5207\u306a\u30d5\u30a3\u30fc\u30c1\u30e3\u30fc\u3092\u9078\u3076\u3053\u3068\u3067\u5f37\u529b\u306a\u5225\u306e\u30a2\u30eb\u30b4\u30ea\u30ba\u30e0\u5f97\u308b\u65b9\u6cd5\n\u591a\u9805\u5f0f\u56de\u5e30\n\n\n\u975e\u7dda\u5f62\u3092\u6271\u3048\u308b\n\n\n\n\nHousing prices prediction\nh\u03b8(x)=\u03b8+\u03b81\u2217frontage+\u03b82\u2217depthh\u03b8(x)=\u03b8+\u03b81\u2217frontage+\u03b82\u2217depth{h_\\theta(x) = \\theta + \\theta_1 * frontage + \\theta_2 * depth\n}\n\n\n\u591a\u9805\u5f0f\u56de\u5e30(polynominal regression)\n\n\u03b80+\u03b81x+\u03b82x2\u03b80+\u03b81x+\u03b82x2{\\theta_0 + \\theta_1x + \\theta_2x^2\n}\n\u03b80+\u03b81x+\u03b82x2+\u03b83x3\u03b80+\u03b81x+\u03b82x2+\u03b83x3{\\theta_0 + \\theta_1x + \\theta_2x^2 + \\theta_3x^3\n}\n\u3053\u308c\u3089\u306e\u30e2\u30c7\u30eb\u3092\u3069\u3046\u3084\u3063\u3066\u5b66\u7fd2\u3059\u308b\u304b\nh\u03b8(x)=\u03b80+\u03b81(size)+\u03b8(size)2+\u03b83(size)3h\u03b8(x)=\u03b80+\u03b81(size)+\u03b8(size)2+\u03b83(size)3{h_\\theta(x) = \\theta_0 + \\theta_1(size) + \\theta(size)^2 + \\theta_3(size)^3\n}\nx1=(size)x2=(size)2x3=(size)3x1=(size)x2=(size)2x3=(size)3{\\begin{align}\nx_1 = (size)\\\\\nx_2 = (size)^2\\\\\nx_3 = (size)^3\\\\\n\\end{align}\n}\n\u3068\u3059\u308c\u3070\u3088\u3044\u3002\u3053\u306e\u5834\u5408feature scaling\u304c\u3088\u308a\u91cd\u8981\u306b\u3002\nh\u03b8(x)=\u03b80+\u03b81(size)+\u03b82(size)\u2212\u2212\u2212\u2212\u2212\u221ah\u03b8(x)=\u03b80+\u03b81(size)+\u03b82(size){\nh_\\theta(x) = \\theta_0 + \\theta_1(size) + \\theta_2\\sqrt{(size)}\n}\n\u3069\u3046\u3084\u3063\u3066\u95a2\u6570\u3092\u9078\u3076\u306e\u304b\u306f\u5f8c\u534a\u3067\n\n\nNormail Equation\n\u3053\u308c\u307e\u3067\u306f\u3001\u518d\u6025\u964d\u4e0b\u6cd5\u3092\u4f7f\u3063\u3066\u304d\u305f\n\u03b8\u03b8\\theta\u3092\u89e3\u6790\u7684\u306b\u89e3\u304f\n\u03b8=(XTX)\u22121XTy\u03b8=(XTX)\u22121XTy{\n\\theta = (X^{T}X)^{-1}X^{T}y\n}\n# Linear Regression with multiple variables\n\n# \u524d\u56de\u306e\u304a\u3055\u3089\u3044\n\n\u5bb6\u306e\u30b5\u30a4\u30ba\u304b\u3089\u4fa1\u683c\u3092\u4e88\u6e2c\u3057\u305f\u3044\n\n# multiple vriables\n\n\u30d9\u30c3\u30c8\u30eb\u30fc\u30e0\u306e\u6570, \u4f55\u968e\u5efa\u3066\uff1f, \u7bc9\u5e74\u6570, ....\n\n# <img width=\"682\" alt=\"screenshot.png\" src=\"https://qiita-image-store.s3.amazonaws.com/0/104227/baedf9b1-5be8-d89a-0916-e9e0263d0820.png\">\n\n# \u4eee\u8aac\u95a2\u6570\n\n## \u3053\u308c\u307e\u3067\n\n```math\nh_\\theta(x) = \\theta_0 + \\theta_1x\n```\n\n# \u4eca\u56de\n\n```math\nh_\\theta(x) = \\theta_0 + \\theta_1x_1 + \\theta_2x_2 + ...\n```\n\n## \u3053\u308c\u3092\u3082\u3063\u3068\u7c21\u5358\u306b\u66f8\u304d\u305f\u3044\n\n$x_0^{(i)}=1$\u3068\u3059\u308b\u3002\n\n```math\n\\boldsymbol{x}\n=\n\\left(\n\\begin{array}{c}\nx_0 \\\\\nx_1 \\\\\n\\vdots \\\\\nx_n\n\\end{array}\n\\right) \\\\\n\n\\boldsymbol{\\theta}\n=\n\\left(\n\\begin{array}{c}\n\\theta_0 \\\\\n\\theta_1 \\\\\n\\vdots \\\\\n\\theta_n\n\\end{array}\n\\right)\n```\n\n\u4e0a\u306e\u4eee\u8aac\u95a2\u6570\u306f,\n\n\n```math\n\nh_\\theta(x) = \\theta_0x_0 + \\theta_1x_1 + \\theta_2x_2 + ....\n\n```\n\n```math\n\nh_\\theta(x) = \\boldsymbol{\\theta^{T}}\\boldsymbol{x}\n\n```\n\nmultiple linear regression\n\n---\n\n# gradient descent\n\n```math\nJ(\\theta_0, \\theta_1, ..., \\theta_n) = \\frac{1}{2m}\\Sigma_{i=1}^{m}(h_\\theta(x^{(i)}) - y^{(i)})^2\n```\n\ngradient descent\n\n```math\n\\theta_j := \\theta_j - \\alpha\\frac{1}{m}\\Sigma_{i=1}^m(h_\\theta(x^{(i)})-y^{(i)})x_j^{(i)}\n```\n\n---\n\n# Feature Scaling\n\n## idea: Make sure features are on a similar scale.\n\nx1 = size (0 ~ 2000 feet*feet)\nx2 = number of bedroom(s) (1~5)\n\n$\\theta_1$&\u3068$\\theta_2$\u3067\u30b0\u30e9\u30d5\u3092\u66f8\u304f\u3068,\u3068\u3066\u3082\u9577\u3044\u6955\u5186\u306b\n\n\u53ce\u675f\u3059\u308b\u306e\u306b\u6642\u9593\u304c\u304b\u304b\u308b\n\nx1 = size (0 ~ 2000 feet*feet) / 2000\nx2 = number of bedroom(s) (1~5) / 5\n\n\u53ce\u675f\u304c\u65e9\u304f\u306a\u308b\n\nGet every feature into approximately a $-1 < x_i < 1$ range.\n\n\u3064\u307e\u308a\u3001\u5927\u304d\u3059\u304e\u305f\u308a\u5c0f\u3055\u3059\u304e\u308b\u6570\u5b57\u304c\u3042\u308b\u306e\u306f\u3088\u304f\u306a\u3044\u3002\n\nAndrew Ng\u306e\u7d4c\u9a13\u5247\u306f\n\n```math\n-3 to 3 \\\\\n-1/3 to 1/3\n```\n\n---\n\n# learning rate\n\ncost funciton\u304c\u53ce\u675f\u3059\u308b\u306e\u3092\u3069\u3046\u3084\u3063\u3066\u5224\u65ad\u3059\u308b\u304b\n\n## \u30b0\u30e9\u30d5\u3092\u898b\u3066\u6c7a\u3081\u308b\n- \u7e26\u8ef8: $J(\\theta)$\n- \u6a2a\u8ef8: No. of iterations\n\n## \u53ce\u675f\u3057\u305f\u304b\u306e\u30c6\u30b9\u30c8\u3082\u3067\u304d\u308b\n- \u3042\u308b\u4e00\u56de\u306e\u30a4\u30c6\u30ec\u30fc\u30b7\u30e7\u30f3\u3067\u3069\u308c\u3060\u3051\u6e1b\u5c11\u3059\u308b\u304b\n- \u95be\u5024\u81ea\u4f53\u3092\u6c7a\u3081\u308b\u306e\u304c\u96e3\u3057\u3044\n\n## \u8aa4\u5dee\u95a2\u6570\u304c\u5897\u52a0\u3057\u3066\u3044\u305f\u3089\u307e\u305a\u3044\n- \u3082\u3063\u3068\u5c0f\u3055\u306a$\\alpha$\u3092\u4f7f\u3048\u3068\u3044\u3046\u3053\u3068\n\n---\n\n# Features and polynomial regression\n\n- \u4f7f\u3046feature\u306e\u9078\u629e\u306b\u3064\u3044\u3066\n- \u9069\u5207\u306a\u30d5\u30a3\u30fc\u30c1\u30e3\u30fc\u3092\u9078\u3076\u3053\u3068\u3067\u5f37\u529b\u306a\u5225\u306e\u30a2\u30eb\u30b4\u30ea\u30ba\u30e0\u5f97\u308b\u65b9\u6cd5\n- \u591a\u9805\u5f0f\u56de\u5e30\n    - \u975e\u7dda\u5f62\u3092\u6271\u3048\u308b\n\n## Housing prices prediction\n\n```math\nh_\\theta(x) = \\theta + \\theta_1 * frontage + \\theta_2 * depth\n```\n<img width=\"311\" alt=\"screenshot.png\" src=\"https://qiita-image-store.s3.amazonaws.com/0/104227/7750b804-788d-cad2-9b10-35f2e90baa44.png\">\n\n\n\n### \u591a\u9805\u5f0f\u56de\u5e30(polynominal regression)\n\n![screenshot.png](https://qiita-image-store.s3.amazonaws.com/0/104227/7039c5b2-e00b-1b16-9018-733c7890b7c8.png)\n\n```math\n\\theta_0 + \\theta_1x + \\theta_2x^2\n```\n\n```math\n\\theta_0 + \\theta_1x + \\theta_2x^2 + \\theta_3x^3\n```\n\n\n\u3053\u308c\u3089\u306e\u30e2\u30c7\u30eb\u3092\u3069\u3046\u3084\u3063\u3066\u5b66\u7fd2\u3059\u308b\u304b\n\n```math\nh_\\theta(x) = \\theta_0 + \\theta_1(size) + \\theta(size)^2 + \\theta_3(size)^3\n```\n\n```math\n\\begin{align}\nx_1 = (size)\\\\\nx_2 = (size)^2\\\\\nx_3 = (size)^3\\\\\n\\end{align}\n```\n\n\u3068\u3059\u308c\u3070\u3088\u3044\u3002\u3053\u306e\u5834\u5408feature scaling\u304c\u3088\u308a\u91cd\u8981\u306b\u3002\n\n```math\n\nh_\\theta(x) = \\theta_0 + \\theta_1(size) + \\theta_2\\sqrt{(size)}\n```\n\n\n\u3069\u3046\u3084\u3063\u3066\u95a2\u6570\u3092\u9078\u3076\u306e\u304b\u306f\u5f8c\u534a\u3067\n\n\n---\n\n# Normail Equation\n\n\u3053\u308c\u307e\u3067\u306f\u3001\u518d\u6025\u964d\u4e0b\u6cd5\u3092\u4f7f\u3063\u3066\u304d\u305f\n\n$\\theta$\u3092\u89e3\u6790\u7684\u306b\u89e3\u304f\n\n\n```math\n\n\\theta = (X^{T}X)^{-1}X^{T}y\n```\n", "tags": ["coursera", "MachineLearning", "\u6a5f\u68b0\u5b66\u7fd2"]}