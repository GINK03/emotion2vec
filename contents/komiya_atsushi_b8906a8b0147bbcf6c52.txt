{"context": " More than 1 year has passed since last update.\u6c7a\u5b9a\u6728\u306f\u305d\u306e\u30ed\u30b8\u30c3\u30af\u7684\u306b\u30e2\u30c7\u30eb\u306e\u89e3\u91c8\u304c\u3057\u3084\u3059\u304f\u3066\u3001\u610f\u5916\u3068\u73fe\u5b9f\u4e16\u754c\u3067\u5229\u7528\u3055\u308c\u308b\u3053\u3068\u304c\u591a\u3044\u3088\u3046\u306a\u6c17\u304c\u3057\u307e\u3059\u3002\n\u305d\u3093\u306a\u308f\u3051\u3067\u3001Spark MLlib (ML Pipeline) \u306e \u6c7a\u5b9a\u6728 \u306e\u30e2\u30c7\u30eb\u306b\u3064\u3044\u3066\u3001\u305d\u306e\u69cb\u9020\u3092\u6a19\u6e96\u51fa\u529b\u3059\u308b\u6a5f\u80fd\u3092\u4f5c\u3063\u305f\u306e\u3067\u30e1\u30e2\u3068\u3057\u3066\u6b8b\u3057\u3066\u7f6e\u304d\u307e\u3059\u3002\npackage biz.k11i.spark.misc\n\nimport org.apache.spark.ml.classification.DecisionTreeClassificationModel\nimport org.apache.spark.ml.tree.{CategoricalSplit, ContinuousSplit, InternalNode, LeafNode}\n\n/**\n  * spark.ml \u306e DecisionTreeClassificationModel \u306e\u6728\u69cb\u9020\u3092\u6a19\u6e96\u51fa\u529b\u306b\u66f8\u304d\u51fa\u3059\u3002\n  */\nobject DecisionTreePrinter {\n  def printTree(model: DecisionTreeClassificationModel): Unit = {\n    model.rootNode match {\n      case node: InternalNode => printNodes(node, 0)\n      case leaf: LeafNode => printLeaf(leaf, 0)\n    }\n  }\n\n  def printNodes(node: InternalNode, numIndents: Int): Unit = {\n    val indents = \"  \" * numIndents\n\n    node.split match {\n      case cat: CategoricalSplit => println(s\"${indents}category, featureIndex=${cat.featureIndex}, left=${cat.leftCategories.mkString(\",\")}, right=${cat.rightCategories.mkString(\",\")}\")\n      case con: ContinuousSplit => println(s\"${indents}continuous, featureIndex=${con.featureIndex}, threshold=${con.threshold}\")\n    }\n\n    Seq(node.leftChild, node.rightChild).foreach {\n      case internalNode: InternalNode => printNodes(internalNode, numIndents + 1)\n      case leafNode: LeafNode => printLeaf(leafNode, numIndents + 1)\n    }\n  }\n\n  def printLeaf(node: LeafNode, indent: Int): Unit = {\n    val indents = \"  \" * indent\n    println(s\"${indents}prediction=${node.prediction}\")\n  }\n}\n\n\u3053\u308c\u306b\u3061\u3087\u3053\u3063\u3068\u624b\u3092\u52a0\u3048\u308c\u3070\u3001Random forest \u306e\u30e2\u30c7\u30eb\u3082 Gradient-boosted trees \u306e\u30e2\u30c7\u30eb\u3082\u540c\u69d8\u306b\u30c0\u30f3\u30d7\u3067\u304d\u308b\u3068\u601d\u3046\u3051\u3069\u3001\u9762\u5012\u304f\u3055\u3044\u306e\u3067\u307e\u305f\u4eca\u5ea6\u3002\n\u6c7a\u5b9a\u6728\u306f\u305d\u306e\u30ed\u30b8\u30c3\u30af\u7684\u306b\u30e2\u30c7\u30eb\u306e\u89e3\u91c8\u304c\u3057\u3084\u3059\u304f\u3066\u3001\u610f\u5916\u3068\u73fe\u5b9f\u4e16\u754c\u3067\u5229\u7528\u3055\u308c\u308b\u3053\u3068\u304c\u591a\u3044\u3088\u3046\u306a\u6c17\u304c\u3057\u307e\u3059\u3002\n\n\u305d\u3093\u306a\u308f\u3051\u3067\u3001Spark MLlib (ML Pipeline) \u306e [\u6c7a\u5b9a\u6728](http://spark.apache.org/docs/latest/mllib-decision-tree.html) \u306e\u30e2\u30c7\u30eb\u306b\u3064\u3044\u3066\u3001\u305d\u306e\u69cb\u9020\u3092\u6a19\u6e96\u51fa\u529b\u3059\u308b\u6a5f\u80fd\u3092\u4f5c\u3063\u305f\u306e\u3067\u30e1\u30e2\u3068\u3057\u3066\u6b8b\u3057\u3066\u7f6e\u304d\u307e\u3059\u3002\n\n```scala\npackage biz.k11i.spark.misc\n\nimport org.apache.spark.ml.classification.DecisionTreeClassificationModel\nimport org.apache.spark.ml.tree.{CategoricalSplit, ContinuousSplit, InternalNode, LeafNode}\n\n/**\n  * spark.ml \u306e DecisionTreeClassificationModel \u306e\u6728\u69cb\u9020\u3092\u6a19\u6e96\u51fa\u529b\u306b\u66f8\u304d\u51fa\u3059\u3002\n  */\nobject DecisionTreePrinter {\n  def printTree(model: DecisionTreeClassificationModel): Unit = {\n    model.rootNode match {\n      case node: InternalNode => printNodes(node, 0)\n      case leaf: LeafNode => printLeaf(leaf, 0)\n    }\n  }\n\n  def printNodes(node: InternalNode, numIndents: Int): Unit = {\n    val indents = \"  \" * numIndents\n\n    node.split match {\n      case cat: CategoricalSplit => println(s\"${indents}category, featureIndex=${cat.featureIndex}, left=${cat.leftCategories.mkString(\",\")}, right=${cat.rightCategories.mkString(\",\")}\")\n      case con: ContinuousSplit => println(s\"${indents}continuous, featureIndex=${con.featureIndex}, threshold=${con.threshold}\")\n    }\n\n    Seq(node.leftChild, node.rightChild).foreach {\n      case internalNode: InternalNode => printNodes(internalNode, numIndents + 1)\n      case leafNode: LeafNode => printLeaf(leafNode, numIndents + 1)\n    }\n  }\n\n  def printLeaf(node: LeafNode, indent: Int): Unit = {\n    val indents = \"  \" * indent\n    println(s\"${indents}prediction=${node.prediction}\")\n  }\n}\n```\n\n\u3053\u308c\u306b\u3061\u3087\u3053\u3063\u3068\u624b\u3092\u52a0\u3048\u308c\u3070\u3001Random forest \u306e\u30e2\u30c7\u30eb\u3082 Gradient-boosted trees \u306e\u30e2\u30c7\u30eb\u3082\u540c\u69d8\u306b\u30c0\u30f3\u30d7\u3067\u304d\u308b\u3068\u601d\u3046\u3051\u3069\u3001\u9762\u5012\u304f\u3055\u3044\u306e\u3067\u307e\u305f\u4eca\u5ea6\u3002\n", "tags": ["MLlib", "Spark"]}