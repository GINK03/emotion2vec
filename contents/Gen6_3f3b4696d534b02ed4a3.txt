{"context": "Twitter API\u3067\u4efb\u610f\u306e\u30ad\u30fc\u30ef\u30fc\u30c9\u3067\u30c4\u30a4\u30fc\u30c8\u3092\u53d6\u5f97\u3002\n\u53d6\u5f97\u3057\u305f\u30c7\u30fc\u30bf\u3092text\u3067\u4fdd\u5b58\u3057\u3001MeCab\u306b\u6e21\u3059\u3002\n\u5f62\u614b\u7d20\u89e3\u6790\u3092\u884c\u3044\u3001\u30de\u30eb\u30b3\u30d5\u9023\u9396\u3067\u6587\u7ae0\u3092\u4f5c\u3063\u3066\u307f\u308b\u3002\n\u4eca\u56de\u306f\u30ab\u30a6\u30f3\u30c8140\u306b\u6291\u3048\u3066\u3001\u305d\u306e\u307e\u307e\u30c4\u30a4\u30fc\u30c8\u306b\u4f7f\u3048\u308b\u3088\u3046\u306b\u3057\u3066\u3044\u308b\u3051\u3069\u3001\n\u9577\u6587\u306b\u3057\u3066\u307f\u3066\u3082\u3044\u3044\u304b\u3082\u3057\u308c\u306a\u3044\u3002\u7cbe\u5ea6\u306f\u4f4e\u3044\u3002\n\u3057\u3085\u3046\u307e\u3044\u3001\u5727\u7e2e\u65b0\u805e\u306e\u51c4\u3055\u3092\u5b9f\u611f\u3057\u305f\u3060\u3051\u3060\u3063\u305f\u3002\n\nmarkov.py\n\n#!/user/bin/env python\n# -*- coding: utf-8 -*-\nfrom requests_oauthlib import OAuth1Session\nimport json\nimport sys\nimport MeCab\nimport random\n\n\nwhile True:\n    search_words = raw_input(u\"Keyword?: \")\n\n    C_KEY = \"******************************\"\n    C_SECRET = \"******************************\"\n    A_KEY = \"******************************\"\n    A_SECRET = \"******************************\"\n\n\n    def Limit_Status():\n        url = \"https://api.twitter.com/1.1/application/rate_limit_status.json\"\n        params = {}\n        tw = OAuth1Session(C_KEY,C_SECRET,A_KEY,A_SECRET)\n        req = tw.get(url, params = params)\n        if req.status_code == 200:\n            limit = req.headers[\"x-rate-limit-remaining\"]\n            print (\"API remain: \" + limit)\n        return Limit_Status\n\n    def Search_words():\n        url = \"https://api.twitter.com/1.1/search/tweets.json?\"\n        params = {\n                \"q\": unicode(search_words, \"utf-8\"),\n                \"lang\": \"ja\",\n                \"result_type\": \"recent\",\n                \"count\": \"100\"\n                }\n        tw = OAuth1Session(C_KEY,C_SECRET,A_KEY,A_SECRET)\n        req = tw.get(url, params = params)\n        tweets = json.loads(req.text)\n        for tweet in tweets[\"statuses\"]:\n            f = open(\"test.txt\" , \"aw\")\n            lists = (tweet[\"text\"].encode(\"utf-8\"))\n            if \"http\" in lists:\n                lists = lists.split(\"http\", 1)[0]\n                lists = lists.split(\"@\")[0]\n                lists = lists.split(\"RT\")[0]\n\n                f.write(lists)\n                f.flush()\n                f.close()\n\n\n    def Mecab_file():   \n        f = open(\"test.txt\",\"rb\")\n        data = f.read()\n        f.close()\n\n        mt = MeCab.Tagger(\"-Owakati\")\n        wordlist = mt.parse(data)\n\n        markov = {}\n        w1 = \"\"\n        w2 = \"\"\n        w3 = \"\"\n        w4 = \"\"\n        w5 = \"\"\n        w6 = \"\"\n        w7 = \"\"\n        w8 = \"\"\n        for word in wordlist:\n            if w1 and w2 and w3 and w4 and w5 and w6 and w7 and w8:\n                if (w1,w2,w3,w4,w5,w6,w7,w8) not in markov:\n                    markov[(w1,w2,w3,w4,w5,w6,w7,w8)] = []\n                markov[(w1,w2,w3,w4,w5,w6,w7,w8)].append(word)\n            w1,w2,w3,w4,w5,w6,w7,w8 = w2,w3,w4,w5,w6,w7,w8,word\n        count = 0\n        sentence = \"\"\n        w1,w2,w3,w4,w5,w6,w7,w8 = random.choice(markov.keys())\n\n        while count < 140:\n            if markov.has_key((w1,w2,w3,w4,w5,w6,w7,w8)) == True:\n                tmp = random.choice(markov[(w1,w2,w3,w4,w5,w6,w7,w8)])\n                sentence += tmp\n                w1,w2,w3,w4,w5,w6,w7,w8 = w2,w3,w4,w5,w6,w7,w8,tmp\n                count +=1\n            if \" \" in sentence:\n                sentence = sentence.split(\" \", 1)[0]\n\n        print sentence\n\n    if search_words:\n        Search_words()\n        Mecab_file()\n        Limit_Status()\n    else:\n        break\n\n\n8\u9023\u9396\u3067\u904b\u7528\u3057\u3066\u307f\u305f\u3002\n4\u9023\u9396\u304f\u3089\u3044\u3067\u6b62\u3081\u3066\u304a\u304b\u306a\u3044\u3068\u9762\u767d\u304f\u306a\u3044\u3053\u3068\u304c\u5206\u304b\u3063\u305f\u3002\n\u672c\u6765\u306fJson\u30c7\u30fc\u30bf\u304b\u3089\u4e0d\u8981\u306a\u30c7\u30fc\u30bf\u3092\u3059\u3079\u3066\u53d6\u308a\u9664\u304d\u305f\u3044\u3068\u3053\u308d\u3067\u3042\u3063\u305f\u304c\u3001\u73fe\u6642\u70b9\u306e\u79c1\u306e\u77e5\u8b58\u3067\u306f\u9650\u754c\u3002\u3072\u3068\u307e\u305ahttp\u304c\u672c\u6587\u4e2d\u306b\u542b\u307e\u308c\u308b\u5834\u5408\u306bsplit\u3067\u53d6\u308a\u9664\u3044\u3066\u307f\u305f\u3002\n\u4f8b\u306b\u3088\u3063\u3066\u540c\u4e00\u30c7\u30a3\u30ec\u30af\u30c8\u30ea\u306btest.txt\u304c\u306a\u3051\u308c\u3070\u751f\u6210\u3002\n\u3042\u308b\u5834\u5408\u306f\u30c9\u30f3\u30c9\u30f3\u4e0a\u66f8\u304d\u3057\u3066\u3044\u304f\u3002\nWhile\u3067\u306e\u30eb\u30fc\u30d7\u306f\u30b5\u30fc\u30c1\u30ef\u30fc\u30c9\u3092\u5165\u529b\u305b\u305a\u306b\u5b9f\u884c\u3059\u308b\u3068break\u3002\n\u69d8\u3005\u306a\u30b5\u30fc\u30c1\u30ef\u30fc\u30c9\u3092\u5225\u3005\u306b\u683c\u7d0d\u3057\u3066\u3044\u304f\u3068\u826f\u3044\u306e\u304b\u3082\u3057\u308c\u306a\u3044\u3002\n\u7de8\u96c6\u304b\u3051\u3066\u307f\u307e\u3057\u305f\u3002\n\u6b63\u898f\u8868\u73fe\u3067\u3044\u3089\u306a\u3044\u7b87\u6240\u3092\u30ac\u30c3\u30c4\u30ea\u524a\u308a\u3001\n\u6587\u672b\u304c\u304a\u304b\u3057\u304f\u306a\u3089\u306a\u3044\u3088\u3046\u306b\u300c\u3067\u3059\u300d\u300c\u307e\u3059\u300d\u306a\u3069\u3092\u30e9\u30f3\u30c0\u30e0\u30c1\u30e7\u30a4\u30b9\u3002\n\u306a\u3093\u304b\u3053\u3063\u3061\u306e\u307b\u3046\u304c\u5b9f\u7528\u6027\u304c\u3042\u308b\u6c17\u304c\u3057\u307e\u3057\u305f\u3002\n    def Mecab_file():   \n        f = open(\"tweet.txt\",\"rb\")\n        data = f.read()\n        f.close()\n\n        mt = MeCab.Tagger(\"-Owakati\")\n\n        wordlist = mt.parse(data)\n        wordlist = wordlist.rstrip(\" \\n\").split(\" \")\n\n        markov = {}\n        w = \"\"\n\n        for x in wordlist:\n            if w:\n                if markov.has_key(w):\n                    new_list = markov[w]\n                else:\n                    new_list =[]\n\n                new_list.append(x)\n                markov[w] = new_list\n            w = x\n\n        choice_words = wordlist[0]\n        sentence = \"\"\n        count = 0\n\n        while count < 90:\n            sentence += choice_words\n            choice_words = random.choice(markov[choice_words])\n            count += 1\n\n            sentence = sentence.split(\" \", 1)[0]\n            p = re.compile(\"[!-/:-@[-`{-~]\")\n            sus = p.sub(\"\", sentence)\n\n            random_words_list = [u\"\u3002\", u\"\u3067\u3059\u3002\", u\"\u3060\u3002\"]\n            last_word = random.choice(random_words_list)\n\n        print re.sub(re.compile(\"[!-~]\"),\"\",sus), last_word\n\n\nTwitter API\u3067\u4efb\u610f\u306e\u30ad\u30fc\u30ef\u30fc\u30c9\u3067\u30c4\u30a4\u30fc\u30c8\u3092\u53d6\u5f97\u3002\n\u53d6\u5f97\u3057\u305f\u30c7\u30fc\u30bf\u3092text\u3067\u4fdd\u5b58\u3057\u3001MeCab\u306b\u6e21\u3059\u3002\n\u5f62\u614b\u7d20\u89e3\u6790\u3092\u884c\u3044\u3001\u30de\u30eb\u30b3\u30d5\u9023\u9396\u3067\u6587\u7ae0\u3092\u4f5c\u3063\u3066\u307f\u308b\u3002\n\n\u4eca\u56de\u306f\u30ab\u30a6\u30f3\u30c8140\u306b\u6291\u3048\u3066\u3001\u305d\u306e\u307e\u307e\u30c4\u30a4\u30fc\u30c8\u306b\u4f7f\u3048\u308b\u3088\u3046\u306b\u3057\u3066\u3044\u308b\u3051\u3069\u3001\n\u9577\u6587\u306b\u3057\u3066\u307f\u3066\u3082\u3044\u3044\u304b\u3082\u3057\u308c\u306a\u3044\u3002\u7cbe\u5ea6\u306f\u4f4e\u3044\u3002\n\u3057\u3085\u3046\u307e\u3044\u3001\u5727\u7e2e\u65b0\u805e\u306e\u51c4\u3055\u3092\u5b9f\u611f\u3057\u305f\u3060\u3051\u3060\u3063\u305f\u3002\n\n\n```python:markov.py\n\n#!/user/bin/env python\n# -*- coding: utf-8 -*-\nfrom requests_oauthlib import OAuth1Session\nimport json\nimport sys\nimport MeCab\nimport random\n\n\nwhile True:\n\tsearch_words = raw_input(u\"Keyword?: \")\n\t\n\tC_KEY = \"******************************\"\n\tC_SECRET = \"******************************\"\n\tA_KEY = \"******************************\"\n\tA_SECRET = \"******************************\"\n\n\n\tdef Limit_Status():\n\t\turl = \"https://api.twitter.com/1.1/application/rate_limit_status.json\"\n\t\tparams = {}\n\t\ttw = OAuth1Session(C_KEY,C_SECRET,A_KEY,A_SECRET)\n\t\treq = tw.get(url, params = params)\n\t\tif req.status_code == 200:\n\t\t\tlimit = req.headers[\"x-rate-limit-remaining\"]\n\t\t\tprint (\"API remain: \" + limit)\n\t\treturn Limit_Status\n\t\n\tdef Search_words():\n\t\turl = \"https://api.twitter.com/1.1/search/tweets.json?\"\n\t\tparams = {\n\t\t\t\t\"q\": unicode(search_words, \"utf-8\"),\n\t\t\t\t\"lang\": \"ja\",\n\t\t\t\t\"result_type\": \"recent\",\n\t\t\t\t\"count\": \"100\"\n\t\t\t\t}\n\t\ttw = OAuth1Session(C_KEY,C_SECRET,A_KEY,A_SECRET)\n\t\treq = tw.get(url, params = params)\n\t\ttweets = json.loads(req.text)\n\t\tfor tweet in tweets[\"statuses\"]:\n\t\t\tf = open(\"test.txt\" , \"aw\")\n\t\t\tlists = (tweet[\"text\"].encode(\"utf-8\"))\n\t\t\tif \"http\" in lists:\n\t\t\t\tlists = lists.split(\"http\", 1)[0]\n\t\t\t\tlists = lists.split(\"@\")[0]\n\t\t\t\tlists = lists.split(\"RT\")[0]\n\n\t\t\t\tf.write(lists)\n\t\t\t\tf.flush()\n\t\t\t\tf.close()\n\n\t\t\n\tdef Mecab_file():\t\n\t\tf = open(\"test.txt\",\"rb\")\n\t\tdata = f.read()\n\t\tf.close()\n\n\t\tmt = MeCab.Tagger(\"-Owakati\")\n\t\twordlist = mt.parse(data)\n \n\t\tmarkov = {}\n\t\tw1 = \"\"\n\t\tw2 = \"\"\n\t\tw3 = \"\"\n\t\tw4 = \"\"\n\t\tw5 = \"\"\n\t\tw6 = \"\"\n\t\tw7 = \"\"\n\t\tw8 = \"\"\n\t\tfor word in wordlist:\n\t\t\tif w1 and w2 and w3 and w4 and w5 and w6 and w7 and w8:\n\t\t\t\tif (w1,w2,w3,w4,w5,w6,w7,w8) not in markov:\n\t\t\t\t\tmarkov[(w1,w2,w3,w4,w5,w6,w7,w8)] = []\n\t\t\t\tmarkov[(w1,w2,w3,w4,w5,w6,w7,w8)].append(word)\n\t\t\tw1,w2,w3,w4,w5,w6,w7,w8 = w2,w3,w4,w5,w6,w7,w8,word\n\t\tcount = 0\n\t\tsentence = \"\"\n\t\tw1,w2,w3,w4,w5,w6,w7,w8 = random.choice(markov.keys())\n    \n\t\twhile count < 140:\n\t\t\tif markov.has_key((w1,w2,w3,w4,w5,w6,w7,w8)) == True:\n\t\t\t\ttmp = random.choice(markov[(w1,w2,w3,w4,w5,w6,w7,w8)])\n\t\t\t\tsentence += tmp\n\t\t\t\tw1,w2,w3,w4,w5,w6,w7,w8 = w2,w3,w4,w5,w6,w7,w8,tmp\n\t\t\t\tcount +=1\n\t\t\tif \" \" in sentence:\n\t\t\t\tsentence = sentence.split(\" \", 1)[0]\n\t\t\t\t\n\t\tprint sentence\n\t\n\tif search_words:\n\t\tSearch_words()\n\t\tMecab_file()\n\t\tLimit_Status()\n\telse:\n\t\tbreak\n```\n\n8\u9023\u9396\u3067\u904b\u7528\u3057\u3066\u307f\u305f\u3002\n4\u9023\u9396\u304f\u3089\u3044\u3067\u6b62\u3081\u3066\u304a\u304b\u306a\u3044\u3068\u9762\u767d\u304f\u306a\u3044\u3053\u3068\u304c\u5206\u304b\u3063\u305f\u3002\n\n\u672c\u6765\u306fJson\u30c7\u30fc\u30bf\u304b\u3089\u4e0d\u8981\u306a\u30c7\u30fc\u30bf\u3092\u3059\u3079\u3066\u53d6\u308a\u9664\u304d\u305f\u3044\u3068\u3053\u308d\u3067\u3042\u3063\u305f\u304c\u3001\u73fe\u6642\u70b9\u306e\u79c1\u306e\u77e5\u8b58\u3067\u306f\u9650\u754c\u3002\u3072\u3068\u307e\u305ahttp\u304c\u672c\u6587\u4e2d\u306b\u542b\u307e\u308c\u308b\u5834\u5408\u306bsplit\u3067\u53d6\u308a\u9664\u3044\u3066\u307f\u305f\u3002\n\n\u4f8b\u306b\u3088\u3063\u3066\u540c\u4e00\u30c7\u30a3\u30ec\u30af\u30c8\u30ea\u306btest.txt\u304c\u306a\u3051\u308c\u3070\u751f\u6210\u3002\n\u3042\u308b\u5834\u5408\u306f\u30c9\u30f3\u30c9\u30f3\u4e0a\u66f8\u304d\u3057\u3066\u3044\u304f\u3002\n\nWhile\u3067\u306e\u30eb\u30fc\u30d7\u306f\u30b5\u30fc\u30c1\u30ef\u30fc\u30c9\u3092\u5165\u529b\u305b\u305a\u306b\u5b9f\u884c\u3059\u308b\u3068break\u3002\n\u69d8\u3005\u306a\u30b5\u30fc\u30c1\u30ef\u30fc\u30c9\u3092\u5225\u3005\u306b\u683c\u7d0d\u3057\u3066\u3044\u304f\u3068\u826f\u3044\u306e\u304b\u3082\u3057\u308c\u306a\u3044\u3002\n\n\n\u7de8\u96c6\u304b\u3051\u3066\u307f\u307e\u3057\u305f\u3002\n\u6b63\u898f\u8868\u73fe\u3067\u3044\u3089\u306a\u3044\u7b87\u6240\u3092\u30ac\u30c3\u30c4\u30ea\u524a\u308a\u3001\n\u6587\u672b\u304c\u304a\u304b\u3057\u304f\u306a\u3089\u306a\u3044\u3088\u3046\u306b\u300c\u3067\u3059\u300d\u300c\u307e\u3059\u300d\u306a\u3069\u3092\u30e9\u30f3\u30c0\u30e0\u30c1\u30e7\u30a4\u30b9\u3002\n\n\u306a\u3093\u304b\u3053\u3063\u3061\u306e\u307b\u3046\u304c\u5b9f\u7528\u6027\u304c\u3042\u308b\u6c17\u304c\u3057\u307e\u3057\u305f\u3002\n\n\n```\n\tdef Mecab_file():\t\n\t\tf = open(\"tweet.txt\",\"rb\")\n\t\tdata = f.read()\n\t\tf.close()\n\n\t\tmt = MeCab.Tagger(\"-Owakati\")\n\n\t\twordlist = mt.parse(data)\n\t\twordlist = wordlist.rstrip(\" \\n\").split(\" \")\n \n\t\tmarkov = {}\n\t\tw = \"\"\n\t\n\t\tfor x in wordlist:\n\t\t\tif w:\n\t\t\t\tif markov.has_key(w):\n\t\t\t\t\tnew_list = markov[w]\n\t\t\t\telse:\n\t\t\t\t\tnew_list =[]\n\t\t\t\n\t\t\t\tnew_list.append(x)\n\t\t\t\tmarkov[w] = new_list\n\t\t\tw = x\n\t\t\n\t\tchoice_words = wordlist[0]\n\t\tsentence = \"\"\n\t\tcount = 0\n\t\n\t\twhile count < 90:\n\t\t\tsentence += choice_words\n\t\t\tchoice_words = random.choice(markov[choice_words])\n\t\t\tcount += 1\n\n\t\t\tsentence = sentence.split(\" \", 1)[0]\n\t\t\tp = re.compile(\"[!-/:-@[-`{-~]\")\n\t\t\tsus = p.sub(\"\", sentence)\n\t\t\n\t\t\trandom_words_list = [u\"\u3002\", u\"\u3067\u3059\u3002\", u\"\u3060\u3002\"]\n\t\t\tlast_word = random.choice(random_words_list)\n\t\n\t\tprint re.sub(re.compile(\"[!-~]\"),\"\",sus), last_word\n\n```\n", "tags": ["Python", "python2.7", "mecab", "\u5f62\u614b\u7d20\u89e3\u6790", "Twitter"]}