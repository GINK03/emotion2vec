{"context": "\u8a00\u8a9e\u51e6\u7406100\u672c\u30ce\u30c3\u30af 2015\u306e\u6311\u6226\u8a18\u9332\u3067\u3059\u3002\u74b0\u5883\u306fUbuntu 16.04 LTS \uff0b Python 3.5.2 :: Anaconda 4.1.1 (64-bit)\u3067\u3059\u3002\u904e\u53bb\u306e\u30ce\u30c3\u30af\u306e\u4e00\u89a7\u306f\u3053\u3061\u3089\u304b\u3089\u3069\u3046\u305e\u3002\n\n\u7b2c6\u7ae0: \u82f1\u8a9e\u30c6\u30ad\u30b9\u30c8\u306e\u51e6\u7406\n\n\u82f1\u8a9e\u306e\u30c6\u30ad\u30b9\u30c8\uff08nlp.txt\uff09\u306b\u5bfe\u3057\u3066\uff0c\u4ee5\u4e0b\u306e\u51e6\u7406\u3092\u5b9f\u884c\u305b\u3088\uff0e\n\n\n54. \u54c1\u8a5e\u30bf\u30b0\u4ed8\u3051\n\nStanford Core NLP\u306e\u89e3\u6790\u7d50\u679cXML\u3092\u8aad\u307f\u8fbc\u307f\uff0c\u5358\u8a9e\uff0c\u30ec\u30f3\u30de\uff0c\u54c1\u8a5e\u3092\u30bf\u30d6\u533a\u5207\u308a\u5f62\u5f0f\u3067\u51fa\u529b\u305b\u3088\uff0e\n\n\n\u51fa\u6765\u4e0a\u304c\u3063\u305f\u30b3\u30fc\u30c9\uff1a\n\nmain.py\n# coding: utf-8\nimport os\nimport subprocess\nimport xml.etree.ElementTree as ET\n\nfname = 'nlp.txt'\nfname_parsed = 'nlp.txt.xml'\n\n\ndef parse_nlp():\n    '''nlp.txt\u3092Stanford Core NLP\u3067\u89e3\u6790\u3057xml\u30d5\u30a1\u30a4\u30eb\u3078\u51fa\u529b\n    \u3059\u3067\u306b\u7d50\u679c\u30d5\u30a1\u30a4\u30eb\u304c\u5b58\u5728\u3059\u308b\u5834\u5408\u306f\u5b9f\u884c\u3057\u306a\u3044\n    '''\n    if not os.path.exists(fname_parsed):\n\n        # StanfordCoreNLP\u5b9f\u884c\u3001\u6a19\u6e96\u30a8\u30e9\u30fc\u306fparse.out\u3078\u51fa\u529b\n        subprocess.run(\n            'java -cp \"/usr/local/lib/stanford-corenlp-full-2016-10-31/*\"'\n            ' -Xmx2g'\n            ' edu.stanford.nlp.pipeline.StanfordCoreNLP'\n            ' -annotators tokenize,ssplit,pos,lemma,ner,parse,dcoref'\n            ' -file ' + fname + ' 2>parse.out',\n            shell=True,     # shell\u3067\u5b9f\u884c\n            check=True      # \u30a8\u30e9\u30fc\u30c1\u30a7\u30c3\u30af\u3042\u308a\n        )\n\n\n# nlp.txt\u3092\u89e3\u6790\nparse_nlp()\n\n# \u89e3\u6790\u7d50\u679c\u306exml\u3092\u30d1\u30fc\u30b9\nroot = ET.parse(fname_parsed)\n\n# token\u306e\u62bd\u51fa\nfor token in root.iter('token'):\n\n    # \u5358\u8a9e\u3001\u30ec\u30f3\u30de\u3001\u54c1\u8a5e\u306e\u62bd\u51fa\n    word = token.findtext('word')\n    lemma = token.findtext('lemma')\n    pos = token.findtext('POS')\n    print('{}\\t{}\\t{}'.format(word, lemma, pos))\n\n\n\n\u5b9f\u884c\u7d50\u679c\uff1a\n\u9577\u3044\u306e\u3067\u5148\u982d\u90e8\u5206\u306e\u629c\u7c8b\u3067\u3059\u3002\n\n\u7aef\u672b\uff1a\u5148\u982d\u90e8\u5206\nNatural natural JJ\nlanguage    language    NN\nprocessing  processing  NN\nFrom    from    IN\nWikipedia   Wikipedia   NNP\n,   ,   ,\nthe the DT\nfree    free    JJ\nencyclopedia    encyclopedia    NN\nNatural natural JJ\nlanguage    language    NN\nprocessing  processing  NN\n-LRB-   -lrb-   -LRB-\nNLP nlp NN\n-RRB-   -rrb-   -RRB-\nis  be  VBZ\na   a   DT\nfield   field   NN\nof  of  IN\ncomputer    computer    NN\nscience science NN\n,   ,   ,\nartificial  artificial  JJ\nintelligence    intelligence    NN\n,   ,   ,\nand and CC\nlinguistics linguistics NNS\nconcerned   concern VBN\nwith    with    IN\nthe the DT\ninteractions    interaction NNS\nbetween between IN\ncomputers   computer    NNS\nand and CC\nhuman   human   JJ\n-LRB-   -lrb-   -LRB-\nnatural natural JJ\n-RRB-   -rrb-   -RRB-\nlanguages   language    NNS\n.   .   .\nAs  as  IN\nsuch    such    JJ\n,   ,   ,\nNLP nlp NN\nis  be  VBZ\nrelated relate  VBN\nto  to  TO\nthe the DT\narea    area    NN\nof  of  IN\nhumani-computer humani-computer JJ\ninteraction interaction NN\n.   .   .\n\n\n\u5168\u4f53\u306e\u7d50\u679c\u306fGitHub\u306b\u30a2\u30c3\u30d7\u3057\u3066\u3044\u307e\u3059\u3002\n\nXML\u306e\u89e3\u6790\n\u4eca\u56de\u306ftoken\u30bf\u30b0\u3092\u62bd\u51fa\u3057\u3001\u305d\u306e\u4e2d\u3092Element.findtext()\u3067\u63a2\u3057\u3066\u3001\u76ee\u7684\u306e\u30bf\u30b0\u306e\u4e2d\u8eab\u3092\u62bd\u51fa\u3057\u3066\u3044\u307e\u3059\u3002\n\n\u30ec\u30f3\u30de\u3068\u306f\n\u30ec\u30f3\u30de\u3068\u306f\u3001\u30a6\u30a3\u30ad\u30da\u30c7\u30a3\u30a2\u306e\u8a9e\u5f59\u7d20\u306e\u89e3\u8aac\u306b\u3088\u308b\u3068\u3001\u8f9e\u66f8\u306b\u304a\u3051\u308b\u898b\u51fa\u3057\u8a9e\u306b\u76f8\u5f53\u3059\u308b\u8a9e\u3068\u306e\u3053\u3068\u3067\u3059\u3002\n\u554f\u984c52\u3067\u51fa\u3066\u304d\u305f\u8a9e\u5e79\u3068\u5c11\u3057\u4f3c\u3066\u3044\u307e\u3059\u304c\u3001\u8a9e\u5e79\u306f\u8a9e\u5c3e\u5909\u5316\u3059\u308b\u90e8\u5206\u3092\u5207\u308a\u6368\u3066\u3066\u3057\u307e\u3046\u306e\u3067\u307e\u3068\u3082\u306a\u5358\u8a9e\u306b\u306a\u3089\u306a\u3044\u5834\u5408\u3082\u3042\u308b\u306e\u306b\u5bfe\u3057\u3066\u3001\u30ec\u30f3\u30de\u306f\u304d\u3061\u3093\u3068\u5358\u8a9e\u306b\u306a\u3063\u3066\u3044\u307e\u3059\u306d\u3002\n\n\u54c1\u8a5e\u306e\u7a2e\u985e\nStanford Core NLP\u306e\u54c1\u8a5e\u306e\u89e3\u6790\u306f\u3001Stanford Log-linear Part-Of-Speech Tagger\u3068\u3044\u3046\u30e9\u30a4\u30d6\u30e9\u30ea\u304c\u4f7f\u308f\u308c\u3066\u3044\u308b\u3088\u3046\u3067\u3001\u89e3\u6790\u3055\u308c\u308b\u54c1\u8a5e\u306e\u7565\u8a9e\uff08NN\u3068\u304bNNP\u3068\u304bIN\u3068\u304b\uff09\u306fThe University of Pennsylvania (Penn) Treebank Tag-set\u306b\u6e96\u62e0\u3059\u308b\u3088\u3046\u3067\u3059\u3002\n\u3000\n55\u672c\u76ee\u306e\u30ce\u30c3\u30af\u306f\u4ee5\u4e0a\u3067\u3059\u3002\u8aa4\u308a\u306a\u3069\u3042\u308a\u307e\u3057\u305f\u3089\u3001\u3054\u6307\u6458\u3044\u305f\u3060\u3051\u307e\u3059\u3068\u5e78\u3044\u3067\u3059\u3002\n\n\u5b9f\u884c\u7d50\u679c\u306b\u306f\u3001100\u672c\u30ce\u30c3\u30af\u3067\u7528\u3044\u308b\u30b3\u30fc\u30d1\u30b9\u30fb\u30c7\u30fc\u30bf\u3067\u914d\u5e03\u3055\u308c\u3066\u3044\u308b\u30c7\u30fc\u30bf\u306e\u4e00\u90e8\u304c\u542b\u307e\u308c\u307e\u3059\u3002\u3053\u306e\u7b2c6\u7ae0\u3067\u7528\u3044\u3066\u3044\u308b\u30c7\u30fc\u30bf\u306e\u30e9\u30a4\u30bb\u30f3\u30b9\u306f\u30af\u30ea\u30a8\u30a4\u30c6\u30a3\u30d6\u30fb\u30b3\u30e2\u30f3\u30ba \u8868\u793a-\u7d99\u627f 3.0 \u975e\u79fb\u690d\uff08\u65e5\u672c\u8a9e\u8a33\uff09\u3067\u3059\u3002\n\n[\u8a00\u8a9e\u51e6\u7406100\u672c\u30ce\u30c3\u30af 2015](http://www.cl.ecei.tohoku.ac.jp/nlp100/)\u306e\u6311\u6226\u8a18\u9332\u3067\u3059\u3002\u74b0\u5883\u306fUbuntu 16.04 LTS \uff0b Python 3.5.2 \\:\\: Anaconda 4.1.1 (64-bit)\u3067\u3059\u3002\u904e\u53bb\u306e\u30ce\u30c3\u30af\u306e\u4e00\u89a7\u306f[\u3053\u3061\u3089](http://qiita.com/segavvy/items)\u304b\u3089\u3069\u3046\u305e\u3002\n\n## \u7b2c6\u7ae0: \u82f1\u8a9e\u30c6\u30ad\u30b9\u30c8\u306e\u51e6\u7406\n>\u82f1\u8a9e\u306e\u30c6\u30ad\u30b9\u30c8\uff08nlp.txt\uff09\u306b\u5bfe\u3057\u3066\uff0c\u4ee5\u4e0b\u306e\u51e6\u7406\u3092\u5b9f\u884c\u305b\u3088\uff0e\n\n###54. \u54c1\u8a5e\u30bf\u30b0\u4ed8\u3051\n>Stanford Core NLP\u306e\u89e3\u6790\u7d50\u679cXML\u3092\u8aad\u307f\u8fbc\u307f\uff0c\u5358\u8a9e\uff0c\u30ec\u30f3\u30de\uff0c\u54c1\u8a5e\u3092\u30bf\u30d6\u533a\u5207\u308a\u5f62\u5f0f\u3067\u51fa\u529b\u305b\u3088\uff0e\n\n####\u51fa\u6765\u4e0a\u304c\u3063\u305f\u30b3\u30fc\u30c9\uff1a\n\n```python:main.py\n# coding: utf-8\nimport os\nimport subprocess\nimport xml.etree.ElementTree as ET\n\nfname = 'nlp.txt'\nfname_parsed = 'nlp.txt.xml'\n\n\ndef parse_nlp():\n\t'''nlp.txt\u3092Stanford Core NLP\u3067\u89e3\u6790\u3057xml\u30d5\u30a1\u30a4\u30eb\u3078\u51fa\u529b\n\t\u3059\u3067\u306b\u7d50\u679c\u30d5\u30a1\u30a4\u30eb\u304c\u5b58\u5728\u3059\u308b\u5834\u5408\u306f\u5b9f\u884c\u3057\u306a\u3044\n\t'''\n\tif not os.path.exists(fname_parsed):\n\n\t\t# StanfordCoreNLP\u5b9f\u884c\u3001\u6a19\u6e96\u30a8\u30e9\u30fc\u306fparse.out\u3078\u51fa\u529b\n\t\tsubprocess.run(\n\t\t\t'java -cp \"/usr/local/lib/stanford-corenlp-full-2016-10-31/*\"'\n\t\t\t' -Xmx2g'\n\t\t\t' edu.stanford.nlp.pipeline.StanfordCoreNLP'\n\t\t\t' -annotators tokenize,ssplit,pos,lemma,ner,parse,dcoref'\n\t\t\t' -file ' + fname + ' 2>parse.out',\n\t\t\tshell=True,\t\t# shell\u3067\u5b9f\u884c\n\t\t\tcheck=True\t\t# \u30a8\u30e9\u30fc\u30c1\u30a7\u30c3\u30af\u3042\u308a\n\t\t)\n\n\n# nlp.txt\u3092\u89e3\u6790\nparse_nlp()\n\n# \u89e3\u6790\u7d50\u679c\u306exml\u3092\u30d1\u30fc\u30b9\nroot = ET.parse(fname_parsed)\n\n# token\u306e\u62bd\u51fa\nfor token in root.iter('token'):\n\n\t# \u5358\u8a9e\u3001\u30ec\u30f3\u30de\u3001\u54c1\u8a5e\u306e\u62bd\u51fa\n\tword = token.findtext('word')\n\tlemma = token.findtext('lemma')\n\tpos = token.findtext('POS')\n\tprint('{}\\t{}\\t{}'.format(word, lemma, pos))\n```\n\n####\u5b9f\u884c\u7d50\u679c\uff1a\n\n\u9577\u3044\u306e\u3067\u5148\u982d\u90e8\u5206\u306e\u629c\u7c8b\u3067\u3059\u3002\n\n```console:\u7aef\u672b\uff1a\u5148\u982d\u90e8\u5206\nNatural\tnatural\tJJ\nlanguage\tlanguage\tNN\nprocessing\tprocessing\tNN\nFrom\tfrom\tIN\nWikipedia\tWikipedia\tNNP\n,\t,\t,\nthe\tthe\tDT\nfree\tfree\tJJ\nencyclopedia\tencyclopedia\tNN\nNatural\tnatural\tJJ\nlanguage\tlanguage\tNN\nprocessing\tprocessing\tNN\n-LRB-\t-lrb-\t-LRB-\nNLP\tnlp\tNN\n-RRB-\t-rrb-\t-RRB-\nis\tbe\tVBZ\na\ta\tDT\nfield\tfield\tNN\nof\tof\tIN\ncomputer\tcomputer\tNN\nscience\tscience\tNN\n,\t,\t,\nartificial\tartificial\tJJ\nintelligence\tintelligence\tNN\n,\t,\t,\nand\tand\tCC\nlinguistics\tlinguistics\tNNS\nconcerned\tconcern\tVBN\nwith\twith\tIN\nthe\tthe\tDT\ninteractions\tinteraction\tNNS\nbetween\tbetween\tIN\ncomputers\tcomputer\tNNS\nand\tand\tCC\nhuman\thuman\tJJ\n-LRB-\t-lrb-\t-LRB-\nnatural\tnatural\tJJ\n-RRB-\t-rrb-\t-RRB-\nlanguages\tlanguage\tNNS\n.\t.\t.\nAs\tas\tIN\nsuch\tsuch\tJJ\n,\t,\t,\nNLP\tnlp\tNN\nis\tbe\tVBZ\nrelated\trelate\tVBN\nto\tto\tTO\nthe\tthe\tDT\narea\tarea\tNN\nof\tof\tIN\nhumani-computer\thumani-computer\tJJ\ninteraction\tinteraction\tNN\n.\t.\t.\n```\n\n\u5168\u4f53\u306e\u7d50\u679c\u306f[GitHub](https://github.com/segavvy/nlp100_Python/tree/master/54)\u306b\u30a2\u30c3\u30d7\u3057\u3066\u3044\u307e\u3059\u3002\n\n###XML\u306e\u89e3\u6790\n\u4eca\u56de\u306f`token`\u30bf\u30b0\u3092\u62bd\u51fa\u3057\u3001\u305d\u306e\u4e2d\u3092[`Element.findtext()`](http://docs.python.jp/3/library/xml.etree.elementtree.html#xml.etree.ElementTree.Element.findtext)\u3067\u63a2\u3057\u3066\u3001\u76ee\u7684\u306e\u30bf\u30b0\u306e\u4e2d\u8eab\u3092\u62bd\u51fa\u3057\u3066\u3044\u307e\u3059\u3002\n\n###\u30ec\u30f3\u30de\u3068\u306f\n\u30ec\u30f3\u30de\u3068\u306f\u3001[\u30a6\u30a3\u30ad\u30da\u30c7\u30a3\u30a2\u306e\u8a9e\u5f59\u7d20](https://ja.wikipedia.org/wiki/\u8a9e\u5f59\u7d20)\u306e\u89e3\u8aac\u306b\u3088\u308b\u3068\u3001\u8f9e\u66f8\u306b\u304a\u3051\u308b\u898b\u51fa\u3057\u8a9e\u306b\u76f8\u5f53\u3059\u308b\u8a9e\u3068\u306e\u3053\u3068\u3067\u3059\u3002\n[\u554f\u984c52](http://qiita.com/segavvy/items/d47fa799883ed16eddc2)\u3067\u51fa\u3066\u304d\u305f\u8a9e\u5e79\u3068\u5c11\u3057\u4f3c\u3066\u3044\u307e\u3059\u304c\u3001\u8a9e\u5e79\u306f\u8a9e\u5c3e\u5909\u5316\u3059\u308b\u90e8\u5206\u3092\u5207\u308a\u6368\u3066\u3066\u3057\u307e\u3046\u306e\u3067\u307e\u3068\u3082\u306a\u5358\u8a9e\u306b\u306a\u3089\u306a\u3044\u5834\u5408\u3082\u3042\u308b\u306e\u306b\u5bfe\u3057\u3066\u3001\u30ec\u30f3\u30de\u306f\u304d\u3061\u3093\u3068\u5358\u8a9e\u306b\u306a\u3063\u3066\u3044\u307e\u3059\u306d\u3002\n\n###\u54c1\u8a5e\u306e\u7a2e\u985e\nStanford Core NLP\u306e\u54c1\u8a5e\u306e\u89e3\u6790\u306f\u3001[Stanford Log-linear Part-Of-Speech Tagger](http://nlp.stanford.edu/software/tagger.shtml)\u3068\u3044\u3046\u30e9\u30a4\u30d6\u30e9\u30ea\u304c\u4f7f\u308f\u308c\u3066\u3044\u308b\u3088\u3046\u3067\u3001\u89e3\u6790\u3055\u308c\u308b\u54c1\u8a5e\u306e\u7565\u8a9e\uff08NN\u3068\u304bNNP\u3068\u304bIN\u3068\u304b\uff09\u306f[The University of Pennsylvania (Penn) Treebank Tag-set](http://www.comp.leeds.ac.uk/amalgam/tagsets/upenn.html)\u306b\u6e96\u62e0\u3059\u308b\u3088\u3046\u3067\u3059\u3002\n\n\u3000\n55\u672c\u76ee\u306e\u30ce\u30c3\u30af\u306f\u4ee5\u4e0a\u3067\u3059\u3002\u8aa4\u308a\u306a\u3069\u3042\u308a\u307e\u3057\u305f\u3089\u3001\u3054\u6307\u6458\u3044\u305f\u3060\u3051\u307e\u3059\u3068\u5e78\u3044\u3067\u3059\u3002\n<hr>\n\n*\u5b9f\u884c\u7d50\u679c\u306b\u306f\u3001[100\u672c\u30ce\u30c3\u30af\u3067\u7528\u3044\u308b\u30b3\u30fc\u30d1\u30b9\u30fb\u30c7\u30fc\u30bf](http://www.cl.ecei.tohoku.ac.jp/nlp100/#data)\u3067\u914d\u5e03\u3055\u308c\u3066\u3044\u308b\u30c7\u30fc\u30bf\u306e\u4e00\u90e8\u304c\u542b\u307e\u308c\u307e\u3059\u3002\u3053\u306e\u7b2c6\u7ae0\u3067\u7528\u3044\u3066\u3044\u308b\u30c7\u30fc\u30bf\u306e\u30e9\u30a4\u30bb\u30f3\u30b9\u306f[\u30af\u30ea\u30a8\u30a4\u30c6\u30a3\u30d6\u30fb\u30b3\u30e2\u30f3\u30ba \u8868\u793a-\u7d99\u627f 3.0 \u975e\u79fb\u690d](https://creativecommons.org/licenses/by-sa/3.0/legalcode)\uff08[\u65e5\u672c\u8a9e\u8a33](https://creativecommons.org/licenses/by-sa/3.0/deed.ja)\uff09\u3067\u3059\u3002*\n", "tags": ["\u81ea\u7136\u8a00\u8a9e\u51e6\u7406", "\u8a00\u8a9e\u51e6\u7406100\u672c\u30ce\u30c3\u30af", "Python"]}