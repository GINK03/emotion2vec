{"context": "\n\nChainer v2 alpha\nChainer v2 alpha\u304c\u30ea\u30ea\u30fc\u30b9\u3055\u308c\u305f\u306e\u3067\u3001\u81ea\u4f5c\u306e\u30bd\u30fc\u30b9\u30b3\u30fc\u30c9\u3092\u5bfe\u5fdc\u3055\u305b\u3066\u307f\u307e\u3057\u305f\u3002\n\u4ee5\u4e0b\u306e\u30b5\u30a4\u30c8\u3092\u53c2\u8003\u306b\u3057\u307e\u3057\u305f\u3002\n\n\u516c\u5f0f\u30c9\u30ad\u30e5\u30e1\u30f3\u30c8\nChainer Meetup #4\u306e\u767a\u8868\u30b9\u30e9\u30a4\u30c9\n\n\n\u52d5\u4f5c\u74b0\u5883\n\nOS: Windows 10(64bit)\nPython: Python 2.7.11 :: Anaconda custom (64-bit)\nGPU: GTX 1080\n\n\n\u4f7f\u7528\u3057\u305f\u30ea\u30dd\u30b8\u30c8\u30ea\n\u4ee5\u524d\u4f5c\u6210\u3057\u305fCIFAR-10\u306e\u753b\u50cf\u8a8d\u8b58\u306e\u30ea\u30dd\u30b8\u30c8\u30ea\u306bChainer v2\u7528\u306e\u30d6\u30e9\u30f3\u30c1\u3092\u4f5c\u6210\u3057\u307e\u3057\u305f\u3002\nhttps://github.com/dsanno/chainer-cifar/tree/chainer_v2\n\n\u30a4\u30f3\u30b9\u30c8\u30fc\u30eb\nChainer Meetup\u306e\u30b9\u30e9\u30a4\u30c9\u306b\u3042\u308b\u3088\u3046\u306b\u3001\u4ee5\u4e0b\u306e\u30b3\u30de\u30f3\u30c9\u3067\u30a4\u30f3\u30b9\u30c8\u30fc\u30eb\u3067\u304d\u307e\u3057\u305f\u3002\n\u5ff5\u306e\u305f\u3081--no-cache-dir\u3092\u3064\u3051\u307e\u3057\u305f\u3002\n$ pip install chainer --pre --no-cache-dir\n$ pip install cupy --no-cache-dir\n\n\n\u3068\u308a\u3042\u3048\u305a\u5b9f\u884c\u3057\u3066\u307f\u308b\nChainer v2\u306e\u4fee\u6b63\u306b\u3088\u308a\u5f8c\u65b9\u4e92\u63db\u6027\u304c\u58ca\u308c\u308b\u306e\u3067\u3001\u52d5\u4f5c\u3057\u306a\u3044\u3053\u3068\u306f\u4e88\u60f3\u3067\u304d\u3066\u3044\u308b\u306e\u3067\u3059\u304c\u3068\u308a\u3042\u3048\u305a\u5b9f\u884c\u3057\u3066\u307f\u307e\u3059\u3002\n$ python src/train.py -g 0 -m vgg -p model\\temp9 -b 100 --iter 200 --lr 0.1 --optimizer sgd --weight_decay 0.0001 --lr_decay_iter 100,150\n\n\u4ee5\u4e0b\u306e\u30a8\u30e9\u30fc\u304c\u767a\u751f\u3057\u307e\u3057\u305f\u3002\nTraceback (most recent call last):\n  File \"src\\train.py\", line 143, in <module>\n    cifar_trainer.fit(train_x, train_y, valid_x, valid_y, test_x, test_y, on_epoch_done)\n  File \"c:\\project_2\\chainer\\chainer-cifar\\src\\trainer.py\", line 26, in fit\n    return self.__fit(x, y, valid_x, valid_y, test_x, test_y, callback)\n  File \"c:\\project_2\\chainer\\chainer-cifar\\src\\trainer.py\", line 40, in __fit\n    loss, acc = self.__forward(x_batch, y[batch_index])\n  File \"c:\\project_2\\chainer\\chainer-cifar\\src\\trainer.py\", line 75, in __forward\n    y = self.net(x, train=train)\n  File \"c:\\project_2\\chainer\\chainer-cifar\\src\\net.py\", line 360, in __call__\n    h = self.bconv1_1(x, train)\n  File \"c:\\project_2\\chainer\\chainer-cifar\\src\\net.py\", line 28, in __call__\n    h = self.bn(self.conv(x), test=not train)\nTypeError: __call__() got an unexpected keyword argument 'test'\n\nchainer.links.BatchNormalization\u306e__call__\u306e\u5f15\u6570\u306btest\u304c\u306a\u3044\u306b\u3082\u304b\u304b\u308f\u3089\u305a\u6e21\u3057\u3066\u3044\u308b\u3068\u3044\u3046\u30a8\u30e9\u30fc\u3067\u3059\u3002\n\nChainer v2\u3067\u52d5\u4f5c\u3059\u308b\u3088\u3046\u306b\u4fee\u6b63\u3059\u308b\n\nchainer.functions.dropout\u306e\u547c\u3073\u51fa\u3057\u5f15\u6570\u304b\u3089train\u3092\u524a\u9664\nChainer v2\u304b\u3089\u306fdropout\u306e\u5f15\u6570train\u304c\u4e0d\u8981\u306b\u306a\u308b\u306e\u3067\u524a\u9664\u3057\u307e\u3059\u3002\n\u4fee\u6b63\u4f8b:\n\u4fee\u6b63\u524d:\nh = F.dropout(F.max_pooling_2d(h, 2), 0.25, train=train)\n\u4fee\u6b63\u5f8c:\nh = F.dropout(F.max_pooling_2d(h, 2), 0.25)\n\n\nchainer.links.BatchNormalization\u306e\u547c\u3073\u51fa\u3057\u5f15\u6570\u304b\u3089test\u3092\u524a\u9664\nBatchNormalization\u306e\u5f15\u6570test\u304c\u4e0d\u8981\u306b\u306a\u308b\u306e\u3067dropout\u306e\u5834\u5408\u3068\u540c\u69d8\u306b\u524a\u9664\u3057\u307e\u3059\u3002\n\u4fee\u6b63\u524d:\nclass BatchConv2D(chainer.Chain):\n    def __init__(self, ch_in, ch_out, ksize, stride=1, pad=0, activation=F.relu):\n        super(BatchConv2D, self).__init__(\n            conv=L.Convolution2D(ch_in, ch_out, ksize, stride, pad),\n            bn=L.BatchNormalization(ch_out),\n        )\n        self.activation=activation\n\n    def __call__(self, x, train):\n        h = self.bn(self.conv(x), test=not train)\n        if self.activation is None:\n            return h\n        return self.activation(h)\n\n\u4fee\u6b63\u5f8c:\nclass BatchConv2D(chainer.Chain):\n    def __init__(self, ch_in, ch_out, ksize, stride=1, pad=0, activation=F.relu):\n        super(BatchConv2D, self).__init__(\n            conv=L.Convolution2D(ch_in, ch_out, ksize, stride, pad),\n            bn=L.BatchNormalization(ch_out),\n        )\n        self.activation=activation\n\n    def __call__(self, x): # train\u3092\u524a\u9664\n        h = self.bn(self.conv(x)) # test\u3092\u524a\u9664\n        if self.activation is None:\n            return h\n        return self.activation(h)\n\n\n\u5b66\u7fd2\u4e2d\u3067\u306a\u3044\u5834\u5408\u306e\u51e6\u7406\u3092chainer.using_config('train', False)\u3067\u62ec\u308b\ndropout\u3084BatchNormalization\u306e\u547c\u3073\u51fa\u3057\u304b\u3089\u5f15\u6570train, test\u3092\u524a\u9664\u3057\u307e\u3057\u305f\u3002\n\u3053\u306e\u307e\u307e\u3060\u3068\u3053\u308c\u3089\u306e\u95a2\u6570\u304c\u5b66\u7fd2\u4e2d\u306e\u30e2\u30fc\u30c9\u3067\u52d5\u4f5c\u3057\u3066\u3057\u307e\u3044\u307e\u3059\u3002\nChainer v2\u304b\u3089\u306fwith chainer.using_config('train', ):\u3092\u4f7f\u3063\u3066\u5b66\u7fd2\u4e2d\u304b\u3069\u3046\u304b\u3092\u5236\u5fa1\u3057\u307e\u3059\u3002\n    with chainer.using_config('train', False):\n        # \u5b66\u7fd2\u4e2d\u3067\u306a\u3044\u5834\u5408\u306e\u51e6\u7406(\u30c6\u30b9\u30c8\u30c7\u30fc\u30bf\u306e\u7cbe\u5ea6\u8a08\u7b97\u306a\u3069)\n\n\n\u5b66\u7fd2\u4e2d\u304b\u3069\u3046\u304b\u3092chainer.config.train\u3067\u533a\u5225\u3059\u308b\nChainer v2\u304b\u3089chainer.config\u304c\u8ffd\u52a0\u3055\u308c\u3001\u5b66\u7fd2\u4e2d\u304b\u3069\u3046\u304b\u3001back propagation\u304c\u5fc5\u8981\u304b\u3069\u3046\u304b\u306a\u3069\u3092config\u3067\u5224\u65ad\u3067\u304d\u308b\u3088\u3046\u306b\u306a\u308a\u307e\u3057\u305f\u3002\n\u79c1\u306f\u4eca\u307e\u3067\u5b66\u7fd2\u4e2d\u304b\u3069\u3046\u304b\u3092\u3001\u4ee5\u4e0b\u306e\u3088\u3046\u306b\u81ea\u4f5c\u95a2\u6570\u306etrain\u5f15\u6570\u3067\u5224\u5b9a\u3057\u3066\u3044\u305f\u306e\u3067\u3059\u304c\u3001v2\u304b\u3089\u306ftrain\u5f15\u6570\u306f\u5fc5\u8981\u306a\u304fconfiguration.config.train\u3067\u5224\u5b9a\u3059\u308c\u3070\u3088\u3044\u3067\u3059\u3002\n\u4fee\u6b63\u524d:\ndef my_func(x, train=True):\n    if train:\n        # \u5b66\u7fd2\u4e2d\u306e\u51e6\u7406\n    else:\n        # \u5b66\u7fd2\u4e2d\u3067\u306a\u3044\u5834\u5408\u306e\u51e6\u7406\n\n\u4fee\u6b63\u5f8c:\ndef my_func(x):\n    if chainer.config.train:\n        # \u5b66\u7fd2\u4e2d\u306e\u51e6\u7406\n    else:\n        # \u5b66\u7fd2\u4e2d\u3067\u306a\u3044\u5834\u5408\u306e\u51e6\u7406\n\n\nback propagation\u304c\u4e0d\u8981\u306a\u5834\u5408\u306bchainer.using_config('train', False)\u3067\u62ec\u308b\nback propagation\u304c\u4e0d\u8981\u306a\u51e6\u7406\u3092chainer.using_config('train', False)\u3067\u62ec\u308a\u307e\u3059\u3002\n\u4eca\u307e\u3067chainer.Variable\u751f\u6210\u6642\u306bvolatile\u30d5\u30e9\u30b0\u3092ON\u306b\u3057\u3066\u3044\u305f\u30b1\u30fc\u30b9\u304c\u8a72\u5f53\u3057\u307e\u3059\u3002\n\nChainer v2 alpha\u3067\u306f\u5fc5\u8981\u306a\u3044\u304c\u4eca\u5f8c(beta\u4ee5\u964d\u3067)\u5fc5\u8981\u306b\u306a\u308b\u3053\u3068\n\nchainer.Variable\u306e\u5f15\u6570volatile\u3092\u524a\u9664\nv2 alpha\u306e\u6bb5\u968e\u3067\u306f\u6b8b\u3063\u3066\u3044\u307e\u3059\u304c\u4eca\u5f8cchainer.Variable\u306evolatile\u306f\u524a\u9664\u3055\u308c\u308b\u4e88\u5b9a\u3067\u3059\u3002\nvolatile\u306e\u4ee3\u308f\u308a\u306bchainer.using_config('enable_backprop', )\u3067\u5236\u5fa1\u3059\u308b\u3053\u3068\u306b\u306a\u308a\u307e\u3059\u3002\nchainer.functions\u3001chainer.links\u306e\u547c\u3073\u51fa\u3057\u306bVariable\u3067\u306f\u306a\u304fNumpy\u914d\u5217\u3001Cupy\u914d\u5217\u3092\u6e21\u305b\u308b\u3088\u3046\u306b\u306a\u3063\u3066\u3044\u308b\u306e\u3067\u3001Variable\u306e\u751f\u6210\u51e6\u7406\u3082\u524a\u9664\u3059\u308b\u9078\u629e\u80a2\u3082\u3042\u308b\u3068\u601d\u3044\u307e\u3059\u3002\n\u4fee\u6b63\u524d:\n    x = Variable(xp.asarray(batch_x), volatile=Train)\n\n\u4fee\u6b63\u5f8c:\n    with chainer.using_config('enable_backprop', False):\n        x = Variable(xp.asarray(batch_x))\n\n\n\u4fee\u6b63\u5f8c\u306e\u5b9f\u884c\nc:\\project_2\\chainer-cifar>python src\\train.py -g 0 -m vgg -p model\\temp -b 100 --iter 200 --lr 0.1 --optimizer sgd --weight_decay 0.0001 --lr_decay_iter 100,150\nDEBUG: nvcc STDOUT mod.cu\n   \u30e9\u30a4\u30d6\u30e9\u30ea C:/Users/user_name/AppData/Local/Theano/compiledir_Windows-10-10.0.14393-Intel64_Family_6_Model_58_Stepping_9_GenuineIntel-2.7.11-64/tmpiwxtcf/265abc51f7c376c224983485238ff1a5.lib \u3068\u30aa\u30d6\u30b8\u30a7\u30af\u30c8 C:/Users/user_name/AppData/Local/Theano/compiledir_Windows-10-10.0.14393-Intel64_Family_6_Model_58_Stepping_9_GenuineIntel-2.7.11-64/tmpiwxtcf/265abc51f7c376c224983485238ff1a5.exp \u3092\u4f5c \u6210\u4e2d\n\nUsing gpu device 0: GeForce GTX 1080 (CNMeM is disabled, cuDNN 5105)\nC:\\Users\\user_name\\Anaconda\\lib\\site-packages\\theano-0.8.2-py2.7.egg\\theano\\sandbox\\cuda\\__init__.py:600: UserWarning: Your cuDNN version is more recent than the one Theano officially supports. If you see any problems, try updating Theano or downgrading cuDNN to version 5.\n  warnings.warn(warn)\nloading dataset...\nstart training\nepoch 0 done\ntrain loss: 2.29680542204 error: 85.5222222221\nvalid loss: 1.95620539665 error: 81.3800000548\ntest  loss: 1.95627536774 error: 80.6099999845\ntest time: 1.04036228008s\nelapsed time: 23.5432411172\nepoch 1 done\ntrain loss: 1.91133875476 error: 76.8000000185\nvalid loss: 1.83026596069 error: 73.6399999559\ntest  loss: 1.8381768012 error: 73.2900000066\ntest time: 0.993011643337s\n\nChainer v2\u306b\u3059\u308b\u524d\u304b\u3089Theano\u5468\u308a\u3067Warning\u304c\u51fa\u3066\u3044\u308b\u306e\u3067\u3059\u304c\u3001\u52d5\u4f5c\u3057\u3066\u3044\u308b\u3088\u3046\u3067\u3059\u3002\n\n\u6700\u5f8c\u306b\nChainer v2\u5411\u3051\u306e\u4fee\u6b63\u306f\u96e3\u3057\u304f\u306f\u306a\u3044\u306e\u3067\u3059\u304c\u3001dropout\u3068BatchNormalization\u306e\u4f7f\u7528\u7b87\u6240\u304c\u591a\u304b\u3063\u305f\u306e\u3067\u3001\u305d\u306e\u5206\u4fee\u6b63\u91cf\u3068\u3057\u3066\u306f\u591a\u304f\u306a\u308a\u307e\u3057\u305f\u3002\n\u4fee\u6b63\u306e\u7d50\u679c\u3068\u3057\u3066\u3001\u3044\u304f\u3064\u304b\u306e\u95a2\u6570\u304c\u6301\u3063\u3066\u3044\u305f\u5f15\u6570train\u304c\u4e0d\u8981\u306b\u306a\u3063\u305f\u306e\u3067\u30b3\u30fc\u30c9\u304c\u5c11\u3057\u3059\u3063\u304d\u308a\u3057\u307e\u3057\u305f\u3002\nv1\u5411\u3051\u306b\u5b9f\u88c5\u3057\u305f\u591a\u304f\u306e\u30b3\u30fc\u30c9\u304cv2\u3067\u306f\u52d5\u304b\u306a\u304f\u306a\u308b\u3068\u601d\u3046\u306e\u3067\u3001v2\u304c\u6b63\u5f0f\u30ea\u30ea\u30fc\u30b9\u3055\u308c\u305f\u76f4\u5f8c\u306f\u62fe\u3063\u3066\u304d\u305fv1\u5411\u3051\u306e\u30b3\u30fc\u30c9\u3092\u52d5\u304b\u305d\u3046\u3068\u3057\u3066\u3082\u52d5\u304b\u306a\u3044\u3068\u3044\u3046\u4e8b\u8c61\u304c\u591a\u304f\u898b\u3089\u308c\u308b\u6c17\u304c\u3057\u307e\u3059\u3002\n# Chainer v2 alpha\n\nChainer v2 alpha\u304c\u30ea\u30ea\u30fc\u30b9\u3055\u308c\u305f\u306e\u3067\u3001\u81ea\u4f5c\u306e\u30bd\u30fc\u30b9\u30b3\u30fc\u30c9\u3092\u5bfe\u5fdc\u3055\u305b\u3066\u307f\u307e\u3057\u305f\u3002\n\u4ee5\u4e0b\u306e\u30b5\u30a4\u30c8\u3092\u53c2\u8003\u306b\u3057\u307e\u3057\u305f\u3002\n\n* [\u516c\u5f0f\u30c9\u30ad\u30e5\u30e1\u30f3\u30c8](http://docs.chainer.org/en/v2.0.0a1/index.html)\n* [Chainer Meetup #4\u306e\u767a\u8868\u30b9\u30e9\u30a4\u30c9](https://www.slideshare.net/beam2d/chainer-v2-alpha)\n\n# \u52d5\u4f5c\u74b0\u5883\n\n* OS: Windows 10(64bit)\n* Python: Python 2.7.11 :: Anaconda custom (64-bit)\n* GPU: GTX 1080\n\n# \u4f7f\u7528\u3057\u305f\u30ea\u30dd\u30b8\u30c8\u30ea\n\n[\u4ee5\u524d\u4f5c\u6210\u3057\u305fCIFAR-10\u306e\u753b\u50cf\u8a8d\u8b58](http://qiita.com/dsanno/items/ad84f078520f9c9c3ed1)\u306e\u30ea\u30dd\u30b8\u30c8\u30ea\u306bChainer v2\u7528\u306e\u30d6\u30e9\u30f3\u30c1\u3092\u4f5c\u6210\u3057\u307e\u3057\u305f\u3002\n\nhttps://github.com/dsanno/chainer-cifar/tree/chainer_v2\n\n# \u30a4\u30f3\u30b9\u30c8\u30fc\u30eb\n\nChainer Meetup\u306e\u30b9\u30e9\u30a4\u30c9\u306b\u3042\u308b\u3088\u3046\u306b\u3001\u4ee5\u4e0b\u306e\u30b3\u30de\u30f3\u30c9\u3067\u30a4\u30f3\u30b9\u30c8\u30fc\u30eb\u3067\u304d\u307e\u3057\u305f\u3002\n\u5ff5\u306e\u305f\u3081`--no-cache-dir`\u3092\u3064\u3051\u307e\u3057\u305f\u3002\n\n```\n$ pip install chainer --pre --no-cache-dir\n$ pip install cupy --no-cache-dir\n```\n\n# \u3068\u308a\u3042\u3048\u305a\u5b9f\u884c\u3057\u3066\u307f\u308b\n\nChainer v2\u306e\u4fee\u6b63\u306b\u3088\u308a\u5f8c\u65b9\u4e92\u63db\u6027\u304c\u58ca\u308c\u308b\u306e\u3067\u3001\u52d5\u4f5c\u3057\u306a\u3044\u3053\u3068\u306f\u4e88\u60f3\u3067\u304d\u3066\u3044\u308b\u306e\u3067\u3059\u304c\u3068\u308a\u3042\u3048\u305a\u5b9f\u884c\u3057\u3066\u307f\u307e\u3059\u3002\n\n```\n$ python src/train.py -g 0 -m vgg -p model\\temp9 -b 100 --iter 200 --lr 0.1 --optimizer sgd --weight_decay 0.0001 --lr_decay_iter 100,150\n```\n\n\u4ee5\u4e0b\u306e\u30a8\u30e9\u30fc\u304c\u767a\u751f\u3057\u307e\u3057\u305f\u3002\n\n```\nTraceback (most recent call last):\n  File \"src\\train.py\", line 143, in <module>\n    cifar_trainer.fit(train_x, train_y, valid_x, valid_y, test_x, test_y, on_epoch_done)\n  File \"c:\\project_2\\chainer\\chainer-cifar\\src\\trainer.py\", line 26, in fit\n    return self.__fit(x, y, valid_x, valid_y, test_x, test_y, callback)\n  File \"c:\\project_2\\chainer\\chainer-cifar\\src\\trainer.py\", line 40, in __fit\n    loss, acc = self.__forward(x_batch, y[batch_index])\n  File \"c:\\project_2\\chainer\\chainer-cifar\\src\\trainer.py\", line 75, in __forward\n    y = self.net(x, train=train)\n  File \"c:\\project_2\\chainer\\chainer-cifar\\src\\net.py\", line 360, in __call__\n    h = self.bconv1_1(x, train)\n  File \"c:\\project_2\\chainer\\chainer-cifar\\src\\net.py\", line 28, in __call__\n    h = self.bn(self.conv(x), test=not train)\nTypeError: __call__() got an unexpected keyword argument 'test'\n```\n\n`chainer.links.BatchNormalization`\u306e`__call__`\u306e\u5f15\u6570\u306b`test`\u304c\u306a\u3044\u306b\u3082\u304b\u304b\u308f\u3089\u305a\u6e21\u3057\u3066\u3044\u308b\u3068\u3044\u3046\u30a8\u30e9\u30fc\u3067\u3059\u3002\n\n# Chainer v2\u3067\u52d5\u4f5c\u3059\u308b\u3088\u3046\u306b\u4fee\u6b63\u3059\u308b\n\n## chainer.functions.dropout\u306e\u547c\u3073\u51fa\u3057\u5f15\u6570\u304b\u3089train\u3092\u524a\u9664\n\nChainer v2\u304b\u3089\u306f`dropout`\u306e\u5f15\u6570`train`\u304c\u4e0d\u8981\u306b\u306a\u308b\u306e\u3067\u524a\u9664\u3057\u307e\u3059\u3002\n\n\u4fee\u6b63\u4f8b:\n\n```python\n\u4fee\u6b63\u524d:\nh = F.dropout(F.max_pooling_2d(h, 2), 0.25, train=train)\n\u4fee\u6b63\u5f8c:\nh = F.dropout(F.max_pooling_2d(h, 2), 0.25)\n```\n\n## chainer.links.BatchNormalization\u306e\u547c\u3073\u51fa\u3057\u5f15\u6570\u304b\u3089test\u3092\u524a\u9664\n\n`BatchNormalization`\u306e\u5f15\u6570`test`\u304c\u4e0d\u8981\u306b\u306a\u308b\u306e\u3067`dropout`\u306e\u5834\u5408\u3068\u540c\u69d8\u306b\u524a\u9664\u3057\u307e\u3059\u3002\n\n\u4fee\u6b63\u524d:\n\n```python\nclass BatchConv2D(chainer.Chain):\n    def __init__(self, ch_in, ch_out, ksize, stride=1, pad=0, activation=F.relu):\n        super(BatchConv2D, self).__init__(\n            conv=L.Convolution2D(ch_in, ch_out, ksize, stride, pad),\n            bn=L.BatchNormalization(ch_out),\n        )\n        self.activation=activation\n\n    def __call__(self, x, train):\n        h = self.bn(self.conv(x), test=not train)\n        if self.activation is None:\n            return h\n        return self.activation(h)\n```\n\n\u4fee\u6b63\u5f8c:\n\n```python\nclass BatchConv2D(chainer.Chain):\n    def __init__(self, ch_in, ch_out, ksize, stride=1, pad=0, activation=F.relu):\n        super(BatchConv2D, self).__init__(\n            conv=L.Convolution2D(ch_in, ch_out, ksize, stride, pad),\n            bn=L.BatchNormalization(ch_out),\n        )\n        self.activation=activation\n\n    def __call__(self, x): # train\u3092\u524a\u9664\n        h = self.bn(self.conv(x)) # test\u3092\u524a\u9664\n        if self.activation is None:\n            return h\n        return self.activation(h)\n```\n\n## \u5b66\u7fd2\u4e2d\u3067\u306a\u3044\u5834\u5408\u306e\u51e6\u7406\u3092chainer.using_config('train', False)\u3067\u62ec\u308b\n\n`dropout`\u3084`BatchNormalization`\u306e\u547c\u3073\u51fa\u3057\u304b\u3089\u5f15\u6570`train`, `test`\u3092\u524a\u9664\u3057\u307e\u3057\u305f\u3002\n\u3053\u306e\u307e\u307e\u3060\u3068\u3053\u308c\u3089\u306e\u95a2\u6570\u304c\u5b66\u7fd2\u4e2d\u306e\u30e2\u30fc\u30c9\u3067\u52d5\u4f5c\u3057\u3066\u3057\u307e\u3044\u307e\u3059\u3002\nChainer v2\u304b\u3089\u306f`with chainer.using_config('train', ):`\u3092\u4f7f\u3063\u3066\u5b66\u7fd2\u4e2d\u304b\u3069\u3046\u304b\u3092\u5236\u5fa1\u3057\u307e\u3059\u3002\n\n```python\n    with chainer.using_config('train', False):\n        # \u5b66\u7fd2\u4e2d\u3067\u306a\u3044\u5834\u5408\u306e\u51e6\u7406(\u30c6\u30b9\u30c8\u30c7\u30fc\u30bf\u306e\u7cbe\u5ea6\u8a08\u7b97\u306a\u3069)\n```\n\n## \u5b66\u7fd2\u4e2d\u304b\u3069\u3046\u304b\u3092chainer.config.train\u3067\u533a\u5225\u3059\u308b\n\nChainer v2\u304b\u3089`chainer.config`\u304c\u8ffd\u52a0\u3055\u308c\u3001\u5b66\u7fd2\u4e2d\u304b\u3069\u3046\u304b\u3001back propagation\u304c\u5fc5\u8981\u304b\u3069\u3046\u304b\u306a\u3069\u3092`config`\u3067\u5224\u65ad\u3067\u304d\u308b\u3088\u3046\u306b\u306a\u308a\u307e\u3057\u305f\u3002\n\u79c1\u306f\u4eca\u307e\u3067\u5b66\u7fd2\u4e2d\u304b\u3069\u3046\u304b\u3092\u3001\u4ee5\u4e0b\u306e\u3088\u3046\u306b\u81ea\u4f5c\u95a2\u6570\u306e`train`\u5f15\u6570\u3067\u5224\u5b9a\u3057\u3066\u3044\u305f\u306e\u3067\u3059\u304c\u3001v2\u304b\u3089\u306f`train`\u5f15\u6570\u306f\u5fc5\u8981\u306a\u304f`configuration.config.train`\u3067\u5224\u5b9a\u3059\u308c\u3070\u3088\u3044\u3067\u3059\u3002\n\n\u4fee\u6b63\u524d:\n\n```python\ndef my_func(x, train=True):\n    if train:\n        # \u5b66\u7fd2\u4e2d\u306e\u51e6\u7406\n    else:\n        # \u5b66\u7fd2\u4e2d\u3067\u306a\u3044\u5834\u5408\u306e\u51e6\u7406\n```\n\n\u4fee\u6b63\u5f8c:\n\n```python\ndef my_func(x):\n    if chainer.config.train:\n        # \u5b66\u7fd2\u4e2d\u306e\u51e6\u7406\n    else:\n        # \u5b66\u7fd2\u4e2d\u3067\u306a\u3044\u5834\u5408\u306e\u51e6\u7406\n```\n\n## back propagation\u304c\u4e0d\u8981\u306a\u5834\u5408\u306bchainer.using_config('train', False)\u3067\u62ec\u308b\n\nback propagation\u304c\u4e0d\u8981\u306a\u51e6\u7406\u3092`chainer.using_config('train', False)`\u3067\u62ec\u308a\u307e\u3059\u3002\n\u4eca\u307e\u3067`chainer.Variable`\u751f\u6210\u6642\u306b`volatile`\u30d5\u30e9\u30b0\u3092ON\u306b\u3057\u3066\u3044\u305f\u30b1\u30fc\u30b9\u304c\u8a72\u5f53\u3057\u307e\u3059\u3002\n\n# Chainer v2 alpha\u3067\u306f\u5fc5\u8981\u306a\u3044\u304c\u4eca\u5f8c(beta\u4ee5\u964d\u3067)\u5fc5\u8981\u306b\u306a\u308b\u3053\u3068\n\n## chainer.Variable\u306e\u5f15\u6570volatile\u3092\u524a\u9664\n\nv2 alpha\u306e\u6bb5\u968e\u3067\u306f\u6b8b\u3063\u3066\u3044\u307e\u3059\u304c\u4eca\u5f8c`chainer.Variable`\u306e`volatile`\u306f\u524a\u9664\u3055\u308c\u308b\u4e88\u5b9a\u3067\u3059\u3002\n`volatile`\u306e\u4ee3\u308f\u308a\u306b`chainer.using_config('enable_backprop', )`\u3067\u5236\u5fa1\u3059\u308b\u3053\u3068\u306b\u306a\u308a\u307e\u3059\u3002\n`chainer.functions`\u3001`chainer.links`\u306e\u547c\u3073\u51fa\u3057\u306b`Variable`\u3067\u306f\u306a\u304fNumpy\u914d\u5217\u3001Cupy\u914d\u5217\u3092\u6e21\u305b\u308b\u3088\u3046\u306b\u306a\u3063\u3066\u3044\u308b\u306e\u3067\u3001`Variable`\u306e\u751f\u6210\u51e6\u7406\u3082\u524a\u9664\u3059\u308b\u9078\u629e\u80a2\u3082\u3042\u308b\u3068\u601d\u3044\u307e\u3059\u3002\n\n\u4fee\u6b63\u524d:\n\n```python\n    x = Variable(xp.asarray(batch_x), volatile=Train)\n```\n\n\u4fee\u6b63\u5f8c:\n\n```python\n    with chainer.using_config('enable_backprop', False):\n        x = Variable(xp.asarray(batch_x))\n```\n\n# \u4fee\u6b63\u5f8c\u306e\u5b9f\u884c\n\n```\nc:\\project_2\\chainer-cifar>python src\\train.py -g 0 -m vgg -p model\\temp -b 100 --iter 200 --lr 0.1 --optimizer sgd --weight_decay 0.0001 --lr_decay_iter 100,150\nDEBUG: nvcc STDOUT mod.cu\n   \u30e9\u30a4\u30d6\u30e9\u30ea C:/Users/user_name/AppData/Local/Theano/compiledir_Windows-10-10.0.14393-Intel64_Family_6_Model_58_Stepping_9_GenuineIntel-2.7.11-64/tmpiwxtcf/265abc51f7c376c224983485238ff1a5.lib \u3068\u30aa\u30d6\u30b8\u30a7\u30af\u30c8 C:/Users/user_name/AppData/Local/Theano/compiledir_Windows-10-10.0.14393-Intel64_Family_6_Model_58_Stepping_9_GenuineIntel-2.7.11-64/tmpiwxtcf/265abc51f7c376c224983485238ff1a5.exp \u3092\u4f5c \u6210\u4e2d\n\nUsing gpu device 0: GeForce GTX 1080 (CNMeM is disabled, cuDNN 5105)\nC:\\Users\\user_name\\Anaconda\\lib\\site-packages\\theano-0.8.2-py2.7.egg\\theano\\sandbox\\cuda\\__init__.py:600: UserWarning: Your cuDNN version is more recent than the one Theano officially supports. If you see any problems, try updating Theano or downgrading cuDNN to version 5.\n  warnings.warn(warn)\nloading dataset...\nstart training\nepoch 0 done\ntrain loss: 2.29680542204 error: 85.5222222221\nvalid loss: 1.95620539665 error: 81.3800000548\ntest  loss: 1.95627536774 error: 80.6099999845\ntest time: 1.04036228008s\nelapsed time: 23.5432411172\nepoch 1 done\ntrain loss: 1.91133875476 error: 76.8000000185\nvalid loss: 1.83026596069 error: 73.6399999559\ntest  loss: 1.8381768012 error: 73.2900000066\ntest time: 0.993011643337s\n```\n\nChainer v2\u306b\u3059\u308b\u524d\u304b\u3089Theano\u5468\u308a\u3067Warning\u304c\u51fa\u3066\u3044\u308b\u306e\u3067\u3059\u304c\u3001\u52d5\u4f5c\u3057\u3066\u3044\u308b\u3088\u3046\u3067\u3059\u3002\n\n# \u6700\u5f8c\u306b\n\nChainer v2\u5411\u3051\u306e\u4fee\u6b63\u306f\u96e3\u3057\u304f\u306f\u306a\u3044\u306e\u3067\u3059\u304c\u3001`dropout`\u3068`BatchNormalization`\u306e\u4f7f\u7528\u7b87\u6240\u304c\u591a\u304b\u3063\u305f\u306e\u3067\u3001\u305d\u306e\u5206\u4fee\u6b63\u91cf\u3068\u3057\u3066\u306f\u591a\u304f\u306a\u308a\u307e\u3057\u305f\u3002\n\u4fee\u6b63\u306e\u7d50\u679c\u3068\u3057\u3066\u3001\u3044\u304f\u3064\u304b\u306e\u95a2\u6570\u304c\u6301\u3063\u3066\u3044\u305f\u5f15\u6570`train`\u304c\u4e0d\u8981\u306b\u306a\u3063\u305f\u306e\u3067\u30b3\u30fc\u30c9\u304c\u5c11\u3057\u3059\u3063\u304d\u308a\u3057\u307e\u3057\u305f\u3002\nv1\u5411\u3051\u306b\u5b9f\u88c5\u3057\u305f\u591a\u304f\u306e\u30b3\u30fc\u30c9\u304cv2\u3067\u306f\u52d5\u304b\u306a\u304f\u306a\u308b\u3068\u601d\u3046\u306e\u3067\u3001v2\u304c\u6b63\u5f0f\u30ea\u30ea\u30fc\u30b9\u3055\u308c\u305f\u76f4\u5f8c\u306f\u62fe\u3063\u3066\u304d\u305fv1\u5411\u3051\u306e\u30b3\u30fc\u30c9\u3092\u52d5\u304b\u305d\u3046\u3068\u3057\u3066\u3082\u52d5\u304b\u306a\u3044\u3068\u3044\u3046\u4e8b\u8c61\u304c\u591a\u304f\u898b\u3089\u308c\u308b\u6c17\u304c\u3057\u307e\u3059\u3002\n", "tags": ["Chainer", "Python", "DeepLearning"]}