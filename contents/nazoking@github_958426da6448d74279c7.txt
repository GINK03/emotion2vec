{"tags": ["scikit-learn", "\u6a5f\u68b0\u5b66\u7fd2", "MachineLearning", "Python"], "context": "http://scikit-learn.org/0.18/modules/model_evaluation.html \u3092 google\u7ffb\u8a33\u3057\u305f\n\u30e6\u30fc\u30b6\u30fc\u30ac\u30a4\u30c9\u76ee\u6b21\n\n\u30e2\u30c7\u30eb\u306e\u4e88\u6e2c\u306e\u8cea\u3092\u8a55\u4fa1\u3059\u308b3\u3064\u306e\u7570\u306a\u308b\u30a2\u30d7\u30ed\u30fc\u30c1\u304c\u3042\u308a\u307e\u3059\u3002\n\n\n\u63a8\u5b9a\u5668\u30b9\u30b3\u30a2\u30e1\u30bd\u30c3\u30c9 \uff1a\u63a8\u5b9a\u5668\u306b\u306f\u3001\u89e3\u6c7a\u3059\u308b\u3088\u3046\u306b\u8a2d\u8a08\u3055\u308c\u305f\u554f\u984c\u306e\u65e2\u5b9a\u306e\u8a55\u4fa1\u57fa\u6e96\u3092\u63d0\u4f9b\u3059\u308b score\u30e1\u30bd\u30c3\u30c9\u304c\u3042\u308a\u307e\u3059\u3002\u3053\u308c\u306f\u3053\u306e\u30da\u30fc\u30b8\u3067\u306f\u306a\u304f\u3001\u5404\u63a8\u5b9a\u5668\u306e\u30c9\u30ad\u30e5\u30e1\u30f3\u30c8\u306b\u8a18\u8f09\u3055\u308c\u3066\u3044\u307e\u3059\u3002\n\n\u30b9\u30b3\u30a2\u30ea\u30f3\u30b0\u30d1\u30e9\u30e1\u30fc\u30bf \uff1a \u30af\u30ed\u30b9\u30d0\u30ea\u30c7\u30fc\u30b7\u30e7\u30f3 \u3092\u4f7f\u7528\u3059\u308b\u30e2\u30c7\u30eb\u8a55\u4fa1\u30c4\u30fc\u30eb\uff08 model_selection.cross_val_score \u3084 model_selection.GridSearchCV \u306a\u3069\uff09\u306f\u3001\u5185\u90e8\u30b9\u30b3\u30a2\u30ea\u30f3\u30b0\u6226\u7565\u306b\u4f9d\u5b58\u3057\u307e\u3059\u3002\u3053\u308c\u306b\u3064\u3044\u3066\u306f\u3001\u30b9\u30b3\u30a2\u30ea\u30f3\u30b0\u30d1\u30e9\u30e1\u30fc\u30bf\uff1a\u30e2\u30c7\u30eb\u8a55\u4fa1\u30eb\u30fc\u30eb\u306e\u5b9a\u7fa9 \u306e\u7bc0\u3067\u8aac\u660e\u3057\u307e\u3059\u3002\n\n\u30e1\u30c8\u30ea\u30c3\u30af\u95a2\u6570 \uff1a\u30e1\u30c8\u30ea\u30c3\u30af\u30e2\u30b8\u30e5\u30fc\u30eb\u306f\u3001\u7279\u5b9a\u306e\u76ee\u7684\u306e\u305f\u3081\u306b\u4e88\u6e2c\u30a8\u30e9\u30fc\u3092\u8a55\u4fa1\u3059\u308b\u95a2\u6570\u3092\u5b9f\u88c5\u3057\u307e\u3059\u3002\u3053\u308c\u3089\u306e\u30e1\u30c8\u30ea\u30c3\u30af\u306f\u3001\u5206\u985e\u30e1\u30c8\u30ea\u30c3\u30af\u3001\u30de\u30eb\u30c1\u30e9\u30d9\u30eb\u30e9\u30f3\u30ad\u30f3\u30b0\u30e1\u30c8\u30ea\u30c3\u30af\u3001\u56de\u5e30\u30e1\u30c8\u30ea\u30c3\u30af\u3001\u304a\u3088\u3073\u30af\u30e9\u30b9\u30bf\u30ea\u30f3\u30b0\u30e1\u30c8\u30ea\u30c3\u30af\u306b\u95a2\u3059\u308b\u30bb\u30af\u30b7\u30e7\u30f3\u3067\u8a73\u3057\u304f\u8aac\u660e\u3057\u3066\u3044\u307e\u3059\u3002\n\n\u6700\u5f8c\u306b\u3001\u30c0\u30df\u30fc\u8a55\u4fa1\u5668\u306f\u3001\u30e9\u30f3\u30c0\u30e0\u4e88\u6e2c\u306e\u305f\u3081\u306e\u305d\u308c\u3089\u306e\u30e1\u30c8\u30ea\u30c3\u30af\u306e\u30d9\u30fc\u30b9\u30e9\u30a4\u30f3\u5024\u3092\u5f97\u308b\u306e\u306b\u4fbf\u5229\u3067\u3059\u3002\n\n\n\u53c2\u7167: \u300c\u30da\u30a2\u3054\u3068\u306e\u300d\u30e1\u30c8\u30ea\u30c3\u30af\u3001\u30b5\u30f3\u30d7\u30eb\u3068\u63a8\u5b9a\u5024\u307e\u305f\u306f\u4e88\u6e2c\u3068\u306e\u9593\u306e\u9055\u3044\u306b\u3064\u3044\u3066\u306f\u3001\u30da\u30a2\u30ef\u30a4\u30ba\u30e1\u30c8\u30ea\u30c3\u30af\u3001\u30a2\u30d5\u30a3\u30cb\u30c6\u30a3\u304a\u3088\u3073\u30ab\u30fc\u30cd\u30eb\u306e\u30bb\u30af\u30b7\u30e7\u30f3\u3092\u53c2\u7167\u3057\u3066\u304f\u3060\u3055\u3044\u3002\n\n\n3.3.1. \u5f97\u70b9\u30d1\u30e9\u30e1\u30fc\u30bf\uff1a\u30e2\u30c7\u30eb\u8a55\u4fa1\u30eb\u30fc\u30eb\u306e\u5b9a\u7fa9\nmodel_selection.GridSearchCV \u3084 model_selection.cross_val_score \u306a\u3069\u306e\u30c4\u30fc\u30eb\u3092\u4f7f\u7528\u3057\u305f\u30e2\u30c7\u30eb\u306e\u9078\u629e\u3068\u8a55\u4fa1\u3067\u306f\u3001\u8a55\u4fa1\u6307\u6a19\u306b\u9069\u7528\u3059\u308b\u30e1\u30c8\u30ea\u30c3\u30af\u3092\u5236\u5fa1\u3059\u308b scoring \u30d1\u30e9\u30e1\u30fc\u30bf\u3092\u4f7f\u7528\u3057\u307e\u3059\u3002\n\n3.3.1.1. \u4e00\u822c\u7684\u306a\u30b1\u30fc\u30b9\uff1a\u5b9a\u7fa9\u6e08\u307f\u306e\u5024\n\u6700\u3082\u4e00\u822c\u7684\u306a\u4f7f\u7528\u4f8b\u306b\u3064\u3044\u3066\u306f\u3001scoring \u30d1\u30e9\u30e1\u30fc\u30bf\u3092\u4f7f\u7528\u3057\u3066\u5f97\u70b9\u30aa\u30d6\u30b8\u30a7\u30af\u30c8\u3092\u6307\u5b9a\u3059\u308b\u3053\u3068\u304c\u3067\u304d\u307e\u3059\u3002 \u4ee5\u4e0b\u306e\u8868\u306f\u3059\u3079\u3066\u306e\u53ef\u80fd\u306a\u5024\u3092\u793a\u3057\u3066\u3044\u307e\u3059\u3002 \u3059\u3079\u3066\u306e\u30b9\u30b3\u30a2\u30e9\u30fc\u30aa\u30d6\u30b8\u30a7\u30af\u30c8\u306f\u3001 \u3088\u308a\u9ad8\u3044\u623b\u308a\u5024\u304c\u4f4e\u3044\u623b\u308a\u5024\u3088\u308a\u3082\u512a\u308c\u3066\u3044\u308b \u3068\u3044\u3046\u898f\u5247\u306b\u5f93\u3044\u307e\u3059\u3002 \u3057\u305f\u304c\u3063\u3066\u3001 metrics.mean_squared_error \u306e\u3088\u3046\u306b\u3001\u30e2\u30c7\u30eb\u3068\u30c7\u30fc\u30bf\u306e\u9593\u306e\u8ddd\u96e2\u3092\u6e2c\u5b9a\u3059\u308b\u30e1\u30c8\u30ea\u30c3\u30af\u306f\u3001\u30e1\u30c8\u30ea\u30c3\u30af\u306e\u5426\u5b9a\u3055\u308c\u305f\u5024\u3092\u8fd4\u3059 neg_mean_squared_error\u3068\u3057\u3066\u5229\u7528\u3067\u304d\u307e\u3059\u3002\n\n\n\nScoring\nFunction\nComment\n\n\n\n\n\u5206\u985e\n\n\n\n\n\u2018accuracy\u2019\nmetrics.accuracy_score\n\n\n\n\u2018average_precision\u2019\nmetrics.average_precision_score\n\n\n\n\u2018f1\u2019\nmetrics.f1_score\n\u30d0\u30a4\u30ca\u30ea\u30bf\u30fc\u30b2\u30c3\u30c8\u306e\u5834\u5408\n\n\n\u2018f1_micro\u2019\nmetrics.f1_score\n\u30df\u30af\u30ed\u5e73\u5747\u5316\n\n\n\u2018f1_macro\u2019\nmetrics.f1_score\n\u30de\u30af\u30ed\u5e73\u5747\u5316\n\n\n\u2018f1_weighted\u2019\nmetrics.f1_score\n\u52a0\u91cd\u5e73\u5747\n\n\n\u2018f1_samples\u2019\nmetrics.f1_score\n\u30de\u30eb\u30c1\u30e9\u30d9\u30eb\u30b5\u30f3\u30d7\u30eb\n\n\n\u2018neg_log_loss\u2019\nmetrics.log_loss\n\npredict_proba \u30b5\u30dd\u30fc\u30c8\u304c\u5fc5\u8981\u3067\u3059\n\n\n\u2018precision\u2019 etc.\nmetrics.precision_score\n\u63a5\u5c3e\u8f9e\u306f 'f1'\u3068\u540c\u69d8\u306b\u9069\u7528\u3055\u308c\u307e\u3059\u3002\n\n\n\u2018recall\u2019 etc.\nmetrics.recall_score\n\u63a5\u5c3e\u8f9e\u306f 'f1'\u3068\u540c\u69d8\u306b\u9069\u7528\u3055\u308c\u307e\u3059\u3002\n\n\n\u2018roc_auc\u2019\nmetrics.roc_auc_score\n\n\n\n\u30af\u30e9\u30b9\u30bf\u30ea\u30f3\u30b0\n\n\n\n\n\u2018adjusted_rand_score\u2019\nmetrics.adjusted_rand_score\n\n\n\n\u56de\u5e30\n\n\n\n\n\u2018neg_mean_absolute_error\u2019\nmetrics.mean_absolute_error\n\n\n\n\u2018neg_mean_squared_error\u2019\nmetrics.mean_squared_error\n\n\n\n\u2018neg_median_absolute_error\u2019\nmetrics.median_absolute_error\n\n\n\n\u2018r2\u2019\nmetrics.r2_score\n\n\n\n\nUsage examples:\n>>>\n>>> from sklearn import svm, datasets\n>>> from sklearn.model_selection import cross_val_score\n>>> iris = datasets.load_iris()\n>>> X, y = iris.data, iris.target\n>>> clf = svm.SVC(probability=True, random_state=0)\n>>> cross_val_score(clf, X, y, scoring='neg_log_loss') \narray([-0.07..., -0.16..., -0.06...])\n>>> model = svm.SVC()\n>>> cross_val_score(model, X, y, scoring='wrong_choice')\nTraceback (most recent call last):\nValueError: 'wrong_choice' is not a valid scoring value. Valid options are ['accuracy', 'adjusted_rand_score', 'average_precision', 'f1', 'f1_macro', 'f1_micro', 'f1_samples', 'f1_weighted', 'neg_log_loss', 'neg_mean_absolute_error', 'neg_mean_squared_error', 'neg_median_absolute_error', 'precision', 'precision_macro', 'precision_micro', 'precision_samples', 'precision_weighted', 'r2', 'recall', 'recall_macro', 'recall_micro', 'recall_samples', 'recall_weighted', 'roc_auc']\n\n\n\nNote: ValueError\u4f8b\u5916\u306b\u3088\u3063\u3066\u30ea\u30b9\u30c8\u3055\u308c\u305f\u5024\u306f\u3001\u6b21\u306e\u30bb\u30af\u30b7\u30e7\u30f3\u3067\u8aac\u660e\u3059\u308b\u4e88\u6e2c\u7cbe\u5ea6\u3092\u6e2c\u5b9a\u3059\u308b\u95a2\u6570\u306b\u5bfe\u5fdc\u3057\u3066\u3044\u307e\u3059\u3002\u3053\u308c\u3089\u306e\u95a2\u6570\u306e\u30b9\u30b3\u30a2\u30e9\u30fc\u30aa\u30d6\u30b8\u30a7\u30af\u30c8\u306f\u3001\u8f9e\u66f8sklearn.metrics.SCORERS\u306b\u683c\u7d0d\u3055\u308c\u307e\u3059\u3002\n\n\n3.3.1.2. \u30e1\u30c8\u30ea\u30c3\u30af\u95a2\u6570\u304b\u3089\u30b9\u30b3\u30a2\u30ea\u30f3\u30b0\u6226\u7565\u3092\u5b9a\u7fa9\u3059\u308b\n\u30e2\u30b8\u30e5\u30fc\u30eb sklearn.metric \u306f\u307e\u305f\u3001\u5b9f\u6e2c\u5024\u3068\u4e88\u6e2c\u3092\u4e0e\u3048\u3089\u308c\u305f\u4e88\u6e2c\u8aa4\u5dee\u3092\u6e2c\u5b9a\u3059\u308b\u5358\u7d14\u306a\u95a2\u6570\u306e\u30bb\u30c3\u30c8\u3092\u516c\u958b\u3057\u3066\u3044\u307e\u3059\uff1a\n\n\n_score \u3067\u7d42\u308f\u308b\u95a2\u6570\u306f\u3001\u6700\u5927\u5316\u3059\u308b\u5024\u3092\u8fd4\u3057\u307e\u3059\u3002\n\n_error \u307e\u305f\u306f _loss \u3067\u7d42\u308f\u308b\u95a2\u6570\u306f\u3001\u6700\u5c0f\u5024\u306b\u623b\u3059\u5024\u3092\u8fd4\u3057\u307e\u3059\u3002 make_scorer \u3092\u4f7f\u7528\u3057\u3066\u30b9\u30b3\u30a2\u30e9\u30fc\u30aa\u30d6\u30b8\u30a7\u30af\u30c8\u306b\u5909\u63db\u3059\u308b\u3068\u304d\u306f\u3001greater_is_better \u30d1\u30e9\u30e1\u30fc\u30bf\u30fc\u3092False\u306b\u8a2d\u5b9a\u3057\u307e\u3059\uff08\u30c7\u30d5\u30a9\u30eb\u30c8\u3067\u306fTrue\u3001\u4ee5\u4e0b\u306e\u30d1\u30e9\u30e1\u30fc\u30bf\u30fc\u306e\u8aac\u660e\u3092\u53c2\u7167\uff09\u3002\n\u3055\u307e\u3056\u307e\u306a\u6a5f\u68b0\u5b66\u7fd2\u30bf\u30b9\u30af\u3067\u4f7f\u7528\u3067\u304d\u308b\u6307\u6a19\u306b\u3064\u3044\u3066\u306f\u3001\u4ee5\u4e0b\u306e\u30bb\u30af\u30b7\u30e7\u30f3\u3067\u8a73\u3057\u304f\u8aac\u660e\u3057\u307e\u3059\u3002\n\n\u591a\u304f\u306e\u30e1\u30c8\u30ea\u30c3\u30af\u306b\u306f\u3001fbeta_score \u306a\u3069\u306e\u8ffd\u52a0\u30d1\u30e9\u30e1\u30fc\u30bf\u304c\u5fc5\u8981\u306a\u5834\u5408\u304c\u3042\u308b\u305f\u3081\u3001\u30b9\u30b3\u30a2\u30ea\u30f3\u30b0\u5024\u3068\u3057\u3066\u4f7f\u7528\u3059\u308b\u540d\u524d\u306f\u3042\u308a\u307e\u305b\u3093\u3002\u305d\u306e\u3088\u3046\u306a\u5834\u5408\u306f\u3001\u9069\u5207\u306a\u30b9\u30b3\u30a2\u30ea\u30f3\u30b0\u30aa\u30d6\u30b8\u30a7\u30af\u30c8\u3092\u751f\u6210\u3059\u308b\u5fc5\u8981\u304c\u3042\u308a\u307e\u3059\u3002\u547c\u3073\u51fa\u3057\u53ef\u80fd\u306a\u30aa\u30d6\u30b8\u30a7\u30af\u30c8\u3092\u751f\u6210\u3059\u308b\u6700\u3082\u7c21\u5358\u306a\u65b9\u6cd5\u306f\u3001make_scorer \u3092\u4f7f\u7528\u3059\u308b\u65b9\u6cd5\u3067\u3059\u3002\u3053\u306e\u95a2\u6570\u306f\u3001\u30e1\u30c8\u30ea\u30c3\u30af\u3092\u30e2\u30c7\u30eb\u8a55\u4fa1\u306b\u4f7f\u7528\u3067\u304d\u308b\u547c\u3073\u51fa\u3057\u53ef\u80fd\u30aa\u30d6\u30b8\u30a7\u30af\u30c8\u306b\u5909\u63db\u3057\u307e\u3059\u3002\n\u5178\u578b\u7684\u306a\u4f7f\u7528\u4f8b\u306e1\u3064\u306f\u3001fbeta_score\u95a2\u6570\u306e\u30d9\u30fc\u30bf\u30d1\u30e9\u30e1\u30fc\u30bf\u306a\u3069\u3001\u30d1\u30e9\u30e1\u30fc\u30bf\u306b\u30c7\u30d5\u30a9\u30eb\u30c8\u4ee5\u5916\u306e\u5024\u3092\u4f7f\u7528\u3057\u3066\u30e9\u30a4\u30d6\u30e9\u30ea\u304b\u3089\u65e2\u5b58\u306e\u30e1\u30c8\u30ea\u30c3\u30af\u95a2\u6570\u3092\u30e9\u30c3\u30d7\u3059\u308b\u3053\u3068\u3067\u3059\u3002\n>>> from sklearn.metrics import fbeta_score, make_scorer\n>>> ftwo_scorer = make_scorer(fbeta_score, beta=2)\n>>> from sklearn.model_selection import GridSearchCV\n>>> from sklearn.svm import LinearSVC\n>>> grid = GridSearchCV(LinearSVC(), param_grid={'C': [1, 10]}, scoring=ftwo_scorer)\n\n2\u756a\u76ee\u306e\u30e6\u30fc\u30b9\u30b1\u30fc\u30b9\u306f\u3001\u3044\u304f\u3064\u304b\u306e\u30d1\u30e9\u30e1\u30fc\u30bf\u3092\u53d6\u308b\u3053\u3068\u304c\u3067\u304d\u308bmake_scorer\u3092\u4f7f\u7528\u3057\u3066\u5358\u7d14\u306aPython\u95a2\u6570\u304b\u3089\u5b8c\u5168\u306b\u30ab\u30b9\u30bf\u30e0\u306escorer\u30aa\u30d6\u30b8\u30a7\u30af\u30c8\u3092\u69cb\u7bc9\u3059\u308b\u3053\u3068\u3067\u3059\uff1a\n  - \u4f7f\u7528\u3059\u308bPython\u95a2\u6570\uff08\u4e0b\u306e\u4f8b\u306e my_custom_loss_func\uff09\n  - python\u95a2\u6570\u304c\u30b9\u30b3\u30a2\u3092\u8fd4\u3059\u304b\u3069\u3046\u304b\uff08\u30c7\u30d5\u30a9\u30eb\u30c8 greater_is_better = True\uff09\u3001\u307e\u305f\u306f\u640d\u5931\uff08 greater_is_better = False\uff09\u3092\u8fd4\u3057\u307e\u3059\u3002 \u640d\u5931\u306e\u5834\u5408\u306f\u3001scorer\u30aa\u30d6\u30b8\u30a7\u30af\u30c8\u306b\u3088\u3063\u3066\u3001python\u95a2\u6570\u306e\u51fa\u529b\u304c\u7121\u52b9\u306b\u306a\u308a\u3001\u30b9\u30b3\u30a2\u30e9\u30fc\u306f\u3088\u308a\u826f\u3044\u30e2\u30c7\u30eb\u306b\u5bfe\u3057\u3066\u9ad8\u3044\u5024\u3092\u8fd4\u3057\u307e\u3059\u3002\n  - \u5206\u985e\u30e1\u30c8\u30ea\u30af\u30b9\u306e\u307f\uff1a\u3042\u306a\u305f\u304c\u63d0\u4f9b\u3057\u305fPython\u95a2\u6570\u304c\u7d99\u7d9a\u7684\u306a\u610f\u601d\u6c7a\u5b9a\u306e\u78ba\u5b9f\u6027\u3092\u5fc5\u8981\u3068\u3059\u308b\u304b\u3069\u3046\u304b\uff08 needs_threshold = True \uff09 \u30c7\u30d5\u30a9\u30eb\u30c8\u5024\u306fFalse\u3067\u3059\u3002\n  - \u30d9\u30fc\u30bf\u3084 f1_score \u306e\u30e9\u30d9\u30eb\u306a\u3069\u306e\u8ffd\u52a0\u30d1\u30e9\u30e1\u30fc\u30bf\u3002\n\u30ab\u30b9\u30bf\u30e0\u30b9\u30b3\u30a2\u30e9\u30fc\u3092\u4f5c\u6210\u3057\u3001greater_is_better\u30d1\u30e9\u30e1\u30fc\u30bf\u30fc\u3092\u4f7f\u7528\u3059\u308b\u4f8b\u3092\u6b21\u306b\u793a\u3057\u307e\u3059\u3002\n>>> import numpy as np\n>>> def my_custom_loss_func(ground_truth, predictions):\n...     diff = np.abs(ground_truth - predictions).max()\n...     return np.log(1 + diff)\n...\n>>> # loss_func\u306f\u3001my_custom_loss_func\u306e\u623b\u308a\u5024\u3092\u7121\u52b9\u306b\u3057\u307e\u3059\u3002\n>>> # \u3053\u308c\u306f\u3001ground_truth\u306e\u5024\u3068\u4e0b\u3067\u5b9a\u7fa9\u3055\u308c\u305f\u4e88\u6e2c\u304c\u3042\u308b\u5834\u5408\u3001np.log(2)\u30010.693\u306b\u306a\u308a\u307e\u3059\u3002\n>>> loss  = make_scorer(my_custom_loss_func, greater_is_better=False)\n>>> score = make_scorer(my_custom_loss_func, greater_is_better=True)\n>>> ground_truth = [[1, 1]]\n>>> predictions  = [0, 1]\n>>> from sklearn.dummy import DummyClassifier\n>>> clf = DummyClassifier(strategy='most_frequent', random_state=0)\n>>> clf = clf.fit(ground_truth, predictions)\n>>> loss(clf,ground_truth, predictions) \n-0.69...\n>>> score(clf,ground_truth, predictions) \n0.69...\n\n\n3.3.1.3. \u72ec\u81ea\u306e\u63a1\u70b9\u30aa\u30d6\u30b8\u30a7\u30af\u30c8\u306e\u5b9f\u88c5\nmake_scorer \u30d5\u30a1\u30af\u30c8\u30ea\u3092\u4f7f\u7528\u305b\u305a\u306b\u3001\u72ec\u81ea\u306e\u30b9\u30b3\u30a2\u30ea\u30f3\u30b0\u30aa\u30d6\u30b8\u30a7\u30af\u30c8\u3092\u30bc\u30ed\u304b\u3089\u69cb\u7bc9\u3059\u308b\u3053\u3068\u3067\u3001\u3088\u308a\u67d4\u8edf\u306a\u30e2\u30c7\u30eb\u30b9\u30b3\u30a2\u30e9\u30fc\u3092\u751f\u6210\u3059\u308b\u3053\u3068\u304c\u3067\u304d\u307e\u3059\u3002\u547c\u3073\u51fa\u3057\u53ef\u80fd\u30aa\u30d6\u30b8\u30a7\u30af\u30c8\u304c\u30b9\u30b3\u30a2\u30e9\u30fc\u3067\u3042\u308b\u305f\u3081\u306b\u306f\u3001\u4ee5\u4e0b\u306e2\u3064\u306e\u30eb\u30fc\u30eb\u3067\u6307\u5b9a\u3055\u308c\u305f\u30d7\u30ed\u30c8\u30b3\u30eb\u3092\u6e80\u305f\u3059\u5fc5\u8981\u304c\u3042\u308a\u307e\u3059\u3002\n  - (estimator, X, y)\u3067\u547c\u3073\u51fa\u3059\u3053\u3068\u304c\u3067\u304d\u308b\u3053\u3068\u3002estimator \u306f\u8a55\u4fa1\u3059\u3079\u304d\u30e2\u30c7\u30eb\u3067\u3042\u308a\u3001X \u306f\u691c\u8a3c\u30c7\u30fc\u30bf\u3067\u3042\u308a\u3001 y \u306f X\uff08\u6559\u5e2b\u3042\u308a\u306e\u5834\u5408\uff09\u307e\u305f\u306f None\uff08\u6559\u5e2b\u306a\u3057\u306e\u5834\u5408\uff09\u306e\u5b9f\u6e2c\u5024\u30bf\u30fc\u30b2\u30c3\u30c8\u3002\n  - y \u3092\u53c2\u7167\u3057\u3066\u3001X \u4e0a\u306e estimator \u4e88\u6e2c\u54c1\u8cea\u3092\u5b9a\u91cf\u5316\u3059\u308b\u6d6e\u52d5\u5c0f\u6570\u70b9\u6570\u3092\u8fd4\u3059\u3053\u3068\u3002\u7e70\u308a\u8fd4\u3057\u306b\u306a\u308a\u307e\u3059\u304c\u3001\u6163\u4f8b\u3067\u306f\u6570\u5024\u304c\u9ad8\u3044\u307b\u3069\u826f\u3044\u306e\u3067\u3001\u30b9\u30b3\u30a2\u30e9\u30fc\u304c\u640d\u5931\u3092\u8fd4\u3059\u5834\u5408\u306f\u3001\u305d\u306e\u5024\u3092\u7121\u52b9\u306b\u3059\u308b\u5fc5\u8981\u304c\u3042\u308a\u307e\u3059\u3002\n\n3.3.2. \u5206\u985e\u30e1\u30c8\u30ea\u30c3\u30af\nsklearn.metrics \u30e2\u30b8\u30e5\u30fc\u30eb\u306f\u3001\u5206\u985e\u30d1\u30d5\u30a9\u30fc\u30de\u30f3\u30b9\u3092\u6e2c\u5b9a\u3059\u308b\u3044\u304f\u3064\u304b\u306e\u640d\u5931\u3001\u30b9\u30b3\u30a2\u3001\u304a\u3088\u3073\u30e6\u30fc\u30c6\u30a3\u30ea\u30c6\u30a3\u95a2\u6570\u3092\u5b9f\u88c5\u3057\u307e\u3059\u3002\u4e00\u90e8\u306e\u30e1\u30c8\u30ea\u30c3\u30af\u3067\u306f\u3001\u6b63\u306e\u30af\u30e9\u30b9\u3001\u4fe1\u983c\u5024\u3001\u307e\u305f\u306f\u30d0\u30a4\u30ca\u30ea\u6c7a\u5b9a\u5024\u306e\u78ba\u7387\u63a8\u5b9a\u304c\u5fc5\u8981\u306a\u5834\u5408\u304c\u3042\u308a\u307e\u3059\u3002\u307b\u3068\u3093\u3069\u306e\u5b9f\u88c5\u3067\u306f\u3001 sample_weight \u30d1\u30e9\u30e1\u30fc\u30bf\u3092\u4f7f\u7528\u3057\u3066\u3001\u5404\u30b5\u30f3\u30d7\u30eb\u304c\u30b9\u30b3\u30a2\u5168\u4f53\u306b\u91cd\u307f\u4ed8\u3051\u3055\u308c\u305f\u5bc4\u4e0e\u3092\u3059\u308b\u3053\u3068\u304c\u3067\u304d\u307e\u3059\u3002\n\u3053\u308c\u3089\u3001\u30d0\u30a4\u30ca\u30ea\u5206\u985e\u306e\u5834\u5408\u306b\u5236\u9650\u3055\u308c\u3066\u3044\u307e\u3059\uff1a\n\n\n\n\n\n\n\n\n\nmatthews_corrcoef(y_true\u3001y_pred [\u3001...])\n\u30d0\u30a4\u30ca\u30ea\u30af\u30e9\u30b9\u306eMatthews\u76f8\u95a2\u4fc2\u6570(MCC\uff09\u3092\u8a08\u7b97\u3059\u308b\n\n\nprecision_recall_curve(y_true\u3001probas_pred)\n\u3055\u307e\u3056\u307e\u306a\u78ba\u7387\u3057\u304d\u3044\u5024\u306b\u5bfe\u3059\u308b\u9069\u5408\u7387 - \u518d\u73fe\u7387\u306e\u30da\u30a2\u3092\u8a08\u7b97\u3059\u308b\n\n\nroc_curve(y_true\u3001y_score [\u3001pos_label\u3001...])\n\u53d7\u4fe1\u6a5f\u306e\u52d5\u4f5c\u7279\u6027(ROC\uff09\u3092\u8a08\u7b97\u3059\u308b\n\n\n\n\u3053\u308c\u3089\u306f\u30de\u30eb\u30c1\u30af\u30e9\u30b9\u3067\u3082\u6a5f\u80fd\u3059\u308b\uff1a\n\n\n\n\n\n\n\n\n\ncohen_kappa_score(y1\u3001y2 [\u3001labels\u3001weights])\nCohen's kappa\uff1a\u30a2\u30ce\u30c6\u30fc\u30bf\u9593\u306e\u5408\u610f\u3092\u6e2c\u5b9a\u3059\u308b\u7d71\u8a08\u3002\n\n\nconfusion_matrix(y_true\u3001y_pred [\u3001labels\u3001...])\n\u5206\u985e\u306e\u7cbe\u5ea6\u3092\u8a55\u4fa1\u3059\u308b\u305f\u3081\u306e\u6df7\u540c\u884c\u5217\u3092\u8a08\u7b97\u3059\u308b\n\n\nhinge_loss(y_true\u3001pred_decision [\u3001labels\u3001...])\n\u5e73\u5747\u30d2\u30f3\u30b8\u30fb\u30ed\u30b9(\u975e\u6b63\u898f\u5316)\n\n\n\n\u3053\u308c\u3089\u306f\u30de\u30eb\u30c1\u30e9\u30d9\u30eb\u306e\u5834\u5408\u306b\u3082\u6a5f\u80fd\u3059\u308b\uff1a\n\n\n\n\n\n\n\n\n\naccuracy_score(y_true\u3001y_pred [\u3001normalize\u3001...])\n\u7cbe\u5ea6\u5206\u985e\u30b9\u30b3\u30a2\u3002\n\n\nclassification_report(y_true\u3001y_pred [\u3001...])\n\u4e3b\u8981\u5206\u985e\u30e1\u30c8\u30ea\u30c3\u30af\u3092\u793a\u3059\u30c6\u30ad\u30b9\u30c8\u30ec\u30dd\u30fc\u30c8\u3092\u4f5c\u6210\u3057\u307e\u3059\n\n\nf1_score(y_true\u3001y_pred [\u3001labels\u3001...])\nF1\u30b9\u30b3\u30a2\u3092\u8a08\u7b97\u3057\u307e\u3059\u3002\u3053\u308c\u306f\u30d0\u30e9\u30f3\u30b9F\u30b9\u30b3\u30a2\u307e\u305f\u306fF\u30e1\u30b8\u30e3\u30fc\u3068\u3082\u547c\u3070\u308c\u307e\u3059\n\n\nfbeta_score(y_true\u3001y_pred\u3001beta [\u3001labels\u3001...])\nF\u30d9\u30fc\u30bf\u30b9\u30b3\u30a2\u3092\u8a08\u7b97\u3059\u308b\n\n\nhamming_loss(y_true\u3001y_pred [\u3001labels\u3001...])\n\u5e73\u5747\u30cf\u30df\u30f3\u30b0\u640d\u5931\u3092\u8a08\u7b97\u3057\u307e\u3059\u3002\n\n\njaccard_similarity_score(y_true\u3001y_pred [\u3001...])\nJaccard\u985e\u4f3c\u5ea6\u30b9\u30b3\u30a2\n\n\nlog_loss(y_true\u3001y_pred [\u3001eps\u3001normalize\u3001...])\n\u30ed\u30b0\u306e\u640d\u5931\u3001\u5225\u540d\u30ed\u30b8\u30b9\u30c6\u30a3\u30c3\u30af\u640d\u5931\u307e\u305f\u306f\u30af\u30ed\u30b9\u30a8\u30f3\u30c8\u30ed\u30d4\u30fc\u640d\u5931\u3002\n\n\nprecision_recall_fscore_support(y_true\u3001y_pred)\n\u5404\u30af\u30e9\u30b9\u306e\u9069\u5408\u7387\u3001\u518d\u73fe\u7387\u3001F-measure\u304a\u3088\u3073\u30b5\u30dd\u30fc\u30c8\u3092\u8a08\u7b97\u3059\u308b\n\n\nprecision_score(y_true\u3001y_pred [\u3001labels\u3001...])\n\u9069\u5408\u7387\u3092\u8a08\u7b97\u3059\u308b\n\n\nrecall_score(y_true\u3001y_pred [\u3001labels\u3001...])\n\u518d\u73fe\u7387\u3092\u8a08\u7b97\u3059\u308b\n\n\nzero_one_loss(y_true\u3001y_pred [\u3001normalize\u3001...])\n\u30bc\u30ed\u306e\u5206\u985e\u640d\u3002\n\n\n\n\u3053\u308c\u3089\u306f\u3001\u30d0\u30a4\u30ca\u30ea\u3068\u30de\u30eb\u30c1\u30e9\u30d9\u30eb(\u30de\u30eb\u30c1\u30af\u30e9\u30b9\u3067\u306f\u306a\u3044)\u3067\u6a5f\u80fd\u3059\u308b\n\n\n\n\n\n\n\n\n\naverage_precision_score(y_true\u3001y_score [\u3001...])\n\u4e88\u6e2c\u30b9\u30b3\u30a2\u304b\u3089\u5e73\u5747\u7cbe\u5ea6(AP)\n\n\nroc_auc_score(y_true\u3001y_score [\u3001average\u3001...])\n\u4e88\u6e2c\u30b9\u30b3\u30a2\u304b\u3089\u306e\u66f2\u7dda\u4e0b\u9762\u7a4d(AUC)\n\n\n\n\u4ee5\u4e0b\u306e\u30b5\u30d6\u30bb\u30af\u30b7\u30e7\u30f3\u3067\u306f\u3001\u3053\u308c\u3089\u306e\u95a2\u6570\u306e\u305d\u308c\u305e\u308c\u306b\u3064\u3044\u3066\u8aac\u660e\u3057\u3001\u5171\u901a\u306eAPI\u3068\u30e1\u30c8\u30ea\u30c3\u30af\u306e\u5b9a\u7fa9\u306b\u3064\u3044\u3066\u3044\u304f\u3064\u304b\u306e\u6ce8\u610f\u3092\u5148\u53d6\u308a\u3057\u307e\u3059\u3002\n\n3.3.2.1. \u30d0\u30a4\u30ca\u30ea\u304b\u3089\u30de\u30eb\u30c1\u30af\u30e9\u30b9\u3001\u30de\u30eb\u30c1\u30e9\u30d9\u30eb\u307e\u3067\n\u57fa\u672c\u7684\u306b\u3001\u30d0\u30a4\u30ca\u30ea\u5206\u985e\u30bf\u30b9\u30af\u306e\u305f\u3081\u306b\u3044\u304f\u3064\u304b\u306e\u30e1\u30c8\u30ea\u30c3\u30af\u304c\u5b9a\u7fa9\u3055\u308c\u3066\u3044\u307e\u3059( f1_score \u3001 roc_auc_score \u306a\u3069\uff09\u3002\u3053\u306e\u3088\u3046\u306a\u5834\u5408\u3001\u30c7\u30d5\u30a9\u30eb\u30c8\u3067\u306f\u30dd\u30b8\u30c6\u30a3\u30d6\u30fb\u30e9\u30d9\u30eb\u306e\u307f\u304c\u8a55\u4fa1\u3055\u308c\u3001\u30dd\u30b8\u30c6\u30a3\u30d6\u30fb\u30af\u30e9\u30b9\u306f1\u3068\u30e9\u30d9\u30eb\u4ed8\u3051\u3055\u308c\u3066\u3044\u307e\u3059\uff08 pos_label \u30d1\u30e9\u30e1\u30fc\u30bf\u3067\u69cb\u6210\u53ef\u80fd\u3067\u3059\u304c\uff09\u3002\n\u30d0\u30a4\u30ca\u30ea\u30e1\u30c8\u30ea\u30c3\u30af\u3092\u30de\u30eb\u30c1\u30af\u30e9\u30b9\u307e\u305f\u306f\u30de\u30eb\u30c1\u30e9\u30d9\u30eb\u306e\u554f\u984c\u306b\u62e1\u5f35\u3059\u308b\u5834\u5408\u3001\u30c7\u30fc\u30bf\u306f\u30d0\u30a4\u30ca\u30ea\u306e\u554f\u984c\u306e\u30b3\u30ec\u30af\u30b7\u30e7\u30f3\u3068\u3057\u3066\u6271\u308f\u308c\u307e\u3059\uff08\u30af\u30e9\u30b9\u3054\u3068\u306b1\u3064\uff09\u3002\u3044\u304f\u3064\u304b\u306e\u30b7\u30ca\u30ea\u30aa\u3067\u306f\u6709\u7528\u306a\u3001\u30af\u30e9\u30b9\u306e\u30bb\u30c3\u30c8\u5168\u4f53\u3067\u30d0\u30a4\u30ca\u30ea\u30e1\u30c8\u30ea\u30c3\u30af\u8a08\u7b97\u3092\u5e73\u5747\u5316\u3059\u308b\u65b9\u6cd5\u306f\u3044\u304f\u3064\u304b\u3042\u308a\u307e\u3059\u3002\u53ef\u80fd\u3067\u3042\u308c\u3070\u3001average \u30d1\u30e9\u30e1\u30fc\u30bf\u3092\u4f7f\u7528\u3057\u3066\u3053\u308c\u3089\u306e\u4e2d\u304b\u3089\u9078\u629e\u3059\u308b\u5fc5\u8981\u304c\u3042\u308a\u307e\u3059\u3002\n\n\n\"macro\" \u306f\u30d0\u30a4\u30ca\u30ea\u30e1\u30c8\u30ea\u30c3\u30af\u306e\u5e73\u5747\u3092\u8a08\u7b97\u3057\u3001\u5404\u30af\u30e9\u30b9\u306b\u7b49\u3057\u3044\u91cd\u307f\u3092\u4e0e\u3048\u307e\u3059\u3002\u305d\u308c\u306b\u3082\u304b\u304b\u308f\u3089\u305a\u3001\u983b\u5ea6\u306e\u4f4e\u3044\u30af\u30e9\u30b9\u304c\u91cd\u8981\u306a\u554f\u984c\u3067\u306f\u3001\u30de\u30af\u30ed\u5e73\u5747\u5316\u304c\u30d1\u30d5\u30a9\u30fc\u30de\u30f3\u30b9\u3092\u5f37\u8abf\u3059\u308b\u624b\u6bb5\u306b\u306a\u308b\u53ef\u80fd\u6027\u304c\u3042\u308a\u307e\u3059\u3002\u4e00\u65b9\u3001\u3059\u3079\u3066\u306e\u30af\u30e9\u30b9\u304c\u540c\u3058\u3088\u3046\u306b\u91cd\u8981\u3067\u3042\u308b\u3068\u3044\u3046\u524d\u63d0\u306f\u3001\u3057\u3070\u3057\u3070\u771f\u5b9f\u3067\u306f\u306a\u3044\u305f\u3081\u3001\u30de\u30af\u30ed\u5e73\u5747\u306f\u3001\u307e\u308c\u306a\u30af\u30e9\u30b9\u3067\u306f\u4e00\u822c\u7684\u306b\u4f4e\u3044\u30d1\u30d5\u30a9\u30fc\u30de\u30f3\u30b9\u3092\u904e\u5ea6\u306b\u5f37\u8abf\u3059\u308b\u3053\u3068\u306b\u306a\u308a\u307e\u3059\u3002\n\n\"weighted\" \u5404\u30af\u30e9\u30b9\u306e\u30b9\u30b3\u30a2\u304c\u771f\u306e\u30c7\u30fc\u30bf\u30b5\u30f3\u30d7\u30eb\u5185\u306b\u5b58\u5728\u3059\u308b\u3053\u3068\u306b\u3088\u3063\u3066\u91cd\u307f\u4ed8\u3051\u3055\u308c\u305f\u30d0\u30a4\u30ca\u30ea\u30e1\u30c8\u30ea\u30c3\u30af\u306e\u5e73\u5747\u3092\u8a08\u7b97\u3059\u308b\u3053\u3068\u306b\u3088\u3063\u3066\u3001\u30af\u30e9\u30b9\u306e\u4e0d\u5747\u8861\u3092\u300c\u91cd\u307f\u4ed8\u3051\u300d\u3059\u308b\u3002\n-\"micro\" \u306f\u3001\u5404\u30b5\u30f3\u30d7\u30eb\u30af\u30e9\u30b9\u306e\u30da\u30a2\u306b\u3001\u5168\u4f53\u7684\u306a\u30e1\u30c8\u30ea\u30c3\u30af\u306b\u7b49\u3057\u304f\u5bc4\u4e0e\u3057\u307e\u3059\uff08\u30b5\u30f3\u30d7\u30eb\u30a6\u30a7\u30a4\u30c8\u306e\u7d50\u679c\u3092\u9664\u3044\u3066\uff09\u3002\u30af\u30e9\u30b9\u3054\u3068\u306e\u30e1\u30c8\u30ea\u30c3\u30af\u3092\u5408\u8a08\u3059\u308b\u306e\u3067\u306f\u306a\u304f\u3001\u30af\u30e9\u30b9\u3054\u3068\u306e\u30e1\u30c8\u30ea\u30c3\u30af\u3092\u69cb\u6210\u3059\u308b\u914d\u5f53\u304a\u3088\u3073\u9664\u6570\u3092\u5408\u8a08\u3057\u3066\u3001\u5168\u4f53\u306e\u5546\u3092\u8a08\u7b97\u3057\u307e\u3059\u3002\u30de\u30a4\u30af\u30ed\u30a2\u30d9\u30ec\u30fc\u30b8\u30f3\u30b0\u306f\u200b\u200b\u3001\u591a\u6570\u30af\u30e9\u30b9\u3092\u7121\u8996\u3059\u308b\u30de\u30eb\u30c1\u30af\u30e9\u30b9\u5206\u985e\u3092\u542b\u3080\u3001\u30de\u30eb\u30c1\u30e9\u30d9\u30eb\u8a2d\u5b9a\u3067\u512a\u5148\u3055\u308c\u308b\u5834\u5408\u304c\u3042\u308a\u307e\u3059\u3002\n-\"samples\"\u306f\u30de\u30eb\u30c1\u30e9\u30d9\u30eb\u554f\u984c\u306b\u306e\u307f\u9069\u7528\u3055\u308c\u307e\u3059\u3002\u4ee3\u308f\u308a\u306b\u3001\u8a55\u4fa1\u30c7\u30fc\u30bf\u306e\u5404\u30b5\u30f3\u30d7\u30eb\u306e\u771f\u306e\u30af\u30e9\u30b9\u3068\u4e88\u6e2c\u3055\u308c\u305f\u30af\u30e9\u30b9\u306e\u30e1\u30c8\u30ea\u30c3\u30af\u3092\u8a08\u7b97\u3057\u3001\u305d\u306e\uff08sample_weight - weighted\uff09\u5e73\u5747\u3092\u8fd4\u3057\u307e\u3059\u3002\n\naverage = None \u3092\u9078\u629e\u3059\u308b\u3068\u3001\u5404\u30af\u30e9\u30b9\u306e\u30b9\u30b3\u30a2\u3092\u542b\u3080\u914d\u5217\u304c\u8fd4\u3055\u308c\u307e\u3059\u3002\n\n\u30de\u30eb\u30c1\u30af\u30e9\u30b9\u30fb\u30c7\u30fc\u30bf\u306f\u3001\u30d0\u30a4\u30ca\u30ea\u30fb\u30bf\u30fc\u30b2\u30c3\u30c8\u306e\u3088\u3046\u306b\u30e1\u30c8\u30ea\u30c3\u30af\u306b\u30af\u30e9\u30b9\u30fb\u30e9\u30d9\u30eb\u306e\u914d\u5217\u3068\u3057\u3066\u63d0\u4f9b\u3055\u308c\u307e\u3059\u304c\u3001\u30de\u30eb\u30c1\u30e9\u30d9\u30eb\u30fb\u30c7\u30fc\u30bf\u306f\u3001\u30b5\u30f3\u30d7\u30ebi\u304c\u30e9\u30d9\u30ebj\u3092\u6301\u3064\u5834\u5408\u306fcell [i\u3001j] \u304c\u50241\u3092\u3001\u305d\u3046\u3067\u306a\u3044\u5834\u5408\u306f0\u3092\u8fd4\u3057\u307e\u3059 \u3002\n\n3.3.2.2. \u7cbe\u5ea6\u30b9\u30b3\u30a2\naccuracy_score \u95a2\u6570\u306f\u3001\u6b63\u78ba\u306a\u4e88\u6e2c\u306e\u5272\u5408\uff08\u30c7\u30d5\u30a9\u30eb\u30c8\uff09\u307e\u305f\u306f\u30ab\u30a6\u30f3\u30c8\uff08normalize=False\uff09\u306e\u3044\u305a\u308c\u304b\u3092\u8a08\u7b97\u3057\u307e\u3059\u3002\n\u30de\u30eb\u30c1\u30e9\u30d9\u30eb\u5206\u985e\u3067\u306f\u3001\u3053\u306e\u95a2\u6570\u306f\u30b5\u30d6\u30bb\u30c3\u30c8\u306e\u7cbe\u5ea6\u3092\u8fd4\u3057\u307e\u3059\u3002 \u30b5\u30f3\u30d7\u30eb\u306e\u4e88\u6e2c\u30e9\u30d9\u30eb\u306e\u30bb\u30c3\u30c8\u5168\u4f53\u304c\u5b9f\u969b\u306e\u30e9\u30d9\u30eb\u30bb\u30c3\u30c8\u3068\u53b3\u5bc6\u306b\u4e00\u81f4\u3059\u308b\u5834\u5408\u3001\u30b5\u30d6\u30bb\u30c3\u30c8\u7cbe\u5ea6\u306f1.0\u3067\u3059\u3002 \u305d\u308c\u4ee5\u5916\u306e\u5834\u5408\u306f0.0\u3067\u3059\u3002\n\\texttt{accuracy}(y, \\hat{y}) = \\frac{1}{n_\\text{samples}} \\sum_{i=0}^{n_\\text{samples}-1} 1(\\hat{y}_i = y_i)\n\n\u3053\u3053\u3067\u3001 $1(x)$ \u306f\u6307\u6a19\u95a2\u6570\u3067\u3059\u3002\n>>> import numpy as np\n>>> from sklearn.metrics import accuracy_score\n>>> y_pred = [0, 2, 1, 3]\n>>> y_true = [0, 1, 2, 3]\n>>> accuracy_score(y_true, y_pred)\n0.5\n>>> accuracy_score(y_true, y_pred, normalize=False)\n2\n\n\u30d0\u30a4\u30ca\u30ea\u30e9\u30d9\u30eb\u30a4\u30f3\u30b8\u30b1\u30fc\u30bf\u3092\u4f7f\u7528\u3057\u305f\u30de\u30eb\u30c1\u30e9\u30d9\u30eb\u306e\u5834\u5408\uff1a\n>>> accuracy_score(np.array([[0, 1], [1, 1]]), np.ones((2, 2)))\n0.5\n\n\n\u4f8b\uff1a\n\n\n\u30c7\u30fc\u30bf\u30bb\u30c3\u30c8\u306e\u9806\u5217\u3092\u4f7f\u7528\u3057\u305f\u7cbe\u5ea6\u30b9\u30b3\u30a2\u306e\u4f7f\u7528\u4f8b\u306e\u5206\u985e\u30b9\u30b3\u30a2\u306e\u91cd\u8981\u6027\u3092\u9806\u5217\u3067\u30c6\u30b9\u30c8\u3059\u308b \u3092\u53c2\u7167\u3057\u3066\u304f\u3060\u3055\u3044\u3002\n\n\n\n\n3.3.2.3. \u30ab\u30c3\u30d1\u4fc2\u6570\n\u95a2\u6570 cohen_kappa_score \u306f\u3001\u30ab\u30c3\u30d1\u4fc2\u6570 \u3092\u8a08\u7b97\u3057\u307e\u3059\u3002\u3053\u306e\u5c3a\u5ea6\u306f\u3001\u7570\u306a\u308b\u4eba\u9593\u306e\u6ce8\u91c8\u8005\u306b\u3088\u308b\u30e9\u30d9\u30ea\u30f3\u30b0\u3092\u6bd4\u8f03\u3059\u308b\u3053\u3068\u3092\u76ee\u7684\u3068\u3057\u3066\u3044\u307e\u3059\u3002\n\u03ba\u30b9\u30b3\u30a2\uff08docstring\u53c2\u7167\uff09\u306f-1\u30681\u306e\u9593\u306e\u6570\u5024\u3067\u3059.8\u4ee5\u4e0a\u306e\u30b9\u30b3\u30a2\u306f\u4e00\u822c\u7684\u306b\u826f\u3044\u4e00\u81f4\u3068\u307f\u306a\u3055\u308c\u307e\u3059\u3002\u30bc\u30ed\u4ee5\u4e0b\u306f\u3001\u5408\u610f\u304c\u306a\u3044\u3053\u3068\u3092\u610f\u5473\u3059\u308b\uff08\u4e8b\u5b9f\u4e0a\u30e9\u30f3\u30c0\u30e0\u306a\u30e9\u30d9\u30eb\uff09\u3002\n\u03ba\u30b9\u30b3\u30a2\u306f\u3001\u30d0\u30a4\u30ca\u30ea\u307e\u305f\u306f\u30de\u30eb\u30c1\u30af\u30e9\u30b9\u306e\u554f\u984c\u306b\u3064\u3044\u3066\u306f\u8a08\u7b97\u3067\u304d\u307e\u3059\u304c\u3001\u30de\u30eb\u30c1\u30e9\u30d9\u30eb\u306e\u554f\u984c\uff08\u30e9\u30d9\u30eb\u3054\u3068\u306e\u30b9\u30b3\u30a2\u3092\u624b\u52d5\u3067\u8a08\u7b97\u3059\u308b\u5834\u5408\u3092\u9664\u304f\uff09\u3067\u306f\u306a\u304f\u30012\u3064\u4ee5\u4e0a\u306e\u6ce8\u91c8\u3067\u306f\u8a08\u7b97\u3067\u304d\u307e\u305b\u3093\u3002\n>>> from sklearn.metrics import cohen_kappa_score\n>>> y_true = [2, 0, 2, 2, 0, 1]\n>>> y_pred = [0, 0, 2, 2, 0, 2]\n>>> cohen_kappa_score(y_true, y_pred)\n0.4285714285714286\n\n\n3.3.2.4. \u6df7\u540c\u884c\u5217\nconfusion_matrix\u95a2\u6570\u306f\u3001\u6df7\u540c\u884c\u5217\u3092\u8a08\u7b97\u3059\u308b\u3053\u3068\u306b\u3088\u3063\u3066\u5206\u985e\u7cbe\u5ea6\u3092\u8a55\u4fa1\u3057\u307e\u3059\u3002\n\u5b9a\u7fa9\u4e0a\u3001\u6df7\u540c\u884c\u5217\u306e\u30a8\u30f3\u30c8\u30ea $i,j$ \u306f\u3001\u30b0\u30eb\u30fc\u30d7 $i$ \u306e\u5b9f\u969b\u306e\u89b3\u6e2c\u6570\u3067\u3059\u304c\u3001\u30b0\u30eb\u30fc\u30d7 $j$ \u306b\u5c5e\u3059\u308b\u3068\u4e88\u6e2c\u3055\u308c\u307e\u3059\u3002 \u6b21\u306b\u4f8b\u3092\u793a\u3057\u307e\u3059\u3002\n>>> from sklearn.metrics import confusion_matrix\n>>> y_true = [2, 0, 2, 2, 0, 1]\n>>> y_pred = [0, 0, 2, 2, 0, 2]\n>>> confusion_matrix(y_true, y_pred)\narray([[2, 0, 0],\n       [0, 0, 1],\n       [1, 0, 2]])\n\n\u3053\u306e\u3088\u3046\u306a\u6df7\u540c\u884c\u5217\u3092\u8996\u899a\u7684\u306b\u8868\u3057\u305f\u3082\u306e\u3067\u3059\uff08\u3053\u306e\u56f3\u306f\u6df7\u540c\u884c\u5217\u306e\u4f8b\u3067\u3059\uff09\u3002\n\n\u30d0\u30a4\u30ca\u30ea\u306e\u554f\u984c\u306b\u3064\u3044\u3066\u306f\u3001\u4ee5\u4e0b\u306e\u3088\u3046\u306b\u3001\u771f\u9670\u6027\u3001\u507d\u967d\u6027\u3001\u507d\u9670\u6027\u304a\u3088\u3073\u771f\u967d\u6027\u306e\u30ab\u30a6\u30f3\u30c8\u3092\u5f97\u308b\u3053\u3068\u304c\u3067\u304d\u307e\u3059\u3002\n\n\u4f8b\uff1a\n\n\n\u6df7\u540c\u884c\u5217\u3092\u4f7f\u7528\u3057\u3066\u5206\u985e\u5b50\u306e\u51fa\u529b\u54c1\u8cea\u3092\u8a55\u4fa1\u3059\u308b\u4f8b\u306b\u3064\u3044\u3066\u306f\u3001\u300c\u6df7\u540c\u884c\u5217\u300d\u3092\u53c2\u7167\u3057\u3066\u304f\u3060\u3055\u3044\u3002\n\u624b\u66f8\u304d\u6570\u5b57\u3092\u5206\u985e\u3059\u308b\u305f\u3081\u306b\u6df7\u540c\u884c\u5217\u3092\u4f7f\u7528\u3059\u308b\u4f8b\u306b\u3064\u3044\u3066\u306f\u3001\u624b\u66f8\u304d\u6570\u5b57\u306e\u8a8d\u8b58\u3092\u53c2\u7167\u3057\u3066\u304f\u3060\u3055\u3044\u3002\n\u6df7\u540c\u884c\u5217\u3092\u4f7f\u7528\u3057\u3066\u30c6\u30ad\u30b9\u30c8\u6587\u66f8\u3092\u5206\u985e\u3059\u308b\u4f8b\u306b\u3064\u3044\u3066\u306f\u3001\u30b9\u30d1\u30fc\u30b9\u95a2\u6570\u3092\u4f7f\u7528\u3057\u305f\u30c6\u30ad\u30b9\u30c8\u6587\u66f8\u306e\u5206\u985e\u3092\u53c2\u7167\u3057\u3066\u304f\u3060\u3055\u3044\u3002\n\n\n\n\n3.3.2.5. \u5206\u985e\u30ec\u30dd\u30fc\u30c8\nclassification_report \u95a2\u6570\u306f\u3001\u4e3b\u8981\u5206\u985e\u30e1\u30c8\u30ea\u30c3\u30af\u3092\u793a\u3059\u30c6\u30ad\u30b9\u30c8\u30ec\u30dd\u30fc\u30c8\u3092\u4f5c\u6210\u3057\u307e\u3059\u3002 \u30ab\u30b9\u30bf\u30e0 target_names \u3068\u63a8\u5b9a\u30e9\u30d9\u30eb\u306e\u5c0f\u3055\u306a\u4f8b\u3092\u6b21\u306b\u793a\u3057\u307e\u3059\u3002\n>>> from sklearn.metrics import classification_report\n>>> y_true = [0, 1, 2, 2, 0]\n>>> y_pred = [0, 0, 2, 1, 0]\n>>> target_names = ['class 0', 'class 1', 'class 2']\n>>> print(classification_report(y_true, y_pred, target_names=target_names))\n             precision    recall  f1-score   support\n\n    class 0       0.67      1.00      0.80         2\n    class 1       0.00      0.00      0.00         1\n    class 2       1.00      0.50      0.67         2\n\navg / total       0.67      0.60      0.59         5\n\n\n\u4f8b\uff1a\n\n\n\u624b\u66f8\u304d\u6570\u5b57\u306e\u5206\u985e\u30ec\u30dd\u30fc\u30c8\u306e\u4f7f\u7528\u4f8b\u306b\u3064\u3044\u3066\u306f\u3001\u624b\u66f8\u304d\u6570\u5b57\u306e\u8a8d\u8b58\u3092\u53c2\u7167\u3057\u3066\u304f\u3060\u3055\u3044\u3002\n\u30c6\u30ad\u30b9\u30c8\u6587\u66f8\u306e\u5206\u985e\u30ec\u30dd\u30fc\u30c8\u306e\u4f7f\u7528\u4f8b\u306b\u3064\u3044\u3066\u306f\u3001\u30b9\u30d1\u30fc\u30b9\u95a2\u6570\u3092\u4f7f\u7528\u3057\u305f\u30c6\u30ad\u30b9\u30c8\u6587\u66f8\u306e\u5206\u985e\u3092\u53c2\u7167\u3057\u3066\u304f\u3060\u3055\u3044\u3002\n\u30cd\u30b9\u30c8\u3055\u308c\u305f\u76f8\u4e92\u691c\u8a3c\u306b\u3088\u308b\u30b0\u30ea\u30c3\u30c9\u691c\u7d22\u306e\u5206\u985e\u30ec\u30dd\u30fc\u30c8\u306e\u4f7f\u7528\u4f8b\u306b\u3064\u3044\u3066\u306f\u3001\u76f8\u4e92\u691c\u8a3c\u4ed8\u304d\u30b0\u30ea\u30c3\u30c9\u691c\u7d22\u3092\u4f7f\u7528\u3057\u305f\u30d1\u30e9\u30e1\u30fc\u30bf\u63a8\u5b9a\u3092\u53c2\u7167\u3057\u3066\u304f\u3060\u3055\u3044\u3002\n\n\n\n\n3.3.2.6. \u30cf\u30df\u30f3\u30b0\u640d\u5931\nhamming_loss\u306f\u30012\u7d44\u306e\u30b5\u30f3\u30d7\u30eb\u9593\u306e\u5e73\u5747\u30cf\u30df\u30f3\u30b0\u640d\u5931\u307e\u305f\u306f\u30cf\u30df\u30f3\u30b0\u8ddd\u96e2\u3092\u8a08\u7b97\u3057\u307e\u3059\u3002\n $\\hat{y}j$ \u304c\u4e0e\u3048\u3089\u308c\u305f\u30b5\u30f3\u30d7\u30eb\u306e $j$ \u756a\u76ee\u306e\u30e9\u30d9\u30eb\u306e\u4e88\u6e2c\u5024\u3067\u3042\u308b\u5834\u5408\u3001 $y_j$ \u306f\u5bfe\u5fdc\u3059\u308b\u771f\u306e\u5024\u3067\u3042\u308a\u3001$n\\text{labels}$ \u306f\u30af\u30e9\u30b9\u307e\u305f\u306f\u30e9\u30d9\u30eb\u306e\u6570\u3067\u3042\u308a\u3001\u30cf\u30df\u30f3\u30b0\u640d\u5931 $L_{Hamming}$ \u306f\u3001\u4ee5\u4e0b\u306e\u3088\u3046\u306b\u5b9a\u7fa9\u3055\u308c\u308b\u3002\nL_{Hamming}(y, \\hat{y}) = \\frac{1}{n_\\text{labels}} \\sum_{j=0}^{n_\\text{labels} - 1} 1(\\hat{y}_j \\not= y_j)\n\n\u3053\u3053\u3067\u3001 $1(x)$ \u306f\u6307\u6a19\u95a2\u6570\u3067\u3059\u3002\n>>> from sklearn.metrics import hamming_loss\n>>> y_pred = [1, 2, 3, 4]\n>>> y_true = [2, 2, 3, 4]\n>>> hamming_loss(y_true, y_pred)\n0.25\n\n\u30d0\u30a4\u30ca\u30ea\u30e9\u30d9\u30eb\u30a4\u30f3\u30b8\u30b1\u30fc\u30bf\u3092\u4f7f\u7528\u3057\u305f\u30de\u30eb\u30c1\u30e9\u30d9\u30eb\u306e\u5834\u5408\uff1a\n>>>\n>>> hamming_loss(np.array([[0, 1], [1, 1]]), np.zeros((2, 2)))\n0.75\n\n\uff08\u6ce8\uff09 \u30de\u30eb\u30c1\u30af\u30e9\u30b9\u5206\u985e\u3067\u306f\u3001\u30cf\u30df\u30f3\u30b0\u640d\u5931\u306f\u3001 \u30bc\u30ed\u30ef\u30f3\u640d\u5931 \u95a2\u6570\u306b\u985e\u4f3c\u3059\u308b y_true \u3068 y_pred \u306e\u9593\u306e\u30cf\u30df\u30f3\u30b0\u8ddd\u96e2\u306b\u5bfe\u5fdc\u3057\u307e\u3059\u3002\u3057\u304b\u3057\u30011\u5bfe1\u306e\u640d\u5931\u306f\u3001\u771f\u306e\u30bb\u30c3\u30c8\u306b\u53b3\u5bc6\u306b\u4e00\u81f4\u3057\u306a\u3044\u4e88\u6e2c\u30bb\u30c3\u30c8\u306b\u30da\u30ca\u30eb\u30c6\u30a3\u3092\u8ab2\u3059\u304c\u3001\u30cf\u30df\u30f3\u30b0\u640d\u5931\u306f\u500b\u3005\u306e\u30e9\u30d9\u30eb\u306b\u4e0d\u5229\u76ca\u3092\u3082\u305f\u3089\u3059\u3002\u3057\u305f\u304c\u3063\u3066\u3001\u30bc\u30ed1\u306e\u640d\u5931\u306b\u3088\u3063\u3066\u4e0a\u9650\u304c\u6c7a\u5b9a\u3055\u308c\u308b\u30cf\u30df\u30f3\u30b0\u640d\u5931\u306f\u3001\u5e38\u306b0\u30681\u3068\u306e\u9593\u3067\u3042\u308a\u3001\u771f\u306e\u30e9\u30d9\u30eb\u306e\u9069\u5207\u306a\u30b5\u30d6\u30bb\u30c3\u30c8\u307e\u305f\u306f\u30b9\u30fc\u30d1\u30fc\u30bb\u30c3\u30c8\u3092\u4e88\u6e2c\u3059\u308b\u3053\u3068\u306f\u3001\u30bc\u30ed\u30681\u3068\u306e\u9593\u306e\u30cf\u30df\u30f3\u30b0\u640d\u5931\u3092\u6392\u9664\u3059\u308b\u3053\u3068\u306b\u306a\u308b\u3002\n\n3.3.2.7. \u30b8\u30e3\u30ab\u30fc\u30c9\u985e\u4f3c\u6027\u4fc2\u6570\u30b9\u30b3\u30a2\njaccard_similarity_score \u95a2\u6570\u306f\u3001\u30da\u30a2\u306e\u30e9\u30d9\u30eb\u30bb\u30c3\u30c8\u9593\u306eJaccard\u30a4\u30f3\u30c7\u30c3\u30af\u30b9\u3068\u3082\u547c\u3070\u308c\u308b Jaccard\u985e\u4f3c\u6027\u4fc2\u6570 \u306e\u5e73\u5747\uff08\u30c7\u30d5\u30a9\u30eb\u30c8\uff09\u307e\u305f\u306f\u5408\u8a08\u3092\u8a08\u7b97\u3057\u307e\u3059\u3002\n\u5b9f\u6e2c\u5024\u30e9\u30d9\u30eb\u30bb\u30c3\u30c8 $y_i$ \u3068\u4e88\u6e2c\u30e9\u30d9\u30eb\u30bb\u30c3\u30c8 $\\hat{y}_i$ \u3092\u6301\u3064 $i$ \u756a\u76ee\u306e\u30b5\u30f3\u30d7\u30eb\u306eJaccard\u985e\u4f3c\u5ea6\u4fc2\u6570\u306f\u3001\u6b21\u306e\u3088\u3046\u306b\u5b9a\u7fa9\u3055\u308c\u307e\u3059\u3002\nJ(y_i, \\hat{y}_i) = \\frac{|y_i \\cap \\hat{y}_i|}{|y_i \\cup \\hat{y}_i|}.\n\n\u30d0\u30a4\u30ca\u30ea\u304a\u3088\u3073\u30de\u30eb\u30c1\u30af\u30e9\u30b9\u5206\u985e\u3067\u306f\u3001Jaccard\u985e\u4f3c\u5ea6\u4fc2\u6570\u30b9\u30b3\u30a2\u306f\u5206\u985e\u7cbe\u5ea6\u306b\u7b49\u3057\u3044\u3002\n>>> import numpy as np\n>>> from sklearn.metrics import jaccard_similarity_score\n>>> y_pred = [0, 2, 1, 3]\n>>> y_true = [0, 1, 2, 3]\n>>> jaccard_similarity_score(y_true, y_pred)\n0.5\n>>> jaccard_similarity_score(y_true, y_pred, normalize=False)\n2\n\n\u30d0\u30a4\u30ca\u30ea\u30e9\u30d9\u30eb\u30a4\u30f3\u30b8\u30b1\u30fc\u30bf\u3092\u4f7f\u7528\u3057\u305f\u30de\u30eb\u30c1\u30e9\u30d9\u30eb\u306e\u5834\u5408\uff1a\n>>>\n>>> jaccard_similarity_score(np.array([[0, 1], [1, 1]]), np.ones((2, 2)))\n0.75\n\n\n3.3.2.8. \u9069\u5408\u7387\u3001\u518d\u73fe\u7387\u3001F-\u5024(F-measure)\n\u76f4\u89b3\u7684\u306b\u306f\u3001\u9069\u5408\u7387 \u306f\u3001\u5206\u985e\u5668\u304c\u5426\u5b9a\u7684\u306a\u30b5\u30f3\u30d7\u30eb\u3092\u967d\u6027\u3068\u30e9\u30d9\u30eb\u4ed8\u3051\u3057\u306a\u3044\u3088\u3046\u306b\u3059\u308b\u80fd\u529b\u3067\u3042\u308a\u3001\u518d\u73fe\u7387\u306f\u3001\u5206\u985e\u5668\u304c\u3059\u3079\u3066\u306e\u967d\u6027\u30b5\u30f3\u30d7\u30eb\u3092\u898b\u3064\u3051\u308b\u80fd\u529b\u3067\u3042\u308b\u3002\nF-\u5024\uff08 $F_\u03b2$ \u304a\u3088\u3073 $F_1$ measures\uff09\u306f\u3001\u9069\u5408\u7387\u304a\u3088\u3073\u518d\u73fe\u7387\u306e\u52a0\u91cd\u8abf\u548c\u5e73\u5747\u3068\u3057\u3066\u89e3\u91c8\u3059\u308b\u3053\u3068\u304c\u3067\u304d\u307e\u3059\u3002 $\\beta = 1$ \u306e\u5834\u5408\u3001$F_\\beta$ \u3068 $F_1$ \u306f\u7b49\u4fa1\u3067\u3042\u308a\u3001\u518d\u73fe\u7387\u3068\u9069\u5408\u7387\u306f\u540c\u3058\u3088\u3046\u306b\u91cd\u8981\u3067\u3059\u3002\nprecision_recall_curve \u306f\u3001\u771f\u7406\u5024\u30e9\u30d9\u30eb\u304b\u3089\u306e\u9069\u5408\u7387-\u518d\u73fe\u7387\u30ab\u30fc\u30d6\u3068\u3001\u5224\u5b9a\u95be\u5024\u3092\u5909\u5316\u3055\u305b\u308b\u3053\u3068\u306b\u3088\u3063\u3066\u5206\u985e\u5668\u306b\u3088\u3063\u3066\u4e0e\u3048\u3089\u308c\u305f\u30b9\u30b3\u30a2\u3092\u8a08\u7b97\u3059\u308b\u3002\naverage_precision_score \u95a2\u6570\u306f\u3001\u4e88\u6e2c\u30b9\u30b3\u30a2\u304b\u3089\u5e73\u5747\u9069\u5408\u7387\uff08AP\uff09\u3092\u8a08\u7b97\u3057\u307e\u3059\u3002\u3053\u306e\u30b9\u30b3\u30a2\u306f\u3001\u9069\u5408\u7387 - \u518d\u73fe\u7387\u66f2\u7dda\u4e0b\u306e\u9762\u7a4d\u306b\u76f8\u5f53\u3057\u307e\u3059\u3002\u5024\u306f0\u30681\u306e\u9593\u3067\u3042\u308a\u3001\u3088\u308a\u9ad8\u3044\u65b9\u304c\u826f\u3044\u3067\u3059\u3002\u30e9\u30f3\u30c0\u30e0\u4e88\u6e2c\u3067\u306f\u3001AP\u306f\u6b63\u306e\u30b5\u30f3\u30d7\u30eb\u306e\u5272\u5408\u3067\u3059\u3002\n\u3044\u304f\u3064\u304b\u306e\u6a5f\u80fd\u3092\u4f7f\u7528\u3057\u3066,\u9069\u5408\u7387,\u518d\u73fe\u7387,F-\u5024 \u306e\u30b9\u30b3\u30a2\u3092\u5206\u6790\u3059\u308b\u3053\u3068\u304c\u3067\u304d\u307e\u3059\u3002\n\n\n\n\n\n\n\n\n\naverage_precision_score(y_true,y_score [,...])\n\u4e88\u6e2c\u30b9\u30b3\u30a2\u304b\u3089\u5e73\u5747\u9069\u5408\u7387(AP)\u3092\u8a08\u7b97\u3059\u308b\n\n\nf1_score(y_true,y_pred [,labels,...])\nF1\u30b9\u30b3\u30a2\u3092\u8a08\u7b97\u3057\u307e\u3059\u3002\u3053\u308c\u306f\u30d0\u30e9\u30f3\u30b9F\u30b9\u30b3\u30a2\u307e\u305f\u306fF\u30e1\u30b8\u30e3\u30fc\u3068\u3082\u547c\u3070\u308c\u307e\u3059\n\n\nfbeta_score(y_true,y_pred,beta [,labels,...])\nF\u30d9\u30fc\u30bf\u30b9\u30b3\u30a2\u3092\u8a08\u7b97\u3059\u308b\n\n\nprecision_recall_curve(y_true,probas_pred)\n\u3055\u307e\u3056\u307e\u306a\u78ba\u7387\u3057\u304d\u3044\u5024\u306b\u5bfe\u3059\u308b\u9069\u5408\u7387 - \u518d\u73fe\u7387\u306e\u30da\u30a2\u3092\u8a08\u7b97\u3059\u308b\n\n\nprecision_recall_fscore_support(y_true,y_pred)\n\u5404\u30af\u30e9\u30b9\u306e\u9069\u5408\u7387,\u518d\u73fe\u7387,F-measure\u304a\u3088\u3073\u30b5\u30dd\u30fc\u30c8\u3092\u8a08\u7b97\u3059\u308b\n\n\nprecision_score(y_true,y_pred [,labels,...])\n\u9069\u5408\u7387\u3092\u8a08\u7b97\u3059\u308b\n\n\nrecall_score(y_true,y_pred [,labels,...])\n\u518d\u73fe\u7387\u3092\u8a08\u7b97\u3059\u308b\n\n\n\nprecision_recall_curve \u95a2\u6570\u306f\u30d0\u30a4\u30ca\u30ea\u306e\u5834\u5408\u306b\u5236\u9650\u3055\u308c\u3066\u3044\u308b\u3053\u3068\u306b\u6ce8\u610f\u3057\u3066\u304f\u3060\u3055\u3044\u3002 average_precision_score \u95a2\u6570\u306f,\u30d0\u30a4\u30ca\u30ea\u5206\u985e\u304a\u3088\u3073\u30de\u30eb\u30c1\u30e9\u30d9\u30eb\u30a4\u30f3\u30b8\u30b1\u30fc\u30bf\u5f62\u5f0f\u3067\u306e\u307f\u6a5f\u80fd\u3057\u307e\u3059\u3002\n\n\u4f8b\uff1a\n\n\n\u30c6\u30ad\u30b9\u30c8\u6587\u66f8\u3092\u5206\u985e\u3059\u308b f1_score \u306e\u4f7f\u7528\u4f8b\u306b\u3064\u3044\u3066\u306f\u3001\u30b9\u30d1\u30fc\u30b9\u95a2\u6570\u3092\u4f7f\u7528\u3057\u305f\u30c6\u30ad\u30b9\u30c8\u6587\u66f8\u306e\u5206\u985e\u3092\u53c2\u7167\u3057\u3066\u304f\u3060\u3055\u3044\u3002\n\u30cd\u30b9\u30c8\u3055\u308c\u305f\u76f8\u4e92\u691c\u8a3c\u3067\u30b0\u30ea\u30c3\u30c9\u691c\u7d22\u3092\u4f7f\u7528\u3057\u3066\u30d1\u30e9\u30e1\u30fc\u30bf\u3092\u63a8\u5b9a\u3059\u308b\u305f\u3081\u306e precision_score \u304a\u3088\u3073 recall_score \u306e\u4f7f\u7528\u4f8b\u306b\u3064\u3044\u3066\u306f\u3001\u30af\u30ed\u30b9\u691c\u8a3c\u306b\u3088\u308b\u30b0\u30ea\u30c3\u30c9\u691c\u7d22\u3092\u4f7f\u7528\u3057\u305f\u30d1\u30e9\u30e1\u30fc\u30bf\u63a8\u5b9a \u3092\u53c2\u7167\u3057\u3066\u304f\u3060\u3055\u3044\u3002\n\u5206\u985e\u5668\u306e\u51fa\u529b\u54c1\u8cea\u3092\u8a55\u4fa1\u3059\u308b\u305f\u3081\u306e precision_recall_curve \u306e\u4f7f\u7528\u4f8b\u306b\u3064\u3044\u3066\u306f\u3001Precision-Recall \u3092\u53c2\u7167\u3057\u3066\u304f\u3060\u3055\u3044\u3002\n\u30b9\u30d1\u30fc\u30b9\u7dda\u5f62\u30e2\u30c7\u30eb\u306e\u30d5\u30a3\u30fc\u30c1\u30e3\u3092\u9078\u629e\u3059\u308b\u305f\u3081\u306e precision_recall_curve \u306e\u4f7f\u7528\u4f8b\u306b\u3064\u3044\u3066\u306f\u3001\u30b9\u30d1\u30fc\u30b9\u30ea\u30cb\u30a2\u30e2\u30c7\u30eb\u306e\u30b9\u30d1\u30fc\u30b9\u30ea\u30ab\u30d0\u30ea\uff1a\u30d5\u30a3\u30fc\u30c1\u30e3\u9078\u629e \u3092\u53c2\u7167\u3057\u3066\u304f\u3060\u3055\u3044\u3002\n\n\n\n\n\n\n\n\n\n\n\n\naverage_precision_score(y_true,y_score [,...])\n\u4e88\u6e2c\u30b9\u30b3\u30a2\u304b\u3089\u5e73\u5747\u7cbe\u5ea6(AP)\u3092\u8a08\u7b97\u3059\u308b\n\n\nf1_score(y_true,y_pred [,labels,...])\nF1\u30b9\u30b3\u30a2\u3092\u8a08\u7b97\u3057\u307e\u3059\u3002\u3053\u308c\u306f\u30d0\u30e9\u30f3\u30b9F\u30b9\u30b3\u30a2\u307e\u305f\u306fF\u30e1\u30b8\u30e3\u30fc\u3068\u3082\u547c\u3070\u308c\u307e\u3059\n\n\nfbeta_score(y_true,y_pred,beta [,labels,...])\nF\u30d9\u30fc\u30bf\u30b9\u30b3\u30a2\u3092\u8a08\u7b97\u3059\u308b\n\n\nprecision_recall_curve(y_true,probas_pred)\n\u3055\u307e\u3056\u307e\u306a\u78ba\u7387\u306e\u3057\u304d\u3044\u5024\u306b\u5bfe\u3059\u308b\u9069\u5408\u7387 - \u518d\u73fe\u7387\u306e\u30da\u30a2\u3092\u8a08\u7b97\u3059\u308b\n\n\nprecision_recall_fscore_support(y_true,y_pred)\n\u5404\u30af\u30e9\u30b9\u306e\u9069\u5408\u7387,\u518d\u73fe\u7387,F\u5024\u304a\u3088\u3073\u30b5\u30dd\u30fc\u30c8\u3092\u8a08\u7b97\u3059\u308b\n\n\nprecision_score(y_true,y_pred [,labels,...])\n\u9069\u5408\u7387\u3092\u8a08\u7b97\u3059\u308b\n\n\nrecall_score(y_true,y_pred [,labels,...])\n\u518d\u73fe\u7387\u3092\u8a08\u7b97\u3059\u308b\n\n\nprecision_recall_curve\u95a2\u6570\u306f\u30d0\u30a4\u30ca\u30ea\u306e\u5834\u5408\u306b\u5236\u9650\u3055\u308c\u3066\u3044\u308b\u3053\u3068\u306b\u6ce8\u610f\u3057\u3066\u304f\u3060\u3055\u3044\u3002\naverage_precision_score\u95a2\u6570\u306f,\u30d0\u30a4\u30ca\u30ea\u5206\u985e\u304a\u3088\u3073\u30de\u30eb\u30c1\u30e9\u30d9\u30eb\u30a4\u30f3\u30b8\u30b1\u30fc\u30bf\u5f62\u5f0f\u3067\u306e\u307f\u6a5f\u80fd\u3057\u307e\u3059\u3002\n\n\n\nprecision_recall_curve\u95a2\u6570\u306f\u30d0\u30a4\u30ca\u30ea\u306e\u5834\u5408\u306b\u5236\u9650\u3055\u308c\u3066\u3044\u308b\u3053\u3068\u306b\u6ce8\u610f\u3057\u3066\u304f\u3060\u3055\u3044\u3002 average_precision_score\u95a2\u6570\u306f\u3001\u30d0\u30a4\u30ca\u30ea\u5206\u985e\u304a\u3088\u3073\u30de\u30eb\u30c1\u30e9\u30d9\u30eb\u30a4\u30f3\u30b8\u30b1\u30fc\u30bf\u5f62\u5f0f\u3067\u306e\u307f\u6a5f\u80fd\u3057\u307e\u3059\u3002\n\u4f8b\uff1a\n\u30c6\u30ad\u30b9\u30c8\u6587\u66f8\u3092\u5206\u985e\u3059\u308bf1_score\u306e\u4f7f\u7528\u4f8b\u306b\u3064\u3044\u3066\u306f\u3001\u30b9\u30d1\u30fc\u30b9\u95a2\u6570\u3092\u4f7f\u7528\u3057\u305f\u30c6\u30ad\u30b9\u30c8\u6587\u66f8\u306e\u5206\u985e\u3092\u53c2\u7167\u3057\u3066\u304f\u3060\u3055\u3044\u3002\n\u30cd\u30b9\u30c8\u3055\u308c\u305f\u76f8\u4e92\u691c\u8a3c\u3067\u30b0\u30ea\u30c3\u30c9\u691c\u7d22\u3092\u4f7f\u7528\u3057\u3066\u30d1\u30e9\u30e1\u30fc\u30bf\u3092\u63a8\u5b9a\u3059\u308b\u305f\u3081\u306eprecision_score\u304a\u3088\u3073recall_score\u306e\u4f7f\u7528\u4f8b\u306b\u3064\u3044\u3066\u306f\u3001\u30af\u30ed\u30b9\u691c\u8a3c\u306b\u3088\u308b\u30b0\u30ea\u30c3\u30c9\u691c\u7d22\u3092\u4f7f\u7528\u3057\u305f\u30d1\u30e9\u30e1\u30fc\u30bf\u63a8\u5b9a\u3092\u53c2\u7167\u3057\u3066\u304f\u3060\u3055\u3044\u3002\n\u5206\u985e\u5668\u306e\u51fa\u529b\u54c1\u8cea\u3092\u8a55\u4fa1\u3059\u308b\u305f\u3081\u306eprecision_recall_curve\u306e\u4f7f\u7528\u4f8b\u306b\u3064\u3044\u3066\u306f\u3001Precision-Recall\u3092\u53c2\u7167\u3057\u3066\u304f\u3060\u3055\u3044\u3002\n\u30b9\u30d1\u30fc\u30b9\u7dda\u5f62\u30e2\u30c7\u30eb\u306e\u30d5\u30a3\u30fc\u30c1\u30e3\u3092\u9078\u629e\u3059\u308b\u305f\u3081\u306eprecision_recall_curve\u306e\u4f7f\u7528\u4f8b\u306b\u3064\u3044\u3066\u306f\u3001\u30b9\u30d1\u30fc\u30b9\u30ea\u30cb\u30a2\u30e2\u30c7\u30eb\u306e\u30b9\u30d1\u30fc\u30b9\u30ea\u30ab\u30d0\u30ea\uff1a\u30d5\u30a3\u30fc\u30c1\u30e3\u9078\u629e\u3092\u53c2\u7167\u3057\u3066\u304f\u3060\u3055\u3044\u3002\n\n3.3.2.8.1. \u4e8c\u5024\u5206\u985e\n\u4e8c\u5024\u5206\u985e\u30bf\u30b9\u30af\u3067\u306f\u3001\u300c\u967d\u6027\u300d\u304a\u3088\u3073\u300c\u9670\u6027\u300d\u3068\u3044\u3046\u7528\u8a9e\u306f\u5206\u985e\u5668\u306e\u4e88\u6e2c\u3092\u793a\u3057\u3001\u300c\u771f\u300d\u304a\u3088\u3073\u300c\u507d\u300d\u3068\u3044\u3046\u7528\u8a9e\u306f\u3001\u305d\u306e\u4e88\u6e2c\u304c\u5916\u90e8\u306e\u5224\u65ad\u306b\u5bfe\u5fdc\u3059\u308b\u304b\u3069\u3046\u304b\u3092\u793a\u3059\u300c\u89b3\u5bdf\u300d\u3068\u3082\u547c\u3070\u308c\u308b\uff09\u3002\u3053\u308c\u3089\u306e\u5b9a\u7fa9\u304c\u4e0e\u3048\u3089\u308c\u305f\u5834\u5408\u3001\u6b21\u306e\u8868\u3092\u4f5c\u6210\u3067\u304d\u307e\u3059\u3002\n\n\n\n\n\u5b9f\u969b\u306e\u30af\u30e9\u30b9\uff08\u89b3\u6e2c\uff09\n\n\n\n\n\n\u4e88\u6e2c\u30af\u30e9\u30b9\uff08\u671f\u5f85\u5024\uff09\ntp\uff08\u771f\u967d\u6027\uff09\u6b63\u3057\u3044\u7d50\u679c\nfp\uff08\u507d\u967d\u6027\uff09\u4e88\u671f\u3057\u306a\u3044\u7d50\u679c\n\n\n\nfn\uff08\u507d\u9670\u6027\uff09\u6b20\u843d\u3057\u305f\u7d50\u679c\ntn\uff08\u771f\u9670\u6027\uff09\u7d50\u679c\u304c\u6b63\u3057\u304f\u306a\u3044\n\n\n\n\u3053\u306e\u6587\u8108\u3067\u306f\u3001\u9069\u5408\u7387\u3001\u518d\u73fe\u7387\u3001F-\u5024\u3068\u3044\u3046\u6982\u5ff5\u3092\u5b9a\u7fa9\u3059\u308b\u3053\u3068\u304c\u3067\u304d\u307e\u3059\u3002\n\\text{precision} = \\frac{tp}{tp + fp}, \\\\\n\\text{recall} = \\frac{tp}{tp + fn}, \\\\\nF_\\beta = (1 + \\beta^2) \\frac{\\text{precision} \\times \\text{recall}}{\\beta^2 \\text{precision} + \\text{recall}}.\n\n\u4e8c\u5024\u5206\u985e\u306e\u5c0f\u3055\u306a\u4f8b\u3092\u3044\u304f\u3064\u304b\u6319\u3052\u307e\u3059\uff1a\n>>> from sklearn import metrics\n>>> y_pred = [0, 1, 0, 0]\n>>> y_true = [0, 1, 0, 1]\n>>> metrics.precision_score(y_true, y_pred)\n1.0\n>>> metrics.recall_score(y_true, y_pred)\n0.5\n>>> metrics.f1_score(y_true, y_pred)  \n0.66...\n>>> metrics.fbeta_score(y_true, y_pred, beta=0.5)  \n0.83...\n>>> metrics.fbeta_score(y_true, y_pred, beta=1)  \n0.66...\n>>> metrics.fbeta_score(y_true, y_pred, beta=2) \n0.55...\n>>> metrics.precision_recall_fscore_support(y_true, y_pred, beta=0.5)  \n(array([ 0.66...,  1.        ]), array([ 1. ,  0.5]), array([ 0.71...,  0.83...]), array([2, 2]...))\n\n\n>>> import numpy as np\n>>> from sklearn.metrics import precision_recall_curve\n>>> from sklearn.metrics import average_precision_score\n>>> y_true = np.array([0, 0, 1, 1])\n>>> y_scores = np.array([0.1, 0.4, 0.35, 0.8])\n>>> precision, recall, threshold = precision_recall_curve(y_true, y_scores)\n>>> precision  \narray([ 0.66...,  0.5       ,  1.        ,  1.        ])\n>>> recall\narray([ 1. ,  0.5,  0.5,  0. ])\n>>> threshold\narray([ 0.35,  0.4 ,  0.8 ])\n>>> average_precision_score(y_true, y_scores)  \n0.79...\n\n\n3.3.2.8.2. \u30de\u30eb\u30c1\u30af\u30e9\u30b9\u3068\u30de\u30eb\u30c1\u30e9\u30d9\u30eb\u306e\u5206\u985e\n\u30de\u30eb\u30c1\u30af\u30e9\u30b9\u304a\u3088\u3073\u30de\u30eb\u30c1\u30e9\u30d9\u30eb\u5206\u985e\u30bf\u30b9\u30af\u3067\u306f\u3001\u9069\u5408\u7387\u3001\u518d\u73fe\u7387\u3001F\u5024\u306e\u6982\u5ff5\u3092\u5404\u30e9\u30d9\u30eb\u306b\u500b\u5225\u306b\u9069\u7528\u3067\u304d\u307e\u3059\u3002\u4e0a\u8a18\u306e\u3088\u3046\u306baverage_precision_score\uff08multilabel\u306e\u307f\uff09\u3001f1_score\u3001fbeta_score\u3001precision_recall_fscore_support\u3001precision_score\u3001\u304a\u3088\u3073recall_score\u95a2\u6570\u306eaverage\u5f15\u6570\u3067\u6307\u5b9a\u3055\u308c\u305f\u30e9\u30d9\u30eb\u9593\u3067\u7d50\u679c\u3092\u7d50\u5408\u3059\u308b\u306b\u306f\u3001\u3044\u304f\u3064\u304b\u306e\u65b9\u6cd5\u304c\u3042\u308a\u307e\u3059\u3002\u3059\u3079\u3066\u306e\u30e9\u30d9\u30eb\u304c\u542b\u307e\u308c\u3066\u3044\u308b\u30de\u30eb\u30c1\u30af\u30e9\u30b9\u8a2d\u5b9a\u3067\u306e \"micro\" \u5e73\u5747\u5316\u3067\u306f\u3001\u7b49\u3057\u3044\u9069\u5408\u7387\u3001\u518d\u73fe\u7387\u3001F\u5024\u304c\u751f\u6210\u3055\u308c\u307e\u3059\u304c\u3001 \"weighted\" \u5e73\u5747\u5316\u3067\u306f\u9069\u5408\u7387\u3068\u518d\u73fe\u7387\u306e\u9593\u306b\u306a\u3044F\u30b9\u30b3\u30a2\u304c\u751f\u6210\u3055\u308c\u308b\u3053\u3068\u306b\u6ce8\u610f\u3057\u3066\u304f\u3060\u3055\u3044\u3002\n\u3053\u308c\u3092\u3088\u308a\u660e\u793a\u7684\u306b\u3059\u308b\u306b\u306f\u3001\u6b21\u306e\u8868\u8a18\u6cd5\u3092\u691c\u8a0e\u3057\u3066\u304f\u3060\u3055\u3044\u3002\n\n$y$ \u306f\u4e88\u6e2c\u3055\u308c\u305f $(sample, label)$ \u306e\u30da\u30a2\u306e\u96c6\u5408\n$\\hat{y}$ \u306f $true(sample, label)$ \u306e\u7d44\u306e\u96c6\u5408\n$L$ \u306f\u30e9\u30d9\u30eb\u306e\u30bb\u30c3\u30c8\n$S$ \u306f\u30b5\u30f3\u30d7\u30eb\u30bb\u30c3\u30c8\n$y_s$ \u306fy\u306e\u30b5\u30d6\u30bb\u30c3\u30c8\u3001\u3059\u306a\u308f\u3061 $y_s := \\left\\{(s', l) \\in y | s' = s\\right\\}$\n$y_l$ \u306f\u30e9\u30d9\u30eb $l$ \u306e $y$ \u306e\u30b5\u30d6\u30bb\u30c3\u30c8\n\u540c\u69d8\u306b\u3001$\\hat{y}_s$ \u3068 $\\hat {y}_l$ \u306f $\\hat{y}$ \u306e\u30b5\u30d6\u30bb\u30c3\u30c8\u3067\u3059\n$P(A, B) := \\frac{\\left| A \\cap B \\right|}{\\left|A\\right|}$\n$R(A, B) := \\frac{\\left| A \\cap B \\right|}{\\left|B\\right|}$ (\u8868\u8a18\u898f\u5247\u306f\u3001 $B = \\emptyset$ \u306e\u53d6\u308a\u6271\u3044\u306b\u3088\u3063\u3066\u7570\u306a\u308a\u307e\u3059\u3002 \u3053\u306e\u5b9f\u88c5\u306f $R(A, B):=0$ \u3092\u4f7f\u7528\u3057\u3001 $P$ \u3082\u540c\u69d8\u3067\u3059\uff09\u3002\n$F_\\beta(A, B) := \\left(1 + \\beta^2\\right) \\frac{P(A, B) \\times R(A, B)}{\\beta^2 P(A, B) + R(A, B)}$\n\n\u6b21\u306b\u3001\u30e1\u30c8\u30ea\u30c3\u30af\u306f\u6b21\u306e\u3088\u3046\u306b\u5b9a\u7fa9\u3055\u308c\u307e\u3059\u3002\n\n\n\naverage\nPrecision\nRecall\nF_beta\n\n\n\n\n\"micro\" $P(y, \\hat{y})$  $R(y, \\hat{y})$  $F_\\beta(y, \\hat{y})$  \n\n \"samples\" \n$\\frac{1}{\\left|S\\right|} \\sum_{s \\in S} P(y_s, \\hat{y}_s)$ \n$\\frac{1}{\\left|S\\right|} \\sum_{s \\in S} R(y_s, \\hat{y}_s)$ \n$\\frac{1}{\\left|S\\right|} \\sum_{s \\in S} F_\\beta(y_s, \\hat{y}_s)$ \n\n\n\"macro\"\n$\\frac{1}{\\left|L\\right|} \\sum_{l \\in L} P(y_l, \\hat{y}_l)$ \n$\\frac{1}{\\left|L\\right|} \\sum_{l \\in L} R(y_l, \\hat{y}_l)$ \n$\\frac{1}{\\left|L\\right|} \\sum_{l \\in L} F_\\beta(y_l, \\hat{y}_l)$ \n\n\n\"weighted\"\n$\\frac{1}{\\sum_{l \\in L} \\left|\\hat{y}_l\\right|} \\sum_{l \\in L} \\left|\\hat{y}_l\\right| P(y_l, \\hat{y}_l)$ \n$\\frac{1}{\\sum_{l \\in L} \\left|\\hat{y}_l\\right|} \\sum_{l \\in L} \\left|\\hat{y}_l\\right| R(y_l, \\hat{y}_l)$ \n$\\frac{1}{\\sum_{l \\in L} \\left|\\hat{y}_l\\right|} \\sum_{l \\in L} \\left|\\hat{y}_l\\right| F_\\beta(y_l, \\hat{y}_l)$ \n\n\nNone\n$\\langle P(y_l, \\hat{y}_l) | l \\in L \\rangle$ \n$\\langle R(y_l, \\hat{y}_l) | l \\in L \\rangle$ \n$\\langle F_\\beta(y_l, \\hat{y}_l) | l \\in L \\rangle$ \n\n\n\n>>> from sklearn import metrics\n>>> y_true = [0, 1, 2, 0, 1, 2]\n>>> y_pred = [0, 2, 1, 0, 0, 1]\n>>> metrics.precision_score(y_true, y_pred, average='macro')  \n0.22...\n>>> metrics.recall_score(y_true, y_pred, average='micro')\n... \n0.33...\n>>> metrics.f1_score(y_true, y_pred, average='weighted')  \n0.26...\n>>> metrics.fbeta_score(y_true, y_pred, average='macro', beta=0.5)  \n0.23...\n>>> metrics.precision_recall_fscore_support(y_true, y_pred, beta=0.5, average=None)\n... \n(array([ 0.66...,  0.        ,  0.        ]), array([ 1.,  0.,  0.]), array([ 0.71...,  0.        ,  0.        ]), array([2, 2, 2]...))\n\n\u300c\u30cd\u30ac\u30c6\u30a3\u30d6\u30af\u30e9\u30b9\u300d\u3092\u542b\u3080\u30de\u30eb\u30c1\u30af\u30e9\u30b9\u5206\u985e\u3067\u306f\u3001\u3044\u304f\u3064\u304b\u306e\u30e9\u30d9\u30eb\u3092\u9664\u5916\u3059\u308b\u3053\u3068\u304c\u3067\u304d\u307e\u3059\u3002\n>>>\n>>> metrics.recall_score(y_true, y_pred, labels=[1, 2], average='micro')\n... # excluding 0, no labels were correctly recalled\n0.0\n\n\u540c\u69d8\u306b\u3001\u30c7\u30fc\u30bf\u30b5\u30f3\u30d7\u30eb\u4e2d\u306b\u5b58\u5728\u3057\u306a\u3044\u30e9\u30d9\u30eb\u306f\u3001\u30de\u30af\u30ed\u5e73\u5747\u5316\u306b\u304a\u3044\u3066\u8aac\u660e\u3055\u308c\u5f97\u308b\u3002\n>>>\n>>> metrics.precision_score(y_true, y_pred, labels=[0, 1, 2, 3], average='macro')\n... \n0.166...\n\n\n3.3.2.9. \u30d2\u30f3\u30b8\u640d\u5931\nhinge_loss \u95a2\u6570\u306f\u3001\u4e88\u6e2c\u8aa4\u5dee\u306e\u307f\u3092\u8003\u616e\u3059\u308b\u7247\u5074\u30e1\u30c8\u30ea\u30c3\u30af\u3067\u3042\u308b \u30d2\u30f3\u30b8\u640d\u5931 \u3092\u4f7f\u7528\u3057\u3066\u3001\u30e2\u30c7\u30eb\u3068\u30c7\u30fc\u30bf\u9593\u306e\u5e73\u5747\u8ddd\u96e2\u3092\u8a08\u7b97\u3057\u307e\u3059\u3002 \uff08\u30d2\u30f3\u30b8\u640d\u5931\u306f\u3001\u30b5\u30dd\u30fc\u30c8\u30d9\u30af\u30bf\u30fc\u30de\u30b7\u30f3\u306a\u3069\u306e\u6700\u5927\u30de\u30fc\u30b8\u30f3\u5206\u985e\u5668\u3067\u4f7f\u7528\u3055\u308c\u307e\u3059\uff09\u3002\n\u30e9\u30d9\u30eb\u304c+1\u304a\u3088\u3073-1\u3067\u30a8\u30f3\u30b3\u30fc\u30c9\u3055\u308c\u3066\u3044\u308b\u5834\u5408\u3001$y\uff1a$ \u306f\u771f\u306e\u5024\u3067\u3042\u308a\u3001 $w$ \u306f decision_function \u306e\u51fa\u529b\u3068\u3057\u3066\u306e\u4e88\u6e2c\u3055\u308c\u305f\u6c7a\u5b9a\u3067\u3042\u308a\u3001\u30d2\u30f3\u30b8\u640d\u5931\u306f\u6b21\u306e\u3088\u3046\u306b\u5b9a\u7fa9\u3055\u308c\u307e\u3059\u3002\nL_\\text{Hinge}(y, w) = \\max\\left\\{1 - wy, 0\\right\\} = \\left|1 - wy\\right|_+\n\n2\u3064\u4ee5\u4e0a\u306e\u30e9\u30d9\u30eb\u304c\u3042\u308b\u5834\u5408\u3001hinge_loss\u306fCrammer\uff06Singer\u306e\u305f\u3081\u306b\u30de\u30eb\u30c1\u30af\u30e9\u30b9\u306e\u5909\u5f62\u3092\u4f7f\u7528\u3057\u307e\u3059\u3002\u3053\u3053\u306b\u305d\u308c\u3092\u8a18\u8ff0\u3059\u308b\u8ad6\u6587\u304c\u3042\u308a\u307e\u3059\u3002\n$y_w$ \u304c\u771f\u306e\u30e9\u30d9\u30eb\u306e\u4e88\u6e2c\u3055\u308c\u305f\u6c7a\u5b9a\u3067\u3042\u308a\u3001 $y_t$ \u304c\u3001\u6c7a\u5b9a\u95a2\u6570\u306b\u3088\u3063\u3066\u4e88\u6e2c\u3055\u308c\u305f\u6c7a\u5b9a\u304c\u51fa\u529b\u3055\u308c\u308b\u4ed6\u306e\u3059\u3079\u3066\u306e\u30e9\u30d9\u30eb\u306e\u4e88\u6e2c\u3055\u308c\u305f\u6c7a\u5b9a\u306e\u6700\u5927\u5024\u3067\u3042\u308b\u5834\u5408\u3001\u30de\u30eb\u30c1\u30af\u30e9\u30b9\u30d2\u30f3\u30b8\u640d\u5931\u306f\u3001\nL_\\text{Hinge}(y_w, y_t) = \\max\\left\\{1 + y_t - y_w, 0\\right\\}\n\n\u3053\u3053\u3067\u306f\u3001\u30d0\u30a4\u30ca\u30ea\u30af\u30e9\u30b9\u306e\u554f\u984c\u3067svm\u5206\u985e\u5668\u3067hinge_loss\u95a2\u6570\u3092\u4f7f\u7528\u3059\u308b\u65b9\u6cd5\u3092\u793a\u3059\u5c0f\u3055\u306a\u4f8b\u3092\u793a\u3057\u307e\u3059\u3002\n>>> from sklearn import svm\n>>> from sklearn.metrics import hinge_loss\n>>> X = [[0], [1]]\n>>> y = [-1, 1]\n>>> est = svm.LinearSVC(random_state=0)\n>>> est.fit(X, y)\nLinearSVC(C=1.0, class_weight=None, dual=True, fit_intercept=True,\n     intercept_scaling=1, loss='squared_hinge', max_iter=1000,\n     multi_class='ovr', penalty='l2', random_state=0, tol=0.0001,\n     verbose=0)\n>>> pred_decision = est.decision_function([[-2], [3], [0.5]])\n>>> pred_decision  \narray([-2.18...,  2.36...,  0.09...])\n>>> hinge_loss([-1, 1, 1], pred_decision)  \n0.3...\n\n\n\u591a\u30af\u30e9\u30b9\u306e\u554f\u984c\u3067\u3001svm\u5206\u985e\u5668\u3067hinge_loss\u95a2\u6570\u3092\u4f7f\u7528\u3059\u308b\u4f8b\u3092\u4ee5\u4e0b\u306b\u793a\u3057\u307e\u3059:\n>>>\n>>> X = np.array([[0], [1], [2], [3]])\n>>> Y = np.array([0, 1, 2, 3])\n>>> labels = np.array([0, 1, 2, 3])\n>>> est = svm.LinearSVC()\n>>> est.fit(X, Y)\nLinearSVC(C=1.0, class_weight=None, dual=True, fit_intercept=True,\n     intercept_scaling=1, loss='squared_hinge', max_iter=1000,\n     multi_class='ovr', penalty='l2', random_state=None, tol=0.0001,\n     verbose=0)\n>>> pred_decision = est.decision_function([[-1], [2], [3]])\n>>> y_true = [0, 2, 3]\n>>> hinge_loss(y_true, pred_decision, labels)  \n0.56...\n\n\n3.3.2.10. \u30ed\u30b0\u640d\u5931\n\u30ed\u30b8\u30b9\u30c6\u30a3\u30c3\u30af\u56de\u5e30\u30ed\u30b9\u307e\u305f\u306f\u30af\u30ed\u30b9\u30a8\u30f3\u30c8\u30ed\u30d4\u30fc\u30ed\u30b9\u3068\u3082\u547c\u3070\u308c\u308b\u30ed\u30b0\u640d\u5931\u306f\u3001\u78ba\u7387\u63a8\u5b9a\u3067\u5b9a\u7fa9\u3055\u308c\u307e\u3059\u3002\u3053\u308c\u306f\u3001\uff08\u591a\u9805\u5f0f\uff09\u30ed\u30b8\u30b9\u30c6\u30a3\u30c3\u30af\u56de\u5e30\u304a\u3088\u3073\u30cb\u30e5\u30fc\u30e9\u30eb\u30cd\u30c3\u30c8\u30ef\u30fc\u30af\u306a\u3089\u3073\u306b\u4e88\u60f3\u6700\u5927\u5316\u306e\u3044\u304f\u3064\u304b\u306e\u5909\u5f62\u4f8b\u3067\u4e00\u822c\u7684\u306b\u4f7f\u7528\u3055\u308c\u3001\u96e2\u6563\u7684\u4e88\u6e2c\u306e\u4ee3\u308f\u308a\u306b\u5206\u985e\u5668\u306e\u78ba\u7387\u51fa\u529b\uff08predict_proba\uff09\u3092\u8a55\u4fa1\u3059\u308b\u305f\u3081\u306b\u4f7f\u7528\u3059\u308b\u3053\u3068\u304c\u3067\u304d\u308b\u3002\n\u771f\u306e\u30e9\u30d9\u30eb $y \\in {0,1}$ \u304a\u3088\u3073\u78ba\u7387\u63a8\u5b9a $ p = \\operatorname{Pr}(y = 1)$ \u3092\u6709\u3059\u308b\u30d0\u30a4\u30ca\u30ea\u5206\u985e\u306e\u5834\u5408\u3001\u30b5\u30f3\u30d7\u30eb\u5f53\u305f\u308a\u306e\u30ed\u30b0\u640d\u5931\u306f\u3001\u771f\u306e\u30e9\u30d9\u30eb\u304c\u4e0e\u3048\u3089\u308c\u305f\u5206\u985e\u5668\u306e\u8ca0\u306e\u5bfe\u6570\u5c24\u5ea6\u3067\u3042\u308b\u3002\nL_{\\log}(y, p) = -\\log \\operatorname{Pr}(y|p) = -(y \\log (p) + (1 - y) \\log (1 - p))\n\n\u3053\u308c\u306f\u4ee5\u4e0b\u306e\u3088\u3046\u306b\u30de\u30eb\u30c1\u30af\u30e9\u30b9\u306e\u5834\u5408\u306b\u307e\u3067\u53ca\u3076\u3002\u30b5\u30f3\u30d7\u30eb\u30bb\u30c3\u30c8\u306b\u5bfe\u3059\u308b\u771f\u306e\u30e9\u30d9\u30eb\u3092K\u500b\u306e\u30d0\u30a4\u30ca\u30ea\u30a4\u30f3\u30b8\u30b1\u30fc\u30bf\u884c\u5217 $Y$ \u306e1\u3064\u3068\u3057\u3066\u7b26\u53f7\u5316\u3059\u308b\u3002\u3059\u306a\u308f\u3061\u3001\u30b5\u30f3\u30d7\u30ebi\u304cK\u500b\u306e\u30e9\u30d9\u30eb\u306e\u30bb\u30c3\u30c8\u304b\u3089\u53d6\u3089\u308c\u305f\u30e9\u30d9\u30ebk\u3092\u6709\u3059\u308b\u5834\u5408\u3001 $ y_{i,k} = 1$ \u3067\u3042\u308b\u3002 $P$ \u3092\u78ba\u7387\u63a8\u5b9a\u306e\u884c\u5217\u3068\u3057\u3001 $p_{i,k} = \\operatorname{Pr}(t_{i,k} = 1)$ \u3068\u3059\u308b\u3002 \u3059\u308b\u3068\u3001\u96c6\u5408\u5168\u4f53\u306e\u5bfe\u6570\u640d\u5931\u306f\nL_{\\log}(Y, P) = -\\log \\operatorname{Pr}(Y|P) = - \\frac{1}{N} \\sum_{i=0}^{N-1} \\sum_{k=0}^{K-1} y_{i,k} \\log p_{i,k}\n\n\u3053\u308c\u304c\u30d0\u30a4\u30ca\u30ea\u306e\u5834\u5408\u3001$ p_{i,0} = 1 - p_{i,1}$ \u3068 $y_{i,0} = 1 - y_{i,1}$ \u3057\u305f\u304c\u3063\u3066\u3001\u5185\u90e8\u5408\u8a08\u3092 $y_{i,k} \\in {0,1}$  \u3088\u308a\u5927\u304d\u304f\u3059\u308b\u3068\u3001\u30d0\u30a4\u30ca\u30ea\u30ed\u30b0\u640d\u5931\u304c\u5f97\u3089\u308c\u307e\u3059\u3002\nlog_loss \u95a2\u6570\u306f\u3001\u63a8\u5b9a\u5024\u306e predict_proba \u30e1\u30bd\u30c3\u30c9\u306b\u3088\u3063\u3066\u8fd4\u3055\u308c\u308b\u3088\u3046\u306b\u3001\u30b0\u30e9\u30f3\u30c9\u771f\u7406\u5024\u30e9\u30d9\u30eb\u3068\u78ba\u7387\u884c\u5217\u306e\u30ea\u30b9\u30c8\u304c\u4e0e\u3048\u3089\u308c\u305f\u3068\u304d\u306e\u30ed\u30b0\u640d\u5931\u3092\u8a08\u7b97\u3057\u307e\u3059\u3002\n>>> from sklearn.metrics import log_loss\n>>> y_true = [0, 0, 1, 1]\n>>> y_pred = [[.9, .1], [.8, .2], [.3, .7], [.01, .99]]\n>>> log_loss(y_true, y_pred)    \n0.1738...\n\ny_pred\u306e\u6700\u521d\u306e [.9, .1] \u306f\u3001\u6700\u521d\u306e\u30b5\u30f3\u30d7\u30eb\u304c\u30e9\u30d9\u30eb0\u3092\u6301\u3064\u78ba\u7387\u304c90\uff05\u3067\u3042\u308b\u3053\u3068\u3092\u793a\u3057\u307e\u3059\u3002\u30ed\u30b0\u640d\u5931\u306f\u8ca0\u3067\u306f\u3042\u308a\u307e\u305b\u3093\u3002\n\n3.3.2.11. \u30de\u30b7\u30e5\u30fc\u30ba\u76f8\u95a2\u4fc2\u6570\nmatthews_corrcoef \u95a2\u6570\u306f\u3001\u30d0\u30a4\u30ca\u30ea\u30af\u30e9\u30b9\u306e\u30de\u30b7\u30e5\u30fc\u76f8\u95a2\u4fc2\u6570\uff08MCC\uff09\u3092\u8a08\u7b97\u3057\u307e\u3059\u3002\u5f15\u7528Wikipedia\uff1a\n\nMatthews\u306e\u76f8\u95a2\u4fc2\u6570\u306f\u3001\u30d0\u30a4\u30ca\u30ea\uff082\u30af\u30e9\u30b9\uff09\u5206\u985e\u306e\u54c1\u8cea\u306e\u5c3a\u5ea6\u3068\u3057\u3066\u6a5f\u68b0\u5b66\u7fd2\u3067\u4f7f\u7528\u3055\u308c\u307e\u3059\u3002\u771f\u967d\u6027\u3068\u9670\u9670\u967d\u6027\u3068\u9670\u6027\u3092\u8003\u616e\u3057\u3001\u30af\u30e9\u30b9\u304c\u975e\u5e38\u306b\u7570\u306a\u308b\u30b5\u30a4\u30ba\u3067\u3042\u3063\u3066\u3082\u4f7f\u7528\u3067\u304d\u308b\u30d0\u30e9\u30f3\u30b9\u306e\u53d6\u308c\u305f\u5c3a\u5ea6\u3068\u4e00\u822c\u7684\u306b\u307f\u306a\u3055\u308c\u307e\u3059\u3002 MCC\u306f\u3001\u672c\u8cea\u7684\u306b\u3001-1\u3068+1\u3068\u306e\u9593\u306e\u76f8\u95a2\u4fc2\u6570\u5024\u3067\u3042\u308b\u3002 + 1\u306e\u4fc2\u6570\u306f\u5b8c\u5168\u4e88\u6e2c\u3092\u8868\u3057\u30010\u306f\u5e73\u5747\u30e9\u30f3\u30c0\u30e0\u4e88\u6e2c\u3092\u8868\u3057\u3001-1\u306f\u9006\u4e88\u6e2c\u3092\u8868\u3059\u3002\u7d71\u8a08\u306f\u3001\u03c6\u4fc2\u6570\u3068\u3057\u3066\u3082\u77e5\u3089\u308c\u3066\u3044\u307e\u3059\u3002\n\n$tp$ \u3001$tn$ \u3001$fp$ \u304a\u3088\u3073 $fn$ \u304c\u305d\u308c\u305e\u308c\u771f\u967d\u6027\u3001\u771f\u9670\u6027\u3001\u507d\u967d\u6027\u304a\u3088\u3073\u507d\u9670\u6027\u306e\u6570\u3067\u3042\u308b\u5834\u5408\u3001MCC\u4fc2\u6570\u306f\nMCC = \\frac{tp \\times tn - fp \\times fn}{\\sqrt{(tp + fp)(tp + fn)(tn + fp)(tn + fn)}}.\n\nmatthews_corrcoef\u95a2\u6570\u306e\u4f7f\u3044\u65b9\u3092\u793a\u3059\u5c0f\u3055\u306a\u4f8b\u3092\u6b21\u306b\u793a\u3057\u307e\u3059\u3002\n>>>\n>>> sklearn.metrics\u304b\u3089\u306e\u30a4\u30f3\u30dd\u30fc\u30c8matthews_corrcoef\n>>> y_true = [+1\u3001+1\u3001+1\u3001-1]\n>>> y_pred = [+1\u3001-1\u3001+1\u3001+1]\n>>> matthews_corrcoef\uff08y_true\u3001y_pred\uff09\n-0.33 ...\n\n\n3.3.2.12. \u30ec\u30b7\u30fc\u30d0\u52d5\u4f5c\u7279\u6027\uff08ROC\uff09\n\u95a2\u6570roc_curve \u306f\u3001\u53d7\u4fe1\u8005\u52d5\u4f5c\u7279\u6027\u66f2\u7dda\u307e\u305f\u306fROC\u30ab\u30fc\u30d6 \u3092\u8a08\u7b97\u3057\u307e\u3059\u3002\u5f15\u7528Wikipedia\uff1a\n\n\u53d7\u4fe1\u6a5f\u52d5\u4f5c\u7279\u6027\uff08ROC\uff09\u3001\u307e\u305f\u306f\u5358\u7d14\u306bROC\u66f2\u7dda\u306f\u3001\u8b58\u5225\u95be\u5024\u304c\u5909\u5316\u3059\u308b\u3068\u304d\u306e\u30d0\u30a4\u30ca\u30ea\u5206\u985e\u30b7\u30b9\u30c6\u30e0\u306e\u6027\u80fd\u3092\u793a\u3059\u30b0\u30e9\u30d5\u30d7\u30ed\u30c3\u30c8\u3067\u3042\u308b\u3002\u3053\u308c\u306f\u3001\u3055\u307e\u3056\u307e\u306a\u95be\u5024\u8a2d\u5b9a\u3067\u3001\u967d\u6027\u304b\u3089\u306e\u771f\u967d\u6027\u306e\u5272\u5408\uff08TPR =\u771f\u967d\u6027\u7387\uff09\u5bfe\u9670\u6027\u304b\u3089\u306e\u507d\u967d\u6027\u306e\u5272\u5408\uff08FPR =\u507d\u967d\u6027\u7387\uff09\u3092\u30d7\u30ed\u30c3\u30c8\u3059\u308b\u3053\u3068\u306b\u3088\u3063\u3066\u4f5c\u6210\u3055\u308c\u307e\u3059\u3002 TPR\u306f\u611f\u53d7\u6027\u3068\u3057\u3066\u3082\u77e5\u3089\u308c\u3066\u304a\u308a\u3001FPR\u306f\u7279\u7570\u6027\u307e\u305f\u306f\u771f\u306e\u8ca0\u306e\u7387\u304b\u30891\u3092\u5f15\u3044\u305f\u3082\u306e\u3067\u3059\u3002\n\n\u3053\u306e\u95a2\u6570\u306f\u3001\u771f\u306e\u30d0\u30a4\u30ca\u30ea\u5024\u3068\u76ee\u6a19\u30b9\u30b3\u30a2\u3092\u5fc5\u8981\u3068\u3057\u307e\u3059\u3002\u3053\u308c\u306f\u3001\u967d\u6027\u30af\u30e9\u30b9\u306e\u78ba\u7387\u63a8\u5b9a\u5024\u3001\u4fe1\u983c\u5024\u3001\u307e\u305f\u306f\u30d0\u30a4\u30ca\u30ea\u6c7a\u5b9a\u306e\u3044\u305a\u308c\u304b\u3067\u3059\u3002 roc_curve\u95a2\u6570\u3092\u4f7f\u7528\u3059\u308b\u65b9\u6cd5\u306e\u5c0f\u3055\u306a\u4f8b\u3092\u6b21\u306b\u793a\u3057\u307e\u3059\u3002\n>>> import numpy as np\n>>> from sklearn.metrics import roc_curve\n>>> y = np.array([1, 1, 2, 2])\n>>> scores = np.array([0.1, 0.4, 0.35, 0.8])\n>>> fpr, tpr, thresholds = roc_curve(y, scores, pos_label=2)\n>>> fpr\narray([ 0. ,  0.5,  0.5,  1. ])\n>>> tpr\narray([ 0.5,  0.5,  1. ,  1. ])\n>>> thresholds\narray([ 0.8 ,  0.4 ,  0.35,  0.1 ])\n\n\u3053\u306e\u56f3\u306f\u3001\u305d\u306e\u3088\u3046\u306aROC\u66f2\u7dda\u306e\u4f8b\u3092\u793a\u3057\u3066\u3044\u307e\u3059\u3002\n\nroc_auc_score \u95a2\u6570\u306f\u3001AUC\u307e\u305f\u306fAUROC\u3067\u8868\u3055\u308c\u308b\u53d7\u4fe1\u6a5f\u52d5\u4f5c\u7279\u6027\uff08ROC\uff09\u30ab\u30fc\u30d6\u306e\u4e0b\u306e\u9762\u7a4d\u3092\u8a08\u7b97\u3057\u307e\u3059\u3002 roc\u66f2\u7dda\u4e0b\u306e\u9762\u7a4d\u3092\u8a08\u7b97\u3059\u308b\u3053\u3068\u306b\u3088\u308a\u3001\u66f2\u7dda\u60c5\u5831\u304c1\u3064\u306e\u6570\u306b\u307e\u3068\u3081\u3089\u308c\u307e\u3059\u3002 \u8a73\u7d30\u306f\u3001AUC\u306b\u95a2\u3059\u308bWikipedia\u306e\u8a18\u4e8b \u3092\u53c2\u7167\u3057\u3066\u304f\u3060\u3055\u3044\u3002\n>>> import numpy as np\n>>> from sklearn.metrics import roc_auc_score\n>>> y_true = np.array([0, 0, 1, 1])\n>>> y_scores = np.array([0.1, 0.4, 0.35, 0.8])\n>>> roc_auc_score(y_true, y_scores)\n0.75\n\n\u30de\u30eb\u30c1\u30e9\u30d9\u30eb\u5206\u985e\u3067\u306f\u3001\u4e0a\u8a18\u306e\u3088\u3046\u306b\u30e9\u30d9\u30eb\u3092\u5e73\u5747\u5316\u3059\u308b\u3053\u3068\u306b\u3088\u3063\u3066roc_auc_score\u95a2\u6570\u304c\u62e1\u5f35\u3055\u308c\u307e\u3059\u3002\n\u30b5\u30d6\u30bb\u30c3\u30c8\u7cbe\u5ea6\u3001\u30cf\u30df\u30f3\u30b0\u640d\u5931\u3001F1\u30b9\u30b3\u30a2\u306a\u3069\u306e\u30e1\u30c8\u30ea\u30c3\u30af\u3068\u6bd4\u8f03\u3057\u3066\u3001ROC\u3067\u306f\u5404\u30e9\u30d9\u30eb\u306e\u3057\u304d\u3044\u5024\u3092\u6700\u9069\u5316\u3059\u308b\u5fc5\u8981\u306f\u3042\u308a\u307e\u305b\u3093\u3002 \u4e88\u6e2c\u3055\u308c\u305f\u51fa\u529b\u304c2\u9032\u5316\u3055\u308c\u3066\u3044\u308b\u5834\u5408\u3001roc_auc_score\u95a2\u6570\u3092\u30de\u30eb\u30c1\u30af\u30e9\u30b9\u5206\u985e\u3067\u4f7f\u7528\u3059\u308b\u3053\u3068\u3082\u3067\u304d\u307e\u3059\u3002\n\n\n\u4f8b\uff1a\n\n\nROC\u3092\u4f7f\u7528\u3057\u3066\u5206\u985e\u5668\u306e\u51fa\u529b\u306e\u54c1\u8cea\u3092\u8a55\u4fa1\u3059\u308b\u4f8b\u306b\u3064\u3044\u3066\u306f\u3001\u53d7\u4fe1\u8005\u52d5\u4f5c\u7279\u6027\uff08ROC\uff09 \u3092\u53c2\u7167\u3057\u3066\u304f\u3060\u3055\u3044\u3002\n\u30af\u30ed\u30b9\u30d0\u30ea\u30c7\u30fc\u30b7\u30e7\u30f3\u3092\u4f7f\u7528\u3057\u3066\u3001\u5206\u985e\u5b50\u306e\u51fa\u529b\u54c1\u8cea\u3092\u8a55\u4fa1\u3059\u308b\u305f\u3081\u306eROC\u306e\u4f7f\u7528\u4f8b\u306b\u3064\u3044\u3066\u306f\u3001\u76f8\u4e92\u691c\u8a3c\u306b\u3088\u308b\u53d7\u4fe1\u8005\u52d5\u4f5c\u7279\u6027\uff08ROC\uff09 \u3092\u53c2\u7167\u3057\u3066\u304f\u3060\u3055\u3044\u3002\n\u7a2e\u306e\u5206\u5e03\u3092\u30e2\u30c7\u30eb\u5316\u3059\u308b\u305f\u3081\u306eROC\u306e\u4f7f\u7528\u4f8b\u306b\u3064\u3044\u3066\u306f\u3001\u7a2e\u306e\u5206\u5e03\u30e2\u30c7\u30eb \u3092\u53c2\u7167\u3057\u3066\u304f\u3060\u3055\u3044\u3002\n\n\n\n\n3.3.2.13. 0-1\u640d\u5931\nzero_one_loss \u95a2\u6570\u306f\u3001$n_{\\text{samples}}$ \u306b\u5bfe\u3059\u308b0-1\u5206\u985e\u640d\u5931 $ (L_{0-1})$ \u306e\u548c\u307e\u305f\u306f\u5e73\u5747\u3092\u8a08\u7b97\u3057\u307e\u3059\u3002 \u30c7\u30d5\u30a9\u30eb\u30c8\u3067\u306f\u3001\u95a2\u6570\u306f\u30b5\u30f3\u30d7\u30eb\u306b\u5bfe\u3057\u3066\u6b63\u898f\u5316\u3055\u308c\u307e\u3059\u3002 $ L_{0-1}$ \u306e\u548c\u3092\u6c42\u3081\u308b\u306b\u306f\u3001normalize \u3092 False \u306b\u8a2d\u5b9a\u3057\u307e\u3059\u3002\n\u30de\u30eb\u30c1\u30e9\u30d9\u30eb\u5206\u985e\u3067\u306f\u3001 zero_one_loss \u306f\u3001\u305d\u306e\u30e9\u30d9\u30eb\u304c\u4e88\u6e2c\u3068\u53b3\u5bc6\u306b\u4e00\u81f4\u3059\u308b\u5834\u5408\u306b\u306f\u30b5\u30d6\u30bb\u30c3\u30c8\u30921\u3068\u3057\u3066\u30b9\u30b3\u30a2\u4ed8\u3051\u3057\u3001\u30a8\u30e9\u30fc\u304c\u3042\u308b\u5834\u5408\u306b\u306f\u30bc\u30ed\u3068\u3057\u3066\u30b9\u30b3\u30a2\u4ed8\u3051\u3057\u307e\u3059\u3002 \u30c7\u30d5\u30a9\u30eb\u30c8\u3067\u306f\u3001\u3053\u306e\u95a2\u6570\u306f\u4e0d\u5b8c\u5168\u306b\u4e88\u6e2c\u3055\u308c\u305f\u30b5\u30d6\u30bb\u30c3\u30c8\u306e\u5272\u5408\u3092\u8fd4\u3057\u307e\u3059\u3002 \u305d\u306e\u3088\u3046\u306a\u30b5\u30d6\u30bb\u30c3\u30c8\u306e\u6570\u3092\u4ee3\u308f\u308a\u306b\u53d6\u5f97\u3059\u308b\u306b\u306f\u3001normalize \u3092 False \u306b\u8a2d\u5b9a\u3057\u307e\u3059\n$\\hat {y} i$ \u304c $i$ \u756a\u76ee\u306e\u30b5\u30f3\u30d7\u30eb\u306e\u4e88\u6e2c\u5024\u3067\u3042\u308a\u3001 $y_i$ \u304c\u5bfe\u5fdc\u3059\u308b\u771f\u306e\u5024\u3067\u3042\u308b\u5834\u5408\u30010-1\u640d\u5931 $L {0-1}$ \u306f\u6b21\u306e\u3088\u3046\u306b\u5b9a\u7fa9\u3055\u308c\u307e\u3059\u3002\nL_{0-1}(y_i, \\hat{y}_i) = 1(\\hat{y}_i \\not= y_i)\n\n\u3053\u3053\u3067\u3001 $1(x)$ \u306f\u6307\u6a19\u95a2\u6570\u3067\u3059\u3002\n>>> from sklearn.metrics import zero_one_loss\n>>> y_pred = [1, 2, 3, 4]\n>>> y_true = [2, 2, 3, 4]\n>>> zero_one_loss(y_true, y_pred)\n0.25\n>>> zero_one_loss(y_true, y_pred, normalize=False)\n1\n\n\u30d0\u30a4\u30ca\u30ea\u30e9\u30d9\u30eb\u30a4\u30f3\u30b8\u30b1\u30fc\u30bf\u3092\u6301\u3064\u30de\u30eb\u30c1\u30e9\u30d9\u30eb\u306e\u5834\u5408\u3001\u6700\u521d\u306e\u30e9\u30d9\u30eb\u30bb\u30c3\u30c8[0,1]\u306b\u30a8\u30e9\u30fc\u304c\u3042\u308a\u307e\u3059\u3002\n>>>\n>>> zero_one_loss(np.array([[0, 1], [1, 1]]), np.ones((2, 2)))\n0.5\n\n>>> zero_one_loss(np.array([[0, 1], [1, 1]]), np.ones((2, 2)),  normalize=False)\n1\n\n\n\u4f8b\uff1a\n\n\n\u30af\u30ed\u30b9\u30d0\u30ea\u30c7\u30fc\u30b7\u30e7\u30f3\u3092\u4f7f\u7528\u3057\u3066\u518d\u5e30\u7684\u306a\u7279\u5fb4\u3092\u524a\u9664\u3059\u308b\u305f\u3081\u306e\u640d\u5931\u640d\u5931\u3092\u30bc\u30ed\u306b\u3059\u308b\u4f8b\u306b\u3064\u3044\u3066\u306f\u3001\u30af\u30ed\u30b9\u691c\u8a3c\u306b\u3088\u308b\u518d\u5e30\u7684\u306a\u7279\u5fb4\u524a\u9664 \u3092\u53c2\u7167\u3057\u3066\u304f\u3060\u3055\u3044\u3002\n\n\n\n\n3.3.2.14. Brier\u30b9\u30b3\u30a2\u640d\u5931\nbrier_score_loss \u95a2\u6570\u306f\u3001\u30d0\u30a4\u30ca\u30ea\u30af\u30e9\u30b9\u306e Brier\u30b9\u30b3\u30a2 \u3092\u8a08\u7b97\u3057\u307e\u3059\u3002\u5f15\u7528Wikipedia\uff1a\n\nBrier\u30b9\u30b3\u30a2\u306f\u3001\u78ba\u7387\u7684\u4e88\u6e2c\u306e\u7cbe\u5ea6\u3092\u6e2c\u5b9a\u3059\u308b\u9069\u5207\u306a\u30b9\u30b3\u30a2\u95a2\u6570\u3067\u3059\u3002\u4e88\u6e2c\u304c\u76f8\u4e92\u6392\u4ed6\u7684\u96e2\u6563\u7d50\u679c\u306e\u96c6\u5408\u306b\u78ba\u7387\u3092\u5272\u308a\u5f53\u3066\u308b\u5fc5\u8981\u304c\u3042\u308b\u30bf\u30b9\u30af\u306b\u9069\u7528\u3067\u304d\u307e\u3059\u3002\n\n\u3053\u306e\u95a2\u6570\u306f\u3001\u5b9f\u969b\u306e\u7d50\u679c\u3068\u53ef\u80fd\u306a\u7d50\u679c\u306e\u4e88\u6e2c\u3055\u308c\u308b\u78ba\u7387\u3068\u306e\u9593\u306e\u5e73\u5747\u4e8c\u4e57\u5dee\u306e\u30b9\u30b3\u30a2\u3092\u8fd4\u3057\u307e\u3059\u3002\u5b9f\u969b\u306e\u7d50\u679c\u306f1\u307e\u305f\u306f0\uff08\u771f\u307e\u305f\u306f\u507d\uff09\u3067\u3042\u308b\u5fc5\u8981\u304c\u3042\u308a\u307e\u3059\u304c\u3001\u5b9f\u969b\u306e\u7d50\u679c\u306e\u4e88\u6e2c\u78ba\u7387\u306f0\u30681\u306e\u9593\u306e\u5024\u306b\u306a\u308a\u307e\u3059\u3002\nbrier\u30b9\u30b3\u30a2\u306e\u640d\u5931\u30820\u301c1\u3067\u3042\u308a\u3001\u30b9\u30b3\u30a2\u304c\u4f4e\u3044\u307b\u3069\uff08\u5e73\u5747\u5e73\u65b9\u5dee\u304c\u5c0f\u3055\u3044\u307b\u3069\uff09\u3001\u4e88\u6e2c\u304c\u3088\u308a\u6b63\u78ba\u3067\u3042\u308b\u3002\u3053\u308c\u306f\u3001\u78ba\u7387\u7684\u4e88\u6e2c\u306e\u30bb\u30c3\u30c8\u306e\u300c\u5c04\u7a0b\u8ddd\u96e2\u6e2c\u5b9a\u300d\u306e\u5c3a\u5ea6\u3068\u8003\u3048\u308b\u3053\u3068\u304c\u3067\u304d\u308b\u3002\nBS = \\frac{1}{N} \\sum_{t=1}^{N}(f_t - o_t)^2\n\n\u3053\u3053\u3067\u3001 $N$ \u306f\u4e88\u6e2c\u306e\u7dcf\u6570\u3067\u3042\u308a\u3001 $f_t$ \u306f\u5b9f\u969b\u306e\u7d50\u679c $o_t$ \u306e\u4e88\u6e2c\u3055\u308c\u308b\u78ba\u7387\u3067\u3042\u308b\u3002\n\u3053\u306e\u95a2\u6570\u306e\u4f7f\u3044\u65b9\u306e\u5c0f\u3055\u306a\u4f8b\u3092\u6b21\u306b\u793a\u3057\u307e\u3059::\n>>> import numpy as np\n>>> from sklearn.metrics import brier_score_loss\n>>> y_true = np.array([0, 1, 1, 0])\n>>> y_true_categorical = np.array([\"spam\", \"ham\", \"ham\", \"spam\"])\n>>> y_prob = np.array([0.1, 0.9, 0.8, 0.4])\n>>> y_pred = np.array([0, 1, 1, 0])\n>>> brier_score_loss(y_true, y_prob)\n0.055\n>>> brier_score_loss(y_true, 1-y_prob, pos_label=0)\n0.055\n>>> brier_score_loss(y_true_categorical, y_prob, pos_label=\"ham\")\n0.055\n>>> brier_score_loss(y_true, y_prob > 0.5)\n0.0\n\n\n\u4f8b\uff1a\n\n\n\u5206\u985e\u5668\u306e\u78ba\u7387\u5c04\u7a0b\u8ddd\u96e2\u6e2c\u5b9a\u3092\u5b9f\u884c\u3059\u308b\u305f\u3081\u306eBrier\u30b9\u30b3\u30a2\u640d\u5931\u306e\u4f7f\u7528\u4f8b\u306b\u3064\u3044\u3066\u306f\u3001\u5206\u985e\u5668\u306e\u78ba\u7387\u5c04\u7a0b\u8ddd\u96e2\u6e2c\u5b9a\u3092\u53c2\u7167\u3057\u3066\u304f\u3060\u3055\u3044\u3002\n\n\n\u53c2\u8003\u6587\u732e\uff1a\n\n\nG. Brier\u3001\u78ba\u7387\u7684\u306b\u8868\u73fe\u3055\u308c\u305f\u4e88\u6e2c\u306e\u691c\u8a3c \u3001\u6bce\u6708\u306e\u6c17\u8c61\u8a55\u4fa178.1\uff081950\uff09\n\n\n\n\n3.3.3. \u30de\u30eb\u30c1\u30e9\u30d9\u30eb\u30e9\u30f3\u30ad\u30f3\u30b0\u30e1\u30c8\u30ea\u30c3\u30af\n\u30de\u30eb\u30c1\u30e9\u30d9\u30eb\u5b66\u7fd2\u3067\u306f\u3001\u5404\u30b5\u30f3\u30d7\u30eb\u306b\u306f\u3001\u305d\u308c\u306b\u95a2\u9023\u3059\u308b\u30b0\u30e9\u30a6\u30f3\u30c9\u30fb\u30c8\u30a5\u30eb\u30fc\u30fb\u30e9\u30d9\u30eb\u3092\u3044\u304f\u3064\u3067\u3082\u6301\u3064\u3053\u3068\u304c\u3067\u304d\u307e\u3059\u3002\u30b4\u30fc\u30eb\u306f\u9ad8\u3044\u5f97\u70b9\u3092\u4e0e\u3048\u3001\u5730\u4e0a\u306e\u771f\u7406\u5024\u672d\u306b\u30e9\u30f3\u30af\u4ed8\u3051\u3059\u308b\u3053\u3068\u3067\u3059\u3002\n\n3.3.3.1. \u30ab\u30d0\u30ec\u30c3\u30b8\u30a8\u30e9\u30fc\ncoverage_error \u95a2\u6570\u306f\u3001\u5168\u3066\u306e\u771f\u306e\u30e9\u30d9\u30eb\u304c\u4e88\u6e2c\u3055\u308c\u308b\u3088\u3046\u306b\u3001\u6700\u7d42\u7684\u306a\u4e88\u6e2c\u306b\u542b\u307e\u308c\u306a\u3051\u308c\u3070\u306a\u3089\u306a\u3044\u30e9\u30d9\u30eb\u306e\u5e73\u5747\u6570\u3092\u8a08\u7b97\u3059\u308b\u3002\u3053\u308c\u306f\u3001\u771f\u306e\u5024\u3092\u5931\u308f\u305a\u306b\u5e73\u5747\u3067\u4e88\u6e2c\u3057\u306a\u3051\u308c\u3070\u306a\u3089\u306a\u3044\u30c8\u30c3\u30d7\u30b9\u30b3\u30a2\u30e9\u30d9\u30eb\u306e\u6570\u3092\u77e5\u308a\u305f\u3044\u5834\u5408\u306b\u4fbf\u5229\u3067\u3059\u3002\u3057\u305f\u304c\u3063\u3066\u3001\u3053\u306e\u30e1\u30c8\u30ea\u30c3\u30af\u306e\u6700\u826f\u306e\u5024\u306f\u3001\u771f\u306e\u30e9\u30d9\u30eb\u306e\u5e73\u5747\u6570\u3067\u3059\u3002\n\u516c\u5f0f\u306b\u306f\u3001\u30b0\u30e9\u30a6\u30f3\u30c9\u30c8\u30a5\u30eb\u30fc\u30b9\u30e9\u30d9\u30eb  \u306e2\u9032\u30a4\u30f3\u30b8\u30b1\u30fc\u30bf\u884c\u5217\u3068\u5404\u30e9\u30d9\u30eb    \u306b\u95a2\u9023\u4ed8\u3051\u3089\u308c\u305f\u30b9\u30b3\u30a2\u304c\u4e0e\u3048\u3089\u308c\u308b\u3068\u3001\u30ab\u30d0\u30ec\u30c3\u30b8\u306f\u4ee5\u4e0b\u306e\u3088\u3046\u306b\u5b9a\u7fa9\u3055\u308c\u308b\u3002\n\u516c\u5f0f\u306b\u306f\u3001\u30b0\u30e9\u30a6\u30f3\u30c9\u30c8\u30a5\u30eb\u30fc\u30b9\u30e9\u30d9\u30eb $ y \\in \\left\\{0, 1\\right\\}^{n_\\text{samples} \\times n_\\text{labels}}$ \u306e2\u9032\u30a4\u30f3\u30b8\u30b1\u30fc\u30bf\u884c\u5217\u3068\u5404\u30e9\u30d9\u30eb $\\hat{f} \\in \\mathbb{R}^{n_\\text{samples} \\times n_\\text{labels}}$ \u306b\u95a2\u9023\u4ed8\u3051\u3089\u308c\u305f\u30b9\u30b3\u30a2\u304c\u4e0e\u3048\u3089\u308c\u308b\u3068\u3001\u30ab\u30d0\u30ec\u30c3\u30b8\u306f\ncoverage(y, \\hat{f}) = \\frac{1}{n_{\\text{samples}}}\n  \\sum_{i=0}^{n_{\\text{samples}} - 1} \\max_{j:y_{ij} = 1} \\text{rank}_{ij}\n\n\u3067 $\\text{rank}_{ij} = \\left|\\left\\{k: \\hat{f}_{ik} \\geq \\hat{f}_{ij} \\right\\}\\right|$ \u3068\u5b9a\u7fa9\u3055\u308c\u307e\u3059\u3002 \u30e9\u30f3\u30af\u306e\u5b9a\u7fa9\u304c\u4e0e\u3048\u3089\u308c\u308b\u3068\u3001y_scores\u306e\u7d50\u3073\u3064\u304d\u306f\u3001\u3059\u3079\u3066\u306e\u7d50\u3073\u4ed8\u3051\u3089\u308c\u305f\u5024\u306b\u5272\u308a\u5f53\u3066\u3089\u308c\u308b\u6700\u5927\u30e9\u30f3\u30af\u3092\u4e0e\u3048\u308b\u3053\u3068\u306b\u3088\u3063\u3066\u58ca\u3055\u308c\u307e\u3059\u3002\n\u3053\u306e\u95a2\u6570\u306e\u4f7f\u3044\u65b9\u306e\u5c0f\u3055\u306a\u4f8b\u3092\u6b21\u306b\u793a\u3057\u307e\u3059::\n>>> import numpy as np\n>>> from sklearn.metrics import coverage_error\n>>> y_true = np.array([[1, 0, 0], [0, 0, 1]])\n>>> y_score = np.array([[0.75, 0.5, 1], [1, 0.2, 0.1]])\n>>> coverage_error(y_true, y_score)\n2.5\n\n\n3.3.3.2. \u30e9\u30d9\u30eb\u30e9\u30f3\u30af\u306e\u5e73\u5747\u9069\u5408\u7387\nlabel_ranking_average_precision_score \u95a2\u6570\u306f\u3001\u30e9\u30d9\u30eb\u30e9\u30f3\u30af\u5e73\u5747\u9069\u5408\u7387\uff08LRAP\uff09\u3092\u5b9f\u88c5\u3057\u307e\u3059\u3002\u3053\u306e\u30e1\u30c8\u30ea\u30c3\u30af\u306f average_precision_score \u95a2\u6570\u306b\u30ea\u30f3\u30af\u3055\u308c\u3066\u3044\u307e\u3059\u304c\u3001\u9069\u5408\u7387\u3068\u518d\u73fe\u7387\u306e\u4ee3\u308f\u308a\u306b\u30e9\u30d9\u30eb\u306e\u30e9\u30f3\u30af\u4ed8\u3051\u306e\u6982\u5ff5\u306b\u57fa\u3065\u3044\u3066\u3044\u307e\u3059\u3002\n\u30e9\u30d9\u30eb\u30e9\u30f3\u30af\u5e73\u5747\u7cbe\u5ea6\uff08LRAP\uff09\u306f\u3001\u5404\u30b5\u30f3\u30d7\u30eb\u306b\u5272\u308a\u5f53\u3066\u3089\u308c\u305f\u5404\u30b0\u30e9\u30f3\u30c9\u30fb\u30c8\u30a5\u30eb\u30fc\u30b9\u30fb\u30e9\u30d9\u30eb\u306e\u5e73\u5747\u5024\u3067\u3042\u308a\u3001\u30b9\u30b3\u30a2\u306e\u4f4e\u3044\u771f\u306e\u30e9\u30d9\u30eb\u3068\u7dcf\u30e9\u30d9\u30eb\u306e\u6bd4\u7387\u3067\u3059\u3002\u3053\u306e\u30e1\u30c8\u30ea\u30c3\u30af\u306f\u3001\u5404\u30b5\u30f3\u30d7\u30eb\u306b\u95a2\u9023\u4ed8\u3051\u3089\u308c\u305f\u30e9\u30d9\u30eb\u306e\u30e9\u30f3\u30af\u3092\u4e0a\u3052\u308b\u3053\u3068\u304c\u3067\u304d\u308c\u3070\u3001\u30b9\u30b3\u30a2\u304c\u5411\u4e0a\u3057\u307e\u3059\u3002\u5f97\u3089\u308c\u305f\u30b9\u30b3\u30a2\u306f\u5e38\u306b\u53b3\u5bc6\u306b0\u3088\u308a\u5927\u304d\u304f\u3001\u6700\u826f\u306e\u5024\u306f1\u3067\u3059\u3002\u30b5\u30f3\u30d7\u30eb\u3042\u305f\u308a1\u3064\u306e\u95a2\u9023\u30e9\u30d9\u30eb\u304c\u6b63\u78ba\u306b\u3042\u308b\u5834\u5408\u3001\u30e9\u30d9\u30eb\u30e9\u30f3\u30ad\u30f3\u30b0\u5e73\u5747\u9069\u5408\u7387\u306f \u5e73\u5747\u9006\u6570\u30e9\u30f3\u30af \u306b\u76f8\u5f53\u3057\u307e\u3059\u3002\n\u6b63\u5f0f\u306b\u306f\u3001\u5730\u4e0a\u306e\u771f\u7406\u5024\u8868\u306e\u4e8c\u9805\u76ee\u306e\u6307\u6a19\u884c\u5217 $\\mathcal {R} ^ {n_ \\text {samples} \\times n_ \\text{labels}}$ \u3068\u5404\u30e9\u30d9\u30eb $\\hat {f} \\ \\mathcal {R} ^ {n_ \\ text {samples} \\ times n_ \\text {labels}}$ \u3067\u306f\u3001\u5e73\u5747\u7cbe\u5ea6\u306f\u6b21\u306e\u3088\u3046\u306b\u5b9a\u7fa9\u3055\u308c\u307e\u3059\u3002\nLRAP(y, \\hat{f}) = \\frac{1}{n_{\\text{samples}}}\n  \\sum_{i=0}^{n_{\\text{samples}} - 1} \\frac{1}{|y_i|}\n  \\sum_{j:y_{ij} = 1} \\frac{|\\mathcal{L}_{ij}|}{\\text{rank}_{ij}}\n\n$\\mathcal{L}_{ij} = \\left\\{k: y_{ik} = 1, \\hat{f}_{ik} \\geq \\hat{f}_{ij} \\right\\}$,  $\\text{rank}_{ij} = \\left|\\left\\{k: \\hat{f}_{ik} \\geq \\hat{f}_{ij} \\right\\}\\right| $ \u305d\u3057\u3066  $|\\cdot|$ \u304c l0\u30ce\u30eb\u30e0\u307e\u305f\u306f\u30bb\u30c3\u30c8\u306e\u57fa\u6570\u3067\u3042\u308b\u3002\n\u3053\u306e\u95a2\u6570\u306e\u4f7f\u7528\u4f8b\u3092\u4ee5\u4e0b\u306b\u793a\u3057\u307e\u3059\u3002\n>>> import numpy as np\n>>> from sklearn.metrics import label_ranking_average_precision_score\n>>> y_true = np.array([[1, 0, 0], [0, 0, 1]])\n>>> y_score = np.array([[0.75, 0.5, 1], [1, 0.2, 0.1]])\n>>> label_ranking_average_precision_score(y_true, y_score) \n0.416...\n\n\n3.3.3.3. \u30e9\u30f3\u30ad\u30f3\u30b0\u640d\u5931\nlabel_ranking_loss \u95a2\u6570\u306f\u3001\u8aa4\u3063\u3066\u9806\u5e8f\u3065\u3051\u3089\u308c\u305f\u30e9\u30d9\u30eb\u30da\u30a2\u306e\u6570\u3001\u3059\u306a\u308f\u3061\u771f\u306e\u30e9\u30d9\u30eb\u304c\u507d\u306e\u30e9\u30d9\u30eb\u3088\u308a\u3082\u30b9\u30b3\u30a2\u304c\u4f4e\u304f\u3001\u507d\u306e\u30e9\u30d9\u30eb\u3068\u771f\u306e\u30e9\u30d9\u30eb\u306e\u9006\u6570\u3067\u91cd\u307f\u4ed8\u3051\u3055\u308c\u305f\u30e9\u30d9\u30eb\u306e\u30da\u30a2\u306e\u6570\u3092\u5e73\u5747\u3059\u308b\u30e9\u30f3\u30ad\u30f3\u30b0\u640d\u5931\u3092\u8a08\u7b97\u3059\u308b\u3002\u9054\u6210\u53ef\u80fd\u306a\u6700\u4f4e\u30e9\u30f3\u30ad\u30f3\u30b0\u640d\u5931\u306f\u30bc\u30ed\u3067\u3059\u3002\n\u516c\u5f0f\u306f\u3001\u5730\u9762\u771f\u7406\u30e9\u30d9\u30eb $ y \\in \\left\\{0, 1\\right\\}^{n_\\text{samples} \\times n_\\text{labels}}$ \u306e2\u9032\u30a4\u30f3\u30b8\u30b1\u30fc\u30bf\u884c\u5217\u3068\u5404\u30e9\u30d9\u30eb $ \\hat{f} \\in \\mathbb{R}^{n_\\text{samples} \\times n_\\text{labels}}$ \u306b\u95a2\u9023\u4ed8\u3051\u3089\u308c\u305f\u30b9\u30b3\u30a2\u304c\u4e0e\u3048\u3089\u308c\u305f\u5834\u5408\u3001\u30e9\u30f3\u30ad\u30f3\u30b0\u640d\u5931\u306f\n\\text{ranking\\_loss}(y, \\hat{f}) =  \\frac{1}{n_{\\text{samples}}}\n  \\sum_{i=0}^{n_{\\text{samples}} - 1} \\frac{1}{|y_i|(n_\\text{labels} - |y_i|)}\n  \\left|\\left\\{(k, l): \\hat{f}_{ik} < \\hat{f}_{il}, y_{ik} = 1, y_{il} = 0 \\right\\}\\right|\n\n\u3053\u3053\u3067\u3001$ |\\cdot| $ \u306f\u3001 $ \\ell_0$ \u30ce\u30eb\u30e0\u307e\u305f\u306f\u96c6\u5408\u306e\u57fa\u6570\u3067\u3042\u308b\u3002\n\u3053\u306e\u95a2\u6570\u306e\u4f7f\u7528\u4f8b\u3092\u4ee5\u4e0b\u306b\u793a\u3057\u307e\u3059\u3002\n>>> import numpy as np\n>>> from sklearn.metrics import label_ranking_loss\n>>> y_true = np.array([[1, 0, 0], [0, 0, 1]])\n>>> y_score = np.array([[0.75, 0.5, 1], [1, 0.2, 0.1]])\n>>> label_ranking_loss(y_true, y_score) \n0.75...\n>>> # With the following prediction, we have perfect and minimal loss\n>>> y_score = np.array([[1.0, 0.1, 0.2], [0.1, 0.2, 0.9]])\n>>> label_ranking_loss(y_true, y_score)\n0.0\n\n\n3.3.4. \u56de\u5e30\u30e1\u30c8\u30ea\u30c3\u30af\nsklearn.metrics \u30e2\u30b8\u30e5\u30fc\u30eb\u306f\u3001\u56de\u5e30\u306e\u30d1\u30d5\u30a9\u30fc\u30de\u30f3\u30b9\u3092\u6e2c\u5b9a\u3059\u308b\u305f\u3081\u306e\u3044\u304f\u3064\u304b\u306e\u640d\u5931\u3001\u30b9\u30b3\u30a2\u3001\u304a\u3088\u3073\u30e6\u30fc\u30c6\u30a3\u30ea\u30c6\u30a3\u95a2\u6570\u3092\u5b9f\u88c5\u3057\u3066\u3044\u307e\u3059\u3002 mean_squared_error\u3001mean_absolute_error\u3001explain_variance_score\u3001\u304a\u3088\u3073 r2_score \u306e\u3088\u3046\u306b\u3001\u8907\u6570\u51fa\u529b\u306e\u5834\u5408\u3092\u51e6\u7406\u3059\u308b\u3088\u3046\u306b\u62e1\u5f35\u3055\u308c\u3066\u3044\u308b\u3082\u306e\u304c\u3042\u308a\u307e\u3059\u3002\n\u3053\u308c\u3089\u306e\u95a2\u6570\u306b\u306f\u3001\u500b\u3005\u306e\u30bf\u30fc\u30b2\u30c3\u30c8\u306e\u30b9\u30b3\u30a2\u307e\u305f\u306f\u640d\u5931\u3092\u5e73\u5747\u3059\u308b\u65b9\u6cd5\u3092\u6307\u5b9a\u3059\u308b multioutput\u30ad\u30fc\u30ef\u30fc\u30c9\u5f15\u6570\u304c\u3042\u308a\u307e\u3059\u3002\u30c7\u30d5\u30a9\u30eb\u30c8\u306f 'uniform_average' \u3067\u3059\u3002\u3053\u308c\u306f\u3001\u51fa\u529b\u306b\u5bfe\u3057\u3066\u5747\u4e00\u306b\u91cd\u307f\u4ed8\u3051\u3055\u308c\u305f\u5e73\u5747\u3092\u6307\u5b9a\u3057\u307e\u3059\u3002\u30b7\u30a7\u30a4\u30d7\u304c \uff08n_outputs\u3001\uff09 \u306e ndarray \u304c\u6e21\u3055\u308c\u305f\u5834\u5408\u3001\u305d\u306e\u30a8\u30f3\u30c8\u30ea\u306f\u91cd\u307f\u3068\u3057\u3066\u89e3\u91c8\u3055\u308c\u3001\u305d\u308c\u306b\u5fdc\u3058\u305f\u52a0\u91cd\u5e73\u5747\u304c\u8fd4\u3055\u308c\u307e\u3059\u3002 multioutput \u304c 'raw_values' \u306e\u5834\u5408\u3001\u5909\u66f4\u3055\u308c\u3066\u3044\u306a\u3044\u500b\u3005\u306e\u30b9\u30b3\u30a2\u3084\u640d\u5931\u306f\u3059\u3079\u3066\u30b7\u30a7\u30a4\u30d7(n_outputs,) \u306e\u914d\u5217 \u3067\u8fd4\u3055\u308c\u307e\u3059\u3002\nr2_score \u3068 explain_variance_score \u306f\u3001multioutput \u30d1\u30e9\u30e1\u30fc\u30bf\u306b\u5bfe\u3057\u3066\u8ffd\u52a0\u306e\u5024 'variance_weighted' \u3092\u53d7\u3051\u5165\u308c\u307e\u3059\u3002\u3053\u306e\u30aa\u30d7\u30b7\u30e7\u30f3\u306f\u3001\u5bfe\u5fdc\u3059\u308b\u30bf\u30fc\u30b2\u30c3\u30c8\u5909\u6570\u306e\u5206\u6563\u306b\u3088\u308b\u500b\u3005\u306e\u30b9\u30b3\u30a2\u306e\u91cd\u307f\u4ed8\u3051\u306b\u3064\u306a\u304c\u308a\u307e\u3059\u3002\u3053\u306e\u8a2d\u5b9a\u306f\u3001\u30b0\u30ed\u30fc\u30d0\u30eb\u306b\u30ad\u30e3\u30d7\u30c1\u30e3\u3055\u308c\u305f\u30b9\u30b1\u30fc\u30ea\u30f3\u30b0\u3055\u308c\u3066\u3044\u306a\u3044\u5206\u6563\u3092\u5b9a\u91cf\u5316\u3057\u307e\u3059\u3002\u76ee\u6a19\u5909\u6570\u306e\u30b9\u30b1\u30fc\u30eb\u304c\u7570\u306a\u308b\u5834\u5408\u3001\u3053\u306e\u30b9\u30b3\u30a2\u306f\u5206\u6563\u5909\u6570\u304c\u9ad8\u3044\u3053\u3068\u3092\u3088\u304f\u8aac\u660e\u3059\u308b\u4e0a\u3067\u91cd\u8981\u3067\u3059\u3002 multioutput = 'variance_weighted' \u306f\u4e0b\u4f4d\u4e92\u63db\u6027\u306e\u305f\u3081\u306br2_score\u306e\u30c7\u30d5\u30a9\u30eb\u30c8\u5024\u3067\u3059\u3002\u3053\u308c\u306f\u5c06\u6765\u3001'uniform_average' \u306b\u5909\u66f4\u3055\u308c\u307e\u3059\u3002\n\n3.3.4.1. \u8aac\u660e\u5909\u6570\u30b9\u30b3\u30a2\nexplain_variance_score\u306f\u3001\u8aac\u660e\u5909\u6570\u56de\u5e30\u30b9\u30b3\u30a2 \u3092\u8a08\u7b97\u3057\u307e\u3059\u3002\n$\\hat {y}$ \u304c\u63a8\u5b9a\u3055\u308c\u305f\u76ee\u6a19\u51fa\u529b\u3067\u3042\u308a\u3001 $y$ \u304c\u5bfe\u5fdc\u3059\u308b\uff08\u6b63\u3057\u3044\uff09\u76ee\u6a19\u51fa\u529b\u3067\u3042\u308a\u3001 $Var$ \u304c\u6a19\u6e96\u504f\u5dee\u306e2\u4e57\u3067\u3042\u308b\u5206\u6563\u3067\u3042\u308b\u5834\u5408\u3001\u8aac\u660e\u5909\u6570\u306f\u6b21\u306e\u3088\u3046\u306b\u63a8\u5b9a\u3055\u308c\u308b\u3002\n\\texttt{explained_variance}(y, \\hat{y}) = 1 - \\frac{Var\\{ y - \\hat{y}\\}}{Var\\{y\\}}\n\n\u6700\u9ad8\u5f97\u70b9\u306f1.0\u3067\u3001\u5024\u304c\u4f4e\u3044\u307b\u3069\u60aa\u3044\u3067\u3059\u3002\n\u6b21\u306b\u3001explain_variance_score\u95a2\u6570\u306e\u4f7f\u7528\u4f8b\u3092\u793a\u3057\u307e\u3059\u3002\n>>> from sklearn.metrics import explained_variance_score\n>>> y_true = [3, -0.5, 2, 7]\n>>> y_pred = [2.5, 0.0, 2, 8]\n>>> explained_variance_score(y_true, y_pred)  \n0.957...\n>>> y_true = [[0.5, 1], [-1, 1], [7, -6]]\n>>> y_pred = [[0, 2], [-1, 2], [8, -5]]\n>>> explained_variance_score(y_true, y_pred, multioutput='raw_values')\n... \narray([ 0.967...,  1.        ])\n>>> explained_variance_score(y_true, y_pred, multioutput=[0.3, 0.7])\n... \n0.990...\n\n\n3.3.4.2. \u5e73\u5747\u7d76\u5bfe\u8aa4\u5dee\nmean_absolute_error \u95a2\u6570\u306f\u3001\u5e73\u5747\u7d76\u5bfe\u8aa4\u5dee\u3001\u7d76\u5bfe\u8aa4\u5dee\u640d\u5931\u307e\u305f\u306f $l1$ \u30ce\u30eb\u30e0\u640d\u5931\u306e\u671f\u5f85\u5024\u306b\u5bfe\u5fdc\u3059\u308b\u30ea\u30b9\u30af\u30e1\u30c8\u30ea\u30c3\u30af\u3092\u8a08\u7b97\u3057\u307e\u3059\u3002\n$\\hat {y} _i$ \u304c $i$ \u756a\u76ee\u306e\u30b5\u30f3\u30d7\u30eb\u306e\u4e88\u6e2c\u5024\u3067\u3042\u308a\u3001 $y_i$ \u304c\u5bfe\u5fdc\u3059\u308b\u771f\u306e\u5024\u3067\u3042\u308b\u5834\u5408\u3001$ n_{\\text{samples}}$ \u3067\u63a8\u5b9a\u3055\u308c\u305f\u5e73\u5747\u7d76\u5bfe\u8aa4\u5dee\uff08MAE\uff09\u306f\u6b21\u306e\u3088\u3046\u306b\u5b9a\u7fa9\u3055\u308c\u307e\u3059\u3002\n\\text{MAE}(y, \\hat{y}) = \\frac{1}{n_{\\text{samples}}} \\sum_{i=0}^{n_{\\text{samples}}-1} \\left| y_i - \\hat{y}_i \\right|.\n\nmean_absolute_error\u95a2\u6570\u306e\u4f7f\u7528\u4f8b\u3092\u4ee5\u4e0b\u306b\u793a\u3057\u307e\u3059\u3002\n>>> from sklearn.metrics import mean_absolute_error\n>>> y_true = [3, -0.5, 2, 7]\n>>> y_pred = [2.5, 0.0, 2, 8]\n>>> mean_absolute_error(y_true, y_pred)\n0.5\n>>> y_true = [[0.5, 1], [-1, 1], [7, -6]]\n>>> y_pred = [[0, 2], [-1, 2], [8, -5]]\n>>> mean_absolute_error(y_true, y_pred)\n0.75\n>>> mean_absolute_error(y_true, y_pred, multioutput='raw_values')\narray([ 0.5,  1. ])\n>>> mean_absolute_error(y_true, y_pred, multioutput=[0.3, 0.7])\n... \n0.849...\n\n\n3.3.4.3. \u5e73\u5747\u4e8c\u4e57\u8aa4\u5dee\nmean_squared_error \u95a2\u6570\u306f\u3001\u4e8c\u4e57\uff08\u4e8c\u6b21\uff09\u30a8\u30e9\u30fc\u640d\u5931\u307e\u305f\u306f\u640d\u5931\u306e\u671f\u5f85\u5024\u306b\u5bfe\u5fdc\u3059\u308b\u30ea\u30b9\u30af\u30fb\u30e1\u30c8\u30ea\u30c3\u30af\u3067\u3042\u308b \u5e73\u5747\u4e8c\u4e57\u8aa4\u5dee \u3092\u8a08\u7b97\u3057\u307e\u3059\u3002\n$\\hat {y} _i$ \u304c $i$ \u756a\u76ee\u306e\u30b5\u30f3\u30d7\u30eb\u306e\u4e88\u6e2c\u5024\u3067\u3042\u308a\u3001 $y_i$ \u304c\u5bfe\u5fdc\u3059\u308b\u771f\u306e\u5024\u3067\u3042\u308b\u5834\u5408\u3001 $ n_{\\text{samples}}$ \u3067\u63a8\u5b9a\u3055\u308c\u305f\u5e73\u5747\u4e8c\u4e57\u8aa4\u5dee\uff08MSE\uff09\u306f\u6b21\u306e\u3088\u3046\u306b\u5b9a\u7fa9\u3055\u308c\u307e\u3059\u3002\n\\text{MSE}(y, \\hat{y}) = \\frac{1}{n_\\text{samples}} \\sum_{i=0}^{n_\\text{samples} - 1} (y_i - \\hat{y}_i)^2.\n\n\u4ee5\u4e0b\u306b\u3001mean_squared_error\u95a2\u6570\u306e\u4f7f\u7528\u4f8b\u3092\u793a\u3057\u307e\u3059\u3002\n>>> from sklearn.metrics import mean_squared_error\n>>> y_true = [3, -0.5, 2, 7]\n>>> y_pred = [2.5, 0.0, 2, 8]\n>>> mean_squared_error(y_true, y_pred)\n0.375\n>>> y_true = [[0.5, 1], [-1, 1], [7, -6]]\n>>> y_pred = [[0, 2], [-1, 2], [8, -5]]\n>>> mean_squared_error(y_true, y_pred)  \n0.7083...\n\n\n\u4f8b\uff1a\n\n\n\u52fe\u914d\u30d6\u30fc\u30b9\u30c6\u30a3\u30f3\u30b0\u56de\u5e30\u3092\u8a55\u4fa1\u3059\u308b\u305f\u3081\u306e\u4e8c\u4e57\u5e73\u5747\u8aa4\u5dee\u306e\u4f7f\u7528\u4f8b\u306b\u3064\u3044\u3066\u306f\u3001\u52fe\u914d\u30d6\u30fc\u30b9\u30c8\u56de\u5e30 \u3092\u53c2\u7167\u3057\u3066\u304f\u3060\u3055\u3044\u3002\n\n\n\n\n3.3.4.4. \u4e2d\u592e\u7d76\u5bfe\u8aa4\u5dee\nmedian_absolute_error \u306f\u7279\u306b\u7570\u5e38\u5024\u306b\u5bfe\u3057\u3066\u5805\u7262\u3067\u3042\u308b\u305f\u3081\u8208\u5473\u6df1\u3044\u3067\u3059\u3002\u640d\u5931\u306f\u200b\u200b\u3001\u30bf\u30fc\u30b2\u30c3\u30c8\u3068\u4e88\u6e2c\u3068\u306e\u9593\u306e\u3059\u3079\u3066\u306e\u7d76\u5bfe\u5dee\u306e\u4e2d\u592e\u5024\u3092\u53d6\u308b\u3053\u3068\u306b\u3088\u3063\u3066\u8a08\u7b97\u3055\u308c\u308b\u3002\n$\\hat {y} _i$ \u304c $i$ \u756a\u76ee\u306e\u30b5\u30f3\u30d7\u30eb\u306e\u4e88\u6e2c\u5024\u3067\u3042\u308a\u3001 $y_i$ \u304c\u5bfe\u5fdc\u3059\u308b\u771f\u306e\u5024\u3067\u3042\u308b\u5834\u5408\u3001 $ n_{\\text{samples}} $ \u3067\u63a8\u5b9a\u3055\u308c\u305f\u30e1\u30b8\u30a2\u30f3\u7d76\u5bfe\u8aa4\u5dee\uff08MedAE\uff09\u306f\u6b21\u306e\u3088\u3046\u306b\u5b9a\u7fa9\u3055\u308c\u307e\u3059\u3002\n\\text{MedAE}(y, \\hat{y}) = \\text{median}(\\mid y_1 - \\hat{y}_1 \\mid, \\ldots, \\mid y_n - \\hat{y}_n \\mid).\n\nmedian_absolute_error\u306f\u30de\u30eb\u30c1\u51fa\u529b\u3092\u30b5\u30dd\u30fc\u30c8\u3057\u3066\u3044\u307e\u305b\u3093\u3002\n\u6b21\u306b\u3001median_absolute_error\u95a2\u6570\u306e\u4f7f\u7528\u4f8b\u3092\u793a\u3057\u307e\u3059\u3002\n>>> from sklearn.metrics import median_absolute_error\n>>> y_true = [3, -0.5, 2, 7]\n>>> y_pred = [2.5, 0.0, 2, 8]\n>>> median_absolute_error(y_true, y_pred)\n0.5\n\n\n3.3.4.5. R\u00b2\u30b9\u30b3\u30a2\u3001\u6c7a\u5b9a\u4fc2\u6570\nr2_score \u95a2\u6570\u306f\u3001\u6c7a\u5b9a\u4fc2\u6570 \u3067\u3042\u308bR\u00b2\u3092\u8a08\u7b97\u3057\u307e\u3059\u3002\u3053\u308c\u306f\u3001\u5c06\u6765\u306e\u30b5\u30f3\u30d7\u30eb\u304c\u30e2\u30c7\u30eb\u306b\u3088\u3063\u3066\u4e88\u6e2c\u3055\u308c\u308b\u53ef\u80fd\u6027\u304c\u9ad8\u3044\u3053\u3068\u306e\u6307\u6a19\u3092\u63d0\u4f9b\u3057\u307e\u3059\u3002\u53ef\u80fd\u306a\u6700\u9ad8\u5f97\u70b9\u306f1.0\u3067\u3042\u308a\u3001\u8ca0\u3067\u3042\u308a\u5f97\u308b\uff08\u30e2\u30c7\u30eb\u304c\u4efb\u610f\u306b\u60aa\u5316\u3059\u308b\u53ef\u80fd\u6027\u304c\u3042\u308b\u305f\u3081\uff09\u3002\u5165\u529b\u7279\u5fb4\u91cf\u3092\u7121\u8996\u3057\u3066y\u306e\u671f\u5f85\u5024\u3092\u5e38\u306b\u4e88\u6e2c\u3059\u308b\u5b9a\u6570\u30e2\u30c7\u30eb\u3067\u306f\u3001R ^ 2\u30b9\u30b3\u30a2\u304c0.0\u306b\u306a\u308a\u307e\u3059\u3002\n$\\ hat {y} _i$ \u304c $i$ \u756a\u76ee\u306e\u30b5\u30f3\u30d7\u30eb\u306e\u4e88\u6e2c\u5024\u3067\u3042\u308a\u3001 $y_i$ \u304c\u5bfe\u5fdc\u3059\u308b\u771f\u306e\u5024\u3067\u3042\u308b\u5834\u5408\u3001 $n_{\\text{samples}}$ \u3067\u63a8\u5b9a\u3055\u308c\u305f\u30b9\u30b3\u30a2R\u00b2\u306f\u6b21\u306e\u3088\u3046\u306b\u5b9a\u7fa9\u3055\u308c\u307e\u3059\u3002\nR^2(y, \\hat{y}) = 1 - \\frac{\\sum_{i=0}^{n_{\\text{samples}} - 1} (y_i - \\hat{y}_i)^2}{\\sum_{i=0}^{n_\\text{samples} - 1} (y_i - \\bar{y})^2}\n\n$\\bar{y} =  \\frac{1}{n_{\\text{samples}}} \\sum_{i=0}^{n_{\\text{samples}} - 1} y_i$. \u3067\u3059\u3002\n\u6b21\u306b\u3001r2_score\u95a2\u6570\u306e\u4f7f\u7528\u4f8b\u3092\u793a\u3057\u307e\u3059\u3002\n>>> from sklearn.metrics import r2_score\n>>> y_true = [3, -0.5, 2, 7]\n>>> y_pred = [2.5, 0.0, 2, 8]\n>>> r2_score(y_true, y_pred)  \n0.948...\n>>> y_true = [[0.5, 1], [-1, 1], [7, -6]]\n>>> y_pred = [[0, 2], [-1, 2], [8, -5]]\n>>> r2_score(y_true, y_pred, multioutput='variance_weighted')\n... \n0.938...\n>>> y_true = [[0.5, 1], [-1, 1], [7, -6]]\n>>> y_pred = [[0, 2], [-1, 2], [8, -5]]\n>>> r2_score(y_true, y_pred, multioutput='uniform_average')\n... \n0.936...\n>>> r2_score(y_true, y_pred, multioutput='raw_values')\n... \narray([ 0.965...,  0.908...])\n>>> r2_score(y_true, y_pred, multioutput=[0.3, 0.7])\n... \n0.925...\n\n\n\u4f8b\uff1a\n\n\n\u758e\u306a\u4fe1\u53f7\u3067Lasso\u3068Elastic Net\u3092\u8a55\u4fa1\u3059\u308b\u305f\u3081\u306eR\u00b2\u30b9\u30b3\u30a2\u306e\u4f7f\u7528\u4f8b\u306b\u3064\u3044\u3066\u306f\u3001\u758e\u4fe1\u53f7\u7528\u306eLasso\u3068Elastic Net \u3092\u53c2\u7167\u3057\u3066\u304f\u3060\u3055\u3044\u3002\n\n\n\n\n3.3.5. \u30af\u30e9\u30b9\u30bf\u30ea\u30f3\u30b0\u30e1\u30c8\u30ea\u30c3\u30af\nsklearn.metrics\u30e2\u30b8\u30e5\u30fc\u30eb\u306f\u3001\u3044\u304f\u3064\u304b\u306e\u640d\u5931\u3001\u30b9\u30b3\u30a2\u3001\u304a\u3088\u3073\u30e6\u30fc\u30c6\u30a3\u30ea\u30c6\u30a3\u95a2\u6570\u3092\u5b9f\u88c5\u3057\u3066\u3044\u307e\u3059\u3002\u8a73\u7d30\u306b\u3064\u3044\u3066\u306f\u3001\u30a4\u30f3\u30b9\u30bf\u30f3\u30b9\u30af\u30e9\u30b9\u30bf\u30ea\u30f3\u30b0\u306e \u30af\u30e9\u30b9\u30bf\u30ea\u30f3\u30b0\u30d1\u30d5\u30a9\u30fc\u30de\u30f3\u30b9\u8a55\u4fa1 \u30bb\u30af\u30b7\u30e7\u30f3\u3001\u304a\u3088\u3073\u30d0\u30a4\u30af\u30e9\u30b9\u30bf\u30ea\u30f3\u30b0\u306e Biclustering\u8a55\u4fa1 \u3092\u53c2\u7167\u3057\u3066\u304f\u3060\u3055\u3044\u3002\n\n3.3.6. \u30c0\u30df\u30fc\u898b\u7a4d\u3082\u308a\n\u6559\u5e2b\u3042\u308a\u5b66\u7fd2\u3092\u3059\u308b\u3068\u304d\u3001\u5358\u7d14\u306a\u5065\u5168\u6027\u30c1\u30a7\u30c3\u30af\u306f\u3001\u63a8\u5b9a\u5668\u3092\u5358\u7d14\u306a\u7d4c\u9a13\u5247\u3068\u6bd4\u8f03\u3059\u308b\u3053\u3068\u304b\u3089\u6210\u308a\u307e\u3059\u3002 DummyClassifier \u306f\u3001\u5206\u985e\u306e\u305f\u3081\u306e\u3053\u306e\u3088\u3046\u306a\u5358\u7d14\u306a\u6226\u7565\u3092\u3044\u304f\u3064\u304b\u5b9f\u88c5\u3057\u3066\u3044\u307e\u3059\u3002\n\n\nstratified \u306f\u3001\u30c8\u30ec\u30fc\u30cb\u30f3\u30b0\u30bb\u30c3\u30c8\u30af\u30e9\u30b9\u5206\u5e03\u3092\u5c0a\u91cd\u3059\u308b\u3053\u3068\u306b\u3088\u3063\u3066\u30e9\u30f3\u30c0\u30e0\u4e88\u6e2c\u3092\u751f\u6210\u3059\u308b\u3002\n\nmost_frequent \u306f\u3001\u30c8\u30ec\u30fc\u30cb\u30f3\u30b0\u30bb\u30c3\u30c8\u5185\u306e\u6700\u3082\u983b\u7e41\u306a\u30e9\u30d9\u30eb\u3092\u5e38\u306b\u4e88\u6e2c\u3057\u307e\u3059\u3002\n\nprior \u306f\u5e38\u306bclass\u3092\u6700\u5927\u306b\u3059\u308b\u30af\u30e9\u30b9\u3092\uff08most_frequent\u306e\u3088\u3046\u306b\uff09\u4e88\u6e2c\u3057\u3001 predict_proba \u306f\u30af\u30e9\u30b9\u3092\u5148\u306b\u8fd4\u3057\u307e\u3059\u3002\n\nuniform \u306f\u30e9\u30f3\u30c0\u30e0\u306b\u4e00\u69d8\u306b\u4e88\u6e2c\u3092\u751f\u6210\u3057\u307e\u3059\u3002\n\nconstant \u306f \u5e38\u306b\u30e6\u30fc\u30b6\u30fc\u304c\u63d0\u4f9b\u3059\u308b\u5b9a\u6570\u30e9\u30d9\u30eb\u3092\u4e88\u6e2c\u3068\u3057\u3066\u8fd4\u3057\u307e\u3059\u3002\n\n\u3053\u306e\u65b9\u6cd5\u306e\u4e3b\u306a\u52d5\u6a5f\u306f\u3001\u30dd\u30b8\u30c6\u30a3\u30d6\u306a\u30af\u30e9\u30b9\u304c\u5c11\u6570\u6d3e\u3067\u3042\u308b\u5834\u5408\u306bF1\u30b9\u30b3\u30a2\u30ea\u30f3\u30b0\u3067\u3042\u308b\u3002\n\n\n\n\u3053\u308c\u3089\u306e\u3059\u3079\u3066\u306e\u6226\u7565\u3067\u306f\u3001 predict \u30e1\u30bd\u30c3\u30c9\u306f\u5165\u529b\u30c7\u30fc\u30bf\u3092\u5b8c\u5168\u306b\u7121\u8996\u3057\u307e\u3059\u3002\nDummyClassifier\u3092\u8aac\u660e\u3059\u308b\u306b\u306f\u3001\u307e\u305a\u4e0d\u5747\u8861\u306a\u30c7\u30fc\u30bf\u30bb\u30c3\u30c8\u3092\u4f5c\u6210\u3057\u307e\u3057\u3087\u3046\uff1a\n>>> from sklearn.datasets import load_iris\n>>> from sklearn.model_selection import train_test_split\n>>> iris = load_iris()\n>>> X, y = iris.data, iris.target\n>>> y[y != 1] = -1\n>>> X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=0)\n\n\u6b21\u306b\u3001SVC \u3068 most_frequent \u306e\u7cbe\u5ea6\u3092\u6bd4\u8f03\u3057\u3066\u307f\u307e\u3057\u3087\u3046\u3002\n>>> from sklearn.dummy import DummyClassifier\n>>> from sklearn.svm import SVC\n>>> clf = SVC(kernel='linear', C=1).fit(X_train, y_train)\n>>> clf.score(X_test, y_test) \n0.63...\n>>> clf = DummyClassifier(strategy='most_frequent',random_state=0)\n>>> clf.fit(X_train, y_train)\nDummyClassifier(constant=None, random_state=0, strategy='most_frequent')\n>>> clf.score(X_test, y_test)  \n0.57...\n\n\u79c1\u305f\u3061\u306f\u3001SVC\u304c\u30c0\u30df\u30fc\u306e\u5206\u985e\u5668\u3088\u308a\u3082\u306f\u308b\u304b\u306b\u512a\u308c\u3066\u3044\u306a\u3044\u3053\u3068\u304c\u308f\u304b\u308a\u307e\u3059\u3002\u3055\u3066\u3001\u30ab\u30fc\u30cd\u30eb\u3092\u5909\u66f4\u3057\u307e\u3057\u3087\u3046\uff1a\n>>> clf = SVC(kernel='rbf', C=1).fit(X_train, y_train)\n>>> clf.score(X_test, y_test)  \n0.97...\n\n\u7cbe\u5ea6\u306f\u307b\u307c100\uff05\u306b\u5411\u4e0a\u3057\u307e\u3057\u305f\u3002 CPU\u306e\u30b3\u30b9\u30c8\u304c\u305d\u308c\u307b\u3069\u9ad8\u304f\u306a\u3044\u5834\u5408\u306f\u3001\u7cbe\u5ea6\u3092\u3088\u308a\u6b63\u78ba\u306b\u8a55\u4fa1\u3059\u308b\u305f\u3081\u306b\u3001\u30af\u30ed\u30b9\u30d0\u30ea\u30c7\u30fc\u30b7\u30e7\u30f3\u3092\u63a8\u5968\u3057\u307e\u3059\u3002\u8a73\u7d30\u306b\u3064\u3044\u3066\u306f\u3001 \u30af\u30ed\u30b9\u30d0\u30ea\u30c7\u30fc\u30b7\u30e7\u30f3\uff1a\u898b\u7a4d\u3082\u308a\u30d1\u30d5\u30a9\u30fc\u30de\u30f3\u30b9\u306e\u8a55\u4fa1 \u30bb\u30af\u30b7\u30e7\u30f3\u3092\u53c2\u7167\u3057\u3066\u304f\u3060\u3055\u3044\u3002\u3055\u3089\u306b\u3001\u30d1\u30e9\u30e1\u30fc\u30bf\u7a7a\u9593\u3092\u6700\u9069\u5316\u3059\u308b\u5834\u5408\u306f\u3001\u9069\u5207\u306a\u65b9\u6cd5\u3092\u4f7f\u7528\u3059\u308b\u3053\u3068\u3092\u5f37\u304f\u304a\u52e7\u3081\u3057\u307e\u3059\u3002\u8a73\u7d30\u306b\u3064\u3044\u3066\u306f\u3001\u63a8\u5b9a\u5668\u306e\u30cf\u30a4\u30d1\u30fc\u30d1\u30e9\u30e1\u30fc\u30bf\u306e\u30c1\u30e5\u30fc\u30cb\u30f3\u30b0 \u30bb\u30af\u30b7\u30e7\u30f3\u3092\u53c2\u7167\u3057\u3066\u304f\u3060\u3055\u3044\u3002\n\u3088\u308a\u4e00\u822c\u7684\u306b\u306f\u3001\u5206\u985e\u5668\u306e\u7cbe\u5ea6\u304c\u30e9\u30f3\u30c0\u30e0\u306b\u8fd1\u3059\u304e\u308b\u3068\u3001\u4f55\u304b\u304c\u9593\u9055\u3063\u3066\u3044\u308b\u53ef\u80fd\u6027\u304c\u3042\u308a\u307e\u3059\u3002\u7279\u5fb4\u91cf\u304c\u5f79\u7acb\u305f\u305a\u3001\u30cf\u30a4\u30d1\u30fc\u30d1\u30e9\u30e1\u30fc\u30bf\u304c\u6b63\u3057\u304f\u8abf\u6574\u3055\u308c\u3066\u3044\u306a\u3044\u3001\u5206\u985e\u5668\u304c\u30af\u30e9\u30b9\u306e\u4e0d\u5747\u8861\u306a\u3069\u306b\u82e6\u3057\u3093\u3067\u3044\u307e\u3059\u3002\nDummyRegressor \u306f\u307e\u305f\u3001\u56de\u5e30\u306e\u305f\u3081\u306e4\u3064\u306e\u7c21\u5358\u306a\u7d4c\u9a13\u5247\u3092\u5b9f\u88c5\u3057\u3066\u3044\u307e\u3059\u3002\n\n\nmean \u306f\u5e38\u306b\u8a13\u7df4\u76ee\u6a19\u306e\u5e73\u5747\u3092\u4e88\u6e2c\u3059\u308b\u3002\n\nmedian \u306f\u5e38\u306b\u8a13\u7df4\u76ee\u6a19\u306e\u4e2d\u592e\u5024\u3092\u4e88\u6e2c\u3059\u308b\u3002\n\nquantile \u306f\u3001\u5e38\u306b\u3001\u30e6\u30fc\u30b6\u30fc\u304c\u8a13\u7df4\u76ee\u6a19\u306e\u5206\u4f4d\u70b9\u3092\u63d0\u4f9b\u3059\u308b\u3053\u3068\u3092\u4e88\u6e2c\u3057\u307e\u3059\u3002\n\nconstant \u306f\u3001\u5e38\u306b\u30e6\u30fc\u30b6\u30fc\u306b\u3088\u3063\u3066\u63d0\u4f9b\u3055\u308c\u308b\u4e00\u5b9a\u306e\u5024\u3092\u4e88\u6e2c\u3068\u3057\u3066\u8fd4\u3057\u307e\u3059\u3002\n\n\u3053\u308c\u3089\u306e\u6226\u7565\u3059\u3079\u3066\u306b\u304a\u3044\u3066\u3001predict \u30e1\u30bd\u30c3\u30c9\u306f\u5165\u529b\u30c7\u30fc\u30bf\u3092\u5b8c\u5168\u306b\u7121\u8996\u3059\u308b\u3002\n\u00a92010 - 2016\u3001scikit-learn developers\uff08BSD\u30e9\u30a4\u30bb\u30f3\u30b9\uff09\u3002\nhttp://scikit-learn.org/0.18/modules/model_evaluation.html \u3092 google\u7ffb\u8a33\u3057\u305f\n[\u30e6\u30fc\u30b6\u30fc\u30ac\u30a4\u30c9\u76ee\u6b21](http://qiita.com/nazoking@github/items/267f2371757516f8c168)\n\n----\n\n\u30e2\u30c7\u30eb\u306e\u4e88\u6e2c\u306e\u8cea\u3092\u8a55\u4fa1\u3059\u308b3\u3064\u306e\u7570\u306a\u308b\u30a2\u30d7\u30ed\u30fc\u30c1\u304c\u3042\u308a\u307e\u3059\u3002\n\n  - **\u63a8\u5b9a\u5668\u30b9\u30b3\u30a2\u30e1\u30bd\u30c3\u30c9** \uff1a\u63a8\u5b9a\u5668\u306b\u306f\u3001\u89e3\u6c7a\u3059\u308b\u3088\u3046\u306b\u8a2d\u8a08\u3055\u308c\u305f\u554f\u984c\u306e\u65e2\u5b9a\u306e\u8a55\u4fa1\u57fa\u6e96\u3092\u63d0\u4f9b\u3059\u308b `score`\u30e1\u30bd\u30c3\u30c9\u304c\u3042\u308a\u307e\u3059\u3002\u3053\u308c\u306f\u3053\u306e\u30da\u30fc\u30b8\u3067\u306f\u306a\u304f\u3001\u5404\u63a8\u5b9a\u5668\u306e\u30c9\u30ad\u30e5\u30e1\u30f3\u30c8\u306b\u8a18\u8f09\u3055\u308c\u3066\u3044\u307e\u3059\u3002\n  - **\u30b9\u30b3\u30a2\u30ea\u30f3\u30b0\u30d1\u30e9\u30e1\u30fc\u30bf** \uff1a [\u30af\u30ed\u30b9\u30d0\u30ea\u30c7\u30fc\u30b7\u30e7\u30f3](http://qiita.com/nazoking@github/items/13b167283590f512d99a) \u3092\u4f7f\u7528\u3059\u308b\u30e2\u30c7\u30eb\u8a55\u4fa1\u30c4\u30fc\u30eb\uff08 [model_selection.cross_val_score](http://scikit-learn.org/0.18/modules/generated/sklearn.model_selection.cross_val_score.html#sklearn.model_selection.cross_val_score) \u3084 [model_selection.GridSearchCV](http://scikit-learn.org/0.18/modules/generated/sklearn.model_selection.GridSearchCV.html#sklearn.model_selection.GridSearchCV) \u306a\u3069\uff09\u306f\u3001\u5185\u90e8\u30b9\u30b3\u30a2\u30ea\u30f3\u30b0\u6226\u7565\u306b\u4f9d\u5b58\u3057\u307e\u3059\u3002\u3053\u308c\u306b\u3064\u3044\u3066\u306f\u3001[\u30b9\u30b3\u30a2\u30ea\u30f3\u30b0\u30d1\u30e9\u30e1\u30fc\u30bf\uff1a\u30e2\u30c7\u30eb\u8a55\u4fa1\u30eb\u30fc\u30eb\u306e\u5b9a\u7fa9](#331-%E5%BE%97%E7%82%B9%E3%83%91%E3%83%A9%E3%83%A1%E3%83%BC%E3%82%BF%E3%83%A2%E3%83%87%E3%83%AB%E8%A9%95%E4%BE%A1%E3%83%AB%E3%83%BC%E3%83%AB%E3%81%AE%E5%AE%9A%E7%BE%A9) \u306e\u7bc0\u3067\u8aac\u660e\u3057\u307e\u3059\u3002\n  - **\u30e1\u30c8\u30ea\u30c3\u30af\u95a2\u6570** \uff1a\u30e1\u30c8\u30ea\u30c3\u30af\u30e2\u30b8\u30e5\u30fc\u30eb\u306f\u3001\u7279\u5b9a\u306e\u76ee\u7684\u306e\u305f\u3081\u306b\u4e88\u6e2c\u30a8\u30e9\u30fc\u3092\u8a55\u4fa1\u3059\u308b\u95a2\u6570\u3092\u5b9f\u88c5\u3057\u307e\u3059\u3002\u3053\u308c\u3089\u306e\u30e1\u30c8\u30ea\u30c3\u30af\u306f\u3001\u5206\u985e\u30e1\u30c8\u30ea\u30c3\u30af\u3001\u30de\u30eb\u30c1\u30e9\u30d9\u30eb\u30e9\u30f3\u30ad\u30f3\u30b0\u30e1\u30c8\u30ea\u30c3\u30af\u3001\u56de\u5e30\u30e1\u30c8\u30ea\u30c3\u30af\u3001\u304a\u3088\u3073\u30af\u30e9\u30b9\u30bf\u30ea\u30f3\u30b0\u30e1\u30c8\u30ea\u30c3\u30af\u306b\u95a2\u3059\u308b\u30bb\u30af\u30b7\u30e7\u30f3\u3067\u8a73\u3057\u304f\u8aac\u660e\u3057\u3066\u3044\u307e\u3059\u3002\n\n\u6700\u5f8c\u306b\u3001\u30c0\u30df\u30fc\u8a55\u4fa1\u5668\u306f\u3001\u30e9\u30f3\u30c0\u30e0\u4e88\u6e2c\u306e\u305f\u3081\u306e\u305d\u308c\u3089\u306e\u30e1\u30c8\u30ea\u30c3\u30af\u306e\u30d9\u30fc\u30b9\u30e9\u30a4\u30f3\u5024\u3092\u5f97\u308b\u306e\u306b\u4fbf\u5229\u3067\u3059\u3002\n\n - **\u53c2\u7167:** \u300c\u30da\u30a2\u3054\u3068\u306e\u300d\u30e1\u30c8\u30ea\u30c3\u30af\u3001\u30b5\u30f3\u30d7\u30eb\u3068\u63a8\u5b9a\u5024\u307e\u305f\u306f\u4e88\u6e2c\u3068\u306e\u9593\u306e\u9055\u3044\u306b\u3064\u3044\u3066\u306f\u3001[\u30da\u30a2\u30ef\u30a4\u30ba\u30e1\u30c8\u30ea\u30c3\u30af\u3001\u30a2\u30d5\u30a3\u30cb\u30c6\u30a3\u304a\u3088\u3073\u30ab\u30fc\u30cd\u30eb](http://scikit-learn.org/0.18/modules/metrics.html#metrics)\u306e\u30bb\u30af\u30b7\u30e7\u30f3\u3092\u53c2\u7167\u3057\u3066\u304f\u3060\u3055\u3044\u3002\n\n## 3.3.1. \u5f97\u70b9\u30d1\u30e9\u30e1\u30fc\u30bf\uff1a\u30e2\u30c7\u30eb\u8a55\u4fa1\u30eb\u30fc\u30eb\u306e\u5b9a\u7fa9\n\n[model_selection.GridSearchCV](http://scikit-learn.org/0.18/modules/generated/sklearn.model_selection.GridSearchCV.html#sklearn.model_selection.GridSearchCV) \u3084 [model_selection.cross_val_score](http://scikit-learn.org/0.18/modules/generated/sklearn.model_selection.cross_val_score.html#sklearn.model_selection.cross_val_score) \u306a\u3069\u306e\u30c4\u30fc\u30eb\u3092\u4f7f\u7528\u3057\u305f\u30e2\u30c7\u30eb\u306e\u9078\u629e\u3068\u8a55\u4fa1\u3067\u306f\u3001\u8a55\u4fa1\u6307\u6a19\u306b\u9069\u7528\u3059\u308b\u30e1\u30c8\u30ea\u30c3\u30af\u3092\u5236\u5fa1\u3059\u308b `scoring` \u30d1\u30e9\u30e1\u30fc\u30bf\u3092\u4f7f\u7528\u3057\u307e\u3059\u3002\n\n## 3.3.1.1. \u4e00\u822c\u7684\u306a\u30b1\u30fc\u30b9\uff1a\u5b9a\u7fa9\u6e08\u307f\u306e\u5024\n\n\u6700\u3082\u4e00\u822c\u7684\u306a\u4f7f\u7528\u4f8b\u306b\u3064\u3044\u3066\u306f\u3001`scoring` \u30d1\u30e9\u30e1\u30fc\u30bf\u3092\u4f7f\u7528\u3057\u3066\u5f97\u70b9\u30aa\u30d6\u30b8\u30a7\u30af\u30c8\u3092\u6307\u5b9a\u3059\u308b\u3053\u3068\u304c\u3067\u304d\u307e\u3059\u3002 \u4ee5\u4e0b\u306e\u8868\u306f\u3059\u3079\u3066\u306e\u53ef\u80fd\u306a\u5024\u3092\u793a\u3057\u3066\u3044\u307e\u3059\u3002 \u3059\u3079\u3066\u306e\u30b9\u30b3\u30a2\u30e9\u30fc\u30aa\u30d6\u30b8\u30a7\u30af\u30c8\u306f\u3001 **\u3088\u308a\u9ad8\u3044\u623b\u308a\u5024\u304c\u4f4e\u3044\u623b\u308a\u5024\u3088\u308a\u3082\u512a\u308c\u3066\u3044\u308b** \u3068\u3044\u3046\u898f\u5247\u306b\u5f93\u3044\u307e\u3059\u3002 \u3057\u305f\u304c\u3063\u3066\u3001 [metrics.mean_squared_error](http://scikit-learn.org/0.18/modules/generated/sklearn.metrics.mean_squared_error.html#sklearn.metrics.mean_squared_error) \u306e\u3088\u3046\u306b\u3001\u30e2\u30c7\u30eb\u3068\u30c7\u30fc\u30bf\u306e\u9593\u306e\u8ddd\u96e2\u3092\u6e2c\u5b9a\u3059\u308b\u30e1\u30c8\u30ea\u30c3\u30af\u306f\u3001\u30e1\u30c8\u30ea\u30c3\u30af\u306e\u5426\u5b9a\u3055\u308c\u305f\u5024\u3092\u8fd4\u3059 neg_mean_squared_error\u3068\u3057\u3066\u5229\u7528\u3067\u304d\u307e\u3059\u3002\n   \n| Scoring | Function | Comment |\n| --- | --- | --- |\n| **\u5206\u985e** |\n| \u2018accuracy\u2019 | [`metrics.accuracy_score`](http://scikit-learn.org/0.18/modules/generated/sklearn.metrics.accuracy_score.html#sklearn.metrics.accuracy_score \"sklearn.metrics.accuracy_score\") |\n| \u2018average_precision\u2019 | [`metrics.average_precision_score`](http://scikit-learn.org/0.18/modules/generated/sklearn.metrics.average_precision_score.html#sklearn.metrics.average_precision_score \"sklearn.metrics.average_precision_score\") |\n| \u2018f1\u2019 | [`metrics.f1_score`](http://scikit-learn.org/0.18/modules/generated/sklearn.metrics.f1_score.html#sklearn.metrics.f1_score \"sklearn.metrics.f1_score\") | \u30d0\u30a4\u30ca\u30ea\u30bf\u30fc\u30b2\u30c3\u30c8\u306e\u5834\u5408 |\n| \u2018f1_micro\u2019 | [`metrics.f1_score`](http://scikit-learn.org/0.18/modules/generated/sklearn.metrics.f1_score.html#sklearn.metrics.f1_score \"sklearn.metrics.f1_score\") | \u30df\u30af\u30ed\u5e73\u5747\u5316 |\n| \u2018f1_macro\u2019 | [`metrics.f1_score`](http://scikit-learn.org/0.18/modules/generated/sklearn.metrics.f1_score.html#sklearn.metrics.f1_score \"sklearn.metrics.f1_score\") | \u30de\u30af\u30ed\u5e73\u5747\u5316 |\n| \u2018f1_weighted\u2019 | [`metrics.f1_score`](http://scikit-learn.org/0.18/modules/generated/sklearn.metrics.f1_score.html#sklearn.metrics.f1_score \"sklearn.metrics.f1_score\") | \u52a0\u91cd\u5e73\u5747 |\n| \u2018f1_samples\u2019 | [`metrics.f1_score`](http://scikit-learn.org/0.18/modules/generated/sklearn.metrics.f1_score.html#sklearn.metrics.f1_score \"sklearn.metrics.f1_score\") | \u30de\u30eb\u30c1\u30e9\u30d9\u30eb\u30b5\u30f3\u30d7\u30eb |\n| \u2018neg_log_loss\u2019 | [`metrics.log_loss`](http://scikit-learn.org/0.18/modules/generated/sklearn.metrics.log_loss.html#sklearn.metrics.log_loss \"sklearn.metrics.log_loss\") | `predict_proba` \u30b5\u30dd\u30fc\u30c8\u304c\u5fc5\u8981\u3067\u3059 |\n| \u2018precision\u2019 etc. | [`metrics.precision_score`](http://scikit-learn.org/0.18/modules/generated/sklearn.metrics.precision_score.html#sklearn.metrics.precision_score \"sklearn.metrics.precision_score\") | \u63a5\u5c3e\u8f9e\u306f 'f1'\u3068\u540c\u69d8\u306b\u9069\u7528\u3055\u308c\u307e\u3059\u3002 |\n| \u2018recall\u2019 etc. | [`metrics.recall_score`](http://scikit-learn.org/0.18/modules/generated/sklearn.metrics.recall_score.html#sklearn.metrics.recall_score \"sklearn.metrics.recall_score\") | \u63a5\u5c3e\u8f9e\u306f 'f1'\u3068\u540c\u69d8\u306b\u9069\u7528\u3055\u308c\u307e\u3059\u3002 |\n| \u2018roc_auc\u2019 | [`metrics.roc_auc_score`](http://scikit-learn.org/0.18/modules/generated/sklearn.metrics.roc_auc_score.html#sklearn.metrics.roc_auc_score \"sklearn.metrics.roc_auc_score\") |\n| **\u30af\u30e9\u30b9\u30bf\u30ea\u30f3\u30b0** |\n| \u2018adjusted_rand_score\u2019 | [`metrics.adjusted_rand_score`](http://scikit-learn.org/0.18/modules/generated/sklearn.metrics.adjusted_rand_score.html#sklearn.metrics.adjusted_rand_score \"sklearn.metrics.adjusted_rand_score\") |\n| **\u56de\u5e30** |\n| \u2018neg_mean_absolute_error\u2019 | [`metrics.mean_absolute_error`](http://scikit-learn.org/0.18/modules/generated/sklearn.metrics.mean_absolute_error.html#sklearn.metrics.mean_absolute_error \"sklearn.metrics.mean_absolute_error\") |\n| \u2018neg_mean_squared_error\u2019 | [`metrics.mean_squared_error`](http://scikit-learn.org/0.18/modules/generated/sklearn.metrics.mean_squared_error.html#sklearn.metrics.mean_squared_error \"sklearn.metrics.mean_squared_error\") |\n| \u2018neg_median_absolute_error\u2019 | [`metrics.median_absolute_error`](http://scikit-learn.org/0.18/modules/generated/sklearn.metrics.median_absolute_error.html#sklearn.metrics.median_absolute_error \"sklearn.metrics.median_absolute_error\") |\n| \u2018r2\u2019 | [`metrics.r2_score`](http://scikit-learn.org/0.18/modules/generated/sklearn.metrics.r2_score.html#sklearn.metrics.r2_score \"sklearn.metrics.r2_score\") |\n\nUsage examples:\n\n```python\n>>>\n>>> from sklearn import svm, datasets\n>>> from sklearn.model_selection import cross_val_score\n>>> iris = datasets.load_iris()\n>>> X, y = iris.data, iris.target\n>>> clf = svm.SVC(probability=True, random_state=0)\n>>> cross_val_score(clf, X, y, scoring='neg_log_loss') \narray([-0.07..., -0.16..., -0.06...])\n>>> model = svm.SVC()\n>>> cross_val_score(model, X, y, scoring='wrong_choice')\nTraceback (most recent call last):\nValueError: 'wrong_choice' is not a valid scoring value. Valid options are ['accuracy', 'adjusted_rand_score', 'average_precision', 'f1', 'f1_macro', 'f1_micro', 'f1_samples', 'f1_weighted', 'neg_log_loss', 'neg_mean_absolute_error', 'neg_mean_squared_error', 'neg_median_absolute_error', 'precision', 'precision_macro', 'precision_micro', 'precision_samples', 'precision_weighted', 'r2', 'recall', 'recall_macro', 'recall_micro', 'recall_samples', 'recall_weighted', 'roc_auc']\n```\n\n  - **Note:** ValueError\u4f8b\u5916\u306b\u3088\u3063\u3066\u30ea\u30b9\u30c8\u3055\u308c\u305f\u5024\u306f\u3001\u6b21\u306e\u30bb\u30af\u30b7\u30e7\u30f3\u3067\u8aac\u660e\u3059\u308b\u4e88\u6e2c\u7cbe\u5ea6\u3092\u6e2c\u5b9a\u3059\u308b\u95a2\u6570\u306b\u5bfe\u5fdc\u3057\u3066\u3044\u307e\u3059\u3002\u3053\u308c\u3089\u306e\u95a2\u6570\u306e\u30b9\u30b3\u30a2\u30e9\u30fc\u30aa\u30d6\u30b8\u30a7\u30af\u30c8\u306f\u3001\u8f9e\u66f8sklearn.metrics.SCORERS\u306b\u683c\u7d0d\u3055\u308c\u307e\u3059\u3002\n\n### 3.3.1.2. \u30e1\u30c8\u30ea\u30c3\u30af\u95a2\u6570\u304b\u3089\u30b9\u30b3\u30a2\u30ea\u30f3\u30b0\u6226\u7565\u3092\u5b9a\u7fa9\u3059\u308b\n\n\u30e2\u30b8\u30e5\u30fc\u30eb `sklearn.metric` \u306f\u307e\u305f\u3001\u5b9f\u6e2c\u5024\u3068\u4e88\u6e2c\u3092\u4e0e\u3048\u3089\u308c\u305f\u4e88\u6e2c\u8aa4\u5dee\u3092\u6e2c\u5b9a\u3059\u308b\u5358\u7d14\u306a\u95a2\u6570\u306e\u30bb\u30c3\u30c8\u3092\u516c\u958b\u3057\u3066\u3044\u307e\u3059\uff1a\n\n  - `_score` \u3067\u7d42\u308f\u308b\u95a2\u6570\u306f\u3001\u6700\u5927\u5316\u3059\u308b\u5024\u3092\u8fd4\u3057\u307e\u3059\u3002\n  - `_error` \u307e\u305f\u306f `_loss` \u3067\u7d42\u308f\u308b\u95a2\u6570\u306f\u3001\u6700\u5c0f\u5024\u306b\u623b\u3059\u5024\u3092\u8fd4\u3057\u307e\u3059\u3002 [make_scorer](http://scikit-learn.org/0.18/modules/generated/sklearn.metrics.make_scorer.html#sklearn.metrics.make_scorer) \u3092\u4f7f\u7528\u3057\u3066\u30b9\u30b3\u30a2\u30e9\u30fc\u30aa\u30d6\u30b8\u30a7\u30af\u30c8\u306b\u5909\u63db\u3059\u308b\u3068\u304d\u306f\u3001`greater_is_better` \u30d1\u30e9\u30e1\u30fc\u30bf\u30fc\u3092False\u306b\u8a2d\u5b9a\u3057\u307e\u3059\uff08\u30c7\u30d5\u30a9\u30eb\u30c8\u3067\u306fTrue\u3001\u4ee5\u4e0b\u306e\u30d1\u30e9\u30e1\u30fc\u30bf\u30fc\u306e\u8aac\u660e\u3092\u53c2\u7167\uff09\u3002\n\u3055\u307e\u3056\u307e\u306a\u6a5f\u68b0\u5b66\u7fd2\u30bf\u30b9\u30af\u3067\u4f7f\u7528\u3067\u304d\u308b\u6307\u6a19\u306b\u3064\u3044\u3066\u306f\u3001\u4ee5\u4e0b\u306e\u30bb\u30af\u30b7\u30e7\u30f3\u3067\u8a73\u3057\u304f\u8aac\u660e\u3057\u307e\u3059\u3002\n\n\u591a\u304f\u306e\u30e1\u30c8\u30ea\u30c3\u30af\u306b\u306f\u3001[fbeta_score](http://scikit-learn.org/0.18/modules/generated/sklearn.metrics.fbeta_score.html#sklearn.metrics.fbeta_score) \u306a\u3069\u306e\u8ffd\u52a0\u30d1\u30e9\u30e1\u30fc\u30bf\u304c\u5fc5\u8981\u306a\u5834\u5408\u304c\u3042\u308b\u305f\u3081\u3001\u30b9\u30b3\u30a2\u30ea\u30f3\u30b0\u5024\u3068\u3057\u3066\u4f7f\u7528\u3059\u308b\u540d\u524d\u306f\u3042\u308a\u307e\u305b\u3093\u3002\u305d\u306e\u3088\u3046\u306a\u5834\u5408\u306f\u3001\u9069\u5207\u306a\u30b9\u30b3\u30a2\u30ea\u30f3\u30b0\u30aa\u30d6\u30b8\u30a7\u30af\u30c8\u3092\u751f\u6210\u3059\u308b\u5fc5\u8981\u304c\u3042\u308a\u307e\u3059\u3002\u547c\u3073\u51fa\u3057\u53ef\u80fd\u306a\u30aa\u30d6\u30b8\u30a7\u30af\u30c8\u3092\u751f\u6210\u3059\u308b\u6700\u3082\u7c21\u5358\u306a\u65b9\u6cd5\u306f\u3001[make_scorer](http://scikit-learn.org/0.18/modules/generated/sklearn.metrics.make_scorer.html#sklearn.metrics.make_scorer) \u3092\u4f7f\u7528\u3059\u308b\u65b9\u6cd5\u3067\u3059\u3002\u3053\u306e\u95a2\u6570\u306f\u3001\u30e1\u30c8\u30ea\u30c3\u30af\u3092\u30e2\u30c7\u30eb\u8a55\u4fa1\u306b\u4f7f\u7528\u3067\u304d\u308b\u547c\u3073\u51fa\u3057\u53ef\u80fd\u30aa\u30d6\u30b8\u30a7\u30af\u30c8\u306b\u5909\u63db\u3057\u307e\u3059\u3002\n\n\u5178\u578b\u7684\u306a\u4f7f\u7528\u4f8b\u306e1\u3064\u306f\u3001fbeta_score\u95a2\u6570\u306e\u30d9\u30fc\u30bf\u30d1\u30e9\u30e1\u30fc\u30bf\u306a\u3069\u3001\u30d1\u30e9\u30e1\u30fc\u30bf\u306b\u30c7\u30d5\u30a9\u30eb\u30c8\u4ee5\u5916\u306e\u5024\u3092\u4f7f\u7528\u3057\u3066\u30e9\u30a4\u30d6\u30e9\u30ea\u304b\u3089\u65e2\u5b58\u306e\u30e1\u30c8\u30ea\u30c3\u30af\u95a2\u6570\u3092\u30e9\u30c3\u30d7\u3059\u308b\u3053\u3068\u3067\u3059\u3002\n\n```python\n>>> from sklearn.metrics import fbeta_score, make_scorer\n>>> ftwo_scorer = make_scorer(fbeta_score, beta=2)\n>>> from sklearn.model_selection import GridSearchCV\n>>> from sklearn.svm import LinearSVC\n>>> grid = GridSearchCV(LinearSVC(), param_grid={'C': [1, 10]}, scoring=ftwo_scorer)\n```\n\n2\u756a\u76ee\u306e\u30e6\u30fc\u30b9\u30b1\u30fc\u30b9\u306f\u3001\u3044\u304f\u3064\u304b\u306e\u30d1\u30e9\u30e1\u30fc\u30bf\u3092\u53d6\u308b\u3053\u3068\u304c\u3067\u304d\u308bmake_scorer\u3092\u4f7f\u7528\u3057\u3066\u5358\u7d14\u306aPython\u95a2\u6570\u304b\u3089\u5b8c\u5168\u306b\u30ab\u30b9\u30bf\u30e0\u306escorer\u30aa\u30d6\u30b8\u30a7\u30af\u30c8\u3092\u69cb\u7bc9\u3059\u308b\u3053\u3068\u3067\u3059\uff1a\n  - \u4f7f\u7528\u3059\u308bPython\u95a2\u6570\uff08\u4e0b\u306e\u4f8b\u306e `my_custom_loss_func`\uff09\n  - python\u95a2\u6570\u304c\u30b9\u30b3\u30a2\u3092\u8fd4\u3059\u304b\u3069\u3046\u304b\uff08\u30c7\u30d5\u30a9\u30eb\u30c8 `greater_is_better = True`\uff09\u3001\u307e\u305f\u306f\u640d\u5931\uff08 `greater_is_better = False`\uff09\u3092\u8fd4\u3057\u307e\u3059\u3002 \u640d\u5931\u306e\u5834\u5408\u306f\u3001scorer\u30aa\u30d6\u30b8\u30a7\u30af\u30c8\u306b\u3088\u3063\u3066\u3001python\u95a2\u6570\u306e\u51fa\u529b\u304c\u7121\u52b9\u306b\u306a\u308a\u3001\u30b9\u30b3\u30a2\u30e9\u30fc\u306f\u3088\u308a\u826f\u3044\u30e2\u30c7\u30eb\u306b\u5bfe\u3057\u3066\u9ad8\u3044\u5024\u3092\u8fd4\u3057\u307e\u3059\u3002\n  - \u5206\u985e\u30e1\u30c8\u30ea\u30af\u30b9\u306e\u307f\uff1a\u3042\u306a\u305f\u304c\u63d0\u4f9b\u3057\u305fPython\u95a2\u6570\u304c\u7d99\u7d9a\u7684\u306a\u610f\u601d\u6c7a\u5b9a\u306e\u78ba\u5b9f\u6027\u3092\u5fc5\u8981\u3068\u3059\u308b\u304b\u3069\u3046\u304b\uff08 `needs_threshold = True` \uff09 \u30c7\u30d5\u30a9\u30eb\u30c8\u5024\u306fFalse\u3067\u3059\u3002\n  - \u30d9\u30fc\u30bf\u3084 [f1_score](http://scikit-learn.org/0.18/modules/generated/sklearn.metrics.f1_score.html#sklearn.metrics.f1_score) \u306e\u30e9\u30d9\u30eb\u306a\u3069\u306e\u8ffd\u52a0\u30d1\u30e9\u30e1\u30fc\u30bf\u3002\n\n\u30ab\u30b9\u30bf\u30e0\u30b9\u30b3\u30a2\u30e9\u30fc\u3092\u4f5c\u6210\u3057\u3001`greater_is_better`\u30d1\u30e9\u30e1\u30fc\u30bf\u30fc\u3092\u4f7f\u7528\u3059\u308b\u4f8b\u3092\u6b21\u306b\u793a\u3057\u307e\u3059\u3002\n\n```python\n>>> import numpy as np\n>>> def my_custom_loss_func(ground_truth, predictions):\n...     diff = np.abs(ground_truth - predictions).max()\n...     return np.log(1 + diff)\n...\n>>> # loss_func\u306f\u3001my_custom_loss_func\u306e\u623b\u308a\u5024\u3092\u7121\u52b9\u306b\u3057\u307e\u3059\u3002\n>>> # \u3053\u308c\u306f\u3001ground_truth\u306e\u5024\u3068\u4e0b\u3067\u5b9a\u7fa9\u3055\u308c\u305f\u4e88\u6e2c\u304c\u3042\u308b\u5834\u5408\u3001np.log(2)\u30010.693\u306b\u306a\u308a\u307e\u3059\u3002\n>>> loss  = make_scorer(my_custom_loss_func, greater_is_better=False)\n>>> score = make_scorer(my_custom_loss_func, greater_is_better=True)\n>>> ground_truth = [[1, 1]]\n>>> predictions  = [0, 1]\n>>> from sklearn.dummy import DummyClassifier\n>>> clf = DummyClassifier(strategy='most_frequent', random_state=0)\n>>> clf = clf.fit(ground_truth, predictions)\n>>> loss(clf,ground_truth, predictions) \n-0.69...\n>>> score(clf,ground_truth, predictions) \n0.69...\n```\n\n### 3.3.1.3. \u72ec\u81ea\u306e\u63a1\u70b9\u30aa\u30d6\u30b8\u30a7\u30af\u30c8\u306e\u5b9f\u88c5\n\nmake_scorer \u30d5\u30a1\u30af\u30c8\u30ea\u3092\u4f7f\u7528\u305b\u305a\u306b\u3001\u72ec\u81ea\u306e\u30b9\u30b3\u30a2\u30ea\u30f3\u30b0\u30aa\u30d6\u30b8\u30a7\u30af\u30c8\u3092\u30bc\u30ed\u304b\u3089\u69cb\u7bc9\u3059\u308b\u3053\u3068\u3067\u3001\u3088\u308a\u67d4\u8edf\u306a\u30e2\u30c7\u30eb\u30b9\u30b3\u30a2\u30e9\u30fc\u3092\u751f\u6210\u3059\u308b\u3053\u3068\u304c\u3067\u304d\u307e\u3059\u3002\u547c\u3073\u51fa\u3057\u53ef\u80fd\u30aa\u30d6\u30b8\u30a7\u30af\u30c8\u304c\u30b9\u30b3\u30a2\u30e9\u30fc\u3067\u3042\u308b\u305f\u3081\u306b\u306f\u3001\u4ee5\u4e0b\u306e2\u3064\u306e\u30eb\u30fc\u30eb\u3067\u6307\u5b9a\u3055\u308c\u305f\u30d7\u30ed\u30c8\u30b3\u30eb\u3092\u6e80\u305f\u3059\u5fc5\u8981\u304c\u3042\u308a\u307e\u3059\u3002\n  - `(estimator, X, y)`\u3067\u547c\u3073\u51fa\u3059\u3053\u3068\u304c\u3067\u304d\u308b\u3053\u3068\u3002`estimator` \u306f\u8a55\u4fa1\u3059\u3079\u304d\u30e2\u30c7\u30eb\u3067\u3042\u308a\u3001`X` \u306f\u691c\u8a3c\u30c7\u30fc\u30bf\u3067\u3042\u308a\u3001 `y` \u306f `X`\uff08\u6559\u5e2b\u3042\u308a\u306e\u5834\u5408\uff09\u307e\u305f\u306f `None`\uff08\u6559\u5e2b\u306a\u3057\u306e\u5834\u5408\uff09\u306e\u5b9f\u6e2c\u5024\u30bf\u30fc\u30b2\u30c3\u30c8\u3002\n  - `y` \u3092\u53c2\u7167\u3057\u3066\u3001`X` \u4e0a\u306e `estimator` \u4e88\u6e2c\u54c1\u8cea\u3092\u5b9a\u91cf\u5316\u3059\u308b\u6d6e\u52d5\u5c0f\u6570\u70b9\u6570\u3092\u8fd4\u3059\u3053\u3068\u3002\u7e70\u308a\u8fd4\u3057\u306b\u306a\u308a\u307e\u3059\u304c\u3001\u6163\u4f8b\u3067\u306f\u6570\u5024\u304c\u9ad8\u3044\u307b\u3069\u826f\u3044\u306e\u3067\u3001\u30b9\u30b3\u30a2\u30e9\u30fc\u304c\u640d\u5931\u3092\u8fd4\u3059\u5834\u5408\u306f\u3001\u305d\u306e\u5024\u3092\u7121\u52b9\u306b\u3059\u308b\u5fc5\u8981\u304c\u3042\u308a\u307e\u3059\u3002\n\n## 3.3.2. \u5206\u985e\u30e1\u30c8\u30ea\u30c3\u30af\n\n[sklearn.metrics](http://scikit-learn.org/0.18/modules/classes.html#module-sklearn.metrics) \u30e2\u30b8\u30e5\u30fc\u30eb\u306f\u3001\u5206\u985e\u30d1\u30d5\u30a9\u30fc\u30de\u30f3\u30b9\u3092\u6e2c\u5b9a\u3059\u308b\u3044\u304f\u3064\u304b\u306e\u640d\u5931\u3001\u30b9\u30b3\u30a2\u3001\u304a\u3088\u3073\u30e6\u30fc\u30c6\u30a3\u30ea\u30c6\u30a3\u95a2\u6570\u3092\u5b9f\u88c5\u3057\u307e\u3059\u3002\u4e00\u90e8\u306e\u30e1\u30c8\u30ea\u30c3\u30af\u3067\u306f\u3001\u6b63\u306e\u30af\u30e9\u30b9\u3001\u4fe1\u983c\u5024\u3001\u307e\u305f\u306f\u30d0\u30a4\u30ca\u30ea\u6c7a\u5b9a\u5024\u306e\u78ba\u7387\u63a8\u5b9a\u304c\u5fc5\u8981\u306a\u5834\u5408\u304c\u3042\u308a\u307e\u3059\u3002\u307b\u3068\u3093\u3069\u306e\u5b9f\u88c5\u3067\u306f\u3001 `sample_weight` \u30d1\u30e9\u30e1\u30fc\u30bf\u3092\u4f7f\u7528\u3057\u3066\u3001\u5404\u30b5\u30f3\u30d7\u30eb\u304c\u30b9\u30b3\u30a2\u5168\u4f53\u306b\u91cd\u307f\u4ed8\u3051\u3055\u308c\u305f\u5bc4\u4e0e\u3092\u3059\u308b\u3053\u3068\u304c\u3067\u304d\u307e\u3059\u3002\n\n\u3053\u308c\u3089\u3001\u30d0\u30a4\u30ca\u30ea\u5206\u985e\u306e\u5834\u5408\u306b\u5236\u9650\u3055\u308c\u3066\u3044\u307e\u3059\uff1a\n\n|  |  |\n|------------------------------|---------------------------|\n|matthews_corrcoef(y_true\u3001y_pred [\u3001...])|\u30d0\u30a4\u30ca\u30ea\u30af\u30e9\u30b9\u306eMatthews\u76f8\u95a2\u4fc2\u6570(MCC\uff09\u3092\u8a08\u7b97\u3059\u308b|\n|precision_recall_curve(y_true\u3001probas_pred)|\u3055\u307e\u3056\u307e\u306a\u78ba\u7387\u3057\u304d\u3044\u5024\u306b\u5bfe\u3059\u308b\u9069\u5408\u7387 - \u518d\u73fe\u7387\u306e\u30da\u30a2\u3092\u8a08\u7b97\u3059\u308b|\n|roc_curve(y_true\u3001y_score [\u3001pos_label\u3001...])|\u53d7\u4fe1\u6a5f\u306e\u52d5\u4f5c\u7279\u6027(ROC\uff09\u3092\u8a08\u7b97\u3059\u308b|\n\n\n\u3053\u308c\u3089\u306f\u30de\u30eb\u30c1\u30af\u30e9\u30b9\u3067\u3082\u6a5f\u80fd\u3059\u308b\uff1a\n\n|  |  |\n|------------------------------|---------------------------|\n|cohen_kappa_score(y1\u3001y2 [\u3001labels\u3001weights]) |Cohen's kappa\uff1a\u30a2\u30ce\u30c6\u30fc\u30bf\u9593\u306e\u5408\u610f\u3092\u6e2c\u5b9a\u3059\u308b\u7d71\u8a08\u3002|\n|confusion_matrix(y_true\u3001y_pred [\u3001labels\u3001...]) |\u5206\u985e\u306e\u7cbe\u5ea6\u3092\u8a55\u4fa1\u3059\u308b\u305f\u3081\u306e\u6df7\u540c\u884c\u5217\u3092\u8a08\u7b97\u3059\u308b|\n|hinge_loss(y_true\u3001pred_decision [\u3001labels\u3001...]) |\u5e73\u5747\u30d2\u30f3\u30b8\u30fb\u30ed\u30b9(\u975e\u6b63\u898f\u5316) ||\n\n\u3053\u308c\u3089\u306f\u30de\u30eb\u30c1\u30e9\u30d9\u30eb\u306e\u5834\u5408\u306b\u3082\u6a5f\u80fd\u3059\u308b\uff1a\n\n|||\n|------------------------------|---------------------------|\n|accuracy_score(y_true\u3001y_pred [\u3001normalize\u3001...]) |\u7cbe\u5ea6\u5206\u985e\u30b9\u30b3\u30a2\u3002|\n|classification_report(y_true\u3001y_pred [\u3001...]) |\u4e3b\u8981\u5206\u985e\u30e1\u30c8\u30ea\u30c3\u30af\u3092\u793a\u3059\u30c6\u30ad\u30b9\u30c8\u30ec\u30dd\u30fc\u30c8\u3092\u4f5c\u6210\u3057\u307e\u3059|\n|f1_score(y_true\u3001y_pred [\u3001labels\u3001...]) |F1\u30b9\u30b3\u30a2\u3092\u8a08\u7b97\u3057\u307e\u3059\u3002\u3053\u308c\u306f\u30d0\u30e9\u30f3\u30b9F\u30b9\u30b3\u30a2\u307e\u305f\u306fF\u30e1\u30b8\u30e3\u30fc\u3068\u3082\u547c\u3070\u308c\u307e\u3059|\n|fbeta_score(y_true\u3001y_pred\u3001beta [\u3001labels\u3001...]) |F\u30d9\u30fc\u30bf\u30b9\u30b3\u30a2\u3092\u8a08\u7b97\u3059\u308b|\n|hamming_loss(y_true\u3001y_pred [\u3001labels\u3001...]) |\u5e73\u5747\u30cf\u30df\u30f3\u30b0\u640d\u5931\u3092\u8a08\u7b97\u3057\u307e\u3059\u3002|\n|jaccard_similarity_score(y_true\u3001y_pred [\u3001...]) |Jaccard\u985e\u4f3c\u5ea6\u30b9\u30b3\u30a2|\n|log_loss(y_true\u3001y_pred [\u3001eps\u3001normalize\u3001...]) |\u30ed\u30b0\u306e\u640d\u5931\u3001\u5225\u540d\u30ed\u30b8\u30b9\u30c6\u30a3\u30c3\u30af\u640d\u5931\u307e\u305f\u306f\u30af\u30ed\u30b9\u30a8\u30f3\u30c8\u30ed\u30d4\u30fc\u640d\u5931\u3002|\n|precision_recall_fscore_support(y_true\u3001y_pred) |\u5404\u30af\u30e9\u30b9\u306e\u9069\u5408\u7387\u3001\u518d\u73fe\u7387\u3001F-measure\u304a\u3088\u3073\u30b5\u30dd\u30fc\u30c8\u3092\u8a08\u7b97\u3059\u308b|\n|precision_score(y_true\u3001y_pred [\u3001labels\u3001...]) |\u9069\u5408\u7387\u3092\u8a08\u7b97\u3059\u308b|\n|recall_score(y_true\u3001y_pred [\u3001labels\u3001...]) |\u518d\u73fe\u7387\u3092\u8a08\u7b97\u3059\u308b|\n|zero_one_loss(y_true\u3001y_pred [\u3001normalize\u3001...]) |\u30bc\u30ed\u306e\u5206\u985e\u640d\u3002|\n\n\u3053\u308c\u3089\u306f\u3001\u30d0\u30a4\u30ca\u30ea\u3068\u30de\u30eb\u30c1\u30e9\u30d9\u30eb(\u30de\u30eb\u30c1\u30af\u30e9\u30b9\u3067\u306f\u306a\u3044)\u3067\u6a5f\u80fd\u3059\u308b\n\n|||\n|------------------------------|---------------------------|\n|average_precision_score(y_true\u3001y_score [\u3001...]) |\u4e88\u6e2c\u30b9\u30b3\u30a2\u304b\u3089\u5e73\u5747\u7cbe\u5ea6(AP) |\u3092\u8a08\u7b97\u3059\u308b|\n|roc_auc_score(y_true\u3001y_score [\u3001average\u3001...]) |\u4e88\u6e2c\u30b9\u30b3\u30a2\u304b\u3089\u306e\u66f2\u7dda\u4e0b\u9762\u7a4d(AUC) |\u306e\u8a08\u7b97|\n\n\u4ee5\u4e0b\u306e\u30b5\u30d6\u30bb\u30af\u30b7\u30e7\u30f3\u3067\u306f\u3001\u3053\u308c\u3089\u306e\u95a2\u6570\u306e\u305d\u308c\u305e\u308c\u306b\u3064\u3044\u3066\u8aac\u660e\u3057\u3001\u5171\u901a\u306eAPI\u3068\u30e1\u30c8\u30ea\u30c3\u30af\u306e\u5b9a\u7fa9\u306b\u3064\u3044\u3066\u3044\u304f\u3064\u304b\u306e\u6ce8\u610f\u3092\u5148\u53d6\u308a\u3057\u307e\u3059\u3002\n\n### 3.3.2.1. \u30d0\u30a4\u30ca\u30ea\u304b\u3089\u30de\u30eb\u30c1\u30af\u30e9\u30b9\u3001\u30de\u30eb\u30c1\u30e9\u30d9\u30eb\u307e\u3067\n\n\u57fa\u672c\u7684\u306b\u3001\u30d0\u30a4\u30ca\u30ea\u5206\u985e\u30bf\u30b9\u30af\u306e\u305f\u3081\u306b\u3044\u304f\u3064\u304b\u306e\u30e1\u30c8\u30ea\u30c3\u30af\u304c\u5b9a\u7fa9\u3055\u308c\u3066\u3044\u307e\u3059( [f1_score](http://scikit-learn.org/0.18/modules/generated/sklearn.metrics.f1_score.html#sklearn.metrics.f1_score) \u3001 [roc_auc_score](http://scikit-learn.org/0.18/modules/generated/sklearn.metrics.roc_auc_score.html#sklearn.metrics.roc_auc_score) \u306a\u3069\uff09\u3002\u3053\u306e\u3088\u3046\u306a\u5834\u5408\u3001\u30c7\u30d5\u30a9\u30eb\u30c8\u3067\u306f\u30dd\u30b8\u30c6\u30a3\u30d6\u30fb\u30e9\u30d9\u30eb\u306e\u307f\u304c\u8a55\u4fa1\u3055\u308c\u3001\u30dd\u30b8\u30c6\u30a3\u30d6\u30fb\u30af\u30e9\u30b9\u306f1\u3068\u30e9\u30d9\u30eb\u4ed8\u3051\u3055\u308c\u3066\u3044\u307e\u3059\uff08 `pos_label` \u30d1\u30e9\u30e1\u30fc\u30bf\u3067\u69cb\u6210\u53ef\u80fd\u3067\u3059\u304c\uff09\u3002\n\u30d0\u30a4\u30ca\u30ea\u30e1\u30c8\u30ea\u30c3\u30af\u3092\u30de\u30eb\u30c1\u30af\u30e9\u30b9\u307e\u305f\u306f\u30de\u30eb\u30c1\u30e9\u30d9\u30eb\u306e\u554f\u984c\u306b\u62e1\u5f35\u3059\u308b\u5834\u5408\u3001\u30c7\u30fc\u30bf\u306f\u30d0\u30a4\u30ca\u30ea\u306e\u554f\u984c\u306e\u30b3\u30ec\u30af\u30b7\u30e7\u30f3\u3068\u3057\u3066\u6271\u308f\u308c\u307e\u3059\uff08\u30af\u30e9\u30b9\u3054\u3068\u306b1\u3064\uff09\u3002\u3044\u304f\u3064\u304b\u306e\u30b7\u30ca\u30ea\u30aa\u3067\u306f\u6709\u7528\u306a\u3001\u30af\u30e9\u30b9\u306e\u30bb\u30c3\u30c8\u5168\u4f53\u3067\u30d0\u30a4\u30ca\u30ea\u30e1\u30c8\u30ea\u30c3\u30af\u8a08\u7b97\u3092\u5e73\u5747\u5316\u3059\u308b\u65b9\u6cd5\u306f\u3044\u304f\u3064\u304b\u3042\u308a\u307e\u3059\u3002\u53ef\u80fd\u3067\u3042\u308c\u3070\u3001`average` \u30d1\u30e9\u30e1\u30fc\u30bf\u3092\u4f7f\u7528\u3057\u3066\u3053\u308c\u3089\u306e\u4e2d\u304b\u3089\u9078\u629e\u3059\u308b\u5fc5\u8981\u304c\u3042\u308a\u307e\u3059\u3002\n\n  - `\"macro\"` \u306f\u30d0\u30a4\u30ca\u30ea\u30e1\u30c8\u30ea\u30c3\u30af\u306e\u5e73\u5747\u3092\u8a08\u7b97\u3057\u3001\u5404\u30af\u30e9\u30b9\u306b\u7b49\u3057\u3044\u91cd\u307f\u3092\u4e0e\u3048\u307e\u3059\u3002\u305d\u308c\u306b\u3082\u304b\u304b\u308f\u3089\u305a\u3001\u983b\u5ea6\u306e\u4f4e\u3044\u30af\u30e9\u30b9\u304c\u91cd\u8981\u306a\u554f\u984c\u3067\u306f\u3001\u30de\u30af\u30ed\u5e73\u5747\u5316\u304c\u30d1\u30d5\u30a9\u30fc\u30de\u30f3\u30b9\u3092\u5f37\u8abf\u3059\u308b\u624b\u6bb5\u306b\u306a\u308b\u53ef\u80fd\u6027\u304c\u3042\u308a\u307e\u3059\u3002\u4e00\u65b9\u3001\u3059\u3079\u3066\u306e\u30af\u30e9\u30b9\u304c\u540c\u3058\u3088\u3046\u306b\u91cd\u8981\u3067\u3042\u308b\u3068\u3044\u3046\u524d\u63d0\u306f\u3001\u3057\u3070\u3057\u3070\u771f\u5b9f\u3067\u306f\u306a\u3044\u305f\u3081\u3001\u30de\u30af\u30ed\u5e73\u5747\u306f\u3001\u307e\u308c\u306a\u30af\u30e9\u30b9\u3067\u306f\u4e00\u822c\u7684\u306b\u4f4e\u3044\u30d1\u30d5\u30a9\u30fc\u30de\u30f3\u30b9\u3092\u904e\u5ea6\u306b\u5f37\u8abf\u3059\u308b\u3053\u3068\u306b\u306a\u308a\u307e\u3059\u3002\n  - `\"weighted\"` \u5404\u30af\u30e9\u30b9\u306e\u30b9\u30b3\u30a2\u304c\u771f\u306e\u30c7\u30fc\u30bf\u30b5\u30f3\u30d7\u30eb\u5185\u306b\u5b58\u5728\u3059\u308b\u3053\u3068\u306b\u3088\u3063\u3066\u91cd\u307f\u4ed8\u3051\u3055\u308c\u305f\u30d0\u30a4\u30ca\u30ea\u30e1\u30c8\u30ea\u30c3\u30af\u306e\u5e73\u5747\u3092\u8a08\u7b97\u3059\u308b\u3053\u3068\u306b\u3088\u3063\u3066\u3001\u30af\u30e9\u30b9\u306e\u4e0d\u5747\u8861\u3092\u300c\u91cd\u307f\u4ed8\u3051\u300d\u3059\u308b\u3002\n  -`\"micro\"` \u306f\u3001\u5404\u30b5\u30f3\u30d7\u30eb\u30af\u30e9\u30b9\u306e\u30da\u30a2\u306b\u3001\u5168\u4f53\u7684\u306a\u30e1\u30c8\u30ea\u30c3\u30af\u306b\u7b49\u3057\u304f\u5bc4\u4e0e\u3057\u307e\u3059\uff08\u30b5\u30f3\u30d7\u30eb\u30a6\u30a7\u30a4\u30c8\u306e\u7d50\u679c\u3092\u9664\u3044\u3066\uff09\u3002\u30af\u30e9\u30b9\u3054\u3068\u306e\u30e1\u30c8\u30ea\u30c3\u30af\u3092\u5408\u8a08\u3059\u308b\u306e\u3067\u306f\u306a\u304f\u3001\u30af\u30e9\u30b9\u3054\u3068\u306e\u30e1\u30c8\u30ea\u30c3\u30af\u3092\u69cb\u6210\u3059\u308b\u914d\u5f53\u304a\u3088\u3073\u9664\u6570\u3092\u5408\u8a08\u3057\u3066\u3001\u5168\u4f53\u306e\u5546\u3092\u8a08\u7b97\u3057\u307e\u3059\u3002\u30de\u30a4\u30af\u30ed\u30a2\u30d9\u30ec\u30fc\u30b8\u30f3\u30b0\u306f\u200b\u200b\u3001\u591a\u6570\u30af\u30e9\u30b9\u3092\u7121\u8996\u3059\u308b\u30de\u30eb\u30c1\u30af\u30e9\u30b9\u5206\u985e\u3092\u542b\u3080\u3001\u30de\u30eb\u30c1\u30e9\u30d9\u30eb\u8a2d\u5b9a\u3067\u512a\u5148\u3055\u308c\u308b\u5834\u5408\u304c\u3042\u308a\u307e\u3059\u3002\n  -`\"samples\"`\u306f\u30de\u30eb\u30c1\u30e9\u30d9\u30eb\u554f\u984c\u306b\u306e\u307f\u9069\u7528\u3055\u308c\u307e\u3059\u3002\u4ee3\u308f\u308a\u306b\u3001\u8a55\u4fa1\u30c7\u30fc\u30bf\u306e\u5404\u30b5\u30f3\u30d7\u30eb\u306e\u771f\u306e\u30af\u30e9\u30b9\u3068\u4e88\u6e2c\u3055\u308c\u305f\u30af\u30e9\u30b9\u306e\u30e1\u30c8\u30ea\u30c3\u30af\u3092\u8a08\u7b97\u3057\u3001\u305d\u306e\uff08`sample_weight` - weighted\uff09\u5e73\u5747\u3092\u8fd4\u3057\u307e\u3059\u3002\n  - `average = None` \u3092\u9078\u629e\u3059\u308b\u3068\u3001\u5404\u30af\u30e9\u30b9\u306e\u30b9\u30b3\u30a2\u3092\u542b\u3080\u914d\u5217\u304c\u8fd4\u3055\u308c\u307e\u3059\u3002\n\n\u30de\u30eb\u30c1\u30af\u30e9\u30b9\u30fb\u30c7\u30fc\u30bf\u306f\u3001\u30d0\u30a4\u30ca\u30ea\u30fb\u30bf\u30fc\u30b2\u30c3\u30c8\u306e\u3088\u3046\u306b\u30e1\u30c8\u30ea\u30c3\u30af\u306b\u30af\u30e9\u30b9\u30fb\u30e9\u30d9\u30eb\u306e\u914d\u5217\u3068\u3057\u3066\u63d0\u4f9b\u3055\u308c\u307e\u3059\u304c\u3001\u30de\u30eb\u30c1\u30e9\u30d9\u30eb\u30fb\u30c7\u30fc\u30bf\u306f\u3001\u30b5\u30f3\u30d7\u30eb`i`\u304c\u30e9\u30d9\u30eb`j`\u3092\u6301\u3064\u5834\u5408\u306fcell `[i\u3001j]` \u304c\u50241\u3092\u3001\u305d\u3046\u3067\u306a\u3044\u5834\u5408\u306f0\u3092\u8fd4\u3057\u307e\u3059 \u3002\n\n### 3.3.2.2. \u7cbe\u5ea6\u30b9\u30b3\u30a2\n\n[accuracy_score](http://scikit-learn.org/0.18/modules/generated/sklearn.metrics.accuracy_score.html#sklearn.metrics.accuracy_score) \u95a2\u6570\u306f\u3001\u6b63\u78ba\u306a\u4e88\u6e2c\u306e\u5272\u5408\uff08\u30c7\u30d5\u30a9\u30eb\u30c8\uff09\u307e\u305f\u306f\u30ab\u30a6\u30f3\u30c8\uff08`normalize=False`\uff09\u306e\u3044\u305a\u308c\u304b\u3092\u8a08\u7b97\u3057\u307e\u3059\u3002\n\u30de\u30eb\u30c1\u30e9\u30d9\u30eb\u5206\u985e\u3067\u306f\u3001\u3053\u306e\u95a2\u6570\u306f\u30b5\u30d6\u30bb\u30c3\u30c8\u306e\u7cbe\u5ea6\u3092\u8fd4\u3057\u307e\u3059\u3002 \u30b5\u30f3\u30d7\u30eb\u306e\u4e88\u6e2c\u30e9\u30d9\u30eb\u306e\u30bb\u30c3\u30c8\u5168\u4f53\u304c\u5b9f\u969b\u306e\u30e9\u30d9\u30eb\u30bb\u30c3\u30c8\u3068\u53b3\u5bc6\u306b\u4e00\u81f4\u3059\u308b\u5834\u5408\u3001\u30b5\u30d6\u30bb\u30c3\u30c8\u7cbe\u5ea6\u306f1.0\u3067\u3059\u3002 \u305d\u308c\u4ee5\u5916\u306e\u5834\u5408\u306f0.0\u3067\u3059\u3002\n\n```math\n\\texttt{accuracy}(y, \\hat{y}) = \\frac{1}{n_\\text{samples}} \\sum_{i=0}^{n_\\text{samples}-1} 1(\\hat{y}_i = y_i)\n```\n\n\u3053\u3053\u3067\u3001 $1(x)$ \u306f[\u6307\u6a19\u95a2\u6570](https://en.wikipedia.org/wiki/Indicator_function)\u3067\u3059\u3002\n\n```python\n>>> import numpy as np\n>>> from sklearn.metrics import accuracy_score\n>>> y_pred = [0, 2, 1, 3]\n>>> y_true = [0, 1, 2, 3]\n>>> accuracy_score(y_true, y_pred)\n0.5\n>>> accuracy_score(y_true, y_pred, normalize=False)\n2\n```\n\n\u30d0\u30a4\u30ca\u30ea\u30e9\u30d9\u30eb\u30a4\u30f3\u30b8\u30b1\u30fc\u30bf\u3092\u4f7f\u7528\u3057\u305f\u30de\u30eb\u30c1\u30e9\u30d9\u30eb\u306e\u5834\u5408\uff1a\n\n```python\n>>> accuracy_score(np.array([[0, 1], [1, 1]]), np.ones((2, 2)))\n0.5\n```\n\n  - \u4f8b\uff1a\n    - \u30c7\u30fc\u30bf\u30bb\u30c3\u30c8\u306e\u9806\u5217\u3092\u4f7f\u7528\u3057\u305f\u7cbe\u5ea6\u30b9\u30b3\u30a2\u306e\u4f7f\u7528\u4f8b\u306e[\u5206\u985e\u30b9\u30b3\u30a2\u306e\u91cd\u8981\u6027\u3092\u9806\u5217\u3067\u30c6\u30b9\u30c8\u3059\u308b](http://scikit-learn.org/0.18/auto_examples/feature_selection/plot_permutation_test_for_classification.html#sphx-glr-auto-examples-feature-selection-plot-permutation-test-for-classification-py) \u3092\u53c2\u7167\u3057\u3066\u304f\u3060\u3055\u3044\u3002\n\n### 3.3.2.3. \u30ab\u30c3\u30d1\u4fc2\u6570\n\n\u95a2\u6570 [cohen_kappa_score](http://scikit-learn.org/0.18/modules/generated/sklearn.metrics.cohen_kappa_score.html#sklearn.metrics.cohen_kappa_score) \u306f\u3001[\u30ab\u30c3\u30d1\u4fc2\u6570](https://en.wikipedia.org/wiki/Cohen%27s_kappa) \u3092\u8a08\u7b97\u3057\u307e\u3059\u3002\u3053\u306e\u5c3a\u5ea6\u306f\u3001\u7570\u306a\u308b\u4eba\u9593\u306e\u6ce8\u91c8\u8005\u306b\u3088\u308b\u30e9\u30d9\u30ea\u30f3\u30b0\u3092\u6bd4\u8f03\u3059\u308b\u3053\u3068\u3092\u76ee\u7684\u3068\u3057\u3066\u3044\u307e\u3059\u3002\n\u03ba\u30b9\u30b3\u30a2\uff08docstring\u53c2\u7167\uff09\u306f-1\u30681\u306e\u9593\u306e\u6570\u5024\u3067\u3059.8\u4ee5\u4e0a\u306e\u30b9\u30b3\u30a2\u306f\u4e00\u822c\u7684\u306b\u826f\u3044\u4e00\u81f4\u3068\u307f\u306a\u3055\u308c\u307e\u3059\u3002\u30bc\u30ed\u4ee5\u4e0b\u306f\u3001\u5408\u610f\u304c\u306a\u3044\u3053\u3068\u3092\u610f\u5473\u3059\u308b\uff08\u4e8b\u5b9f\u4e0a\u30e9\u30f3\u30c0\u30e0\u306a\u30e9\u30d9\u30eb\uff09\u3002\n\u03ba\u30b9\u30b3\u30a2\u306f\u3001\u30d0\u30a4\u30ca\u30ea\u307e\u305f\u306f\u30de\u30eb\u30c1\u30af\u30e9\u30b9\u306e\u554f\u984c\u306b\u3064\u3044\u3066\u306f\u8a08\u7b97\u3067\u304d\u307e\u3059\u304c\u3001\u30de\u30eb\u30c1\u30e9\u30d9\u30eb\u306e\u554f\u984c\uff08\u30e9\u30d9\u30eb\u3054\u3068\u306e\u30b9\u30b3\u30a2\u3092\u624b\u52d5\u3067\u8a08\u7b97\u3059\u308b\u5834\u5408\u3092\u9664\u304f\uff09\u3067\u306f\u306a\u304f\u30012\u3064\u4ee5\u4e0a\u306e\u6ce8\u91c8\u3067\u306f\u8a08\u7b97\u3067\u304d\u307e\u305b\u3093\u3002\n\n```python\n>>> from sklearn.metrics import cohen_kappa_score\n>>> y_true = [2, 0, 2, 2, 0, 1]\n>>> y_pred = [0, 0, 2, 2, 0, 2]\n>>> cohen_kappa_score(y_true, y_pred)\n0.4285714285714286\n```\n\n### 3.3.2.4. \u6df7\u540c\u884c\u5217\n\n[confusion_matrix](http://scikit-learn.org/0.18/modules/generated/sklearn.metrics.confusion_matrix.html#sklearn.metrics.confusion_matrix)\u95a2\u6570\u306f\u3001[\u6df7\u540c\u884c\u5217](https://en.wikipedia.org/wiki/Confusion_matrix)\u3092\u8a08\u7b97\u3059\u308b\u3053\u3068\u306b\u3088\u3063\u3066\u5206\u985e\u7cbe\u5ea6\u3092\u8a55\u4fa1\u3057\u307e\u3059\u3002\n\u5b9a\u7fa9\u4e0a\u3001\u6df7\u540c\u884c\u5217\u306e\u30a8\u30f3\u30c8\u30ea $i,j$ \u306f\u3001\u30b0\u30eb\u30fc\u30d7 $i$ \u306e\u5b9f\u969b\u306e\u89b3\u6e2c\u6570\u3067\u3059\u304c\u3001\u30b0\u30eb\u30fc\u30d7 $j$ \u306b\u5c5e\u3059\u308b\u3068\u4e88\u6e2c\u3055\u308c\u307e\u3059\u3002 \u6b21\u306b\u4f8b\u3092\u793a\u3057\u307e\u3059\u3002\n\n```python\n>>> from sklearn.metrics import confusion_matrix\n>>> y_true = [2, 0, 2, 2, 0, 1]\n>>> y_pred = [0, 0, 2, 2, 0, 2]\n>>> confusion_matrix(y_true, y_pred)\narray([[2, 0, 0],\n       [0, 0, 1],\n       [1, 0, 2]])\n```\n\n\u3053\u306e\u3088\u3046\u306a\u6df7\u540c\u884c\u5217\u3092\u8996\u899a\u7684\u306b\u8868\u3057\u305f\u3082\u306e\u3067\u3059\uff08\u3053\u306e\u56f3\u306f[\u6df7\u540c\u884c\u5217](http://scikit-learn.org/0.18/auto_examples/model_selection/plot_confusion_matrix.html#sphx-glr-auto-examples-model-selection-plot-confusion-matrix-py)\u306e\u4f8b\u3067\u3059\uff09\u3002\n\n![](http://scikit-learn.org/0.18/_images/sphx_glr_plot_confusion_matrix_0011.png)\n\n\u30d0\u30a4\u30ca\u30ea\u306e\u554f\u984c\u306b\u3064\u3044\u3066\u306f\u3001\u4ee5\u4e0b\u306e\u3088\u3046\u306b\u3001\u771f\u9670\u6027\u3001\u507d\u967d\u6027\u3001\u507d\u9670\u6027\u304a\u3088\u3073\u771f\u967d\u6027\u306e\u30ab\u30a6\u30f3\u30c8\u3092\u5f97\u308b\u3053\u3068\u304c\u3067\u304d\u307e\u3059\u3002\n\n  - \u4f8b\uff1a\n    - \u6df7\u540c\u884c\u5217\u3092\u4f7f\u7528\u3057\u3066\u5206\u985e\u5b50\u306e\u51fa\u529b\u54c1\u8cea\u3092\u8a55\u4fa1\u3059\u308b\u4f8b\u306b\u3064\u3044\u3066\u306f\u3001\u300c[\u6df7\u540c\u884c\u5217](http://scikit-learn.org/0.18/auto_examples/model_selection/plot_confusion_matrix.html#sphx-glr-auto-examples-model-selection-plot-confusion-matrix-py)\u300d\u3092\u53c2\u7167\u3057\u3066\u304f\u3060\u3055\u3044\u3002\n    - \u624b\u66f8\u304d\u6570\u5b57\u3092\u5206\u985e\u3059\u308b\u305f\u3081\u306b\u6df7\u540c\u884c\u5217\u3092\u4f7f\u7528\u3059\u308b\u4f8b\u306b\u3064\u3044\u3066\u306f\u3001[\u624b\u66f8\u304d\u6570\u5b57\u306e\u8a8d\u8b58](http://scikit-learn.org/0.18/auto_examples/classification/plot_digits_classification.html#sphx-glr-auto-examples-classification-plot-digits-classification-py)\u3092\u53c2\u7167\u3057\u3066\u304f\u3060\u3055\u3044\u3002\n    - \u6df7\u540c\u884c\u5217\u3092\u4f7f\u7528\u3057\u3066\u30c6\u30ad\u30b9\u30c8\u6587\u66f8\u3092\u5206\u985e\u3059\u308b\u4f8b\u306b\u3064\u3044\u3066\u306f\u3001[\u30b9\u30d1\u30fc\u30b9\u95a2\u6570\u3092\u4f7f\u7528\u3057\u305f\u30c6\u30ad\u30b9\u30c8\u6587\u66f8\u306e\u5206\u985e](http://scikit-learn.org/0.18/auto_examples/text/document_classification_20newsgroups.html#sphx-glr-auto-examples-text-document-classification-20newsgroups-py)\u3092\u53c2\u7167\u3057\u3066\u304f\u3060\u3055\u3044\u3002\n\n### 3.3.2.5. \u5206\u985e\u30ec\u30dd\u30fc\u30c8\n\n[classification_report](http://scikit-learn.org/0.18/modules/generated/sklearn.metrics.classification_report.html#sklearn.metrics.classification_report) \u95a2\u6570\u306f\u3001\u4e3b\u8981\u5206\u985e\u30e1\u30c8\u30ea\u30c3\u30af\u3092\u793a\u3059\u30c6\u30ad\u30b9\u30c8\u30ec\u30dd\u30fc\u30c8\u3092\u4f5c\u6210\u3057\u307e\u3059\u3002 \u30ab\u30b9\u30bf\u30e0 `target_names` \u3068\u63a8\u5b9a\u30e9\u30d9\u30eb\u306e\u5c0f\u3055\u306a\u4f8b\u3092\u6b21\u306b\u793a\u3057\u307e\u3059\u3002\n\n```pycon\n>>> from sklearn.metrics import classification_report\n>>> y_true = [0, 1, 2, 2, 0]\n>>> y_pred = [0, 0, 2, 1, 0]\n>>> target_names = ['class 0', 'class 1', 'class 2']\n>>> print(classification_report(y_true, y_pred, target_names=target_names))\n             precision    recall  f1-score   support\n\n    class 0       0.67      1.00      0.80         2\n    class 1       0.00      0.00      0.00         1\n    class 2       1.00      0.50      0.67         2\n\navg / total       0.67      0.60      0.59         5\n```\n\n  - \u4f8b\uff1a\n    - \u624b\u66f8\u304d\u6570\u5b57\u306e\u5206\u985e\u30ec\u30dd\u30fc\u30c8\u306e\u4f7f\u7528\u4f8b\u306b\u3064\u3044\u3066\u306f\u3001[\u624b\u66f8\u304d\u6570\u5b57\u306e\u8a8d\u8b58](http://scikit-learn.org/0.18/auto_examples/classification/plot_digits_classification.html#sphx-glr-auto-examples-classification-plot-digits-classification-py)\u3092\u53c2\u7167\u3057\u3066\u304f\u3060\u3055\u3044\u3002\n    - \u30c6\u30ad\u30b9\u30c8\u6587\u66f8\u306e\u5206\u985e\u30ec\u30dd\u30fc\u30c8\u306e\u4f7f\u7528\u4f8b\u306b\u3064\u3044\u3066\u306f\u3001[\u30b9\u30d1\u30fc\u30b9\u95a2\u6570\u3092\u4f7f\u7528\u3057\u305f\u30c6\u30ad\u30b9\u30c8\u6587\u66f8\u306e\u5206\u985e](http://scikit-learn.org/0.18/auto_examples/text/document_classification_20newsgroups.html#sphx-glr-auto-examples-text-document-classification-20newsgroups-py)\u3092\u53c2\u7167\u3057\u3066\u304f\u3060\u3055\u3044\u3002\n    - \u30cd\u30b9\u30c8\u3055\u308c\u305f\u76f8\u4e92\u691c\u8a3c\u306b\u3088\u308b\u30b0\u30ea\u30c3\u30c9\u691c\u7d22\u306e\u5206\u985e\u30ec\u30dd\u30fc\u30c8\u306e\u4f7f\u7528\u4f8b\u306b\u3064\u3044\u3066\u306f\u3001[\u76f8\u4e92\u691c\u8a3c\u4ed8\u304d\u30b0\u30ea\u30c3\u30c9\u691c\u7d22\u3092\u4f7f\u7528\u3057\u305f\u30d1\u30e9\u30e1\u30fc\u30bf\u63a8\u5b9a](http://scikit-learn.org/0.18/auto_examples/model_selection/grid_search_digits.html#sphx-glr-auto-examples-model-selection-grid-search-digits-py)\u3092\u53c2\u7167\u3057\u3066\u304f\u3060\u3055\u3044\u3002\n\n### 3.3.2.6. \u30cf\u30df\u30f3\u30b0\u640d\u5931\n\n[hamming_loss](http://scikit-learn.org/0.18/modules/generated/sklearn.metrics.hamming_loss.html#sklearn.metrics.hamming_loss)\u306f\u30012\u7d44\u306e\u30b5\u30f3\u30d7\u30eb\u9593\u306e\u5e73\u5747\u30cf\u30df\u30f3\u30b0\u640d\u5931\u307e\u305f\u306f\u30cf\u30df\u30f3\u30b0\u8ddd\u96e2\u3092\u8a08\u7b97\u3057\u307e\u3059\u3002\n $\\hat{y}_j$ \u304c\u4e0e\u3048\u3089\u308c\u305f\u30b5\u30f3\u30d7\u30eb\u306e $j$ \u756a\u76ee\u306e\u30e9\u30d9\u30eb\u306e\u4e88\u6e2c\u5024\u3067\u3042\u308b\u5834\u5408\u3001 $y_j$ \u306f\u5bfe\u5fdc\u3059\u308b\u771f\u306e\u5024\u3067\u3042\u308a\u3001$n_\\text{labels}$ \u306f\u30af\u30e9\u30b9\u307e\u305f\u306f\u30e9\u30d9\u30eb\u306e\u6570\u3067\u3042\u308a\u3001\u30cf\u30df\u30f3\u30b0\u640d\u5931 $L_{Hamming}$ \u306f\u3001\u4ee5\u4e0b\u306e\u3088\u3046\u306b\u5b9a\u7fa9\u3055\u308c\u308b\u3002\n\n```math\nL_{Hamming}(y, \\hat{y}) = \\frac{1}{n_\\text{labels}} \\sum_{j=0}^{n_\\text{labels} - 1} 1(\\hat{y}_j \\not= y_j)\n```\n\n\u3053\u3053\u3067\u3001 $1(x)$ \u306f[\u6307\u6a19\u95a2\u6570](https://en.wikipedia.org/wiki/Indicator_function)\u3067\u3059\u3002\n\n```python\n>>> from sklearn.metrics import hamming_loss\n>>> y_pred = [1, 2, 3, 4]\n>>> y_true = [2, 2, 3, 4]\n>>> hamming_loss(y_true, y_pred)\n0.25\n```\n\n\u30d0\u30a4\u30ca\u30ea\u30e9\u30d9\u30eb\u30a4\u30f3\u30b8\u30b1\u30fc\u30bf\u3092\u4f7f\u7528\u3057\u305f\u30de\u30eb\u30c1\u30e9\u30d9\u30eb\u306e\u5834\u5408\uff1a\n\n```python\n>>>\n>>> hamming_loss(np.array([[0, 1], [1, 1]]), np.zeros((2, 2)))\n0.75\n```\n\n**\uff08\u6ce8\uff09** \u30de\u30eb\u30c1\u30af\u30e9\u30b9\u5206\u985e\u3067\u306f\u3001\u30cf\u30df\u30f3\u30b0\u640d\u5931\u306f\u3001 [\u30bc\u30ed\u30ef\u30f3\u640d\u5931](#33213-%E3%82%BC%E3%83%AD1%E3%81%A4%E3%81%AE%E6%90%8D%E5%A4%B1) \u95a2\u6570\u306b\u985e\u4f3c\u3059\u308b `y_true` \u3068 `y_pred` \u306e\u9593\u306e\u30cf\u30df\u30f3\u30b0\u8ddd\u96e2\u306b\u5bfe\u5fdc\u3057\u307e\u3059\u3002\u3057\u304b\u3057\u30011\u5bfe1\u306e\u640d\u5931\u306f\u3001\u771f\u306e\u30bb\u30c3\u30c8\u306b\u53b3\u5bc6\u306b\u4e00\u81f4\u3057\u306a\u3044\u4e88\u6e2c\u30bb\u30c3\u30c8\u306b\u30da\u30ca\u30eb\u30c6\u30a3\u3092\u8ab2\u3059\u304c\u3001\u30cf\u30df\u30f3\u30b0\u640d\u5931\u306f\u500b\u3005\u306e\u30e9\u30d9\u30eb\u306b\u4e0d\u5229\u76ca\u3092\u3082\u305f\u3089\u3059\u3002\u3057\u305f\u304c\u3063\u3066\u3001\u30bc\u30ed1\u306e\u640d\u5931\u306b\u3088\u3063\u3066\u4e0a\u9650\u304c\u6c7a\u5b9a\u3055\u308c\u308b\u30cf\u30df\u30f3\u30b0\u640d\u5931\u306f\u3001\u5e38\u306b0\u30681\u3068\u306e\u9593\u3067\u3042\u308a\u3001\u771f\u306e\u30e9\u30d9\u30eb\u306e\u9069\u5207\u306a\u30b5\u30d6\u30bb\u30c3\u30c8\u307e\u305f\u306f\u30b9\u30fc\u30d1\u30fc\u30bb\u30c3\u30c8\u3092\u4e88\u6e2c\u3059\u308b\u3053\u3068\u306f\u3001\u30bc\u30ed\u30681\u3068\u306e\u9593\u306e\u30cf\u30df\u30f3\u30b0\u640d\u5931\u3092\u6392\u9664\u3059\u308b\u3053\u3068\u306b\u306a\u308b\u3002\n\n### 3.3.2.7. \u30b8\u30e3\u30ab\u30fc\u30c9\u985e\u4f3c\u6027\u4fc2\u6570\u30b9\u30b3\u30a2\n\n[jaccard_similarity_score](http://scikit-learn.org/0.18/modules/generated/sklearn.metrics.jaccard_similarity_score.html#sklearn.metrics.jaccard_similarity_score) \u95a2\u6570\u306f\u3001\u30da\u30a2\u306e\u30e9\u30d9\u30eb\u30bb\u30c3\u30c8\u9593\u306eJaccard\u30a4\u30f3\u30c7\u30c3\u30af\u30b9\u3068\u3082\u547c\u3070\u308c\u308b [Jaccard\u985e\u4f3c\u6027\u4fc2\u6570](https://en.wikipedia.org/wiki/Jaccard_index) \u306e\u5e73\u5747\uff08\u30c7\u30d5\u30a9\u30eb\u30c8\uff09\u307e\u305f\u306f\u5408\u8a08\u3092\u8a08\u7b97\u3057\u307e\u3059\u3002\n\u5b9f\u6e2c\u5024\u30e9\u30d9\u30eb\u30bb\u30c3\u30c8 $y_i$ \u3068\u4e88\u6e2c\u30e9\u30d9\u30eb\u30bb\u30c3\u30c8 $\\hat{y}_i$ \u3092\u6301\u3064 $i$ \u756a\u76ee\u306e\u30b5\u30f3\u30d7\u30eb\u306eJaccard\u985e\u4f3c\u5ea6\u4fc2\u6570\u306f\u3001\u6b21\u306e\u3088\u3046\u306b\u5b9a\u7fa9\u3055\u308c\u307e\u3059\u3002\n\n```math\nJ(y_i, \\hat{y}_i) = \\frac{|y_i \\cap \\hat{y}_i|}{|y_i \\cup \\hat{y}_i|}.\n```\n\n\u30d0\u30a4\u30ca\u30ea\u304a\u3088\u3073\u30de\u30eb\u30c1\u30af\u30e9\u30b9\u5206\u985e\u3067\u306f\u3001Jaccard\u985e\u4f3c\u5ea6\u4fc2\u6570\u30b9\u30b3\u30a2\u306f\u5206\u985e\u7cbe\u5ea6\u306b\u7b49\u3057\u3044\u3002\n\n```python\n>>> import numpy as np\n>>> from sklearn.metrics import jaccard_similarity_score\n>>> y_pred = [0, 2, 1, 3]\n>>> y_true = [0, 1, 2, 3]\n>>> jaccard_similarity_score(y_true, y_pred)\n0.5\n>>> jaccard_similarity_score(y_true, y_pred, normalize=False)\n2\n```\n\n\u30d0\u30a4\u30ca\u30ea\u30e9\u30d9\u30eb\u30a4\u30f3\u30b8\u30b1\u30fc\u30bf\u3092\u4f7f\u7528\u3057\u305f\u30de\u30eb\u30c1\u30e9\u30d9\u30eb\u306e\u5834\u5408\uff1a\n\n```python\n>>>\n>>> jaccard_similarity_score(np.array([[0, 1], [1, 1]]), np.ones((2, 2)))\n0.75\n```\n\n### 3.3.2.8. \u9069\u5408\u7387\u3001\u518d\u73fe\u7387\u3001F-\u5024(F-measure)\n\n\u76f4\u89b3\u7684\u306b\u306f\u3001[\u9069\u5408\u7387](https://en.wikipedia.org/wiki/Precision_and_recall#Precision) \u306f\u3001\u5206\u985e\u5668\u304c\u5426\u5b9a\u7684\u306a\u30b5\u30f3\u30d7\u30eb\u3092\u967d\u6027\u3068\u30e9\u30d9\u30eb\u4ed8\u3051\u3057\u306a\u3044\u3088\u3046\u306b\u3059\u308b\u80fd\u529b\u3067\u3042\u308a\u3001[\u518d\u73fe\u7387](https://en.wikipedia.org/wiki/Precision_and_recall#Recall)\u306f\u3001\u5206\u985e\u5668\u304c\u3059\u3079\u3066\u306e\u967d\u6027\u30b5\u30f3\u30d7\u30eb\u3092\u898b\u3064\u3051\u308b\u80fd\u529b\u3067\u3042\u308b\u3002\nF-\u5024\uff08 $F_\u03b2$ \u304a\u3088\u3073 $F\\_1$ measures\uff09\u306f\u3001\u9069\u5408\u7387\u304a\u3088\u3073\u518d\u73fe\u7387\u306e\u52a0\u91cd\u8abf\u548c\u5e73\u5747\u3068\u3057\u3066\u89e3\u91c8\u3059\u308b\u3053\u3068\u304c\u3067\u304d\u307e\u3059\u3002 $\\beta = 1$ \u306e\u5834\u5408\u3001$F_\\beta$ \u3068 $F\\_1$ \u306f\u7b49\u4fa1\u3067\u3042\u308a\u3001\u518d\u73fe\u7387\u3068\u9069\u5408\u7387\u306f\u540c\u3058\u3088\u3046\u306b\u91cd\u8981\u3067\u3059\u3002\n[precision_recall_curve](http://scikit-learn.org/0.18/modules/generated/sklearn.metrics.precision_recall_curve.html#sklearn.metrics.precision_recall_curve) \u306f\u3001\u771f\u7406\u5024\u30e9\u30d9\u30eb\u304b\u3089\u306e\u9069\u5408\u7387-\u518d\u73fe\u7387\u30ab\u30fc\u30d6\u3068\u3001\u5224\u5b9a\u95be\u5024\u3092\u5909\u5316\u3055\u305b\u308b\u3053\u3068\u306b\u3088\u3063\u3066\u5206\u985e\u5668\u306b\u3088\u3063\u3066\u4e0e\u3048\u3089\u308c\u305f\u30b9\u30b3\u30a2\u3092\u8a08\u7b97\u3059\u308b\u3002\n[average_precision_score](http://scikit-learn.org/0.18/modules/generated/sklearn.metrics.average_precision_score.html#sklearn.metrics.average_precision_score) \u95a2\u6570\u306f\u3001\u4e88\u6e2c\u30b9\u30b3\u30a2\u304b\u3089\u5e73\u5747\u9069\u5408\u7387\uff08AP\uff09\u3092\u8a08\u7b97\u3057\u307e\u3059\u3002\u3053\u306e\u30b9\u30b3\u30a2\u306f\u3001\u9069\u5408\u7387 - \u518d\u73fe\u7387\u66f2\u7dda\u4e0b\u306e\u9762\u7a4d\u306b\u76f8\u5f53\u3057\u307e\u3059\u3002\u5024\u306f0\u30681\u306e\u9593\u3067\u3042\u308a\u3001\u3088\u308a\u9ad8\u3044\u65b9\u304c\u826f\u3044\u3067\u3059\u3002\u30e9\u30f3\u30c0\u30e0\u4e88\u6e2c\u3067\u306f\u3001AP\u306f\u6b63\u306e\u30b5\u30f3\u30d7\u30eb\u306e\u5272\u5408\u3067\u3059\u3002\n\n\u3044\u304f\u3064\u304b\u306e\u6a5f\u80fd\u3092\u4f7f\u7528\u3057\u3066,\u9069\u5408\u7387,\u518d\u73fe\u7387,F-\u5024 \u306e\u30b9\u30b3\u30a2\u3092\u5206\u6790\u3059\u308b\u3053\u3068\u304c\u3067\u304d\u307e\u3059\u3002\n\n|    |    |\n|----|----|\n|average_precision_score(y_true,y_score [,...])| \u4e88\u6e2c\u30b9\u30b3\u30a2\u304b\u3089\u5e73\u5747\u9069\u5408\u7387(AP)\u3092\u8a08\u7b97\u3059\u308b|\n|f1_score(y_true,y_pred [,labels,...])| F1\u30b9\u30b3\u30a2\u3092\u8a08\u7b97\u3057\u307e\u3059\u3002\u3053\u308c\u306f\u30d0\u30e9\u30f3\u30b9F\u30b9\u30b3\u30a2\u307e\u305f\u306fF\u30e1\u30b8\u30e3\u30fc\u3068\u3082\u547c\u3070\u308c\u307e\u3059|\n|fbeta_score(y_true,y_pred,beta [,labels,...])| F\u30d9\u30fc\u30bf\u30b9\u30b3\u30a2\u3092\u8a08\u7b97\u3059\u308b|\n|precision_recall_curve(y_true,probas_pred)| \u3055\u307e\u3056\u307e\u306a\u78ba\u7387\u3057\u304d\u3044\u5024\u306b\u5bfe\u3059\u308b\u9069\u5408\u7387 - \u518d\u73fe\u7387\u306e\u30da\u30a2\u3092\u8a08\u7b97\u3059\u308b|\n|precision_recall_fscore_support(y_true,y_pred)| \u5404\u30af\u30e9\u30b9\u306e\u9069\u5408\u7387,\u518d\u73fe\u7387,F-measure\u304a\u3088\u3073\u30b5\u30dd\u30fc\u30c8\u3092\u8a08\u7b97\u3059\u308b|\n|precision_score(y_true,y_pred [,labels,...])| \u9069\u5408\u7387\u3092\u8a08\u7b97\u3059\u308b|\n|recall_score(y_true,y_pred [,labels,...])| \u518d\u73fe\u7387\u3092\u8a08\u7b97\u3059\u308b|\n\n[precision_recall_curve](http://scikit-learn.org/0.18/modules/generated/sklearn.metrics.precision_recall_curve.html#sklearn.metrics.precision_recall_curve) \u95a2\u6570\u306f\u30d0\u30a4\u30ca\u30ea\u306e\u5834\u5408\u306b\u5236\u9650\u3055\u308c\u3066\u3044\u308b\u3053\u3068\u306b\u6ce8\u610f\u3057\u3066\u304f\u3060\u3055\u3044\u3002 [average_precision_score](http://scikit-learn.org/0.18/modules/generated/sklearn.metrics.average_precision_score.html#sklearn.metrics.average_precision_score) \u95a2\u6570\u306f,\u30d0\u30a4\u30ca\u30ea\u5206\u985e\u304a\u3088\u3073\u30de\u30eb\u30c1\u30e9\u30d9\u30eb\u30a4\u30f3\u30b8\u30b1\u30fc\u30bf\u5f62\u5f0f\u3067\u306e\u307f\u6a5f\u80fd\u3057\u307e\u3059\u3002\n\n  - \u4f8b\uff1a\n    - \u30c6\u30ad\u30b9\u30c8\u6587\u66f8\u3092\u5206\u985e\u3059\u308b [f1_score](http://scikit-learn.org/0.18/modules/generated/sklearn.metrics.f1_score.html#sklearn.metrics.f1_score) \u306e\u4f7f\u7528\u4f8b\u306b\u3064\u3044\u3066\u306f\u3001[\u30b9\u30d1\u30fc\u30b9\u95a2\u6570\u3092\u4f7f\u7528\u3057\u305f\u30c6\u30ad\u30b9\u30c8\u6587\u66f8\u306e\u5206\u985e](http://scikit-learn.org/0.18/auto_examples/text/document_classification_20newsgroups.html#sphx-glr-auto-examples-text-document-classification-20newsgroups-py)\u3092\u53c2\u7167\u3057\u3066\u304f\u3060\u3055\u3044\u3002\n    - \u30cd\u30b9\u30c8\u3055\u308c\u305f\u76f8\u4e92\u691c\u8a3c\u3067\u30b0\u30ea\u30c3\u30c9\u691c\u7d22\u3092\u4f7f\u7528\u3057\u3066\u30d1\u30e9\u30e1\u30fc\u30bf\u3092\u63a8\u5b9a\u3059\u308b\u305f\u3081\u306e [precision_score](http://scikit-learn.org/0.18/modules/generated/sklearn.metrics.precision_score.html#sklearn.metrics.precision_score) \u304a\u3088\u3073 [recall_score](http://scikit-learn.org/0.18/modules/generated/sklearn.metrics.recall_score.html#sklearn.metrics.recall_score) \u306e\u4f7f\u7528\u4f8b\u306b\u3064\u3044\u3066\u306f\u3001[\u30af\u30ed\u30b9\u691c\u8a3c\u306b\u3088\u308b\u30b0\u30ea\u30c3\u30c9\u691c\u7d22\u3092\u4f7f\u7528\u3057\u305f\u30d1\u30e9\u30e1\u30fc\u30bf\u63a8\u5b9a](http://scikit-learn.org/0.18/auto_examples/model_selection/grid_search_digits.html#sphx-glr-auto-examples-model-selection-grid-search-digits-py) \u3092\u53c2\u7167\u3057\u3066\u304f\u3060\u3055\u3044\u3002\n    - \u5206\u985e\u5668\u306e\u51fa\u529b\u54c1\u8cea\u3092\u8a55\u4fa1\u3059\u308b\u305f\u3081\u306e [precision_recall_curve](http://scikit-learn.org/0.18/modules/generated/sklearn.metrics.precision_recall_curve.html#sklearn.metrics.precision_recall_curve) \u306e\u4f7f\u7528\u4f8b\u306b\u3064\u3044\u3066\u306f\u3001[Precision-Recall](http://scikit-learn.org/0.18/auto_examples/model_selection/plot_precision_recall.html#sphx-glr-auto-examples-model-selection-plot-precision-recall-py) \u3092\u53c2\u7167\u3057\u3066\u304f\u3060\u3055\u3044\u3002\n    - \u30b9\u30d1\u30fc\u30b9\u7dda\u5f62\u30e2\u30c7\u30eb\u306e\u30d5\u30a3\u30fc\u30c1\u30e3\u3092\u9078\u629e\u3059\u308b\u305f\u3081\u306e [precision_recall_curve](http://scikit-learn.org/0.18/modules/generated/sklearn.metrics.precision_recall_curve.html#sklearn.metrics.precision_recall_curve) \u306e\u4f7f\u7528\u4f8b\u306b\u3064\u3044\u3066\u306f\u3001[\u30b9\u30d1\u30fc\u30b9\u30ea\u30cb\u30a2\u30e2\u30c7\u30eb\u306e\u30b9\u30d1\u30fc\u30b9\u30ea\u30ab\u30d0\u30ea\uff1a\u30d5\u30a3\u30fc\u30c1\u30e3\u9078\u629e](http://scikit-learn.org/0.18/auto_examples/linear_model/plot_sparse_recovery.html#sphx-glr-auto-examples-linear-model-plot-sparse-recovery-py) \u3092\u53c2\u7167\u3057\u3066\u304f\u3060\u3055\u3044\u3002\n\n|  |  |\n|-----|------|\n|average_precision_score(y_true,y_score [,...])|\u4e88\u6e2c\u30b9\u30b3\u30a2\u304b\u3089\u5e73\u5747\u7cbe\u5ea6(AP)\u3092\u8a08\u7b97\u3059\u308b|\n|f1_score(y_true,y_pred [,labels,...])|F1\u30b9\u30b3\u30a2\u3092\u8a08\u7b97\u3057\u307e\u3059\u3002\u3053\u308c\u306f\u30d0\u30e9\u30f3\u30b9F\u30b9\u30b3\u30a2\u307e\u305f\u306fF\u30e1\u30b8\u30e3\u30fc\u3068\u3082\u547c\u3070\u308c\u307e\u3059|\n|fbeta_score(y_true,y_pred,beta [,labels,...])|F\u30d9\u30fc\u30bf\u30b9\u30b3\u30a2\u3092\u8a08\u7b97\u3059\u308b|\n|precision_recall_curve(y_true,probas_pred)|\u3055\u307e\u3056\u307e\u306a\u78ba\u7387\u306e\u3057\u304d\u3044\u5024\u306b\u5bfe\u3059\u308b\u9069\u5408\u7387 - \u518d\u73fe\u7387\u306e\u30da\u30a2\u3092\u8a08\u7b97\u3059\u308b|\n|precision_recall_fscore_support(y_true,y_pred)|\u5404\u30af\u30e9\u30b9\u306e\u9069\u5408\u7387,\u518d\u73fe\u7387,F\u5024\u304a\u3088\u3073\u30b5\u30dd\u30fc\u30c8\u3092\u8a08\u7b97\u3059\u308b|\n|precision_score(y_true,y_pred [,labels,...])|\u9069\u5408\u7387\u3092\u8a08\u7b97\u3059\u308b|\n|recall_score(y_true,y_pred [,labels,...])|\u518d\u73fe\u7387\u3092\u8a08\u7b97\u3059\u308b|\n|precision_recall_curve\u95a2\u6570\u306f\u30d0\u30a4\u30ca\u30ea\u306e\u5834\u5408\u306b\u5236\u9650\u3055\u308c\u3066\u3044\u308b\u3053\u3068\u306b\u6ce8\u610f\u3057\u3066\u304f\u3060\u3055\u3044\u3002 |average_precision_score\u95a2\u6570\u306f,\u30d0\u30a4\u30ca\u30ea\u5206\u985e\u304a\u3088\u3073\u30de\u30eb\u30c1\u30e9\u30d9\u30eb\u30a4\u30f3\u30b8\u30b1\u30fc\u30bf\u5f62\u5f0f\u3067\u306e\u307f\u6a5f\u80fd\u3057\u307e\u3059\u3002|\n\nprecision_recall_curve\u95a2\u6570\u306f\u30d0\u30a4\u30ca\u30ea\u306e\u5834\u5408\u306b\u5236\u9650\u3055\u308c\u3066\u3044\u308b\u3053\u3068\u306b\u6ce8\u610f\u3057\u3066\u304f\u3060\u3055\u3044\u3002 average_precision_score\u95a2\u6570\u306f\u3001\u30d0\u30a4\u30ca\u30ea\u5206\u985e\u304a\u3088\u3073\u30de\u30eb\u30c1\u30e9\u30d9\u30eb\u30a4\u30f3\u30b8\u30b1\u30fc\u30bf\u5f62\u5f0f\u3067\u306e\u307f\u6a5f\u80fd\u3057\u307e\u3059\u3002\n\u4f8b\uff1a\n\u30c6\u30ad\u30b9\u30c8\u6587\u66f8\u3092\u5206\u985e\u3059\u308bf1_score\u306e\u4f7f\u7528\u4f8b\u306b\u3064\u3044\u3066\u306f\u3001\u30b9\u30d1\u30fc\u30b9\u95a2\u6570\u3092\u4f7f\u7528\u3057\u305f\u30c6\u30ad\u30b9\u30c8\u6587\u66f8\u306e\u5206\u985e\u3092\u53c2\u7167\u3057\u3066\u304f\u3060\u3055\u3044\u3002\n\u30cd\u30b9\u30c8\u3055\u308c\u305f\u76f8\u4e92\u691c\u8a3c\u3067\u30b0\u30ea\u30c3\u30c9\u691c\u7d22\u3092\u4f7f\u7528\u3057\u3066\u30d1\u30e9\u30e1\u30fc\u30bf\u3092\u63a8\u5b9a\u3059\u308b\u305f\u3081\u306eprecision_score\u304a\u3088\u3073recall_score\u306e\u4f7f\u7528\u4f8b\u306b\u3064\u3044\u3066\u306f\u3001\u30af\u30ed\u30b9\u691c\u8a3c\u306b\u3088\u308b\u30b0\u30ea\u30c3\u30c9\u691c\u7d22\u3092\u4f7f\u7528\u3057\u305f\u30d1\u30e9\u30e1\u30fc\u30bf\u63a8\u5b9a\u3092\u53c2\u7167\u3057\u3066\u304f\u3060\u3055\u3044\u3002\n\u5206\u985e\u5668\u306e\u51fa\u529b\u54c1\u8cea\u3092\u8a55\u4fa1\u3059\u308b\u305f\u3081\u306eprecision_recall_curve\u306e\u4f7f\u7528\u4f8b\u306b\u3064\u3044\u3066\u306f\u3001Precision-Recall\u3092\u53c2\u7167\u3057\u3066\u304f\u3060\u3055\u3044\u3002\n\u30b9\u30d1\u30fc\u30b9\u7dda\u5f62\u30e2\u30c7\u30eb\u306e\u30d5\u30a3\u30fc\u30c1\u30e3\u3092\u9078\u629e\u3059\u308b\u305f\u3081\u306eprecision_recall_curve\u306e\u4f7f\u7528\u4f8b\u306b\u3064\u3044\u3066\u306f\u3001\u30b9\u30d1\u30fc\u30b9\u30ea\u30cb\u30a2\u30e2\u30c7\u30eb\u306e\u30b9\u30d1\u30fc\u30b9\u30ea\u30ab\u30d0\u30ea\uff1a\u30d5\u30a3\u30fc\u30c1\u30e3\u9078\u629e\u3092\u53c2\u7167\u3057\u3066\u304f\u3060\u3055\u3044\u3002\n\n#### 3.3.2.8.1. \u4e8c\u5024\u5206\u985e\n\n\u4e8c\u5024\u5206\u985e\u30bf\u30b9\u30af\u3067\u306f\u3001\u300c\u967d\u6027\u300d\u304a\u3088\u3073\u300c\u9670\u6027\u300d\u3068\u3044\u3046\u7528\u8a9e\u306f\u5206\u985e\u5668\u306e\u4e88\u6e2c\u3092\u793a\u3057\u3001\u300c\u771f\u300d\u304a\u3088\u3073\u300c\u507d\u300d\u3068\u3044\u3046\u7528\u8a9e\u306f\u3001\u305d\u306e\u4e88\u6e2c\u304c\u5916\u90e8\u306e\u5224\u65ad\u306b\u5bfe\u5fdc\u3059\u308b\u304b\u3069\u3046\u304b\u3092\u793a\u3059\u300c\u89b3\u5bdf\u300d\u3068\u3082\u547c\u3070\u308c\u308b\uff09\u3002\u3053\u308c\u3089\u306e\u5b9a\u7fa9\u304c\u4e0e\u3048\u3089\u308c\u305f\u5834\u5408\u3001\u6b21\u306e\u8868\u3092\u4f5c\u6210\u3067\u304d\u307e\u3059\u3002\n\n|  |\u5b9f\u969b\u306e\u30af\u30e9\u30b9\uff08\u89b3\u6e2c\uff09||\n|------|-------|-----|\n|\u4e88\u6e2c\u30af\u30e9\u30b9\uff08\u671f\u5f85\u5024\uff09|tp\uff08\u771f\u967d\u6027\uff09\u6b63\u3057\u3044\u7d50\u679c|fp\uff08\u507d\u967d\u6027\uff09\u4e88\u671f\u3057\u306a\u3044\u7d50\u679c|\n|               |fn\uff08\u507d\u9670\u6027\uff09\u6b20\u843d\u3057\u305f\u7d50\u679c|tn\uff08\u771f\u9670\u6027\uff09\u7d50\u679c\u304c\u6b63\u3057\u304f\u306a\u3044|\n\n\u3053\u306e\u6587\u8108\u3067\u306f\u3001\u9069\u5408\u7387\u3001\u518d\u73fe\u7387\u3001F-\u5024\u3068\u3044\u3046\u6982\u5ff5\u3092\u5b9a\u7fa9\u3059\u308b\u3053\u3068\u304c\u3067\u304d\u307e\u3059\u3002\n\n```math\n\\text{precision} = \\frac{tp}{tp + fp}, \\\\\n\\text{recall} = \\frac{tp}{tp + fn}, \\\\\nF_\\beta = (1 + \\beta^2) \\frac{\\text{precision} \\times \\text{recall}}{\\beta^2 \\text{precision} + \\text{recall}}.\n```\n\n\u4e8c\u5024\u5206\u985e\u306e\u5c0f\u3055\u306a\u4f8b\u3092\u3044\u304f\u3064\u304b\u6319\u3052\u307e\u3059\uff1a\n\n```py\n>>> from sklearn import metrics\n>>> y_pred = [0, 1, 0, 0]\n>>> y_true = [0, 1, 0, 1]\n>>> metrics.precision_score(y_true, y_pred)\n1.0\n>>> metrics.recall_score(y_true, y_pred)\n0.5\n>>> metrics.f1_score(y_true, y_pred)  \n0.66...\n>>> metrics.fbeta_score(y_true, y_pred, beta=0.5)  \n0.83...\n>>> metrics.fbeta_score(y_true, y_pred, beta=1)  \n0.66...\n>>> metrics.fbeta_score(y_true, y_pred, beta=2) \n0.55...\n>>> metrics.precision_recall_fscore_support(y_true, y_pred, beta=0.5)  \n(array([ 0.66...,  1.        ]), array([ 1. ,  0.5]), array([ 0.71...,  0.83...]), array([2, 2]...))\n\n\n>>> import numpy as np\n>>> from sklearn.metrics import precision_recall_curve\n>>> from sklearn.metrics import average_precision_score\n>>> y_true = np.array([0, 0, 1, 1])\n>>> y_scores = np.array([0.1, 0.4, 0.35, 0.8])\n>>> precision, recall, threshold = precision_recall_curve(y_true, y_scores)\n>>> precision  \narray([ 0.66...,  0.5       ,  1.        ,  1.        ])\n>>> recall\narray([ 1. ,  0.5,  0.5,  0. ])\n>>> threshold\narray([ 0.35,  0.4 ,  0.8 ])\n>>> average_precision_score(y_true, y_scores)  \n0.79...\n```\n\n#### 3.3.2.8.2. \u30de\u30eb\u30c1\u30af\u30e9\u30b9\u3068\u30de\u30eb\u30c1\u30e9\u30d9\u30eb\u306e\u5206\u985e\n\n\u30de\u30eb\u30c1\u30af\u30e9\u30b9\u304a\u3088\u3073\u30de\u30eb\u30c1\u30e9\u30d9\u30eb\u5206\u985e\u30bf\u30b9\u30af\u3067\u306f\u3001\u9069\u5408\u7387\u3001\u518d\u73fe\u7387\u3001F\u5024\u306e\u6982\u5ff5\u3092\u5404\u30e9\u30d9\u30eb\u306b\u500b\u5225\u306b\u9069\u7528\u3067\u304d\u307e\u3059\u3002\u4e0a\u8a18\u306e\u3088\u3046\u306b[average_precision_score](http://scikit-learn.org/0.18/modules/generated/sklearn.metrics.average_precision_score.html#sklearn.metrics.average_precision_score)\uff08multilabel\u306e\u307f\uff09\u3001[f1_score](http://scikit-learn.org/0.18/modules/generated/sklearn.metrics.f1_score.html#sklearn.metrics.f1_score)\u3001[fbeta_score](http://scikit-learn.org/0.18/modules/generated/sklearn.metrics.fbeta_score.html#sklearn.metrics.fbeta_score)\u3001[precision_recall_fscore_support](http://scikit-learn.org/0.18/modules/generated/sklearn.metrics.precision_recall_fscore_support.html#sklearn.metrics.precision_recall_fscore_support)\u3001[precision_score](http://scikit-learn.org/0.18/modules/generated/sklearn.metrics.precision_score.html#sklearn.metrics.precision_score)\u3001\u304a\u3088\u3073[recall_score](http://scikit-learn.org/0.18/modules/generated/sklearn.metrics.recall_score.html#sklearn.metrics.recall_score)\u95a2\u6570\u306e`average`\u5f15\u6570\u3067\u6307\u5b9a\u3055\u308c\u305f\u30e9\u30d9\u30eb\u9593\u3067\u7d50\u679c\u3092\u7d50\u5408\u3059\u308b\u306b\u306f\u3001\u3044\u304f\u3064\u304b\u306e\u65b9\u6cd5\u304c\u3042\u308a\u307e\u3059\u3002\u3059\u3079\u3066\u306e\u30e9\u30d9\u30eb\u304c\u542b\u307e\u308c\u3066\u3044\u308b\u30de\u30eb\u30c1\u30af\u30e9\u30b9\u8a2d\u5b9a\u3067\u306e \"micro\" \u5e73\u5747\u5316\u3067\u306f\u3001\u7b49\u3057\u3044\u9069\u5408\u7387\u3001\u518d\u73fe\u7387\u3001F\u5024\u304c\u751f\u6210\u3055\u308c\u307e\u3059\u304c\u3001 \"weighted\" \u5e73\u5747\u5316\u3067\u306f\u9069\u5408\u7387\u3068\u518d\u73fe\u7387\u306e\u9593\u306b\u306a\u3044F\u30b9\u30b3\u30a2\u304c\u751f\u6210\u3055\u308c\u308b\u3053\u3068\u306b\u6ce8\u610f\u3057\u3066\u304f\u3060\u3055\u3044\u3002\n\n\u3053\u308c\u3092\u3088\u308a\u660e\u793a\u7684\u306b\u3059\u308b\u306b\u306f\u3001\u6b21\u306e\u8868\u8a18\u6cd5\u3092\u691c\u8a0e\u3057\u3066\u304f\u3060\u3055\u3044\u3002\n\n  - $y$ \u306f\u4e88\u6e2c\u3055\u308c\u305f $(sample, label)$ \u306e\u30da\u30a2\u306e\u96c6\u5408\n  - $\\hat{y}$ \u306f $true(sample, label)$ \u306e\u7d44\u306e\u96c6\u5408\n  - $L$ \u306f\u30e9\u30d9\u30eb\u306e\u30bb\u30c3\u30c8\n  - $S$ \u306f\u30b5\u30f3\u30d7\u30eb\u30bb\u30c3\u30c8\n  - $y_s$ \u306fy\u306e\u30b5\u30d6\u30bb\u30c3\u30c8\u3001\u3059\u306a\u308f\u3061 $y_s := \\left\\\\\\{(s', l) \\in y | s' = s\\right\\\\\\}$\n  - $y_l$ \u306f\u30e9\u30d9\u30eb $l$ \u306e $y$ \u306e\u30b5\u30d6\u30bb\u30c3\u30c8\n  - \u540c\u69d8\u306b\u3001$\\hat{y}\\_s$ \u3068 $\\hat {y}\\_l$ \u306f $\\hat{y}$ \u306e\u30b5\u30d6\u30bb\u30c3\u30c8\u3067\u3059\n  - $P(A, B) := \\frac{\\left| A \\cap B \\right|}{\\left|A\\right|}$\n  - $R(A, B) := \\frac{\\left| A \\cap B \\right|}{\\left|B\\right|}$ (\u8868\u8a18\u898f\u5247\u306f\u3001 $B = \\emptyset$ \u306e\u53d6\u308a\u6271\u3044\u306b\u3088\u3063\u3066\u7570\u306a\u308a\u307e\u3059\u3002 \u3053\u306e\u5b9f\u88c5\u306f $R(A, B):=0$ \u3092\u4f7f\u7528\u3057\u3001 $P$ \u3082\u540c\u69d8\u3067\u3059\uff09\u3002\n  - $F_\\beta(A, B) := \\left(1 + \\beta^2\\right) \\frac{P(A, B) \\times R(A, B)}{\\beta^2 P(A, B) + R(A, B)}$\n\n\u6b21\u306b\u3001\u30e1\u30c8\u30ea\u30c3\u30af\u306f\u6b21\u306e\u3088\u3046\u306b\u5b9a\u7fa9\u3055\u308c\u307e\u3059\u3002\n\n<table>\n<thead>\n<tr><th>average</th>\n<th>Precision</th>\n<th>Recall</th>\n<th>F_beta</th>\n</tr>\n</thead>\n<tbody>\n<tr><td><code>\"micro\"</code></td> <td>$P(y, \\hat{y})$ </td> <td>$R(y, \\hat{y})$ </td> <td>$F_\\beta(y, \\hat{y})$ </td> </tr>\n<tr><td> <code>\"samples\"</code> </td>\n<td>$\\frac{1}{\\left|S\\right|} \\sum_{s \\in S} P(y_s, \\hat{y}_s)$ </td>\n<td>$\\frac{1}{\\left|S\\right|} \\sum_{s \\in S} R(y_s, \\hat{y}_s)$ </td>\n<td>$\\frac{1}{\\left|S\\right|} \\sum_{s \\in S} F_\\beta(y_s, \\hat{y}_s)$ </td>\n</tr>\n<tr><td><code>\"macro\"</code></td>\n<td>$\\frac{1}{\\left|L\\right|} \\sum_{l \\in L} P(y_l, \\hat{y}_l)$ </td>\n<td>$\\frac{1}{\\left|L\\right|} \\sum_{l \\in L} R(y_l, \\hat{y}_l)$ </td>\n<td>$\\frac{1}{\\left|L\\right|} \\sum_{l \\in L} F_\\beta(y_l, \\hat{y}_l)$ </td>\n</tr>\n<tr><td><code>\"weighted\"</code></td>\n<td>$\\frac{1}{\\sum_{l \\in L} \\left|\\hat{y}_l\\right|} \\sum_{l \\in L} \\left|\\hat{y}_l\\right| P(y_l, \\hat{y}_l)$ </td>\n<td>$\\frac{1}{\\sum_{l \\in L} \\left|\\hat{y}_l\\right|} \\sum_{l \\in L} \\left|\\hat{y}_l\\right| R(y_l, \\hat{y}_l)$ </td>\n<td>$\\frac{1}{\\sum_{l \\in L} \\left|\\hat{y}_l\\right|} \\sum_{l \\in L} \\left|\\hat{y}_l\\right| F_\\beta(y_l, \\hat{y}_l)$ </td>\n</tr>\n<tr><td><code>None</code></td>\n<td>$\\langle P(y_l, \\hat{y}_l) | l \\in L \\rangle$ </td>\n<td>$\\langle R(y_l, \\hat{y}_l) | l \\in L \\rangle$ </td>\n<td>$\\langle F_\\beta(y_l, \\hat{y}_l) | l \\in L \\rangle$ </td>\n</tr>\n</tbody>\n</table>\n\n\n```python\n>>> from sklearn import metrics\n>>> y_true = [0, 1, 2, 0, 1, 2]\n>>> y_pred = [0, 2, 1, 0, 0, 1]\n>>> metrics.precision_score(y_true, y_pred, average='macro')  \n0.22...\n>>> metrics.recall_score(y_true, y_pred, average='micro')\n... \n0.33...\n>>> metrics.f1_score(y_true, y_pred, average='weighted')  \n0.26...\n>>> metrics.fbeta_score(y_true, y_pred, average='macro', beta=0.5)  \n0.23...\n>>> metrics.precision_recall_fscore_support(y_true, y_pred, beta=0.5, average=None)\n... \n(array([ 0.66...,  0.        ,  0.        ]), array([ 1.,  0.,  0.]), array([ 0.71...,  0.        ,  0.        ]), array([2, 2, 2]...))\n```\n\n\u300c\u30cd\u30ac\u30c6\u30a3\u30d6\u30af\u30e9\u30b9\u300d\u3092\u542b\u3080\u30de\u30eb\u30c1\u30af\u30e9\u30b9\u5206\u985e\u3067\u306f\u3001\u3044\u304f\u3064\u304b\u306e\u30e9\u30d9\u30eb\u3092\u9664\u5916\u3059\u308b\u3053\u3068\u304c\u3067\u304d\u307e\u3059\u3002\n\n```python\n>>>\n>>> metrics.recall_score(y_true, y_pred, labels=[1, 2], average='micro')\n... # excluding 0, no labels were correctly recalled\n0.0\n```\n\n\u540c\u69d8\u306b\u3001\u30c7\u30fc\u30bf\u30b5\u30f3\u30d7\u30eb\u4e2d\u306b\u5b58\u5728\u3057\u306a\u3044\u30e9\u30d9\u30eb\u306f\u3001\u30de\u30af\u30ed\u5e73\u5747\u5316\u306b\u304a\u3044\u3066\u8aac\u660e\u3055\u308c\u5f97\u308b\u3002\n\n```python\n>>>\n>>> metrics.precision_score(y_true, y_pred, labels=[0, 1, 2, 3], average='macro')\n... \n0.166...\n```\n\n### 3.3.2.9. \u30d2\u30f3\u30b8\u640d\u5931\n\n[hinge_loss](http://scikit-learn.org/0.18/modules/generated/sklearn.metrics.hinge_loss.html#sklearn.metrics.hinge_loss) \u95a2\u6570\u306f\u3001\u4e88\u6e2c\u8aa4\u5dee\u306e\u307f\u3092\u8003\u616e\u3059\u308b\u7247\u5074\u30e1\u30c8\u30ea\u30c3\u30af\u3067\u3042\u308b [\u30d2\u30f3\u30b8\u640d\u5931](https://en.wikipedia.org/wiki/Hinge_loss) \u3092\u4f7f\u7528\u3057\u3066\u3001\u30e2\u30c7\u30eb\u3068\u30c7\u30fc\u30bf\u9593\u306e\u5e73\u5747\u8ddd\u96e2\u3092\u8a08\u7b97\u3057\u307e\u3059\u3002 \uff08\u30d2\u30f3\u30b8\u640d\u5931\u306f\u3001\u30b5\u30dd\u30fc\u30c8\u30d9\u30af\u30bf\u30fc\u30de\u30b7\u30f3\u306a\u3069\u306e\u6700\u5927\u30de\u30fc\u30b8\u30f3\u5206\u985e\u5668\u3067\u4f7f\u7528\u3055\u308c\u307e\u3059\uff09\u3002\n\u30e9\u30d9\u30eb\u304c+1\u304a\u3088\u3073-1\u3067\u30a8\u30f3\u30b3\u30fc\u30c9\u3055\u308c\u3066\u3044\u308b\u5834\u5408\u3001$y\uff1a$ \u306f\u771f\u306e\u5024\u3067\u3042\u308a\u3001 $w$ \u306f `decision_function` \u306e\u51fa\u529b\u3068\u3057\u3066\u306e\u4e88\u6e2c\u3055\u308c\u305f\u6c7a\u5b9a\u3067\u3042\u308a\u3001\u30d2\u30f3\u30b8\u640d\u5931\u306f\u6b21\u306e\u3088\u3046\u306b\u5b9a\u7fa9\u3055\u308c\u307e\u3059\u3002\n\n```math\nL_\\text{Hinge}(y, w) = \\max\\left\\{1 - wy, 0\\right\\} = \\left|1 - wy\\right|_+\n```\n\n2\u3064\u4ee5\u4e0a\u306e\u30e9\u30d9\u30eb\u304c\u3042\u308b\u5834\u5408\u3001hinge_loss\u306fCrammer\uff06Singer\u306e\u305f\u3081\u306b\u30de\u30eb\u30c1\u30af\u30e9\u30b9\u306e\u5909\u5f62\u3092\u4f7f\u7528\u3057\u307e\u3059\u3002[\u3053\u3053\u306b\u305d\u308c\u3092\u8a18\u8ff0\u3059\u308b\u8ad6\u6587\u304c\u3042\u308a\u307e\u3059](http://jmlr.csail.mit.edu/papers/volume2/crammer01a/crammer01a.pdf)\u3002\n$y_w$ \u304c\u771f\u306e\u30e9\u30d9\u30eb\u306e\u4e88\u6e2c\u3055\u308c\u305f\u6c7a\u5b9a\u3067\u3042\u308a\u3001 $y_t$ \u304c\u3001\u6c7a\u5b9a\u95a2\u6570\u306b\u3088\u3063\u3066\u4e88\u6e2c\u3055\u308c\u305f\u6c7a\u5b9a\u304c\u51fa\u529b\u3055\u308c\u308b\u4ed6\u306e\u3059\u3079\u3066\u306e\u30e9\u30d9\u30eb\u306e\u4e88\u6e2c\u3055\u308c\u305f\u6c7a\u5b9a\u306e\u6700\u5927\u5024\u3067\u3042\u308b\u5834\u5408\u3001\u30de\u30eb\u30c1\u30af\u30e9\u30b9\u30d2\u30f3\u30b8\u640d\u5931\u306f\u3001\n\n```math\nL_\\text{Hinge}(y_w, y_t) = \\max\\left\\{1 + y_t - y_w, 0\\right\\}\n```\n\n\u3053\u3053\u3067\u306f\u3001\u30d0\u30a4\u30ca\u30ea\u30af\u30e9\u30b9\u306e\u554f\u984c\u3067svm\u5206\u985e\u5668\u3067hinge_loss\u95a2\u6570\u3092\u4f7f\u7528\u3059\u308b\u65b9\u6cd5\u3092\u793a\u3059\u5c0f\u3055\u306a\u4f8b\u3092\u793a\u3057\u307e\u3059\u3002\n\n```python\n>>> from sklearn import svm\n>>> from sklearn.metrics import hinge_loss\n>>> X = [[0], [1]]\n>>> y = [-1, 1]\n>>> est = svm.LinearSVC(random_state=0)\n>>> est.fit(X, y)\nLinearSVC(C=1.0, class_weight=None, dual=True, fit_intercept=True,\n     intercept_scaling=1, loss='squared_hinge', max_iter=1000,\n     multi_class='ovr', penalty='l2', random_state=0, tol=0.0001,\n     verbose=0)\n>>> pred_decision = est.decision_function([[-2], [3], [0.5]])\n>>> pred_decision  \narray([-2.18...,  2.36...,  0.09...])\n>>> hinge_loss([-1, 1, 1], pred_decision)  \n0.3...\n\n```\n\n\u591a\u30af\u30e9\u30b9\u306e\u554f\u984c\u3067\u3001svm\u5206\u985e\u5668\u3067hinge_loss\u95a2\u6570\u3092\u4f7f\u7528\u3059\u308b\u4f8b\u3092\u4ee5\u4e0b\u306b\u793a\u3057\u307e\u3059:\n\n```python\n>>>\n>>> X = np.array([[0], [1], [2], [3]])\n>>> Y = np.array([0, 1, 2, 3])\n>>> labels = np.array([0, 1, 2, 3])\n>>> est = svm.LinearSVC()\n>>> est.fit(X, Y)\nLinearSVC(C=1.0, class_weight=None, dual=True, fit_intercept=True,\n     intercept_scaling=1, loss='squared_hinge', max_iter=1000,\n     multi_class='ovr', penalty='l2', random_state=None, tol=0.0001,\n     verbose=0)\n>>> pred_decision = est.decision_function([[-1], [2], [3]])\n>>> y_true = [0, 2, 3]\n>>> hinge_loss(y_true, pred_decision, labels)  \n0.56...\n```\n\n### 3.3.2.10. \u30ed\u30b0\u640d\u5931\n\n\u30ed\u30b8\u30b9\u30c6\u30a3\u30c3\u30af\u56de\u5e30\u30ed\u30b9\u307e\u305f\u306f\u30af\u30ed\u30b9\u30a8\u30f3\u30c8\u30ed\u30d4\u30fc\u30ed\u30b9\u3068\u3082\u547c\u3070\u308c\u308b\u30ed\u30b0\u640d\u5931\u306f\u3001\u78ba\u7387\u63a8\u5b9a\u3067\u5b9a\u7fa9\u3055\u308c\u307e\u3059\u3002\u3053\u308c\u306f\u3001\uff08\u591a\u9805\u5f0f\uff09\u30ed\u30b8\u30b9\u30c6\u30a3\u30c3\u30af\u56de\u5e30\u304a\u3088\u3073\u30cb\u30e5\u30fc\u30e9\u30eb\u30cd\u30c3\u30c8\u30ef\u30fc\u30af\u306a\u3089\u3073\u306b\u4e88\u60f3\u6700\u5927\u5316\u306e\u3044\u304f\u3064\u304b\u306e\u5909\u5f62\u4f8b\u3067\u4e00\u822c\u7684\u306b\u4f7f\u7528\u3055\u308c\u3001\u96e2\u6563\u7684\u4e88\u6e2c\u306e\u4ee3\u308f\u308a\u306b\u5206\u985e\u5668\u306e\u78ba\u7387\u51fa\u529b\uff08`predict_proba`\uff09\u3092\u8a55\u4fa1\u3059\u308b\u305f\u3081\u306b\u4f7f\u7528\u3059\u308b\u3053\u3068\u304c\u3067\u304d\u308b\u3002\n\n\u771f\u306e\u30e9\u30d9\u30eb $y \\in \\{0,1\\}$ \u304a\u3088\u3073\u78ba\u7387\u63a8\u5b9a $ p = \\operatorname{Pr}(y = 1)$ \u3092\u6709\u3059\u308b\u30d0\u30a4\u30ca\u30ea\u5206\u985e\u306e\u5834\u5408\u3001\u30b5\u30f3\u30d7\u30eb\u5f53\u305f\u308a\u306e\u30ed\u30b0\u640d\u5931\u306f\u3001\u771f\u306e\u30e9\u30d9\u30eb\u304c\u4e0e\u3048\u3089\u308c\u305f\u5206\u985e\u5668\u306e\u8ca0\u306e\u5bfe\u6570\u5c24\u5ea6\u3067\u3042\u308b\u3002\n\n```math\nL_{\\log}(y, p) = -\\log \\operatorname{Pr}(y|p) = -(y \\log (p) + (1 - y) \\log (1 - p))\n```\n\n\u3053\u308c\u306f\u4ee5\u4e0b\u306e\u3088\u3046\u306b\u30de\u30eb\u30c1\u30af\u30e9\u30b9\u306e\u5834\u5408\u306b\u307e\u3067\u53ca\u3076\u3002\u30b5\u30f3\u30d7\u30eb\u30bb\u30c3\u30c8\u306b\u5bfe\u3059\u308b\u771f\u306e\u30e9\u30d9\u30eb\u3092K\u500b\u306e\u30d0\u30a4\u30ca\u30ea\u30a4\u30f3\u30b8\u30b1\u30fc\u30bf\u884c\u5217 $Y$ \u306e1\u3064\u3068\u3057\u3066\u7b26\u53f7\u5316\u3059\u308b\u3002\u3059\u306a\u308f\u3061\u3001\u30b5\u30f3\u30d7\u30ebi\u304cK\u500b\u306e\u30e9\u30d9\u30eb\u306e\u30bb\u30c3\u30c8\u304b\u3089\u53d6\u3089\u308c\u305f\u30e9\u30d9\u30ebk\u3092\u6709\u3059\u308b\u5834\u5408\u3001 $ y_{i,k} = 1$ \u3067\u3042\u308b\u3002 $P$ \u3092\u78ba\u7387\u63a8\u5b9a\u306e\u884c\u5217\u3068\u3057\u3001 $p_{i,k} = \\operatorname{Pr}(t_{i,k} = 1)$ \u3068\u3059\u308b\u3002 \u3059\u308b\u3068\u3001\u96c6\u5408\u5168\u4f53\u306e\u5bfe\u6570\u640d\u5931\u306f\n\n```math\nL_{\\log}(Y, P) = -\\log \\operatorname{Pr}(Y|P) = - \\frac{1}{N} \\sum_{i=0}^{N-1} \\sum_{k=0}^{K-1} y_{i,k} \\log p_{i,k}\n```\n\n\u3053\u308c\u304c\u30d0\u30a4\u30ca\u30ea\u306e\u5834\u5408\u3001$ p_{i,0} = 1 - p_{i,1}$ \u3068 $y_{i,0} = 1 - y_{i,1}$ \u3057\u305f\u304c\u3063\u3066\u3001\u5185\u90e8\u5408\u8a08\u3092 $y_{i,k} \\in \\{0,1\\}$  \u3088\u308a\u5927\u304d\u304f\u3059\u308b\u3068\u3001\u30d0\u30a4\u30ca\u30ea\u30ed\u30b0\u640d\u5931\u304c\u5f97\u3089\u308c\u307e\u3059\u3002\n\n[log_loss](http://scikit-learn.org/0.18/modules/generated/sklearn.metrics.log_loss.html#sklearn.metrics.log_loss) \u95a2\u6570\u306f\u3001\u63a8\u5b9a\u5024\u306e `predict_proba` \u30e1\u30bd\u30c3\u30c9\u306b\u3088\u3063\u3066\u8fd4\u3055\u308c\u308b\u3088\u3046\u306b\u3001\u30b0\u30e9\u30f3\u30c9\u771f\u7406\u5024\u30e9\u30d9\u30eb\u3068\u78ba\u7387\u884c\u5217\u306e\u30ea\u30b9\u30c8\u304c\u4e0e\u3048\u3089\u308c\u305f\u3068\u304d\u306e\u30ed\u30b0\u640d\u5931\u3092\u8a08\u7b97\u3057\u307e\u3059\u3002\n\n\n```python\n>>> from sklearn.metrics import log_loss\n>>> y_true = [0, 0, 1, 1]\n>>> y_pred = [[.9, .1], [.8, .2], [.3, .7], [.01, .99]]\n>>> log_loss(y_true, y_pred)    \n0.1738...\n```\n\n`y_pred`\u306e\u6700\u521d\u306e `[.9, .1]` \u306f\u3001\u6700\u521d\u306e\u30b5\u30f3\u30d7\u30eb\u304c\u30e9\u30d9\u30eb0\u3092\u6301\u3064\u78ba\u7387\u304c90\uff05\u3067\u3042\u308b\u3053\u3068\u3092\u793a\u3057\u307e\u3059\u3002\u30ed\u30b0\u640d\u5931\u306f\u8ca0\u3067\u306f\u3042\u308a\u307e\u305b\u3093\u3002\n\n### 3.3.2.11. \u30de\u30b7\u30e5\u30fc\u30ba\u76f8\u95a2\u4fc2\u6570\n\n[matthews_corrcoef](http://scikit-learn.org/0.18/modules/generated/sklearn.metrics.matthews_corrcoef.html#sklearn.metrics.matthews_corrcoef) \u95a2\u6570\u306f\u3001\u30d0\u30a4\u30ca\u30ea\u30af\u30e9\u30b9\u306e[\u30de\u30b7\u30e5\u30fc\u76f8\u95a2\u4fc2\u6570\uff08MCC\uff09](https://en.wikipedia.org/wiki/Matthews_correlation_coefficient)\u3092\u8a08\u7b97\u3057\u307e\u3059\u3002\u5f15\u7528Wikipedia\uff1a\n\n> Matthews\u306e\u76f8\u95a2\u4fc2\u6570\u306f\u3001\u30d0\u30a4\u30ca\u30ea\uff082\u30af\u30e9\u30b9\uff09\u5206\u985e\u306e\u54c1\u8cea\u306e\u5c3a\u5ea6\u3068\u3057\u3066\u6a5f\u68b0\u5b66\u7fd2\u3067\u4f7f\u7528\u3055\u308c\u307e\u3059\u3002\u771f\u967d\u6027\u3068\u9670\u9670\u967d\u6027\u3068\u9670\u6027\u3092\u8003\u616e\u3057\u3001\u30af\u30e9\u30b9\u304c\u975e\u5e38\u306b\u7570\u306a\u308b\u30b5\u30a4\u30ba\u3067\u3042\u3063\u3066\u3082\u4f7f\u7528\u3067\u304d\u308b\u30d0\u30e9\u30f3\u30b9\u306e\u53d6\u308c\u305f\u5c3a\u5ea6\u3068\u4e00\u822c\u7684\u306b\u307f\u306a\u3055\u308c\u307e\u3059\u3002 MCC\u306f\u3001\u672c\u8cea\u7684\u306b\u3001-1\u3068+1\u3068\u306e\u9593\u306e\u76f8\u95a2\u4fc2\u6570\u5024\u3067\u3042\u308b\u3002 + 1\u306e\u4fc2\u6570\u306f\u5b8c\u5168\u4e88\u6e2c\u3092\u8868\u3057\u30010\u306f\u5e73\u5747\u30e9\u30f3\u30c0\u30e0\u4e88\u6e2c\u3092\u8868\u3057\u3001-1\u306f\u9006\u4e88\u6e2c\u3092\u8868\u3059\u3002\u7d71\u8a08\u306f\u3001\u03c6\u4fc2\u6570\u3068\u3057\u3066\u3082\u77e5\u3089\u308c\u3066\u3044\u307e\u3059\u3002\n\n$tp$ \u3001$tn$ \u3001$fp$ \u304a\u3088\u3073 $fn$ \u304c\u305d\u308c\u305e\u308c\u771f\u967d\u6027\u3001\u771f\u9670\u6027\u3001\u507d\u967d\u6027\u304a\u3088\u3073\u507d\u9670\u6027\u306e\u6570\u3067\u3042\u308b\u5834\u5408\u3001MCC\u4fc2\u6570\u306f\n\n```math\nMCC = \\frac{tp \\times tn - fp \\times fn}{\\sqrt{(tp + fp)(tp + fn)(tn + fp)(tn + fn)}}.\n```\n\nmatthews_corrcoef\u95a2\u6570\u306e\u4f7f\u3044\u65b9\u3092\u793a\u3059\u5c0f\u3055\u306a\u4f8b\u3092\u6b21\u306b\u793a\u3057\u307e\u3059\u3002\n\n```python\n>>>\n>>> sklearn.metrics\u304b\u3089\u306e\u30a4\u30f3\u30dd\u30fc\u30c8matthews_corrcoef\n>>> y_true = [+1\u3001+1\u3001+1\u3001-1]\n>>> y_pred = [+1\u3001-1\u3001+1\u3001+1]\n>>> matthews_corrcoef\uff08y_true\u3001y_pred\uff09\n-0.33 ...\n```\n\n### 3.3.2.12. \u30ec\u30b7\u30fc\u30d0\u52d5\u4f5c\u7279\u6027\uff08ROC\uff09\n\n\u95a2\u6570[roc_curve](http://scikit-learn.org/0.18/modules/generated/sklearn.metrics.roc_curve.html#sklearn.metrics.roc_curve) \u306f\u3001[\u53d7\u4fe1\u8005\u52d5\u4f5c\u7279\u6027\u66f2\u7dda\u307e\u305f\u306fROC\u30ab\u30fc\u30d6](https://en.wikipedia.org/wiki/Receiver_operating_characteristic) \u3092\u8a08\u7b97\u3057\u307e\u3059\u3002\u5f15\u7528Wikipedia\uff1a\n> \u53d7\u4fe1\u6a5f\u52d5\u4f5c\u7279\u6027\uff08ROC\uff09\u3001\u307e\u305f\u306f\u5358\u7d14\u306bROC\u66f2\u7dda\u306f\u3001\u8b58\u5225\u95be\u5024\u304c\u5909\u5316\u3059\u308b\u3068\u304d\u306e\u30d0\u30a4\u30ca\u30ea\u5206\u985e\u30b7\u30b9\u30c6\u30e0\u306e\u6027\u80fd\u3092\u793a\u3059\u30b0\u30e9\u30d5\u30d7\u30ed\u30c3\u30c8\u3067\u3042\u308b\u3002\u3053\u308c\u306f\u3001\u3055\u307e\u3056\u307e\u306a\u95be\u5024\u8a2d\u5b9a\u3067\u3001\u967d\u6027\u304b\u3089\u306e\u771f\u967d\u6027\u306e\u5272\u5408\uff08TPR =\u771f\u967d\u6027\u7387\uff09\u5bfe\u9670\u6027\u304b\u3089\u306e\u507d\u967d\u6027\u306e\u5272\u5408\uff08FPR =\u507d\u967d\u6027\u7387\uff09\u3092\u30d7\u30ed\u30c3\u30c8\u3059\u308b\u3053\u3068\u306b\u3088\u3063\u3066\u4f5c\u6210\u3055\u308c\u307e\u3059\u3002 TPR\u306f\u611f\u53d7\u6027\u3068\u3057\u3066\u3082\u77e5\u3089\u308c\u3066\u304a\u308a\u3001FPR\u306f\u7279\u7570\u6027\u307e\u305f\u306f\u771f\u306e\u8ca0\u306e\u7387\u304b\u30891\u3092\u5f15\u3044\u305f\u3082\u306e\u3067\u3059\u3002\n\n\u3053\u306e\u95a2\u6570\u306f\u3001\u771f\u306e\u30d0\u30a4\u30ca\u30ea\u5024\u3068\u76ee\u6a19\u30b9\u30b3\u30a2\u3092\u5fc5\u8981\u3068\u3057\u307e\u3059\u3002\u3053\u308c\u306f\u3001\u967d\u6027\u30af\u30e9\u30b9\u306e\u78ba\u7387\u63a8\u5b9a\u5024\u3001\u4fe1\u983c\u5024\u3001\u307e\u305f\u306f\u30d0\u30a4\u30ca\u30ea\u6c7a\u5b9a\u306e\u3044\u305a\u308c\u304b\u3067\u3059\u3002 roc_curve\u95a2\u6570\u3092\u4f7f\u7528\u3059\u308b\u65b9\u6cd5\u306e\u5c0f\u3055\u306a\u4f8b\u3092\u6b21\u306b\u793a\u3057\u307e\u3059\u3002\n\n```python\n>>> import numpy as np\n>>> from sklearn.metrics import roc_curve\n>>> y = np.array([1, 1, 2, 2])\n>>> scores = np.array([0.1, 0.4, 0.35, 0.8])\n>>> fpr, tpr, thresholds = roc_curve(y, scores, pos_label=2)\n>>> fpr\narray([ 0. ,  0.5,  0.5,  1. ])\n>>> tpr\narray([ 0.5,  0.5,  1. ,  1. ])\n>>> thresholds\narray([ 0.8 ,  0.4 ,  0.35,  0.1 ])\n```\n\n\u3053\u306e\u56f3\u306f\u3001\u305d\u306e\u3088\u3046\u306aROC\u66f2\u7dda\u306e\u4f8b\u3092\u793a\u3057\u3066\u3044\u307e\u3059\u3002\n\n![](http://scikit-learn.org/0.18/_images/sphx_glr_plot_roc_0011.png)\n\n[roc_auc_score](http://scikit-learn.org/0.18/modules/generated/sklearn.metrics.roc_auc_score.html#sklearn.metrics.roc_auc_score) \u95a2\u6570\u306f\u3001AUC\u307e\u305f\u306fAUROC\u3067\u8868\u3055\u308c\u308b\u53d7\u4fe1\u6a5f\u52d5\u4f5c\u7279\u6027\uff08ROC\uff09\u30ab\u30fc\u30d6\u306e\u4e0b\u306e\u9762\u7a4d\u3092\u8a08\u7b97\u3057\u307e\u3059\u3002 roc\u66f2\u7dda\u4e0b\u306e\u9762\u7a4d\u3092\u8a08\u7b97\u3059\u308b\u3053\u3068\u306b\u3088\u308a\u3001\u66f2\u7dda\u60c5\u5831\u304c1\u3064\u306e\u6570\u306b\u307e\u3068\u3081\u3089\u308c\u307e\u3059\u3002 \u8a73\u7d30\u306f\u3001[AUC\u306b\u95a2\u3059\u308bWikipedia\u306e\u8a18\u4e8b](https://en.wikipedia.org/wiki/Receiver_operating_characteristic#Area_under_the_curve) \u3092\u53c2\u7167\u3057\u3066\u304f\u3060\u3055\u3044\u3002\n\n```python\n>>> import numpy as np\n>>> from sklearn.metrics import roc_auc_score\n>>> y_true = np.array([0, 0, 1, 1])\n>>> y_scores = np.array([0.1, 0.4, 0.35, 0.8])\n>>> roc_auc_score(y_true, y_scores)\n0.75\n```\n\n\u30de\u30eb\u30c1\u30e9\u30d9\u30eb\u5206\u985e\u3067\u306f\u3001\u4e0a\u8a18\u306e\u3088\u3046\u306b\u30e9\u30d9\u30eb\u3092\u5e73\u5747\u5316\u3059\u308b\u3053\u3068\u306b\u3088\u3063\u3066roc_auc_score\u95a2\u6570\u304c\u62e1\u5f35\u3055\u308c\u307e\u3059\u3002\n\u30b5\u30d6\u30bb\u30c3\u30c8\u7cbe\u5ea6\u3001\u30cf\u30df\u30f3\u30b0\u640d\u5931\u3001F1\u30b9\u30b3\u30a2\u306a\u3069\u306e\u30e1\u30c8\u30ea\u30c3\u30af\u3068\u6bd4\u8f03\u3057\u3066\u3001ROC\u3067\u306f\u5404\u30e9\u30d9\u30eb\u306e\u3057\u304d\u3044\u5024\u3092\u6700\u9069\u5316\u3059\u308b\u5fc5\u8981\u306f\u3042\u308a\u307e\u305b\u3093\u3002 \u4e88\u6e2c\u3055\u308c\u305f\u51fa\u529b\u304c2\u9032\u5316\u3055\u308c\u3066\u3044\u308b\u5834\u5408\u3001roc_auc_score\u95a2\u6570\u3092\u30de\u30eb\u30c1\u30af\u30e9\u30b9\u5206\u985e\u3067\u4f7f\u7528\u3059\u308b\u3053\u3068\u3082\u3067\u304d\u307e\u3059\u3002\n\n![](http://scikit-learn.org/0.18/_images/sphx_glr_plot_roc_0021.png)\n\n  - \u4f8b\uff1a\n    - ROC\u3092\u4f7f\u7528\u3057\u3066\u5206\u985e\u5668\u306e\u51fa\u529b\u306e\u54c1\u8cea\u3092\u8a55\u4fa1\u3059\u308b\u4f8b\u306b\u3064\u3044\u3066\u306f\u3001[\u53d7\u4fe1\u8005\u52d5\u4f5c\u7279\u6027\uff08ROC\uff09](http://scikit-learn.org/0.18/auto_examples/model_selection/plot_roc.html#sphx-glr-auto-examples-model-selection-plot-roc-py) \u3092\u53c2\u7167\u3057\u3066\u304f\u3060\u3055\u3044\u3002\n    - \u30af\u30ed\u30b9\u30d0\u30ea\u30c7\u30fc\u30b7\u30e7\u30f3\u3092\u4f7f\u7528\u3057\u3066\u3001\u5206\u985e\u5b50\u306e\u51fa\u529b\u54c1\u8cea\u3092\u8a55\u4fa1\u3059\u308b\u305f\u3081\u306eROC\u306e\u4f7f\u7528\u4f8b\u306b\u3064\u3044\u3066\u306f\u3001[\u76f8\u4e92\u691c\u8a3c\u306b\u3088\u308b\u53d7\u4fe1\u8005\u52d5\u4f5c\u7279\u6027\uff08ROC\uff09](http://scikit-learn.org/0.18/auto_examples/model_selection/plot_roc_crossval.html#sphx-glr-auto-examples-model-selection-plot-roc-crossval-py) \u3092\u53c2\u7167\u3057\u3066\u304f\u3060\u3055\u3044\u3002\n    - \u7a2e\u306e\u5206\u5e03\u3092\u30e2\u30c7\u30eb\u5316\u3059\u308b\u305f\u3081\u306eROC\u306e\u4f7f\u7528\u4f8b\u306b\u3064\u3044\u3066\u306f\u3001[\u7a2e\u306e\u5206\u5e03\u30e2\u30c7\u30eb](http://scikit-learn.org/0.18/auto_examples/applications/plot_species_distribution_modeling.html#sphx-glr-auto-examples-applications-plot-species-distribution-modeling-py) \u3092\u53c2\u7167\u3057\u3066\u304f\u3060\u3055\u3044\u3002\n\n### 3.3.2.13. 0-1\u640d\u5931\n\n[zero_one_loss](http://scikit-learn.org/0.18/modules/generated/sklearn.metrics.zero_one_loss.html#sklearn.metrics.zero_one_loss) \u95a2\u6570\u306f\u3001$n_{\\text{samples}}$ \u306b\u5bfe\u3059\u308b0-1\u5206\u985e\u640d\u5931 $ (L_{0-1})$ \u306e\u548c\u307e\u305f\u306f\u5e73\u5747\u3092\u8a08\u7b97\u3057\u307e\u3059\u3002 \u30c7\u30d5\u30a9\u30eb\u30c8\u3067\u306f\u3001\u95a2\u6570\u306f\u30b5\u30f3\u30d7\u30eb\u306b\u5bfe\u3057\u3066\u6b63\u898f\u5316\u3055\u308c\u307e\u3059\u3002 $ L_{0-1}$ \u306e\u548c\u3092\u6c42\u3081\u308b\u306b\u306f\u3001`normalize` \u3092 `False` \u306b\u8a2d\u5b9a\u3057\u307e\u3059\u3002\n\u30de\u30eb\u30c1\u30e9\u30d9\u30eb\u5206\u985e\u3067\u306f\u3001 zero_one_loss \u306f\u3001\u305d\u306e\u30e9\u30d9\u30eb\u304c\u4e88\u6e2c\u3068\u53b3\u5bc6\u306b\u4e00\u81f4\u3059\u308b\u5834\u5408\u306b\u306f\u30b5\u30d6\u30bb\u30c3\u30c8\u30921\u3068\u3057\u3066\u30b9\u30b3\u30a2\u4ed8\u3051\u3057\u3001\u30a8\u30e9\u30fc\u304c\u3042\u308b\u5834\u5408\u306b\u306f\u30bc\u30ed\u3068\u3057\u3066\u30b9\u30b3\u30a2\u4ed8\u3051\u3057\u307e\u3059\u3002 \u30c7\u30d5\u30a9\u30eb\u30c8\u3067\u306f\u3001\u3053\u306e\u95a2\u6570\u306f\u4e0d\u5b8c\u5168\u306b\u4e88\u6e2c\u3055\u308c\u305f\u30b5\u30d6\u30bb\u30c3\u30c8\u306e\u5272\u5408\u3092\u8fd4\u3057\u307e\u3059\u3002 \u305d\u306e\u3088\u3046\u306a\u30b5\u30d6\u30bb\u30c3\u30c8\u306e\u6570\u3092\u4ee3\u308f\u308a\u306b\u53d6\u5f97\u3059\u308b\u306b\u306f\u3001`normalize` \u3092 `False` \u306b\u8a2d\u5b9a\u3057\u307e\u3059\n$\\hat {y} _i$ \u304c $i$ \u756a\u76ee\u306e\u30b5\u30f3\u30d7\u30eb\u306e\u4e88\u6e2c\u5024\u3067\u3042\u308a\u3001 $y_i$ \u304c\u5bfe\u5fdc\u3059\u308b\u771f\u306e\u5024\u3067\u3042\u308b\u5834\u5408\u30010-1\u640d\u5931 $L_ {0-1}$ \u306f\u6b21\u306e\u3088\u3046\u306b\u5b9a\u7fa9\u3055\u308c\u307e\u3059\u3002\n\n```math\nL_{0-1}(y_i, \\hat{y}_i) = 1(\\hat{y}_i \\not= y_i)\n```\n\n\u3053\u3053\u3067\u3001 $1(x)$ \u306f[\u6307\u6a19\u95a2\u6570](https://en.wikipedia.org/wiki/Indicator_function)\u3067\u3059\u3002\n\n```python\n>>> from sklearn.metrics import zero_one_loss\n>>> y_pred = [1, 2, 3, 4]\n>>> y_true = [2, 2, 3, 4]\n>>> zero_one_loss(y_true, y_pred)\n0.25\n>>> zero_one_loss(y_true, y_pred, normalize=False)\n1\n```\n\n\u30d0\u30a4\u30ca\u30ea\u30e9\u30d9\u30eb\u30a4\u30f3\u30b8\u30b1\u30fc\u30bf\u3092\u6301\u3064\u30de\u30eb\u30c1\u30e9\u30d9\u30eb\u306e\u5834\u5408\u3001\u6700\u521d\u306e\u30e9\u30d9\u30eb\u30bb\u30c3\u30c8[0,1]\u306b\u30a8\u30e9\u30fc\u304c\u3042\u308a\u307e\u3059\u3002\n\n```python\n>>>\n>>> zero_one_loss(np.array([[0, 1], [1, 1]]), np.ones((2, 2)))\n0.5\n\n>>> zero_one_loss(np.array([[0, 1], [1, 1]]), np.ones((2, 2)),  normalize=False)\n1\n```\n\n  - \u4f8b\uff1a\n    - \u30af\u30ed\u30b9\u30d0\u30ea\u30c7\u30fc\u30b7\u30e7\u30f3\u3092\u4f7f\u7528\u3057\u3066\u518d\u5e30\u7684\u306a\u7279\u5fb4\u3092\u524a\u9664\u3059\u308b\u305f\u3081\u306e\u640d\u5931\u640d\u5931\u3092\u30bc\u30ed\u306b\u3059\u308b\u4f8b\u306b\u3064\u3044\u3066\u306f\u3001[\u30af\u30ed\u30b9\u691c\u8a3c\u306b\u3088\u308b\u518d\u5e30\u7684\u306a\u7279\u5fb4\u524a\u9664](http://scikit-learn.org/0.18/auto_examples/feature_selection/plot_rfe_with_cross_validation.html#sphx-glr-auto-examples-feature-selection-plot-rfe-with-cross-validation-py) \u3092\u53c2\u7167\u3057\u3066\u304f\u3060\u3055\u3044\u3002\n\n### 3.3.2.14. Brier\u30b9\u30b3\u30a2\u640d\u5931\n\n[brier_score_loss](http://scikit-learn.org/0.18/modules/generated/sklearn.metrics.brier_score_loss.html#sklearn.metrics.brier_score_loss) \u95a2\u6570\u306f\u3001\u30d0\u30a4\u30ca\u30ea\u30af\u30e9\u30b9\u306e [Brier\u30b9\u30b3\u30a2](https://en.wikipedia.org/wiki/Brier_score) \u3092\u8a08\u7b97\u3057\u307e\u3059\u3002\u5f15\u7528Wikipedia\uff1a\n\n> Brier\u30b9\u30b3\u30a2\u306f\u3001\u78ba\u7387\u7684\u4e88\u6e2c\u306e\u7cbe\u5ea6\u3092\u6e2c\u5b9a\u3059\u308b\u9069\u5207\u306a\u30b9\u30b3\u30a2\u95a2\u6570\u3067\u3059\u3002\u4e88\u6e2c\u304c\u76f8\u4e92\u6392\u4ed6\u7684\u96e2\u6563\u7d50\u679c\u306e\u96c6\u5408\u306b\u78ba\u7387\u3092\u5272\u308a\u5f53\u3066\u308b\u5fc5\u8981\u304c\u3042\u308b\u30bf\u30b9\u30af\u306b\u9069\u7528\u3067\u304d\u307e\u3059\u3002\n\n\u3053\u306e\u95a2\u6570\u306f\u3001\u5b9f\u969b\u306e\u7d50\u679c\u3068\u53ef\u80fd\u306a\u7d50\u679c\u306e\u4e88\u6e2c\u3055\u308c\u308b\u78ba\u7387\u3068\u306e\u9593\u306e\u5e73\u5747\u4e8c\u4e57\u5dee\u306e\u30b9\u30b3\u30a2\u3092\u8fd4\u3057\u307e\u3059\u3002\u5b9f\u969b\u306e\u7d50\u679c\u306f1\u307e\u305f\u306f0\uff08\u771f\u307e\u305f\u306f\u507d\uff09\u3067\u3042\u308b\u5fc5\u8981\u304c\u3042\u308a\u307e\u3059\u304c\u3001\u5b9f\u969b\u306e\u7d50\u679c\u306e\u4e88\u6e2c\u78ba\u7387\u306f0\u30681\u306e\u9593\u306e\u5024\u306b\u306a\u308a\u307e\u3059\u3002\nbrier\u30b9\u30b3\u30a2\u306e\u640d\u5931\u30820\u301c1\u3067\u3042\u308a\u3001\u30b9\u30b3\u30a2\u304c\u4f4e\u3044\u307b\u3069\uff08\u5e73\u5747\u5e73\u65b9\u5dee\u304c\u5c0f\u3055\u3044\u307b\u3069\uff09\u3001\u4e88\u6e2c\u304c\u3088\u308a\u6b63\u78ba\u3067\u3042\u308b\u3002\u3053\u308c\u306f\u3001\u78ba\u7387\u7684\u4e88\u6e2c\u306e\u30bb\u30c3\u30c8\u306e\u300c\u5c04\u7a0b\u8ddd\u96e2\u6e2c\u5b9a\u300d\u306e\u5c3a\u5ea6\u3068\u8003\u3048\u308b\u3053\u3068\u304c\u3067\u304d\u308b\u3002\n\n```math\nBS = \\frac{1}{N} \\sum_{t=1}^{N}(f_t - o_t)^2\n```\n\n\u3053\u3053\u3067\u3001 $N$ \u306f\u4e88\u6e2c\u306e\u7dcf\u6570\u3067\u3042\u308a\u3001 $f_t$ \u306f\u5b9f\u969b\u306e\u7d50\u679c $o_t$ \u306e\u4e88\u6e2c\u3055\u308c\u308b\u78ba\u7387\u3067\u3042\u308b\u3002\n\n\u3053\u306e\u95a2\u6570\u306e\u4f7f\u3044\u65b9\u306e\u5c0f\u3055\u306a\u4f8b\u3092\u6b21\u306b\u793a\u3057\u307e\u3059::\n\n```python\n>>> import numpy as np\n>>> from sklearn.metrics import brier_score_loss\n>>> y_true = np.array([0, 1, 1, 0])\n>>> y_true_categorical = np.array([\"spam\", \"ham\", \"ham\", \"spam\"])\n>>> y_prob = np.array([0.1, 0.9, 0.8, 0.4])\n>>> y_pred = np.array([0, 1, 1, 0])\n>>> brier_score_loss(y_true, y_prob)\n0.055\n>>> brier_score_loss(y_true, 1-y_prob, pos_label=0)\n0.055\n>>> brier_score_loss(y_true_categorical, y_prob, pos_label=\"ham\")\n0.055\n>>> brier_score_loss(y_true, y_prob > 0.5)\n0.0\n```\n\n  - \u4f8b\uff1a\n    - \u5206\u985e\u5668\u306e\u78ba\u7387\u5c04\u7a0b\u8ddd\u96e2\u6e2c\u5b9a\u3092\u5b9f\u884c\u3059\u308b\u305f\u3081\u306eBrier\u30b9\u30b3\u30a2\u640d\u5931\u306e\u4f7f\u7528\u4f8b\u306b\u3064\u3044\u3066\u306f\u3001[\u5206\u985e\u5668\u306e\u78ba\u7387\u5c04\u7a0b\u8ddd\u96e2\u6e2c\u5b9a](http://scikit-learn.org/0.18/auto_examples/calibration/plot_calibration.html#sphx-glr-auto-examples-calibration-plot-calibration-py)\u3092\u53c2\u7167\u3057\u3066\u304f\u3060\u3055\u3044\u3002\n  - \u53c2\u8003\u6587\u732e\uff1a\n    - G. Brier\u3001[\u78ba\u7387\u7684\u306b\u8868\u73fe\u3055\u308c\u305f\u4e88\u6e2c\u306e\u691c\u8a3c](http://docs.lib.noaa.gov/rescue/mwr/078/mwr-078-01-0001.pdf) \u3001\u6bce\u6708\u306e\u6c17\u8c61\u8a55\u4fa178.1\uff081950\uff09\n\n### 3.3.3. \u30de\u30eb\u30c1\u30e9\u30d9\u30eb\u30e9\u30f3\u30ad\u30f3\u30b0\u30e1\u30c8\u30ea\u30c3\u30af\n\n\u30de\u30eb\u30c1\u30e9\u30d9\u30eb\u5b66\u7fd2\u3067\u306f\u3001\u5404\u30b5\u30f3\u30d7\u30eb\u306b\u306f\u3001\u305d\u308c\u306b\u95a2\u9023\u3059\u308b\u30b0\u30e9\u30a6\u30f3\u30c9\u30fb\u30c8\u30a5\u30eb\u30fc\u30fb\u30e9\u30d9\u30eb\u3092\u3044\u304f\u3064\u3067\u3082\u6301\u3064\u3053\u3068\u304c\u3067\u304d\u307e\u3059\u3002\u30b4\u30fc\u30eb\u306f\u9ad8\u3044\u5f97\u70b9\u3092\u4e0e\u3048\u3001\u5730\u4e0a\u306e\u771f\u7406\u5024\u672d\u306b\u30e9\u30f3\u30af\u4ed8\u3051\u3059\u308b\u3053\u3068\u3067\u3059\u3002\n\n### 3.3.3.1. \u30ab\u30d0\u30ec\u30c3\u30b8\u30a8\u30e9\u30fc\n\n[coverage_error](http://scikit-learn.org/0.18/modules/generated/sklearn.metrics.coverage_error.html#sklearn.metrics.coverage_error) \u95a2\u6570\u306f\u3001\u5168\u3066\u306e\u771f\u306e\u30e9\u30d9\u30eb\u304c\u4e88\u6e2c\u3055\u308c\u308b\u3088\u3046\u306b\u3001\u6700\u7d42\u7684\u306a\u4e88\u6e2c\u306b\u542b\u307e\u308c\u306a\u3051\u308c\u3070\u306a\u3089\u306a\u3044\u30e9\u30d9\u30eb\u306e\u5e73\u5747\u6570\u3092\u8a08\u7b97\u3059\u308b\u3002\u3053\u308c\u306f\u3001\u771f\u306e\u5024\u3092\u5931\u308f\u305a\u306b\u5e73\u5747\u3067\u4e88\u6e2c\u3057\u306a\u3051\u308c\u3070\u306a\u3089\u306a\u3044\u30c8\u30c3\u30d7\u30b9\u30b3\u30a2\u30e9\u30d9\u30eb\u306e\u6570\u3092\u77e5\u308a\u305f\u3044\u5834\u5408\u306b\u4fbf\u5229\u3067\u3059\u3002\u3057\u305f\u304c\u3063\u3066\u3001\u3053\u306e\u30e1\u30c8\u30ea\u30c3\u30af\u306e\u6700\u826f\u306e\u5024\u306f\u3001\u771f\u306e\u30e9\u30d9\u30eb\u306e\u5e73\u5747\u6570\u3067\u3059\u3002\n\u516c\u5f0f\u306b\u306f\u3001\u30b0\u30e9\u30a6\u30f3\u30c9\u30c8\u30a5\u30eb\u30fc\u30b9\u30e9\u30d9\u30eb  \u306e2\u9032\u30a4\u30f3\u30b8\u30b1\u30fc\u30bf\u884c\u5217\u3068\u5404\u30e9\u30d9\u30eb    \u306b\u95a2\u9023\u4ed8\u3051\u3089\u308c\u305f\u30b9\u30b3\u30a2\u304c\u4e0e\u3048\u3089\u308c\u308b\u3068\u3001\u30ab\u30d0\u30ec\u30c3\u30b8\u306f\u4ee5\u4e0b\u306e\u3088\u3046\u306b\u5b9a\u7fa9\u3055\u308c\u308b\u3002\n\n\u516c\u5f0f\u306b\u306f\u3001\u30b0\u30e9\u30a6\u30f3\u30c9\u30c8\u30a5\u30eb\u30fc\u30b9\u30e9\u30d9\u30eb $ y \\in \\left\\\\\\{0, 1\\right\\\\\\}^{n\\_\\text{samples} \\times n\\_\\text{labels}}$ \u306e2\u9032\u30a4\u30f3\u30b8\u30b1\u30fc\u30bf\u884c\u5217\u3068\u5404\u30e9\u30d9\u30eb $\\hat{f} \\in \\mathbb{R}^{n\\_\\text{samples} \\times n\\_\\text{labels}}$ \u306b\u95a2\u9023\u4ed8\u3051\u3089\u308c\u305f\u30b9\u30b3\u30a2\u304c\u4e0e\u3048\u3089\u308c\u308b\u3068\u3001\u30ab\u30d0\u30ec\u30c3\u30b8\u306f\n\n```math\ncoverage(y, \\hat{f}) = \\frac{1}{n_{\\text{samples}}}\n  \\sum_{i=0}^{n_{\\text{samples}} - 1} \\max_{j:y_{ij} = 1} \\text{rank}_{ij}\n```\n\n\u3067 $\\text{rank}_{ij} = \\left\\|\\left\\\\\\{k: \\hat{f}\\_{ik} \\geq \\hat{f}\\_{ij} \\right\\\\\\}\\right\\|$ \u3068\u5b9a\u7fa9\u3055\u308c\u307e\u3059\u3002 \u30e9\u30f3\u30af\u306e\u5b9a\u7fa9\u304c\u4e0e\u3048\u3089\u308c\u308b\u3068\u3001`y_scores`\u306e\u7d50\u3073\u3064\u304d\u306f\u3001\u3059\u3079\u3066\u306e\u7d50\u3073\u4ed8\u3051\u3089\u308c\u305f\u5024\u306b\u5272\u308a\u5f53\u3066\u3089\u308c\u308b\u6700\u5927\u30e9\u30f3\u30af\u3092\u4e0e\u3048\u308b\u3053\u3068\u306b\u3088\u3063\u3066\u58ca\u3055\u308c\u307e\u3059\u3002\n\n\n\u3053\u306e\u95a2\u6570\u306e\u4f7f\u3044\u65b9\u306e\u5c0f\u3055\u306a\u4f8b\u3092\u6b21\u306b\u793a\u3057\u307e\u3059::\n\n```python\n>>> import numpy as np\n>>> from sklearn.metrics import coverage_error\n>>> y_true = np.array([[1, 0, 0], [0, 0, 1]])\n>>> y_score = np.array([[0.75, 0.5, 1], [1, 0.2, 0.1]])\n>>> coverage_error(y_true, y_score)\n2.5\n```\n\n### 3.3.3.2. \u30e9\u30d9\u30eb\u30e9\u30f3\u30af\u306e\u5e73\u5747\u9069\u5408\u7387\n\n[label_ranking_average_precision_score](http://scikit-learn.org/0.18/modules/generated/sklearn.metrics.label_ranking_average_precision_score.html#sklearn.metrics.label_ranking_average_precision_score) \u95a2\u6570\u306f\u3001\u30e9\u30d9\u30eb\u30e9\u30f3\u30af\u5e73\u5747\u9069\u5408\u7387\uff08LRAP\uff09\u3092\u5b9f\u88c5\u3057\u307e\u3059\u3002\u3053\u306e\u30e1\u30c8\u30ea\u30c3\u30af\u306f [average_precision_score](http://scikit-learn.org/0.18/modules/generated/sklearn.metrics.average_precision_score.html#sklearn.metrics.average_precision_score) \u95a2\u6570\u306b\u30ea\u30f3\u30af\u3055\u308c\u3066\u3044\u307e\u3059\u304c\u3001\u9069\u5408\u7387\u3068\u518d\u73fe\u7387\u306e\u4ee3\u308f\u308a\u306b\u30e9\u30d9\u30eb\u306e\u30e9\u30f3\u30af\u4ed8\u3051\u306e\u6982\u5ff5\u306b\u57fa\u3065\u3044\u3066\u3044\u307e\u3059\u3002\n\u30e9\u30d9\u30eb\u30e9\u30f3\u30af\u5e73\u5747\u7cbe\u5ea6\uff08LRAP\uff09\u306f\u3001\u5404\u30b5\u30f3\u30d7\u30eb\u306b\u5272\u308a\u5f53\u3066\u3089\u308c\u305f\u5404\u30b0\u30e9\u30f3\u30c9\u30fb\u30c8\u30a5\u30eb\u30fc\u30b9\u30fb\u30e9\u30d9\u30eb\u306e\u5e73\u5747\u5024\u3067\u3042\u308a\u3001\u30b9\u30b3\u30a2\u306e\u4f4e\u3044\u771f\u306e\u30e9\u30d9\u30eb\u3068\u7dcf\u30e9\u30d9\u30eb\u306e\u6bd4\u7387\u3067\u3059\u3002\u3053\u306e\u30e1\u30c8\u30ea\u30c3\u30af\u306f\u3001\u5404\u30b5\u30f3\u30d7\u30eb\u306b\u95a2\u9023\u4ed8\u3051\u3089\u308c\u305f\u30e9\u30d9\u30eb\u306e\u30e9\u30f3\u30af\u3092\u4e0a\u3052\u308b\u3053\u3068\u304c\u3067\u304d\u308c\u3070\u3001\u30b9\u30b3\u30a2\u304c\u5411\u4e0a\u3057\u307e\u3059\u3002\u5f97\u3089\u308c\u305f\u30b9\u30b3\u30a2\u306f\u5e38\u306b\u53b3\u5bc6\u306b0\u3088\u308a\u5927\u304d\u304f\u3001\u6700\u826f\u306e\u5024\u306f1\u3067\u3059\u3002\u30b5\u30f3\u30d7\u30eb\u3042\u305f\u308a1\u3064\u306e\u95a2\u9023\u30e9\u30d9\u30eb\u304c\u6b63\u78ba\u306b\u3042\u308b\u5834\u5408\u3001\u30e9\u30d9\u30eb\u30e9\u30f3\u30ad\u30f3\u30b0\u5e73\u5747\u9069\u5408\u7387\u306f [\u5e73\u5747\u9006\u6570\u30e9\u30f3\u30af](https://en.wikipedia.org/wiki/Mean_reciprocal_rank) \u306b\u76f8\u5f53\u3057\u307e\u3059\u3002\n\u6b63\u5f0f\u306b\u306f\u3001\u5730\u4e0a\u306e\u771f\u7406\u5024\u8868\u306e\u4e8c\u9805\u76ee\u306e\u6307\u6a19\u884c\u5217 $\\mathcal {R} ^ {n_ \\text {samples} \\times n_ \\text{labels}}$ \u3068\u5404\u30e9\u30d9\u30eb $\\hat {f} \\ \\mathcal {R} ^ {n_ \\ text {samples} \\ times n_ \\text {labels}}$ \u3067\u306f\u3001\u5e73\u5747\u7cbe\u5ea6\u306f\u6b21\u306e\u3088\u3046\u306b\u5b9a\u7fa9\u3055\u308c\u307e\u3059\u3002\n\n```math\nLRAP(y, \\hat{f}) = \\frac{1}{n_{\\text{samples}}}\n  \\sum_{i=0}^{n_{\\text{samples}} - 1} \\frac{1}{|y_i|}\n  \\sum_{j:y_{ij} = 1} \\frac{|\\mathcal{L}_{ij}|}{\\text{rank}_{ij}}\n```\n\n$\\mathcal{L}\\_{ij} = \\left\\\\\\{k: y_{ik} = 1, \\hat{f}\\_{ik} \\geq \\hat{f}\\_{ij} \\right\\\\\\}$,  $\\text{rank}\\_{ij} = \\left\\|\\left\\\\\\{k: \\hat{f}_{ik} \\geq \\hat{f}\\_{ij} \\right\\\\\\}\\right| $ \u305d\u3057\u3066  $\\|\\cdot\\|$ \u304c l0\u30ce\u30eb\u30e0\u307e\u305f\u306f\u30bb\u30c3\u30c8\u306e\u57fa\u6570\u3067\u3042\u308b\u3002\n\u3053\u306e\u95a2\u6570\u306e\u4f7f\u7528\u4f8b\u3092\u4ee5\u4e0b\u306b\u793a\u3057\u307e\u3059\u3002\n\n```python\n>>> import numpy as np\n>>> from sklearn.metrics import label_ranking_average_precision_score\n>>> y_true = np.array([[1, 0, 0], [0, 0, 1]])\n>>> y_score = np.array([[0.75, 0.5, 1], [1, 0.2, 0.1]])\n>>> label_ranking_average_precision_score(y_true, y_score) \n0.416...\n```\n\n### 3.3.3.3. \u30e9\u30f3\u30ad\u30f3\u30b0\u640d\u5931\n\n[label_ranking_loss](http://scikit-learn.org/0.18/modules/generated/sklearn.metrics.label_ranking_loss.html#sklearn.metrics.label_ranking_loss) \u95a2\u6570\u306f\u3001\u8aa4\u3063\u3066\u9806\u5e8f\u3065\u3051\u3089\u308c\u305f\u30e9\u30d9\u30eb\u30da\u30a2\u306e\u6570\u3001\u3059\u306a\u308f\u3061\u771f\u306e\u30e9\u30d9\u30eb\u304c\u507d\u306e\u30e9\u30d9\u30eb\u3088\u308a\u3082\u30b9\u30b3\u30a2\u304c\u4f4e\u304f\u3001\u507d\u306e\u30e9\u30d9\u30eb\u3068\u771f\u306e\u30e9\u30d9\u30eb\u306e\u9006\u6570\u3067\u91cd\u307f\u4ed8\u3051\u3055\u308c\u305f\u30e9\u30d9\u30eb\u306e\u30da\u30a2\u306e\u6570\u3092\u5e73\u5747\u3059\u308b\u30e9\u30f3\u30ad\u30f3\u30b0\u640d\u5931\u3092\u8a08\u7b97\u3059\u308b\u3002\u9054\u6210\u53ef\u80fd\u306a\u6700\u4f4e\u30e9\u30f3\u30ad\u30f3\u30b0\u640d\u5931\u306f\u30bc\u30ed\u3067\u3059\u3002\n\u516c\u5f0f\u306f\u3001\u5730\u9762\u771f\u7406\u30e9\u30d9\u30eb $ y \\in \\left\\\\\\{0, 1\\right\\\\\\}\\^{n\\_\\text{samples} \\times n\\_\\text{labels}}$ \u306e2\u9032\u30a4\u30f3\u30b8\u30b1\u30fc\u30bf\u884c\u5217\u3068\u5404\u30e9\u30d9\u30eb $ \\hat{f} \\in \\mathbb{R}^{n\\_\\text{samples} \\times n\\_\\text{labels}}$ \u306b\u95a2\u9023\u4ed8\u3051\u3089\u308c\u305f\u30b9\u30b3\u30a2\u304c\u4e0e\u3048\u3089\u308c\u305f\u5834\u5408\u3001\u30e9\u30f3\u30ad\u30f3\u30b0\u640d\u5931\u306f\n\n```math\n\\text{ranking\\_loss}(y, \\hat{f}) =  \\frac{1}{n_{\\text{samples}}}\n  \\sum_{i=0}^{n_{\\text{samples}} - 1} \\frac{1}{|y_i|(n_\\text{labels} - |y_i|)}\n  \\left|\\left\\{(k, l): \\hat{f}_{ik} < \\hat{f}_{il}, y_{ik} = 1, y_{il} = 0 \\right\\}\\right|\n```\n\n\u3053\u3053\u3067\u3001$ |\\cdot| $ \u306f\u3001 $ \\ell_0$ \u30ce\u30eb\u30e0\u307e\u305f\u306f\u96c6\u5408\u306e\u57fa\u6570\u3067\u3042\u308b\u3002\n\n\u3053\u306e\u95a2\u6570\u306e\u4f7f\u7528\u4f8b\u3092\u4ee5\u4e0b\u306b\u793a\u3057\u307e\u3059\u3002\n\n```python\n>>> import numpy as np\n>>> from sklearn.metrics import label_ranking_loss\n>>> y_true = np.array([[1, 0, 0], [0, 0, 1]])\n>>> y_score = np.array([[0.75, 0.5, 1], [1, 0.2, 0.1]])\n>>> label_ranking_loss(y_true, y_score) \n0.75...\n>>> # With the following prediction, we have perfect and minimal loss\n>>> y_score = np.array([[1.0, 0.1, 0.2], [0.1, 0.2, 0.9]])\n>>> label_ranking_loss(y_true, y_score)\n0.0\n```\n\n## 3.3.4. \u56de\u5e30\u30e1\u30c8\u30ea\u30c3\u30af\n\n[sklearn.metrics](http://scikit-learn.org/0.18/modules/classes.html#module-sklearn.metrics) \u30e2\u30b8\u30e5\u30fc\u30eb\u306f\u3001\u56de\u5e30\u306e\u30d1\u30d5\u30a9\u30fc\u30de\u30f3\u30b9\u3092\u6e2c\u5b9a\u3059\u308b\u305f\u3081\u306e\u3044\u304f\u3064\u304b\u306e\u640d\u5931\u3001\u30b9\u30b3\u30a2\u3001\u304a\u3088\u3073\u30e6\u30fc\u30c6\u30a3\u30ea\u30c6\u30a3\u95a2\u6570\u3092\u5b9f\u88c5\u3057\u3066\u3044\u307e\u3059\u3002 [mean_squared_error](http://scikit-learn.org/0.18/modules/generated/sklearn.metrics.mean_squared_error.html#sklearn.metrics.mean_squared_error)\u3001[mean_absolute_error](http://scikit-learn.org/0.18/modules/generated/sklearn.metrics.mean_absolute_error.html#sklearn.metrics.mean_absolute_error)\u3001[explain_variance_score](http://scikit-learn.org/0.18/modules/generated/sklearn.metrics.explained_variance_score.html#sklearn.metrics.explained_variance_score)\u3001\u304a\u3088\u3073 [r2_score](http://scikit-learn.org/0.18/modules/generated/sklearn.metrics.r2_score.html#sklearn.metrics.r2_score) \u306e\u3088\u3046\u306b\u3001\u8907\u6570\u51fa\u529b\u306e\u5834\u5408\u3092\u51e6\u7406\u3059\u308b\u3088\u3046\u306b\u62e1\u5f35\u3055\u308c\u3066\u3044\u308b\u3082\u306e\u304c\u3042\u308a\u307e\u3059\u3002\n\u3053\u308c\u3089\u306e\u95a2\u6570\u306b\u306f\u3001\u500b\u3005\u306e\u30bf\u30fc\u30b2\u30c3\u30c8\u306e\u30b9\u30b3\u30a2\u307e\u305f\u306f\u640d\u5931\u3092\u5e73\u5747\u3059\u308b\u65b9\u6cd5\u3092\u6307\u5b9a\u3059\u308b `multioutput`\u30ad\u30fc\u30ef\u30fc\u30c9\u5f15\u6570\u304c\u3042\u308a\u307e\u3059\u3002\u30c7\u30d5\u30a9\u30eb\u30c8\u306f `'uniform_average'` \u3067\u3059\u3002\u3053\u308c\u306f\u3001\u51fa\u529b\u306b\u5bfe\u3057\u3066\u5747\u4e00\u306b\u91cd\u307f\u4ed8\u3051\u3055\u308c\u305f\u5e73\u5747\u3092\u6307\u5b9a\u3057\u307e\u3059\u3002\u30b7\u30a7\u30a4\u30d7\u304c `\uff08n_outputs\u3001\uff09` \u306e `ndarray` \u304c\u6e21\u3055\u308c\u305f\u5834\u5408\u3001\u305d\u306e\u30a8\u30f3\u30c8\u30ea\u306f\u91cd\u307f\u3068\u3057\u3066\u89e3\u91c8\u3055\u308c\u3001\u305d\u308c\u306b\u5fdc\u3058\u305f\u52a0\u91cd\u5e73\u5747\u304c\u8fd4\u3055\u308c\u307e\u3059\u3002 `multioutput` \u304c `'raw_values'` \u306e\u5834\u5408\u3001\u5909\u66f4\u3055\u308c\u3066\u3044\u306a\u3044\u500b\u3005\u306e\u30b9\u30b3\u30a2\u3084\u640d\u5931\u306f\u3059\u3079\u3066\u30b7\u30a7\u30a4\u30d7`(n_outputs,)` \u306e\u914d\u5217 \u3067\u8fd4\u3055\u308c\u307e\u3059\u3002\nr2_score \u3068 explain_variance_score \u306f\u3001`multioutput` \u30d1\u30e9\u30e1\u30fc\u30bf\u306b\u5bfe\u3057\u3066\u8ffd\u52a0\u306e\u5024 `'variance_weighted'` \u3092\u53d7\u3051\u5165\u308c\u307e\u3059\u3002\u3053\u306e\u30aa\u30d7\u30b7\u30e7\u30f3\u306f\u3001\u5bfe\u5fdc\u3059\u308b\u30bf\u30fc\u30b2\u30c3\u30c8\u5909\u6570\u306e\u5206\u6563\u306b\u3088\u308b\u500b\u3005\u306e\u30b9\u30b3\u30a2\u306e\u91cd\u307f\u4ed8\u3051\u306b\u3064\u306a\u304c\u308a\u307e\u3059\u3002\u3053\u306e\u8a2d\u5b9a\u306f\u3001\u30b0\u30ed\u30fc\u30d0\u30eb\u306b\u30ad\u30e3\u30d7\u30c1\u30e3\u3055\u308c\u305f\u30b9\u30b1\u30fc\u30ea\u30f3\u30b0\u3055\u308c\u3066\u3044\u306a\u3044\u5206\u6563\u3092\u5b9a\u91cf\u5316\u3057\u307e\u3059\u3002\u76ee\u6a19\u5909\u6570\u306e\u30b9\u30b1\u30fc\u30eb\u304c\u7570\u306a\u308b\u5834\u5408\u3001\u3053\u306e\u30b9\u30b3\u30a2\u306f\u5206\u6563\u5909\u6570\u304c\u9ad8\u3044\u3053\u3068\u3092\u3088\u304f\u8aac\u660e\u3059\u308b\u4e0a\u3067\u91cd\u8981\u3067\u3059\u3002 `multioutput = 'variance_weighted'` \u306f\u4e0b\u4f4d\u4e92\u63db\u6027\u306e\u305f\u3081\u306br2_score\u306e\u30c7\u30d5\u30a9\u30eb\u30c8\u5024\u3067\u3059\u3002\u3053\u308c\u306f\u5c06\u6765\u3001`'uniform_average'` \u306b\u5909\u66f4\u3055\u308c\u307e\u3059\u3002\n\n### 3.3.4.1. \u8aac\u660e\u5909\u6570\u30b9\u30b3\u30a2\n\n[explain_variance_score](http://scikit-learn.org/0.18/modules/generated/sklearn.metrics.explained_variance_score.html#sklearn.metrics.explained_variance_score)\u306f\u3001[\u8aac\u660e\u5909\u6570\u56de\u5e30\u30b9\u30b3\u30a2](https://en.wikipedia.org/wiki/Explained_variation) \u3092\u8a08\u7b97\u3057\u307e\u3059\u3002\n$\\hat {y}$ \u304c\u63a8\u5b9a\u3055\u308c\u305f\u76ee\u6a19\u51fa\u529b\u3067\u3042\u308a\u3001 $y$ \u304c\u5bfe\u5fdc\u3059\u308b\uff08\u6b63\u3057\u3044\uff09\u76ee\u6a19\u51fa\u529b\u3067\u3042\u308a\u3001 $Var$ \u304c\u6a19\u6e96\u504f\u5dee\u306e2\u4e57\u3067\u3042\u308b\u5206\u6563\u3067\u3042\u308b\u5834\u5408\u3001\u8aac\u660e\u5909\u6570\u306f\u6b21\u306e\u3088\u3046\u306b\u63a8\u5b9a\u3055\u308c\u308b\u3002\n\n```math\n\\texttt{explained_variance}(y, \\hat{y}) = 1 - \\frac{Var\\{ y - \\hat{y}\\}}{Var\\{y\\}}\n```\n\n\u6700\u9ad8\u5f97\u70b9\u306f1.0\u3067\u3001\u5024\u304c\u4f4e\u3044\u307b\u3069\u60aa\u3044\u3067\u3059\u3002\n\u6b21\u306b\u3001explain_variance_score\u95a2\u6570\u306e\u4f7f\u7528\u4f8b\u3092\u793a\u3057\u307e\u3059\u3002\n\n```python\n>>> from sklearn.metrics import explained_variance_score\n>>> y_true = [3, -0.5, 2, 7]\n>>> y_pred = [2.5, 0.0, 2, 8]\n>>> explained_variance_score(y_true, y_pred)  \n0.957...\n>>> y_true = [[0.5, 1], [-1, 1], [7, -6]]\n>>> y_pred = [[0, 2], [-1, 2], [8, -5]]\n>>> explained_variance_score(y_true, y_pred, multioutput='raw_values')\n... \narray([ 0.967...,  1.        ])\n>>> explained_variance_score(y_true, y_pred, multioutput=[0.3, 0.7])\n... \n0.990...\n```\n\n### 3.3.4.2. \u5e73\u5747\u7d76\u5bfe\u8aa4\u5dee\n\n[mean_absolute_error](http://scikit-learn.org/0.18/modules/generated/sklearn.metrics.mean_absolute_error.html#sklearn.metrics.mean_absolute_error) \u95a2\u6570\u306f\u3001[\u5e73\u5747\u7d76\u5bfe\u8aa4\u5dee](https://en.wikipedia.org/wiki/Mean_absolute_error)\u3001\u7d76\u5bfe\u8aa4\u5dee\u640d\u5931\u307e\u305f\u306f $l1$ \u30ce\u30eb\u30e0\u640d\u5931\u306e\u671f\u5f85\u5024\u306b\u5bfe\u5fdc\u3059\u308b\u30ea\u30b9\u30af\u30e1\u30c8\u30ea\u30c3\u30af\u3092\u8a08\u7b97\u3057\u307e\u3059\u3002\n$\\hat {y} \\_i$ \u304c $i$ \u756a\u76ee\u306e\u30b5\u30f3\u30d7\u30eb\u306e\u4e88\u6e2c\u5024\u3067\u3042\u308a\u3001 $y\\_i$ \u304c\u5bfe\u5fdc\u3059\u308b\u771f\u306e\u5024\u3067\u3042\u308b\u5834\u5408\u3001$ n\\_{\\text{samples}}$ \u3067\u63a8\u5b9a\u3055\u308c\u305f\u5e73\u5747\u7d76\u5bfe\u8aa4\u5dee\uff08MAE\uff09\u306f\u6b21\u306e\u3088\u3046\u306b\u5b9a\u7fa9\u3055\u308c\u307e\u3059\u3002\n\n```math\n\\text{MAE}(y, \\hat{y}) = \\frac{1}{n_{\\text{samples}}} \\sum_{i=0}^{n_{\\text{samples}}-1} \\left| y_i - \\hat{y}_i \\right|.\n```\n\nmean_absolute_error\u95a2\u6570\u306e\u4f7f\u7528\u4f8b\u3092\u4ee5\u4e0b\u306b\u793a\u3057\u307e\u3059\u3002\n\n```python\n>>> from sklearn.metrics import mean_absolute_error\n>>> y_true = [3, -0.5, 2, 7]\n>>> y_pred = [2.5, 0.0, 2, 8]\n>>> mean_absolute_error(y_true, y_pred)\n0.5\n>>> y_true = [[0.5, 1], [-1, 1], [7, -6]]\n>>> y_pred = [[0, 2], [-1, 2], [8, -5]]\n>>> mean_absolute_error(y_true, y_pred)\n0.75\n>>> mean_absolute_error(y_true, y_pred, multioutput='raw_values')\narray([ 0.5,  1. ])\n>>> mean_absolute_error(y_true, y_pred, multioutput=[0.3, 0.7])\n... \n0.849...\n```\n\n### 3.3.4.3. \u5e73\u5747\u4e8c\u4e57\u8aa4\u5dee\n\n[mean_squared_error](http://scikit-learn.org/0.18/modules/generated/sklearn.metrics.mean_squared_error.html#sklearn.metrics.mean_squared_error) \u95a2\u6570\u306f\u3001\u4e8c\u4e57\uff08\u4e8c\u6b21\uff09\u30a8\u30e9\u30fc\u640d\u5931\u307e\u305f\u306f\u640d\u5931\u306e\u671f\u5f85\u5024\u306b\u5bfe\u5fdc\u3059\u308b\u30ea\u30b9\u30af\u30fb\u30e1\u30c8\u30ea\u30c3\u30af\u3067\u3042\u308b [\u5e73\u5747\u4e8c\u4e57\u8aa4\u5dee](https://en.wikipedia.org/wiki/Mean_squared_error) \u3092\u8a08\u7b97\u3057\u307e\u3059\u3002\n$\\hat {y} \\_i$ \u304c $i$ \u756a\u76ee\u306e\u30b5\u30f3\u30d7\u30eb\u306e\u4e88\u6e2c\u5024\u3067\u3042\u308a\u3001 $y\\_i$ \u304c\u5bfe\u5fdc\u3059\u308b\u771f\u306e\u5024\u3067\u3042\u308b\u5834\u5408\u3001 $ n\\_{\\text{samples}}$ \u3067\u63a8\u5b9a\u3055\u308c\u305f\u5e73\u5747\u4e8c\u4e57\u8aa4\u5dee\uff08MSE\uff09\u306f\u6b21\u306e\u3088\u3046\u306b\u5b9a\u7fa9\u3055\u308c\u307e\u3059\u3002\n\n```math\n\\text{MSE}(y, \\hat{y}) = \\frac{1}{n_\\text{samples}} \\sum_{i=0}^{n_\\text{samples} - 1} (y_i - \\hat{y}_i)^2.\n```\n\n\u4ee5\u4e0b\u306b\u3001mean_squared_error\u95a2\u6570\u306e\u4f7f\u7528\u4f8b\u3092\u793a\u3057\u307e\u3059\u3002\n\n```\n>>> from sklearn.metrics import mean_squared_error\n>>> y_true = [3, -0.5, 2, 7]\n>>> y_pred = [2.5, 0.0, 2, 8]\n>>> mean_squared_error(y_true, y_pred)\n0.375\n>>> y_true = [[0.5, 1], [-1, 1], [7, -6]]\n>>> y_pred = [[0, 2], [-1, 2], [8, -5]]\n>>> mean_squared_error(y_true, y_pred)  \n0.7083...\n```\n\n  - \u4f8b\uff1a\n    - \u52fe\u914d\u30d6\u30fc\u30b9\u30c6\u30a3\u30f3\u30b0\u56de\u5e30\u3092\u8a55\u4fa1\u3059\u308b\u305f\u3081\u306e\u4e8c\u4e57\u5e73\u5747\u8aa4\u5dee\u306e\u4f7f\u7528\u4f8b\u306b\u3064\u3044\u3066\u306f\u3001[\u52fe\u914d\u30d6\u30fc\u30b9\u30c8\u56de\u5e30](http://scikit-learn.org/0.18/auto_examples/ensemble/plot_gradient_boosting_regression.html#sphx-glr-auto-examples-ensemble-plot-gradient-boosting-regression-py) \u3092\u53c2\u7167\u3057\u3066\u304f\u3060\u3055\u3044\u3002\n\n### 3.3.4.4. \u4e2d\u592e\u7d76\u5bfe\u8aa4\u5dee\n\n[median_absolute_error](http://scikit-learn.org/0.18/modules/generated/sklearn.metrics.median_absolute_error.html#sklearn.metrics.median_absolute_error) \u306f\u7279\u306b\u7570\u5e38\u5024\u306b\u5bfe\u3057\u3066\u5805\u7262\u3067\u3042\u308b\u305f\u3081\u8208\u5473\u6df1\u3044\u3067\u3059\u3002\u640d\u5931\u306f\u200b\u200b\u3001\u30bf\u30fc\u30b2\u30c3\u30c8\u3068\u4e88\u6e2c\u3068\u306e\u9593\u306e\u3059\u3079\u3066\u306e\u7d76\u5bfe\u5dee\u306e\u4e2d\u592e\u5024\u3092\u53d6\u308b\u3053\u3068\u306b\u3088\u3063\u3066\u8a08\u7b97\u3055\u308c\u308b\u3002\n$\\hat {y} \\_i$ \u304c $i$ \u756a\u76ee\u306e\u30b5\u30f3\u30d7\u30eb\u306e\u4e88\u6e2c\u5024\u3067\u3042\u308a\u3001 $y\\_i$ \u304c\u5bfe\u5fdc\u3059\u308b\u771f\u306e\u5024\u3067\u3042\u308b\u5834\u5408\u3001 $ n\\_{\\text{samples}} $ \u3067\u63a8\u5b9a\u3055\u308c\u305f\u30e1\u30b8\u30a2\u30f3\u7d76\u5bfe\u8aa4\u5dee\uff08MedAE\uff09\u306f\u6b21\u306e\u3088\u3046\u306b\u5b9a\u7fa9\u3055\u308c\u307e\u3059\u3002\n\n```math\n\\text{MedAE}(y, \\hat{y}) = \\text{median}(\\mid y_1 - \\hat{y}_1 \\mid, \\ldots, \\mid y_n - \\hat{y}_n \\mid).\n```\n\nmedian_absolute_error\u306f\u30de\u30eb\u30c1\u51fa\u529b\u3092\u30b5\u30dd\u30fc\u30c8\u3057\u3066\u3044\u307e\u305b\u3093\u3002\n\u6b21\u306b\u3001median_absolute_error\u95a2\u6570\u306e\u4f7f\u7528\u4f8b\u3092\u793a\u3057\u307e\u3059\u3002\n\n```python\n>>> from sklearn.metrics import median_absolute_error\n>>> y_true = [3, -0.5, 2, 7]\n>>> y_pred = [2.5, 0.0, 2, 8]\n>>> median_absolute_error(y_true, y_pred)\n0.5\n```\n\n### 3.3.4.5. R\u00b2\u30b9\u30b3\u30a2\u3001\u6c7a\u5b9a\u4fc2\u6570\n\n[r2_score](http://scikit-learn.org/0.18/modules/generated/sklearn.metrics.r2_score.html#sklearn.metrics.r2_score) \u95a2\u6570\u306f\u3001[\u6c7a\u5b9a\u4fc2\u6570](https://en.wikipedia.org/wiki/Coefficient_of_determination) \u3067\u3042\u308bR\u00b2\u3092\u8a08\u7b97\u3057\u307e\u3059\u3002\u3053\u308c\u306f\u3001\u5c06\u6765\u306e\u30b5\u30f3\u30d7\u30eb\u304c\u30e2\u30c7\u30eb\u306b\u3088\u3063\u3066\u4e88\u6e2c\u3055\u308c\u308b\u53ef\u80fd\u6027\u304c\u9ad8\u3044\u3053\u3068\u306e\u6307\u6a19\u3092\u63d0\u4f9b\u3057\u307e\u3059\u3002\u53ef\u80fd\u306a\u6700\u9ad8\u5f97\u70b9\u306f1.0\u3067\u3042\u308a\u3001\u8ca0\u3067\u3042\u308a\u5f97\u308b\uff08\u30e2\u30c7\u30eb\u304c\u4efb\u610f\u306b\u60aa\u5316\u3059\u308b\u53ef\u80fd\u6027\u304c\u3042\u308b\u305f\u3081\uff09\u3002\u5165\u529b\u7279\u5fb4\u91cf\u3092\u7121\u8996\u3057\u3066y\u306e\u671f\u5f85\u5024\u3092\u5e38\u306b\u4e88\u6e2c\u3059\u308b\u5b9a\u6570\u30e2\u30c7\u30eb\u3067\u306f\u3001R ^ 2\u30b9\u30b3\u30a2\u304c0.0\u306b\u306a\u308a\u307e\u3059\u3002\n$\\ hat {y} \\_i$ \u304c $i$ \u756a\u76ee\u306e\u30b5\u30f3\u30d7\u30eb\u306e\u4e88\u6e2c\u5024\u3067\u3042\u308a\u3001 $y\\_i$ \u304c\u5bfe\u5fdc\u3059\u308b\u771f\u306e\u5024\u3067\u3042\u308b\u5834\u5408\u3001 $n\\_{\\text{samples}}$ \u3067\u63a8\u5b9a\u3055\u308c\u305f\u30b9\u30b3\u30a2R\u00b2\u306f\u6b21\u306e\u3088\u3046\u306b\u5b9a\u7fa9\u3055\u308c\u307e\u3059\u3002\n\n```math\nR^2(y, \\hat{y}) = 1 - \\frac{\\sum_{i=0}^{n_{\\text{samples}} - 1} (y_i - \\hat{y}_i)^2}{\\sum_{i=0}^{n_\\text{samples} - 1} (y_i - \\bar{y})^2}\n```\n\n$\\bar{y} =  \\frac{1}{n_{\\text{samples}}} \\sum_{i=0}^{n_{\\text{samples}} - 1} y_i$. \u3067\u3059\u3002\n\u6b21\u306b\u3001r2_score\u95a2\u6570\u306e\u4f7f\u7528\u4f8b\u3092\u793a\u3057\u307e\u3059\u3002\n\n```\n>>> from sklearn.metrics import r2_score\n>>> y_true = [3, -0.5, 2, 7]\n>>> y_pred = [2.5, 0.0, 2, 8]\n>>> r2_score(y_true, y_pred)  \n0.948...\n>>> y_true = [[0.5, 1], [-1, 1], [7, -6]]\n>>> y_pred = [[0, 2], [-1, 2], [8, -5]]\n>>> r2_score(y_true, y_pred, multioutput='variance_weighted')\n... \n0.938...\n>>> y_true = [[0.5, 1], [-1, 1], [7, -6]]\n>>> y_pred = [[0, 2], [-1, 2], [8, -5]]\n>>> r2_score(y_true, y_pred, multioutput='uniform_average')\n... \n0.936...\n>>> r2_score(y_true, y_pred, multioutput='raw_values')\n... \narray([ 0.965...,  0.908...])\n>>> r2_score(y_true, y_pred, multioutput=[0.3, 0.7])\n... \n0.925...\n```\n\n  - \u4f8b\uff1a\n    - \u758e\u306a\u4fe1\u53f7\u3067Lasso\u3068Elastic Net\u3092\u8a55\u4fa1\u3059\u308b\u305f\u3081\u306eR\u00b2\u30b9\u30b3\u30a2\u306e\u4f7f\u7528\u4f8b\u306b\u3064\u3044\u3066\u306f\u3001[\u758e\u4fe1\u53f7\u7528\u306eLasso\u3068Elastic Net](http://scikit-learn.org/0.18/auto_examples/linear_model/plot_lasso_and_elasticnet.html#sphx-glr-auto-examples-linear-model-plot-lasso-and-elasticnet-py) \u3092\u53c2\u7167\u3057\u3066\u304f\u3060\u3055\u3044\u3002\n\n\n## 3.3.5. \u30af\u30e9\u30b9\u30bf\u30ea\u30f3\u30b0\u30e1\u30c8\u30ea\u30c3\u30af\n\nsklearn.metrics\u30e2\u30b8\u30e5\u30fc\u30eb\u306f\u3001\u3044\u304f\u3064\u304b\u306e\u640d\u5931\u3001\u30b9\u30b3\u30a2\u3001\u304a\u3088\u3073\u30e6\u30fc\u30c6\u30a3\u30ea\u30c6\u30a3\u95a2\u6570\u3092\u5b9f\u88c5\u3057\u3066\u3044\u307e\u3059\u3002\u8a73\u7d30\u306b\u3064\u3044\u3066\u306f\u3001\u30a4\u30f3\u30b9\u30bf\u30f3\u30b9\u30af\u30e9\u30b9\u30bf\u30ea\u30f3\u30b0\u306e [\u30af\u30e9\u30b9\u30bf\u30ea\u30f3\u30b0\u30d1\u30d5\u30a9\u30fc\u30de\u30f3\u30b9\u8a55\u4fa1](http://scikit-learn.org/0.18/modules/clustering.html#clustering-evaluation) \u30bb\u30af\u30b7\u30e7\u30f3\u3001\u304a\u3088\u3073\u30d0\u30a4\u30af\u30e9\u30b9\u30bf\u30ea\u30f3\u30b0\u306e [Biclustering\u8a55\u4fa1](http://scikit-learn.org/0.18/modules/biclustering.html#biclustering-evaluation) \u3092\u53c2\u7167\u3057\u3066\u304f\u3060\u3055\u3044\u3002\n\n## 3.3.6. \u30c0\u30df\u30fc\u898b\u7a4d\u3082\u308a\n\n\u6559\u5e2b\u3042\u308a\u5b66\u7fd2\u3092\u3059\u308b\u3068\u304d\u3001\u5358\u7d14\u306a\u5065\u5168\u6027\u30c1\u30a7\u30c3\u30af\u306f\u3001\u63a8\u5b9a\u5668\u3092\u5358\u7d14\u306a\u7d4c\u9a13\u5247\u3068\u6bd4\u8f03\u3059\u308b\u3053\u3068\u304b\u3089\u6210\u308a\u307e\u3059\u3002 [DummyClassifier](http://scikit-learn.org/0.18/modules/generated/sklearn.dummy.DummyClassifier.html#sklearn.dummy.DummyClassifier) \u306f\u3001\u5206\u985e\u306e\u305f\u3081\u306e\u3053\u306e\u3088\u3046\u306a\u5358\u7d14\u306a\u6226\u7565\u3092\u3044\u304f\u3064\u304b\u5b9f\u88c5\u3057\u3066\u3044\u307e\u3059\u3002\n\n  - `stratified` \u306f\u3001\u30c8\u30ec\u30fc\u30cb\u30f3\u30b0\u30bb\u30c3\u30c8\u30af\u30e9\u30b9\u5206\u5e03\u3092\u5c0a\u91cd\u3059\u308b\u3053\u3068\u306b\u3088\u3063\u3066\u30e9\u30f3\u30c0\u30e0\u4e88\u6e2c\u3092\u751f\u6210\u3059\u308b\u3002\n  - `most_frequent` \u306f\u3001\u30c8\u30ec\u30fc\u30cb\u30f3\u30b0\u30bb\u30c3\u30c8\u5185\u306e\u6700\u3082\u983b\u7e41\u306a\u30e9\u30d9\u30eb\u3092\u5e38\u306b\u4e88\u6e2c\u3057\u307e\u3059\u3002\n  - `prior` \u306f\u5e38\u306bclass\u3092\u6700\u5927\u306b\u3059\u308b\u30af\u30e9\u30b9\u3092\uff08`most_frequent`\u306e\u3088\u3046\u306b\uff09\u4e88\u6e2c\u3057\u3001 `predict_proba` \u306f\u30af\u30e9\u30b9\u3092\u5148\u306b\u8fd4\u3057\u307e\u3059\u3002\n  - `uniform` \u306f\u30e9\u30f3\u30c0\u30e0\u306b\u4e00\u69d8\u306b\u4e88\u6e2c\u3092\u751f\u6210\u3057\u307e\u3059\u3002\n  - `constant` \u306f **\u5e38\u306b\u30e6\u30fc\u30b6\u30fc\u304c\u63d0\u4f9b\u3059\u308b\u5b9a\u6570\u30e9\u30d9\u30eb\u3092\u4e88\u6e2c\u3068\u3057\u3066\u8fd4\u3057\u307e\u3059\u3002**\n    - \u3053\u306e\u65b9\u6cd5\u306e\u4e3b\u306a\u52d5\u6a5f\u306f\u3001\u30dd\u30b8\u30c6\u30a3\u30d6\u306a\u30af\u30e9\u30b9\u304c\u5c11\u6570\u6d3e\u3067\u3042\u308b\u5834\u5408\u306bF1\u30b9\u30b3\u30a2\u30ea\u30f3\u30b0\u3067\u3042\u308b\u3002\n\n\u3053\u308c\u3089\u306e\u3059\u3079\u3066\u306e\u6226\u7565\u3067\u306f\u3001 `predict` \u30e1\u30bd\u30c3\u30c9\u306f\u5165\u529b\u30c7\u30fc\u30bf\u3092\u5b8c\u5168\u306b\u7121\u8996\u3057\u307e\u3059\u3002\nDummyClassifier\u3092\u8aac\u660e\u3059\u308b\u306b\u306f\u3001\u307e\u305a\u4e0d\u5747\u8861\u306a\u30c7\u30fc\u30bf\u30bb\u30c3\u30c8\u3092\u4f5c\u6210\u3057\u307e\u3057\u3087\u3046\uff1a\n\n```python\n>>> from sklearn.datasets import load_iris\n>>> from sklearn.model_selection import train_test_split\n>>> iris = load_iris()\n>>> X, y = iris.data, iris.target\n>>> y[y != 1] = -1\n>>> X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=0)\n```\n\n\u6b21\u306b\u3001`SVC` \u3068 `most_frequent` \u306e\u7cbe\u5ea6\u3092\u6bd4\u8f03\u3057\u3066\u307f\u307e\u3057\u3087\u3046\u3002\n\n```python\n>>> from sklearn.dummy import DummyClassifier\n>>> from sklearn.svm import SVC\n>>> clf = SVC(kernel='linear', C=1).fit(X_train, y_train)\n>>> clf.score(X_test, y_test) \n0.63...\n>>> clf = DummyClassifier(strategy='most_frequent',random_state=0)\n>>> clf.fit(X_train, y_train)\nDummyClassifier(constant=None, random_state=0, strategy='most_frequent')\n>>> clf.score(X_test, y_test)  \n0.57...\n```\n\n\u79c1\u305f\u3061\u306f\u3001SVC\u304c\u30c0\u30df\u30fc\u306e\u5206\u985e\u5668\u3088\u308a\u3082\u306f\u308b\u304b\u306b\u512a\u308c\u3066\u3044\u306a\u3044\u3053\u3068\u304c\u308f\u304b\u308a\u307e\u3059\u3002\u3055\u3066\u3001\u30ab\u30fc\u30cd\u30eb\u3092\u5909\u66f4\u3057\u307e\u3057\u3087\u3046\uff1a\n\n```python\n>>> clf = SVC(kernel='rbf', C=1).fit(X_train, y_train)\n>>> clf.score(X_test, y_test)  \n0.97...\n```\n\n\u7cbe\u5ea6\u306f\u307b\u307c100\uff05\u306b\u5411\u4e0a\u3057\u307e\u3057\u305f\u3002 CPU\u306e\u30b3\u30b9\u30c8\u304c\u305d\u308c\u307b\u3069\u9ad8\u304f\u306a\u3044\u5834\u5408\u306f\u3001\u7cbe\u5ea6\u3092\u3088\u308a\u6b63\u78ba\u306b\u8a55\u4fa1\u3059\u308b\u305f\u3081\u306b\u3001\u30af\u30ed\u30b9\u30d0\u30ea\u30c7\u30fc\u30b7\u30e7\u30f3\u3092\u63a8\u5968\u3057\u307e\u3059\u3002\u8a73\u7d30\u306b\u3064\u3044\u3066\u306f\u3001 [\u30af\u30ed\u30b9\u30d0\u30ea\u30c7\u30fc\u30b7\u30e7\u30f3\uff1a\u898b\u7a4d\u3082\u308a\u30d1\u30d5\u30a9\u30fc\u30de\u30f3\u30b9\u306e\u8a55\u4fa1](http://qiita.com/nazoking@github/items/13b167283590f512d99a) \u30bb\u30af\u30b7\u30e7\u30f3\u3092\u53c2\u7167\u3057\u3066\u304f\u3060\u3055\u3044\u3002\u3055\u3089\u306b\u3001\u30d1\u30e9\u30e1\u30fc\u30bf\u7a7a\u9593\u3092\u6700\u9069\u5316\u3059\u308b\u5834\u5408\u306f\u3001\u9069\u5207\u306a\u65b9\u6cd5\u3092\u4f7f\u7528\u3059\u308b\u3053\u3068\u3092\u5f37\u304f\u304a\u52e7\u3081\u3057\u307e\u3059\u3002\u8a73\u7d30\u306b\u3064\u3044\u3066\u306f\u3001[\u63a8\u5b9a\u5668\u306e\u30cf\u30a4\u30d1\u30fc\u30d1\u30e9\u30e1\u30fc\u30bf\u306e\u30c1\u30e5\u30fc\u30cb\u30f3\u30b0](http://scikit-learn.org/0.18/modules/grid_search.html#grid-search) \u30bb\u30af\u30b7\u30e7\u30f3\u3092\u53c2\u7167\u3057\u3066\u304f\u3060\u3055\u3044\u3002\n\u3088\u308a\u4e00\u822c\u7684\u306b\u306f\u3001\u5206\u985e\u5668\u306e\u7cbe\u5ea6\u304c\u30e9\u30f3\u30c0\u30e0\u306b\u8fd1\u3059\u304e\u308b\u3068\u3001\u4f55\u304b\u304c\u9593\u9055\u3063\u3066\u3044\u308b\u53ef\u80fd\u6027\u304c\u3042\u308a\u307e\u3059\u3002\u7279\u5fb4\u91cf\u304c\u5f79\u7acb\u305f\u305a\u3001\u30cf\u30a4\u30d1\u30fc\u30d1\u30e9\u30e1\u30fc\u30bf\u304c\u6b63\u3057\u304f\u8abf\u6574\u3055\u308c\u3066\u3044\u306a\u3044\u3001\u5206\u985e\u5668\u304c\u30af\u30e9\u30b9\u306e\u4e0d\u5747\u8861\u306a\u3069\u306b\u82e6\u3057\u3093\u3067\u3044\u307e\u3059\u3002\n\n[DummyRegressor](http://scikit-learn.org/0.18/modules/generated/sklearn.dummy.DummyRegressor.html#sklearn.dummy.DummyRegressor) \u306f\u307e\u305f\u3001\u56de\u5e30\u306e\u305f\u3081\u306e4\u3064\u306e\u7c21\u5358\u306a\u7d4c\u9a13\u5247\u3092\u5b9f\u88c5\u3057\u3066\u3044\u307e\u3059\u3002\n\n  - `mean` \u306f\u5e38\u306b\u8a13\u7df4\u76ee\u6a19\u306e\u5e73\u5747\u3092\u4e88\u6e2c\u3059\u308b\u3002\n  - `median` \u306f\u5e38\u306b\u8a13\u7df4\u76ee\u6a19\u306e\u4e2d\u592e\u5024\u3092\u4e88\u6e2c\u3059\u308b\u3002\n  - `quantile` \u306f\u3001\u5e38\u306b\u3001\u30e6\u30fc\u30b6\u30fc\u304c\u8a13\u7df4\u76ee\u6a19\u306e\u5206\u4f4d\u70b9\u3092\u63d0\u4f9b\u3059\u308b\u3053\u3068\u3092\u4e88\u6e2c\u3057\u307e\u3059\u3002\n  - `constant` \u306f\u3001\u5e38\u306b\u30e6\u30fc\u30b6\u30fc\u306b\u3088\u3063\u3066\u63d0\u4f9b\u3055\u308c\u308b\u4e00\u5b9a\u306e\u5024\u3092\u4e88\u6e2c\u3068\u3057\u3066\u8fd4\u3057\u307e\u3059\u3002\n\n\u3053\u308c\u3089\u306e\u6226\u7565\u3059\u3079\u3066\u306b\u304a\u3044\u3066\u3001`predict` \u30e1\u30bd\u30c3\u30c9\u306f\u5165\u529b\u30c7\u30fc\u30bf\u3092\u5b8c\u5168\u306b\u7121\u8996\u3059\u308b\u3002\n\n\u00a92010 - 2016\u3001scikit-learn developers\uff08BSD\u30e9\u30a4\u30bb\u30f3\u30b9\uff09\u3002\n"}