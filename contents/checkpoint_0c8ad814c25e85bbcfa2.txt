{"context": "\n\nScrapy\u5165\u9580\uff08\uff13\uff09\n\n\u306f\u3058\u3081\u306b\nScrapy\u5165\u9580\uff08\uff11\uff09\nScrapy\u5165\u9580\uff08\uff12\uff09\n\u524d\u56de\u307e\u3067\u306e\u8a18\u4e8b\u3067\u306f\u3001Scrapy\u3092\u5229\u7528\u3057\u3066WebAPI\u3092\u30b3\u30fc\u30eb\u3059\u308b\u65b9\u6cd5\u3092\u8a66\u3057\u307e\u3057\u305f\u3002\u4eca\u56de\u306f\u30d5\u30a1\u30a4\u30eb\u306e\u30c0\u30a6\u30f3\u30ed\u30fc\u30c9\u51e6\u7406\u3092\u884c\u3046Spider\u3092\u4f5c\u6210\u3057\u3066\u307f\u307e\u3057\u3087\u3046\u3002\n\nSpider\u306e\u4f5c\u6210\n\u4eca\u56de\u306fMLB\u306b\u95a2\u3059\u308b\u30c7\u30fc\u30bf\uff08zip\u30d5\u30a1\u30a4\u30eb\uff09\u3092\u30c0\u30a6\u30f3\u30ed\u30fc\u30c9\u3059\u308bSpider\u3092\u4f5c\u6210\u3057\u307e\u3059\u3002\u5b9f\u969b\u306e\u30c7\u30fc\u30bf\u306fSean Lahman Database\u3067\u516c\u958b\u3055\u308c\u3066\u3044\u308b\u30c7\u30fc\u30bf\u3092\u5229\u7528\u3057\u307e\u3059\u3002\u30c0\u30a6\u30f3\u30ed\u30fc\u30c9\u3057\u305fzip\u30d5\u30a1\u30a4\u30eb\u306f\u4efb\u610f\u306e\u30c7\u30a3\u30ec\u30af\u30c8\u30ea\u306b\u4fdd\u5b58\u3059\u308b\u3053\u3068\u306b\u3057\u307e\u3057\u3087\u3046\u3002\nSprider\u306e\u51e6\u7406\u306e\u6d41\u308c\u306f\u6b21\u306e\u901a\u308a\u3067\u3059\u3002\n\nstart_urls\u306e\u30da\u30fc\u30b8\u306e\u5185\u5bb9\u3092\u53d6\u5f97\n\u53d6\u5f97\u3057\u305f\u30da\u30fc\u30b8\u306e\u5185\u5bb9\u3092\u89e3\u6790\u3057\u3001a\u30bf\u30b0\u306ehref\u306bcsv\u306e\u6587\u5b57\u5217\u304c\u542b\u307e\u308c\u3066\u3044\u308burl\u3092\u53d6\u5f97\n\u4e0a\u8a18\u3067\u53d6\u5f97\u3057\u305furl\u306e\u5185\u5bb9\u3092\u53d6\u5f97\n\n\nget_csv_spider.py\n# -*- coding:utf-8 -*-\n\nfrom scrapy import Spider\nfrom scrapy.http import Request\n\n\nclass GetCSVSpider(Spider):\n    name = 'get_csv_spider'\n    allowed_domains = ['seanlahman.com']\n\n    custom_settings = {\n        'DOWNLOAD_DELAY': 1.5,\n    }\n\n    # CSV\u30d5\u30a1\u30a4\u30eb\u3092\u4fdd\u5b58\u3059\u308b\u4efb\u610f\u306e\u30c7\u30a3\u30ec\u30af\u30c8\u30ea\n    DIR_NAME = '/tmp/csv/'\n\n    # \u30a8\u30f3\u30c9\u30dd\u30a4\u30f3\u30c8\uff08\u30af\u30ed\u30fc\u30ea\u30f3\u30b0\u3092\u958b\u59cb\u3059\u308bURL\u3092\u8a18\u8f09\u3059\u308b\uff09\n    start_urls = ['http://seanlahman.com/baseball-archive/statistics/']\n\n    # URL\u306e\u62bd\u51fa\u51e6\u7406\u3092\u8a18\u8f09\n    def parse(self, response):\n        for href in response.css('.entry-content a[href*=csv]::attr(href)'):\n            full_url = response.urljoin(href.extract())\n\n            # \u62bd\u51fa\u3057\u305fURL\u3092\u5143\u306bRequest\u3092\u4f5c\u6210\u3057\u3001\u30c0\u30a6\u30f3\u30ed\u30fc\u30c9\u3059\u308b\n            yield Request(full_url, callback=self.parse_item)\n\n    # \u30c0\u30a6\u30f3\u30ed\u30fc\u30c9\u3057\u305f\u30da\u30fc\u30b8\u3092\u5143\u306b\u3001\u5185\u5bb9\u3092\u62bd\u51fa\u3057\u4fdd\u5b58\u3059\u308b\n    def parse_item(self, response):\n\n        file_name = '{0}{1}'.format(self.DIR_NAME, response.url.split('/')[-1])\n\n        # \u30d5\u30a1\u30a4\u30eb\u306e\u4fdd\u5b58\n        f = open(file_name, 'w')\n        f.write(response.body)\n        f.close()\n\n\n\n\u5b9f\u884c\nScrapy\u4ed8\u5c5e\u306e\u30b3\u30de\u30f3\u30c9\u3092\u5229\u7528\u3057\u3066\u30af\u30ed\u30fc\u30eb\u3092\u5b9f\u884c\u3057\u307e\u3059\u3002\nscrapy runspider get_csv_spider\n\n\u30b3\u30de\u30f3\u30c9\u3092\u5b9f\u884c\u3059\u308b\u3068\u4e0b\u8a18\u306e\u3088\u3046\u306a\u30ed\u30b0\u304c\u30b3\u30f3\u30bd\u30fc\u30eb\u306b\u8868\u793a\u3055\u308c\u307e\u3059\u3002\u30ed\u30b0\u306b\u306f\u53d6\u5f97\u4e2d\u306eURL\u3001\u30b9\u30c6\u30fc\u30bf\u30b9\u3001\u30d0\u30a4\u30c8\u6570\u3001\u30b5\u30de\u30ea\u30fc\u306a\u3069\u6709\u76ca\u306a\u60c5\u5831\u304c\u8868\u793a\u3055\u308c\u307e\u3059\u3002\n2016-12-06 10:02:22 [scrapy] INFO: Scrapy 1.2.0 started (bot: scrapybot)\n2016-12-06 10:02:22 [scrapy] INFO: Overridden settings: {'TELNETCONSOLE_ENABLED': False, 'SPIDER_MODULES': ['crawler.main.spiders'], 'COOKIES_ENABLED': False, 'DOWNLOAD_DELAY': 1}\n2016-12-06 10:02:22 [scrapy] INFO: Enabled extensions:\n['scrapy.extensions.logstats.LogStats',\n 'scrapy.extensions.corestats.CoreStats']\n2016-12-06 10:02:22 [scrapy] INFO: Enabled downloader middlewares:\n['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',\n 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',\n 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',\n 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',\n 'scrapy.downloadermiddlewares.retry.RetryMiddleware',\n 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',\n 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',\n 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',\n 'scrapy.downloadermiddlewares.chunked.ChunkedTransferMiddleware',\n 'scrapy.downloadermiddlewares.stats.DownloaderStats']\n2016-12-06 10:02:22 [scrapy] INFO: Enabled spider middlewares:\n['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',\n 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',\n 'scrapy.spidermiddlewares.referer.RefererMiddleware',\n 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',\n 'scrapy.spidermiddlewares.depth.DepthMiddleware']\n2016-12-06 10:02:22 [scrapy] INFO: Enabled item pipelines:\n[]\n2016-12-06 10:02:22 [scrapy] INFO: Spider opened\n2016-12-06 10:02:22 [scrapy] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)\n2016-12-06 10:02:23 [scrapy] DEBUG: Crawled (200) <GET http://seanlahman.com/baseball-archive/statistics/> (referer: None)\n2016-12-06 10:02:28 [scrapy] DEBUG: Crawled (200) <GET http://seanlahman.com/files/database/lahman30_csv.zip> (referer: http://seanlahman.com/baseball-archive/statistics/)\n2016-12-06 10:02:35 [scrapy] DEBUG: Crawled (200) <GET http://seanlahman.com/files/database/lahman51-csv.zip> (referer: http://seanlahman.com/baseball-archive/statistics/)\n2016-12-06 10:02:38 [scrapy] DEBUG: Crawled (200) <GET http://seanlahman.com/files/database/lahman_50-csv.zip> (referer: http://seanlahman.com/baseball-archive/statistics/)\n2016-12-06 10:02:39 [scrapy] DEBUG: Crawled (200) <GET http://seanlahman.com/files/database/lahman53_csv.zip> (referer: http://seanlahman.com/baseball-archive/statistics/)\n2016-12-06 10:02:41 [scrapy] DEBUG: Crawled (200) <GET http://seanlahman.com/files/database/lahman56-csv.zip> (referer: http://seanlahman.com/baseball-archive/statistics/)\n2016-12-06 10:02:41 [scrapy] DEBUG: Crawled (200) <GET http://seanlahman.com/files/database/lahman52_csv.zip> (referer: http://seanlahman.com/baseball-archive/statistics/)\n2016-12-06 10:02:42 [scrapy] DEBUG: Crawled (200) <GET http://seanlahman.com/files/database/lahman54_csv.zip> (referer: http://seanlahman.com/baseball-archive/statistics/)\n2016-12-06 10:02:47 [scrapy] DEBUG: Crawled (200) <GET http://seanlahman.com/files/database/lahman591-csv.zip> (referer: http://seanlahman.com/baseball-archive/statistics/)\n2016-12-06 10:02:49 [scrapy] DEBUG: Crawled (200) <GET http://seanlahman.com/files/database/lahman55_csv.zip> (referer: http://seanlahman.com/baseball-archive/statistics/)\n2016-12-06 10:02:49 [scrapy] DEBUG: Crawled (200) <GET http://seanlahman.com/files/database/lahman57-csv.zip> (referer: http://seanlahman.com/baseball-archive/statistics/)\n2016-12-06 10:02:52 [scrapy] DEBUG: Crawled (200) <GET http://seanlahman.com/files/database/lahman58-csv.zip> (referer: http://seanlahman.com/baseball-archive/statistics/)\n2016-12-06 10:02:55 [scrapy] DEBUG: Crawled (200) <GET http://seanlahman.com/files/database/lahman-csv_2014-02-14.zip> (referer: http://seanlahman.com/baseball-archive/statistics/)\n2016-12-06 10:02:55 [scrapy] DEBUG: Crawled (200) <GET http://seanlahman.com/files/database/lahman-csv_2015-01-24.zip> (referer: http://seanlahman.com/baseball-archive/statistics/)\n2016-12-06 10:03:00 [scrapy] DEBUG: Crawled (200) <GET http://seanlahman.com/files/database/lahman2012-csv.zip> (referer: http://seanlahman.com/baseball-archive/statistics/)\n2016-12-06 10:03:00 [scrapy] INFO: Closing spider (finished)\n2016-12-06 10:03:00 [scrapy] INFO: Dumping Scrapy stats:\n{'downloader/request_bytes': 4518,\n 'downloader/request_count': 15,\n 'downloader/request_method_count/GET': 15,\n 'downloader/response_bytes': 104279737,\n 'downloader/response_count': 15,\n 'downloader/response_status_count/200': 15,\n 'finish_reason': 'finished',\n 'finish_time': datetime.datetime(2016, 12, 6, 1, 3, 0, 285944),\n 'log_count/DEBUG': 15,\n 'log_count/INFO': 7,\n 'request_depth_max': 1,\n 'response_received_count': 15,\n 'scheduler/dequeued': 15,\n 'scheduler/dequeued/memory': 15,\n 'scheduler/enqueued': 15,\n 'scheduler/enqueued/memory': 15,\n 'start_time': datetime.datetime(2016, 12, 6, 1, 2, 22, 878024)}\n2016-12-06 10:03:00 [scrapy] INFO: Spider closed (finished)\n\n\u30c0\u30a6\u30f3\u30ed\u30fc\u30c9\u304c\u5b8c\u4e86\u3057\u305f\u306e\u3067\u5b9f\u969b\u306b\u30c0\u30a6\u30f3\u30ed\u30fc\u30c9\u3055\u308c\u3066\u3044\u308b\u304b\u78ba\u8a8d\u3057\u307e\u3057\u3087\u3046\u3002\n\u7121\u4e8b\u30c0\u30a6\u30f3\u30ed\u30fc\u30c9\u3055\u308c\u3066\u3044\u308b\u3088\u3046\u3067\u3059\u306d\u3002\ntree /tmp/csv\n\n/tmp/csv\n\u251c\u2500\u2500 lahman-csv_2014-02-14.zip\n\u251c\u2500\u2500 lahman-csv_2015-01-24.zip\n\u251c\u2500\u2500 lahman2012-csv.zip\n\u251c\u2500\u2500 lahman30_csv.zip\n\u251c\u2500\u2500 lahman51-csv.zip\n\u251c\u2500\u2500 lahman52_csv.zip\n\u251c\u2500\u2500 lahman53_csv.zip\n\u251c\u2500\u2500 lahman54_csv.zip\n\u251c\u2500\u2500 lahman55_csv.zip\n\u251c\u2500\u2500 lahman56-csv.zip\n\u251c\u2500\u2500 lahman57-csv.zip\n\u251c\u2500\u2500 lahman58-csv.zip\n\u251c\u2500\u2500 lahman591-csv.zip\n\u2514\u2500\u2500 lahman_50-csv.zip\n\n0 directories, 14 files\n\n\n\u7d42\u308f\u308a\u306b\nScrapy\u3092\u4f7f\u7528\u3059\u308b\u3068\u3001\u30d5\u30a1\u30a4\u30eb\u306e\u30c0\u30a6\u30f3\u30ed\u30fc\u30c9\u51e6\u7406\u3082\u7c21\u5358\u306b\u8a18\u8ff0\u3059\u308b\u3053\u3068\u304c\u3067\u304d\u307e\u3059\u3002Scrapy\u306f\u30af\u30ed\u30fc\u30ea\u30f3\u30b0\u7528\u306e\u30d5\u30ec\u30fc\u30e0\u30ef\u30fc\u30af\u306a\u306e\u3067\u3001\u958b\u767a\u8005\u306f\u30d5\u30ec\u30fc\u30e0\u30ef\u30fc\u30af\u304b\u3089\u547c\u3073\u51fa\u3055\u308c\u308b\u90e8\u5206\u306b\u306e\u307f\u96c6\u4e2d\u3057\u3066\u958b\u767a\u3059\u308b\u3053\u3068\u304c\u53ef\u80fd\u3067\u3059\u3002\u6b21\u56de\u4ee5\u964d\u306f\u4eca\u56de\u8aac\u660e\u3057\u306a\u304b\u3063\u305f\u3001\u30c7\u30fc\u30bf\u306e\u30d1\u30a4\u30d7\u30e9\u30a4\u30f3\u51e6\u7406\u306b\u3064\u3044\u3066\u53d6\u308a\u4e0a\u3052\u307e\u3059\u3002\u304a\u697d\u3057\u307f\u306b\uff01\n\n\u53c2\u8003URL\n\nhttp://www.slideshare.net/shinyorke/python-39061157\nhttp://qiita.com/checkpoint/items/d9bcc63292d7f01c62d3\n\n# Scrapy\u5165\u9580\uff08\uff13\uff09\n\n## \u306f\u3058\u3081\u306b\n\n[Scrapy\u5165\u9580\uff08\uff11\uff09](http://qiita.com/checkpoint/items/038b59b29df8e1e384a2)\n[Scrapy\u5165\u9580\uff08\uff12\uff09](http://qiita.com/checkpoint/items/65bb757d305f4a1288c0)\n\n\u524d\u56de\u307e\u3067\u306e\u8a18\u4e8b\u3067\u306f\u3001Scrapy\u3092\u5229\u7528\u3057\u3066WebAPI\u3092\u30b3\u30fc\u30eb\u3059\u308b\u65b9\u6cd5\u3092\u8a66\u3057\u307e\u3057\u305f\u3002\u4eca\u56de\u306f\u30d5\u30a1\u30a4\u30eb\u306e\u30c0\u30a6\u30f3\u30ed\u30fc\u30c9\u51e6\u7406\u3092\u884c\u3046Spider\u3092\u4f5c\u6210\u3057\u3066\u307f\u307e\u3057\u3087\u3046\u3002\n\n## Spider\u306e\u4f5c\u6210\n\n\u4eca\u56de\u306fMLB\u306b\u95a2\u3059\u308b\u30c7\u30fc\u30bf\uff08zip\u30d5\u30a1\u30a4\u30eb\uff09\u3092\u30c0\u30a6\u30f3\u30ed\u30fc\u30c9\u3059\u308bSpider\u3092\u4f5c\u6210\u3057\u307e\u3059\u3002\u5b9f\u969b\u306e\u30c7\u30fc\u30bf\u306f[Sean Lahman Database](http://seanlahman.com/baseball-archive/statistics/)\u3067\u516c\u958b\u3055\u308c\u3066\u3044\u308b\u30c7\u30fc\u30bf\u3092\u5229\u7528\u3057\u307e\u3059\u3002\u30c0\u30a6\u30f3\u30ed\u30fc\u30c9\u3057\u305fzip\u30d5\u30a1\u30a4\u30eb\u306f\u4efb\u610f\u306e\u30c7\u30a3\u30ec\u30af\u30c8\u30ea\u306b\u4fdd\u5b58\u3059\u308b\u3053\u3068\u306b\u3057\u307e\u3057\u3087\u3046\u3002\n\nSprider\u306e\u51e6\u7406\u306e\u6d41\u308c\u306f\u6b21\u306e\u901a\u308a\u3067\u3059\u3002\n\n* start_urls\u306e\u30da\u30fc\u30b8\u306e\u5185\u5bb9\u3092\u53d6\u5f97\n* \u53d6\u5f97\u3057\u305f\u30da\u30fc\u30b8\u306e\u5185\u5bb9\u3092\u89e3\u6790\u3057\u3001a\u30bf\u30b0\u306ehref\u306bcsv\u306e\u6587\u5b57\u5217\u304c\u542b\u307e\u308c\u3066\u3044\u308burl\u3092\u53d6\u5f97\n* \u4e0a\u8a18\u3067\u53d6\u5f97\u3057\u305furl\u306e\u5185\u5bb9\u3092\u53d6\u5f97\n\n\n\n```get_csv_spider.py\n# -*- coding:utf-8 -*-\n\nfrom scrapy import Spider\nfrom scrapy.http import Request\n\n\nclass GetCSVSpider(Spider):\n    name = 'get_csv_spider'\n    allowed_domains = ['seanlahman.com']\n\n    custom_settings = {\n        'DOWNLOAD_DELAY': 1.5,\n    }\n\n    # CSV\u30d5\u30a1\u30a4\u30eb\u3092\u4fdd\u5b58\u3059\u308b\u4efb\u610f\u306e\u30c7\u30a3\u30ec\u30af\u30c8\u30ea\n    DIR_NAME = '/tmp/csv/'\n\n    # \u30a8\u30f3\u30c9\u30dd\u30a4\u30f3\u30c8\uff08\u30af\u30ed\u30fc\u30ea\u30f3\u30b0\u3092\u958b\u59cb\u3059\u308bURL\u3092\u8a18\u8f09\u3059\u308b\uff09\n    start_urls = ['http://seanlahman.com/baseball-archive/statistics/']\n\n    # URL\u306e\u62bd\u51fa\u51e6\u7406\u3092\u8a18\u8f09\n    def parse(self, response):\n        for href in response.css('.entry-content a[href*=csv]::attr(href)'):\n            full_url = response.urljoin(href.extract())\n\n            # \u62bd\u51fa\u3057\u305fURL\u3092\u5143\u306bRequest\u3092\u4f5c\u6210\u3057\u3001\u30c0\u30a6\u30f3\u30ed\u30fc\u30c9\u3059\u308b\n            yield Request(full_url, callback=self.parse_item)\n\n    # \u30c0\u30a6\u30f3\u30ed\u30fc\u30c9\u3057\u305f\u30da\u30fc\u30b8\u3092\u5143\u306b\u3001\u5185\u5bb9\u3092\u62bd\u51fa\u3057\u4fdd\u5b58\u3059\u308b\n    def parse_item(self, response):\n\n        file_name = '{0}{1}'.format(self.DIR_NAME, response.url.split('/')[-1])\n\n        # \u30d5\u30a1\u30a4\u30eb\u306e\u4fdd\u5b58\n        f = open(file_name, 'w')\n        f.write(response.body)\n        f.close()\n```\n\n\n\n## \u5b9f\u884c\n\nScrapy\u4ed8\u5c5e\u306e\u30b3\u30de\u30f3\u30c9\u3092\u5229\u7528\u3057\u3066\u30af\u30ed\u30fc\u30eb\u3092\u5b9f\u884c\u3057\u307e\u3059\u3002\n\n```shell\nscrapy runspider get_csv_spider\n```\n\n\u30b3\u30de\u30f3\u30c9\u3092\u5b9f\u884c\u3059\u308b\u3068\u4e0b\u8a18\u306e\u3088\u3046\u306a\u30ed\u30b0\u304c\u30b3\u30f3\u30bd\u30fc\u30eb\u306b\u8868\u793a\u3055\u308c\u307e\u3059\u3002\u30ed\u30b0\u306b\u306f\u53d6\u5f97\u4e2d\u306eURL\u3001\u30b9\u30c6\u30fc\u30bf\u30b9\u3001\u30d0\u30a4\u30c8\u6570\u3001\u30b5\u30de\u30ea\u30fc\u306a\u3069\u6709\u76ca\u306a\u60c5\u5831\u304c\u8868\u793a\u3055\u308c\u307e\u3059\u3002\n\n```shelll\n2016-12-06 10:02:22 [scrapy] INFO: Scrapy 1.2.0 started (bot: scrapybot)\n2016-12-06 10:02:22 [scrapy] INFO: Overridden settings: {'TELNETCONSOLE_ENABLED': False, 'SPIDER_MODULES': ['crawler.main.spiders'], 'COOKIES_ENABLED': False, 'DOWNLOAD_DELAY': 1}\n2016-12-06 10:02:22 [scrapy] INFO: Enabled extensions:\n['scrapy.extensions.logstats.LogStats',\n 'scrapy.extensions.corestats.CoreStats']\n2016-12-06 10:02:22 [scrapy] INFO: Enabled downloader middlewares:\n['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',\n 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',\n 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',\n 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',\n 'scrapy.downloadermiddlewares.retry.RetryMiddleware',\n 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',\n 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',\n 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',\n 'scrapy.downloadermiddlewares.chunked.ChunkedTransferMiddleware',\n 'scrapy.downloadermiddlewares.stats.DownloaderStats']\n2016-12-06 10:02:22 [scrapy] INFO: Enabled spider middlewares:\n['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',\n 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',\n 'scrapy.spidermiddlewares.referer.RefererMiddleware',\n 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',\n 'scrapy.spidermiddlewares.depth.DepthMiddleware']\n2016-12-06 10:02:22 [scrapy] INFO: Enabled item pipelines:\n[]\n2016-12-06 10:02:22 [scrapy] INFO: Spider opened\n2016-12-06 10:02:22 [scrapy] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)\n2016-12-06 10:02:23 [scrapy] DEBUG: Crawled (200) <GET http://seanlahman.com/baseball-archive/statistics/> (referer: None)\n2016-12-06 10:02:28 [scrapy] DEBUG: Crawled (200) <GET http://seanlahman.com/files/database/lahman30_csv.zip> (referer: http://seanlahman.com/baseball-archive/statistics/)\n2016-12-06 10:02:35 [scrapy] DEBUG: Crawled (200) <GET http://seanlahman.com/files/database/lahman51-csv.zip> (referer: http://seanlahman.com/baseball-archive/statistics/)\n2016-12-06 10:02:38 [scrapy] DEBUG: Crawled (200) <GET http://seanlahman.com/files/database/lahman_50-csv.zip> (referer: http://seanlahman.com/baseball-archive/statistics/)\n2016-12-06 10:02:39 [scrapy] DEBUG: Crawled (200) <GET http://seanlahman.com/files/database/lahman53_csv.zip> (referer: http://seanlahman.com/baseball-archive/statistics/)\n2016-12-06 10:02:41 [scrapy] DEBUG: Crawled (200) <GET http://seanlahman.com/files/database/lahman56-csv.zip> (referer: http://seanlahman.com/baseball-archive/statistics/)\n2016-12-06 10:02:41 [scrapy] DEBUG: Crawled (200) <GET http://seanlahman.com/files/database/lahman52_csv.zip> (referer: http://seanlahman.com/baseball-archive/statistics/)\n2016-12-06 10:02:42 [scrapy] DEBUG: Crawled (200) <GET http://seanlahman.com/files/database/lahman54_csv.zip> (referer: http://seanlahman.com/baseball-archive/statistics/)\n2016-12-06 10:02:47 [scrapy] DEBUG: Crawled (200) <GET http://seanlahman.com/files/database/lahman591-csv.zip> (referer: http://seanlahman.com/baseball-archive/statistics/)\n2016-12-06 10:02:49 [scrapy] DEBUG: Crawled (200) <GET http://seanlahman.com/files/database/lahman55_csv.zip> (referer: http://seanlahman.com/baseball-archive/statistics/)\n2016-12-06 10:02:49 [scrapy] DEBUG: Crawled (200) <GET http://seanlahman.com/files/database/lahman57-csv.zip> (referer: http://seanlahman.com/baseball-archive/statistics/)\n2016-12-06 10:02:52 [scrapy] DEBUG: Crawled (200) <GET http://seanlahman.com/files/database/lahman58-csv.zip> (referer: http://seanlahman.com/baseball-archive/statistics/)\n2016-12-06 10:02:55 [scrapy] DEBUG: Crawled (200) <GET http://seanlahman.com/files/database/lahman-csv_2014-02-14.zip> (referer: http://seanlahman.com/baseball-archive/statistics/)\n2016-12-06 10:02:55 [scrapy] DEBUG: Crawled (200) <GET http://seanlahman.com/files/database/lahman-csv_2015-01-24.zip> (referer: http://seanlahman.com/baseball-archive/statistics/)\n2016-12-06 10:03:00 [scrapy] DEBUG: Crawled (200) <GET http://seanlahman.com/files/database/lahman2012-csv.zip> (referer: http://seanlahman.com/baseball-archive/statistics/)\n2016-12-06 10:03:00 [scrapy] INFO: Closing spider (finished)\n2016-12-06 10:03:00 [scrapy] INFO: Dumping Scrapy stats:\n{'downloader/request_bytes': 4518,\n 'downloader/request_count': 15,\n 'downloader/request_method_count/GET': 15,\n 'downloader/response_bytes': 104279737,\n 'downloader/response_count': 15,\n 'downloader/response_status_count/200': 15,\n 'finish_reason': 'finished',\n 'finish_time': datetime.datetime(2016, 12, 6, 1, 3, 0, 285944),\n 'log_count/DEBUG': 15,\n 'log_count/INFO': 7,\n 'request_depth_max': 1,\n 'response_received_count': 15,\n 'scheduler/dequeued': 15,\n 'scheduler/dequeued/memory': 15,\n 'scheduler/enqueued': 15,\n 'scheduler/enqueued/memory': 15,\n 'start_time': datetime.datetime(2016, 12, 6, 1, 2, 22, 878024)}\n2016-12-06 10:03:00 [scrapy] INFO: Spider closed (finished)\n```\n\n\u30c0\u30a6\u30f3\u30ed\u30fc\u30c9\u304c\u5b8c\u4e86\u3057\u305f\u306e\u3067\u5b9f\u969b\u306b\u30c0\u30a6\u30f3\u30ed\u30fc\u30c9\u3055\u308c\u3066\u3044\u308b\u304b\u78ba\u8a8d\u3057\u307e\u3057\u3087\u3046\u3002\n\u7121\u4e8b\u30c0\u30a6\u30f3\u30ed\u30fc\u30c9\u3055\u308c\u3066\u3044\u308b\u3088\u3046\u3067\u3059\u306d\u3002\n\n```\ntree /tmp/csv\n```\n\n```\n/tmp/csv\n\u251c\u2500\u2500 lahman-csv_2014-02-14.zip\n\u251c\u2500\u2500 lahman-csv_2015-01-24.zip\n\u251c\u2500\u2500 lahman2012-csv.zip\n\u251c\u2500\u2500 lahman30_csv.zip\n\u251c\u2500\u2500 lahman51-csv.zip\n\u251c\u2500\u2500 lahman52_csv.zip\n\u251c\u2500\u2500 lahman53_csv.zip\n\u251c\u2500\u2500 lahman54_csv.zip\n\u251c\u2500\u2500 lahman55_csv.zip\n\u251c\u2500\u2500 lahman56-csv.zip\n\u251c\u2500\u2500 lahman57-csv.zip\n\u251c\u2500\u2500 lahman58-csv.zip\n\u251c\u2500\u2500 lahman591-csv.zip\n\u2514\u2500\u2500 lahman_50-csv.zip\n\n0 directories, 14 files\n```\n\n## \u7d42\u308f\u308a\u306b\n\nScrapy\u3092\u4f7f\u7528\u3059\u308b\u3068\u3001\u30d5\u30a1\u30a4\u30eb\u306e\u30c0\u30a6\u30f3\u30ed\u30fc\u30c9\u51e6\u7406\u3082\u7c21\u5358\u306b\u8a18\u8ff0\u3059\u308b\u3053\u3068\u304c\u3067\u304d\u307e\u3059\u3002Scrapy\u306f\u30af\u30ed\u30fc\u30ea\u30f3\u30b0\u7528\u306e\u30d5\u30ec\u30fc\u30e0\u30ef\u30fc\u30af\u306a\u306e\u3067\u3001\u958b\u767a\u8005\u306f\u30d5\u30ec\u30fc\u30e0\u30ef\u30fc\u30af\u304b\u3089\u547c\u3073\u51fa\u3055\u308c\u308b\u90e8\u5206\u306b\u306e\u307f\u96c6\u4e2d\u3057\u3066\u958b\u767a\u3059\u308b\u3053\u3068\u304c\u53ef\u80fd\u3067\u3059\u3002\u6b21\u56de\u4ee5\u964d\u306f\u4eca\u56de\u8aac\u660e\u3057\u306a\u304b\u3063\u305f\u3001\u30c7\u30fc\u30bf\u306e\u30d1\u30a4\u30d7\u30e9\u30a4\u30f3\u51e6\u7406\u306b\u3064\u3044\u3066\u53d6\u308a\u4e0a\u3052\u307e\u3059\u3002\u304a\u697d\u3057\u307f\u306b\uff01\n\n## \u53c2\u8003URL\n\n* http://www.slideshare.net/shinyorke/python-39061157\n* http://qiita.com/checkpoint/items/d9bcc63292d7f01c62d3\n", "tags": ["Python", "Scrapy"]}