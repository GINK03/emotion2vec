{"tags": ["OpenCV", "Python", "\u753b\u50cf\u51e6\u7406"], "context": "\n\nOpenCV\u3092\u4f7f\u3063\u305f\u9854\u63a8\u5b9a\n\u524d\u56de\u306f\u3001Haar-like\u7279\u5fb4\u5206\u985e\u5668\u3092\u4f7f\u3063\u3066\u9854\u9818\u57df\u3092\u62bd\u51fa\u3057\u307e\u3057\u305f\uff08OpenCV\u3092\u4f7f\u3063\u305f\u9854\u8a8d\u8b58\uff08Haar-like\u7279\u5fb4\u5206\u985e\u5668\uff09\uff09\u3002\u4eca\u56de\u306f\u3001\u5fdc\u7528\u3068\u3057\u3066\u3001Haar-like\u7279\u5fb4\u5206\u985e\u5668\u3067\u62bd\u51fa\u3057\u305f\u9854\u753b\u50cf\u3092OpenCV\u306e\u9854\u63a8\u5b9a\u5668\uff08Eigenface, Fisherface, LBPH\uff09\u306b\u5b66\u7fd2\u3055\u305b\u3001\u8868\u60c5\u306e\u9055\u3044\u3001\u5909\u88c5\u3001\u30e9\u30a4\u30c8\u306e\u5f53\u305f\u308a\u5177\u5408\u306e\u9055\u3044\u304c\u3042\u308b\u4e2d\u3067\u3001\u672a\u5b66\u7fd2\u306e\u9854\u304c\u8ab0\u306e\u9854\u306a\u306e\u304b\u3092\u63a8\u6e2c\u3055\u305b\u3066\u307f\u307e\u3059\u3002\nOpenCV\u304c\u642d\u8f09\u3057\u3066\u3044\u308b\u9854\u63a8\u5b9a\u30a2\u30eb\u30b4\u30ea\u30ba\u30e0\u306f\u4ee5\u4e0b\u306b\u306a\u308a\u307e\u3059\u3002\uff08\u8a73\u7d30\u306f\u3053\u3061\u3089\uff09\n\n\nEigenface\uff08\u56fa\u6709\u9854\uff09\n\u9854\u753b\u50cf\u3092\u56fa\u6709\u9854\u306b\u5909\u63db\u3059\u308b\u3001\u4e3b\u6210\u5206\u5206\u6790\uff08PCA\uff09\u306e\u51e6\u7406\u904e\u7a0b\u306f\u6b21\u306e\u3088\u3046\u306b\u306a\u308a\u307e\u3059\u3002\n\n\u8a13\u7df4\u7528\u306e\u753b\u50cf\uff08\u540c\u3058\u7167\u660e\u6761\u4ef6\u3001\u76ee\u3084\u9f3b\u306e\u4f4d\u7f6e\u3067\u30b9\u30b1\u30fc\u30ea\u30f3\u30b0\u3001\u540c\u89e3\u50cf\u5ea6\uff09\u3092\u6e96\u5099\u3057\u307e\u3059\u3002\n\u8a13\u7df4\u7528\u753b\u50cf\u306e\u5e73\u5747\u3092\u6c42\u3081\u3001\u5e73\u5747\u753b\u50cf\u3092\u5404\u753b\u50cf\u304b\u3089\u6e1b\u7b97\u3057\u307e\u3059\u3002\n\u6e1b\u7b97\u3057\u305f\u753b\u50cf\u306e\u5171\u5206\u6563\u884c\u5217\u3092\u8a08\u7b97\u3057\u307e\u3059\u3002\n\u5171\u5206\u6563\u884c\u5217\u304b\u3089\u3001\u56fa\u6709\u30d9\u30af\u30c8\u30eb\u3068\u56fa\u6709\u5024\u3092\u8a08\u7b97\u3057\u307e\u3059\u3002\n\u4e3b\u6210\u5206\u3092\u9078\u629e\u3057\u307e\u3059\u3002\n\n\n\u3000  \n\n\nFisherface\nEigenface\u306e\u6539\u826f\u7248\u3067\u3059\u3002Eigenface\u3068\u6bd4\u8f03\u3057\u3001\u7167\u660e\u3084\u89d2\u5ea6\u306e\u9055\u3044\u306b\u5f71\u97ff\u3055\u308c\u306b\u304f\u3044\u3068\u3044\u3046\u7279\u5fb4\u304c\u3042\u308a\u307e\u3059\u3002\n\n\u3000  \n\n\nLocal Binary Patterns Histogram(LBPH)\n\u9854\u3092\u5c0f\u3055\u306a\u30bb\u30eb\u306b\u5206\u5272\u3057\u3001\u305d\u308c\u305e\u308c\u306e\u30a8\u30ea\u30a2\u306e\u30d2\u30b9\u30c8\u30b0\u30e9\u30e0\u3092\u6bd4\u8f03\u3057\u307e\u3059\u3002\u3053\u306e\u30a2\u30eb\u30b4\u30ea\u30ba\u30e0\u306fEigenface, Fisherface\u3068\u6bd4\u3079\u3001\u30b5\u30f3\u30d7\u30eb\u306e\u9854\u306e\u30b5\u30a4\u30ba\u3084\u5f62\u304c\u7570\u306a\u3063\u3066\u3044\u3066\u3082\u7cbe\u5ea6\u3088\u304f\u691c\u51fa\u3067\u304d\u308b\u3068\u3044\u3046\u7279\u5fb4\u304c\u3042\u308a\u307e\u3059\u3002\n\n\n\n\u203b \u753b\u50cf\u306f\u3001\u3044\u305a\u308c\u3082OpenCV\u306e\u30c1\u30e5\u30fc\u30c8\u30ea\u30a2\u30eb\u304b\u3089\uff08\u30ea\u30f3\u30af\uff09\n\u4eca\u56de\u306f\u3001\u9854\u306e\u8a8d\u8b58\u3092\u884c\u3044\u307e\u3059\u304c\u3001\u3053\u308c\u3089\u306e\u30a2\u30eb\u30b4\u30ea\u30ba\u30e0\u306f\u3001\u7b46\u8de1\u9451\u5b9a\u3001\u533b\u7528\u753b\u50cf\u51e6\u7406\u3001\u8aad\u5507\u8853\u306b\u3082\u5fdc\u7528\u3055\u308c\u308b\u6280\u8853\u3067\u3059\u3002\n\u9762\u767d\u3044\u3068\u3053\u308d\u3067\u306f\u3001\u5909\u88c5\u3057\u3066\u3044\u308b\u4eba\u3092\u898b\u5206\u3051\u308b\u306a\u3093\u3066\u3053\u3068\u3082\u53ef\u80fd\u3067\u3059\u3002\n\nOpenCV\nOpenCV(Open Source Computer Vision Library)\u306fBSD\u30e9\u30a4\u30bb\u30f3\u30b9\u306e\u6620\u50cf/\u753b\u50cf\u51e6\u7406\u30e9\u30a4\u30d6\u30e9\u30ea\u96c6\u3067\u3059\u3002\u753b\u50cf\u306e\u30d5\u30a3\u30eb\u30bf\u51e6\u7406\u3001\u30c6\u30f3\u30d7\u30ec\u30fc\u30c8\u30de\u30c3\u30c1\u30f3\u30b0\u3001\u7269\u4f53\u8a8d\u8b58\u3001\u6620\u50cf\u89e3\u6790\u3001\u6a5f\u68b0\u5b66\u7fd2\u306a\u3069\u306e\u30a2\u30eb\u30b4\u30ea\u30ba\u30e0\u304c\u591a\u6570\u7528\u610f\u3055\u308c\u3066\u3044\u307e\u3059\u3002\n\u25a0 OpenCV\u3092\u4f7f\u3063\u305f\u52d5\u4f53\u8ffd\u8de1\u306e\u4f8b (OpenCV Google Summer of Code 2015)\nhttps://www.youtube.com/watch?v=OUbUFn71S4s\n\u25a0 \u30a4\u30f3\u30b9\u30c8\u30fc\u30eb\u3068\u7c21\u5358\u306a\u4f7f\u3044\u65b9\u306f\u3053\u3061\u3089\nOpenCV 3\uff08core + contrib\uff09\u3092Python 3\u306e\u74b0\u5883\u306b\u30a4\u30f3\u30b9\u30c8\u30fc\u30eb\uff06OpenCV 2\u3068OpenCV 3\u306e\u9055\u3044\uff06\u7c21\u5358\u306a\u52d5\u4f5c\u30c1\u30a7\u30c3\u30af\n\u3000\u3000\u2605 OpenCV 3.1\u306eopencv_contrib\u306eface\u30e2\u30b8\u30e5\u30fc\u30eb\u306fpredict()\u30e1\u30bd\u30c3\u30c9\u304c\u610f\u56f3\u901a\u308a\u306b\u52d5\u4f5c\u3057\u307e\u305b\u3093\u3067\u3057\u305f\u3002\n\u3000\u3000\u3000 \u4eca\u56de\u306f\u3001Anaconda 2\u306bOpenCV 2\u3092\u30a4\u30f3\u30b9\u30c8\u30fc\u30eb\u3057\u3066\u4e0b\u8a18\u30d7\u30ed\u30b0\u30e9\u30e0\u3092\u52d5\u4f5c\u3055\u305b\u3066\u3044\u307e\u3059\u3002\n\u25a0 \u9759\u6b62\u753b\u50cf\u306e\u51e6\u7406\u306b\u3064\u3044\u3066\u306f\u3053\u3061\u3089\nOpenCV\u3067\u30a8\u30c3\u30b8\u691c\u51fa\u3057\u3066\u307f\u308b\nOpenCV\u3067\u5404\u7a2e\u30d5\u30a3\u30eb\u30bf\u30fc\u51e6\u7406\u3092\u3059\u308b\uff08\u30b0\u30e9\u30c7\u30a3\u30a8\u30f3\u30c8\u3001\u30cf\u30a4\u30d1\u30b9\u3001\u30e9\u30d7\u30e9\u30b7\u30a2\u30f3\u3001\u30ac\u30a6\u30b7\u30a2\u30f3\uff09\nOpenCV\u3067\u7279\u5fb4\u70b9\u3092\u62bd\u51fa\u3059\u308b\uff08AgastFeature, FAST, GFTT, MSER, AKAZE, BRISK, KAZE, ORB, SimpleBlob\uff09\nOpenCV\u3092\u4f7f\u3063\u305f\u9854\u8a8d\u8b58\uff08Haar-like\u7279\u5fb4\u5206\u985e\u5668\uff09\n\u25a0 \u52d5\u753b\u306e\u51e6\u7406\u306b\u3064\u3044\u3066\u306f\u3053\u3061\u3089\nOpenCV\u3067\u52d5\u753b\u3092\u30ea\u30a2\u30eb\u30bf\u30a4\u30e0\u306b\u5909\u63db\u3057\u3066\u307f\u308b\nOpenCV\u3067Web\u30ab\u30e1\u30e9/\u30d3\u30c7\u30aa\u30ab\u30e1\u30e9\u306e\u52d5\u753b\u3092\u30ea\u30a2\u30eb\u30bf\u30a4\u30e0\u306b\u5909\u63db\u3057\u3066\u307f\u308b\nOpenCV\u3067\u30aa\u30d7\u30c6\u30a3\u30ab\u30eb\u30d5\u30ed\u30fc\u3092\u30ea\u30a2\u30eb\u30bf\u30a4\u30e0\u306b\u63cf\u753b\u3059\u308b\uff08Shi-Tomasi\u6cd5\u3001Lucas-Kanade\u6cd5\uff09\nOpenCV\u3092\u4f7f\u3063\u305f\u7269\u4f53\u8ffd\u8de1\uff08\u30de\u30a6\u30b9\u3067\u6307\u5b9a\u3057\u305f\u7279\u5fb4\u70b9\u3092Lucas-Kanade\u6cd5\u3067\u8ffd\u8de1\u3059\u308b\nOpenCV\u3092\u4f7f\u3063\u305f\u30e2\u30fc\u30b7\u30e7\u30f3 \u30c6\u30f3\u30d7\u30ec\u30fc\u30c8\u89e3\u6790\uff08\u30ea\u30a2\u30eb\u30bf\u30a4\u30e0\u306b\u7269\u4f53\u3068\u305d\u306e\u52d5\u304f\u65b9\u5411\u3092\u8a8d\u8b58\u3059\u308b\uff09\n\n\u9854\u30c7\u30fc\u30bf\u30d9\u30fc\u30b9\n\u753b\u50cf\u51e6\u7406\u3067\u3088\u304f\u5229\u7528\u3055\u308c\u308b\u9854\u30c7\u30fc\u30bf\u30d9\u30fc\u30b9\u3092\u7d39\u4ecb\u3057\u307e\u3059\u3002\n\nThe Yale face database(Yalefaces)\uff1a\nhttp://vision.ucsd.edu/content/yale-face-database\nGIF\u5f62\u5f0f\u306e\u9854\u753b\u50cf\u3067\u3059\u3002\n\nThe AT&T\uff1a\nhttp://www.cl.cam.ac.uk/research/dtg/attarchive/facedatabase.html\nPBM\u5f62\u5f0f\u306e\u9854\u753b\u50cf\u3067\u3059\u3002\n\n\n\u4eca\u56de\u306f\u3001Yale face database(Yalefaces)\u3092\u5229\u7528\u3057\u307e\u3059\u3002\n\n\u8a13\u7df4\u30c7\u30fc\u30bf\u3068\u30c6\u30b9\u30c8\u30c7\u30fc\u30bf\n\u3000Yalefaces\u306b\u306f\u300115\u4eba\u306e\u69d8\u3005\u306a\u8868\u60c5\u306e\u9854\u304c\u683c\u7d0d\u3055\u308c\u3066\u3044\u307e\u3059\u3002\u305d\u308c\u305e\u308c\u306e\u4eba\u304c\u666e\u901a\u306e\u9854\u3001\u773c\u93e1\u3092\u304b\u3051\u3066\u3044\u308b\u9854\u3001\u559c\u3093\u3067\u3044\u308b\u9854\u3001\u30a6\u30a3\u30f3\u30af\u3057\u3066\u3044\u308b\u9854\u3001\u60b2\u3057\u3093\u3067\u3044\u308b\u9854\u3001\u60b2\u3057\u3093\u3067\u3044\u308b\u9854\u3001\u9a5a\u3044\u3066\u3044\u308b\u9854\u3001\u53f3/\u5de6\u304b\u3089\u306e\u30e9\u30a4\u30c8\u304c\u5f53\u305f\u3063\u3066\u3044\u308b\u9854\u3092\u3057\u3066\u3044\u307e\u3059\u3002\n\u3000\u9069\u5b9c\u3001\u305d\u308c\u305e\u308c\u306e\u4eba\u306e\u9854\u753b\u50cf\u304b\u3089\u4efb\u610f\u306e\uff11\u679a\u306e\u9854\u753b\u50cf\u3092\u30c6\u30b9\u30c8\u7528\u3068\u3057\u3066\u629c\u304d\u53d6\u308a\u307e\u3059\uff08\u8a13\u7df4\u7528\u753b\u50cf\u306b\u30c6\u30b9\u30c8\u753b\u50cf\u3092\u542b\u3081\u306a\u3044\u3088\u3046\u306b\u3057\u307e\u3059\uff09\u3002\n\u3000\u4eca\u56de\u306f\u3001\u8a13\u7df4\u7528\u753b\u50cf\u3092yalefaces\u30c7\u30a3\u30ec\u30af\u30c8\u30ea\u3001\u30c6\u30b9\u30c8\u7528\u753b\u50cf\u3092test\u30c7\u30a3\u30ec\u30af\u30c8\u30ea\u306b\u683c\u7d0d\u3057\u307e\u3057\u305f\u3002\n\n\u3000\u3000\u3000\u3000\u3000\u3000\u3000\u3000\u3000\u3000\u69d8\u3005\u306a\u8868\u60c5\u306e\u9854\n\n\u30d7\u30ed\u30b0\u30e9\u30e0\n\u30d7\u30ed\u30b0\u30e9\u30e0\u306e\u6d41\u308c\u306f\u4ee5\u4e0b\u306e\u3068\u304a\u308a\u3067\u3059\u3002\n1. \u8a13\u7df4\u7528\u753b\u50cf\u3092\u8aad\u307f\u8fbc\u3080\n2. Haar-like\u7279\u5fb4\u5206\u985e\u5668\u3092\u4f7f\u3063\u3066\u9854\u9818\u57df\u3092\u62bd\u51fa\n3. \u9854\u9818\u57df\u3092\u4e00\u5b9a\u30b5\u30a4\u30ba\u306b\u30ea\u30b5\u30a4\u30ba\n4. \u8a13\u7df4\u30c7\u30fc\u30bf\u3068\u3057\u3066\u753b\u50cf\u3068\u30e9\u30d9\u30eb\u3092FaceRecognizer\u3067\u30c8\u30ec\u30fc\u30cb\u30f3\u30b0\uff08train()\uff09\n5. \u5168\u8a13\u7df4\u7528\u753b\u50cf\u306b\u5bfe\u3057\u30661\uff5e4\u3092\u7e70\u308a\u8fd4\u3057\u5b9f\u65bd\n6. \u30c6\u30b9\u30c8\u7528\u753b\u50cf\u3092\u8aad\u307f\u8fbc\u3080\n7. Haar-like\u7279\u5fb4\u5206\u985e\u5668\u3092\u4f7f\u3063\u3066\u9854\u9818\u57df\u3092\u62bd\u51fa\n8. \u9854\u9818\u57df\u3092\u4e00\u5b9a\u30b5\u30a4\u30ba\u306b\u30ea\u30b5\u30a4\u30ba\n9. FaceRecognizer\u3067\u30c6\u30b9\u30c8\u753b\u50cf\u306e\u4e88\u6e2c\u5b9f\u65bd\uff08predict()\uff09\u21d2[\u30e9\u30d9\u30eb, \u78ba\u5ea6]\n10. \u5168\u30c6\u30b9\u30c8\u7528\u753b\u50cf\u306b\u5bfe\u3057\u30666\uff5e9\u3092\u7e70\u308a\u8fd4\u3057\u5b9f\u65bd\n\u30d7\u30ed\u30b0\u30e9\u30e0\u306e\u30dd\u30a4\u30f3\u30c8\u304c\u3044\u304f\u3064\u304b\u3042\u308a\u307e\u3059\u3002\n\n\u30e9\u30d9\u30eb\u306f\u6570\u5024\uff08int\uff09\u3067\u6307\u5b9a\u3057\u307e\u3059\u3002\n\u8a13\u7df4\u753b\u50cf\u3001\u30c6\u30b9\u30c8\u753b\u50cf\u306f\u540c\u3058\u753b\u50cf\u30b5\u30a4\u30ba\u306b\u30ea\u30b5\u30a4\u30ba\u3057\u3066\u304a\u304f\u5fc5\u8981\u304c\u3042\u308a\u307e\u3059\u3002\n\u78ba\u5ea6\uff08confidence\uff09\u306f\u3001\u5206\u6563\u306b\u57fa\u3065\u3044\u3066\u8a08\u7b97\u3055\u308c\u308b\u305f\u3081\u30010\u306b\u8fd1\u3044\u307b\u3046\u304c\u78ba\u5ea6\u304c\u9ad8\u304f\u306a\u308a\u307e\u3059\u3002\u8a13\u7df4\u6642\u306b\u30c6\u30b9\u30c8\u753b\u50cf\u3068\u540c\u4e00\u753b\u50cf\u3092\u5b66\u7fd2\u3057\u3066\u3044\u308b\u3068\u3001\u7279\u5fb4\u70b9\u304c\u4e00\u81f4\u3059\u308b\u305f\u3081\u3001\u78ba\u5ea6\uff08confidence\uff09\u304c0\u306b\u306a\u308a\u307e\u3059\u3002\nOpenCV\u306fGIF\u753b\u50cf\u3092\u30b5\u30dd\u30fc\u30c8\u3057\u3066\u3044\u307e\u305b\u3093\u3002Yalefaces\u306eGIF\u753b\u50cf\u306f\u3001Pillow(PIL)\u3067\u51e6\u7406\u3057\u307e\u3059\u3002\nHaar-like\u7279\u5fb4\u5206\u985e\u5668\u306e\u30c6\u30f3\u30d7\u30ec\u30fc\u30c8\u306f\u3001OpenCV\u306b\u4ed8\u5c5e\u3057\u3066\u3044\u308bhaarcascade_frontalface_default.xml\u3092\u5229\u7528\u3057\u307e\u3059\u3002\n\u9854\u63a8\u5b9a\u5668\u306e\u30a2\u30eb\u30b4\u30ea\u30ba\u30e0\u3092EigenFace, FisherFace, LBPH\u306b\u5207\u308a\u66ff\u3048\u305f\u3044\u5834\u5408\u306f\u3001\u30b3\u30e1\u30f3\u30c8\u30a2\u30a6\u30c8\u3057\u3066\u3044\u308brecognizer\u3092\u5207\u308a\u66ff\u3048\u3066\u304f\u3060\u3055\u3044\u3002\n\n\nface_predict.py\n#!/usr/bin/python\n# -*- coding: utf-8 -*-\n\nimport cv2, os\nimport numpy as np\nfrom PIL import Image\n\n# \u30c8\u30ec\u30fc\u30cb\u30f3\u30b0\u753b\u50cf\ntrain_path = './yalefaces'\n\n# \u30c6\u30b9\u30c8\u753b\u50cf\ntest_path = './test'\n\n# Haar-like\u7279\u5fb4\u5206\u985e\u5668\ncascadePath = \"haarcascade_frontalface_default.xml\"\nfaceCascade = cv2.CascadeClassifier(cascadePath)\n\n# \u9854\u8a8d\u8b58\u5668\u306e\u69cb\u7bc9 for OpenCV 2\n#   \u203b OpenCV3\u3067\u306fFaceRecognizer\u306fcv2.face\u306e\u30e2\u30b8\u30e5\u30fc\u30eb\u306b\u306a\u308a\u307e\u3059\n# EigenFace\n#recognizer = cv2.createEigenFaceRecognizer()\n# FisherFace\n#recognizer = cv2.createFisherFaceRecognizer()\n# LBPH\nrecognizer = cv2.createLBPHFaceRecognizer()\n\n# \u6307\u5b9a\u3055\u308c\u305fpath\u5185\u306e\u753b\u50cf\u3092\u53d6\u5f97\ndef get_images_and_labels(path):\n    # \u753b\u50cf\u3092\u683c\u7d0d\u3059\u308b\u914d\u5217\n    images = []\n    # \u30e9\u30d9\u30eb\u3092\u683c\u7d0d\u3059\u308b\u914d\u5217\n    labels = []\n    # \u30d5\u30a1\u30a4\u30eb\u540d\u3092\u683c\u7d0d\u3059\u308b\u914d\u5217\n    files = []\n    for f in os.listdir(path):\n        # \u753b\u50cf\u306e\u30d1\u30b9\n        image_path = os.path.join(path, f)\n        # \u30b0\u30ec\u30fc\u30b9\u30b1\u30fc\u30eb\u3067\u753b\u50cf\u3092\u8aad\u307f\u8fbc\u3080\n        image_pil = Image.open(image_path).convert('L')\n        # NumPy\u306e\u914d\u5217\u306b\u683c\u7d0d\n        image = np.array(image_pil, 'uint8')\n        # Haar-like\u7279\u5fb4\u5206\u985e\u5668\u3067\u9854\u3092\u691c\u77e5\n        faces = faceCascade.detectMultiScale(image)\n        # \u691c\u51fa\u3057\u305f\u9854\u753b\u50cf\u306e\u51e6\u7406\n        for (x, y, w, h) in faces:\n            # \u9854\u3092 200x200 \u30b5\u30a4\u30ba\u306b\u30ea\u30b5\u30a4\u30ba\n            roi = cv2.resize(image[y: y + h, x: x + w], (200, 200), interpolation=cv2.INTER_LINEAR)\n            # \u753b\u50cf\u3092\u914d\u5217\u306b\u683c\u7d0d\n            images.append(roi)\n            # \u30d5\u30a1\u30a4\u30eb\u540d\u304b\u3089\u30e9\u30d9\u30eb\u3092\u53d6\u5f97\n            labels.append(int(f[7:9]))\n            # \u30d5\u30a1\u30a4\u30eb\u540d\u3092\u914d\u5217\u306b\u683c\u7d0d\n            files.append(f)\n\n    return images, labels, files\n\n\n# \u30c8\u30ec\u30fc\u30cb\u30f3\u30b0\u753b\u50cf\u3092\u53d6\u5f97\nimages, labels, files = get_images_and_labels(train_path)\n\n# \u30c8\u30ec\u30fc\u30cb\u30f3\u30b0\u5b9f\u65bd\nrecognizer.train(images, np.array(labels))\n\n# \u30c6\u30b9\u30c8\u753b\u50cf\u3092\u53d6\u5f97\ntest_images, test_labels, test_files = get_images_and_labels(test_path)\n\ni = 0\nwhile i < len(test_labels):\n    # \u30c6\u30b9\u30c8\u753b\u50cf\u306b\u5bfe\u3057\u3066\u4e88\u6e2c\u5b9f\u65bd\n    label, confidence = recognizer.predict(test_images[i])\n    # \u4e88\u6e2c\u7d50\u679c\u3092\u30b3\u30f3\u30bd\u30fc\u30eb\u51fa\u529b\n    print(\"Test Image: {}, Predicted Label: {}, Confidence: {}\".format(test_files[i], label, confidence))\n    # \u30c6\u30b9\u30c8\u753b\u50cf\u3092\u8868\u793a\n    cv2.imshow(\"test image\", test_images[i])\n    cv2.waitKey(300)\n\n    i += 1\n\n# \u7d42\u4e86\u51e6\u7406\ncv2.destroyAllWindows()\n\n\n\u4eca\u56de\u306e\u30d7\u30ed\u30b0\u30e9\u30e0\u306f\u3001Python 2.7.12\u3068OpenCV 2.4.13\u3067\u5b9f\u884c\u3057\u307e\u3057\u305f\u3002\nPython 3\u3068OpenCV 3\u3067\u5b9f\u884c\u3059\u308b\u5834\u5408\u306f\u3001\u30d7\u30ed\u30b0\u30e9\u30e0\u4e2d\u306eFaceRecognizer\u306e\u90e8\u5206\u3092cv2\u304b\u3089cv2.face\u306b\u5909\u66f4\u3057\u3066\u304f\u3060\u3055\u3044\u3002\u307e\u305f\u3001OpenCV 3.1\u3067\u306f\u3001FaceRecognizer\u306epredict()\u30e1\u30bd\u30c3\u30c9\u304c\u610f\u56f3\u3057\u305f\u901a\u308a\u306b\u52d5\u4f5c\u3057\u307e\u305b\u3093\u3002\u8a73\u7d30\u306f\u3053\u3061\u3089\u306eOpenCV2\u3068OpenCV3\u306e\u9055\u3044\uff06etc.\u21d2\u30d0\u30b0\u3067\u52d5\u4f5c\u3057\u306a\u3044\u30e1\u30bd\u30c3\u30c9\u304c\u3042\u308b\u3092\u53c2\u7167\u3057\u3066\u304f\u3060\u3055\u3044\u3002\n\n\u5b9f\u884c\u7d50\u679c\nsubjectXX\u306e\u300cXX\u300d\u306e\u90e8\u5206\u3092\u6570\u5024\u3068\u3057\u3066\u30e9\u30d9\u30eb\u306b\u8a2d\u5b9a\u3057\u3066\u8a13\u7df4\u3092\u5b9f\u884c\u3057\u3066\u3044\u307e\u3059\u3002\u30c6\u30b9\u30c8\u753b\u50cf\uff08Image\uff09\u306b\u5bfe\u3057\u3066\u3001\u6b63\u3057\u3044\u30e9\u30d9\u30eb\uff08Predicted Label\uff09\u3092\u63a8\u5b9a\u3059\u308b\u3053\u3068\u304c\u3067\u304d\u3066\u3044\u307e\u3059\u3002\nEigenface\u3067\u63a8\u5b9a\u3057\u305f\u3068\u3053\u308d\u3001\u30e9\u30a4\u30c8\u95a2\u4fc2\u306elabel=5, 6, 8, 9\u306e\u63a8\u5b9a\u306b\u5931\u6557\u3057\u3001\u305d\u306e\u4ed6\u306e\u63a8\u5b9a\u306b\u306f\u6210\u529f\u3057\u307e\u3057\u305f\u3002\nTest Image: subject01.happy, Predicted Label: 1, Confidence: 4383.25505059\nTest Image: subject02.wink, Predicted Label: 2, Confidence: 6947.75053221\nTest Image: subject03.happy, Predicted Label: 3, Confidence: 4145.80848328\nTest Image: subject04.glasses, Predicted Label: 4, Confidence: 5420.9213318\nTest Image: subject05.leftlight, Predicted Label: 12, Confidence: 7722.72936213\nTest Image: subject06.leftlight, Predicted Label: 1, Confidence: 10086.4101755\nTest Image: subject07.glasses, Predicted Label: 7, Confidence: 7043.70495967\nTest Image: subject08.leftlight, Predicted Label: 2, Confidence: 10275.9545456\nTest Image: subject09.rightlight, Predicted Label: 15, Confidence: 7481.31094502\nTest Image: subject10.sleepy, Predicted Label: 10, Confidence: 2317.22633915\nTest Image: subject11.centerlight, Predicted Label: 11, Confidence: 8077.42380817\nTest Image: subject12.glasses, Predicted Label: 12, Confidence: 5233.03342586\nTest Image: subject13.surprised, Predicted Label: 13, Confidence: 6516.98395617\nTest Image: subject14.normal, Predicted Label: 14, Confidence: 0.0\nTest Image: subject15.surprised, Predicted Label: 15, Confidence: 7165.71597327\n\nFisherface\u3067\u63a8\u5b9a\u3057\u305f\u3068\u3053\u308d\u3001\u5168\u3066\u306e\u63a8\u5b9a\u306b\u6210\u529f\u3057\u307e\u3057\u305f\u3002\nTest Image: subject01.happy, Predicted Label: 1, Confidence: 801.784987691\nTest Image: subject02.wink, Predicted Label: 2, Confidence: 2368.90429845\nTest Image: subject03.happy, Predicted Label: 3, Confidence: 826.018934498\nTest Image: subject04.glasses, Predicted Label: 4, Confidence: 1080.94198758\nTest Image: subject05.leftlight, Predicted Label: 5, Confidence: 2137.42013849\nTest Image: subject06.leftlight, Predicted Label: 6, Confidence: 2092.53092982\nTest Image: subject07.glasses, Predicted Label: 7, Confidence: 2042.67529443\nTest Image: subject08.leftlight, Predicted Label: 8, Confidence: 2239.45348941\nTest Image: subject09.rightlight, Predicted Label: 9, Confidence: 2875.2788263\nTest Image: subject10.sleepy, Predicted Label: 10, Confidence: 662.762591569\nTest Image: subject11.centerlight, Predicted Label: 11, Confidence: 1703.80515728\nTest Image: subject12.glasses, Predicted Label: 12, Confidence: 1480.18770297\nTest Image: subject13.surprised, Predicted Label: 13, Confidence: 1690.12255703\nTest Image: subject14.normal, Predicted Label: 14, Confidence: 0.0\nTest Image: subject15.surprised, Predicted Label: 15, Confidence: 1887.42538269\n\nLBPH\u3067\u63a8\u5b9a\u3057\u305f\u3068\u3053\u308d\u3001\u30e9\u30a4\u30c8\u95a2\u4fc2\u306elabel=6, 9\u306e\u63a8\u5b9a\u306b\u5931\u6557\u3002\u305d\u306e\u4ed6\u306f\u6210\u529f\u3057\u307e\u3057\u305f\u3002\nTest Image: subject01.happy, Predicted Label: 1, Confidence: 34.9751422497\nTest Image: subject02.wink, Predicted Label: 2, Confidence: 37.8730262399\nTest Image: subject03.happy, Predicted Label: 3, Confidence: 35.1183059319\nTest Image: subject04.glasses, Predicted Label: 4, Confidence: 37.5886492389\nTest Image: subject05.leftlight, Predicted Label: 5, Confidence: 48.2634869014\nTest Image: subject06.leftlight, Predicted Label: 14, Confidence: 64.5502245279\nTest Image: subject07.glasses, Predicted Label: 7, Confidence: 54.5043891288\nTest Image: subject08.leftlight, Predicted Label: 8, Confidence: 84.4281976817\nTest Image: subject09.rightlight, Predicted Label: 12, Confidence: 75.3254674542\nTest Image: subject10.sleepy, Predicted Label: 10, Confidence: 17.8806440153\nTest Image: subject11.centerlight, Predicted Label: 11, Confidence: 74.8238311755\nTest Image: subject12.glasses, Predicted Label: 12, Confidence: 31.8721301084\nTest Image: subject13.surprised, Predicted Label: 13, Confidence: 40.3420527188\nTest Image: subject14.normal, Predicted Label: 14, Confidence: 0.0\nTest Image: subject15.surprised, Predicted Label: 15, Confidence: 33.2920487407\n\n\uff13\u3064\u306e\u30a2\u30eb\u30b4\u30ea\u30ba\u30e0\u306e\u6bd4\u8f03\u7d50\u679c\u306f\u3001\u524d\u8a55\u5224\u901a\u308a\u3001Fisherface\u304c\u30e9\u30a4\u30c8\u306e\u5f71\u97ff\u3092\u53d7\u3051\u306b\u304f\u304f\u306a\u3063\u3066\u3044\u307e\u3057\u305f\u3002\n\u307e\u305f\u3001\u63a8\u5b9a\u306e\u6210\u529f\u3001\u5931\u6557\u306fConfidence\u306e\u5024\u3068\u3042\u308b\u7a0b\u5ea6\u5bfe\u5fdc\u3057\u305f\u7d50\u679c\u306b\u306a\u3063\u305f\u305f\u3081\u3001Confidence\u306b\u95be\u5024\u3092\u8a2d\u3051\u3001\u4fe1\u983c\u3067\u304d\u306a\u3044\u63a8\u5b9a\u7d50\u679c\u306f\u3001\u63a8\u5b9a\u4e0d\u80fd\u306e\u9805\u76ee\u306b\u5206\u985e\u3059\u308b\u3068\u3088\u3055\u305d\u3046\u3067\u3057\u305f\u3002\n\n\uff08\u304a\u307e\u3051\uff09GIF\u753b\u50cf \u2192 PNG\u753b\u50cf\u5909\u63db\nOpenCV\u306f\u30d1\u30c6\u30f3\u30c8\u306e\u554f\u984c\u3092\u56de\u907f\u3059\u308b\u305f\u3081\u3001GIF\u753b\u50cf\u3092\u30b5\u30dd\u30fc\u30c8\u3057\u3066\u3044\u307e\u305b\u3093\u3002cv2.imread()\u3067GIF\u753b\u50cf\u3092\u8aad\u307f\u8fbc\u3093\u3067\u3082\u4f55\u3082\u8aad\u307f\u8fbc\u307f\u307e\u305b\u3093\u3002\nGIF\u5f62\u5f0f\u306e\u9854\u753b\u50cf\u30c7\u30fc\u30bf\u30d9\u30fc\u30b9\u3001Yalefaces\u3092OpenCV\u3067\u5229\u7528\u3057\u305f\u3044\u65b9\u306f\u3001\u4e0b\u8a18\u30b9\u30af\u30ea\u30d7\u30c8\u3067\u4e8b\u524d\u306bPNG\u5f62\u5f0f\u306e\u9854\u753b\u50cf\u306b\u5909\u63db\u3057\u3066\u304a\u304f\u3068\u4fbf\u5229\u3067\u3059\u3002\u4e0b\u8a18\u30b9\u30af\u30ea\u30d7\u30c8\u306f\u300cyalefaces\u300d\u30c7\u30a3\u30ec\u30af\u30c8\u30ea\u5185\u306eGIF\u753b\u50cf\u3092PNG\u753b\u50cf\u306b\u5909\u63db\u3057\u3066\u300cpng\u300d\u30c7\u30a3\u30ec\u30af\u30c8\u30ea\u306b\u4fdd\u5b58\u3057\u307e\u3059\u3002\u5fc5\u8981\u306a\u65b9\u306f\u4e0b\u8a18\u30b9\u30af\u30ea\u30d7\u30c8\u3092\u3054\u5229\u7528\u304f\u3060\u3055\u3044\u3002\n\ngif2png.py\n# -*- coding: utf-8 -*-\n\nimport os\nfrom PIL import Image\nimport shutil\n\n# \u5909\u63db\u5bfe\u8c61\u30d5\u30a1\u30a4\u30eb\u3092\u683c\u7d0d\u3057\u305f\u30c7\u30a3\u30ec\u30af\u30c8\u30ea\norg_dir = 'yalefaces'\n# \u5909\u63db\u5bfe\u8c61\u30d5\u30a1\u30a4\u30eb\u306e\u62e1\u5f35\u5b50\norg_ext = 'gif'\n# \u5909\u63db\u5f8c\u306e\u30d5\u30a1\u30a4\u30eb\u3092\u683c\u7d0d\u3059\u308b\u30c7\u30a3\u30ec\u30af\u30c8\u30ea\nconv_dir = 'png'\n# \u5909\u63db\u5f8c\u306e\u30d5\u30a1\u30a4\u30eb\u306e\u62e1\u5f35\u5b50\nconv_ext = 'png'\n\n# \u65e2\u5b58\u306e\u30c7\u30a3\u30ec\u30af\u30c8\u30ea\u3092\u30d5\u30a1\u30a4\u30eb\u3082\u542b\u3081\u3066\u524a\u9664\nif os.path.exists(conv_dir):\n    shutil.rmtree(conv_dir)\n# \u30c7\u30a3\u30ec\u30af\u30c8\u30ea\u3092\u4f5c\u6210\nos.mkdir(conv_dir)\n\n# \u300c.\u300d\u3068\u62e1\u5f35\u5b50\u3092\u5408\u308f\u305b\u305f\u6587\u5b57\u5217\u9577\norg_ext_len = len(org_ext) + 1\n\nfor dirname, dirnames, filenames in os.walk(org_dir):\n    for filename in filenames:\n        # \u5909\u63db\u5bfe\u8c61\u30d5\u30a1\u30a4\u30eb\u306e\u30d1\u30b9\n        org_path = org_dir + '/' + filename\n\n        # \u8fd4\u9084\u5f8c\u306e\u30d5\u30a1\u30a4\u30eb\u30d1\u30b9\n        if len(filename) > org_ext_len and \\\n            filename[-org_ext_len:] == '.' + org_ext:\n            filename = filename[0:-org_ext_len]\n        conv_path = conv_dir + '/' + filename + '.' + conv_ext\n\n        try:\n            # \u5909\u63db\u5b9f\u884c\n            Image.open(org_path).save(conv_path)\n        except IOError:\n            print('cannot convert :', org_path)\n\n\nPython\u306e\u753b\u50cf\u51e6\u7406\u30e9\u30a4\u30d6\u30e9\u30ea\u3001PIL\u30e2\u30b8\u30e5\u30fc\u30eb\u304c\u30a4\u30f3\u30b9\u30c8\u30fc\u30eb\u3055\u308c\u3066\u3044\u306a\u3044\u65b9\u306f\u3001pillow\u3092\u30a4\u30f3\u30b9\u30c8\u30fc\u30eb\u3057\u3066\u304f\u3060\u3055\u3044\u3002\n\u4f8b\uff09\n\n$ conda install pillow\n\n# OpenCV\u3092\u4f7f\u3063\u305f\u9854\u63a8\u5b9a\n\u524d\u56de\u306f\u3001Haar-like\u7279\u5fb4\u5206\u985e\u5668\u3092\u4f7f\u3063\u3066\u9854\u9818\u57df\u3092\u62bd\u51fa\u3057\u307e\u3057\u305f\uff08[OpenCV\u3092\u4f7f\u3063\u305f\u9854\u8a8d\u8b58\uff08Haar-like\u7279\u5fb4\u5206\u985e\u5668\uff09](http://qiita.com/olympic2020/items/04b1b26c1bc2e8081427)\uff09\u3002\u4eca\u56de\u306f\u3001\u5fdc\u7528\u3068\u3057\u3066\u3001Haar-like\u7279\u5fb4\u5206\u985e\u5668\u3067\u62bd\u51fa\u3057\u305f\u9854\u753b\u50cf\u3092OpenCV\u306e\u9854\u63a8\u5b9a\u5668\uff08Eigenface, Fisherface, LBPH\uff09\u306b\u5b66\u7fd2\u3055\u305b\u3001\u8868\u60c5\u306e\u9055\u3044\u3001\u5909\u88c5\u3001\u30e9\u30a4\u30c8\u306e\u5f53\u305f\u308a\u5177\u5408\u306e\u9055\u3044\u304c\u3042\u308b\u4e2d\u3067\u3001\u672a\u5b66\u7fd2\u306e\u9854\u304c\u8ab0\u306e\u9854\u306a\u306e\u304b\u3092\u63a8\u6e2c\u3055\u305b\u3066\u307f\u307e\u3059\u3002\n\nOpenCV\u304c\u642d\u8f09\u3057\u3066\u3044\u308b\u9854\u63a8\u5b9a\u30a2\u30eb\u30b4\u30ea\u30ba\u30e0\u306f\u4ee5\u4e0b\u306b\u306a\u308a\u307e\u3059\u3002\uff08[\u8a73\u7d30\u306f\u3053\u3061\u3089](http://docs.opencv.org/2.4/modules/contrib/doc/facerec/facerec_tutorial.html)\uff09\n\n+ **Eigenface\uff08\u56fa\u6709\u9854\uff09**  \n    \u9854\u753b\u50cf\u3092\u56fa\u6709\u9854\u306b\u5909\u63db\u3059\u308b\u3001\u4e3b\u6210\u5206\u5206\u6790\uff08PCA\uff09\u306e\u51e6\u7406\u904e\u7a0b\u306f\u6b21\u306e\u3088\u3046\u306b\u306a\u308a\u307e\u3059\u3002\n    1. \u8a13\u7df4\u7528\u306e\u753b\u50cf\uff08\u540c\u3058\u7167\u660e\u6761\u4ef6\u3001\u76ee\u3084\u9f3b\u306e\u4f4d\u7f6e\u3067\u30b9\u30b1\u30fc\u30ea\u30f3\u30b0\u3001\u540c\u89e3\u50cf\u5ea6\uff09\u3092\u6e96\u5099\u3057\u307e\u3059\u3002\n    2. \u8a13\u7df4\u7528\u753b\u50cf\u306e\u5e73\u5747\u3092\u6c42\u3081\u3001\u5e73\u5747\u753b\u50cf\u3092\u5404\u753b\u50cf\u304b\u3089\u6e1b\u7b97\u3057\u307e\u3059\u3002\n    3. \u6e1b\u7b97\u3057\u305f\u753b\u50cf\u306e\u5171\u5206\u6563\u884c\u5217\u3092\u8a08\u7b97\u3057\u307e\u3059\u3002\n    4. \u5171\u5206\u6563\u884c\u5217\u304b\u3089\u3001\u56fa\u6709\u30d9\u30af\u30c8\u30eb\u3068\u56fa\u6709\u5024\u3092\u8a08\u7b97\u3057\u307e\u3059\u3002\n    5. \u4e3b\u6210\u5206\u3092\u9078\u629e\u3057\u307e\u3059\u3002\n    \n    ![eigenfaces_opencv.png](https://qiita-image-store.s3.amazonaws.com/0/107056/ae1cdee3-8508-cea0-3fee-79aa3e3656e8.png)\n    \u3000  \n+ **Fisherface**  \n    Eigenface\u306e\u6539\u826f\u7248\u3067\u3059\u3002Eigenface\u3068\u6bd4\u8f03\u3057\u3001\u7167\u660e\u3084\u89d2\u5ea6\u306e\u9055\u3044\u306b\u5f71\u97ff\u3055\u308c\u306b\u304f\u3044\u3068\u3044\u3046\u7279\u5fb4\u304c\u3042\u308a\u307e\u3059\u3002\n    \n    ![fisherfaces_opencv.png](https://qiita-image-store.s3.amazonaws.com/0/107056/1f7aa5b7-19f6-5fa3-efd8-1845c2986cc7.png)\n    \u3000  \n     \n+ **Local Binary Patterns Histogram(LBPH)**  \n    \u9854\u3092\u5c0f\u3055\u306a\u30bb\u30eb\u306b\u5206\u5272\u3057\u3001\u305d\u308c\u305e\u308c\u306e\u30a8\u30ea\u30a2\u306e\u30d2\u30b9\u30c8\u30b0\u30e9\u30e0\u3092\u6bd4\u8f03\u3057\u307e\u3059\u3002\u3053\u306e\u30a2\u30eb\u30b4\u30ea\u30ba\u30e0\u306fEigenface, Fisherface\u3068\u6bd4\u3079\u3001\u30b5\u30f3\u30d7\u30eb\u306e\u9854\u306e\u30b5\u30a4\u30ba\u3084\u5f62\u304c\u7570\u306a\u3063\u3066\u3044\u3066\u3082\u7cbe\u5ea6\u3088\u304f\u691c\u51fa\u3067\u304d\u308b\u3068\u3044\u3046\u7279\u5fb4\u304c\u3042\u308a\u307e\u3059\u3002\n    \n    ![lbp_yale.jpg](https://qiita-image-store.s3.amazonaws.com/0/107056/a91e13bc-9320-e260-8923-40bfe6b3e681.jpeg)\n\n\n\n\u203b \u753b\u50cf\u306f\u3001\u3044\u305a\u308c\u3082OpenCV\u306e\u30c1\u30e5\u30fc\u30c8\u30ea\u30a2\u30eb\u304b\u3089\uff08[\u30ea\u30f3\u30af](http://docs.opencv.org/2.4/modules/contrib/doc/facerec/facerec_tutorial.html)\uff09\n\n\u4eca\u56de\u306f\u3001\u9854\u306e\u8a8d\u8b58\u3092\u884c\u3044\u307e\u3059\u304c\u3001\u3053\u308c\u3089\u306e\u30a2\u30eb\u30b4\u30ea\u30ba\u30e0\u306f\u3001\u7b46\u8de1\u9451\u5b9a\u3001\u533b\u7528\u753b\u50cf\u51e6\u7406\u3001\u8aad\u5507\u8853\u306b\u3082\u5fdc\u7528\u3055\u308c\u308b\u6280\u8853\u3067\u3059\u3002\n\u9762\u767d\u3044\u3068\u3053\u308d\u3067\u306f\u3001\u5909\u88c5\u3057\u3066\u3044\u308b\u4eba\u3092\u898b\u5206\u3051\u308b\u306a\u3093\u3066\u3053\u3068\u3082\u53ef\u80fd\u3067\u3059\u3002\n\n# OpenCV\nOpenCV(Open Source Computer Vision Library)\u306fBSD\u30e9\u30a4\u30bb\u30f3\u30b9\u306e\u6620\u50cf/\u753b\u50cf\u51e6\u7406\u30e9\u30a4\u30d6\u30e9\u30ea\u96c6\u3067\u3059\u3002\u753b\u50cf\u306e\u30d5\u30a3\u30eb\u30bf\u51e6\u7406\u3001\u30c6\u30f3\u30d7\u30ec\u30fc\u30c8\u30de\u30c3\u30c1\u30f3\u30b0\u3001\u7269\u4f53\u8a8d\u8b58\u3001\u6620\u50cf\u89e3\u6790\u3001\u6a5f\u68b0\u5b66\u7fd2\u306a\u3069\u306e\u30a2\u30eb\u30b4\u30ea\u30ba\u30e0\u304c\u591a\u6570\u7528\u610f\u3055\u308c\u3066\u3044\u307e\u3059\u3002\n\n\u25a0 OpenCV\u3092\u4f7f\u3063\u305f\u52d5\u4f53\u8ffd\u8de1\u306e\u4f8b (OpenCV Google Summer of Code 2015)\n[https://www.youtube.com/watch?v=OUbUFn71S4s](https://www.youtube.com/watch?v=OUbUFn71S4s)\n\n\u25a0 \u30a4\u30f3\u30b9\u30c8\u30fc\u30eb\u3068\u7c21\u5358\u306a\u4f7f\u3044\u65b9\u306f\u3053\u3061\u3089\n[OpenCV 3\uff08core + contrib\uff09\u3092Python 3\u306e\u74b0\u5883\u306b\u30a4\u30f3\u30b9\u30c8\u30fc\u30eb\uff06OpenCV 2\u3068OpenCV 3\u306e\u9055\u3044\uff06\u7c21\u5358\u306a\u52d5\u4f5c\u30c1\u30a7\u30c3\u30af](http://qiita.com/olympic2020/items/d5d475a446ec9c73261e)  \n\u3000\u3000\u2605 OpenCV 3.1\u306eopencv_contrib\u306eface\u30e2\u30b8\u30e5\u30fc\u30eb\u306fpredict()\u30e1\u30bd\u30c3\u30c9\u304c\u610f\u56f3\u901a\u308a\u306b\u52d5\u4f5c\u3057\u307e\u305b\u3093\u3067\u3057\u305f\u3002\n\u3000\u3000\u3000 \u4eca\u56de\u306f\u3001Anaconda 2\u306bOpenCV 2\u3092\u30a4\u30f3\u30b9\u30c8\u30fc\u30eb\u3057\u3066\u4e0b\u8a18\u30d7\u30ed\u30b0\u30e9\u30e0\u3092\u52d5\u4f5c\u3055\u305b\u3066\u3044\u307e\u3059\u3002\n\n\u25a0 \u9759\u6b62\u753b\u50cf\u306e\u51e6\u7406\u306b\u3064\u3044\u3066\u306f\u3053\u3061\u3089\n[OpenCV\u3067\u30a8\u30c3\u30b8\u691c\u51fa\u3057\u3066\u307f\u308b](http://qiita.com/olympic2020/items/2c3a2bfefe73ab5c86a4)\n[OpenCV\u3067\u5404\u7a2e\u30d5\u30a3\u30eb\u30bf\u30fc\u51e6\u7406\u3092\u3059\u308b\uff08\u30b0\u30e9\u30c7\u30a3\u30a8\u30f3\u30c8\u3001\u30cf\u30a4\u30d1\u30b9\u3001\u30e9\u30d7\u30e9\u30b7\u30a2\u30f3\u3001\u30ac\u30a6\u30b7\u30a2\u30f3\uff09](http://qiita.com/olympic2020/items/93e01ef22e46b14a60a9)\n[OpenCV\u3067\u7279\u5fb4\u70b9\u3092\u62bd\u51fa\u3059\u308b\uff08AgastFeature, FAST, GFTT, MSER, AKAZE, BRISK, KAZE, ORB, SimpleBlob\uff09](http://qiita.com/olympic2020/items/62989573a30ec1d8180b)\n[OpenCV\u3092\u4f7f\u3063\u305f\u9854\u8a8d\u8b58\uff08Haar-like\u7279\u5fb4\u5206\u985e\u5668\uff09](http://qiita.com/olympic2020/items/04b1b26c1bc2e8081427)\n\n\u25a0 \u52d5\u753b\u306e\u51e6\u7406\u306b\u3064\u3044\u3066\u306f\u3053\u3061\u3089\n[OpenCV\u3067\u52d5\u753b\u3092\u30ea\u30a2\u30eb\u30bf\u30a4\u30e0\u306b\u5909\u63db\u3057\u3066\u307f\u308b](http://qiita.com/olympic2020/items/ce00fab38d829965db3b)\n[OpenCV\u3067Web\u30ab\u30e1\u30e9/\u30d3\u30c7\u30aa\u30ab\u30e1\u30e9\u306e\u52d5\u753b\u3092\u30ea\u30a2\u30eb\u30bf\u30a4\u30e0\u306b\u5909\u63db\u3057\u3066\u307f\u308b](http://qiita.com/olympic2020/items/12a2eceaf65f142ec3df)\n[OpenCV\u3067\u30aa\u30d7\u30c6\u30a3\u30ab\u30eb\u30d5\u30ed\u30fc\u3092\u30ea\u30a2\u30eb\u30bf\u30a4\u30e0\u306b\u63cf\u753b\u3059\u308b\uff08Shi-Tomasi\u6cd5\u3001Lucas-Kanade\u6cd5\uff09](http://qiita.com/olympic2020/items/772549d0fc3c89fb3cc4)\n[OpenCV\u3092\u4f7f\u3063\u305f\u7269\u4f53\u8ffd\u8de1\uff08\u30de\u30a6\u30b9\u3067\u6307\u5b9a\u3057\u305f\u7279\u5fb4\u70b9\u3092Lucas-Kanade\u6cd5\u3067\u8ffd\u8de1\u3059\u308b](http://qiita.com/olympic2020/items/3d8973f855e963c9d999)\n[OpenCV\u3092\u4f7f\u3063\u305f\u30e2\u30fc\u30b7\u30e7\u30f3 \u30c6\u30f3\u30d7\u30ec\u30fc\u30c8\u89e3\u6790\uff08\u30ea\u30a2\u30eb\u30bf\u30a4\u30e0\u306b\u7269\u4f53\u3068\u305d\u306e\u52d5\u304f\u65b9\u5411\u3092\u8a8d\u8b58\u3059\u308b\uff09](http://qiita.com/olympic2020/items/a4ecf7babdbe710208ae)\n\n# \u9854\u30c7\u30fc\u30bf\u30d9\u30fc\u30b9\n\u753b\u50cf\u51e6\u7406\u3067\u3088\u304f\u5229\u7528\u3055\u308c\u308b\u9854\u30c7\u30fc\u30bf\u30d9\u30fc\u30b9\u3092\u7d39\u4ecb\u3057\u307e\u3059\u3002\n\n+ The Yale face database(Yalefaces)\uff1a  \n    http://vision.ucsd.edu/content/yale-face-database  \n    GIF\u5f62\u5f0f\u306e\u9854\u753b\u50cf\u3067\u3059\u3002  \n+ The AT&T\uff1a  \n    http://www.cl.cam.ac.uk/research/dtg/attarchive/facedatabase.html  \n    PBM\u5f62\u5f0f\u306e\u9854\u753b\u50cf\u3067\u3059\u3002  \n\n\u4eca\u56de\u306f\u3001Yale face database(Yalefaces)\u3092\u5229\u7528\u3057\u307e\u3059\u3002\n\n# \u8a13\u7df4\u30c7\u30fc\u30bf\u3068\u30c6\u30b9\u30c8\u30c7\u30fc\u30bf\n\u3000Yalefaces\u306b\u306f\u300115\u4eba\u306e\u69d8\u3005\u306a\u8868\u60c5\u306e\u9854\u304c\u683c\u7d0d\u3055\u308c\u3066\u3044\u307e\u3059\u3002\u305d\u308c\u305e\u308c\u306e\u4eba\u304c\u666e\u901a\u306e\u9854\u3001\u773c\u93e1\u3092\u304b\u3051\u3066\u3044\u308b\u9854\u3001\u559c\u3093\u3067\u3044\u308b\u9854\u3001\u30a6\u30a3\u30f3\u30af\u3057\u3066\u3044\u308b\u9854\u3001\u60b2\u3057\u3093\u3067\u3044\u308b\u9854\u3001\u60b2\u3057\u3093\u3067\u3044\u308b\u9854\u3001\u9a5a\u3044\u3066\u3044\u308b\u9854\u3001\u53f3/\u5de6\u304b\u3089\u306e\u30e9\u30a4\u30c8\u304c\u5f53\u305f\u3063\u3066\u3044\u308b\u9854\u3092\u3057\u3066\u3044\u307e\u3059\u3002\n\u3000\u9069\u5b9c\u3001\u305d\u308c\u305e\u308c\u306e\u4eba\u306e\u9854\u753b\u50cf\u304b\u3089\u4efb\u610f\u306e\uff11\u679a\u306e\u9854\u753b\u50cf\u3092\u30c6\u30b9\u30c8\u7528\u3068\u3057\u3066\u629c\u304d\u53d6\u308a\u307e\u3059\uff08\u8a13\u7df4\u7528\u753b\u50cf\u306b\u30c6\u30b9\u30c8\u753b\u50cf\u3092\u542b\u3081\u306a\u3044\u3088\u3046\u306b\u3057\u307e\u3059\uff09\u3002\n\u3000\u4eca\u56de\u306f\u3001\u8a13\u7df4\u7528\u753b\u50cf\u3092`yalefaces`\u30c7\u30a3\u30ec\u30af\u30c8\u30ea\u3001\u30c6\u30b9\u30c8\u7528\u753b\u50cf\u3092`test`\u30c7\u30a3\u30ec\u30af\u30c8\u30ea\u306b\u683c\u7d0d\u3057\u307e\u3057\u305f\u3002\n\n![trainingdata.png](https://qiita-image-store.s3.amazonaws.com/0/107056/e996e1d1-6568-579a-d64d-a06bb9170209.png)\n\u3000\u3000\u3000\u3000\u3000\u3000\u3000\u3000\u3000\u3000\u69d8\u3005\u306a\u8868\u60c5\u306e\u9854\n\n# \u30d7\u30ed\u30b0\u30e9\u30e0\n\n\u30d7\u30ed\u30b0\u30e9\u30e0\u306e\u6d41\u308c\u306f\u4ee5\u4e0b\u306e\u3068\u304a\u308a\u3067\u3059\u3002\n1. \u8a13\u7df4\u7528\u753b\u50cf\u3092\u8aad\u307f\u8fbc\u3080\n2. Haar-like\u7279\u5fb4\u5206\u985e\u5668\u3092\u4f7f\u3063\u3066\u9854\u9818\u57df\u3092\u62bd\u51fa\n3. \u9854\u9818\u57df\u3092\u4e00\u5b9a\u30b5\u30a4\u30ba\u306b\u30ea\u30b5\u30a4\u30ba\n4. \u8a13\u7df4\u30c7\u30fc\u30bf\u3068\u3057\u3066\u753b\u50cf\u3068\u30e9\u30d9\u30eb\u3092FaceRecognizer\u3067\u30c8\u30ec\u30fc\u30cb\u30f3\u30b0\uff08train()\uff09\n5. \u5168\u8a13\u7df4\u7528\u753b\u50cf\u306b\u5bfe\u3057\u30661\uff5e4\u3092\u7e70\u308a\u8fd4\u3057\u5b9f\u65bd\n6. \u30c6\u30b9\u30c8\u7528\u753b\u50cf\u3092\u8aad\u307f\u8fbc\u3080\n7. Haar-like\u7279\u5fb4\u5206\u985e\u5668\u3092\u4f7f\u3063\u3066\u9854\u9818\u57df\u3092\u62bd\u51fa\n8. \u9854\u9818\u57df\u3092\u4e00\u5b9a\u30b5\u30a4\u30ba\u306b\u30ea\u30b5\u30a4\u30ba\n9. FaceRecognizer\u3067\u30c6\u30b9\u30c8\u753b\u50cf\u306e\u4e88\u6e2c\u5b9f\u65bd\uff08predict()\uff09\u21d2[\u30e9\u30d9\u30eb, \u78ba\u5ea6]\n10. \u5168\u30c6\u30b9\u30c8\u7528\u753b\u50cf\u306b\u5bfe\u3057\u30666\uff5e9\u3092\u7e70\u308a\u8fd4\u3057\u5b9f\u65bd\n\n\u30d7\u30ed\u30b0\u30e9\u30e0\u306e\u30dd\u30a4\u30f3\u30c8\u304c\u3044\u304f\u3064\u304b\u3042\u308a\u307e\u3059\u3002\n\n+ \u30e9\u30d9\u30eb\u306f\u6570\u5024\uff08int\uff09\u3067\u6307\u5b9a\u3057\u307e\u3059\u3002\n+ \u8a13\u7df4\u753b\u50cf\u3001\u30c6\u30b9\u30c8\u753b\u50cf\u306f\u540c\u3058\u753b\u50cf\u30b5\u30a4\u30ba\u306b\u30ea\u30b5\u30a4\u30ba\u3057\u3066\u304a\u304f\u5fc5\u8981\u304c\u3042\u308a\u307e\u3059\u3002\n+ \u78ba\u5ea6\uff08confidence\uff09\u306f\u3001\u5206\u6563\u306b\u57fa\u3065\u3044\u3066\u8a08\u7b97\u3055\u308c\u308b\u305f\u3081\u30010\u306b\u8fd1\u3044\u307b\u3046\u304c\u78ba\u5ea6\u304c\u9ad8\u304f\u306a\u308a\u307e\u3059\u3002\u8a13\u7df4\u6642\u306b\u30c6\u30b9\u30c8\u753b\u50cf\u3068\u540c\u4e00\u753b\u50cf\u3092\u5b66\u7fd2\u3057\u3066\u3044\u308b\u3068\u3001\u7279\u5fb4\u70b9\u304c\u4e00\u81f4\u3059\u308b\u305f\u3081\u3001\u78ba\u5ea6\uff08confidence\uff09\u304c0\u306b\u306a\u308a\u307e\u3059\u3002\n+ OpenCV\u306fGIF\u753b\u50cf\u3092\u30b5\u30dd\u30fc\u30c8\u3057\u3066\u3044\u307e\u305b\u3093\u3002Yalefaces\u306eGIF\u753b\u50cf\u306f\u3001Pillow(PIL)\u3067\u51e6\u7406\u3057\u307e\u3059\u3002\n+ Haar-like\u7279\u5fb4\u5206\u985e\u5668\u306e\u30c6\u30f3\u30d7\u30ec\u30fc\u30c8\u306f\u3001OpenCV\u306b\u4ed8\u5c5e\u3057\u3066\u3044\u308b`haarcascade_frontalface_default.xml`\u3092\u5229\u7528\u3057\u307e\u3059\u3002\n+ \u9854\u63a8\u5b9a\u5668\u306e\u30a2\u30eb\u30b4\u30ea\u30ba\u30e0\u3092EigenFace, FisherFace, LBPH\u306b\u5207\u308a\u66ff\u3048\u305f\u3044\u5834\u5408\u306f\u3001\u30b3\u30e1\u30f3\u30c8\u30a2\u30a6\u30c8\u3057\u3066\u3044\u308b`recognizer`\u3092\u5207\u308a\u66ff\u3048\u3066\u304f\u3060\u3055\u3044\u3002\n\n```face_predict.py\n#!/usr/bin/python\n# -*- coding: utf-8 -*-\n\nimport cv2, os\nimport numpy as np\nfrom PIL import Image\n\n# \u30c8\u30ec\u30fc\u30cb\u30f3\u30b0\u753b\u50cf\ntrain_path = './yalefaces'\n\n# \u30c6\u30b9\u30c8\u753b\u50cf\ntest_path = './test'\n\n# Haar-like\u7279\u5fb4\u5206\u985e\u5668\ncascadePath = \"haarcascade_frontalface_default.xml\"\nfaceCascade = cv2.CascadeClassifier(cascadePath)\n\n# \u9854\u8a8d\u8b58\u5668\u306e\u69cb\u7bc9 for OpenCV 2\n#   \u203b OpenCV3\u3067\u306fFaceRecognizer\u306fcv2.face\u306e\u30e2\u30b8\u30e5\u30fc\u30eb\u306b\u306a\u308a\u307e\u3059\n# EigenFace\n#recognizer = cv2.createEigenFaceRecognizer()\n# FisherFace\n#recognizer = cv2.createFisherFaceRecognizer()\n# LBPH\nrecognizer = cv2.createLBPHFaceRecognizer()\n\n# \u6307\u5b9a\u3055\u308c\u305fpath\u5185\u306e\u753b\u50cf\u3092\u53d6\u5f97\ndef get_images_and_labels(path):\n    # \u753b\u50cf\u3092\u683c\u7d0d\u3059\u308b\u914d\u5217\n    images = []\n    # \u30e9\u30d9\u30eb\u3092\u683c\u7d0d\u3059\u308b\u914d\u5217\n    labels = []\n    # \u30d5\u30a1\u30a4\u30eb\u540d\u3092\u683c\u7d0d\u3059\u308b\u914d\u5217\n    files = []\n    for f in os.listdir(path):\n        # \u753b\u50cf\u306e\u30d1\u30b9\n        image_path = os.path.join(path, f)\n        # \u30b0\u30ec\u30fc\u30b9\u30b1\u30fc\u30eb\u3067\u753b\u50cf\u3092\u8aad\u307f\u8fbc\u3080\n        image_pil = Image.open(image_path).convert('L')\n        # NumPy\u306e\u914d\u5217\u306b\u683c\u7d0d\n        image = np.array(image_pil, 'uint8')\n        # Haar-like\u7279\u5fb4\u5206\u985e\u5668\u3067\u9854\u3092\u691c\u77e5\n        faces = faceCascade.detectMultiScale(image)\n        # \u691c\u51fa\u3057\u305f\u9854\u753b\u50cf\u306e\u51e6\u7406\n        for (x, y, w, h) in faces:\n            # \u9854\u3092 200x200 \u30b5\u30a4\u30ba\u306b\u30ea\u30b5\u30a4\u30ba\n            roi = cv2.resize(image[y: y + h, x: x + w], (200, 200), interpolation=cv2.INTER_LINEAR)\n            # \u753b\u50cf\u3092\u914d\u5217\u306b\u683c\u7d0d\n            images.append(roi)\n            # \u30d5\u30a1\u30a4\u30eb\u540d\u304b\u3089\u30e9\u30d9\u30eb\u3092\u53d6\u5f97\n            labels.append(int(f[7:9]))\n            # \u30d5\u30a1\u30a4\u30eb\u540d\u3092\u914d\u5217\u306b\u683c\u7d0d\n            files.append(f)\n\n    return images, labels, files\n\n\n# \u30c8\u30ec\u30fc\u30cb\u30f3\u30b0\u753b\u50cf\u3092\u53d6\u5f97\nimages, labels, files = get_images_and_labels(train_path)\n\n# \u30c8\u30ec\u30fc\u30cb\u30f3\u30b0\u5b9f\u65bd\nrecognizer.train(images, np.array(labels))\n\n# \u30c6\u30b9\u30c8\u753b\u50cf\u3092\u53d6\u5f97\ntest_images, test_labels, test_files = get_images_and_labels(test_path)\n\ni = 0\nwhile i < len(test_labels):\n    # \u30c6\u30b9\u30c8\u753b\u50cf\u306b\u5bfe\u3057\u3066\u4e88\u6e2c\u5b9f\u65bd\n    label, confidence = recognizer.predict(test_images[i])\n    # \u4e88\u6e2c\u7d50\u679c\u3092\u30b3\u30f3\u30bd\u30fc\u30eb\u51fa\u529b\n    print(\"Test Image: {}, Predicted Label: {}, Confidence: {}\".format(test_files[i], label, confidence))\n    # \u30c6\u30b9\u30c8\u753b\u50cf\u3092\u8868\u793a\n    cv2.imshow(\"test image\", test_images[i])\n    cv2.waitKey(300)\n    \n    i += 1\n\n# \u7d42\u4e86\u51e6\u7406\ncv2.destroyAllWindows()\n```\n\n\n\n\u4eca\u56de\u306e\u30d7\u30ed\u30b0\u30e9\u30e0\u306f\u3001Python 2.7.12\u3068OpenCV 2.4.13\u3067\u5b9f\u884c\u3057\u307e\u3057\u305f\u3002\nPython 3\u3068OpenCV 3\u3067\u5b9f\u884c\u3059\u308b\u5834\u5408\u306f\u3001\u30d7\u30ed\u30b0\u30e9\u30e0\u4e2d\u306eFaceRecognizer\u306e\u90e8\u5206\u3092`cv2`\u304b\u3089`cv2.face`\u306b\u5909\u66f4\u3057\u3066\u304f\u3060\u3055\u3044\u3002\u307e\u305f\u3001OpenCV 3.1\u3067\u306f\u3001FaceRecognizer\u306epredict()\u30e1\u30bd\u30c3\u30c9\u304c\u610f\u56f3\u3057\u305f\u901a\u308a\u306b\u52d5\u4f5c\u3057\u307e\u305b\u3093\u3002\u8a73\u7d30\u306f\u3053\u3061\u3089\u306e[OpenCV2\u3068OpenCV3\u306e\u9055\u3044\uff06etc.\u21d2\u30d0\u30b0\u3067\u52d5\u4f5c\u3057\u306a\u3044\u30e1\u30bd\u30c3\u30c9\u304c\u3042\u308b](http://qiita.com/olympic2020/items/d5d475a446ec9c73261e)\u3092\u53c2\u7167\u3057\u3066\u304f\u3060\u3055\u3044\u3002\n\n# \u5b9f\u884c\u7d50\u679c\nsubjectXX\u306e\u300cXX\u300d\u306e\u90e8\u5206\u3092\u6570\u5024\u3068\u3057\u3066\u30e9\u30d9\u30eb\u306b\u8a2d\u5b9a\u3057\u3066\u8a13\u7df4\u3092\u5b9f\u884c\u3057\u3066\u3044\u307e\u3059\u3002\u30c6\u30b9\u30c8\u753b\u50cf\uff08Image\uff09\u306b\u5bfe\u3057\u3066\u3001\u6b63\u3057\u3044\u30e9\u30d9\u30eb\uff08Predicted Label\uff09\u3092\u63a8\u5b9a\u3059\u308b\u3053\u3068\u304c\u3067\u304d\u3066\u3044\u307e\u3059\u3002\n\nEigenface\u3067\u63a8\u5b9a\u3057\u305f\u3068\u3053\u308d\u3001\u30e9\u30a4\u30c8\u95a2\u4fc2\u306elabel=5, 6, 8, 9\u306e\u63a8\u5b9a\u306b\u5931\u6557\u3057\u3001\u305d\u306e\u4ed6\u306e\u63a8\u5b9a\u306b\u306f\u6210\u529f\u3057\u307e\u3057\u305f\u3002\n\n```Eigenface\nTest Image: subject01.happy, Predicted Label: 1, Confidence: 4383.25505059\nTest Image: subject02.wink, Predicted Label: 2, Confidence: 6947.75053221\nTest Image: subject03.happy, Predicted Label: 3, Confidence: 4145.80848328\nTest Image: subject04.glasses, Predicted Label: 4, Confidence: 5420.9213318\nTest Image: subject05.leftlight, Predicted Label: 12, Confidence: 7722.72936213\nTest Image: subject06.leftlight, Predicted Label: 1, Confidence: 10086.4101755\nTest Image: subject07.glasses, Predicted Label: 7, Confidence: 7043.70495967\nTest Image: subject08.leftlight, Predicted Label: 2, Confidence: 10275.9545456\nTest Image: subject09.rightlight, Predicted Label: 15, Confidence: 7481.31094502\nTest Image: subject10.sleepy, Predicted Label: 10, Confidence: 2317.22633915\nTest Image: subject11.centerlight, Predicted Label: 11, Confidence: 8077.42380817\nTest Image: subject12.glasses, Predicted Label: 12, Confidence: 5233.03342586\nTest Image: subject13.surprised, Predicted Label: 13, Confidence: 6516.98395617\nTest Image: subject14.normal, Predicted Label: 14, Confidence: 0.0\nTest Image: subject15.surprised, Predicted Label: 15, Confidence: 7165.71597327\n```\n\nFisherface\u3067\u63a8\u5b9a\u3057\u305f\u3068\u3053\u308d\u3001\u5168\u3066\u306e\u63a8\u5b9a\u306b\u6210\u529f\u3057\u307e\u3057\u305f\u3002\n\n```Fisherface\nTest Image: subject01.happy, Predicted Label: 1, Confidence: 801.784987691\nTest Image: subject02.wink, Predicted Label: 2, Confidence: 2368.90429845\nTest Image: subject03.happy, Predicted Label: 3, Confidence: 826.018934498\nTest Image: subject04.glasses, Predicted Label: 4, Confidence: 1080.94198758\nTest Image: subject05.leftlight, Predicted Label: 5, Confidence: 2137.42013849\nTest Image: subject06.leftlight, Predicted Label: 6, Confidence: 2092.53092982\nTest Image: subject07.glasses, Predicted Label: 7, Confidence: 2042.67529443\nTest Image: subject08.leftlight, Predicted Label: 8, Confidence: 2239.45348941\nTest Image: subject09.rightlight, Predicted Label: 9, Confidence: 2875.2788263\nTest Image: subject10.sleepy, Predicted Label: 10, Confidence: 662.762591569\nTest Image: subject11.centerlight, Predicted Label: 11, Confidence: 1703.80515728\nTest Image: subject12.glasses, Predicted Label: 12, Confidence: 1480.18770297\nTest Image: subject13.surprised, Predicted Label: 13, Confidence: 1690.12255703\nTest Image: subject14.normal, Predicted Label: 14, Confidence: 0.0\nTest Image: subject15.surprised, Predicted Label: 15, Confidence: 1887.42538269\n```\n\nLBPH\u3067\u63a8\u5b9a\u3057\u305f\u3068\u3053\u308d\u3001\u30e9\u30a4\u30c8\u95a2\u4fc2\u306elabel=6, 9\u306e\u63a8\u5b9a\u306b\u5931\u6557\u3002\u305d\u306e\u4ed6\u306f\u6210\u529f\u3057\u307e\u3057\u305f\u3002\n\n```LBPH\nTest Image: subject01.happy, Predicted Label: 1, Confidence: 34.9751422497\nTest Image: subject02.wink, Predicted Label: 2, Confidence: 37.8730262399\nTest Image: subject03.happy, Predicted Label: 3, Confidence: 35.1183059319\nTest Image: subject04.glasses, Predicted Label: 4, Confidence: 37.5886492389\nTest Image: subject05.leftlight, Predicted Label: 5, Confidence: 48.2634869014\nTest Image: subject06.leftlight, Predicted Label: 14, Confidence: 64.5502245279\nTest Image: subject07.glasses, Predicted Label: 7, Confidence: 54.5043891288\nTest Image: subject08.leftlight, Predicted Label: 8, Confidence: 84.4281976817\nTest Image: subject09.rightlight, Predicted Label: 12, Confidence: 75.3254674542\nTest Image: subject10.sleepy, Predicted Label: 10, Confidence: 17.8806440153\nTest Image: subject11.centerlight, Predicted Label: 11, Confidence: 74.8238311755\nTest Image: subject12.glasses, Predicted Label: 12, Confidence: 31.8721301084\nTest Image: subject13.surprised, Predicted Label: 13, Confidence: 40.3420527188\nTest Image: subject14.normal, Predicted Label: 14, Confidence: 0.0\nTest Image: subject15.surprised, Predicted Label: 15, Confidence: 33.2920487407\n```\n\n\uff13\u3064\u306e\u30a2\u30eb\u30b4\u30ea\u30ba\u30e0\u306e\u6bd4\u8f03\u7d50\u679c\u306f\u3001\u524d\u8a55\u5224\u901a\u308a\u3001Fisherface\u304c\u30e9\u30a4\u30c8\u306e\u5f71\u97ff\u3092\u53d7\u3051\u306b\u304f\u304f\u306a\u3063\u3066\u3044\u307e\u3057\u305f\u3002\n\u307e\u305f\u3001\u63a8\u5b9a\u306e\u6210\u529f\u3001\u5931\u6557\u306fConfidence\u306e\u5024\u3068\u3042\u308b\u7a0b\u5ea6\u5bfe\u5fdc\u3057\u305f\u7d50\u679c\u306b\u306a\u3063\u305f\u305f\u3081\u3001Confidence\u306b\u95be\u5024\u3092\u8a2d\u3051\u3001\u4fe1\u983c\u3067\u304d\u306a\u3044\u63a8\u5b9a\u7d50\u679c\u306f\u3001\u63a8\u5b9a\u4e0d\u80fd\u306e\u9805\u76ee\u306b\u5206\u985e\u3059\u308b\u3068\u3088\u3055\u305d\u3046\u3067\u3057\u305f\u3002\n\n# \uff08\u304a\u307e\u3051\uff09GIF\u753b\u50cf \u2192 PNG\u753b\u50cf\u5909\u63db\nOpenCV\u306f\u30d1\u30c6\u30f3\u30c8\u306e\u554f\u984c\u3092\u56de\u907f\u3059\u308b\u305f\u3081\u3001GIF\u753b\u50cf\u3092\u30b5\u30dd\u30fc\u30c8\u3057\u3066\u3044\u307e\u305b\u3093\u3002cv2.imread()\u3067GIF\u753b\u50cf\u3092\u8aad\u307f\u8fbc\u3093\u3067\u3082\u4f55\u3082\u8aad\u307f\u8fbc\u307f\u307e\u305b\u3093\u3002\nGIF\u5f62\u5f0f\u306e\u9854\u753b\u50cf\u30c7\u30fc\u30bf\u30d9\u30fc\u30b9\u3001Yalefaces\u3092OpenCV\u3067\u5229\u7528\u3057\u305f\u3044\u65b9\u306f\u3001\u4e0b\u8a18\u30b9\u30af\u30ea\u30d7\u30c8\u3067\u4e8b\u524d\u306bPNG\u5f62\u5f0f\u306e\u9854\u753b\u50cf\u306b\u5909\u63db\u3057\u3066\u304a\u304f\u3068\u4fbf\u5229\u3067\u3059\u3002\u4e0b\u8a18\u30b9\u30af\u30ea\u30d7\u30c8\u306f\u300cyalefaces\u300d\u30c7\u30a3\u30ec\u30af\u30c8\u30ea\u5185\u306eGIF\u753b\u50cf\u3092PNG\u753b\u50cf\u306b\u5909\u63db\u3057\u3066\u300cpng\u300d\u30c7\u30a3\u30ec\u30af\u30c8\u30ea\u306b\u4fdd\u5b58\u3057\u307e\u3059\u3002\u5fc5\u8981\u306a\u65b9\u306f\u4e0b\u8a18\u30b9\u30af\u30ea\u30d7\u30c8\u3092\u3054\u5229\u7528\u304f\u3060\u3055\u3044\u3002\n\n```gif2png.py\n# -*- coding: utf-8 -*-\n\nimport os\nfrom PIL import Image\nimport shutil\n\n# \u5909\u63db\u5bfe\u8c61\u30d5\u30a1\u30a4\u30eb\u3092\u683c\u7d0d\u3057\u305f\u30c7\u30a3\u30ec\u30af\u30c8\u30ea\norg_dir = 'yalefaces'\n# \u5909\u63db\u5bfe\u8c61\u30d5\u30a1\u30a4\u30eb\u306e\u62e1\u5f35\u5b50\norg_ext = 'gif'\n# \u5909\u63db\u5f8c\u306e\u30d5\u30a1\u30a4\u30eb\u3092\u683c\u7d0d\u3059\u308b\u30c7\u30a3\u30ec\u30af\u30c8\u30ea\nconv_dir = 'png'\n# \u5909\u63db\u5f8c\u306e\u30d5\u30a1\u30a4\u30eb\u306e\u62e1\u5f35\u5b50\nconv_ext = 'png'\n\n# \u65e2\u5b58\u306e\u30c7\u30a3\u30ec\u30af\u30c8\u30ea\u3092\u30d5\u30a1\u30a4\u30eb\u3082\u542b\u3081\u3066\u524a\u9664\nif os.path.exists(conv_dir):\n    shutil.rmtree(conv_dir)\n# \u30c7\u30a3\u30ec\u30af\u30c8\u30ea\u3092\u4f5c\u6210\nos.mkdir(conv_dir)\n\n# \u300c.\u300d\u3068\u62e1\u5f35\u5b50\u3092\u5408\u308f\u305b\u305f\u6587\u5b57\u5217\u9577\norg_ext_len = len(org_ext) + 1\n\nfor dirname, dirnames, filenames in os.walk(org_dir):\n    for filename in filenames:\n        # \u5909\u63db\u5bfe\u8c61\u30d5\u30a1\u30a4\u30eb\u306e\u30d1\u30b9\n        org_path = org_dir + '/' + filename\n\n        # \u8fd4\u9084\u5f8c\u306e\u30d5\u30a1\u30a4\u30eb\u30d1\u30b9\n        if len(filename) > org_ext_len and \\\n            filename[-org_ext_len:] == '.' + org_ext:\n            filename = filename[0:-org_ext_len]\n        conv_path = conv_dir + '/' + filename + '.' + conv_ext\n\n        try:\n            # \u5909\u63db\u5b9f\u884c\n            Image.open(org_path).save(conv_path)\n        except IOError:\n            print('cannot convert :', org_path)\n```\n\nPython\u306e\u753b\u50cf\u51e6\u7406\u30e9\u30a4\u30d6\u30e9\u30ea\u3001PIL\u30e2\u30b8\u30e5\u30fc\u30eb\u304c\u30a4\u30f3\u30b9\u30c8\u30fc\u30eb\u3055\u308c\u3066\u3044\u306a\u3044\u65b9\u306f\u3001pillow\u3092\u30a4\u30f3\u30b9\u30c8\u30fc\u30eb\u3057\u3066\u304f\u3060\u3055\u3044\u3002\n\u4f8b\uff09\n\n> $ conda install pillow\n"}