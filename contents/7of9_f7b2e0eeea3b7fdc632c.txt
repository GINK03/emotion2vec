{"context": "\n\u52d5\u4f5c\u74b0\u5883\nGeForce GTX 1070 (8GB)\nASRock Z170M Pro4S [Intel Z170chipset]\nUbuntu 14.04 LTS desktop amd64\nTensorFlow v0.11\ncuDNN v5.1 for Linux\nCUDA v8.0\nPython 2.7.6\nIPython 5.1.0 -- An enhanced Interactive Python.\n\n\n\u95a2\u9023\u3000http://qiita.com/7of9/items/b364d897b95476a30754\nsine curve\u3092\u5b66\u7fd2\u3057\u305f\u6642\u306eweight\u3068bias\u3092\u3082\u3068\u306b\u81ea\u5206\u3067\u30cd\u30c3\u30c8\u30ef\u30fc\u30af\u3092\u518d\u73fe\u3057\u3066\u51fa\u529b\u3092\u8a08\u7b97\u3057\u3088\u3046\u3068\u3057\u3066\u3044\u308b\u3002\nnp.save()\u3092\u4f7f\u3046\u3053\u3068\u306b\u306a\u308b\u3060\u308d\u3046\u304b\u3002\nhttp://qiita.com/7of9/items/c730990479687ec2e959\n\ninput.csv\u751f\u6210\nhttp://qiita.com/7of9/items/b364d897b95476a30754#\u30c7\u30fc\u30bf\u751f\u6210\u90e8\n\n\u66f8\u51fa\u3057code\n\nlinreg2_reprod.py\n#!/usr/bin/env python\n# -*- coding: utf-8 -*-\n\nimport sys\nimport tensorflow as tf\nimport tensorflow.contrib.slim as slim\nimport numpy as np\n\n# \u30d5\u30a1\u30a4\u30eb\u540d\u306e Queue \u3092\u4f5c\u6210\nfilename_queue = tf.train.string_input_producer([\"input.csv\"])\n\n# CSV \u3092 parse\nreader = tf.TextLineReader()\nkey, value = reader.read(filename_queue)\ninput1, output = tf.decode_csv(value, record_defaults=[[0.], [0.]])\ninputs = tf.pack([input1])\noutput = tf.pack([output])\n\nbatch_size=4 # [4]\ninputs_batch, output_batch = tf.train.shuffle_batch([inputs, output], batch_size, capacity=40, min_after_dequeue=batch_size)\n\ninput_ph = tf.placeholder(\"float\", [None,1])\noutput_ph = tf.placeholder(\"float\",[None,1])\n\n## NN \u306e\u30b0\u30e9\u30d5\u751f\u6210\nhiddens = slim.stack(input_ph, slim.fully_connected, [1,7,7,7], \n  activation_fn=tf.nn.sigmoid, scope=\"hidden\")\nprediction = slim.fully_connected(hiddens, 1, activation_fn=tf.nn.sigmoid, scope=\"output\")\nloss = tf.contrib.losses.mean_squared_error(prediction, output_ph)\n\ntrain_op = slim.learning.create_train_op(loss, tf.train.AdamOptimizer(0.001))\n\ninit_op = tf.initialize_all_variables()\n\nwith tf.Session() as sess:\n  coord = tf.train.Coordinator()\n  threads = tf.train.start_queue_runners(sess=sess, coord=coord)\n\n  try:\n    sess.run(init_op)\n    for i in range(30000): #[10000]\n      inpbt, outbt = sess.run([inputs_batch, output_batch])\n      _, t_loss = sess.run([train_op, loss], feed_dict={input_ph:inpbt, output_ph: outbt})\n\n      if (i+1) % 100 == 0:\n        print(\"%d,%f\" % (i+1, t_loss))\n\n    # output to npy \n    model_variables = slim.get_model_variables()\n    res = sess.run(model_variables)\n    np.save('model_variables.npy', res)\n\n  finally:\n    coord.request_stop()\n\n  coord.join(threads)\n\n\n\u5b9f\u884c\u3059\u308b\u3068model_variables.npy\u3068\u3044\u3046\u30d5\u30a1\u30a4\u30eb\u304c\u751f\u6210\u3055\u308c\u305f\u3002\n\n\u8aad\u8fbc\u307fcode\n\nread_model_var.py\nimport numpy as np\n\nmodel_var = np.load('model_variables.npy')\nprint (model_var)\n\n\n\n\u5b9f\u884c\n$python read_model_var.py\n[array([[-5.22224426]], dtype=float32) array([ 1.78673065], dtype=float32)\n array([[-4.58573723, -4.27450418, -3.75889063,  4.51949883, -4.02780342,\n        -4.10122681,  4.0842309 ]], dtype=float32)\n array([ 0.97008353,  0.70625514,  0.27048966, -0.83405548,  0.57475132,\n        0.64893931, -0.45576799], dtype=float32)\n array([[ 1.84565568,  1.49943328,  1.65000439,  2.44512415,  2.09082389,\n         2.37278032,  1.65048397],\n       [ 1.4404825 ,  0.94583297,  1.89746273,  2.51769876,  1.5209198 ,\n         1.94879484,  1.19026875],\n       [ 1.49121964,  1.18247831,  1.51108956,  1.18311214,  0.88615912,\n         1.1377635 ,  1.33165669],\n       [-2.37849569,  0.55434752, -2.70425415, -2.46672988, -2.60600066,\n        -2.62578273, -2.78632236],\n       [ 0.82718104,  1.42030048,  1.06626236,  1.53540218,  1.55356538,\n         1.84659779,  1.25057125],\n       [ 1.30038536,  1.45610416,  1.77369738,  2.22379041,  2.24454832,\n         2.2828269 ,  1.8470453 ],\n       [-2.0469408 ,  1.2918936 , -1.87940514, -2.31857991, -2.2989893 ,\n        -2.25665474, -1.73469198]], dtype=float32)\n array([-1.1732285 ,  0.97712201, -1.06408942, -0.75335336, -0.74013597,\n       -0.65020418, -1.12149072], dtype=float32)\n array([[ 0.9464646 , -0.11631355, -0.16895044,  0.36979192,  1.05458641,\n         0.76118785, -0.4746716 ],\n       [-1.47142816, -0.67341083,  0.86623627, -1.63780856, -1.4503684 ,\n        -0.71064085,  1.02097607],\n       [ 1.58198178,  1.17400146, -1.40148842,  0.5268032 ,  1.45251906,\n         0.28084767, -0.8032999 ],\n       [ 1.61421323,  1.7214433 , -1.26047742,  1.9050349 ,  1.21235812,\n         1.24344146, -2.05446649],\n       [ 0.47106522,  1.23160982, -1.13437021,  1.25667596,  0.68895262,\n         1.86171079, -0.76870179],\n       [ 1.17536426,  1.74713993, -1.9202348 ,  1.397084  ,  1.61537564,\n         2.0741148 , -1.37128556],\n       [ 0.85221511,  0.6925481 , -0.62384129,  1.12779391,  0.73884082,\n         0.08157811, -1.01910996]], dtype=float32)\n array([-1.03282344, -1.26972938,  1.24813604, -1.1338433 , -1.21751046,\n       -0.94728774,  1.32416117], dtype=float32)\n array([[-2.49866319],\n       [-1.76430416],\n       [ 1.60942447],\n       [-2.18569684],\n       [-2.33169866],\n       [-1.27172542],\n       [ 2.39537191]], dtype=float32)\n array([-0.45804733], dtype=float32)]\n\n\n\u8aad\u3081\u3066\u3044\u305d\u3046\u3060\u3002\n\u3053\u308c\u3067\u5b66\u7fd2\u3092\u7e70\u308a\u8fd4\u3055\u305a\u306b\u3001\u5b66\u7fd2\u7d50\u679c\u3092\u4f7f\u3063\u305f\u51e6\u7406\u3092\u7e70\u308a\u8fd4\u3057\u8a66\u3059\u3053\u3068\u304c\u3067\u304d\u308b\u3002\n```txt:\u52d5\u4f5c\u74b0\u5883\nGeForce GTX 1070 (8GB)\nASRock Z170M Pro4S [Intel Z170chipset]\nUbuntu 14.04 LTS desktop amd64\nTensorFlow v0.11\ncuDNN v5.1 for Linux\nCUDA v8.0\nPython 2.7.6\nIPython 5.1.0 -- An enhanced Interactive Python.\n```\n\n\u95a2\u9023\u3000http://qiita.com/7of9/items/b364d897b95476a30754\n\nsine curve\u3092\u5b66\u7fd2\u3057\u305f\u6642\u306eweight\u3068bias\u3092\u3082\u3068\u306b\u81ea\u5206\u3067\u30cd\u30c3\u30c8\u30ef\u30fc\u30af\u3092\u518d\u73fe\u3057\u3066\u51fa\u529b\u3092\u8a08\u7b97\u3057\u3088\u3046\u3068\u3057\u3066\u3044\u308b\u3002\n\n\nnp.save()\u3092\u4f7f\u3046\u3053\u3068\u306b\u306a\u308b\u3060\u308d\u3046\u304b\u3002\nhttp://qiita.com/7of9/items/c730990479687ec2e959\n\n### input.csv\u751f\u6210\n\nhttp://qiita.com/7of9/items/b364d897b95476a30754#\u30c7\u30fc\u30bf\u751f\u6210\u90e8\n\n### \u66f8\u51fa\u3057code\n\n```linreg2_reprod.py\n#!/usr/bin/env python\n# -*- coding: utf-8 -*-\n\nimport sys\nimport tensorflow as tf\nimport tensorflow.contrib.slim as slim\nimport numpy as np\n\n# \u30d5\u30a1\u30a4\u30eb\u540d\u306e Queue \u3092\u4f5c\u6210\nfilename_queue = tf.train.string_input_producer([\"input.csv\"])\n\n# CSV \u3092 parse\nreader = tf.TextLineReader()\nkey, value = reader.read(filename_queue)\ninput1, output = tf.decode_csv(value, record_defaults=[[0.], [0.]])\ninputs = tf.pack([input1])\noutput = tf.pack([output])\n\nbatch_size=4 # [4]\ninputs_batch, output_batch = tf.train.shuffle_batch([inputs, output], batch_size, capacity=40, min_after_dequeue=batch_size)\n\ninput_ph = tf.placeholder(\"float\", [None,1])\noutput_ph = tf.placeholder(\"float\",[None,1])\n\n## NN \u306e\u30b0\u30e9\u30d5\u751f\u6210\nhiddens = slim.stack(input_ph, slim.fully_connected, [1,7,7,7], \n  activation_fn=tf.nn.sigmoid, scope=\"hidden\")\nprediction = slim.fully_connected(hiddens, 1, activation_fn=tf.nn.sigmoid, scope=\"output\")\nloss = tf.contrib.losses.mean_squared_error(prediction, output_ph)\n\ntrain_op = slim.learning.create_train_op(loss, tf.train.AdamOptimizer(0.001))\n\ninit_op = tf.initialize_all_variables()\n\nwith tf.Session() as sess:\n  coord = tf.train.Coordinator()\n  threads = tf.train.start_queue_runners(sess=sess, coord=coord)\n\n  try:\n    sess.run(init_op)\n    for i in range(30000): #[10000]\n      inpbt, outbt = sess.run([inputs_batch, output_batch])\n      _, t_loss = sess.run([train_op, loss], feed_dict={input_ph:inpbt, output_ph: outbt})\n\n      if (i+1) % 100 == 0:\n        print(\"%d,%f\" % (i+1, t_loss))\n\n    # output to npy \n    model_variables = slim.get_model_variables()\n    res = sess.run(model_variables)\n    np.save('model_variables.npy', res)\n\n  finally:\n    coord.request_stop()\n\n  coord.join(threads)\n```\n\n\u5b9f\u884c\u3059\u308b\u3068model_variables.npy\u3068\u3044\u3046\u30d5\u30a1\u30a4\u30eb\u304c\u751f\u6210\u3055\u308c\u305f\u3002\n\n### \u8aad\u8fbc\u307fcode\n\n```read_model_var.py\nimport numpy as np\n\nmodel_var = np.load('model_variables.npy')\nprint (model_var)\n```\n\n```txt:\u5b9f\u884c\n$python read_model_var.py\n[array([[-5.22224426]], dtype=float32) array([ 1.78673065], dtype=float32)\n array([[-4.58573723, -4.27450418, -3.75889063,  4.51949883, -4.02780342,\n        -4.10122681,  4.0842309 ]], dtype=float32)\n array([ 0.97008353,  0.70625514,  0.27048966, -0.83405548,  0.57475132,\n        0.64893931, -0.45576799], dtype=float32)\n array([[ 1.84565568,  1.49943328,  1.65000439,  2.44512415,  2.09082389,\n         2.37278032,  1.65048397],\n       [ 1.4404825 ,  0.94583297,  1.89746273,  2.51769876,  1.5209198 ,\n         1.94879484,  1.19026875],\n       [ 1.49121964,  1.18247831,  1.51108956,  1.18311214,  0.88615912,\n         1.1377635 ,  1.33165669],\n       [-2.37849569,  0.55434752, -2.70425415, -2.46672988, -2.60600066,\n        -2.62578273, -2.78632236],\n       [ 0.82718104,  1.42030048,  1.06626236,  1.53540218,  1.55356538,\n         1.84659779,  1.25057125],\n       [ 1.30038536,  1.45610416,  1.77369738,  2.22379041,  2.24454832,\n         2.2828269 ,  1.8470453 ],\n       [-2.0469408 ,  1.2918936 , -1.87940514, -2.31857991, -2.2989893 ,\n        -2.25665474, -1.73469198]], dtype=float32)\n array([-1.1732285 ,  0.97712201, -1.06408942, -0.75335336, -0.74013597,\n       -0.65020418, -1.12149072], dtype=float32)\n array([[ 0.9464646 , -0.11631355, -0.16895044,  0.36979192,  1.05458641,\n         0.76118785, -0.4746716 ],\n       [-1.47142816, -0.67341083,  0.86623627, -1.63780856, -1.4503684 ,\n        -0.71064085,  1.02097607],\n       [ 1.58198178,  1.17400146, -1.40148842,  0.5268032 ,  1.45251906,\n         0.28084767, -0.8032999 ],\n       [ 1.61421323,  1.7214433 , -1.26047742,  1.9050349 ,  1.21235812,\n         1.24344146, -2.05446649],\n       [ 0.47106522,  1.23160982, -1.13437021,  1.25667596,  0.68895262,\n         1.86171079, -0.76870179],\n       [ 1.17536426,  1.74713993, -1.9202348 ,  1.397084  ,  1.61537564,\n         2.0741148 , -1.37128556],\n       [ 0.85221511,  0.6925481 , -0.62384129,  1.12779391,  0.73884082,\n         0.08157811, -1.01910996]], dtype=float32)\n array([-1.03282344, -1.26972938,  1.24813604, -1.1338433 , -1.21751046,\n       -0.94728774,  1.32416117], dtype=float32)\n array([[-2.49866319],\n       [-1.76430416],\n       [ 1.60942447],\n       [-2.18569684],\n       [-2.33169866],\n       [-1.27172542],\n       [ 2.39537191]], dtype=float32)\n array([-0.45804733], dtype=float32)]\n```\n\n\u8aad\u3081\u3066\u3044\u305d\u3046\u3060\u3002\n\n\u3053\u308c\u3067\u5b66\u7fd2\u3092\u7e70\u308a\u8fd4\u3055\u305a\u306b\u3001\u5b66\u7fd2\u7d50\u679c\u3092\u4f7f\u3063\u305f\u51e6\u7406\u3092\u7e70\u308a\u8fd4\u3057\u8a66\u3059\u3053\u3068\u304c\u3067\u304d\u308b\u3002\n\n", "tags": ["borgWarp"]}