{"context": " More than 1 year has passed since last update.\n\ngoogle compute engine\u306bspark\u3092\u30a4\u30f3\u30b9\u30c8\u30fc\u30eb\u3059\u308b\n\ngce\u306b\u30af\u30a4\u30c3\u30af\u30c7\u30d7\u30ed\u30a4\u3067\u306f\u306a\u304f\u3001\u65b0\u3057\u3044\u30a4\u30f3\u30b9\u30bf\u30f3\u30b9\u3092\u4f5c\u6210\u3057\u3066spark\u3092\u30a4\u30f3\u30b9\u30c8\u30fc\u30eb\u3059\u308b\u3002\n\n\u524d\u63d0\n\n\u30ed\u30fc\u30ab\u30eb\u74b0\u5883\u306fubuntu\ngcloud\u306f\u30bb\u30c3\u30c8\u30a2\u30c3\u30d7\u6e08\u307f\n\n\n\u624b\u9806\uff08\u30a4\u30f3\u30b9\u30bf\u30f3\u30b9\u4f5c\u6210\uff09\n\uff11\uff0eVM\u30a4\u30f3\u30b9\u30bf\u30f3\u30b9\u306e\u753b\u9762\u3067[\u65b0\u3057\u3044\u30a4\u30f3\u30b9\u30bf\u30f3\u30b9]\u30dc\u30bf\u30f3\u3092\u62bc\u3059\n\n\uff12\uff0e\u30de\u30b7\u30f3\u30bf\u30a4\u30d7\u7b49\u3092\u9069\u5f53\u306b\u9078\u629e\u3001\u30d6\u30fc\u30c8\u30c7\u30a3\u30b9\u30af\u306f\u3082\u3061\u308d\u3093ubuntu\u306b\u3002\u30d0\u30fc\u30b8\u30e7\u30f3\u306f\u304a\u597d\u307f\u3067\u3002\n\n\uff13\uff0e\u4f5c\u6210\u3057\u305f\u30a4\u30f3\u30b9\u30bf\u30f3\u30b9\u306egcloud\u3067\u63a5\u7d9a\u3092\u9078\u629e\n\n\uff14\uff0e\u51fa\u3066\u304d\u305f\u30b3\u30de\u30f3\u30c9\u30e9\u30a4\u30f3\u3092\u30ed\u30fc\u30ab\u30eb\u306eubuntu\u306eterm\u306b\u8cbc\u308a\u4ed8\u3051\u308b\n\n\u3053\u308c\u3067\u30ed\u30fc\u30ab\u30eb\u304b\u3089\u65b0\u3057\u304f\u4f5c\u3063\u305fgce\u306eubuntu\u30a4\u30f3\u30b9\u30bf\u30f3\u30b9\u306b\u63a5\u7d9a\u3067\u304d\u308b\u3002\n\u4ee5\u964d\u306e\u624b\u9806\u7b49\u306fgcloud\u3067\u63a5\u7d9a\u3057\u305fVM\u5074\u3067\u5b9f\u884c\u3059\u308b\u3002\n\n\u624b\u9806\uff08\u30a4\u30f3\u30b9\u30c8\u30fc\u30eb\uff09\n\uff11\uff0eJava8\u3092\u30a4\u30f3\u30b9\u30c8\u30fc\u30eb\n\u7d20\u306eubuntu VM\u306fJava\u304c\u5165\u3063\u3066\u306a\u304b\u3063\u305f\u306e\u3067\u30a4\u30f3\u30b9\u30c8\u30fc\u30eb\u3057\u307e\u3059\u3002\n$ sudo add-apt-repository ppa:webupd8team/java\n$ sudo apt-get update\n$ sudo apt-get install oracle-java8-installer\n\n\u9014\u4e2d\u3067[ENTER]\u3068\u304b[Y]\u3068\u304b[OK]\u3068\u304b[yes]\u3068\u304b\u9078\u3093\u3067\u30a4\u30f3\u30b9\u30c8\u30fc\u30eb\u3059\u308b\u3002\n\u30a4\u30f3\u30b9\u30c8\u30fc\u30eb\u304c\u7d42\u308f\u3063\u305f\u3089\u3068\u308a\u3042\u3048\u305a\u78ba\u8a8d\u3057\u3066\u307f\u308b\u3002\njunk@instance-2:~$ java -version\njava version \"1.8.0_45\"\nJava(TM) SE Runtime Environment (build 1.8.0_45-b14)\nJava HotSpot(TM) 64-Bit Server VM (build 25.45-b02, mixed mode)\njunk@instance-2:~$ \n\nOK\u3063\u307d\u3044\u3002\n\uff12\uff0escala\u3092\u30c0\u30a6\u30f3\u30ed\u30fc\u30c9\n$ cd ~\n$ mkdir dl\n$ cd dl\n$ wget http://www.scala-lang.org/files/archive/scala-2.11.7.tgz\n\n--2015-07-06 16:04:20--  http://www.scala-lang.org/files/archive/scala-2.11.7.tgz\nResolving www.scala-lang.org (www.scala-lang.org)... 128.178.154.159\nConnecting to www.scala-lang.org (www.scala-lang.org)|128.178.154.159|:80... connected.\nHTTP request sent, awaiting response... 200 OK\nLength: 28460530 (27M) [application/x-gzip]\nSaving to: \u2018scala-2.11.7.tgz\u2019\n\nscala-2.11.7.tgz                100%[======================================================>]  27.14M  5.57MB/s   in 8.3s   \n\n2015-07-06 16:04:29 (3.27 MB/s) - \u2018scala-2.11.7.tgz\u2019 saved [28460530/28460530]\n\n\uff13\uff0e\u89e3\u51cd\u3059\u308b\n\ntar -xzvf scala-2.11.7.tgz\n\n\uff14\uff0e\u89e3\u51cd\u3057\u305fscala\u3092\u30b3\u30d4\u30fc\u3057\u3066\u30ea\u30f3\u30af\u3082\u4f5c\u3063\u3066\u3042\u3052\u308b\u3002\n$ cd /usr/local/\n$ sudo cp -r ~/dl/scala-2.11.7 .\n$ sudo ln -sv scala-2.11.7/ scala\n\u2018scala\u2019 -> \u2018scala-2.11.7/\u2019\n\n\uff15\uff0espark\u3092\u30c0\u30a6\u30f3\u30ed\u30fc\u30c9\n$ cd ~/dl\n$ wget http://archive.apache.org/dist/spark/spark-1.4.0/spark-1.4.0-bin-hadoop2.6.tgz\n\n--2015-07-06 16:11:16--  http://archive.apache.org/dist/spark/spark-1.4.0/spark-1.4.0-bin-hadoop2.6.tgz\nResolving archive.apache.org (archive.apache.org)... 192.87.106.229, 140.211.11.131, 2001:610:1:80bc:192:87:106:229\nConnecting to archive.apache.org (archive.apache.org)|192.87.106.229|:80... connected.\nHTTP request sent, awaiting response... 200 OK\nLength: 250194134 (239M) [application/x-tar]\nSaving to: \u2018spark-1.4.0-bin-hadoop2.6.tgz\u2019\n\nspark-1.4.0-bin-hadoop2.6.tgz   100%[======================================================>] 238.60M  6.62MB/s   in 45s    \n\n2015-07-06 16:12:02 (5.32 MB/s) - \u2018spark-1.4.0-bin-hadoop2.6.tgz\u2019 saved [250194134/250194134]\n\n\n\uff16\uff0e\u89e3\u51cd\u3059\u308b\n\n$ tar -xzvf spark-1.4.0-bin-hadoop2.6.tgz \n\n\uff17\uff0e\u89e3\u51cd\u3057\u305fspark\u3092\u30b3\u30d4\u30fc\u3057\u3066\u30ea\u30f3\u30af\u3082\uff08\uff52\uff59\n$ cd /usr/local/\n$ sudo cp -r ~/dl/spark-1.4.0-bin-hadoop2.6 .\n$ sudo ln -sv spark-1.4.0-bin-hadoop2.6/ spark\n\u2018spark\u2019 -> \u2018spark-1.4.0-bin-hadoop2.6/\u2019\n\n\uff18\uff0e\u30d1\u30b9\u3092\u8a2d\u5b9a\u3059\u308b\n$ vi ~/.bashrc  \n\n.bashrc\u306e\u6700\u5f8c\u306b\u4ee5\u4e0b\u3092\u8ffd\u52a0\nexport SCALA_HOME=/usr/local/scala\nexport SPARK_HOME=/usr/local/spark\nexport PATH=$SCALA_HOME/bin:$PATH\n\n\u8aad\u307f\u8fbc\u307f\u76f4\u3057\n$ source ~/.bashrc\n\n\uff19\uff0e\u8d77\u52d5\n$ cd $SPARK_HOME\n$ ./bin/spark-shell\n\nlog4j:WARN No appenders could be found for logger (org.apache.hadoop.metrics2.lib.MutableMetricsFactory).\nlog4j:WARN Please initialize the log4j system properly.\nlog4j:WARN See http://logging.apache.org/log4j/1.2/faq.html#noconfig for more info.\nUsing Spark's default log4j profile: org/apache/spark/log4j-defaults.properties\n15/07/06 16:24:33 INFO SecurityManager: Changing view acls to: junk\n15/07/06 16:24:33 INFO SecurityManager: Changing modify acls to: junk\n15/07/06 16:24:33 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users with view permissions: Set(junk); users with modify permissions: Set(junk)\n15/07/06 16:24:33 INFO HttpServer: Starting HTTP Server\n15/07/06 16:24:33 INFO Utils: Successfully started service 'HTTP class server' on port 45846.\nWelcome to\n      ____              __\n     / __/__  ___ _____/ /__\n    _\\ \\/ _ \\/ _ `/ __/  '_/\n   /___/ .__/\\_,_/_/ /_/\\_\\   version 1.4.0\n      /_/\n\nUsing Scala version 2.10.4 (Java HotSpot(TM) 64-Bit Server VM, Java 1.8.0_45)\nType in expressions to have them evaluated.\nType :help for more information.\n15/07/06 16:24:38 INFO SparkContext: Running Spark version 1.4.0\n15/07/06 16:24:38 INFO SecurityManager: Changing view acls to: junk\n15/07/06 16:24:38 INFO SecurityManager: Changing modify acls to: junk\n15/07/06 16:24:38 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users with view permissions: Set(junk); users with modify permissions: Set(junk)\n15/07/06 16:24:39 INFO Slf4jLogger: Slf4jLogger started\n15/07/06 16:24:39 INFO Remoting: Starting remoting\nMon Jul 06 16:24:42 UTC 2015 Thread[main,5,main] java.io.FileNotFoundException: derby.log (Permission denied)\n15/07/06 16:24:43 WARN Connection: BoneCP specified but not present in CLASSPATH (or one of dependencies)\n----------------------------------------------------------------\nLoaded from file:/usr/local/spark-1.4.0-bin-hadoop2.6/lib/spark-assembly-1.4.0-hadoop2.6.0.jar\njava.vendor=Oracle Corporation\njava.runtime.version=1.8.0_45-b14\nuser.dir=/usr/local/spark-1.4.0-bin-hadoop2.6\nos.name=Linux\nos.arch=amd64\nos.version=3.19.0-21-generic\nderby.system.home=null\nDatabase Class Loader started - derby.database.classpath=''\n15/07/06 16:24:45 INFO ObjectStore: Setting MetaStore object pin classes with hive.metastore.cache.pinobjtypes=\"Table,StorageDescriptor,SerDeInfo,Partition,Database,Type,FieldSchema,Order\"\n15/07/06 16:24:45 INFO MetaStoreDirectSql: MySQL check failed, assuming we are not on mysql: Lexical error at line 1, column 5.  Encountered: \"@\" (64), after : \"\".\n15/07/06 16:24:46 INFO Datastore: The class \"org.apache.hadoop.hive.metastore.model.MFieldSchema\" is tagged as \"embedded-only\" so does not have its own datastore table.\n15/07/06 16:24:46 INFO Datastore: The class \"org.apache.hadoop.hive.metastore.model.MOrder\" is tagged as \"embedded-only\" so does not have its own datastore table.\n15/07/06 16:24:47 INFO Datastore: The class \"org.apache.hadoop.hive.metastore.model.MFieldSchema\" is tagged as \"embedded-only\" so does not have its own datastore table.\n15/07/06 16:24:47 INFO Datastore: The class \"org.apache.hadoop.hive.metastore.model.MOrder\" is tagged as \"embedded-only\" so does not have its own datastore table.\n15/07/06 16:24:47 INFO ObjectStore: Initialized ObjectStore\n15/07/06 16:24:48 WARN ObjectStore: Version information not found in metastore. hive.metastore.schema.verification is not enabled so recording the schema version 0.13.1aa\n15/07/06 16:24:48 INFO HiveMetaStore: Added admin role in metastore\n15/07/06 16:24:48 INFO HiveMetaStore: Added public role in metastore\n15/07/06 16:24:48 INFO HiveMetaStore: No user is added in admin role, since config is empty\n15/07/06 16:24:48 INFO SessionState: No Tez session required at this point. hive.execution.engine=mr.\n15/07/06 16:24:48 INFO SparkILoop: Created sql context (with Hive support)..\nSQL context available as sqlContext.\n\nscala> \n\n\u6700\u5f8c\u306e\u30ed\u30b0\u306f\u9577\u3044\u306e\u3067\u9014\u4e2d\u7565\u3057\u307e\u3057\u305f\n\u3053\u3053\u307e\u306710\u5206\u304f\u3089\u3044\u3067\u51fa\u6765\u308b\u3063\u307d\u3044\u3067\u3059\u3002\n# ***google compute engine\u306bspark\u3092\u30a4\u30f3\u30b9\u30c8\u30fc\u30eb\u3059\u308b***\ngce\u306b\u30af\u30a4\u30c3\u30af\u30c7\u30d7\u30ed\u30a4\u3067\u306f\u306a\u304f\u3001\u65b0\u3057\u3044\u30a4\u30f3\u30b9\u30bf\u30f3\u30b9\u3092\u4f5c\u6210\u3057\u3066spark\u3092\u30a4\u30f3\u30b9\u30c8\u30fc\u30eb\u3059\u308b\u3002\n## \u524d\u63d0 \n+ \u30ed\u30fc\u30ab\u30eb\u74b0\u5883\u306fubuntu\n+ gcloud\u306f\u30bb\u30c3\u30c8\u30a2\u30c3\u30d7\u6e08\u307f\n\n## \u624b\u9806\uff08\u30a4\u30f3\u30b9\u30bf\u30f3\u30b9\u4f5c\u6210\uff09\n\uff11\uff0eVM\u30a4\u30f3\u30b9\u30bf\u30f3\u30b9\u306e\u753b\u9762\u3067[\u65b0\u3057\u3044\u30a4\u30f3\u30b9\u30bf\u30f3\u30b9]\u30dc\u30bf\u30f3\u3092\u62bc\u3059\n![image](https://qiita-image-store.s3.amazonaws.com/0/84915/ef86b8f2-d814-b0ab-09c5-9d15a08b0634.png)\n\n\uff12\uff0e\u30de\u30b7\u30f3\u30bf\u30a4\u30d7\u7b49\u3092\u9069\u5f53\u306b\u9078\u629e\u3001\u30d6\u30fc\u30c8\u30c7\u30a3\u30b9\u30af\u306f\u3082\u3061\u308d\u3093ubuntu\u306b\u3002\u30d0\u30fc\u30b8\u30e7\u30f3\u306f\u304a\u597d\u307f\u3067\u3002\n![image](https://qiita-image-store.s3.amazonaws.com/0/84915/48b69efc-42be-9d49-fa4e-dd9a2ed012d7.png)\n\n\uff13\uff0e\u4f5c\u6210\u3057\u305f\u30a4\u30f3\u30b9\u30bf\u30f3\u30b9\u306egcloud\u3067\u63a5\u7d9a\u3092\u9078\u629e\n![image](https://qiita-image-store.s3.amazonaws.com/0/84915/d718dff9-d4e8-abcd-2f1d-6b3825c1f74f.png)\n\n\uff14\uff0e\u51fa\u3066\u304d\u305f\u30b3\u30de\u30f3\u30c9\u30e9\u30a4\u30f3\u3092\u30ed\u30fc\u30ab\u30eb\u306eubuntu\u306eterm\u306b\u8cbc\u308a\u4ed8\u3051\u308b\n![image](https://qiita-image-store.s3.amazonaws.com/0/84915/6fc63aab-2529-2b3d-b6a0-e1d6f353a2aa.png)\n\n\u3053\u308c\u3067\u30ed\u30fc\u30ab\u30eb\u304b\u3089\u65b0\u3057\u304f\u4f5c\u3063\u305fgce\u306eubuntu\u30a4\u30f3\u30b9\u30bf\u30f3\u30b9\u306b\u63a5\u7d9a\u3067\u304d\u308b\u3002\n\u4ee5\u964d\u306e\u624b\u9806\u7b49\u306fgcloud\u3067\u63a5\u7d9a\u3057\u305fVM\u5074\u3067\u5b9f\u884c\u3059\u308b\u3002\n\n## \u624b\u9806\uff08\u30a4\u30f3\u30b9\u30c8\u30fc\u30eb\uff09\n\n\uff11\uff0eJava8\u3092\u30a4\u30f3\u30b9\u30c8\u30fc\u30eb\n\u7d20\u306eubuntu VM\u306fJava\u304c\u5165\u3063\u3066\u306a\u304b\u3063\u305f\u306e\u3067\u30a4\u30f3\u30b9\u30c8\u30fc\u30eb\u3057\u307e\u3059\u3002\n\n```\n$ sudo add-apt-repository ppa:webupd8team/java\n$ sudo apt-get update\n$ sudo apt-get install oracle-java8-installer\n```\n\n\u9014\u4e2d\u3067[ENTER]\u3068\u304b[Y]\u3068\u304b[OK]\u3068\u304b[yes]\u3068\u304b\u9078\u3093\u3067\u30a4\u30f3\u30b9\u30c8\u30fc\u30eb\u3059\u308b\u3002\n\u30a4\u30f3\u30b9\u30c8\u30fc\u30eb\u304c\u7d42\u308f\u3063\u305f\u3089\u3068\u308a\u3042\u3048\u305a\u78ba\u8a8d\u3057\u3066\u307f\u308b\u3002\n\n```\njunk@instance-2:~$ java -version\njava version \"1.8.0_45\"\nJava(TM) SE Runtime Environment (build 1.8.0_45-b14)\nJava HotSpot(TM) 64-Bit Server VM (build 25.45-b02, mixed mode)\njunk@instance-2:~$ \n```\n\nOK\u3063\u307d\u3044\u3002\n\n\uff12\uff0escala\u3092\u30c0\u30a6\u30f3\u30ed\u30fc\u30c9\n\n```\n$ cd ~\n$ mkdir dl\n$ cd dl\n$ wget http://www.scala-lang.org/files/archive/scala-2.11.7.tgz\n```\n\n\n```\n--2015-07-06 16:04:20--  http://www.scala-lang.org/files/archive/scala-2.11.7.tgz\nResolving www.scala-lang.org (www.scala-lang.org)... 128.178.154.159\nConnecting to www.scala-lang.org (www.scala-lang.org)|128.178.154.159|:80... connected.\nHTTP request sent, awaiting response... 200 OK\nLength: 28460530 (27M) [application/x-gzip]\nSaving to: \u2018scala-2.11.7.tgz\u2019\n\nscala-2.11.7.tgz                100%[======================================================>]  27.14M  5.57MB/s   in 8.3s   \n\n2015-07-06 16:04:29 (3.27 MB/s) - \u2018scala-2.11.7.tgz\u2019 saved [28460530/28460530]\n```\n\n\uff13\uff0e\u89e3\u51cd\u3059\u308b\n```\ntar -xzvf scala-2.11.7.tgz\n```\n\n\uff14\uff0e\u89e3\u51cd\u3057\u305fscala\u3092\u30b3\u30d4\u30fc\u3057\u3066\u30ea\u30f3\u30af\u3082\u4f5c\u3063\u3066\u3042\u3052\u308b\u3002\n\n```\n$ cd /usr/local/\n$ sudo cp -r ~/dl/scala-2.11.7 .\n$ sudo ln -sv scala-2.11.7/ scala\n\u2018scala\u2019 -> \u2018scala-2.11.7/\u2019\n```\n\n\uff15\uff0espark\u3092\u30c0\u30a6\u30f3\u30ed\u30fc\u30c9\n\n```\n$ cd ~/dl\n$ wget http://archive.apache.org/dist/spark/spark-1.4.0/spark-1.4.0-bin-hadoop2.6.tgz\n```\n\n```\n--2015-07-06 16:11:16--  http://archive.apache.org/dist/spark/spark-1.4.0/spark-1.4.0-bin-hadoop2.6.tgz\nResolving archive.apache.org (archive.apache.org)... 192.87.106.229, 140.211.11.131, 2001:610:1:80bc:192:87:106:229\nConnecting to archive.apache.org (archive.apache.org)|192.87.106.229|:80... connected.\nHTTP request sent, awaiting response... 200 OK\nLength: 250194134 (239M) [application/x-tar]\nSaving to: \u2018spark-1.4.0-bin-hadoop2.6.tgz\u2019\n\nspark-1.4.0-bin-hadoop2.6.tgz   100%[======================================================>] 238.60M  6.62MB/s   in 45s    \n\n2015-07-06 16:12:02 (5.32 MB/s) - \u2018spark-1.4.0-bin-hadoop2.6.tgz\u2019 saved [250194134/250194134]\n\n```\n\n\uff16\uff0e\u89e3\u51cd\u3059\u308b\n```\n$ tar -xzvf spark-1.4.0-bin-hadoop2.6.tgz \n```\n\n\uff17\uff0e\u89e3\u51cd\u3057\u305fspark\u3092\u30b3\u30d4\u30fc\u3057\u3066\u30ea\u30f3\u30af\u3082\uff08\uff52\uff59\n\n```\n$ cd /usr/local/\n$ sudo cp -r ~/dl/spark-1.4.0-bin-hadoop2.6 .\n$ sudo ln -sv spark-1.4.0-bin-hadoop2.6/ spark\n\u2018spark\u2019 -> \u2018spark-1.4.0-bin-hadoop2.6/\u2019\n```\n\n\uff18\uff0e\u30d1\u30b9\u3092\u8a2d\u5b9a\u3059\u308b\n\n```\n$ vi ~/.bashrc  \n```\n\n .bashrc\u306e\u6700\u5f8c\u306b\u4ee5\u4e0b\u3092\u8ffd\u52a0\n\n```\nexport SCALA_HOME=/usr/local/scala\nexport SPARK_HOME=/usr/local/spark\nexport PATH=$SCALA_HOME/bin:$PATH\n```\n\n\u8aad\u307f\u8fbc\u307f\u76f4\u3057\n\n```\n$ source ~/.bashrc\n```\n\n\uff19\uff0e\u8d77\u52d5\n\n```\n$ cd $SPARK_HOME\n$ ./bin/spark-shell\n```\n\n```\nlog4j:WARN No appenders could be found for logger (org.apache.hadoop.metrics2.lib.MutableMetricsFactory).\nlog4j:WARN Please initialize the log4j system properly.\nlog4j:WARN See http://logging.apache.org/log4j/1.2/faq.html#noconfig for more info.\nUsing Spark's default log4j profile: org/apache/spark/log4j-defaults.properties\n15/07/06 16:24:33 INFO SecurityManager: Changing view acls to: junk\n15/07/06 16:24:33 INFO SecurityManager: Changing modify acls to: junk\n15/07/06 16:24:33 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users with view permissions: Set(junk); users with modify permissions: Set(junk)\n15/07/06 16:24:33 INFO HttpServer: Starting HTTP Server\n15/07/06 16:24:33 INFO Utils: Successfully started service 'HTTP class server' on port 45846.\nWelcome to\n      ____              __\n     / __/__  ___ _____/ /__\n    _\\ \\/ _ \\/ _ `/ __/  '_/\n   /___/ .__/\\_,_/_/ /_/\\_\\   version 1.4.0\n      /_/\n\nUsing Scala version 2.10.4 (Java HotSpot(TM) 64-Bit Server VM, Java 1.8.0_45)\nType in expressions to have them evaluated.\nType :help for more information.\n15/07/06 16:24:38 INFO SparkContext: Running Spark version 1.4.0\n15/07/06 16:24:38 INFO SecurityManager: Changing view acls to: junk\n15/07/06 16:24:38 INFO SecurityManager: Changing modify acls to: junk\n15/07/06 16:24:38 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users with view permissions: Set(junk); users with modify permissions: Set(junk)\n15/07/06 16:24:39 INFO Slf4jLogger: Slf4jLogger started\n15/07/06 16:24:39 INFO Remoting: Starting remoting\nMon Jul 06 16:24:42 UTC 2015 Thread[main,5,main] java.io.FileNotFoundException: derby.log (Permission denied)\n15/07/06 16:24:43 WARN Connection: BoneCP specified but not present in CLASSPATH (or one of dependencies)\n----------------------------------------------------------------\nLoaded from file:/usr/local/spark-1.4.0-bin-hadoop2.6/lib/spark-assembly-1.4.0-hadoop2.6.0.jar\njava.vendor=Oracle Corporation\njava.runtime.version=1.8.0_45-b14\nuser.dir=/usr/local/spark-1.4.0-bin-hadoop2.6\nos.name=Linux\nos.arch=amd64\nos.version=3.19.0-21-generic\nderby.system.home=null\nDatabase Class Loader started - derby.database.classpath=''\n15/07/06 16:24:45 INFO ObjectStore: Setting MetaStore object pin classes with hive.metastore.cache.pinobjtypes=\"Table,StorageDescriptor,SerDeInfo,Partition,Database,Type,FieldSchema,Order\"\n15/07/06 16:24:45 INFO MetaStoreDirectSql: MySQL check failed, assuming we are not on mysql: Lexical error at line 1, column 5.  Encountered: \"@\" (64), after : \"\".\n15/07/06 16:24:46 INFO Datastore: The class \"org.apache.hadoop.hive.metastore.model.MFieldSchema\" is tagged as \"embedded-only\" so does not have its own datastore table.\n15/07/06 16:24:46 INFO Datastore: The class \"org.apache.hadoop.hive.metastore.model.MOrder\" is tagged as \"embedded-only\" so does not have its own datastore table.\n15/07/06 16:24:47 INFO Datastore: The class \"org.apache.hadoop.hive.metastore.model.MFieldSchema\" is tagged as \"embedded-only\" so does not have its own datastore table.\n15/07/06 16:24:47 INFO Datastore: The class \"org.apache.hadoop.hive.metastore.model.MOrder\" is tagged as \"embedded-only\" so does not have its own datastore table.\n15/07/06 16:24:47 INFO ObjectStore: Initialized ObjectStore\n15/07/06 16:24:48 WARN ObjectStore: Version information not found in metastore. hive.metastore.schema.verification is not enabled so recording the schema version 0.13.1aa\n15/07/06 16:24:48 INFO HiveMetaStore: Added admin role in metastore\n15/07/06 16:24:48 INFO HiveMetaStore: Added public role in metastore\n15/07/06 16:24:48 INFO HiveMetaStore: No user is added in admin role, since config is empty\n15/07/06 16:24:48 INFO SessionState: No Tez session required at this point. hive.execution.engine=mr.\n15/07/06 16:24:48 INFO SparkILoop: Created sql context (with Hive support)..\nSQL context available as sqlContext.\n\nscala> \n```\n***\u6700\u5f8c\u306e\u30ed\u30b0\u306f\u9577\u3044\u306e\u3067\u9014\u4e2d\u7565\u3057\u307e\u3057\u305f***\n\n\u3053\u3053\u307e\u306710\u5206\u304f\u3089\u3044\u3067\u51fa\u6765\u308b\u3063\u307d\u3044\u3067\u3059\u3002\n", "tags": ["gce", "Spark", "Ubuntu15.04"]}