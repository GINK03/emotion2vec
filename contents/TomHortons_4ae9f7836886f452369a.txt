{"tags": ["\u753b\u50cf\u51e6\u7406", "OpenCV", "\u30af\u30e9\u30b9\u30bf\u30ea\u30f3\u30b0", "Python", "DBSCAN"], "context": "\n\n\u306f\u3058\u3081\u306b\n\u672c\u8a18\u4e8b\u306fKaggle\uff1aThe Nature Conservancy Fisheries Monitoring\u306e\u30b5\u30f3\u30d7\u30eb\u30b3\u30fc\u30c9\u306e\u4e00\u90e8\u3067\u3059\uff0e\n\u3053\u3053\u3067\u306f\u3042\u3048\u3066CNN\u306b\u95a2\u3059\u308b\u30d7\u30ed\u30b0\u30e9\u30e0\u306f\u8f09\u305b\u3066\u3044\u307e\u305b\u3093\uff0e\n\u8a73\u7d30\u306f\u5f8c\u65e5\u307e\u3068\u3081\u307e\u3059\uff0e\n\u3053\u3053\u3067\u306f\u6f01\u696d\u73fe\u5834\u306e\u5199\u771f\u304b\u3089\uff12\u3064\u306e\u89e3\u6790\u3092\u884c\u3044\u307e\u3059\uff0e\n1. \u30dc\u30fc\u30c8\u3054\u3068\u56fa\u6709\u306eID\u3092\u63a8\u5b9a\u3059\u308b\n2. \u5199\u771f\u304b\u3089\u9b5a\u306e\u5834\u6240\u3092\u30bb\u30b0\u30e1\u30f3\u30c6\u30fc\u30b7\u30e7\u30f3\u3059\u308b\n\n1. \u5199\u771f\u3092\u64ae\u3063\u305f\u30dc\u30fc\u30c8\u306e\u30af\u30e9\u30b9\u30bf\u30ea\u30f3\u30b0\n\u3053\u3053\u3067\u306f\u5199\u771f\u3092\u64ae\u5f71\u3057\u305f\u30dc\u30fc\u30c8\u306e\u7a2e\u985e\u3092\u81ea\u52d5\u3067\u30af\u30e9\u30b9\u30bf\u30ea\u30f3\u30b0\u3059\u308b\u65b9\u6cd5\u3092\u7d39\u4ecb\u3057\u307e\u3059\uff0e\u305f\u3068\u3048\u3070\uff0c\u30dc\u30fc\u30c8\u3054\u3068\u306b\u7570\u306a\u308b\u30e2\u30c7\u30eb\u3092\u4f5c\u6210\u3059\u308b\uff0c\u307e\u305f\u306f\u30dc\u30fc\u30c9\u306e\u9b5a\u304c\u3044\u306a\u3044\u5834\u6240\u3092\u30de\u30b9\u30ad\u30f3\u30b0\u3059\u308b\u305f\u3081\u306b\u6d3b\u7528\u304c\u53ef\u80fd\u3067\u3059\uff0e\n\u753b\u50cf\u3092\u4e26\u3079\u3066\u8868\u793a\u3059\u308b\u95a2\u6570\u3092\u4f5c\u6210\u3057\u307e\u3059\uff0e\uff14\u3064\u3068\uff18\u3064\u306e\uff12\u7a2e\u985e\u3067\u3059\uff0e\n\u305d\u306e\u5f8c\uff0ctrain\u304b\u3089500\u30b5\u30f3\u30d7\u30eb\u3092\u8aad\u307f\u51fa\u3057\u307e\u3059\uff0e\nimport pandas as pd\nimport numpy as np\nimport glob\nfrom sklearn import cluster\nfrom scipy.misc import imread\nimport cv2\nimport skimage.measure as sm\n# import progressbar\nimport multiprocessing\nimport random\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n%matplotlib inline\nnew_style = {'grid': False}\nplt.rc('axes', **new_style)\n\n# Function to show 4 images\ndef show_four(imgs, title):\n    #select_imgs = [np.random.choice(imgs) for _ in range(4)]\n    select_imgs = [imgs[np.random.choice(len(imgs))] for _ in range(4)]\n    _, ax = plt.subplots(1, 4, sharex='col', sharey='row', figsize=(20, 3))\n    plt.suptitle(title, size=20)\n    for i, img in enumerate(select_imgs):\n        ax[i].imshow(img)\n\n# Function to show 8 images\ndef show_eight(imgs, title):\n    select_imgs = [imgs[np.random.choice(len(imgs))] for _ in range(8)]\n    _, ax = plt.subplots(2, 4, sharex='col', sharey='row', figsize=(20, 6))\n    plt.suptitle(title, size=20)\n    for i, img in enumerate(select_imgs):\n        ax[i // 4, i % 4].imshow(img)\n\nselect = 500 # Only load 500 images for speed\n# Data loading\ntrain_files = sorted(glob.glob('../input/train/*/*.jpg'), key=lambda x: random.random())[:select]\ntrain = np.array([imread(img) for img in train_files])\nprint('Length of train {}'.format(len(train)))\n\ntrain\u306e\u753b\u50cf\u306f\u30b5\u30a4\u30ba\u304c\u7d71\u4e00\u3055\u308c\u3066\u3044\u307e\u305b\u3093\uff0e\u7279\u5b9a\u306e\u30dc\u30fc\u30c8\u3060\u3051\u3092\u542b\u3080\u5199\u771f\u30b5\u30a4\u30ba\u304c\u3042\u308b\u306e\u3067\u3057\u3087\u3046\u304b\uff1f\u30dc\u30fc\u30c8ID\u3092\u753b\u50cf\u30b5\u30a4\u30ba\u3068\u307f\u306a\u3057\u3066\u78ba\u8a8d\u3057\u3066\u307f\u307e\u3057\u3087\u3046\uff0e\nprint('Sizes in train:')\nshapes = np.array([str(img.shape) for img in train])\npd.Series(shapes).value_counts()\n\n(720, 1280, 3)    287\n(750, 1280, 3)     81\n(974, 1280, 3)     50\n(670, 1192, 3)     29\n(718, 1276, 3)     28\n(924, 1280, 3)      9\n(974, 1732, 3)      7\n(700, 1244, 3)      5\n(854, 1518, 3)      3\n(750, 1334, 3)      1\ndtype: int64\n\n\u30b5\u30a4\u30ba\u3092\u5206\u5272\u3057\u307e\u3057\u305f\uff0e\n\u5b9f\u969b\u306e\u753b\u50cf\u3092\uff14\u3064\u305a\u3064\u8868\u793a\u3057\u3066\u307f\u307e\u3059\uff0e\nfor uniq in pd.Series(shapes).unique():\n    show_four(train[shapes == uniq], 'Images with shape: {}'.format(uniq))\n    plt.show()\n\n(854, 1518, 3)\u306e\u753b\u50cf\u30b5\u30a4\u30ba\u3092\u9664\u304f\uff0c\u4ed6\u306e\u753b\u50cf\u306f\u4e00\u3064\u4ee5\u4e0a\u306e\u30dc\u30fc\u30c8\u3092\u542b\u3093\u3067\u3044\u307e\u3059\uff0e\n\u30dc\u30fc\u30c8ID\u3092\u8003\u3048\u308b\u4e0a\u3067\uff0c\u4ed6\u306e\u30a2\u30d7\u30ed\u30fc\u30c1\u304c\u5fc5\u8981\u306b\u306a\u308a\u305d\u3046\u3067\u3059\uff0e\n\n\u30dc\u30fc\u30c8\u30af\u30e9\u30b9\u30bf\u30ea\u30f3\u30b0\n\u7c21\u5358\u306e\u305f\u3081\uff0c\u3053\u308c\u3089500\u30c7\u30fc\u30bf\u3067\u89e3\u6790\u3092\u884c\u3044\u307e\u3059\uff0e\u5f53\u7136\u3067\u3059\u304c\uff0c\u540c\u69d8\u306e\u51e6\u7406\u306f\u5168\u3066\u306e\u753b\u50cf\u30c7\u30fc\u30bf\u3092\u4f7f\u7528\u3057\u3066\u884c\u3046\u3053\u3068\u304c\u53ef\u80fd\u3067\u3059\uff0e\n\u6b21\u306e\uff13\u3064\u306e\u30b9\u30c6\u30c3\u30d7\u3067\u89e3\u6790\u3057\u307e\u3059\uff0e\n\n\u753b\u50cf\u3092\u6a19\u6e96\u5316(Normalize)\u3057\u307e\u3059\n\u753b\u50cf\u9593\u306e\u5e73\u5747\u30d4\u30af\u30bb\u30eb\u9593\u8aa4\u5dee\u3092\u753b\u50cf\u306e\u8ddd\u96e2\u3068\u3057\u307e\u3059\n\u753b\u50cf\u9593\u306e\u8ddd\u96e2\u3092\u4e8b\u524d\u8ddd\u96e2\u884c\u5217\u3068\u3057\uff0cDBSCAN\u3067\u30af\u30e9\u30b9\u30bf\u3092\u4f5c\u6210\u3057\u307e\u3059\n\n# Function for computing distance between images\ndef compare(args):\n    img, img2 = args\n    img = (img - img.mean()) / img.std()\n    img2 = (img2 - img2.mean()) / img2.std()\n    return np.mean(np.abs(img - img2))\n\n# Resize the images to speed it up.\ntrain = [cv2.resize(img, (224, 224), cv2.INTER_LINEAR) for img in train]\n\n# Create the distance matrix in a multithreaded fashion\npool = multiprocessing.Pool(8)\n#bar = progressbar.ProgressBar(max=len(train))\ndistances = np.zeros((len(train), len(train)))\nfor i, img in enumerate(train): #enumerate(bar(train)):\n    all_imgs = [(img, f) for f in train]\n    dists = pool.map(compare, all_imgs)\n    distances[i, :] = dists\n\nNxN\u306e\u30de\u30c8\u30ea\u30af\u30b9\u3092\u4f5c\u6210\u3057\u307e\u3059\uff0eN\u306f\u753b\u50cf\u306e\u6570\u3067\uff0c\u3053\u306e\u30de\u30c8\u30ea\u30af\u30b9\u306f\u753b\u50cf\u9593\u306e\u8ddd\u96e2\u3092\u793a\u3057\u307e\u3059\uff0e\nSKLearn\u306b\u306f\u4e8b\u524d\u306b\u8a08\u7b97\u3057\u305f\u8ddd\u96e2\u884c\u5217\u3092\u4f7f\u7528\u3067\u304d\u308b\u30af\u30e9\u30b9\u30bf\u30ea\u30f3\u30b0\u624b\u6cd5\u304c\u591a\u6570\u3042\u308a\u307e\u3059\uff0e\u3053\u3053\u3067\u306fDBSCAN\u3078distance matrix\u3092\u4e0e\u3048\u3066\u30af\u30e9\u30b9\u30bf\u30ea\u30f3\u30b0\u3092\u884c\u3044\u307e\u3059\uff0e\nprint(distances)\nplt.hist(distances.flatten(), bins=50)\nplt.title('Histogram of distance matrix')\nprint('')\n\n\n0.8\u4ee5\u4e0b\u306e\u9818\u57df\u304c\u3042\u308b\u3053\u3068\u304c\u308f\u304b\u308a\u307e\u3059\uff0e\u304a\u305d\u3089\u304f\u540c\u3058\u30dc\u30fc\u30c8\u306e\u753b\u50cf\u9593\u3067\u8ddd\u96e2\u3092\u8a08\u7b97\u3057\u305f\u969b\u306e\u3082\u306e\u3060\u308d\u3046\u3068\u601d\u308f\u308c\u307e\u3059\uff0eDBSCAN\u306f0.5\u307e\u3067\u306e\u8ddd\u96e2\u3092\u540c\u69d8\u306e\u30af\u30e9\u30b9\u30bf\u3068\u307f\u306a\u3057\u307e\u3059\uff0e\u30d2\u30b9\u30c8\u30b0\u30e9\u30e0\u3092\u898b\u308b\u9650\u308a\uff0c0.6\u304c\u9069\u3057\u305f\u95be\u5024\u3060\u3068\u5224\u65ad\u3057\u307e\u3059\uff0e\ncls = cluster.DBSCAN(metric='precomputed', min_samples=5, eps=0.6)\ny = cls.fit_predict(distances)\nprint(y)\nprint('Cluster sizes:')\nprint(pd.Series(y).value_counts())\n\nfor uniq in pd.Series(y).value_counts().index:\n    if uniq != -1:\n        size = len(np.array(train)[y == uniq])\n        if size > 10:\n            show_eight(np.array(train)[y == uniq], 'BoatID: {} - Image count {}'.format(uniq, size))\n            plt.show()\n        else:\n            show_four(np.array(train)[y == uniq], 'BoatID: {} - Image count {}'.format(uniq, size))\n            plt.show()\n\n\u304b\u306a\u308a\u3046\u307e\u304f\u3044\u304d\u307e\u3057\u305f\uff0e\n\u3057\u304b\u3057\u3069\u306e\u30dc\u30fc\u30c8ID\u306b\u3082\u5c5e\u3055\u306a\u3044\u96c6\u56e3\u304c\u3067\u304d\u307e\u3057\u305f\uff0e\n\u3042\u308a\u3046\u308b\u7406\u7531\u306f\uff12\u3064\uff0e\n\n\u30dc\u30fc\u30c8ID\u306e\u95be\u5024\u3068\u3057\u3066\u8a2d\u5b9a\u3057\u305f\uff0c\uff15\u3064\u4ee5\u4e0b\u306e\u753b\u50cf\u3057\u304b\u306a\u3044\n\u8ddd\u96e2\u95a2\u6570\u304c\u753b\u50cf\u306e\u30af\u30e9\u30b9\u30bf\u306b\u5341\u5206\u3067\u306f\u306a\u3044\uff0e\u4f8b\u3048\u3070\u591c\u3068\u663c\u306e\u5199\u771f\u304c\u6df7\u5728\u3057\u3066\u3044\u308b\u306a\u3069\uff0e\n\nsize = len(np.array(train)[y == -1])\nshow_eight(np.array(train)[y == -1], 'BoatID: {} (Unclassified images) - Image count {}'.format(-1, size))\n\n\u3044\u304f\u3064\u304b\u306f\u76ee\u8996\u3067\u30af\u30e9\u30b9\u30bf\u3092\u4f5c\u6210\u3059\u308b\u3053\u3068\u304c\u3067\u304d\u307e\u3059\uff0e\u3064\u307e\u308a\u30a2\u30eb\u30b4\u30ea\u30ba\u30e0\u306e\u6539\u5584\u306e\u4f59\u5730\u304c\u3042\u308b\u3068\u3044\u3046\u3053\u3068\u3067\u3059\uff0e\n\u3057\u304b\u3057\u306a\u304c\u3089\uff0c\u6559\u5e2b\u306a\u3057\u5b66\u7fd2\u306775%\u4ee5\u4e0a\u3082\u306e\u30dc\u30fc\u30c8\u306e\u5206\u985e\u304c\u3067\u304d\u305f\u3068\u3044\u3046\u3053\u3068\u306f\uff0c\u304b\u306a\u308a\u6b63\u78ba\u306a\u30ab\u30c6\u30b4\u30ea\u5206\u3051\u304c\u6210\u529f\u3057\u305f\u3068\u8a00\u3048\u307e\u3059\uff0e\n\n2. \u9b5a\u306e\u30bb\u30b0\u30e1\u30f3\u30c6\u30fc\u30b7\u30e7\u30f3\n\u9b5a\u306e\u753b\u50cf\u3092\u30bb\u30b0\u30e1\u30f3\u30c6\u30fc\u30b7\u30e7\u30f3\u3057\u307e\u3059\uff0e\n\u4f5c\u696d\u624b\u9806\u3068\u3057\u3066\u306f\uff0c\n\n\u30c6\u30f3\u30d7\u30ec\u30fc\u30c8\u3068\u306a\u308b\u9b5a\u306e\u5199\u771f\u3092\u6e96\u5099\n\u30c6\u30f3\u30d7\u30ec\u30fc\u30c8\u4ee5\u5916\u306e\u5199\u771f\u3092\uff11\u679a\u9078\u629e\u80a2\uff0c\u8907\u6570\u306e\u30a2\u30eb\u30b4\u30ea\u30ba\u30e0\u3067\u9069\u3057\u305f\u30bb\u30b0\u30e1\u30f3\u30c6\u30fc\u30b7\u30e7\u30f3\u624b\u6cd5\u3092\u9078\u629e\n\u5148\u307b\u3069\u9078\u629e\u3057\u305f\u30a2\u30eb\u30b4\u30ea\u30ba\u30e0\u3092\u4f7f\u7528\u3057\uff0c\u8907\u6570\u306e\u5199\u771f\u3092\u30bb\u30b0\u30e1\u30f3\u30c6\u30fc\u30b7\u30e7\u30f3\n\nimport os \nfrom scipy import ndimage\nfrom subprocess import check_output\n\nimport cv2\nimport numpy as np\nfrom matplotlib import pyplot as plt\n%matplotlib inline\n\nimg_rows, img_cols= 350, 425\nim_array = cv2.imread('../input/train/LAG/img_00091.jpg',0)\ntemplate = np.zeros([ img_rows, img_cols], dtype='uint8') # initialisation of the template\ntemplate[:, :] = im_array[100:450,525:950] # I try multiple times to find the correct rectangle. \n#template /= 255.\nplt.subplots(figsize=(10, 7))\nplt.subplot(121),plt.imshow(template, cmap='gray') \nplt.subplot(122), plt.imshow(im_array, cmap='gray')\n\n\u5148\u307b\u3069\u30c6\u30f3\u30d7\u30ec\u30fc\u30c8\u3068\u3057\u3066\u4f7f\u7528\u3057\u305f\u5199\u771f\u3068\u306f\u5225\u306e\u30c7\u30fc\u30bf\u3092\u4f7f\u7528\u3057\u307e\u3059\uff0e\nopencv\u306ematchTemplate\u3092\u4f7f\u7528\u3059\u308b\u3053\u3068\u3067\uff0c\u6e96\u5099\u3057\u305f\u30c6\u30f3\u30d7\u30ec\u30fc\u30c8\u3068\u985e\u4f3c\u3057\u305f\u90e8\u5206\u3092\u767a\u898b\u3059\u308b\u3053\u3068\u304c\u3067\u304d\u307e\u3059\uff0e\n\u30aa\u30d7\u30b7\u30e7\u30f3\u306emethod\u306b\u306f\u3044\u304f\u3064\u304b\u7a2e\u985e\u304c\u3042\u308b\u306e\u3067\uff0c\uff16\u3064\u306e\u65b9\u6cd5\u306b\u3064\u3044\u3066\u305d\u308c\u305e\u308c\u5b9f\u9a13\u3057\u307e\u3059\uff0e\n\u7279\u5b9a\u3057\u305f\u5834\u6240\u306f\u56db\u89d2\u5f62\u3067\u56f2\u3080\u8a2d\u5b9a\u3067\u3059\uff0e\nfile_name = '../input/train/LAG/img_01512.jpg' # img_00176,img_02758, img_01512\nimg = cv2.imread(file_name,0) \nimg2 = img\nw, h = template.shape[::-1]\n\n# All the 6 methods for comparison in a list\nmethods = ['cv2.TM_CCOEFF', 'cv2.TM_CCOEFF_NORMED', 'cv2.TM_CCORR',\n            'cv2.TM_CCORR_NORMED', 'cv2.TM_SQDIFF', 'cv2.TM_SQDIFF_NORMED']\n\nfor meth in methods:\n     img = img2\n     method = eval(meth)\n\n     # Apply template Matching\n     res = cv2.matchTemplate(img,template,method)\n     min_val, max_val, min_loc, max_loc = cv2.minMaxLoc(res)\n\n     # If the method is TM_SQDIFF or TM_SQDIFF_NORMED, take minimum\n     if method in [cv2.TM_SQDIFF, cv2.TM_SQDIFF_NORMED]:\n         top_left = min_loc\n     else:\n         top_left = max_loc\n     bottom_right = (top_left[0] + w, top_left[1] + h)\n\n     cv2.rectangle(img,top_left, bottom_right, 255, 2)\n     fig, ax = plt.subplots(figsize=(12, 7))\n     plt.subplot(121),plt.imshow(res,cmap = 'gray')\n     plt.title('Matching Result'), plt.xticks([]), plt.yticks([])\n     plt.subplot(122),plt.imshow(img,cmap = 'gray') #,aspect='auto'\n     plt.title('Detected Point'), plt.xticks([]), plt.yticks([])\n     plt.suptitle(meth)\n\n     plt.show()\n\n\u5b9f\u884c\u3057\u3066\u898b\u308b\u3068\uff0cTM_SQDIFF, TM_SQDIFF_NORMED\u4ee5\u5916\u306e\u65b9\u6cd5\u306f\u4e0a\u624b\u306b\u9b5a\u3092\u30bb\u30b0\u30e1\u30f3\u30c6\u30fc\u30b7\u30e7\u30f3\u3067\u304d\u3066\u3044\u307e\u3059\uff0e\n\u305d\u3053\u3067\u4eca\u56de\u306f\uff0cTM_CCOEFF\u3092\u767a\u898b\u624b\u6cd5\u3068\u3057\u3066\u4f7f\u7528\u3057\u307e\u3059\uff0e\n\u672c\u30b3\u30f3\u30da\u306e\u5199\u771f\u306f\uff0c\u9b5a\u306e\u7a2e\u985e\u304c\uff18\u7a2e\u985e\u3068\u9650\u5b9a\u3055\u308c\u3066\u3044\u307e\u3059\uff0e\n\u305d\u3053\u3067\u5404\u9b5a\u7a2e\u304b\u3089\u5199\u771f\u3092\uff14\u679a\u9078\u629e\u3057\uff0cTM_CCOEFF\u3067\u30bb\u30b0\u30e1\u30f3\u30c6\u30fc\u30b7\u30e7\u30f3\u3092\u5b9f\u884c\u3057\u307e\u3059\uff0e\nmethod = eval('cv2.TM_CCOEFF')\nindexes=[1,30,40,5]\n\ntrain_path = \"../input/train/\"\nsub_folders = check_output([\"ls\", train_path]).decode(\"utf8\").strip().split('\\n')\nfor sub_folder in sub_folders:\n    file_names = check_output([\"ls\", train_path+sub_folder]).decode(\"utf8\").strip().split('\\n')\n    k=0\n    _, ax = plt.subplots(2,2,figsize=(10, 7))\n    for file_name in [file_names[x] for x in indexes]: # I take only 4 images of each group. \n        img = cv2.imread(train_path+sub_folder+\"/\"+file_name,0)\n        img2 = img\n        w, h = template.shape[::-1]\n        # Apply template Matching\n        res = cv2.matchTemplate(img,template,method)\n        min_val, max_val, min_loc, max_loc = cv2.minMaxLoc(res)\n        top_left = max_loc\n        bottom_right = (top_left[0] + w, top_left[1] + h)\n\n        cv2.rectangle(img,top_left, bottom_right, 255, 2)\n        if k==0 : \n            ax[0,0].imshow(img,cmap = 'gray')\n            plt.xticks([]), plt.yticks([])\n        if k==1 : \n            ax[0,1].imshow(img,cmap = 'gray')\n            plt.xticks([]), plt.yticks([])\n        if k==2 : \n            ax[1,0].imshow(img,cmap = 'gray')\n            plt.xticks([]), plt.yticks([])\n        if k==3 : \n            ax[1,1].imshow(img,cmap = 'gray')\n            plt.xticks([]), plt.yticks([])\n        k=k+1\n    plt.suptitle(sub_folder)\n    plt.show()\n\n\u5b9f\u884c\u3057\u3066\u898b\u308b\u3068\uff0c\u30c6\u30f3\u30d7\u30ec\u30fc\u30c8\u3067\u4f7f\u7528\u3057\u305f\"LAG\"\u3068\u3044\u3046\u9b5a\u306e\u30c7\u30fc\u30bf\u3060\u3051\u306f\u6bd4\u8f03\u7684\u7cbe\u5ea6\u3088\u304f\u30bb\u30b0\u30e1\u30f3\u30c6\u30fc\u30b7\u30e7\u30f3\u3067\u304d\u3066\u3044\u308b\u3053\u3068\u304c\u308f\u304b\u308a\u307e\u3059\uff0e\n\u4ed6\u306e\u9b5a\u306b\u306f\u5225\u306e\u30c6\u30f3\u30d7\u30ec\u30fc\u30c8\u3092\u6e96\u5099\u3059\u308b\u3068\u826f\u3044\u304b\u3082\u3057\u308c\u307e\u305b\u3093\uff0e\n# \u306f\u3058\u3081\u306b\n\u672c\u8a18\u4e8b\u306f[Kaggle\uff1aThe Nature Conservancy Fisheries Monitoring](https://www.kaggle.com/c/the-nature-conservancy-fisheries-monitoring)\u306e\u30b5\u30f3\u30d7\u30eb\u30b3\u30fc\u30c9\u306e\u4e00\u90e8\u3067\u3059\uff0e\n\u3053\u3053\u3067\u306f\u3042\u3048\u3066CNN\u306b\u95a2\u3059\u308b\u30d7\u30ed\u30b0\u30e9\u30e0\u306f\u8f09\u305b\u3066\u3044\u307e\u305b\u3093\uff0e\n\u8a73\u7d30\u306f\u5f8c\u65e5\u307e\u3068\u3081\u307e\u3059\uff0e\n\n\u3053\u3053\u3067\u306f\u6f01\u696d\u73fe\u5834\u306e\u5199\u771f\u304b\u3089\uff12\u3064\u306e\u89e3\u6790\u3092\u884c\u3044\u307e\u3059\uff0e\n1. \u30dc\u30fc\u30c8\u3054\u3068\u56fa\u6709\u306eID\u3092\u63a8\u5b9a\u3059\u308b\n2. \u5199\u771f\u304b\u3089\u9b5a\u306e\u5834\u6240\u3092\u30bb\u30b0\u30e1\u30f3\u30c6\u30fc\u30b7\u30e7\u30f3\u3059\u308b\n\n\n# 1. \u5199\u771f\u3092\u64ae\u3063\u305f\u30dc\u30fc\u30c8\u306e\u30af\u30e9\u30b9\u30bf\u30ea\u30f3\u30b0\n\u3053\u3053\u3067\u306f[\u5199\u771f\u3092\u64ae\u5f71\u3057\u305f\u30dc\u30fc\u30c8\u306e\u7a2e\u985e\u3092\u81ea\u52d5\u3067\u30af\u30e9\u30b9\u30bf\u30ea\u30f3\u30b0\u3059\u308b\u65b9\u6cd5](https://www.kaggle.com/anokas/the-nature-conservancy-fisheries-monitoring/finding-boatids)\u3092\u7d39\u4ecb\u3057\u307e\u3059\uff0e\u305f\u3068\u3048\u3070\uff0c\u30dc\u30fc\u30c8\u3054\u3068\u306b\u7570\u306a\u308b\u30e2\u30c7\u30eb\u3092\u4f5c\u6210\u3059\u308b\uff0c\u307e\u305f\u306f\u30dc\u30fc\u30c9\u306e\u9b5a\u304c\u3044\u306a\u3044\u5834\u6240\u3092\u30de\u30b9\u30ad\u30f3\u30b0\u3059\u308b\u305f\u3081\u306b\u6d3b\u7528\u304c\u53ef\u80fd\u3067\u3059\uff0e\n\n\u753b\u50cf\u3092\u4e26\u3079\u3066\u8868\u793a\u3059\u308b\u95a2\u6570\u3092\u4f5c\u6210\u3057\u307e\u3059\uff0e\uff14\u3064\u3068\uff18\u3064\u306e\uff12\u7a2e\u985e\u3067\u3059\uff0e\n\u305d\u306e\u5f8c\uff0ctrain\u304b\u3089500\u30b5\u30f3\u30d7\u30eb\u3092\u8aad\u307f\u51fa\u3057\u307e\u3059\uff0e\n\n```py\nimport pandas as pd\nimport numpy as np\nimport glob\nfrom sklearn import cluster\nfrom scipy.misc import imread\nimport cv2\nimport skimage.measure as sm\n# import progressbar\nimport multiprocessing\nimport random\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n%matplotlib inline\nnew_style = {'grid': False}\nplt.rc('axes', **new_style)\n\n# Function to show 4 images\ndef show_four(imgs, title):\n    #select_imgs = [np.random.choice(imgs) for _ in range(4)]\n    select_imgs = [imgs[np.random.choice(len(imgs))] for _ in range(4)]\n    _, ax = plt.subplots(1, 4, sharex='col', sharey='row', figsize=(20, 3))\n    plt.suptitle(title, size=20)\n    for i, img in enumerate(select_imgs):\n        ax[i].imshow(img)\n\n# Function to show 8 images\ndef show_eight(imgs, title):\n    select_imgs = [imgs[np.random.choice(len(imgs))] for _ in range(8)]\n    _, ax = plt.subplots(2, 4, sharex='col', sharey='row', figsize=(20, 6))\n    plt.suptitle(title, size=20)\n    for i, img in enumerate(select_imgs):\n        ax[i // 4, i % 4].imshow(img)\n\nselect = 500 # Only load 500 images for speed\n# Data loading\ntrain_files = sorted(glob.glob('../input/train/*/*.jpg'), key=lambda x: random.random())[:select]\ntrain = np.array([imread(img) for img in train_files])\nprint('Length of train {}'.format(len(train)))\n```\n\ntrain\u306e\u753b\u50cf\u306f\u30b5\u30a4\u30ba\u304c\u7d71\u4e00\u3055\u308c\u3066\u3044\u307e\u305b\u3093\uff0e\u7279\u5b9a\u306e\u30dc\u30fc\u30c8\u3060\u3051\u3092\u542b\u3080\u5199\u771f\u30b5\u30a4\u30ba\u304c\u3042\u308b\u306e\u3067\u3057\u3087\u3046\u304b\uff1f\u30dc\u30fc\u30c8ID\u3092\u753b\u50cf\u30b5\u30a4\u30ba\u3068\u307f\u306a\u3057\u3066\u78ba\u8a8d\u3057\u3066\u307f\u307e\u3057\u3087\u3046\uff0e\n\n```py\nprint('Sizes in train:')\nshapes = np.array([str(img.shape) for img in train])\npd.Series(shapes).value_counts()\n```\n\n```\n(720, 1280, 3)    287\n(750, 1280, 3)     81\n(974, 1280, 3)     50\n(670, 1192, 3)     29\n(718, 1276, 3)     28\n(924, 1280, 3)      9\n(974, 1732, 3)      7\n(700, 1244, 3)      5\n(854, 1518, 3)      3\n(750, 1334, 3)      1\ndtype: int64\n```\n\u30b5\u30a4\u30ba\u3092\u5206\u5272\u3057\u307e\u3057\u305f\uff0e\n\u5b9f\u969b\u306e\u753b\u50cf\u3092\uff14\u3064\u305a\u3064\u8868\u793a\u3057\u3066\u307f\u307e\u3059\uff0e\n\n```py\nfor uniq in pd.Series(shapes).unique():\n    show_four(train[shapes == uniq], 'Images with shape: {}'.format(uniq))\n    plt.show()\n```\n\n\n(854, 1518, 3)\u306e\u753b\u50cf\u30b5\u30a4\u30ba\u3092\u9664\u304f\uff0c\u4ed6\u306e\u753b\u50cf\u306f\u4e00\u3064\u4ee5\u4e0a\u306e\u30dc\u30fc\u30c8\u3092\u542b\u3093\u3067\u3044\u307e\u3059\uff0e\n\u30dc\u30fc\u30c8ID\u3092\u8003\u3048\u308b\u4e0a\u3067\uff0c\u4ed6\u306e\u30a2\u30d7\u30ed\u30fc\u30c1\u304c\u5fc5\u8981\u306b\u306a\u308a\u305d\u3046\u3067\u3059\uff0e\n\n## \u30dc\u30fc\u30c8\u30af\u30e9\u30b9\u30bf\u30ea\u30f3\u30b0\n\u7c21\u5358\u306e\u305f\u3081\uff0c\u3053\u308c\u3089500\u30c7\u30fc\u30bf\u3067\u89e3\u6790\u3092\u884c\u3044\u307e\u3059\uff0e\u5f53\u7136\u3067\u3059\u304c\uff0c\u540c\u69d8\u306e\u51e6\u7406\u306f\u5168\u3066\u306e\u753b\u50cf\u30c7\u30fc\u30bf\u3092\u4f7f\u7528\u3057\u3066\u884c\u3046\u3053\u3068\u304c\u53ef\u80fd\u3067\u3059\uff0e\n\u6b21\u306e\uff13\u3064\u306e\u30b9\u30c6\u30c3\u30d7\u3067\u89e3\u6790\u3057\u307e\u3059\uff0e\n\n* \u753b\u50cf\u3092\u6a19\u6e96\u5316(Normalize)\u3057\u307e\u3059\n* \u753b\u50cf\u9593\u306e\u5e73\u5747\u30d4\u30af\u30bb\u30eb\u9593\u8aa4\u5dee\u3092\u753b\u50cf\u306e\u8ddd\u96e2\u3068\u3057\u307e\u3059\n* \u753b\u50cf\u9593\u306e\u8ddd\u96e2\u3092\u4e8b\u524d\u8ddd\u96e2\u884c\u5217\u3068\u3057\uff0cDBSCAN\u3067\u30af\u30e9\u30b9\u30bf\u3092\u4f5c\u6210\u3057\u307e\u3059\n\n```py\n# Function for computing distance between images\ndef compare(args):\n    img, img2 = args\n    img = (img - img.mean()) / img.std()\n    img2 = (img2 - img2.mean()) / img2.std()\n    return np.mean(np.abs(img - img2))\n\n# Resize the images to speed it up.\ntrain = [cv2.resize(img, (224, 224), cv2.INTER_LINEAR) for img in train]\n\n# Create the distance matrix in a multithreaded fashion\npool = multiprocessing.Pool(8)\n#bar = progressbar.ProgressBar(max=len(train))\ndistances = np.zeros((len(train), len(train)))\nfor i, img in enumerate(train): #enumerate(bar(train)):\n    all_imgs = [(img, f) for f in train]\n    dists = pool.map(compare, all_imgs)\n    distances[i, :] = dists\n```\nNxN\u306e\u30de\u30c8\u30ea\u30af\u30b9\u3092\u4f5c\u6210\u3057\u307e\u3059\uff0eN\u306f\u753b\u50cf\u306e\u6570\u3067\uff0c\u3053\u306e\u30de\u30c8\u30ea\u30af\u30b9\u306f\u753b\u50cf\u9593\u306e\u8ddd\u96e2\u3092\u793a\u3057\u307e\u3059\uff0e\nSKLearn\u306b\u306f\u4e8b\u524d\u306b\u8a08\u7b97\u3057\u305f\u8ddd\u96e2\u884c\u5217\u3092\u4f7f\u7528\u3067\u304d\u308b\u30af\u30e9\u30b9\u30bf\u30ea\u30f3\u30b0\u624b\u6cd5\u304c\u591a\u6570\u3042\u308a\u307e\u3059\uff0e\u3053\u3053\u3067\u306fDBSCAN\u3078distance matrix\u3092\u4e0e\u3048\u3066\u30af\u30e9\u30b9\u30bf\u30ea\u30f3\u30b0\u3092\u884c\u3044\u307e\u3059\uff0e\n\n```py\nprint(distances)\nplt.hist(distances.flatten(), bins=50)\nplt.title('Histogram of distance matrix')\nprint('')\n```\n\n![__results___9_1.png](https://qiita-image-store.s3.amazonaws.com/0/72093/53f37a9b-3502-48d2-b322-b988d2386e2d.png)\n\n0.8\u4ee5\u4e0b\u306e\u9818\u57df\u304c\u3042\u308b\u3053\u3068\u304c\u308f\u304b\u308a\u307e\u3059\uff0e\u304a\u305d\u3089\u304f\u540c\u3058\u30dc\u30fc\u30c8\u306e\u753b\u50cf\u9593\u3067\u8ddd\u96e2\u3092\u8a08\u7b97\u3057\u305f\u969b\u306e\u3082\u306e\u3060\u308d\u3046\u3068\u601d\u308f\u308c\u307e\u3059\uff0eDBSCAN\u306f0.5\u307e\u3067\u306e\u8ddd\u96e2\u3092\u540c\u69d8\u306e\u30af\u30e9\u30b9\u30bf\u3068\u307f\u306a\u3057\u307e\u3059\uff0e\u30d2\u30b9\u30c8\u30b0\u30e9\u30e0\u3092\u898b\u308b\u9650\u308a\uff0c0.6\u304c\u9069\u3057\u305f\u95be\u5024\u3060\u3068\u5224\u65ad\u3057\u307e\u3059\uff0e\n\n\n```py\ncls = cluster.DBSCAN(metric='precomputed', min_samples=5, eps=0.6)\ny = cls.fit_predict(distances)\nprint(y)\nprint('Cluster sizes:')\nprint(pd.Series(y).value_counts())\n\nfor uniq in pd.Series(y).value_counts().index:\n    if uniq != -1:\n        size = len(np.array(train)[y == uniq])\n        if size > 10:\n            show_eight(np.array(train)[y == uniq], 'BoatID: {} - Image count {}'.format(uniq, size))\n            plt.show()\n        else:\n            show_four(np.array(train)[y == uniq], 'BoatID: {} - Image count {}'.format(uniq, size))\n            plt.show()\n```\n\n\u304b\u306a\u308a\u3046\u307e\u304f\u3044\u304d\u307e\u3057\u305f\uff0e\n\u3057\u304b\u3057\u3069\u306e\u30dc\u30fc\u30c8ID\u306b\u3082\u5c5e\u3055\u306a\u3044\u96c6\u56e3\u304c\u3067\u304d\u307e\u3057\u305f\uff0e\n\u3042\u308a\u3046\u308b\u7406\u7531\u306f\uff12\u3064\uff0e\n\n1. \u30dc\u30fc\u30c8ID\u306e\u95be\u5024\u3068\u3057\u3066\u8a2d\u5b9a\u3057\u305f\uff0c\uff15\u3064\u4ee5\u4e0b\u306e\u753b\u50cf\u3057\u304b\u306a\u3044\n2. \u8ddd\u96e2\u95a2\u6570\u304c\u753b\u50cf\u306e\u30af\u30e9\u30b9\u30bf\u306b\u5341\u5206\u3067\u306f\u306a\u3044\uff0e\u4f8b\u3048\u3070\u591c\u3068\u663c\u306e\u5199\u771f\u304c\u6df7\u5728\u3057\u3066\u3044\u308b\u306a\u3069\uff0e\n\n\n```py\nsize = len(np.array(train)[y == -1])\nshow_eight(np.array(train)[y == -1], 'BoatID: {} (Unclassified images) - Image count {}'.format(-1, size))\n```\n\n\u3044\u304f\u3064\u304b\u306f\u76ee\u8996\u3067\u30af\u30e9\u30b9\u30bf\u3092\u4f5c\u6210\u3059\u308b\u3053\u3068\u304c\u3067\u304d\u307e\u3059\uff0e\u3064\u307e\u308a\u30a2\u30eb\u30b4\u30ea\u30ba\u30e0\u306e\u6539\u5584\u306e\u4f59\u5730\u304c\u3042\u308b\u3068\u3044\u3046\u3053\u3068\u3067\u3059\uff0e\n\u3057\u304b\u3057\u306a\u304c\u3089\uff0c\u6559\u5e2b\u306a\u3057\u5b66\u7fd2\u306775%\u4ee5\u4e0a\u3082\u306e\u30dc\u30fc\u30c8\u306e\u5206\u985e\u304c\u3067\u304d\u305f\u3068\u3044\u3046\u3053\u3068\u306f\uff0c\u304b\u306a\u308a\u6b63\u78ba\u306a\u30ab\u30c6\u30b4\u30ea\u5206\u3051\u304c\u6210\u529f\u3057\u305f\u3068\u8a00\u3048\u307e\u3059\uff0e\n\n# 2. \u9b5a\u306e\u30bb\u30b0\u30e1\u30f3\u30c6\u30fc\u30b7\u30e7\u30f3\n[\u9b5a\u306e\u753b\u50cf\u3092\u30bb\u30b0\u30e1\u30f3\u30c6\u30fc\u30b7\u30e7\u30f3\u3057\u307e\u3059\uff0e](https://www.kaggle.com/narae78/the-nature-conservancy-fisheries-monitoring/fish-detection)\n\u4f5c\u696d\u624b\u9806\u3068\u3057\u3066\u306f\uff0c\n\n1. \u30c6\u30f3\u30d7\u30ec\u30fc\u30c8\u3068\u306a\u308b\u9b5a\u306e\u5199\u771f\u3092\u6e96\u5099\n2. \u30c6\u30f3\u30d7\u30ec\u30fc\u30c8\u4ee5\u5916\u306e\u5199\u771f\u3092\uff11\u679a\u9078\u629e\u80a2\uff0c\u8907\u6570\u306e\u30a2\u30eb\u30b4\u30ea\u30ba\u30e0\u3067\u9069\u3057\u305f\u30bb\u30b0\u30e1\u30f3\u30c6\u30fc\u30b7\u30e7\u30f3\u624b\u6cd5\u3092\u9078\u629e\n3. \u5148\u307b\u3069\u9078\u629e\u3057\u305f\u30a2\u30eb\u30b4\u30ea\u30ba\u30e0\u3092\u4f7f\u7528\u3057\uff0c\u8907\u6570\u306e\u5199\u771f\u3092\u30bb\u30b0\u30e1\u30f3\u30c6\u30fc\u30b7\u30e7\u30f3\n\n```py\nimport os \nfrom scipy import ndimage\nfrom subprocess import check_output\n\nimport cv2\nimport numpy as np\nfrom matplotlib import pyplot as plt\n%matplotlib inline\n\nimg_rows, img_cols= 350, 425\nim_array = cv2.imread('../input/train/LAG/img_00091.jpg',0)\ntemplate = np.zeros([ img_rows, img_cols], dtype='uint8') # initialisation of the template\ntemplate[:, :] = im_array[100:450,525:950] # I try multiple times to find the correct rectangle. \n#template /= 255.\nplt.subplots(figsize=(10, 7))\nplt.subplot(121),plt.imshow(template, cmap='gray') \nplt.subplot(122), plt.imshow(im_array, cmap='gray')\n```\n\n\n\u5148\u307b\u3069\u30c6\u30f3\u30d7\u30ec\u30fc\u30c8\u3068\u3057\u3066\u4f7f\u7528\u3057\u305f\u5199\u771f\u3068\u306f\u5225\u306e\u30c7\u30fc\u30bf\u3092\u4f7f\u7528\u3057\u307e\u3059\uff0e\nopencv\u306ematchTemplate\u3092\u4f7f\u7528\u3059\u308b\u3053\u3068\u3067\uff0c\u6e96\u5099\u3057\u305f\u30c6\u30f3\u30d7\u30ec\u30fc\u30c8\u3068\u985e\u4f3c\u3057\u305f\u90e8\u5206\u3092\u767a\u898b\u3059\u308b\u3053\u3068\u304c\u3067\u304d\u307e\u3059\uff0e\n\u30aa\u30d7\u30b7\u30e7\u30f3\u306emethod\u306b\u306f\u3044\u304f\u3064\u304b\u7a2e\u985e\u304c\u3042\u308b\u306e\u3067\uff0c\uff16\u3064\u306e\u65b9\u6cd5\u306b\u3064\u3044\u3066\u305d\u308c\u305e\u308c\u5b9f\u9a13\u3057\u307e\u3059\uff0e\n\u7279\u5b9a\u3057\u305f\u5834\u6240\u306f\u56db\u89d2\u5f62\u3067\u56f2\u3080\u8a2d\u5b9a\u3067\u3059\uff0e\n\n```py\nfile_name = '../input/train/LAG/img_01512.jpg' # img_00176,img_02758, img_01512\nimg = cv2.imread(file_name,0) \nimg2 = img\nw, h = template.shape[::-1]\n\n# All the 6 methods for comparison in a list\nmethods = ['cv2.TM_CCOEFF', 'cv2.TM_CCOEFF_NORMED', 'cv2.TM_CCORR',\n            'cv2.TM_CCORR_NORMED', 'cv2.TM_SQDIFF', 'cv2.TM_SQDIFF_NORMED']\n\nfor meth in methods:\n     img = img2\n     method = eval(meth)\n \n     # Apply template Matching\n     res = cv2.matchTemplate(img,template,method)\n     min_val, max_val, min_loc, max_loc = cv2.minMaxLoc(res)\n \n     # If the method is TM_SQDIFF or TM_SQDIFF_NORMED, take minimum\n     if method in [cv2.TM_SQDIFF, cv2.TM_SQDIFF_NORMED]:\n         top_left = min_loc\n     else:\n         top_left = max_loc\n     bottom_right = (top_left[0] + w, top_left[1] + h)\n \n     cv2.rectangle(img,top_left, bottom_right, 255, 2)\n     fig, ax = plt.subplots(figsize=(12, 7))\n     plt.subplot(121),plt.imshow(res,cmap = 'gray')\n     plt.title('Matching Result'), plt.xticks([]), plt.yticks([])\n     plt.subplot(122),plt.imshow(img,cmap = 'gray') #,aspect='auto'\n     plt.title('Detected Point'), plt.xticks([]), plt.yticks([])\n     plt.suptitle(meth)\n \n     plt.show()\n```\n\n\n\u5b9f\u884c\u3057\u3066\u898b\u308b\u3068\uff0cTM_SQDIFF, TM_SQDIFF_NORMED\u4ee5\u5916\u306e\u65b9\u6cd5\u306f\u4e0a\u624b\u306b\u9b5a\u3092\u30bb\u30b0\u30e1\u30f3\u30c6\u30fc\u30b7\u30e7\u30f3\u3067\u304d\u3066\u3044\u307e\u3059\uff0e\n\u305d\u3053\u3067\u4eca\u56de\u306f\uff0cTM_CCOEFF\u3092\u767a\u898b\u624b\u6cd5\u3068\u3057\u3066\u4f7f\u7528\u3057\u307e\u3059\uff0e\n\n\u672c\u30b3\u30f3\u30da\u306e\u5199\u771f\u306f\uff0c\u9b5a\u306e\u7a2e\u985e\u304c\uff18\u7a2e\u985e\u3068\u9650\u5b9a\u3055\u308c\u3066\u3044\u307e\u3059\uff0e\n\u305d\u3053\u3067\u5404\u9b5a\u7a2e\u304b\u3089\u5199\u771f\u3092\uff14\u679a\u9078\u629e\u3057\uff0cTM_CCOEFF\u3067\u30bb\u30b0\u30e1\u30f3\u30c6\u30fc\u30b7\u30e7\u30f3\u3092\u5b9f\u884c\u3057\u307e\u3059\uff0e\n\n```py\nmethod = eval('cv2.TM_CCOEFF')\nindexes=[1,30,40,5]\n\ntrain_path = \"../input/train/\"\nsub_folders = check_output([\"ls\", train_path]).decode(\"utf8\").strip().split('\\n')\nfor sub_folder in sub_folders:\n    file_names = check_output([\"ls\", train_path+sub_folder]).decode(\"utf8\").strip().split('\\n')\n    k=0\n    _, ax = plt.subplots(2,2,figsize=(10, 7))\n    for file_name in [file_names[x] for x in indexes]: # I take only 4 images of each group. \n        img = cv2.imread(train_path+sub_folder+\"/\"+file_name,0)\n        img2 = img\n        w, h = template.shape[::-1]\n        # Apply template Matching\n        res = cv2.matchTemplate(img,template,method)\n        min_val, max_val, min_loc, max_loc = cv2.minMaxLoc(res)\n        top_left = max_loc\n        bottom_right = (top_left[0] + w, top_left[1] + h)\n \n        cv2.rectangle(img,top_left, bottom_right, 255, 2)\n        if k==0 : \n            ax[0,0].imshow(img,cmap = 'gray')\n            plt.xticks([]), plt.yticks([])\n        if k==1 : \n            ax[0,1].imshow(img,cmap = 'gray')\n            plt.xticks([]), plt.yticks([])\n        if k==2 : \n            ax[1,0].imshow(img,cmap = 'gray')\n            plt.xticks([]), plt.yticks([])\n        if k==3 : \n            ax[1,1].imshow(img,cmap = 'gray')\n            plt.xticks([]), plt.yticks([])\n        k=k+1\n    plt.suptitle(sub_folder)\n    plt.show()\n```\n\n\u5b9f\u884c\u3057\u3066\u898b\u308b\u3068\uff0c\u30c6\u30f3\u30d7\u30ec\u30fc\u30c8\u3067\u4f7f\u7528\u3057\u305f\"LAG\"\u3068\u3044\u3046\u9b5a\u306e\u30c7\u30fc\u30bf\u3060\u3051\u306f\u6bd4\u8f03\u7684\u7cbe\u5ea6\u3088\u304f\u30bb\u30b0\u30e1\u30f3\u30c6\u30fc\u30b7\u30e7\u30f3\u3067\u304d\u3066\u3044\u308b\u3053\u3068\u304c\u308f\u304b\u308a\u307e\u3059\uff0e\n\u4ed6\u306e\u9b5a\u306b\u306f\u5225\u306e\u30c6\u30f3\u30d7\u30ec\u30fc\u30c8\u3092\u6e96\u5099\u3059\u308b\u3068\u826f\u3044\u304b\u3082\u3057\u308c\u307e\u305b\u3093\uff0e\n\n\n"}