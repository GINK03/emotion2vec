{"context": "\n\u52d5\u4f5c\u74b0\u5883\nGeForce GTX 1070 (8GB)\nASRock Z170M Pro4S [Intel Z170chipset]\nUbuntu 14.04 LTS desktop amd64\nTensorFlow v0.11\ncuDNN v5.1 for Linux\nCUDA v8.0\nPython 2.7.6\nIPython 5.1.0 -- An enhanced Interactive Python.\n\n\nv0.1 http://qiita.com/7of9/items/b364d897b95476a30754\nsine curve\u3092\u5b66\u7fd2\u3059\u308b\u30b3\u30fc\u30c9\u3092placeholder\u4f7f\u7528\u306b\u5909\u66f4\u3057\u3066\u3044\u308b\u304closs\u304c0.4\u3092\u4e2d\u5fc3\u3068\u3057\u3066\u3044\u308b\u3002\n\ninput.csv\u751f\u6210\nhttp://qiita.com/7of9/items/b364d897b95476a30754#\u30c7\u30fc\u30bf\u751f\u6210\u90e8\n\noriginal (placeholder\u4e0d\u4f7f\u7528)\n\nlinreg2.py\n#!/usr/bin/env python\n# -*- coding: utf-8 -*-\n\nimport sys\nimport tensorflow as tf\nimport tensorflow.contrib.slim as slim\n\n# \u30d5\u30a1\u30a4\u30eb\u540d\u306e Queue \u3092\u4f5c\u6210\nfilename_queue = tf.train.string_input_producer([\"input.csv\"])\n\n# CSV \u3092 parse\nreader = tf.TextLineReader()\nkey, value = reader.read(filename_queue)\ninput1, output = tf.decode_csv(value, record_defaults=[[0.], [0.]])\ninputs = tf.pack([input1])\noutput = tf.pack([output])\n\nbatch_size=4 # [4]\ninputs_batch, output_batch = tf.train.shuffle_batch([inputs, output], batch_size, capacity=40, min_after_dequeue=batch_size)\n\n## NN \u306e\u30b0\u30e9\u30d5\u751f\u6210\nhiddens = slim.stack(inputs_batch, slim.fully_connected, [1,7,7,7], \n  activation_fn=tf.nn.sigmoid, scope=\"hidden\")\nprediction = slim.fully_connected(hiddens, 1, activation_fn=tf.nn.sigmoid, scope=\"output\")\n\nloss = tf.contrib.losses.mean_squared_error(prediction, output_batch)\n#train_op = slim.learning.create_train_op(loss, tf.train.AdamOptimizer(0.01))\ntrain_op = slim.learning.create_train_op(loss, tf.train.AdamOptimizer(0.001))\n\ninit_op = tf.initialize_all_variables()\n\nwith tf.Session() as sess:\n  coord = tf.train.Coordinator()\n  threads = tf.train.start_queue_runners(sess=sess, coord=coord)\n\n  try:\n    sess.run(init_op)\n    for i in range(30000): #[10000]\n      _, t_loss = sess.run([train_op, loss])\n      if (i+1) % 100 == 0:\n        print(\"%d,%f\" % (i+1, t_loss))\n#        print(\"%d,%f,#step, loss\" % (i+1, t_loss))\n  finally:\n    coord.request_stop()\n\n  coord.join(threads)\n\n\n\nplaceholder\u4f7f\u7528\n\nlinreg2_feeddict.py\n#!/usr/bin/env python\n# -*- coding: utf-8 -*-\n\nimport sys\nimport tensorflow as tf\nimport tensorflow.contrib.slim as slim\n\n# \u30d5\u30a1\u30a4\u30eb\u540d\u306e Queue \u3092\u4f5c\u6210\nfilename_queue = tf.train.string_input_producer([\"input.csv\"])\n\n# CSV \u3092 parse\nreader = tf.TextLineReader()\nkey, value = reader.read(filename_queue)\ninput1, output = tf.decode_csv(value, record_defaults=[[0.], [0.]])\ninputs = tf.pack([input1])\noutput = tf.pack([output])\n\nbatch_size=4 # [4]\ninputs_batch, output_batch = tf.train.shuffle_batch([inputs, output], batch_size, capacity=40, min_after_dequeue=batch_size)\n\ninput_ph = tf.placeholder(\"float\", [None,1])\noutput_ph = tf.placeholder(\"float\",[None,1])\n\n## NN \u306e\u30b0\u30e9\u30d5\u751f\u6210\nhiddens = slim.stack(input_ph, slim.fully_connected, [1,7,7,7], \n  activation_fn=tf.nn.sigmoid, scope=\"hidden\")\nprediction = slim.fully_connected(hiddens, 1, activation_fn=tf.nn.sigmoid, scope=\"output\")\nloss = tf.contrib.losses.mean_squared_error(prediction, output_ph)\n\n#train_op = slim.learning.create_train_op(loss, tf.train.AdamOptimizer(0.01))\ntrain_op = slim.learning.create_train_op(loss, tf.train.AdamOptimizer(0.001))\n\ndef feed_dict(inputs, output):\n    return {input_ph: inputs.eval(), output_ph: output.eval()}\n\ninit_op = tf.initialize_all_variables()\n\nwith tf.Session() as sess:\n  coord = tf.train.Coordinator()\n  threads = tf.train.start_queue_runners(sess=sess, coord=coord)\n\n  try:\n    sess.run(init_op)\n    for i in range(30000): #[10000]\n      _, t_loss = sess.run([train_op, loss], feed_dict=feed_dict(inputs_batch, output_batch))\n      if (i+1) % 100 == 0:\n        print(\"%d,%f\" % (i+1, t_loss))\n#        print(\"%d,%f,#step, loss\" % (i+1, t_loss))\n  finally:\n    coord.request_stop()\n\n  coord.join(threads)\n\n\n\n\u7d50\u679c\npython linreg2.py > log.learn_original\npython linreg2_feeddict.py > log.learn_placeholder\n\nmatplotlib\u30b3\u30fc\u30c9 on Jupyter\n\u53c2\u8003 http://qiita.com/ynakayama/items/8d3b1f7356da5bcbe9bc\n%matplotlib inline\n\nimport numpy as np\nimport matplotlib.pyplot as plt\n\n#data = np.loadtxt('log.learn_non_qmc', delimiter=',')\ndata1 = np.loadtxt('log.learn_original', delimiter=',')\n#data = np.loadtxt('log.learn_original.batch1', delimiter=',')\n#data = np.loadtxt('log.learn_no_reshape', delimiter=',')\ndata2 = np.loadtxt('log.learn_placeholder', delimiter=',')\n\ninput1 = data1[:,0]\noutput1 = data1[:,1]\ninput2 = data2[:,0]\noutput2 = data2[:,1]\n\nfig = plt.figure()\nax1 = fig.add_subplot(2,1,1)\nax2 = fig.add_subplot(2,1,2)\n\n#ax.plot(input1, output1, color='black', linestyle='dotted', label='rate=0.001')\nax1.plot(input1, output1, color='black', linestyle='solid', label='original')\nax2.plot(input2, output2, color='red', linestyle='solid', label='placeholder')\n#ax.scatter(input1, output1)\n\nax1.set_title('loss')\nax1.set_xlabel('step')\nax1.set_ylabel('loss')\nax1.grid(True)\nax1.legend()\n\n#ax2.set_title('loss')\nax2.set_xlabel('step')\nax2.set_ylabel('loss')\nax2.grid(True)\nax2.legend()\n\nfig.show()\n\n\n\n2\u3064\u306e\u30b3\u30fc\u30c9\u306ediff\n$ diff linreg2.py linreg2_feeddict.py \n20a21,23\n> input_ph = tf.placeholder(\"float\", [None,1])\n> output_ph = tf.placeholder(\"float\",[None,1])\n> \n22c25\n< hiddens = slim.stack(inputs_batch, slim.fully_connected, [1,7,7,7], \n---\n> hiddens = slim.stack(input_ph, slim.fully_connected, [1,7,7,7], \n24a28\n> loss = tf.contrib.losses.mean_squared_error(prediction, output_ph)\n26d29\n< loss = tf.contrib.losses.mean_squared_error(prediction, output_batch)\n29a33,35\n> def feed_dict(inputs, output):\n>     return {input_ph: inputs.eval(), output_ph: output.eval()}\n> \n39c45\n<       _, t_loss = sess.run([train_op, loss])\n---\n>       _, t_loss = sess.run([train_op, loss], feed_dict=feed_dict(inputs_batch, output_batch))\n\n```txt:\u52d5\u4f5c\u74b0\u5883\nGeForce GTX 1070 (8GB)\nASRock Z170M Pro4S [Intel Z170chipset]\nUbuntu 14.04 LTS desktop amd64\nTensorFlow v0.11\ncuDNN v5.1 for Linux\nCUDA v8.0\nPython 2.7.6\nIPython 5.1.0 -- An enhanced Interactive Python.\n```\n\nv0.1 http://qiita.com/7of9/items/b364d897b95476a30754\n\nsine curve\u3092\u5b66\u7fd2\u3059\u308b\u30b3\u30fc\u30c9\u3092placeholder\u4f7f\u7528\u306b\u5909\u66f4\u3057\u3066\u3044\u308b\u304closs\u304c0.4\u3092\u4e2d\u5fc3\u3068\u3057\u3066\u3044\u308b\u3002\n\n### input.csv\u751f\u6210\n\nhttp://qiita.com/7of9/items/b364d897b95476a30754#\u30c7\u30fc\u30bf\u751f\u6210\u90e8\n\n### original (placeholder\u4e0d\u4f7f\u7528)\n\n```linreg2.py\n#!/usr/bin/env python\n# -*- coding: utf-8 -*-\n\nimport sys\nimport tensorflow as tf\nimport tensorflow.contrib.slim as slim\n\n# \u30d5\u30a1\u30a4\u30eb\u540d\u306e Queue \u3092\u4f5c\u6210\nfilename_queue = tf.train.string_input_producer([\"input.csv\"])\n\n# CSV \u3092 parse\nreader = tf.TextLineReader()\nkey, value = reader.read(filename_queue)\ninput1, output = tf.decode_csv(value, record_defaults=[[0.], [0.]])\ninputs = tf.pack([input1])\noutput = tf.pack([output])\n\nbatch_size=4 # [4]\ninputs_batch, output_batch = tf.train.shuffle_batch([inputs, output], batch_size, capacity=40, min_after_dequeue=batch_size)\n\n## NN \u306e\u30b0\u30e9\u30d5\u751f\u6210\nhiddens = slim.stack(inputs_batch, slim.fully_connected, [1,7,7,7], \n  activation_fn=tf.nn.sigmoid, scope=\"hidden\")\nprediction = slim.fully_connected(hiddens, 1, activation_fn=tf.nn.sigmoid, scope=\"output\")\n\nloss = tf.contrib.losses.mean_squared_error(prediction, output_batch)\n#train_op = slim.learning.create_train_op(loss, tf.train.AdamOptimizer(0.01))\ntrain_op = slim.learning.create_train_op(loss, tf.train.AdamOptimizer(0.001))\n\ninit_op = tf.initialize_all_variables()\n\nwith tf.Session() as sess:\n  coord = tf.train.Coordinator()\n  threads = tf.train.start_queue_runners(sess=sess, coord=coord)\n\n  try:\n    sess.run(init_op)\n    for i in range(30000): #[10000]\n      _, t_loss = sess.run([train_op, loss])\n      if (i+1) % 100 == 0:\n        print(\"%d,%f\" % (i+1, t_loss))\n#        print(\"%d,%f,#step, loss\" % (i+1, t_loss))\n  finally:\n    coord.request_stop()\n\n  coord.join(threads)\n```\n\n### placeholder\u4f7f\u7528\n\n```linreg2_feeddict.py\n#!/usr/bin/env python\n# -*- coding: utf-8 -*-\n\nimport sys\nimport tensorflow as tf\nimport tensorflow.contrib.slim as slim\n\n# \u30d5\u30a1\u30a4\u30eb\u540d\u306e Queue \u3092\u4f5c\u6210\nfilename_queue = tf.train.string_input_producer([\"input.csv\"])\n\n# CSV \u3092 parse\nreader = tf.TextLineReader()\nkey, value = reader.read(filename_queue)\ninput1, output = tf.decode_csv(value, record_defaults=[[0.], [0.]])\ninputs = tf.pack([input1])\noutput = tf.pack([output])\n\nbatch_size=4 # [4]\ninputs_batch, output_batch = tf.train.shuffle_batch([inputs, output], batch_size, capacity=40, min_after_dequeue=batch_size)\n\ninput_ph = tf.placeholder(\"float\", [None,1])\noutput_ph = tf.placeholder(\"float\",[None,1])\n\n## NN \u306e\u30b0\u30e9\u30d5\u751f\u6210\nhiddens = slim.stack(input_ph, slim.fully_connected, [1,7,7,7], \n  activation_fn=tf.nn.sigmoid, scope=\"hidden\")\nprediction = slim.fully_connected(hiddens, 1, activation_fn=tf.nn.sigmoid, scope=\"output\")\nloss = tf.contrib.losses.mean_squared_error(prediction, output_ph)\n\n#train_op = slim.learning.create_train_op(loss, tf.train.AdamOptimizer(0.01))\ntrain_op = slim.learning.create_train_op(loss, tf.train.AdamOptimizer(0.001))\n\ndef feed_dict(inputs, output):\n    return {input_ph: inputs.eval(), output_ph: output.eval()}\n\ninit_op = tf.initialize_all_variables()\n\nwith tf.Session() as sess:\n  coord = tf.train.Coordinator()\n  threads = tf.train.start_queue_runners(sess=sess, coord=coord)\n\n  try:\n    sess.run(init_op)\n    for i in range(30000): #[10000]\n      _, t_loss = sess.run([train_op, loss], feed_dict=feed_dict(inputs_batch, output_batch))\n      if (i+1) % 100 == 0:\n        print(\"%d,%f\" % (i+1, t_loss))\n#        print(\"%d,%f,#step, loss\" % (i+1, t_loss))\n  finally:\n    coord.request_stop()\n\n  coord.join(threads)\n```\n\n## \u7d50\u679c\n\npython linreg2.py > log.learn_original\npython linreg2_feeddict.py > log.learn_placeholder\n\n### matplotlib\u30b3\u30fc\u30c9 on Jupyter\n\n\u53c2\u8003 http://qiita.com/ynakayama/items/8d3b1f7356da5bcbe9bc\n\n```py\n%matplotlib inline\n\nimport numpy as np\nimport matplotlib.pyplot as plt\n\n#data = np.loadtxt('log.learn_non_qmc', delimiter=',')\ndata1 = np.loadtxt('log.learn_original', delimiter=',')\n#data = np.loadtxt('log.learn_original.batch1', delimiter=',')\n#data = np.loadtxt('log.learn_no_reshape', delimiter=',')\ndata2 = np.loadtxt('log.learn_placeholder', delimiter=',')\n\ninput1 = data1[:,0]\noutput1 = data1[:,1]\ninput2 = data2[:,0]\noutput2 = data2[:,1]\n\nfig = plt.figure()\nax1 = fig.add_subplot(2,1,1)\nax2 = fig.add_subplot(2,1,2)\n\n#ax.plot(input1, output1, color='black', linestyle='dotted', label='rate=0.001')\nax1.plot(input1, output1, color='black', linestyle='solid', label='original')\nax2.plot(input2, output2, color='red', linestyle='solid', label='placeholder')\n#ax.scatter(input1, output1)\n\nax1.set_title('loss')\nax1.set_xlabel('step')\nax1.set_ylabel('loss')\nax1.grid(True)\nax1.legend()\n\n#ax2.set_title('loss')\nax2.set_xlabel('step')\nax2.set_ylabel('loss')\nax2.grid(True)\nax2.legend()\n\nfig.show()\n```\n\n\n![qiita.png](https://qiita-image-store.s3.amazonaws.com/0/32870/8d1e5f24-ba02-d337-9862-1eac04ad8303.png)\n\n\n\n### 2\u3064\u306e\u30b3\u30fc\u30c9\u306ediff\n\n```py\n$ diff linreg2.py linreg2_feeddict.py \n20a21,23\n> input_ph = tf.placeholder(\"float\", [None,1])\n> output_ph = tf.placeholder(\"float\",[None,1])\n> \n22c25\n< hiddens = slim.stack(inputs_batch, slim.fully_connected, [1,7,7,7], \n---\n> hiddens = slim.stack(input_ph, slim.fully_connected, [1,7,7,7], \n24a28\n> loss = tf.contrib.losses.mean_squared_error(prediction, output_ph)\n26d29\n< loss = tf.contrib.losses.mean_squared_error(prediction, output_batch)\n29a33,35\n> def feed_dict(inputs, output):\n>     return {input_ph: inputs.eval(), output_ph: output.eval()}\n> \n39c45\n<       _, t_loss = sess.run([train_op, loss])\n---\n>       _, t_loss = sess.run([train_op, loss], feed_dict=feed_dict(inputs_batch, output_batch))\n```\n", "tags": ["TensorFlow", "borgWarp"]}