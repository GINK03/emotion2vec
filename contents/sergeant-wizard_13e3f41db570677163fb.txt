{"context": " More than 1 year has passed since last update.\n\n\u6982\u8981\nNaive Bayes Classifier (Wikipedia)\u306f\u30d9\u30a4\u30ba\u306e\u5b9a\u7406\u3092\u7528\u3044\u305f\u6559\u5e2b\u3042\u308a\u306e\u5206\u985e\u5668\u3067\u3001\u30e2\u30c7\u30eb\u306e\u66f4\u65b0\u306e\u3057\u3084\u3059\u3055\u3068\u30c1\u30e5\u30fc\u30cb\u30f3\u30b0\u306e\u3057\u3084\u3059\u3055\u304c\u7279\u5fb4\u3067\u3059[1]\u3002\nnn\u500b\u306e\u5165\u529b\u30d5\u30a3\u30fc\u30c1\u30e3\u30fc(x1,\u22ef,xn)(x_1, \\cdots, x_n)\u3068\u5206\u985e\u30af\u30e9\u30b9Ck(k\u2208K)C_k (k \\in K)\u306b\u5bfe\u3057\u3066\u3001\u4ee5\u4e0b\u306e\u3088\u3046\u306b\u5c24\u5ea6\u304c\u6700\u5927\u3068\u306a\u308b\u30af\u30e9\u30b9\u3092\u63a2\u3057\u307e\u3059\u3002\n\\mathrm{argmax}_{k \\in K} \\left( \\ln P(C_k) + \\sum_{i=1}^n \\ln P(x_i \\vert C_k) \\right)\n\\tag{1}\nargmaxk\u2208K(lnP(Ck)+n\u2211i=1lnP(xi|Ck)){\\mathrm{argmax}_{k \\in K} \\left( \\ln P(C_k) + \\sum_{i=1}^n \\ln P(x_i \\vert C_k) \\right)\n\\tag{1}\n}\n\nGaussian Naive Bayes\n\u5165\u529bxix_i\u304c\u96e2\u6563\u5024\u306e\u5834\u5408\u3001P(xi|Ck)P(x_i|C_k)\u306e\u5024\u306f\u6559\u5e2b\u30e9\u30d9\u30ebCkC_k\u306b\u8a72\u5f53\u3059\u308bxix_i\u306e\u5165\u529b\u306e\u6570\u3092\u6570\u3048\u308c\u3070\u3044\u3044\u306e\u3067\u81ea\u660e\u3067\u3059\u3002\n\u5165\u529bxix_i\u304c\u9023\u7d9a\u5024\u306e\u5834\u5408\u3067\u305d\u306e\u78ba\u7387\u5bc6\u5ea6\u95a2\u6570\u3092\u6b63\u898f\u5206\u5e03\u3068\u898b\u7acb\u3066\u308b\u5206\u985e\u5668\u3092Gaussian Naive Bayes\u3068\u547c\u3073\u307e\u3059\u3002\n\u3059\u306a\u308f\u3061\u3001\nP(x_i = x \\vert C_k) = \\frac{\\exp{\\left(-\\frac{(x-\\mu)^2}{2 \\sigma^2}\\right)}}{\\sqrt{2\\pi \\sigma^2}}\n\\tag{2}\nP(xi=x|Ck)=exp(\u2212(x\u2212\u03bc)22\u03c32)\u221a2\u03c0\u03c32{P(x_i = x \\vert C_k) = \\frac{\\exp{\\left(-\\frac{(x-\\mu)^2}{2 \\sigma^2}\\right)}}{\\sqrt{2\\pi \\sigma^2}}\n\\tag{2}\n}\n\n\u5b9f\u88c5\n\n\u5206\u985e\u30af\u30e9\u30b9\u6bce\u3001\u5165\u529b\u30d5\u30a3\u30fc\u30c1\u30e3\u30fc\u6bce\u306b\u6b63\u898f\u5206\u5e03\u306e\u30d1\u30e9\u30e1\u30fc\u30bf\uff08\u5e73\u5747\u5024\u3001\u5206\u6563\uff09\u3092\u8a08\u7b97\u3059\u308b\n\u5f0f(2)(2)\u306e\u30ac\u30a6\u30b9\u5206\u5e03\u306f\u5206\u985e\u30af\u30e9\u30b9\u6bce\u3001\u5165\u529b\u30d5\u30a3\u30fc\u30c1\u30e3\u30fc\u6bce\u306b\u8a08\u7b97\u3059\u308b\u5fc5\u8981\u304c\u3042\u308b\u306e\u3067\u3001\u4ee5\u4e0b\u306e\u3088\u3046\u306b\u6c42\u3081\u3066\u304a\u304d\u307e\u3059\u3002\ndef get_gaussian_params(input, target):\n  num_input_type = input.shape[1]\n  klasses = numpy.unique(target)\n  mean     = numpy.empty([numpy.size(klasses), num_input_type])\n  variance = numpy.empty([numpy.size(klasses), num_input_type])\n  for klass in klasses:\n    input_in_class = input[target == klass]\n    for input_type in range(num_input_type):\n      mean[klass, input_type] = numpy.mean(input_in_class[:, input_type])\n      variance[klass, input_type] = numpy.var(input_in_class[:, input_type])\n  return mean, variance\n\n\n\u4e0e\u3048\u3089\u308c\u305f\u5404\u5165\u529b\u30c7\u30fc\u30bf\u6bce\u306b\u5c24\u5ea6\u304c\u6700\u5927\u3068\u306a\u308b\u30af\u30e9\u30b9\u3092\u6c42\u3081\u308b\n\u5f0f(1)(1)\u306b\u5f93\u3063\u305f\u5c24\u5ea6\u306e\u8a08\u7b97\u3067\u3059\u3002\u305f\u3060\u3057\u4eca\u56de\u53d6\u308a\u6271\u3046\u554f\u984c\u3067\u306f\u5404\u30af\u30e9\u30b9\u306b\u6240\u5c5e\u3059\u308b\u30c7\u30fc\u30bf\u6570\u306f\u7b49\u3057\u3044\u306e\u3067\u5f0f(1)(1)\u306e\u6700\u521d\u306e\u9805\u306f\u7701\u7565\u3057\u3066\u3044\u307e\u3059\u3002\ndef gaussian_naive_bayes(input, target):\n  means, variances = get_gaussian_params(input, target)\n  num_class_type, num_input_type = means.shape\n  input_size = input.shape[0]\n  estimated_class = numpy.empty(input_size)\n  for data_index in range(input_size):\n    likelihood = numpy.zeros(num_class_type)\n    for class_type in range(num_class_type):\n      for input_type in range(num_input_type):\n        mean = means[class_type, input_type]\n        variance = variances[class_type, input_type]\n        likelihood[class_type] += numpy.log(gaussian(input[data_index][input_type], mean, variance))\n    estimated_class[data_index] = numpy.argmax(likelihood)\n  return estimated_class\n\n\n\u691c\u8a3c\nsklearn\u3067\u63d0\u4f9b\u3055\u308c\u3066\u3044\u308b\u30a2\u30e4\u30e1(iris)\u306e\u30c7\u30fc\u30bf\u3092\u4f7f\u7528\u3057\u307e\u3059\u3002\n\u30a2\u30e4\u30e1\u306e\u30c7\u30fc\u30bf\u306f\u4ee5\u4e0b\u306e\u901a\u308a\u3067\u3059\u3002\n- \u5165\u529b\u30d5\u30a3\u30fc\u30c1\u30e3\u30fc : [\"Sepal.Width\", \"Sepal.Length\", \"Petal.Width\", \"Petal.Length\"]\u306e4\u7a2e\u985e\u306e\u5b9f\u6570\u5024\n- \u5206\u985e\u30af\u30e9\u30b9 : \u30a2\u30e4\u30e1\u306e\u7a2e [\"Setosa\", \"Versicolor\", \"Virginica\"]\u3092\u8868\u3059[0, 1, 2]\u306e\u3044\u305a\u308c\u304b\n\u4ee5\u4e0b\u306e\u3088\u3046\u306b\u3001\u8aa4\u3063\u305f\u5206\u985e\u306e\u6570\u3092\u51fa\u529b\u3057\u307e\u3059\u3002\nfrom sklearn import datasets\niris = datasets.load_iris()\nprint numpy.count_nonzero(gaussian_naive_bayes(iris.data, iris.target) - iris.target)\n\n\u51fa\u529b\u7d50\u679c\n6\n\n150\u500b\u4e2d6\u500b\u306a\u306e\u3067\u30014%\u306e\u8aa4\u7b54\u7387\u3068\u306a\u308a\u307e\u3057\u305f\u3002\n\u53c2\u8003\u6587\u732e[2]\u306b\u8a18\u8f09\u3055\u308c\u3066\u3044\u308b\u3001scikit-learn\u306eNaive Bayes\u306e\u5b9f\u88c5\u306e\u8aa4\u7b54\u65706\u3068\u4e00\u81f4\u3057\u307e\u3057\u305f\u3002\n\u4eca\u56de\u306f\u7c21\u4fbf\u5316\u306e\u305f\u3081\u306b\u8a13\u7df4\u30c7\u30fc\u30bf\u3068\u30c6\u30b9\u30c8\u30c7\u30fc\u30bf\u3067\u540c\u3058\u3082\u306e\u3092\u4f7f\u7528\u3057\u3066\u3044\u307e\u3059\u304c\u3001\u4e00\u822c\u7684\u306b\u306f\u3053\u308c\u306f\u826f\u3044\u78ba\u8a8d\u65b9\u6cd5\u3067\u306f\u306a\u304f\u3001\u4ee3\u66ff\u65b9\u6cd5\u3068\u3057\u3066\u30db\u30fc\u30eb\u30c9\u30a2\u30a6\u30c8\u6cd5\u3084\u4ea4\u5dee\u78ba\u8a8d\u6cd5\u7b49\u304c\u63d0\u6848\u3055\u308c\u3066\u3044\u307e\u3059[2]\u3002\n\n\u53c2\u8003\u6587\u732e\n\n[1]\u30c7\u30fc\u30bf\u30b5\u30a4\u30a8\u30f3\u30c6\u30a3\u30b9\u30c8\u990a\u6210\u8aad\u672c\u3000\u6a5f\u68b0\u5b66\u7fd2\u5165\u9580\u7de8\n[2]\u306f\u3058\u3081\u3066\u306e\u30d1\u30bf\u30fc\u30f3\u8a8d\u8b58\n\n\n(\u53c2\u8003)\u5168\u30b3\u30fc\u30c9\nimport numpy\nfrom sklearn import datasets\n\ndef gaussian(x, mean, variance):\n  return numpy.exp(-numpy.power(x - mean, 2.) / (2. * variance)) / numpy.sqrt(variance)\n\ndef get_gaussian_params(input, target):\n  num_input_type = input.shape[1]\n  klasses = numpy.unique(target)\n  mean     = numpy.empty([numpy.size(klasses), num_input_type])\n  variance = numpy.empty([numpy.size(klasses), num_input_type])\n  for klass in klasses:\n    input_in_class = input[target == klass]\n    for input_type in range(num_input_type):\n      mean[klass, input_type] = numpy.mean(input_in_class[:, input_type])\n      variance[klass, input_type] = numpy.var(input_in_class[:, input_type])\n  return mean, variance\n\ndef gaussian_naive_bayes(input, target):\n  means, variances = get_gaussian_params(input, target)\n  num_class_type, num_input_type = means.shape\n  input_size = input.shape[0]\n  estimated_class = numpy.empty(input_size)\n  for data_index in range(input_size):\n    likelihood = numpy.zeros(num_class_type)\n    for class_type in range(num_class_type):\n      for input_type in range(num_input_type):\n        mean = means[class_type, input_type]\n        variance = variances[class_type, input_type]\n        likelihood[class_type] += numpy.log(gaussian(input[data_index][input_type], mean, variance))\n    estimated_class[data_index] = numpy.argmax(likelihood)\n  return estimated_class\n\niris = datasets.load_iris()\nprint numpy.count_nonzero(gaussian_naive_bayes(iris.data, iris.target) - iris.target)\n\n# \u6982\u8981\n\n[Naive Bayes Classifier (Wikipedia)](https://en.wikipedia.org/wiki/Naive_Bayes_classifier)\u306f\u30d9\u30a4\u30ba\u306e\u5b9a\u7406\u3092\u7528\u3044\u305f\u6559\u5e2b\u3042\u308a\u306e\u5206\u985e\u5668\u3067\u3001\u30e2\u30c7\u30eb\u306e\u66f4\u65b0\u306e\u3057\u3084\u3059\u3055\u3068\u30c1\u30e5\u30fc\u30cb\u30f3\u30b0\u306e\u3057\u3084\u3059\u3055\u304c\u7279\u5fb4\u3067\u3059[1]\u3002\n$n$\u500b\u306e\u5165\u529b\u30d5\u30a3\u30fc\u30c1\u30e3\u30fc$(x_1, \\cdots, x_n)$\u3068\u5206\u985e\u30af\u30e9\u30b9$C_k (k \\in K)$\u306b\u5bfe\u3057\u3066\u3001\u4ee5\u4e0b\u306e\u3088\u3046\u306b\u5c24\u5ea6\u304c\u6700\u5927\u3068\u306a\u308b\u30af\u30e9\u30b9\u3092\u63a2\u3057\u307e\u3059\u3002\n\n```math\n\\mathrm{argmax}_{k \\in K} \\left( \\ln P(C_k) + \\sum_{i=1}^n \\ln P(x_i \\vert C_k) \\right)\n\\tag{1}\n```\n\n# Gaussian Naive Bayes\n\n\u5165\u529b$x_i$\u304c\u96e2\u6563\u5024\u306e\u5834\u5408\u3001$P(x_i|C_k)$\u306e\u5024\u306f\u6559\u5e2b\u30e9\u30d9\u30eb$C_k$\u306b\u8a72\u5f53\u3059\u308b$x_i$\u306e\u5165\u529b\u306e\u6570\u3092\u6570\u3048\u308c\u3070\u3044\u3044\u306e\u3067\u81ea\u660e\u3067\u3059\u3002\n\u5165\u529b$x_i$\u304c\u9023\u7d9a\u5024\u306e\u5834\u5408\u3067\u305d\u306e\u78ba\u7387\u5bc6\u5ea6\u95a2\u6570\u3092\u6b63\u898f\u5206\u5e03\u3068\u898b\u7acb\u3066\u308b\u5206\u985e\u5668\u3092Gaussian Naive Bayes\u3068\u547c\u3073\u307e\u3059\u3002\n\u3059\u306a\u308f\u3061\u3001\n\n```math\nP(x_i = x \\vert C_k) = \\frac{\\exp{\\left(-\\frac{(x-\\mu)^2}{2 \\sigma^2}\\right)}}{\\sqrt{2\\pi \\sigma^2}}\n\\tag{2}\n```\n\n# \u5b9f\u88c5\n\n## \u5206\u985e\u30af\u30e9\u30b9\u6bce\u3001\u5165\u529b\u30d5\u30a3\u30fc\u30c1\u30e3\u30fc\u6bce\u306b\u6b63\u898f\u5206\u5e03\u306e\u30d1\u30e9\u30e1\u30fc\u30bf\uff08\u5e73\u5747\u5024\u3001\u5206\u6563\uff09\u3092\u8a08\u7b97\u3059\u308b\n\n\u5f0f$(2)$\u306e\u30ac\u30a6\u30b9\u5206\u5e03\u306f\u5206\u985e\u30af\u30e9\u30b9\u6bce\u3001\u5165\u529b\u30d5\u30a3\u30fc\u30c1\u30e3\u30fc\u6bce\u306b\u8a08\u7b97\u3059\u308b\u5fc5\u8981\u304c\u3042\u308b\u306e\u3067\u3001\u4ee5\u4e0b\u306e\u3088\u3046\u306b\u6c42\u3081\u3066\u304a\u304d\u307e\u3059\u3002\n\n```py\ndef get_gaussian_params(input, target):\n  num_input_type = input.shape[1]\n  klasses = numpy.unique(target)\n  mean     = numpy.empty([numpy.size(klasses), num_input_type])\n  variance = numpy.empty([numpy.size(klasses), num_input_type])\n  for klass in klasses:\n    input_in_class = input[target == klass]\n    for input_type in range(num_input_type):\n      mean[klass, input_type] = numpy.mean(input_in_class[:, input_type])\n      variance[klass, input_type] = numpy.var(input_in_class[:, input_type])\n  return mean, variance\n```\n\n## \u4e0e\u3048\u3089\u308c\u305f\u5404\u5165\u529b\u30c7\u30fc\u30bf\u6bce\u306b\u5c24\u5ea6\u304c\u6700\u5927\u3068\u306a\u308b\u30af\u30e9\u30b9\u3092\u6c42\u3081\u308b\n\n\u5f0f$(1)$\u306b\u5f93\u3063\u305f\u5c24\u5ea6\u306e\u8a08\u7b97\u3067\u3059\u3002\u305f\u3060\u3057\u4eca\u56de\u53d6\u308a\u6271\u3046\u554f\u984c\u3067\u306f\u5404\u30af\u30e9\u30b9\u306b\u6240\u5c5e\u3059\u308b\u30c7\u30fc\u30bf\u6570\u306f\u7b49\u3057\u3044\u306e\u3067\u5f0f$(1)$\u306e\u6700\u521d\u306e\u9805\u306f\u7701\u7565\u3057\u3066\u3044\u307e\u3059\u3002\n\n```py\ndef gaussian_naive_bayes(input, target):\n  means, variances = get_gaussian_params(input, target)\n  num_class_type, num_input_type = means.shape\n  input_size = input.shape[0]\n  estimated_class = numpy.empty(input_size)\n  for data_index in range(input_size):\n    likelihood = numpy.zeros(num_class_type)\n    for class_type in range(num_class_type):\n      for input_type in range(num_input_type):\n        mean = means[class_type, input_type]\n        variance = variances[class_type, input_type]\n        likelihood[class_type] += numpy.log(gaussian(input[data_index][input_type], mean, variance))\n    estimated_class[data_index] = numpy.argmax(likelihood)\n  return estimated_class\n```\n\n# \u691c\u8a3c\n\n[sklearn](http://scikit-learn.org/stable/)\u3067\u63d0\u4f9b\u3055\u308c\u3066\u3044\u308b\u30a2\u30e4\u30e1(iris)\u306e\u30c7\u30fc\u30bf\u3092\u4f7f\u7528\u3057\u307e\u3059\u3002\n\u30a2\u30e4\u30e1\u306e\u30c7\u30fc\u30bf\u306f\u4ee5\u4e0b\u306e\u901a\u308a\u3067\u3059\u3002\n- \u5165\u529b\u30d5\u30a3\u30fc\u30c1\u30e3\u30fc : `[\"Sepal.Width\", \"Sepal.Length\", \"Petal.Width\", \"Petal.Length\"]`\u306e4\u7a2e\u985e\u306e**\u5b9f\u6570\u5024**\n- \u5206\u985e\u30af\u30e9\u30b9 : \u30a2\u30e4\u30e1\u306e\u7a2e `[\"Setosa\", \"Versicolor\", \"Virginica\"]`\u3092\u8868\u3059`[0, 1, 2]`\u306e\u3044\u305a\u308c\u304b\n\n\u4ee5\u4e0b\u306e\u3088\u3046\u306b\u3001\u8aa4\u3063\u305f\u5206\u985e\u306e\u6570\u3092\u51fa\u529b\u3057\u307e\u3059\u3002\n\n```py\nfrom sklearn import datasets\niris = datasets.load_iris()\nprint numpy.count_nonzero(gaussian_naive_bayes(iris.data, iris.target) - iris.target)\n```\n\n\u51fa\u529b\u7d50\u679c\n\n```\n6\n```\n\n150\u500b\u4e2d6\u500b\u306a\u306e\u3067\u30014%\u306e\u8aa4\u7b54\u7387\u3068\u306a\u308a\u307e\u3057\u305f\u3002\n\u53c2\u8003\u6587\u732e[2]\u306b\u8a18\u8f09\u3055\u308c\u3066\u3044\u308b\u3001`scikit-learn`\u306eNaive Bayes\u306e\u5b9f\u88c5\u306e\u8aa4\u7b54\u65706\u3068\u4e00\u81f4\u3057\u307e\u3057\u305f\u3002\n\n\u4eca\u56de\u306f\u7c21\u4fbf\u5316\u306e\u305f\u3081\u306b\u8a13\u7df4\u30c7\u30fc\u30bf\u3068\u30c6\u30b9\u30c8\u30c7\u30fc\u30bf\u3067\u540c\u3058\u3082\u306e\u3092\u4f7f\u7528\u3057\u3066\u3044\u307e\u3059\u304c\u3001\u4e00\u822c\u7684\u306b\u306f\u3053\u308c\u306f\u826f\u3044\u78ba\u8a8d\u65b9\u6cd5\u3067\u306f\u306a\u304f\u3001\u4ee3\u66ff\u65b9\u6cd5\u3068\u3057\u3066\u30db\u30fc\u30eb\u30c9\u30a2\u30a6\u30c8\u6cd5\u3084\u4ea4\u5dee\u78ba\u8a8d\u6cd5\u7b49\u304c\u63d0\u6848\u3055\u308c\u3066\u3044\u307e\u3059[2]\u3002\n\n# \u53c2\u8003\u6587\u732e\n\n- [[1]\u30c7\u30fc\u30bf\u30b5\u30a4\u30a8\u30f3\u30c6\u30a3\u30b9\u30c8\u990a\u6210\u8aad\u672c\u3000\u6a5f\u68b0\u5b66\u7fd2\u5165\u9580\u7de8](http://www.amazon.co.jp/dp/B0152OV4VW/ref=pe_492632_166382082_TE_M1T1DP)\n- [[2]\u306f\u3058\u3081\u3066\u306e\u30d1\u30bf\u30fc\u30f3\u8a8d\u8b58](http://www.amazon.co.jp/%E3%81%AF%E3%81%98%E3%82%81%E3%81%A6%E3%81%AE%E3%83%91%E3%82%BF%E3%83%BC%E3%83%B3%E8%AA%8D%E8%AD%98-%E5%B9%B3%E4%BA%95-%E6%9C%89%E4%B8%89/dp/4627849710/ref=sr_1_1?ie=UTF8&qid=1448360850&sr=8-1&keywords=%E3%81%AF%E3%81%98%E3%82%81%E3%81%A6%E3%81%AE%E3%83%91%E3%82%BF%E3%83%BC%E3%83%B3%E8%AA%8D%E8%AD%98)\n\n# (\u53c2\u8003)\u5168\u30b3\u30fc\u30c9\n\n```py\nimport numpy\nfrom sklearn import datasets\n\ndef gaussian(x, mean, variance):\n  return numpy.exp(-numpy.power(x - mean, 2.) / (2. * variance)) / numpy.sqrt(variance)\n\ndef get_gaussian_params(input, target):\n  num_input_type = input.shape[1]\n  klasses = numpy.unique(target)\n  mean     = numpy.empty([numpy.size(klasses), num_input_type])\n  variance = numpy.empty([numpy.size(klasses), num_input_type])\n  for klass in klasses:\n    input_in_class = input[target == klass]\n    for input_type in range(num_input_type):\n      mean[klass, input_type] = numpy.mean(input_in_class[:, input_type])\n      variance[klass, input_type] = numpy.var(input_in_class[:, input_type])\n  return mean, variance\n\ndef gaussian_naive_bayes(input, target):\n  means, variances = get_gaussian_params(input, target)\n  num_class_type, num_input_type = means.shape\n  input_size = input.shape[0]\n  estimated_class = numpy.empty(input_size)\n  for data_index in range(input_size):\n    likelihood = numpy.zeros(num_class_type)\n    for class_type in range(num_class_type):\n      for input_type in range(num_input_type):\n        mean = means[class_type, input_type]\n        variance = variances[class_type, input_type]\n        likelihood[class_type] += numpy.log(gaussian(input[data_index][input_type], mean, variance))\n    estimated_class[data_index] = numpy.argmax(likelihood)\n  return estimated_class\n\niris = datasets.load_iris()\nprint numpy.count_nonzero(gaussian_naive_bayes(iris.data, iris.target) - iris.target)\n```\n", "tags": ["numpy", "NaiveBayes", "MachineLearning", "\u6a5f\u68b0\u5b66\u7fd2"]}