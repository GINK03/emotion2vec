{"context": " More than 1 year has passed since last update.tkazusa\u3055\u3093\u306e\u5b9f\u88c5\u3092\u898b\u3066\u611f\u5316\u3055\u308c\u305f\u306e\u3067\u3084\u3063\u3066\u307f\u307e\u3057\u305f\n\u30cb\u30e5\u30fc\u30e9\u30eb\u30cd\u30c3\u30c8\u306f\u7dda\u5f62\u56de\u5e30\u30e2\u30c7\u30eb\u3084\u30af\u30e9\u30b9\u5206\u985e\u30e2\u30c7\u30eb\u3067\u51fa\u3066\u304d\u305f\u7279\u5fb4\u91cf\u3092\u4f5c\u6210\u3059\u308bbasis\u95a2\u6570 \u03d5(x)\\phi(x)\u3092\u96a0\u308c\u5c64\u3067\u4f5c\u3063\u3066\u3057\u307e\u304a\u3046\u3001\u305d\u3093\u3067\u305d\u306e\u30d1\u30e9\u30e1\u30fc\u30bf\u3082\u66f4\u65b0\u3057\u3066\u3057\u307e\u304a\u3046\u3068\u3044\u3046\u3001\u3042\u308b\u610f\u5473\u7a76\u6975\u306b\u30c7\u30fc\u30bf\u306b\u5408\u308f\u305b\u3066\u3044\u304f\u3088\u3046\u306a\u3001\u305d\u3093\u306a\u30a4\u30e1\u30fc\u30b8\n\n\u3084\u308b\u3053\u3068\u3068\u304b\u5f0f\u3068\u304b\n\u30cb\u30e5\u30fc\u30e9\u30eb\u30cd\u30c3\u30c8\u306b\u3088\u308b\u56de\u5e30\u554f\u984c\u3092\u89e3\u304d\u307e\u3059\u3002\n\u8aa4\u5dee\u95a2\u6570\u306f\u3001\u3088\u304f\u3042\u308b\u4e8c\u4e57\u30ed\u30b9\u3092\u7528\u3044\u3066\u3001\u51fa\u529b\u5c64\u306e\u6d3b\u6027\u5316\u95a2\u6570\u306f\u7dda\u5f62\uff08f(x)=xf(x)=x)\u3001\u96a0\u308c\u5c64\u306e\u6d3b\u6027\u5316\u95a2\u6570h(x)h(x)\u306b\u306f\u3001tanh(x)tanh(x)\u3092\u7528\u3044\u307e\u3059\u3002\n\u306a\u306e\u3067\u6700\u7d42\u7684\u306a\u51fa\u529b\u306f\u4ee5\u4e0b\u306e\u69d8\u306a\u611f\u3058\u3002\n\\begin{align}\ny_n&=f(\\sum_{j=1}^M w_{kj}^{(2)} \\tanh(\\sum_{i=1}^D w_{ji}^{(1)}x_i+w_{j0}^{(0)})+w_{k0}^{(2)})\\\\\n&=\\sum_{j=1}^M w_{kj}^{(2)} \\tanh(\\sum_{i=1}^D w_{ji}^{(1)}x_i+w_{j0}^{(0)})+w_{k0}^{(2)}\n\\end{align}\nyn=f(M\u2211j=1w(2)kjtanh(D\u2211i=1w(1)jixi+w(0)j0)+w(2)k0)=M\u2211j=1w(2)kjtanh(D\u2211i=1w(1)jixi+w(0)j0)+w(2)k0{\\begin{align}\ny_n&=f(\\sum_{j=1}^M w_{kj}^{(2)} \\tanh(\\sum_{i=1}^D w_{ji}^{(1)}x_i+w_{j0}^{(0)})+w_{k0}^{(2)})\\\\\n&=\\sum_{j=1}^M w_{kj}^{(2)} \\tanh(\\sum_{i=1}^D w_{ji}^{(1)}x_i+w_{j0}^{(0)})+w_{k0}^{(2)}\n\\end{align}\n}\n\u51fa\u529b\u304c\u6c7a\u5b9a\u3059\u308c\u3070\u3001\u8aa4\u5dee\u95a2\u6570\u304c\u6c42\u307e\u308a\u307e\u3059\u3002\nE(w)=\\sum_{n=1}^N ||y_n-t_n||_2^2\nE(w)=N\u2211n=1||yn\u2212tn||22{E(w)=\\sum_{n=1}^N ||y_n-t_n||_2^2\n}\n\u3042\u3068\u306f\u3001\u5358\u7d14\u306b\u8aa4\u5dee\u95a2\u6570\u3092\u91cd\u307fw\u3067\u5fae\u5206\u3057\u305f\u52fe\u914d\u3092\u7528\u3044\u3066\u3001w\u3092\u66f4\u65b0\u3059\u308b\u308f\u3051\u3067\u3059\u304c\u3001\u3053\u3053\u3067\u306f\u3001\u8aa4\u5dee\u95a2\u6570\u304c\u30c7\u30fc\u30bf\u306e\u6570\u306e\u8db3\u3057\u7b97\u3067\u8868\u3059\u3053\u3068\u304c\u3067\u304d\u308b\u3053\u3068\u3092\u4f7f\u3063\u305f\u3001SGD\u3092\u7528\u3044\u3066\u66f4\u65b0\u3092\u3057\u307e\u3059\u3002\n\u7c21\u5358\u306b\u8a00\u3063\u3066\u3057\u307e\u3048\u3070\u3001\u8aa4\u5dee\u95a2\u6570\u5168\u4f53\u306e\u52fe\u914d\u8a08\u7b97\u306b\u306f\u6642\u9593\u304c\u304b\u304b\u308b\u306e\u3067\u3001\u30c7\u30fc\u30bf\u70b9\u3072\u3068\u3064\u306b\u5bfe\u3059\u308b\u52fe\u914d\u3092\u8a08\u7b97\u3057\u3066\u3001\u305d\u308c\u3092\u4f7f\u3063\u3066\u3061\u3087\u3063\u3068\u3060\u3051w\u306e\u66f4\u65b0\u3092\u3059\u308b\u3001\u3068\u3044\u3046\u4f5c\u696d\u3092\u591a\u6570\u7e70\u308a\u8fd4\u3057\u3066\u3001\u8aa4\u5dee\u95a2\u6570\u5168\u4f53\u3067\u306e\u52fe\u914d\u306e\u8a08\u7b97\u3092\u56de\u907f\u3057\u306a\u304c\u3089\u6700\u9069\u89e3\u3092\u6c42\u3081\u3066\u3044\u304f\u3001\u3068\u3044\u3046\u65b9\u6cd5\u304cSGD\u3067\u3059\u3002\n\n\u5b9f\u88c5\n\u5b9f\u88c5\u306e\u30b3\u30fc\u30c9\u3067\u3059\u3002\u672c\u5f53\u306f\u30c7\u30fc\u30bf\u30bb\u30c3\u30c8\u6bce\u306b\u4e26\u5217\u8a08\u7b97\u3068\u304b\u3057\u305f\u304b\u3063\u305f\u3093\u3067\u3059\u304c\u3001\u306a\u3093\u304b\u3046\u307e\u304f\u3044\u304b\u306a\u3044\u2026\u2026\u306e\u3067\u3084\u3063\u3066\u307e\u305b\u3093\u3002\n\u30a4\u30f3\u30b9\u30bf\u30f3\u30b9\u4f5c\u6210\u6642\u306b\u3001\u5165\u51fa\u529b\u53ca\u3073\u96a0\u308c\u5c64\u306e\u6b21\u5143\u3092\u3044\u308c\u3066\u3001Fit\u3092\u5b9f\u884c\u3057\u3066\u5b66\u7fd2\u3057\u307e\u3059\u3002\n#coding:utf-8\nimport numpy as np\nimport matplotlib.pyplot as plt\n#import multiprocessing as mp\nimport seaborn as sns\n\nclass NeuralNet():\n    def __init__(self,input=1,output=1,hidden=3):\n        self.input = input\n        self.output = output\n        self.hidden = hidden\n        self.w_1 = np.random.rand(self.input+1,self.hidden)*2.-1.\n        self.w_2 = np.random.rand(self.hidden+1,self.output)*2.-1.\n        np.random.seed(71) #\u518d\u73fe\u6027\u306e\u305f\u3081\n\n    def predict(self,x):\n        \"\"\"\n        predict target value.\n        x: x value for predict.numpy.ndarray like.\n        return predict value.numpy.ndarray like\n        \"\"\"\n        A = self.w_1[1:].dot(x)+self.w_1[0]\n        Z = np.tanh(A)\n        Y = self.w_2[1:].T.dot(Z.T)+self.w_2[0]\n        self.Z = Z\n        return Y[0]\n\n    def Fit(self,X,t,epoch=1000,eta=.1):\n        \"\"\"\n        Fitting Parameters\n        X:  Training Data X value.numpy.ndarray like\n        t:  target value.ndarray like\n        epoch: number of iteration (whole dataset)\n        eta: learning rate with one gradient.\n        return void\n        \"\"\"\n        self.X = X\n        self.t = t\n        self.eta = eta\n        error_list = []\n        for n in range(epoch):\n            if n%50 == 0:\n                error_list.append([n+1,self._compute_error()])\n\n            for x_i,t_i in zip(X,t):\n                delta_k = self.predict(np.array((x_i)))-t_i\n                delta_j = (1-self.Z**2)*self.w_2[1:].dot(delta_k)\n                # print \"self.Z\",self.Z\n                # print \"delta_k:\",delta_k\n                # print \"delta_j:\",delta_j\n                # print \"self.w1\",self.w_1\n                # print \"w2:\",self.w_2\n\n                #\u30d0\u30a4\u30a2\u30b9\u9805\u306f\u5e38\u306bdelta_j,k\u306b\u3088\u308a\u66f4\u65b0\uff08x_0=1.\u3067\u56fa\u5b9a\u306a\u305f\u3081\uff09\n                self.w_1[0] = self.w_1[0] - eta * delta_j\n                self.w_2[0] = self.w_2[0] - eta * delta_k\n\n                self.w_1[1:] = self.w_1[1:] - eta * np.outer(np.array((x_i)),delta_j)\n                self.w_2[1:] = self.w_2[1:] - eta * np.outer(self.Z,delta_k)\n        self.errors = np.array(error_list)\n        return\n\n    def _compute_error(self):\n        \"\"\"\n        Compute loss function.(sum of squares)\n        return: error whole dataset.\n        \"\"\"\n        error = 0.\n        for X_n,t_n in zip(self.X,self.t):\n            error = error + sum(self.predict(np.array((X_n)))-t_n)**2\n        return error\n\ntarget_val_list = []\nx_train = np.linspace(-1,1,50)\ntarget_val_list.append(np.sin(x_train*np.pi))\ntarget_val_list.append(x_train**2)\ntarget_val_list.append(np.abs(x_train))\ntarget_val_list.append((np.sign(x_train)+1)*.5)\n\ndef subcalc(p):#p=0,1,......\n    target_val = target_val_list[p]\n    neural_net = NeuralNet(input=1,output=1,hidden=3)\n    neural_net.Fit(x_train,target_val)\n    pred = []\n    for x in x_train:\n        pred.append(neural_net.predict(np.array(x)))\n    return [pred,neural_net.errors]\n\nproc = len(target_val_list)\n#pool = mp.Pool(proc)\n#callback = pool.map(subcalc,range(proc))\n\ncallback = []\nfor i in range(len(target_val_list)):\n    callback.append(subcalc(i))\n\npred_list = []\nerror_list = []\nfor i in range(proc):\n    pred_list.append(callback[i][0])\n    error_list.append(callback[i][1])\n\ntest_num = len(target_val_list)\nfor i,(pred,target_val) in enumerate(zip(pred_list,target_val_list)):\n    plt.subplot(test_num,2,i*2+1)\n    plt.plot(x_train,target_val,\"o\")\n    plt.plot(x_train,pred,\"--\")\n    plt.subplot(test_num,2,i*2+2)\n    plt.plot(error_list[i][:,0],error_list[i][:,1])\n    plt.yscale(\"log\")\n    plt.xscale(\"log\")\nplt.show()\n\n\n\u51fa\u6765\u305f\u7d75\n\n\u5de6\u304c\u3001\u4e88\u6e2c\u5024\u3092\u4e8c\u70b9\u9396\u7dda\u3001\u30c7\u30fc\u30bf\u3092\u70b9\u3067\u8868\u793a\u3057\u305f\u30b0\u30e9\u30d5\u3067\u3001\u53f3\u5074\u306f\u6a2a\u8ef8\u304cepoch\uff08\u30c7\u30fc\u30bf\u30bb\u30c3\u30c8\u3092\u4f55\u56de\u7e70\u308a\u8fd4\u3057\u3066\u66f4\u65b0\u3057\u305f\u304b\uff09\u306e\u6570\u3001\u7e26\u8ef8\u3092\u30ed\u30b9\u95a2\u6570\u306e\u5024\u3067\u3001\u4e21\u8ef8\u5171\u306b\u5bfe\u6570\u8868\u793a\u3057\u305f\u3082\u306e\u306b\u306a\u3063\u3066\u3044\u307e\u3059\u3002\n\u4e0a2\u3064\u306e\u3088\u3046\u306a\u9023\u7d9a\u7684\u304b\u3064\u5fae\u5206\u53ef\u80fd\u306a\u95a2\u6570\u306b\u5bfe\u3057\u3066\u306f\u3001\u3046\u307e\u304f\u30d5\u30a3\u30c3\u30c6\u30a3\u30f3\u30b0\u3067\u304d\u3066\u3044\u307e\u3059\u304c\u3001\u7d76\u5bfe\u5024\u3084\u30d8\u30f4\u30a3\u30b5\u30a4\u30c9\u95a2\u6570\u306e\u3088\u3046\u306a\u5fae\u5206\u4e0d\u53ef\u80fd\u3060\u3063\u305f\u308a\u3001\u305d\u3082\u305d\u3082\u4e0d\u9023\u7d9a\u3060\u3063\u305f\u308a\u3059\u308b\u95a2\u6570\u306b\u5bfe\u3057\u3066\u306f\u3001\u30ed\u30b9\u306e\u5024\u304c\u5927\u304d\u3044\u3053\u3068\u3082\u308f\u304b\u308a\u307e\u3059\u3002\n\u5b9f\u969b\u3001\u6642\u9593\u3092\u304b\u3051\u3055\u3048\u3059\u308c\u3070\u3001\u304b\u306a\u308a\u8aa4\u5dee\u306f\u6e1b\u3089\u3059\u3053\u3068\u306f\u51fa\u6765\u307e\u3059\u3002\u30d8\u30f4\u30a3\u30b5\u30a4\u30c9\u95a2\u6570\u306b\u5bfe\u3057\u3066\u3001epoch=10^5\u3068\u3057\u3066\u3001\u03b7=[0.1,0.6]\\eta=[0.1,0.6]\u306e0.1\u523b\u307f\u306e6\u70b9\u3067\u540c\u3058\u3088\u3046\u306bSGD\u3092\u4f7f\u3063\u3066\u5b66\u7fd2\u3055\u305b\u308b\u3068\u4ee5\u4e0b\u306e\u3088\u3046\u306b\u306a\u308a\u307e\u3059\u3002\n\n\u898b\u96e3\u3044\u3067\u3059\u304c\u3001\u5148\u3068\u540c\u3058\u3088\u3046\u306b\u53f3\u304c\u30c7\u30fc\u30bf\u3068\u4e88\u6e2c\u5024\u3001\u5de6\u304c\u30ed\u30b9\u95a2\u6570\u306e\u5024\u306e\u5909\u5316\u3067\u3059\u3002\u5148\u307b\u3069\u306eepoch=1000\u306e\u5834\u5408\u3068\u6bd4\u3079\u3066\u304b\u306a\u308a\u30d5\u30a3\u30c3\u30c6\u30a3\u30f3\u30b0\u304c\u3088\u304f\u306a\u3063\u3066\u3044\u308b\u3001\u8a00\u3044\u63db\u3048\u308b\u3068\u30c7\u30fc\u30bf\u306b\u5f37\u304f\u5f15\u3063\u5f35\u3089\u308c\u3066\u3044\u308b\u3053\u3068\u304c\u78ba\u8a8d\u3067\u304d\u307e\u3059\u3002\n\u5b9f\u969b\u554f\u984c\u3001\u6c4e\u5316\u6027\u80fd\u3092\u8003\u3048\u308b\u3068\u4e0e\u3048\u3089\u308c\u305f\u30c7\u30fc\u30bf\u3092\u305d\u3063\u304f\u308a\u305d\u306e\u307e\u307e\u518d\u73fe\u3059\u308b\u3053\u3068\u304c\u6700\u7d42\u76ee\u6a19\u3067\u306f\u3042\u308a\u307e\u305b\u3093\u3002\u3067\u3059\u304b\u3089\u3001\u4eca\u56de\u306e\u7d50\u679c\u304b\u3089\u3082\u3001\u30cb\u30e5\u30fc\u30e9\u30eb\u30cd\u30c3\u30c8\u306e\u6b63\u5247\u5316\u624b\u6cd5\u306e\u4e00\u3064\u3068\u3057\u3066\u3042\u308b\u65e9\u671f\u7d42\u4e86\u304c\u6709\u52b9\u3067\u3042\u308b\u3068\u3082\u8a00\u3048\u308b\u306e\u304b\u306a\uff1f\n\n\u5f8c\u3067\u3084\u308a\u305f\u3044\u3053\u3068\n\nSGD\u306e\u6539\u826f\uff08RDA\u3068\u304b)\n\u5206\u985e\u554f\u984c\u3078\u306e\u62e1\u5f35\uff08\u4ed6\u306e\u30ed\u30b9\u95a2\u6570\u3067\u3082\u5b66\u7fd2\u3067\u304d\u308b\u3088\u3046\u306b\uff09\n\n[tkazusa\u3055\u3093\u306e\u5b9f\u88c5](http://qiita.com/tkazusa/items/b8e4d287f94f8b87ed52)\u3092\u898b\u3066\u611f\u5316\u3055\u308c\u305f\u306e\u3067\u3084\u3063\u3066\u307f\u307e\u3057\u305f\n\n\u30cb\u30e5\u30fc\u30e9\u30eb\u30cd\u30c3\u30c8\u306f\u7dda\u5f62\u56de\u5e30\u30e2\u30c7\u30eb\u3084\u30af\u30e9\u30b9\u5206\u985e\u30e2\u30c7\u30eb\u3067\u51fa\u3066\u304d\u305f\u7279\u5fb4\u91cf\u3092\u4f5c\u6210\u3059\u308bbasis\u95a2\u6570 $\\phi(x)$\u3092\u96a0\u308c\u5c64\u3067\u4f5c\u3063\u3066\u3057\u307e\u304a\u3046\u3001\u305d\u3093\u3067\u305d\u306e\u30d1\u30e9\u30e1\u30fc\u30bf\u3082\u66f4\u65b0\u3057\u3066\u3057\u307e\u304a\u3046\u3068\u3044\u3046\u3001\u3042\u308b\u610f\u5473\u7a76\u6975\u306b\u30c7\u30fc\u30bf\u306b\u5408\u308f\u305b\u3066\u3044\u304f\u3088\u3046\u306a\u3001\u305d\u3093\u306a\u30a4\u30e1\u30fc\u30b8\n\n# \u3084\u308b\u3053\u3068\u3068\u304b\u5f0f\u3068\u304b\n\u30cb\u30e5\u30fc\u30e9\u30eb\u30cd\u30c3\u30c8\u306b\u3088\u308b\u56de\u5e30\u554f\u984c\u3092\u89e3\u304d\u307e\u3059\u3002\n\u8aa4\u5dee\u95a2\u6570\u306f\u3001\u3088\u304f\u3042\u308b\u4e8c\u4e57\u30ed\u30b9\u3092\u7528\u3044\u3066\u3001\u51fa\u529b\u5c64\u306e\u6d3b\u6027\u5316\u95a2\u6570\u306f\u7dda\u5f62\uff08$f(x)=x$)\u3001\u96a0\u308c\u5c64\u306e\u6d3b\u6027\u5316\u95a2\u6570$h(x)$\u306b\u306f\u3001$tanh(x)$\u3092\u7528\u3044\u307e\u3059\u3002\n\n\u306a\u306e\u3067\u6700\u7d42\u7684\u306a\u51fa\u529b\u306f\u4ee5\u4e0b\u306e\u69d8\u306a\u611f\u3058\u3002\n\n```math\n\\begin{align}\ny_n&=f(\\sum_{j=1}^M w_{kj}^{(2)} \\tanh(\\sum_{i=1}^D w_{ji}^{(1)}x_i+w_{j0}^{(0)})+w_{k0}^{(2)})\\\\\n&=\\sum_{j=1}^M w_{kj}^{(2)} \\tanh(\\sum_{i=1}^D w_{ji}^{(1)}x_i+w_{j0}^{(0)})+w_{k0}^{(2)}\n\\end{align}\n```\n\u51fa\u529b\u304c\u6c7a\u5b9a\u3059\u308c\u3070\u3001\u8aa4\u5dee\u95a2\u6570\u304c\u6c42\u307e\u308a\u307e\u3059\u3002\n\n```math\nE(w)=\\sum_{n=1}^N ||y_n-t_n||_2^2\n```\n\n\u3042\u3068\u306f\u3001\u5358\u7d14\u306b\u8aa4\u5dee\u95a2\u6570\u3092\u91cd\u307fw\u3067\u5fae\u5206\u3057\u305f\u52fe\u914d\u3092\u7528\u3044\u3066\u3001w\u3092\u66f4\u65b0\u3059\u308b\u308f\u3051\u3067\u3059\u304c\u3001\u3053\u3053\u3067\u306f\u3001\u8aa4\u5dee\u95a2\u6570\u304c\u30c7\u30fc\u30bf\u306e\u6570\u306e\u8db3\u3057\u7b97\u3067\u8868\u3059\u3053\u3068\u304c\u3067\u304d\u308b\u3053\u3068\u3092\u4f7f\u3063\u305f\u3001SGD\u3092\u7528\u3044\u3066\u66f4\u65b0\u3092\u3057\u307e\u3059\u3002\n\n\u7c21\u5358\u306b\u8a00\u3063\u3066\u3057\u307e\u3048\u3070\u3001\u8aa4\u5dee\u95a2\u6570\u5168\u4f53\u306e\u52fe\u914d\u8a08\u7b97\u306b\u306f\u6642\u9593\u304c\u304b\u304b\u308b\u306e\u3067\u3001\u30c7\u30fc\u30bf\u70b9\u3072\u3068\u3064\u306b\u5bfe\u3059\u308b\u52fe\u914d\u3092\u8a08\u7b97\u3057\u3066\u3001\u305d\u308c\u3092\u4f7f\u3063\u3066\u3061\u3087\u3063\u3068\u3060\u3051w\u306e\u66f4\u65b0\u3092\u3059\u308b\u3001\u3068\u3044\u3046\u4f5c\u696d\u3092\u591a\u6570\u7e70\u308a\u8fd4\u3057\u3066\u3001\u8aa4\u5dee\u95a2\u6570\u5168\u4f53\u3067\u306e\u52fe\u914d\u306e\u8a08\u7b97\u3092\u56de\u907f\u3057\u306a\u304c\u3089\u6700\u9069\u89e3\u3092\u6c42\u3081\u3066\u3044\u304f\u3001\u3068\u3044\u3046\u65b9\u6cd5\u304cSGD\u3067\u3059\u3002\n\n# \u5b9f\u88c5\n\n\u5b9f\u88c5\u306e\u30b3\u30fc\u30c9\u3067\u3059\u3002\u672c\u5f53\u306f\u30c7\u30fc\u30bf\u30bb\u30c3\u30c8\u6bce\u306b\u4e26\u5217\u8a08\u7b97\u3068\u304b\u3057\u305f\u304b\u3063\u305f\u3093\u3067\u3059\u304c\u3001\u306a\u3093\u304b\u3046\u307e\u304f\u3044\u304b\u306a\u3044\u2026\u2026\u306e\u3067\u3084\u3063\u3066\u307e\u305b\u3093\u3002\n\u30a4\u30f3\u30b9\u30bf\u30f3\u30b9\u4f5c\u6210\u6642\u306b\u3001\u5165\u51fa\u529b\u53ca\u3073\u96a0\u308c\u5c64\u306e\u6b21\u5143\u3092\u3044\u308c\u3066\u3001Fit\u3092\u5b9f\u884c\u3057\u3066\u5b66\u7fd2\u3057\u307e\u3059\u3002\n\n\n```py\n#coding:utf-8\nimport numpy as np\nimport matplotlib.pyplot as plt\n#import multiprocessing as mp\nimport seaborn as sns\n\nclass NeuralNet():\n    def __init__(self,input=1,output=1,hidden=3):\n        self.input = input\n        self.output = output\n        self.hidden = hidden\n        self.w_1 = np.random.rand(self.input+1,self.hidden)*2.-1.\n        self.w_2 = np.random.rand(self.hidden+1,self.output)*2.-1.\n        np.random.seed(71) #\u518d\u73fe\u6027\u306e\u305f\u3081\n\n    def predict(self,x):\n        \"\"\"\n        predict target value.\n        x: x value for predict.numpy.ndarray like.\n        return predict value.numpy.ndarray like\n        \"\"\"\n        A = self.w_1[1:].dot(x)+self.w_1[0]\n        Z = np.tanh(A)\n        Y = self.w_2[1:].T.dot(Z.T)+self.w_2[0]\n        self.Z = Z\n        return Y[0]\n\n    def Fit(self,X,t,epoch=1000,eta=.1):\n        \"\"\"\n        Fitting Parameters\n        X:  Training Data X value.numpy.ndarray like\n        t:  target value.ndarray like\n        epoch: number of iteration (whole dataset)\n        eta: learning rate with one gradient.\n        return void\n        \"\"\"\n        self.X = X\n        self.t = t\n        self.eta = eta\n        error_list = []\n        for n in range(epoch):\n            if n%50 == 0:\n                error_list.append([n+1,self._compute_error()])\n\n            for x_i,t_i in zip(X,t):\n                delta_k = self.predict(np.array((x_i)))-t_i\n                delta_j = (1-self.Z**2)*self.w_2[1:].dot(delta_k)\n                # print \"self.Z\",self.Z\n                # print \"delta_k:\",delta_k\n                # print \"delta_j:\",delta_j\n                # print \"self.w1\",self.w_1\n                # print \"w2:\",self.w_2\n\n                #\u30d0\u30a4\u30a2\u30b9\u9805\u306f\u5e38\u306bdelta_j,k\u306b\u3088\u308a\u66f4\u65b0\uff08x_0=1.\u3067\u56fa\u5b9a\u306a\u305f\u3081\uff09\n                self.w_1[0] = self.w_1[0] - eta * delta_j\n                self.w_2[0] = self.w_2[0] - eta * delta_k\n\n                self.w_1[1:] = self.w_1[1:] - eta * np.outer(np.array((x_i)),delta_j)\n                self.w_2[1:] = self.w_2[1:] - eta * np.outer(self.Z,delta_k)\n        self.errors = np.array(error_list)\n        return\n\n    def _compute_error(self):\n        \"\"\"\n        Compute loss function.(sum of squares)\n        return: error whole dataset.\n        \"\"\"\n        error = 0.\n        for X_n,t_n in zip(self.X,self.t):\n            error = error + sum(self.predict(np.array((X_n)))-t_n)**2\n        return error\n\ntarget_val_list = []\nx_train = np.linspace(-1,1,50)\ntarget_val_list.append(np.sin(x_train*np.pi))\ntarget_val_list.append(x_train**2)\ntarget_val_list.append(np.abs(x_train))\ntarget_val_list.append((np.sign(x_train)+1)*.5)\n\ndef subcalc(p):#p=0,1,......\n    target_val = target_val_list[p]\n    neural_net = NeuralNet(input=1,output=1,hidden=3)\n    neural_net.Fit(x_train,target_val)\n    pred = []\n    for x in x_train:\n        pred.append(neural_net.predict(np.array(x)))\n    return [pred,neural_net.errors]\n\nproc = len(target_val_list)\n#pool = mp.Pool(proc)\n#callback = pool.map(subcalc,range(proc))\n\ncallback = []\nfor i in range(len(target_val_list)):\n    callback.append(subcalc(i))\n\npred_list = []\nerror_list = []\nfor i in range(proc):\n    pred_list.append(callback[i][0])\n    error_list.append(callback[i][1])\n\ntest_num = len(target_val_list)\nfor i,(pred,target_val) in enumerate(zip(pred_list,target_val_list)):\n    plt.subplot(test_num,2,i*2+1)\n    plt.plot(x_train,target_val,\"o\")\n    plt.plot(x_train,pred,\"--\")\n    plt.subplot(test_num,2,i*2+2)\n    plt.plot(error_list[i][:,0],error_list[i][:,1])\n    plt.yscale(\"log\")\n    plt.xscale(\"log\")\nplt.show()\n```\n## \u51fa\u6765\u305f\u7d75\n![neural_net_experiment1.png](https://qiita-image-store.s3.amazonaws.com/0/42627/b3f3b697-ee66-798d-28c7-82257f385076.png)\n\n\u5de6\u304c\u3001\u4e88\u6e2c\u5024\u3092\u4e8c\u70b9\u9396\u7dda\u3001\u30c7\u30fc\u30bf\u3092\u70b9\u3067\u8868\u793a\u3057\u305f\u30b0\u30e9\u30d5\u3067\u3001\u53f3\u5074\u306f\u6a2a\u8ef8\u304cepoch\uff08\u30c7\u30fc\u30bf\u30bb\u30c3\u30c8\u3092\u4f55\u56de\u7e70\u308a\u8fd4\u3057\u3066\u66f4\u65b0\u3057\u305f\u304b\uff09\u306e\u6570\u3001\u7e26\u8ef8\u3092\u30ed\u30b9\u95a2\u6570\u306e\u5024\u3067\u3001\u4e21\u8ef8\u5171\u306b\u5bfe\u6570\u8868\u793a\u3057\u305f\u3082\u306e\u306b\u306a\u3063\u3066\u3044\u307e\u3059\u3002\n\n\u4e0a2\u3064\u306e\u3088\u3046\u306a\u9023\u7d9a\u7684\u304b\u3064\u5fae\u5206\u53ef\u80fd\u306a\u95a2\u6570\u306b\u5bfe\u3057\u3066\u306f\u3001\u3046\u307e\u304f\u30d5\u30a3\u30c3\u30c6\u30a3\u30f3\u30b0\u3067\u304d\u3066\u3044\u307e\u3059\u304c\u3001\u7d76\u5bfe\u5024\u3084\u30d8\u30f4\u30a3\u30b5\u30a4\u30c9\u95a2\u6570\u306e\u3088\u3046\u306a\u5fae\u5206\u4e0d\u53ef\u80fd\u3060\u3063\u305f\u308a\u3001\u305d\u3082\u305d\u3082\u4e0d\u9023\u7d9a\u3060\u3063\u305f\u308a\u3059\u308b\u95a2\u6570\u306b\u5bfe\u3057\u3066\u306f\u3001\u30ed\u30b9\u306e\u5024\u304c\u5927\u304d\u3044\u3053\u3068\u3082\u308f\u304b\u308a\u307e\u3059\u3002\n\n\u5b9f\u969b\u3001\u6642\u9593\u3092\u304b\u3051\u3055\u3048\u3059\u308c\u3070\u3001\u304b\u306a\u308a\u8aa4\u5dee\u306f\u6e1b\u3089\u3059\u3053\u3068\u306f\u51fa\u6765\u307e\u3059\u3002\u30d8\u30f4\u30a3\u30b5\u30a4\u30c9\u95a2\u6570\u306b\u5bfe\u3057\u3066\u3001epoch=10^5\u3068\u3057\u3066\u3001$\\eta=[0.1,0.6]$\u306e0.1\u523b\u307f\u306e6\u70b9\u3067\u540c\u3058\u3088\u3046\u306bSGD\u3092\u4f7f\u3063\u3066\u5b66\u7fd2\u3055\u305b\u308b\u3068\u4ee5\u4e0b\u306e\u3088\u3046\u306b\u306a\u308a\u307e\u3059\u3002\n![neural_net_epoch=100000_eta=[1e-1~6e-1].png](https://qiita-image-store.s3.amazonaws.com/0/42627/77eb9288-24bf-da6f-d72d-c34bdd54b013.png)\n\u898b\u96e3\u3044\u3067\u3059\u304c\u3001\u5148\u3068\u540c\u3058\u3088\u3046\u306b\u53f3\u304c\u30c7\u30fc\u30bf\u3068\u4e88\u6e2c\u5024\u3001\u5de6\u304c\u30ed\u30b9\u95a2\u6570\u306e\u5024\u306e\u5909\u5316\u3067\u3059\u3002\u5148\u307b\u3069\u306eepoch=1000\u306e\u5834\u5408\u3068\u6bd4\u3079\u3066\u304b\u306a\u308a\u30d5\u30a3\u30c3\u30c6\u30a3\u30f3\u30b0\u304c\u3088\u304f\u306a\u3063\u3066\u3044\u308b\u3001\u8a00\u3044\u63db\u3048\u308b\u3068\u30c7\u30fc\u30bf\u306b\u5f37\u304f\u5f15\u3063\u5f35\u3089\u308c\u3066\u3044\u308b\u3053\u3068\u304c\u78ba\u8a8d\u3067\u304d\u307e\u3059\u3002\n\n\u5b9f\u969b\u554f\u984c\u3001\u6c4e\u5316\u6027\u80fd\u3092\u8003\u3048\u308b\u3068\u4e0e\u3048\u3089\u308c\u305f\u30c7\u30fc\u30bf\u3092\u305d\u3063\u304f\u308a\u305d\u306e\u307e\u307e\u518d\u73fe\u3059\u308b\u3053\u3068\u304c\u6700\u7d42\u76ee\u6a19\u3067\u306f\u3042\u308a\u307e\u305b\u3093\u3002\u3067\u3059\u304b\u3089\u3001\u4eca\u56de\u306e\u7d50\u679c\u304b\u3089\u3082\u3001\u30cb\u30e5\u30fc\u30e9\u30eb\u30cd\u30c3\u30c8\u306e\u6b63\u5247\u5316\u624b\u6cd5\u306e\u4e00\u3064\u3068\u3057\u3066\u3042\u308b\u65e9\u671f\u7d42\u4e86\u304c\u6709\u52b9\u3067\u3042\u308b\u3068\u3082\u8a00\u3048\u308b\u306e\u304b\u306a\uff1f\n\n# \u5f8c\u3067\u3084\u308a\u305f\u3044\u3053\u3068\n+ SGD\u306e\u6539\u826f\uff08RDA\u3068\u304b)\n+ \u5206\u985e\u554f\u984c\u3078\u306e\u62e1\u5f35\uff08\u4ed6\u306e\u30ed\u30b9\u95a2\u6570\u3067\u3082\u5b66\u7fd2\u3067\u304d\u308b\u3088\u3046\u306b\uff09\n", "tags": ["PRML", "Python"]}