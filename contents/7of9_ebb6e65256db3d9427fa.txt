{"context": "\n\u52d5\u4f5c\u74b0\u5883\nGeForce GTX 1070 (8GB)\nASRock Z170M Pro4S [Intel Z170chipset]\nUbuntu 14.04 LTS desktop amd64\nTensorFlow v0.11\ncuDNN v5.1 for Linux\nCUDA v8.0\nPython 2.7.6\nIPython 5.1.0 -- An enhanced Interactive Python.\ngcc (Ubuntu 4.8.4-2ubuntu1~14.04.3) 4.8.4\n\n\nTensorFlow\u306e\u5b66\u7fd2\u904e\u7a0b\u306e\u8aa4\u5dee\u51fa\u529b\u3092print()\u3067\u884c\u3063\u3066\u3044\u308b\u3002\n\u30ea\u30c0\u30a4\u30ec\u30af\u30b7\u30e7\u30f3(> res)\u4ed8\u304d\u3067TensorFlow\u30b3\u30fc\u30c9\u3092\u5b9f\u884c\u3057\u3066\u3044\u308b\u304c\u3001\u51fa\u529b\u5148\u30d5\u30a1\u30a4\u30eb(res)\u306e\u30b5\u30a4\u30ba\u304c\u3059\u3050\u306b\u306f\u5897\u3048\u3066\u3044\u304b\u306a\u304b\u3063\u305f\u3002\u4f55\u304b\u306e\u30bf\u30a4\u30df\u30f3\u30b0\u306e\u6642\u306b\u5927\u304d\u304f\u5897\u3048\u308b\u3088\u3046\u306a\u52d5\u4f5c\u3060\u3063\u305f\u3002\nflush\u3092\u3059\u308c\u3070\u3044\u3044\u306e\u3067\u306f\u3068\u601d\u3044\u8abf\u3079\u3001\u4ee5\u4e0b\u3092\u898b\u3064\u3051\u305f\u3002\nhttp://7rpn.hatenablog.com/entry/2015/11/29/131601\n\nsys.stdout.flush()\n\n\u4ee5\u4e0b\u306e\u3088\u3046\u306b92\u884c\u76ee\u306bsys.stdout.flush()\u3092\u8ffd\u52a0\u3059\u308b\u3053\u3068\u3067\u3001\u5b66\u7fd2\u904e\u7a0b\u306e\u8aa4\u5dee\u51fa\u529b\u304c\u9069\u6642\u884c\u308f\u308c\u308b\u3088\u3046\u306b\u306a\u3063\u305f\u3002\n\u60c5\u5831\u611f\u8b1d\u3067\u3059\u3002\n\nlearn_in100out100.py\n#!/usr/bin/env python\n# -*- coding: utf-8 -*-\nimport sys\nimport tensorflow as tf\nimport tensorflow.contrib.slim as slim\nimport numpy as np\n\n'''\nv0.6 Feb. 19, 2017\n    - add sys.stdout.flush() to immediately print \nv0.5 Feb. 18, 2017\n    - add fc_drop()\nv0.4 Feb. 15, 2017\n    - fix bug > ZeroDivisionError: float division by zero @ shuffle_batch()\nv0.3 Feb. 15, 2017\n    - tweak [batch_size] for shuffle_batch()\nv0.2 Feb. 15, 2017\n    - fix bug > different dimensions for placeholder and network\nv0.1 Feb. 06, 2017\n    - read [test_in.csv],[test_out.csv]\n'''\n\n'''\ncodingrule:PEP8\n'''\n\n\ndef fc_drop(inputs, *args, **kwargs):\n    # Thanks to: http://qiita.com/shngt/items/f532601b4f059ce8584f\n    net = slim.fully_connected(inputs, *args, **kwargs)\n    return slim.dropout(net, 0.5)\n\nfilename_inp = tf.train.string_input_producer([\"test_in.csv\"])\nfilename_out = tf.train.string_input_producer([\"test_out.csv\"])\nNUM_INP_NODE = 100\nNUM_OUT_NODE = 100\n\n# parse csv\n# a. input node\nreader = tf.TextLineReader()\nkey, value = reader.read(filename_inp)\ndeflist = [[0.] for idx in range(NUM_INP_NODE)]\ninput1 = tf.decode_csv(value, record_defaults=deflist)\n# b. output node\nkey, value = reader.read(filename_out)\ndeflist = [[0.] for idx in range(NUM_OUT_NODE)]\noutput1 = tf.decode_csv(value, record_defaults=deflist)\n# c. pack\n# inputs = tf.pack([input1])\ninputs = input1\n# outputs = tf.pack([output1])\noutputs = output1\n\nbatch_size = 2\ninputs_batch, output_batch = tf.train.shuffle_batch(\n    [inputs, outputs], batch_size, capacity=10, min_after_dequeue=batch_size)\n\ninput_ph = tf.placeholder(\"float\", [None, 100])\noutput_ph = tf.placeholder(\"float\", [None, 100])\n\n# network\nhiddens = slim.stack(input_ph, slim.fully_connected, [7, 7, 7],\n                     activation_fn=tf.nn.sigmoid, scope=\"hidden\")\n# a. without dropout\n# prediction = slim.fully_connected(\n#    hiddens, 100, activation_fn=None, scope=\"output\")\n# b. with dropout\ndrpout = slim.stack(hiddens, fc_drop, [100, 100], scope='fc')\nprediction = slim.fully_connected(\n    drpout, 100, activation_fn=None, scope=\"output\")\nloss = tf.contrib.losses.mean_squared_error(prediction, output_ph)\n\ntrain_op = slim.learning.create_train_op(loss, tf.train.AdamOptimizer(0.001))\n\ninit_op = tf.initialize_all_variables()\n\nwith tf.Session() as sess:\n    coord = tf.train.Coordinator()\n    threads = tf.train.start_queue_runners(sess=sess, coord=coord)\n\n    try:\n        sess.run(init_op)\n        # for idx in range(10000):\n        for idx in range(100000):\n            inpbt, outbt = sess.run([inputs_batch, output_batch])\n            _, t_loss = sess.run(\n                [train_op, loss],\n                feed_dict={input_ph: inpbt, output_ph: outbt})\n\n            if (idx+1) % 100 == 0:\n                print(\"%d,%f\" % (idx+1, t_loss))\n                sys.stdout.flush()\n    finally:\n        coord.request_stop()\n\n    coord.join(threads)\n\n\n$ python learn_in100out100.py > res.learn.N\\=1000_dropout@output_longrun_170218\n\nres.learn.N=1000_dropout@output_longrun_170218\u304c\u9069\u5b9c\u66f4\u65b0\u3055\u308c\u3001Jupyter\u3067\u306e\u8aa4\u5dee\u30b0\u30e9\u30d5\u306e\u78ba\u8a8d\u304c\u4fbf\u5229\u306b\u306a\u3063\u305f\u3002\n\n\u4e0b\u304c\u5b66\u7fd2\u9014\u4e2d\u306e\u7d50\u679c\u3002\n\u5168\u7136\u30c0\u30e1\u306a\u7d50\u679c\u3068\u3044\u3046\u3053\u3068\u304c\u3059\u3050\u306b\u5206\u304b\u308a\u3002\u3002\u3002\n\n```txt:\u52d5\u4f5c\u74b0\u5883\nGeForce GTX 1070 (8GB)\nASRock Z170M Pro4S [Intel Z170chipset]\nUbuntu 14.04 LTS desktop amd64\nTensorFlow v0.11\ncuDNN v5.1 for Linux\nCUDA v8.0\nPython 2.7.6\nIPython 5.1.0 -- An enhanced Interactive Python.\ngcc (Ubuntu 4.8.4-2ubuntu1~14.04.3) 4.8.4\n```\n\nTensorFlow\u306e\u5b66\u7fd2\u904e\u7a0b\u306e\u8aa4\u5dee\u51fa\u529b\u3092print()\u3067\u884c\u3063\u3066\u3044\u308b\u3002\n\n\u30ea\u30c0\u30a4\u30ec\u30af\u30b7\u30e7\u30f3(`> res`)\u4ed8\u304d\u3067TensorFlow\u30b3\u30fc\u30c9\u3092\u5b9f\u884c\u3057\u3066\u3044\u308b\u304c\u3001\u51fa\u529b\u5148\u30d5\u30a1\u30a4\u30eb(res)\u306e\u30b5\u30a4\u30ba\u304c\u3059\u3050\u306b\u306f\u5897\u3048\u3066\u3044\u304b\u306a\u304b\u3063\u305f\u3002\u4f55\u304b\u306e\u30bf\u30a4\u30df\u30f3\u30b0\u306e\u6642\u306b\u5927\u304d\u304f\u5897\u3048\u308b\u3088\u3046\u306a\u52d5\u4f5c\u3060\u3063\u305f\u3002\n\nflush\u3092\u3059\u308c\u3070\u3044\u3044\u306e\u3067\u306f\u3068\u601d\u3044\u8abf\u3079\u3001\u4ee5\u4e0b\u3092\u898b\u3064\u3051\u305f\u3002\n\nhttp://7rpn.hatenablog.com/entry/2015/11/29/131601\n> sys.stdout.flush()\n\n\u4ee5\u4e0b\u306e\u3088\u3046\u306b92\u884c\u76ee\u306b`sys.stdout.flush()`\u3092\u8ffd\u52a0\u3059\u308b\u3053\u3068\u3067\u3001\u5b66\u7fd2\u904e\u7a0b\u306e\u8aa4\u5dee\u51fa\u529b\u304c\u9069\u6642\u884c\u308f\u308c\u308b\u3088\u3046\u306b\u306a\u3063\u305f\u3002\n\n\u60c5\u5831\u611f\u8b1d\u3067\u3059\u3002\n\n```learn_in100out100.py\n#!/usr/bin/env python\n# -*- coding: utf-8 -*-\nimport sys\nimport tensorflow as tf\nimport tensorflow.contrib.slim as slim\nimport numpy as np\n\n'''\nv0.6 Feb. 19, 2017\n    - add sys.stdout.flush() to immediately print \nv0.5 Feb. 18, 2017\n    - add fc_drop()\nv0.4 Feb. 15, 2017\n    - fix bug > ZeroDivisionError: float division by zero @ shuffle_batch()\nv0.3 Feb. 15, 2017\n    - tweak [batch_size] for shuffle_batch()\nv0.2 Feb. 15, 2017\n    - fix bug > different dimensions for placeholder and network\nv0.1 Feb. 06, 2017\n    - read [test_in.csv],[test_out.csv]\n'''\n\n'''\ncodingrule:PEP8\n'''\n\n\ndef fc_drop(inputs, *args, **kwargs):\n    # Thanks to: http://qiita.com/shngt/items/f532601b4f059ce8584f\n    net = slim.fully_connected(inputs, *args, **kwargs)\n    return slim.dropout(net, 0.5)\n\nfilename_inp = tf.train.string_input_producer([\"test_in.csv\"])\nfilename_out = tf.train.string_input_producer([\"test_out.csv\"])\nNUM_INP_NODE = 100\nNUM_OUT_NODE = 100\n\n# parse csv\n# a. input node\nreader = tf.TextLineReader()\nkey, value = reader.read(filename_inp)\ndeflist = [[0.] for idx in range(NUM_INP_NODE)]\ninput1 = tf.decode_csv(value, record_defaults=deflist)\n# b. output node\nkey, value = reader.read(filename_out)\ndeflist = [[0.] for idx in range(NUM_OUT_NODE)]\noutput1 = tf.decode_csv(value, record_defaults=deflist)\n# c. pack\n# inputs = tf.pack([input1])\ninputs = input1\n# outputs = tf.pack([output1])\noutputs = output1\n\nbatch_size = 2\ninputs_batch, output_batch = tf.train.shuffle_batch(\n    [inputs, outputs], batch_size, capacity=10, min_after_dequeue=batch_size)\n\ninput_ph = tf.placeholder(\"float\", [None, 100])\noutput_ph = tf.placeholder(\"float\", [None, 100])\n\n# network\nhiddens = slim.stack(input_ph, slim.fully_connected, [7, 7, 7],\n                     activation_fn=tf.nn.sigmoid, scope=\"hidden\")\n# a. without dropout\n# prediction = slim.fully_connected(\n#    hiddens, 100, activation_fn=None, scope=\"output\")\n# b. with dropout\ndrpout = slim.stack(hiddens, fc_drop, [100, 100], scope='fc')\nprediction = slim.fully_connected(\n    drpout, 100, activation_fn=None, scope=\"output\")\nloss = tf.contrib.losses.mean_squared_error(prediction, output_ph)\n\ntrain_op = slim.learning.create_train_op(loss, tf.train.AdamOptimizer(0.001))\n\ninit_op = tf.initialize_all_variables()\n\nwith tf.Session() as sess:\n    coord = tf.train.Coordinator()\n    threads = tf.train.start_queue_runners(sess=sess, coord=coord)\n\n    try:\n        sess.run(init_op)\n        # for idx in range(10000):\n        for idx in range(100000):\n            inpbt, outbt = sess.run([inputs_batch, output_batch])\n            _, t_loss = sess.run(\n                [train_op, loss],\n                feed_dict={input_ph: inpbt, output_ph: outbt})\n\n            if (idx+1) % 100 == 0:\n                print(\"%d,%f\" % (idx+1, t_loss))\n                sys.stdout.flush()\n    finally:\n        coord.request_stop()\n\n    coord.join(threads)\n```\n\n```\n$ python learn_in100out100.py > res.learn.N\\=1000_dropout@output_longrun_170218\n```\n\nres.learn.N\\=1000_dropout@output_longrun_170218\u304c\u9069\u5b9c\u66f4\u65b0\u3055\u308c\u3001Jupyter\u3067\u306e\u8aa4\u5dee\u30b0\u30e9\u30d5\u306e\u78ba\u8a8d\u304c\u4fbf\u5229\u306b\u306a\u3063\u305f\u3002\n\n\n![qiita.png](https://qiita-image-store.s3.amazonaws.com/0/32870/858b4d70-46d0-5470-44ec-cfb09950716b.png)\n\n\u4e0b\u304c\u5b66\u7fd2\u9014\u4e2d\u306e\u7d50\u679c\u3002\n\u5168\u7136\u30c0\u30e1\u306a\u7d50\u679c\u3068\u3044\u3046\u3053\u3068\u304c\u3059\u3050\u306b\u5206\u304b\u308a\u3002\u3002\u3002\n\n\n![qiita.png](https://qiita-image-store.s3.amazonaws.com/0/32870/e0ed1514-46ac-a766-4811-216d47f6bf64.png)\n", "tags": ["Python", "TensorFlow", "borgWarp", "link"]}