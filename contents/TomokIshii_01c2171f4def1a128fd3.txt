{"context": "Recurrent Neural Network\uff08\u518d\u5e30\u578b\u30cb\u30e5\u30fc\u30e9\u30eb\u30cd\u30c3\u30c8\uff09\u306b\u95a2\u5fc3\u306f\u3042\u308b\u304c\uff0c\u306a\u304b\u306a\u304b\u30b3\u30fc\u30c9\u4f5c\u6210\u306b\u624b\u304c\u3064\u304b\u306a\u3044\uff0c\u3053\u306e\u3088\u3046\u306a\u30b1\u30fc\u30b9\u304c\u591a\u304f\u306a\u3044\u3060\u308d\u3046\u304b\uff1f\u7406\u7531\u306f\u3044\u304f\u3064\u304b\u3042\u308b\u304c\uff0c\u79c1\u306e\u5834\u5408\u306f\u6b21\u306e\u3088\u3046\u306a\u3082\u306e\u304c\u601d\u3044\u5f53\u305f\u308b\uff0e  \n\n\u5358\u7d14\u306b\u30cd\u30c3\u30c8\u30ef\u30fc\u30af\u306e\u69cb\u6210\u304c\u8907\u96d1\uff0eMLP(Multi-layer Perceptron)\u304b\u3089\u5165\u9580\u3057\u3066CNN(Convolutional-NN)\u306b\u9032\u3080\u307e\u3067\u306f\uff0c\u7279\u6b8a\u306aLayer\u304c\u3042\u308b\u306b\u305b\u3088\uff0c\u4fe1\u53f7\u306e\u6d41\u308c\u306f\u9806\u65b9\u5411\u306e\u307f\u3067\u3042\u3063\u305f\uff0e\uff08\u8aa4\u5dee\u306e\u8a08\u7b97\u306f\u9664\u304f\uff0e\uff09\nMLP\u3084CNN\u306b\u304a\u3044\u3066\u306f\u5206\u304b\u308a\u3084\u3059\u3044\u4f8b\u984c\uff0c\uff08Deep Learning\u306e\u2019Hello World'\u3068\u79f0\u3055\u308c\u308b\uff09\"MNIST\" \u304c\u3042\u3063\u305f\u304c\uff0c\u305d\u306e\u3088\u3046\u306a\u6a19\u6e96\u7684\u306a(\u30b9\u30bf\u30f3\u30c0\u30fc\u30c9\u306a\uff09\u4f8b\u984c\u304cRNN\u306b\u306f\u306a\u3044\uff0e\n\n\u56e0\u307f\u306bTheano\u306eDeep Learning\u3084TensorFlow\u306eTutorial\u306f\uff0c\u8a00\u8a9e\u30e2\u30c7\u30eb\u3092\u6271\u3063\u305f\u3082\u306e\u3067\u3042\u308b\uff0e\u8a00\u8a9e\u30e2\u30c7\u30eb\u306b\u7cbe\u901a\u3055\u308c\u3066\u3044\u308b\u65b9\u306f\u3059\u3050\u306b\u53d6\u308a\u304b\u304b\u308c\u308b\u304b\u3082\u3057\u308c\u306a\u3044\u304c\uff0c\u521d\u5fc3\u8005\u306f\u307e\u305a\u300c\u4f8b\u984c\u304c\u4f55\u3092\u89e3\u3053\u3046\u3068\u3057\u3066\u3044\u308b\u304b\u300d\u306b\u3064\u3044\u3066\u7406\u89e3\u3059\u308b\u5fc5\u8981\u304c\u3042\u308b\uff0e\n\u4eca\u56de\u306f\uff0c\u8a00\u8a9e\u30e2\u30c7\u30eb\u3067\u306a\u3044\uff0c\u3088\u308a\u5358\u7d14\u306a\u6570\u5217\u3092\u6271\u3046\u4f8b\u984c\u3092\u53d6\u308a\u4e0a\u3052\uff0c\u7c21\u5358\u306aRecurrent Neural Network\uff08RNN)\u3092\u5b9f\u88c5\u3057\u3066\u307f\u308b\u3053\u3068\u306b\u3057\u305f\uff0e\n(\u4f7f\u7528\u3057\u305f\u30d7\u30ed\u30b0\u30e9\u30df\u30f3\u30b0\u74b0\u5883\u306f\uff0cpython 2.7.11, Theano 0.7.0\u306b\u306a\u308a\u307e\u3059\uff0e\uff09\n\n\u30b7\u30f3\u30d7\u30eb\u306aRNN\u69cb\u9020\nRNN\u3092\u8abf\u3079\u308b\u306b\u3042\u305f\u308a\uff0c\u521d\u3081\u306b\"TensorFlow\"\u306eTutorial(ptb_word_lm.py)\u3092\u52d5\u304b\u3057\u3066\u307f\u305f\u304c\uff0c\n\"epoch\"\u306e\u6570\u5024\u304c\u5897\u3059\u306b\u3057\u305f\u304c\u3044\"perplexity\"(\u8907\u96d1\u3055?)\u306e\u5909\u6570\u304c\u6e1b\u3063\u3066\u3044\u304f\u69d8\u5b50\u304c\u898b\u3089\u308c\u308b\uff0e\u3057\u304b\u3057\u306a\u304c\u3089\uff0c\u305d\u308c\u304c\u4f55\u3092\u89e3\u3044\u3066\u3044\u308b\u304b\u306b\u3064\u3044\u3066\u306f\uff0c\u8a73\u7d30\u306f\u7406\u89e3\u3067\u304d\u306a\u304b\u3063\u305f\uff0eRNN\u306e\u30e2\u30c7\u30eb\u3068\u3057\u3066\u3082LSTM(Long Short-term Memory)\u3092\u7528\u3044\u3066\u3044\u308b\u306e\u3067\uff0c\u3053\u308c\u3067RNN\u5165\u9580\u3068\u3044\u3046\u306e\u306f\u6577\u5c45\u304c\u9ad8\u3044\u3068\u611f\u3058\u305f\uff0e\n\u6587\u732e\u300c\u6df1\u5c64\u5b66\u7fd2\u300d\u3067\u306f\u30b7\u30f3\u30d7\u30eb\u306aRNN\u3068\u3057\u3066Elman\u30cd\u30c3\u30c8\u304c\u7d39\u4ecb\u3055\u308c\u3066\u3044\u308b\uff0e\u307e\u305f\uff0c\"Elman RNN\"\u3092\u30ad\u30fc\u30ef\u30fc\u30c9\u306b\u8abf\u3079\u305f\u3068\u3053\u308d\uff0cSimple\u306aRNN\u3092\u7d39\u4ecb\u3059\u308b\"Peter's note\"\uff08http://peterroelants.github.io/) \u3068\u3044\u3046\u30d6\u30ed\u30b0\u304c\u53c2\u8003\u306b\u306a\u3063\u305f\u306e\u3067\uff0c\u3053\u308c\u3092\u30d9\u30fc\u30b9\u306b\u30d7\u30ed\u30b0\u30e9\u30e0\u3092\u691c\u8a0e\u3057\u305f\uff0e\n\u4e0a\u8a18\u30b5\u30a4\u30c8\u304b\u3089RNN\u306e\u56f3\u3092\u5f15\u7528\u3059\u308b\uff0e\nFig. Simple RNN structure\n\n\u5165\u529b\u30e6\u30cb\u30c3\u30c8x\u304b\u3089\u30c7\u30fc\u30bf\u304c\u5165\u308a\uff0c\u91cd\u307f W_in \u3092\u4e57\u3058\u305f\u5f8c\uff0c\u96a0\u308c\u5c64\u30e6\u30cb\u30c3\u30c8s\u306b\u5165\u308b\uff0e\u30e6\u30cb\u30c3\u30c8S\u306e\u51fa\u529b\u306b\u3064\u3044\u3066\u518d\u5e30\u306e\u6d41\u308c\u304c\u3042\u3063\u3066\uff0c\u91cd\u307f W_rec \u3092\u304b\u3051\u305f\u7d50\u679c\u304c\u6b21\u306e\u6642\u523b\u306b\u30e6\u30cb\u30c3\u30c8s\u306b\u623b\u308b\uff0e\u307e\u305f\uff0c\u51fa\u529b\u306b\u5bfe\u3057\u3066\u306f\u901a\u5e38\uff0c\u91cd\u307f W_out \u3092\u8003\u616e\u3059\u308b\u5fc5\u8981\u304c\u3042\u308b\u304c\uff0c\u69cb\u9020\u3092\u3088\u308a\u5358\u7d14\u5316\u3059\u308b\u305f\u3081\u306b\uff0cW_out=1.0 \u3068\u56fa\u5b9a\u3059\u308b\u3068\u30e6\u30cb\u30c3\u30c8S\u306e\u72b6\u614b\u304c\u305d\u306e\u307e\u307e\u51fa\u529b\u3055\u308c\u308b\u69cb\u6210\u3068\u306a\u308b\uff0e\n\u5de6\u56f3\u306e\u72b6\u614b\u306b\u5bfe\u3057\u3066\uff0cBPTT\u6cd5(Backpropagation through time)\u3092\u9069\u7528\u3059\u308b\u305f\u3081\u53f3\u5074\u306e\u300c\u5c55\u958b\u3055\u308c\u305f\u300d\u72b6\u614b\u3092\u8003\u3048\u308b\uff0e\u96a0\u308c\u30e6\u30cb\u30c3\u30c8\u306e\u521d\u671f\u5024 s_0 \u306e\u72b6\u614b\u306f\uff0c\u6642\u523b\u304c\u9032\u3080\u306b\u3064\u308c\u91cd\u307f W_rec \u3092\u4e57\u3058\u306a\u304c\u3089\u53f3\u65b9\u5411\u3078\u72b6\u614b\u304c\u9077\u79fb\u3059\u308b\uff0e\u307e\u305f\u5404\u6642\u523b\u306b\u304a\u3044\u3066 [x_1, x_2, ... x_n] \u304c\u5165\u529b\u3055\u308c\u308b\uff0e\u6700\u7d42\u6642\u523b\u306b s_n \u306e\u72b6\u614b\u304c\u30e6\u30cb\u30c3\u30c8\uff59\u306b\u51fa\u529b\u3055\u308c\u308b\uff0e\n\u4ee5\u4e0a\u793a\u3057\u305f\u30e2\u30c7\u30eb\u3092Python\u30b3\u30fc\u30c9\u306b\u76f4\u3059\u3068\u4ee5\u4e0b\u306e\u3088\u3046\u306b\u306a\u308b\uff0e\uff08\"Peter's note\" \u304b\u3089\u5f15\u7528\uff0e\uff09\ndef update_state(xk, sk, wx, wRec):\n\n    return xk * wx + sk * wRec\n\ndef forward_states(X, wx, wRec):\n    # Initialise the matrix that holds all states for all input sequences.\n    # The initial state s0 is set to 0.\n    S = np.zeros((X.shape[0], X.shape[1]+1))\n    # Use the recurrence relation defined by update_state to update the \n    #  states trough time.\n    for k in range(0, X.shape[1]):\n        # S[k] = S[k-1] * wRec + X[k] * wx\n        S[:,k+1] = update_state(X[:,k], S[:,k], wx, wRec)\n\n    return S\n\n\n\u4f8b\u984c\u306f\u3069\u306e\u3088\u3046\u306a\u5185\u5bb9\u304b\uff1f\n\u307e\u305f\uff0c\u300c\u4e0a\u8a18\u306eRNN\u30e2\u30c7\u30eb\u3067\u3069\u306e\u3088\u3046\u306a\u554f\u984c\u3092\u6271\u3063\u3066\u3044\u308b\u304b\u300d\u3067\u3042\u308b\u304c\uff0c\u5165\u529b\u3068\u3057\u3066 X_k = 0. or 1.\u306e\u30d0\u30a4\u30ca\u30ea\u30fc\u306e\u6570\u5024\u3092\u5165\u529b\u3059\u308b\uff0e\u51fa\u529b\u306f\uff0c\u3053\u308c\u3089\u306e\u30d0\u30a4\u30ca\u30ea\u30fc\u306e\u5408\u8a08\u5024\u3092\u51fa\u529b\u3059\u308b\u30cd\u30c3\u30c8\u30ef\u30fc\u30af\u30e2\u30c7\u30eb\u3068\u3059\u308b\uff0e\u4f8b\u3048\u3070\uff0c\nX = [ 0.  1.  0.  0.  0.  0.  0.  0.  0.  1.]\u3000\u306b\u5bfe\u3057\u3066\uff0c\uff08\u3053\u306e\u30ea\u30b9\u30c8X\u306e\u5408\u8a08\u5024\u304c2.\u306a\u306e\u3067\uff09\nY = 2. \u306e\u51fa\u529b\u304c\u6b63\u3057\u3044\u5024\u3068\u8a2d\u5b9a\u3059\u308b\uff0e\n\u3082\u3061\u308d\u3093\uff0c\u300c\u6570\u5024\u3092\u30ab\u30a6\u30f3\u30c8\u3059\u308b\u3068\u3044\u3046\u30a2\u30eb\u30b4\u30ea\u30ba\u30e0\u300d\u306f\u4f7f\u308f\u305a\u306bRNN(\u542b\u30802\u3064\u306e\u91cd\u307f\u4fc2\u6570\uff09\u3067\u63a8\u5b9a\u3059\u308b\u306e\u304c\u4f8b\u984c\u306e\u5185\u5bb9\u3067\u3042\u308b\uff0e\n\u51fa\u529b\u5024\u304c\u9023\u7d9a\u306e\u5024\u3092\u3068\u308b\u6570\u5024\u306a\u306e\u3067\uff0c\u300c\u5206\u985e\u300d\u306e\u554f\u984c\u3067\u306a\u304f\uff0c\u300c\u56de\u5e30\u300d\u306e\u554f\u984c\u306e\u4e00\u7a2e\u3068\u8003\u3048\u308b\u3053\u3068\u304c\u3067\u304d\u308b\uff0e\u3057\u305f\u304c\u3063\u3066\uff0c\u30b3\u30b9\u30c8\u95a2\u6570\u3068\u3057\u3066\u306fMSE(mean square error)\u3092\u7528\u3044\uff0cActivation\u95a2\u6570\u306f\u901a\u3055\u305a\uff0c\u305d\u306e\u307e\u307e\u30e6\u30cb\u30c3\u30c8\u306e\u30c7\u30fc\u30bf\u3092\u901a\u3059\u3088\u3046\u306b\u3057\u3066\u3044\u308b\uff0e\n\u307e\u305a\uff08\u4e8b\u524d\u306b\u4f5c\u6210\u3057\u305f\uff09Train\u30c7\u30fc\u30bf\u3067\u5b66\u7fd2\u3092\u884c\u3044\uff0c2\u306e\u91cd\u307f\u4fc2\u6570[W_in, W_rec]\u3092\u6c42\u3081\u308b\u3053\u3068\u306b\u306a\u308b\u304c\uff0c\u4e0a\u56f3\u3092\u898b\u308c\u3070\u5bb9\u6613\u306b\u63a8\u5b9a\u3067\u304d\u308b\u304c\uff0c\u6b63\u89e3\u306f [W_in, W_rec] = [1.0, 1.0] \u3067\u3042\u308b\uff0e\n\n\u30e2\u30c7\u30eb\u5b9f\u88c5\u306e\u4e8b\u524d\u691c\u8a0e\n\u53c2\u8003\u306b\u3057\u305f\"Peter's note\"\u306e\u8a18\u4e8b\u3067\u306f\uff0cDeep Learning\u306e\u30e9\u30a4\u30d6\u30e9\u30ea\u3092\u7528\u3044\u308b\u3053\u3068\u306a\u304f\uff0cpython (with numpy) \u3092\u7528\u3044\u3066IPython Notebook\u306b\u307e\u3068\u3081\u3066\u3044\u308b\uff0e\u3053\u308c\u3092\u3053\u306e\u307e\u307e\u5199\u7d4c\u3059\u308c\u3070\uff0c\u30d6\u30ed\u30b0\u8a18\u4e8b\u901a\u308a\u306e\u7d50\u679c\u3092\u5f97\u3089\u308c\u308b\u304c\uff0c\u767a\u5c55\u6027\u3092\u8003\u616e\u3057\u3066Deep Learning\u306e\u30e9\u30a4\u30d6\u30e9\u30ea\u3092\u7528\u3044\u308b\u5b9f\u88c5\u3092\u8a66\u307f\u305f\uff0e\u9078\u629e\u80a2\u3068\u3057\u3066\u4ee5\u4e0b\u3092\u8003\u3048\u305f\uff0e\n\n\"TensorFlow\" \u3092\u7528\u3044\u308b\uff0e\n\u201dTheano\" \u3092\u7528\u3044\u308b\uff0e\n\u3088\u308a\u30cf\u30a4\u30ec\u30d9\u30eb\u306a\uff08\u62bd\u8c61\u5316\u3057\u305f\uff09\u30e9\u30a4\u30d6\u30e9\u30ea \"Keras\", \"Pylearn2\" \u7b49\u3092\u7528\u3044\u308b\uff0e\n\n\u6700\u521d\uff0c\u30aa\u30ea\u30b8\u30ca\u30eb\u306epython\u30b3\u30fc\u30c9\u3092 \"one by one\" \u3067TensorFlow\u7248\u306b\u3057\u3088\u3046\u3068\u8a66\u307f\u305f\u304c\uff0c\n    for k in range(0, X.shape[1]):\n        # S[k] = S[k-1] * wRec + X[k] * wx\n        S[:,k+1] = update_state(X[:,k], S[:,k], wx, wRec)\n\n    return S\n\n\u306e\u90e8\u5206\u306e\u30eb\u30fc\u30d7\u51e6\u7406\u304c\u3046\u307e\u304f\uff08TensorFlow\u7248\u306b\uff09\u76f4\u305b\u306a\u3044\u3053\u3068\u304c\u5206\u304b\u3063\u305f\uff0eTensorFlow\u306eTutorial\u30b3\u30fc\u30c9(ptb_word_lm.py\u306a\u3069) \u3092\u53c2\u8003\u306b\u3059\u308c\u3070\uff0c\u5f53\u7136\u4eca\u56de\u306e\u7c21\u5358\u306aRNN\u30e2\u30c7\u30eb\u3082\u5b9f\u88c5\u3067\u304d\u308b\u306f\u305a\u3067\u3042\u308b\u304c\uff0c\u95a2\u9023\u3059\u308b\u30af\u30e9\u30b9\u30e9\u30a4\u30d6\u30e9\u30ea\u304c\u8907\u96d1\u3067\u7406\u89e3\u304c\u96e3\u3057\u304b\u3063\u305f\u306e\u3067\uff0c\u4eca\u56de\u306fTensorFlow\u306e\u4f7f\u7528\u3092\u898b\u9001\u3063\u305f\uff0e\n\u307e\u305f\uff0c\u9078\u629e\u80a23\u306e\"Keras\", \"Pylearn2\"\u7b49\u306b\u3064\u3044\u3066\u306f\uff0c\u300cRNN\u306e\u5b9f\u88c5\u3092\u7406\u89e3\u3059\u308b\u300d\u3068\u3044\u3046\u76ee\u7684\u304b\u3089\u5916\u308c\u308b\u305f\u3081\u4eca\u56de\u306f\u9078\u3070\u306a\u304b\u3063\u305f\uff0e\n\u7d50\u5c40\uff0c\u9078\u629e\u80a22\u306e\"Theano\"\u7248\u306e\u30b3\u30fc\u30c9\u3092\u4f5c\u6210\u3059\u308b\u3053\u3068\u306b\u3057\u305f\uff0e\n\nRNN\u306e\u305f\u3081\u306e\u201dTheano scan\u201d\n\u30cd\u30c3\u30c8\u3067\u898b\u304b\u3051\u308bTheano\u306b\u3088\u308bRNN\u30b3\u30fc\u30c9\u306b\u5171\u901a\u3057\u3066\u3044\u308b\u306e\u306f\uff0c\u307b\u3068\u3093\u3069\u306e\u30b3\u30fc\u30c9\u3067\"Theano scan\"\u3092\u7528\u3044\u3066\u3044\u308b\u3053\u3068\u3067\u3042\u308b\uff0eTheano scan\u306f\uff0cTheano\u30d5\u30ec\u30fc\u30e0\u30ef\u30fc\u30af\u306e\u306a\u304b\u3067Loop\u51e6\u7406\uff08\u53cd\u5fa9\u51e6\u7406\uff09\uff0cIteration\u51e6\u7406\uff08\u53ce\u675f\u8a08\u7b97\uff09\u3092\u884c\u3046\u305f\u3081\u306b\u6a5f\u80fd\u3067\u3042\u308b\uff0e\u4ed5\u69d8\u304c\u8907\u96d1\u3067\uff0c\u307e\u305f\u672c\u5bb6\u30c9\u30ad\u30e5\u30e1\u30f3\u30c8(Theano Documentation)\u3092\u898b\u3066\u3082\u3059\u3050\u306b\u306f\u7406\u89e3\u304c\u96e3\u3057\u3044\uff0e\u65e5\u672c\u8a9e\u60c5\u5831\u306f\u304b\u306a\u308a\u9650\u3089\u308c\u308b\u304c\uff0csinhrks\u6c0f\u306e\u30d6\u30ed\u30b0\u8a18\u4e8b\u3092\u53c2\u8003\u306b\uff0c\u5c0f\u3055\u3044\u30b3\u30fc\u30c9\u3092Jupyter Notebook\u3067\u8a66\u3057\u306a\u304c\u3089\uff0cTheano scan\u306e\u6319\u52d5\u8abf\u67fb\u3092\u9032\u3081\u305f\uff0e\nn = T.iscalar('n')\nresult, updates = theano.scan(fn=lambda prior, nonseq: prior * 2,\n                              sequences=None,\n                              outputs_info=a, # \u4e00\u3064\u524d\u306eLoop\u306b\u304a\u3051\u308b\u5024\u3092\u53c2\u7167 --> prior\n                              non_sequences=a, # \u30b7\u30fc\u30b1\u30f3\u30b9\u3067\u306a\u3044\u5024 --> nonseq\n                              n_steps=n)\n\nmyfun1 = theano.function(inputs=[a, n], outputs=result, updates=updates)\nmyfun1(5, 3)\n# array([10, 20, 40])\n# return-1 = 5 * 2\n# return-2 = return-1 * 2\n# return-3 = return-2 * 2 \n\n\u5b9f\u884c\u7d50\u679c\uff1a\n>>> array([10, 20, 40], dtype=int32)\n\n\u3068\u3066\u3082\u8a73\u7d30\u3092\u8aac\u660e\u3057\u304d\u308c\u306a\u3044\u306e\u3067\uff0c\u4f7f\u7528\u4f8b\u3092\u3044\u304f\u3064\u304b\u53d6\u308a\u4e0a\u3052\u308b\uff0etheano.scan()\u306f\uff0c\u4e0a\u8a18\u306e\u901a\u308a\uff0c5\u7a2e\u985e\u306e\u5f15\u6570\u3092\u3068\u308b\uff0e\n\n\n\nKey Word\n\u5185\u5bb9\u3000\u3000\u3000\n\u4f7f\u7528\u4f8b\n\n\n\n\nfn\n\u53cd\u5fa9\u51e6\u7406\u306e\u305f\u3081\u306e\u95a2\u6570\nfn=lambda prior, nonseq: prior * 2\n\n\nsequences\n\u9010\u6b21\u51e6\u7406\u306e\u969b\uff0c\u8981\u7d20\u3092\u9032\u3081\u306a\u304c\u3089\u5165\u529b\u3092\u884c\u3046List, Matrix\u30bf\u30a4\u30d7\u306e\u5909\u6570\nsequences=T.arange(x)\n\n\noutputs_info\n\u9010\u6b21\u51e6\u7406\u306e\u521d\u671f\u5024\u3092\u4e0e\u3048\u308b\noutputs_info=a\n\n\nnon_sequences\n\u30b7\u30fc\u30b1\u30f3\u30b9\u3067\u306a\u3044\uff08\u53cd\u5fa9\u51e6\u7406\u3067\u4e0d\u5909\u306e\uff09\u56fa\u5b9a\u5024\nnon_sequences=a\n\n\nn_steps\n\u7e70\u308a\u8fd4\u3057\u95a2\u6570\nn_steps=n\n\n\n\n\u4e0a\u306e\u30b3\u30fc\u30c9\u3067\u306f\uff0ctheano.scan() \u306b\u5bfe\u3057\uff0c\uff08\u30b7\u30fc\u30b1\u30f3\u30b9\u3067\u306f\u306a\u3044\uff09\u521d\u671f\u5024 5 \u3068\u56de\u6570 \uff13 \u304c\u4e0e\u3048\u3089\u308c\uff0c\u53cd\u5fa9\u51e6\u7406\u306e\u5ea6\u306b\uff0c\u524d\u56de\u306e\u51e6\u7406\u306e\u7d50\u679c\u306b\u5bfe\u3057 2 \u3092\u4e57\u305a\u308b\uff0c\u3068\u3044\u3046\u51e6\u7406\u3092\u884c\u3063\u3066\u3044\u308b\uff0e\n1\u56de\u76ee\u306e\u53cd\u5fa9\u51e6\u7406 \uff1a 5 x 2 = 10\n2\u56de\u76ee\u306e\u53cd\u5fa9\u51e6\u7406 \uff1a 10 x 2 = 20\n3\u56de\u76ee\u306e\u53cd\u5fa9\u51e6\u7406 \uff1a 20 x 2 = 40\n\u3053\u306e\u7d50\u679c\uff0cresult = [10, 20, 40] \u3068\u7b97\u5b9a\u3055\u308c\u3066\u3044\u308b\uff0e\n\u3082\u3046\u5c11\u3057RNN\u3092\u610f\u8b58\u3057\u305f\u30c6\u30b9\u30c8\u304c\u4ee5\u4e0b\u3067\u3042\u308b\uff0e\nv = T.matrix('v')\ns0 = T.vector('s0')\nresult, updates = theano.scan(fn=lambda seq, prior: seq + prior * 2,\n                                             sequences=v,\n                                             outputs_info=s0,\n                                             non_sequences=None)\nmyfun2 = theano.function(inputs=[v, s0], outputs=result, updates=updates)\n\nmyfun2([[1., 0.], [0., 1.], [1., 1.]], [0.5, 0.5])\n\n\u5b9f\u884c\u7d50\u679c\uff1a\n>>> array([[ 2.,  1.],\n       [ 4.,  3.],\n       [ 9.,  7.]], dtype=float32)\n\n\u521d\u671f\u5024 [0.5, 0.5] \u304c\u95a2\u6570\u306b\u5165\u529b\u3055\u308c\u308b\uff0e$$ fn=\\texttt{lambda}\\ seq, prior:\\ seq + prior * 2$$ \u3068\u5b9a\u7fa9\u3057\u305f\u306e\u3067\uff0c\n1\u56de\u76ee\u306e\u53cd\u5fa9\u51e6\u7406 \uff1a [1., 0.] + [0.5, 0.5] x 2 = [2., 1.]\n2\u56de\u76ee\u306e\u53cd\u5fa9\u51e6\u7406 \uff1a [0., 1.] + [2., 1.] x 2 = [4., 3.]\n3\u56de\u76ee\u306e\u53cd\u5fa9\u51e6\u7406 \uff1a [1., 1.] + [4., 3.] x 2 = [9., 7.]\n\u3068\u3044\u3046\u6d41\u308c\u3067\u8a08\u7b97\u3055\u308c\u3066\u3044\u308b\uff0e\n\"theano.scan()\" \u306f\uff0cRNN\u3067\u5fc5\u8981\u306a\u51e6\u7406\u306e\u30d5\u30ed\u30fc\u30b3\u30f3\u30c8\u30ed\u30fc\u30eb\u3092\u30b5\u30dd\u30fc\u30c8\u3059\u308b\u6a5f\u80fd\u3067\u3042\u308b\uff0eTensorFlow\u306b\u3064\u3044\u3066\u540c\u69d8\u306e\u6a5f\u80fd\u306f\u73fe\u6bb5\u968e\u3067\u30b5\u30dd\u30fc\u30c8\u3055\u308c\u3066\u3044\u306a\u3044\u304c\uff0c\n\nOur white paper mentions a number of control flow operations that we've experimented with\n -- I think once we're happy with its API and confident in its implementation we will try\n  to make it available through the public API -- we're just not quite there yet. \n  It's still early days for us :)\n(GitHub TensorFlow issue #208 \u306ediscussion\u3088\u308a\u5f15\u7528\uff0e\uff09\n\n\u3068\u306e\u3053\u3068\u306a\u306e\u3067\uff0c\u5c06\u6765\u306e\u30b5\u30dd\u30fc\u30c8\u3092\u5f85\u3061\u305f\u3044\uff0e\n\uff08TensorFlow \u306eRNN model\u306b\u3064\u3044\u3066\u3069\u306e\u3088\u3046\u306a\u5b9f\u88c5\u304c\u884c\u308f\u308c\u3066\u3044\u308b\u304b\u7406\u89e3\u3067\u304d\u3066\u3044\u307e\u305b\u3093\u304c\uff0c\u3059\u3067\u306bRNN\u306e\u8a08\u7b97\u3092\u5b9f\u73fe\u3055\u305b\u3066\u3044\u308b\u3068\u3044\u3046\u3053\u3068\u306f\uff0c\u3053\u306e\u3088\u3046\u306a\"theano.scan()\"\u30e9\u30a4\u30af\u306e\u6a5f\u80fd\u304c\u300c\u5fc5\u9808\u300d\u3067\u306f\u306a\u3044\uff0c\u3068\u3044\u3046\u3053\u3068\u3092\u8868\u3057\u3066\u3044\u307e\u3059\uff0e\u3053\u306e\u4ef6\uff0c\u3082\u3046\u5c11\u3057TenforFlow\u306e\u30b5\u30f3\u30d7\u30eb\u30b3\u30fc\u30c9\u3092\u52c9\u5f37\u3059\u308b\u5fc5\u8981\u304c\u3042\u308b\u3068\u8003\u3048\u3066\u3044\u307e\u3059\uff0e\uff09\n\nTheano\u3092\u7528\u3044\u305fSimple RNN\u306e\u30b3\u30fc\u30c9\u8a73\u7d30\nTheano Scan()\u304c\u5206\u304b\u3063\u305f\u3068\u3053\u308d\u3067\uff0cSimple RNN\u306e\u30b3\u30fc\u30c9\u3092\u898b\u3066\u3044\u304f\uff0e\u307e\u305a\uff0csimpleRNN\u306e\u30af\u30e9\u30b9\u3092\u5b9a\u7fa9\u3059\u308b\uff0e\nclass simpleRNN(object):\n    #   members:  slen  : state length\n    #             w_x   : weight of input-->hidden layer\n    #             w_rec : weight of recurrnce \n    def __init__(self, slen, nx, nrec):\n        self.len = slen\n        self.w_x = theano.shared(\n            np.asarray(np.random.uniform(-.1, .1, (nx)),\n            dtype=theano.config.floatX)\n        )\n        self.w_rec = theano.shared(\n            np.asarray(np.random.uniform(-.1, .1, (nrec)),\n            dtype=theano.config.floatX)\n        )\n\n    def state_update(self, x_t, s0):\n        # this is the network updater for simpleRNN\n        def inner_fn(xv, s_tm1, wx, wr):\n            s_t = xv * wx + s_tm1 * wr\n            y_t = s_t\n\n            return [s_t, y_t]\n\n        w_x_vec = T.cast(self.w_x[0], 'float32')\n        w_rec_vec = T.cast(self.w_rec[0], 'float32')\n\n        [s_t, y_t], updates = theano.scan(fn=inner_fn,\n                                    sequences=x_t,\n                                    outputs_info=[s0, None],\n                                    non_sequences=[w_x_vec, w_rec_vec]\n                                   )\n        return y_t\n\n\n\u30af\u30e9\u30b9\u30e1\u30f3\u30d0\u3068\u3057\u3066\uff0c\u72b6\u614b(state)\u306e\u9577\u3055\u3068\u91cd\u307f(w_x, w_rec)\u3092\u4e0e\u3048\u3066\u30af\u30e9\u30b9\u3092\u5b9a\u7fa9\u3059\u308b\uff0e\u30af\u30e9\u30b9\u30e1\u30bd\u30c3\u30c9 state_update() \u306f\uff0cstate\u306e\u521d\u671f\u5024 s0 \u3068\u5165\u529b\u7cfb\u5217 x_t \u304c\u4e0e\u3048\u3089\u308c\u305f\u3068\u304d\u306b\u30cd\u30c3\u30c8\u30ef\u30fc\u30af\u306e\u72b6\u614b\u3092\u66f4\u65b0\u3057\uff0cy_t \uff08\u51fa\u529b\u7cfb\u5217\uff09 \u3092\u7b97\u5b9a\u3059\u308b\uff0ey_t \u306f\u30d9\u30af\u30c8\u30eb\u3067\u3042\u308b\u304c\uff0c\u30e1\u30a4\u30f3\u306e\u51e6\u7406\u3067\u306f\uff0cy = y_t[-1] \u306e\u3088\u3046\u306b\u6700\u7d42\u5024\u306e\u307f\u3092\u53d6\u308a\u51fa\u3057\u3066\u30b3\u30b9\u30c8\u95a2\u6570\u306e\u7b97\u5b9a\u306b\u7528\u3044\u308b\uff0e\n\u30e1\u30a4\u30f3\u306e\u51e6\u7406\u3067\u306f\uff0c\u307e\u305a\u5b66\u7fd2\u306b\u7528\u3044\u308b\u30c7\u30fc\u30bf\u3092\u4f5c\u6210\u3059\u308b\uff0e\uff08\u307b\u307c\uff0c\u30cd\u30bf\u5143\"Peter's note\"\u306e\u901a\u308a\uff0e\uff09\n    np.random.seed(seed=1)\n\n    # Create Dataset by program\n    num_samples = 20\n    seq_len = 10\n\n    trX = np.zeros((num_samples, seq_len))\n    for row_idx in range(num_samples):\n        trX[row_idx,:] = np.around(np.random.rand(seq_len)).astype(int)\n    trY = np.sum(trX, axis=1)\n    trX = trX.astype(np.float32)\n    trX = trX.T                    # need 'List of vector' shape dataset\n    trY = trY.astype(np.float32)\n    # s0 is time-zero state \n    s0np = np.zeros((num_samples), dtype=np.float32)\n\n\ntrX\u304c\uff0c\u9577\u305510\u306e\u7cfb\u5217\u30c7\u30fc\u30bf\uff0c20\u30b5\u30f3\u30d7\u30eb\u3068\u306a\u308b\uff0e\u3053\u3053\u3067\u30dd\u30a4\u30f3\u30c8\u306f\uff0ctrX = trX.T \u3068\u30de\u30c8\u30ea\u30af\u30b9\u3092\u8ee2\u7f6e\u3055\u305b\u3066\u3044\u308b\u3053\u3068\u3067\u3042\u308b\uff0e\u4e00\u822c\u7684\u306a\u6a5f\u68b0\u5b66\u7fd2\u306e\u30c7\u30fc\u30bf\u30bb\u30c3\u30c8\u3068\u3057\u3066\u306f\uff0c\u6a2a\u65b9\u5411\uff08column)\u306b\uff11\u3064\u306e\u30c7\u30fc\u30bf\u306e\u7279\u5fb4\u91cf\u3092\u4e26\u3079\uff0c\u305d\u308c\u3092\u7e26\u65b9\u5411\uff08row)\u306b\u30b5\u30f3\u30d7\u30eb\u6570\u5206\uff0c\u4e26\u3079\u308b\u3053\u3068\u304c\u591a\u3044\u3068\u601d\u308f\u308c\u308b\uff0e\n  Data Set Shape\n                  feature1   feature2   feature3  ...\n     sample1:        -          -          -\n     sample2:        -          -          -\n     sample3:        -          -          -\n       .\n       .\n\n\u3057\u304b\u3057\u306a\u304c\u3089\uff0c\u4eca\u56de\u306f\uff0c\u6642\u7cfb\u5217\u30c7\u30fc\u30bf\u3092 theano.scan() \u3067\u66f4\u65b0\u3055\u305b\u308b\u969b\uff0c\u7e26\u65b9\u5411\u306b\u30b0\u30eb\u30fc\u30d4\u30f3\u30b0\u3057\u3066\u30c7\u30fc\u30bf\u3092\u6e21\u3059\u5fc5\u8981\u304c\u3042\u3063\u305f\uff0e\n\uff08\u4ee5\u4e0b\u306e\u3088\u3046\u306b\u30b0\u30eb\u30fc\u30d7\u5316\u3059\u308b\u3053\u3068\u3067\uff0ctheano.scan() \u306e\u52d5\u4f5c\u3068\u6574\u5408\u6027\u3092\u3068\u308b\uff0e\uff09\n  Data Set Shape (updated)\n               [  time1[sample1,  time2[sample1,  time3[sample1 ...    ]\n                        sample2,        sample2,        sample2,\n                        sample3,        sample3,        sample3,\n                         ...    ]         ...   ]         ...    ]\n\n\u3053\u308c\u3092\u7c21\u4fbf\u306b\u5b9f\u73fe\u3059\u308b\u305f\u3081\u306b\uff0c\u30de\u30c8\u30ea\u30af\u30b9\u306e\u8ee2\u7f6e\u3092\u884c\u3044\uff0ctheano.scan()\u3078\u306e\u5165\u529b\u3068\u3057\u3066\u51e6\u7406\u3057\u3066\u3044\u308b\uff0e\n\u3053\u306e\u5f8c\uff0cTheano\u306e\u30b0\u30e9\u30d5\uff0c\u30e2\u30c7\u30eb\u7b97\u5b9a\u5024 y_hypo \u3068Train\u30c7\u30fc\u30bf\u30e9\u30d9\u30eb y_ \u304b\u3089\u30b3\u30b9\u30c8 loss \u3092\u6c42\u3081\u3066\u3044\u308b\uff0e\n    # Tensor Declaration\n    x_t = T.matrix('x_t')\n    x = T.matrix('x')\n    y_ = T.vector('y_')\n    s0 = T.vector('s0')\n    y_hypo = T.vector('y_hypo')\n\n    net = simpleRNN(seq_len, 1, 1)  \n    y_t = net.state_update(x_t, s0)\n    y_hypo = y_t[-1]\n    loss = ((y_ - y_hypo) ** 2).sum()\n\n\n\u3053\u3053\u307e\u3067\u6765\u308c\u3070\uff0c\u5f8c\u306f\u304a\u99b4\u67d3\u307f\u306e\u65b9\u6cd5\u3067\u5b66\u7fd2\u3092\u9032\u3081\u308b\u3053\u3068\u304c\u3067\u304d\u308b\uff0e\n# Train Net Model\n    params = [net.w_x, net.w_rec]\n    optimizer = GradientDescentOptimizer(params, learning_rate=1.e-5)\n    train_op = optimizer.minimize(loss)\n\n    # Compile ... define theano.function \n    train_model = theano.function(\n        inputs=[],\n        outputs=[loss],\n        updates=train_op,\n        givens=[(x_t, trX), (y_, trY), (s0, s0np)],\n        allow_input_downcast=True\n    )\n\n    n_epochs = 2001\n    epoch = 0\n\n    w_x_ini = (net.w_x).get_value()\n    w_rec_ini = (net.w_rec).get_value()\n    print('Initial weights: wx = %8.4f, wRec = %8.4f' \\\n                % (w_x_ini, w_rec_ini))\n\n    while (epoch < n_epochs):\n        epoch += 1\n        loss = train_model()\n        if epoch % 100 == 0:\n            print('epoch[%5d] : cost =%8.4f' % (epoch, loss[0]))\n\n    w_x_final = (net.w_x).get_value()\n    w_rec_final = (net.w_rec).get_value()\n    print('Final weights : wx = %8.4f, wRec = %8.4f' \\\n                % (w_x_final, w_rec_final))\n\n\u4eca\u56de\uff0c\u30aa\u30d7\u30c6\u30a3\u30de\u30a4\u30b6\u306f\uff0cGradientDecent\uff08\u52fe\u914d\u964d\u4e0b\u6cd5\uff09\u3068RMSPropOptimizer(RMSProp\u6cd5)\u306e2\u3064\u7528\u610f\u3057\u3066\u7528\u3044\u305f\uff0e\uff08\u30aa\u30d7\u30c6\u30a3\u30de\u30a4\u30b6\u306e\u90e8\u5206\u306e\u30b3\u30fc\u30c9\u306f\uff0c\u4eca\u56de\u7701\u7565\u3044\u305f\u3057\u307e\u3059\uff0eRMSProp\u6cd5\u306b\u3064\u3044\u3066\u306f\uff0c\u5f8c\u306b\u793a\u3059Web\u30b5\u30a4\u30c8\u3092\u53c2\u7167\u3057\u307e\u3057\u305f\uff0e\uff09\n\n\u5b9f\u884c\u7d50\u679c\n\u300cRNN\u306f\u4e00\u822c\u7684\u306b\u5b66\u7fd2\u3092\u9032\u307e\u305b\u308b\u304c\u306e\u96e3\u3057\u3044\u300d\u3068\u3044\u3046\u8a18\u8ff0\u306f\uff0c\u3044\u308d\u3044\u308d\u306a\u3068\u3053\u308d\u3067\u898b\u53d7\u3051\u3089\u308c\u308b\u304c\uff0c\u305d\u308c\u3092\u5b9f\u611f\u3055\u305b\u308b\u7d50\u679c\u3068\u306a\u3063\u305f\uff0e\n\n\u6761\u4ef6\uff11\uff0e\u52fe\u914d\u964d\u4e0b\u6cd5(GradientDescent), \u5b66\u7fd2\u7387= 1.0e-5\nInitial weights: wx =   0.0900, wRec =   0.0113\nepoch[  100] : cost =529.6915\nepoch[  200] : cost =504.5684\nepoch[  300] : cost =475.3019\nepoch[  400] : cost =435.9507\nepoch[  500] : cost =362.6525\nepoch[  600] : cost =  0.2677\nepoch[  700] : cost =  0.1585\nepoch[  800] : cost =  0.1484\nepoch[  900] : cost =  0.1389\nepoch[ 1000] : cost =  0.1300\nepoch[ 1100] : cost =  0.1216\nepoch[ 1200] : cost =  0.1138\nepoch[ 1300] : cost =  0.1064\nepoch[ 1400] : cost =  0.0995\nepoch[ 1500] : cost =  0.0930\nepoch[ 1600] : cost =  0.0870\nepoch[ 1700] : cost =  0.0813\nepoch[ 1800] : cost =  0.0760\nepoch[ 1900] : cost =  0.0710\nepoch[ 2000] : cost =  0.0663\nFinal weights : wx =   1.0597, wRec =   0.9863\n\n\n\u5b66\u7fd2\u306e\u7d50\u679c\uff0c\u6b63\u89e3 [w_x, w_rec] = [1.0, 1.0] \u306e\u8fd1\u4f3c\u5024\u3092\u5f97\u308b\u3053\u3068\u304c\u3067\u304d\u3066\u3044\u308b\uff0e\u4e0b\u306e\u56f3\u306f\uff0c\u30b3\u30b9\u30c8\u95a2\u6570\u304c\u4f4e\u6e1b\u3059\u308b\u69d8\u5b50\u3092\u793a\u3057\u3066\u3044\u308b\uff0e\nFig. Loss curve (GradientDescent)\n\n\n\u6761\u4ef62. RMSProp\u6cd5\uff0c\u5b66\u7fd2\u7387=0.001\nInitial weights: wx =   0.0900, wRec =   0.0113\nepoch[  100] : cost =  5.7880\nepoch[  200] : cost =  0.3313\nepoch[  300] : cost =  0.0181\nepoch[  400] : cost =  0.0072\nepoch[  500] : cost =  0.0068\nepoch[  600] : cost =  0.0068\nepoch[  700] : cost =  0.0068\nepoch[  800] : cost =  0.0068\nepoch[  900] : cost =  0.0068\nepoch[ 1000] : cost =  0.0068\nepoch[ 1100] : cost =  0.0068\nepoch[ 1200] : cost =  0.0068\nepoch[ 1300] : cost =  0.0068\nepoch[ 1400] : cost =  0.0068\nepoch[ 1500] : cost =  0.0068\nepoch[ 1600] : cost =  0.0068\nepoch[ 1700] : cost =  0.0068\nepoch[ 1800] : cost =  0.0068\nepoch[ 1900] : cost =  0.0068\nepoch[ 2000] : cost =  0.0068\nFinal weights : wx =   0.9995, wRec =   0.9993\n\n\nFig. Loss curve (RMSProp)\n\n\u4eca\u56de\u306e\u30e2\u30c7\u30eb\u3067\u306f\uff0c\u30b3\u30b9\u30c8\u95a2\u6570 vs. parameters \u306e\u975e\u7dda\u5f62\u6027\u304c\u975e\u5e38\u306b\u5f37\u3044\u3082\u306e\u3068\u306a\u3063\u3066\u3044\u308b\uff0e\u5b66\u7fd2\u7387\u3092\u5927\u304d\u304f\u3068\u308b\u3068\u3059\u3050\u306b\u6570\u5024\u304c\u767a\u6563\u3057\u3066\u3057\u307e\u3046\u305f\u3081\uff0c\u52fe\u914d\u964d\u4e0b\u6cd5(Gradient Descent) \u3067\u306f\uff0c\u5b66\u7fd2\u7387 = 1.0e-5 \u3068\u304b\u306a\u308a\u5c0f\u3055\u304f\u8a2d\u5b9a\u3059\u308b\u5fc5\u8981\u304c\u3042\u3063\u305f\uff0e\u4e00\u65b9\u3067\uff0cRNN\u306b\u5411\u304f\u3068\u8a00\u308f\u308c\u308bRMSProp\u6cd5\u3067\u306f\uff0c\u5b66\u7fd2\u7387 = 0.001 \u3067\u3082\u554f\u984c\u306a\u304f\u5b66\u7fd2\u3092\u9032\u3081\u308b\u3053\u3068\u304c\u3067\u304d\u3066\u3044\u308b\uff0e\n\uff08\u88dc\u8db3\uff09\n\u53c2\u8003\u306b\u3057\u305f \"Peter's note\" \u306e\u30d6\u30ed\u30b0\u3067\u306f\uff0c\u30b3\u30b9\u30c8\u95a2\u6570\u306e\u72b6\u6cc1\u3068RMSProp\uff08\u5f15\u7528\u5143\u306e\u30d6\u30ed\u30b0\u3067\u306f\"Rprop\"\u3068\u3044\u3046\u547c\u3073\u540d\uff09\u306b\u3064\u3044\u3066\u8a73\u3057\u3044\u8aac\u660e\u304c\u63b2\u8f09\u3055\u308c\u3066\u3044\u307e\u3059\uff0e\u30b3\u30b9\u30c8\u95a2\u6570\u306e\u975e\u7dda\u5f62\u6027\u304c\u8272\u306e\u6fc3\u6de1\u3067Visual\u5316\u3055\u308c\u3066\u3044\u307e\u3059\u306e\u3067\u95a2\u5fc3\u306e\u3042\u308b\u65b9\u306f\u53c2\u7167\u3057\u3066\u307f\u3066\u304f\u3060\u3055\u3044\uff0e\uff08\u4e0b\u30ea\u30f3\u30af\u306b\u306a\u308a\u307e\u3059\uff0e\uff09\n\n\u53c2\u8003\u6587\u732e (web site)\n\nPeter's note - How to implement a recurrent neural network\nhttp://peterroelants.github.io/\n\nPython Theano function / scan \u306e\u6319\u52d5\u307e\u3068\u3081 - StatsFragments(sinhrks\u3055\u3093\u30d6\u30ed\u30b0\uff09\nhttp://sinhrks.hatenablog.com/entry/2015/04/25/233025\n\nTheano scan\u3000- Looping in Theano\nhttp://deeplearning.net/software/theano/library/scan.html\n\nTheano optimizers - Gist/ kastnerkyle/opimizers.py\nhttps://gist.github.com/kastnerkyle/816134462577399ee8b2\n(RMSProp\u6cd5\u30aa\u30d7\u30c6\u30a3\u30de\u30a4\u30b6\u30fc\u306e\u5b9f\u88c5\u4f8b\u3067\u3059\uff0e\u4eca\u56de\uff0c\u3053\u308c\u3092\u53c2\u8003\u306b\u3055\u305b\u3066\u3044\u305f\u3060\u304d\u307e\u3057\u305f\uff0e\uff09\n\u6df1\u5c64\u5b66\u7fd2\uff0c\u8b1b\u8ac7\u793e\u6a5f\u68b0\u5b66\u7fd2\u30d7\u30ed\u30d5\u30a7\u30c3\u30b7\u30e7\u30ca\u30eb\u30b7\u30ea\u30fc\u30ba\n\u4eca\u4e00\u5ea6Theano\u306e\u57fa\u672c\u3092\u5b66\u3076 - Qiita \nhttp://qiita.com/TomokIshii/items/1f483e9d4bfeb05ae231\n\n\n\nRecurrent Neural Network\uff08\u518d\u5e30\u578b\u30cb\u30e5\u30fc\u30e9\u30eb\u30cd\u30c3\u30c8\uff09\u306b\u95a2\u5fc3\u306f\u3042\u308b\u304c\uff0c\u306a\u304b\u306a\u304b\u30b3\u30fc\u30c9\u4f5c\u6210\u306b\u624b\u304c\u3064\u304b\u306a\u3044\uff0c\u3053\u306e\u3088\u3046\u306a\u30b1\u30fc\u30b9\u304c\u591a\u304f\u306a\u3044\u3060\u308d\u3046\u304b\uff1f\u7406\u7531\u306f\u3044\u304f\u3064\u304b\u3042\u308b\u304c\uff0c\u79c1\u306e\u5834\u5408\u306f\u6b21\u306e\u3088\u3046\u306a\u3082\u306e\u304c\u601d\u3044\u5f53\u305f\u308b\uff0e  \n\n1. \u5358\u7d14\u306b\u30cd\u30c3\u30c8\u30ef\u30fc\u30af\u306e\u69cb\u6210\u304c\u8907\u96d1\uff0eMLP(Multi-layer Perceptron)\u304b\u3089\u5165\u9580\u3057\u3066CNN(Convolutional-NN)\u306b\u9032\u3080\u307e\u3067\u306f\uff0c\u7279\u6b8a\u306aLayer\u304c\u3042\u308b\u306b\u305b\u3088\uff0c\u4fe1\u53f7\u306e\u6d41\u308c\u306f\u9806\u65b9\u5411\u306e\u307f\u3067\u3042\u3063\u305f\uff0e\uff08\u8aa4\u5dee\u306e\u8a08\u7b97\u306f\u9664\u304f\uff0e\uff09\n2. MLP\u3084CNN\u306b\u304a\u3044\u3066\u306f\u5206\u304b\u308a\u3084\u3059\u3044\u4f8b\u984c\uff0c\uff08Deep Learning\u306e\u2019Hello World'\u3068\u79f0\u3055\u308c\u308b\uff09\"MNIST\" \u304c\u3042\u3063\u305f\u304c\uff0c\u305d\u306e\u3088\u3046\u306a\u6a19\u6e96\u7684\u306a(\u30b9\u30bf\u30f3\u30c0\u30fc\u30c9\u306a\uff09\u4f8b\u984c\u304cRNN\u306b\u306f\u306a\u3044\uff0e\n\n\u56e0\u307f\u306bTheano\u306eDeep Learning\u3084TensorFlow\u306eTutorial\u306f\uff0c\u8a00\u8a9e\u30e2\u30c7\u30eb\u3092\u6271\u3063\u305f\u3082\u306e\u3067\u3042\u308b\uff0e\u8a00\u8a9e\u30e2\u30c7\u30eb\u306b\u7cbe\u901a\u3055\u308c\u3066\u3044\u308b\u65b9\u306f\u3059\u3050\u306b\u53d6\u308a\u304b\u304b\u308c\u308b\u304b\u3082\u3057\u308c\u306a\u3044\u304c\uff0c\u521d\u5fc3\u8005\u306f\u307e\u305a\u300c\u4f8b\u984c\u304c\u4f55\u3092\u89e3\u3053\u3046\u3068\u3057\u3066\u3044\u308b\u304b\u300d\u306b\u3064\u3044\u3066\u7406\u89e3\u3059\u308b\u5fc5\u8981\u304c\u3042\u308b\uff0e\n\n\u4eca\u56de\u306f\uff0c\u8a00\u8a9e\u30e2\u30c7\u30eb\u3067\u306a\u3044\uff0c\u3088\u308a\u5358\u7d14\u306a\u6570\u5217\u3092\u6271\u3046\u4f8b\u984c\u3092\u53d6\u308a\u4e0a\u3052\uff0c\u7c21\u5358\u306aRecurrent Neural Network\uff08RNN)\u3092\u5b9f\u88c5\u3057\u3066\u307f\u308b\u3053\u3068\u306b\u3057\u305f\uff0e\n\n(\u4f7f\u7528\u3057\u305f\u30d7\u30ed\u30b0\u30e9\u30df\u30f3\u30b0\u74b0\u5883\u306f\uff0cpython 2.7.11, Theano 0.7.0\u306b\u306a\u308a\u307e\u3059\uff0e\uff09\n\n## \u30b7\u30f3\u30d7\u30eb\u306aRNN\u69cb\u9020\n\nRNN\u3092\u8abf\u3079\u308b\u306b\u3042\u305f\u308a\uff0c\u521d\u3081\u306b\"TensorFlow\"\u306eTutorial(ptb_word_lm.py)\u3092\u52d5\u304b\u3057\u3066\u307f\u305f\u304c\uff0c\n\"epoch\"\u306e\u6570\u5024\u304c\u5897\u3059\u306b\u3057\u305f\u304c\u3044\"perplexity\"(\u8907\u96d1\u3055?)\u306e\u5909\u6570\u304c\u6e1b\u3063\u3066\u3044\u304f\u69d8\u5b50\u304c\u898b\u3089\u308c\u308b\uff0e\u3057\u304b\u3057\u306a\u304c\u3089\uff0c\u305d\u308c\u304c\u4f55\u3092\u89e3\u3044\u3066\u3044\u308b\u304b\u306b\u3064\u3044\u3066\u306f\uff0c\u8a73\u7d30\u306f\u7406\u89e3\u3067\u304d\u306a\u304b\u3063\u305f\uff0eRNN\u306e\u30e2\u30c7\u30eb\u3068\u3057\u3066\u3082LSTM(Long Short-term Memory)\u3092\u7528\u3044\u3066\u3044\u308b\u306e\u3067\uff0c\u3053\u308c\u3067RNN\u5165\u9580\u3068\u3044\u3046\u306e\u306f\u6577\u5c45\u304c\u9ad8\u3044\u3068\u611f\u3058\u305f\uff0e\n\n\u6587\u732e\u300c\u6df1\u5c64\u5b66\u7fd2\u300d\u3067\u306f\u30b7\u30f3\u30d7\u30eb\u306aRNN\u3068\u3057\u3066Elman\u30cd\u30c3\u30c8\u304c\u7d39\u4ecb\u3055\u308c\u3066\u3044\u308b\uff0e\u307e\u305f\uff0c\"Elman RNN\"\u3092\u30ad\u30fc\u30ef\u30fc\u30c9\u306b\u8abf\u3079\u305f\u3068\u3053\u308d\uff0cSimple\u306aRNN\u3092\u7d39\u4ecb\u3059\u308b\"Peter's note\"\uff08http://peterroelants.github.io/) \u3068\u3044\u3046\u30d6\u30ed\u30b0\u304c\u53c2\u8003\u306b\u306a\u3063\u305f\u306e\u3067\uff0c\u3053\u308c\u3092\u30d9\u30fc\u30b9\u306b\u30d7\u30ed\u30b0\u30e9\u30e0\u3092\u691c\u8a0e\u3057\u305f\uff0e\n\n\u4e0a\u8a18\u30b5\u30a4\u30c8\u304b\u3089RNN\u306e\u56f3\u3092\u5f15\u7528\u3059\u308b\uff0e\n\n**Fig. Simple RNN structure**\n![SRNmodel2.png](https://qiita-image-store.s3.amazonaws.com/0/74152/96fd7330-4d43-5e3f-5c52-d60330476d98.png)\n\n\u5165\u529b\u30e6\u30cb\u30c3\u30c8x\u304b\u3089\u30c7\u30fc\u30bf\u304c\u5165\u308a\uff0c\u91cd\u307f W_in \u3092\u4e57\u3058\u305f\u5f8c\uff0c\u96a0\u308c\u5c64\u30e6\u30cb\u30c3\u30c8s\u306b\u5165\u308b\uff0e\u30e6\u30cb\u30c3\u30c8S\u306e\u51fa\u529b\u306b\u3064\u3044\u3066\u518d\u5e30\u306e\u6d41\u308c\u304c\u3042\u3063\u3066\uff0c\u91cd\u307f W_rec \u3092\u304b\u3051\u305f\u7d50\u679c\u304c\u6b21\u306e\u6642\u523b\u306b\u30e6\u30cb\u30c3\u30c8s\u306b\u623b\u308b\uff0e\u307e\u305f\uff0c\u51fa\u529b\u306b\u5bfe\u3057\u3066\u306f\u901a\u5e38\uff0c\u91cd\u307f W_out \u3092\u8003\u616e\u3059\u308b\u5fc5\u8981\u304c\u3042\u308b\u304c\uff0c\u69cb\u9020\u3092\u3088\u308a\u5358\u7d14\u5316\u3059\u308b\u305f\u3081\u306b\uff0cW_out=1.0 \u3068\u56fa\u5b9a\u3059\u308b\u3068\u30e6\u30cb\u30c3\u30c8S\u306e\u72b6\u614b\u304c\u305d\u306e\u307e\u307e\u51fa\u529b\u3055\u308c\u308b\u69cb\u6210\u3068\u306a\u308b\uff0e\n\n\u5de6\u56f3\u306e\u72b6\u614b\u306b\u5bfe\u3057\u3066\uff0cBPTT\u6cd5(Backpropagation through time)\u3092\u9069\u7528\u3059\u308b\u305f\u3081\u53f3\u5074\u306e\u300c\u5c55\u958b\u3055\u308c\u305f\u300d\u72b6\u614b\u3092\u8003\u3048\u308b\uff0e\u96a0\u308c\u30e6\u30cb\u30c3\u30c8\u306e\u521d\u671f\u5024 s_0 \u306e\u72b6\u614b\u306f\uff0c\u6642\u523b\u304c\u9032\u3080\u306b\u3064\u308c\u91cd\u307f W_rec \u3092\u4e57\u3058\u306a\u304c\u3089\u53f3\u65b9\u5411\u3078\u72b6\u614b\u304c\u9077\u79fb\u3059\u308b\uff0e\u307e\u305f\u5404\u6642\u523b\u306b\u304a\u3044\u3066 [x_1, x_2, ... x_n] \u304c\u5165\u529b\u3055\u308c\u308b\uff0e\u6700\u7d42\u6642\u523b\u306b s_n \u306e\u72b6\u614b\u304c\u30e6\u30cb\u30c3\u30c8\uff59\u306b\u51fa\u529b\u3055\u308c\u308b\uff0e\n\n\u4ee5\u4e0a\u793a\u3057\u305f\u30e2\u30c7\u30eb\u3092Python\u30b3\u30fc\u30c9\u306b\u76f4\u3059\u3068\u4ee5\u4e0b\u306e\u3088\u3046\u306b\u306a\u308b\uff0e\uff08\"Peter's note\" \u304b\u3089\u5f15\u7528\uff0e\uff09\n\n```py\ndef update_state(xk, sk, wx, wRec):\n\n    return xk * wx + sk * wRec\n\ndef forward_states(X, wx, wRec):\n    # Initialise the matrix that holds all states for all input sequences.\n    # The initial state s0 is set to 0.\n    S = np.zeros((X.shape[0], X.shape[1]+1))\n    # Use the recurrence relation defined by update_state to update the \n    #  states trough time.\n    for k in range(0, X.shape[1]):\n        # S[k] = S[k-1] * wRec + X[k] * wx\n        S[:,k+1] = update_state(X[:,k], S[:,k], wx, wRec)\n    \n    return S\n```\n\n## \u4f8b\u984c\u306f\u3069\u306e\u3088\u3046\u306a\u5185\u5bb9\u304b\uff1f\n\n\u307e\u305f\uff0c\u300c\u4e0a\u8a18\u306eRNN\u30e2\u30c7\u30eb\u3067\u3069\u306e\u3088\u3046\u306a\u554f\u984c\u3092\u6271\u3063\u3066\u3044\u308b\u304b\u300d\u3067\u3042\u308b\u304c\uff0c\u5165\u529b\u3068\u3057\u3066 X_k = 0. or 1.\u306e\u30d0\u30a4\u30ca\u30ea\u30fc\u306e\u6570\u5024\u3092\u5165\u529b\u3059\u308b\uff0e\u51fa\u529b\u306f\uff0c\u3053\u308c\u3089\u306e\u30d0\u30a4\u30ca\u30ea\u30fc\u306e\u5408\u8a08\u5024\u3092\u51fa\u529b\u3059\u308b\u30cd\u30c3\u30c8\u30ef\u30fc\u30af\u30e2\u30c7\u30eb\u3068\u3059\u308b\uff0e\u4f8b\u3048\u3070\uff0c  \nX = [ 0.  1.  0.  0.  0.  0.  0.  0.  0.  1.]\u3000\u306b\u5bfe\u3057\u3066\uff0c\uff08\u3053\u306e\u30ea\u30b9\u30c8X\u306e\u5408\u8a08\u5024\u304c2.\u306a\u306e\u3067\uff09\nY = 2. \u306e\u51fa\u529b\u304c\u6b63\u3057\u3044\u5024\u3068\u8a2d\u5b9a\u3059\u308b\uff0e  \n\u3082\u3061\u308d\u3093\uff0c\u300c\u6570\u5024\u3092\u30ab\u30a6\u30f3\u30c8\u3059\u308b\u3068\u3044\u3046\u30a2\u30eb\u30b4\u30ea\u30ba\u30e0\u300d\u306f\u4f7f\u308f\u305a\u306bRNN(\u542b\u30802\u3064\u306e\u91cd\u307f\u4fc2\u6570\uff09\u3067\u63a8\u5b9a\u3059\u308b\u306e\u304c\u4f8b\u984c\u306e\u5185\u5bb9\u3067\u3042\u308b\uff0e\n\n\u51fa\u529b\u5024\u304c\u9023\u7d9a\u306e\u5024\u3092\u3068\u308b\u6570\u5024\u306a\u306e\u3067\uff0c\u300c\u5206\u985e\u300d\u306e\u554f\u984c\u3067\u306a\u304f\uff0c\u300c\u56de\u5e30\u300d\u306e\u554f\u984c\u306e\u4e00\u7a2e\u3068\u8003\u3048\u308b\u3053\u3068\u304c\u3067\u304d\u308b\uff0e\u3057\u305f\u304c\u3063\u3066\uff0c\u30b3\u30b9\u30c8\u95a2\u6570\u3068\u3057\u3066\u306fMSE(mean square error)\u3092\u7528\u3044\uff0cActivation\u95a2\u6570\u306f\u901a\u3055\u305a\uff0c\u305d\u306e\u307e\u307e\u30e6\u30cb\u30c3\u30c8\u306e\u30c7\u30fc\u30bf\u3092\u901a\u3059\u3088\u3046\u306b\u3057\u3066\u3044\u308b\uff0e\n\n\u307e\u305a\uff08\u4e8b\u524d\u306b\u4f5c\u6210\u3057\u305f\uff09Train\u30c7\u30fc\u30bf\u3067\u5b66\u7fd2\u3092\u884c\u3044\uff0c2\u306e\u91cd\u307f\u4fc2\u6570[W_in, W_rec]\u3092\u6c42\u3081\u308b\u3053\u3068\u306b\u306a\u308b\u304c\uff0c\u4e0a\u56f3\u3092\u898b\u308c\u3070\u5bb9\u6613\u306b\u63a8\u5b9a\u3067\u304d\u308b\u304c\uff0c\u6b63\u89e3\u306f `[W_in, W_rec] = [1.0, 1.0]` \u3067\u3042\u308b\uff0e\n\n## \u30e2\u30c7\u30eb\u5b9f\u88c5\u306e\u4e8b\u524d\u691c\u8a0e\n\n\u53c2\u8003\u306b\u3057\u305f\"Peter's note\"\u306e\u8a18\u4e8b\u3067\u306f\uff0cDeep Learning\u306e\u30e9\u30a4\u30d6\u30e9\u30ea\u3092\u7528\u3044\u308b\u3053\u3068\u306a\u304f\uff0cpython (with numpy) \u3092\u7528\u3044\u3066IPython Notebook\u306b\u307e\u3068\u3081\u3066\u3044\u308b\uff0e\u3053\u308c\u3092\u3053\u306e\u307e\u307e\u5199\u7d4c\u3059\u308c\u3070\uff0c\u30d6\u30ed\u30b0\u8a18\u4e8b\u901a\u308a\u306e\u7d50\u679c\u3092\u5f97\u3089\u308c\u308b\u304c\uff0c\u767a\u5c55\u6027\u3092\u8003\u616e\u3057\u3066Deep Learning\u306e\u30e9\u30a4\u30d6\u30e9\u30ea\u3092\u7528\u3044\u308b\u5b9f\u88c5\u3092\u8a66\u307f\u305f\uff0e\u9078\u629e\u80a2\u3068\u3057\u3066\u4ee5\u4e0b\u3092\u8003\u3048\u305f\uff0e\n\n1. \"TensorFlow\" \u3092\u7528\u3044\u308b\uff0e\n2. \u201dTheano\" \u3092\u7528\u3044\u308b\uff0e\n3. \u3088\u308a\u30cf\u30a4\u30ec\u30d9\u30eb\u306a\uff08\u62bd\u8c61\u5316\u3057\u305f\uff09\u30e9\u30a4\u30d6\u30e9\u30ea \"Keras\", \"Pylearn2\" \u7b49\u3092\u7528\u3044\u308b\uff0e\n\n\u6700\u521d\uff0c\u30aa\u30ea\u30b8\u30ca\u30eb\u306epython\u30b3\u30fc\u30c9\u3092 \"one by one\" \u3067TensorFlow\u7248\u306b\u3057\u3088\u3046\u3068\u8a66\u307f\u305f\u304c\uff0c\n\n```py\n    for k in range(0, X.shape[1]):\n        # S[k] = S[k-1] * wRec + X[k] * wx\n        S[:,k+1] = update_state(X[:,k], S[:,k], wx, wRec)\n    \n    return S\n```\n\u306e\u90e8\u5206\u306e\u30eb\u30fc\u30d7\u51e6\u7406\u304c\u3046\u307e\u304f\uff08TensorFlow\u7248\u306b\uff09\u76f4\u305b\u306a\u3044\u3053\u3068\u304c\u5206\u304b\u3063\u305f\uff0eTensorFlow\u306eTutorial\u30b3\u30fc\u30c9(ptb_word_lm.py\u306a\u3069) \u3092\u53c2\u8003\u306b\u3059\u308c\u3070\uff0c\u5f53\u7136\u4eca\u56de\u306e\u7c21\u5358\u306aRNN\u30e2\u30c7\u30eb\u3082\u5b9f\u88c5\u3067\u304d\u308b\u306f\u305a\u3067\u3042\u308b\u304c\uff0c\u95a2\u9023\u3059\u308b\u30af\u30e9\u30b9\u30e9\u30a4\u30d6\u30e9\u30ea\u304c\u8907\u96d1\u3067\u7406\u89e3\u304c\u96e3\u3057\u304b\u3063\u305f\u306e\u3067\uff0c\u4eca\u56de\u306fTensorFlow\u306e\u4f7f\u7528\u3092\u898b\u9001\u3063\u305f\uff0e\n\n\u307e\u305f\uff0c\u9078\u629e\u80a23\u306e\"Keras\", \"Pylearn2\"\u7b49\u306b\u3064\u3044\u3066\u306f\uff0c\u300cRNN\u306e\u5b9f\u88c5\u3092\u7406\u89e3\u3059\u308b\u300d\u3068\u3044\u3046\u76ee\u7684\u304b\u3089\u5916\u308c\u308b\u305f\u3081\u4eca\u56de\u306f\u9078\u3070\u306a\u304b\u3063\u305f\uff0e\n\n\u7d50\u5c40\uff0c\u9078\u629e\u80a22\u306e\"Theano\"\u7248\u306e\u30b3\u30fc\u30c9\u3092\u4f5c\u6210\u3059\u308b\u3053\u3068\u306b\u3057\u305f\uff0e\n\n\n## RNN\u306e\u305f\u3081\u306e\u201dTheano scan\u201d\n\n\u30cd\u30c3\u30c8\u3067\u898b\u304b\u3051\u308bTheano\u306b\u3088\u308bRNN\u30b3\u30fc\u30c9\u306b\u5171\u901a\u3057\u3066\u3044\u308b\u306e\u306f\uff0c\u307b\u3068\u3093\u3069\u306e\u30b3\u30fc\u30c9\u3067\"Theano scan\"\u3092\u7528\u3044\u3066\u3044\u308b\u3053\u3068\u3067\u3042\u308b\uff0eTheano scan\u306f\uff0cTheano\u30d5\u30ec\u30fc\u30e0\u30ef\u30fc\u30af\u306e\u306a\u304b\u3067Loop\u51e6\u7406\uff08\u53cd\u5fa9\u51e6\u7406\uff09\uff0cIteration\u51e6\u7406\uff08\u53ce\u675f\u8a08\u7b97\uff09\u3092\u884c\u3046\u305f\u3081\u306b\u6a5f\u80fd\u3067\u3042\u308b\uff0e\u4ed5\u69d8\u304c\u8907\u96d1\u3067\uff0c\u307e\u305f\u672c\u5bb6\u30c9\u30ad\u30e5\u30e1\u30f3\u30c8(Theano Documentation)\u3092\u898b\u3066\u3082\u3059\u3050\u306b\u306f\u7406\u89e3\u304c\u96e3\u3057\u3044\uff0e\u65e5\u672c\u8a9e\u60c5\u5831\u306f\u304b\u306a\u308a\u9650\u3089\u308c\u308b\u304c\uff0csinhrks\u6c0f\u306e\u30d6\u30ed\u30b0\u8a18\u4e8b\u3092\u53c2\u8003\u306b\uff0c\u5c0f\u3055\u3044\u30b3\u30fc\u30c9\u3092Jupyter Notebook\u3067\u8a66\u3057\u306a\u304c\u3089\uff0cTheano scan\u306e\u6319\u52d5\u8abf\u67fb\u3092\u9032\u3081\u305f\uff0e\n\n```py\nn = T.iscalar('n')\nresult, updates = theano.scan(fn=lambda prior, nonseq: prior * 2,\n                              sequences=None,\n                              outputs_info=a, # \u4e00\u3064\u524d\u306eLoop\u306b\u304a\u3051\u308b\u5024\u3092\u53c2\u7167 --> prior\n                              non_sequences=a, # \u30b7\u30fc\u30b1\u30f3\u30b9\u3067\u306a\u3044\u5024 --> nonseq\n                              n_steps=n)\n\nmyfun1 = theano.function(inputs=[a, n], outputs=result, updates=updates)\nmyfun1(5, 3)\n# array([10, 20, 40])\n# return-1 = 5 * 2\n# return-2 = return-1 * 2\n# return-3 = return-2 * 2 \n```\n\u5b9f\u884c\u7d50\u679c\uff1a\n\n```\n>>> array([10, 20, 40], dtype=int32)\n```\n\n\u3068\u3066\u3082\u8a73\u7d30\u3092\u8aac\u660e\u3057\u304d\u308c\u306a\u3044\u306e\u3067\uff0c\u4f7f\u7528\u4f8b\u3092\u3044\u304f\u3064\u304b\u53d6\u308a\u4e0a\u3052\u308b\uff0etheano.scan()\u306f\uff0c\u4e0a\u8a18\u306e\u901a\u308a\uff0c5\u7a2e\u985e\u306e\u5f15\u6570\u3092\u3068\u308b\uff0e\n\n|  Key Word  |   \u5185\u5bb9\u3000\u3000\u3000|  \u4f7f\u7528\u4f8b  |\n|:----------:|:---------|:-------|\n| fn         | \u53cd\u5fa9\u51e6\u7406\u306e\u305f\u3081\u306e\u95a2\u6570 |  fn=lambda prior, nonseq: prior * 2 |\n| sequences  | \u9010\u6b21\u51e6\u7406\u306e\u969b\uff0c\u8981\u7d20\u3092\u9032\u3081\u306a\u304c\u3089\u5165\u529b\u3092\u884c\u3046List, Matrix\u30bf\u30a4\u30d7\u306e\u5909\u6570 | sequences=T.arange(x) |\n| outputs_info | \u9010\u6b21\u51e6\u7406\u306e\u521d\u671f\u5024\u3092\u4e0e\u3048\u308b | outputs_info=a |\n| non_sequences | \u30b7\u30fc\u30b1\u30f3\u30b9\u3067\u306a\u3044\uff08\u53cd\u5fa9\u51e6\u7406\u3067\u4e0d\u5909\u306e\uff09\u56fa\u5b9a\u5024 | non_sequences=a |\n| n_steps   | \u7e70\u308a\u8fd4\u3057\u95a2\u6570 | n_steps=n |\n\n\u4e0a\u306e\u30b3\u30fc\u30c9\u3067\u306f\uff0ctheano.scan() \u306b\u5bfe\u3057\uff0c\uff08\u30b7\u30fc\u30b1\u30f3\u30b9\u3067\u306f\u306a\u3044\uff09\u521d\u671f\u5024 5 \u3068\u56de\u6570 \uff13 \u304c\u4e0e\u3048\u3089\u308c\uff0c\u53cd\u5fa9\u51e6\u7406\u306e\u5ea6\u306b\uff0c\u524d\u56de\u306e\u51e6\u7406\u306e\u7d50\u679c\u306b\u5bfe\u3057 2 \u3092\u4e57\u305a\u308b\uff0c\u3068\u3044\u3046\u51e6\u7406\u3092\u884c\u3063\u3066\u3044\u308b\uff0e  \n1\u56de\u76ee\u306e\u53cd\u5fa9\u51e6\u7406 \uff1a 5 x 2 = 10\n2\u56de\u76ee\u306e\u53cd\u5fa9\u51e6\u7406 \uff1a 10 x 2 = 20\n3\u56de\u76ee\u306e\u53cd\u5fa9\u51e6\u7406 \uff1a 20 x 2 = 40\n\u3053\u306e\u7d50\u679c\uff0cresult = [10, 20, 40] \u3068\u7b97\u5b9a\u3055\u308c\u3066\u3044\u308b\uff0e\n\n\u3082\u3046\u5c11\u3057RNN\u3092\u610f\u8b58\u3057\u305f\u30c6\u30b9\u30c8\u304c\u4ee5\u4e0b\u3067\u3042\u308b\uff0e\n\n```py\nv = T.matrix('v')\ns0 = T.vector('s0')\nresult, updates = theano.scan(fn=lambda seq, prior: seq + prior * 2,\n                                             sequences=v,\n                                             outputs_info=s0,\n                                             non_sequences=None)\nmyfun2 = theano.function(inputs=[v, s0], outputs=result, updates=updates)\n\nmyfun2([[1., 0.], [0., 1.], [1., 1.]], [0.5, 0.5])\n```\n\n\u5b9f\u884c\u7d50\u679c\uff1a\n\n```\n>>> array([[ 2.,  1.],\n       [ 4.,  3.],\n       [ 9.,  7.]], dtype=float32)\n```\n\n\u521d\u671f\u5024 [0.5, 0.5] \u304c\u95a2\u6570\u306b\u5165\u529b\u3055\u308c\u308b\uff0e$$ fn=\\texttt{lambda}\\ seq, prior:\\ seq + prior * 2$$ \u3068\u5b9a\u7fa9\u3057\u305f\u306e\u3067\uff0c\n1\u56de\u76ee\u306e\u53cd\u5fa9\u51e6\u7406 \uff1a [1., 0.] + [0.5, 0.5] x 2 = [2., 1.]\n2\u56de\u76ee\u306e\u53cd\u5fa9\u51e6\u7406 \uff1a [0., 1.] + [2., 1.] x 2 = [4., 3.]\n3\u56de\u76ee\u306e\u53cd\u5fa9\u51e6\u7406 \uff1a [1., 1.] + [4., 3.] x 2 = [9., 7.]\n\u3068\u3044\u3046\u6d41\u308c\u3067\u8a08\u7b97\u3055\u308c\u3066\u3044\u308b\uff0e\n\n\"theano.scan()\" \u306f\uff0cRNN\u3067\u5fc5\u8981\u306a\u51e6\u7406\u306e\u30d5\u30ed\u30fc\u30b3\u30f3\u30c8\u30ed\u30fc\u30eb\u3092\u30b5\u30dd\u30fc\u30c8\u3059\u308b\u6a5f\u80fd\u3067\u3042\u308b\uff0eTensorFlow\u306b\u3064\u3044\u3066\u540c\u69d8\u306e\u6a5f\u80fd\u306f\u73fe\u6bb5\u968e\u3067\u30b5\u30dd\u30fc\u30c8\u3055\u308c\u3066\u3044\u306a\u3044\u304c\uff0c\n\n>Our white paper mentions a number of control flow operations that we've experimented with\n -- I think once we're happy with its API and confident in its implementation we will try\n  to make it available through the public API -- we're just not quite there yet. \n  It's still early days for us :)\n>  \n> (GitHub TensorFlow issue #208 \u306ediscussion\u3088\u308a\u5f15\u7528\uff0e\uff09\n\n\u3068\u306e\u3053\u3068\u306a\u306e\u3067\uff0c\u5c06\u6765\u306e\u30b5\u30dd\u30fc\u30c8\u3092\u5f85\u3061\u305f\u3044\uff0e\n\n\uff08TensorFlow \u306eRNN model\u306b\u3064\u3044\u3066\u3069\u306e\u3088\u3046\u306a\u5b9f\u88c5\u304c\u884c\u308f\u308c\u3066\u3044\u308b\u304b\u7406\u89e3\u3067\u304d\u3066\u3044\u307e\u305b\u3093\u304c\uff0c\u3059\u3067\u306bRNN\u306e\u8a08\u7b97\u3092\u5b9f\u73fe\u3055\u305b\u3066\u3044\u308b\u3068\u3044\u3046\u3053\u3068\u306f\uff0c\u3053\u306e\u3088\u3046\u306a\"theano.scan()\"\u30e9\u30a4\u30af\u306e\u6a5f\u80fd\u304c\u300c\u5fc5\u9808\u300d\u3067\u306f\u306a\u3044\uff0c\u3068\u3044\u3046\u3053\u3068\u3092\u8868\u3057\u3066\u3044\u307e\u3059\uff0e\u3053\u306e\u4ef6\uff0c\u3082\u3046\u5c11\u3057TenforFlow\u306e\u30b5\u30f3\u30d7\u30eb\u30b3\u30fc\u30c9\u3092\u52c9\u5f37\u3059\u308b\u5fc5\u8981\u304c\u3042\u308b\u3068\u8003\u3048\u3066\u3044\u307e\u3059\uff0e\uff09\n\n## Theano\u3092\u7528\u3044\u305fSimple RNN\u306e\u30b3\u30fc\u30c9\u8a73\u7d30\n\nTheano Scan()\u304c\u5206\u304b\u3063\u305f\u3068\u3053\u308d\u3067\uff0cSimple RNN\u306e\u30b3\u30fc\u30c9\u3092\u898b\u3066\u3044\u304f\uff0e\u307e\u305a\uff0csimpleRNN\u306e\u30af\u30e9\u30b9\u3092\u5b9a\u7fa9\u3059\u308b\uff0e\n\n```py\nclass simpleRNN(object):\n    #   members:  slen  : state length\n    #             w_x   : weight of input-->hidden layer\n    #             w_rec : weight of recurrnce \n    def __init__(self, slen, nx, nrec):\n        self.len = slen\n        self.w_x = theano.shared(\n            np.asarray(np.random.uniform(-.1, .1, (nx)),\n            dtype=theano.config.floatX)\n        )\n        self.w_rec = theano.shared(\n            np.asarray(np.random.uniform(-.1, .1, (nrec)),\n            dtype=theano.config.floatX)\n        )\n    \n    def state_update(self, x_t, s0):\n        # this is the network updater for simpleRNN\n        def inner_fn(xv, s_tm1, wx, wr):\n            s_t = xv * wx + s_tm1 * wr\n            y_t = s_t\n            \n            return [s_t, y_t]\n        \n        w_x_vec = T.cast(self.w_x[0], 'float32')\n        w_rec_vec = T.cast(self.w_rec[0], 'float32')\n\n        [s_t, y_t], updates = theano.scan(fn=inner_fn,\n                                    sequences=x_t,\n                                    outputs_info=[s0, None],\n                                    non_sequences=[w_x_vec, w_rec_vec]\n                                   )\n        return y_t\n\n```\n\n\u30af\u30e9\u30b9\u30e1\u30f3\u30d0\u3068\u3057\u3066\uff0c\u72b6\u614b(state)\u306e\u9577\u3055\u3068\u91cd\u307f(w_x, w_rec)\u3092\u4e0e\u3048\u3066\u30af\u30e9\u30b9\u3092\u5b9a\u7fa9\u3059\u308b\uff0e\u30af\u30e9\u30b9\u30e1\u30bd\u30c3\u30c9 state_update() \u306f\uff0cstate\u306e\u521d\u671f\u5024 s0 \u3068\u5165\u529b\u7cfb\u5217 x_t \u304c\u4e0e\u3048\u3089\u308c\u305f\u3068\u304d\u306b\u30cd\u30c3\u30c8\u30ef\u30fc\u30af\u306e\u72b6\u614b\u3092\u66f4\u65b0\u3057\uff0cy_t \uff08\u51fa\u529b\u7cfb\u5217\uff09 \u3092\u7b97\u5b9a\u3059\u308b\uff0ey_t \u306f\u30d9\u30af\u30c8\u30eb\u3067\u3042\u308b\u304c\uff0c\u30e1\u30a4\u30f3\u306e\u51e6\u7406\u3067\u306f\uff0c`y = y_t[-1]` \u306e\u3088\u3046\u306b\u6700\u7d42\u5024\u306e\u307f\u3092\u53d6\u308a\u51fa\u3057\u3066\u30b3\u30b9\u30c8\u95a2\u6570\u306e\u7b97\u5b9a\u306b\u7528\u3044\u308b\uff0e\n\n\u30e1\u30a4\u30f3\u306e\u51e6\u7406\u3067\u306f\uff0c\u307e\u305a\u5b66\u7fd2\u306b\u7528\u3044\u308b\u30c7\u30fc\u30bf\u3092\u4f5c\u6210\u3059\u308b\uff0e\uff08\u307b\u307c\uff0c\u30cd\u30bf\u5143\"Peter's note\"\u306e\u901a\u308a\uff0e\uff09\n\n```py\n    np.random.seed(seed=1)\n\n    # Create Dataset by program\n    num_samples = 20\n    seq_len = 10\n    \n    trX = np.zeros((num_samples, seq_len))\n    for row_idx in range(num_samples):\n        trX[row_idx,:] = np.around(np.random.rand(seq_len)).astype(int)\n    trY = np.sum(trX, axis=1)\n    trX = trX.astype(np.float32)\n    trX = trX.T                    # need 'List of vector' shape dataset\n    trY = trY.astype(np.float32)\n    # s0 is time-zero state \n    s0np = np.zeros((num_samples), dtype=np.float32)\n\n```\n\ntrX\u304c\uff0c\u9577\u305510\u306e\u7cfb\u5217\u30c7\u30fc\u30bf\uff0c20\u30b5\u30f3\u30d7\u30eb\u3068\u306a\u308b\uff0e\u3053\u3053\u3067\u30dd\u30a4\u30f3\u30c8\u306f\uff0c`trX = trX.T` \u3068\u30de\u30c8\u30ea\u30af\u30b9\u3092\u8ee2\u7f6e\u3055\u305b\u3066\u3044\u308b\u3053\u3068\u3067\u3042\u308b\uff0e\u4e00\u822c\u7684\u306a\u6a5f\u68b0\u5b66\u7fd2\u306e\u30c7\u30fc\u30bf\u30bb\u30c3\u30c8\u3068\u3057\u3066\u306f\uff0c\u6a2a\u65b9\u5411\uff08column)\u306b\uff11\u3064\u306e\u30c7\u30fc\u30bf\u306e\u7279\u5fb4\u91cf\u3092\u4e26\u3079\uff0c\u305d\u308c\u3092\u7e26\u65b9\u5411\uff08row)\u306b\u30b5\u30f3\u30d7\u30eb\u6570\u5206\uff0c\u4e26\u3079\u308b\u3053\u3068\u304c\u591a\u3044\u3068\u601d\u308f\u308c\u308b\uff0e\n\n```\n  Data Set Shape\n                  feature1   feature2   feature3  ...\n     sample1:        -          -          -\n     sample2:        -          -          -\n     sample3:        -          -          -\n       .\n       .\n```\n\n\u3057\u304b\u3057\u306a\u304c\u3089\uff0c\u4eca\u56de\u306f\uff0c\u6642\u7cfb\u5217\u30c7\u30fc\u30bf\u3092 theano.scan() \u3067\u66f4\u65b0\u3055\u305b\u308b\u969b\uff0c\u7e26\u65b9\u5411\u306b\u30b0\u30eb\u30fc\u30d4\u30f3\u30b0\u3057\u3066\u30c7\u30fc\u30bf\u3092\u6e21\u3059\u5fc5\u8981\u304c\u3042\u3063\u305f\uff0e\n\n```\n\uff08\u4ee5\u4e0b\u306e\u3088\u3046\u306b\u30b0\u30eb\u30fc\u30d7\u5316\u3059\u308b\u3053\u3068\u3067\uff0ctheano.scan() \u306e\u52d5\u4f5c\u3068\u6574\u5408\u6027\u3092\u3068\u308b\uff0e\uff09\n  Data Set Shape (updated)\n               [  time1[sample1,  time2[sample1,  time3[sample1 ...    ]\n                        sample2,        sample2,        sample2,\n                        sample3,        sample3,        sample3,\n                         ...    ]         ...   ]         ...    ]\n```\n\n\u3053\u308c\u3092\u7c21\u4fbf\u306b\u5b9f\u73fe\u3059\u308b\u305f\u3081\u306b\uff0c\u30de\u30c8\u30ea\u30af\u30b9\u306e\u8ee2\u7f6e\u3092\u884c\u3044\uff0ctheano.scan()\u3078\u306e\u5165\u529b\u3068\u3057\u3066\u51e6\u7406\u3057\u3066\u3044\u308b\uff0e\n\n\u3053\u306e\u5f8c\uff0cTheano\u306e\u30b0\u30e9\u30d5\uff0c\u30e2\u30c7\u30eb\u7b97\u5b9a\u5024 `y_hypo` \u3068Train\u30c7\u30fc\u30bf\u30e9\u30d9\u30eb `y_` \u304b\u3089\u30b3\u30b9\u30c8 `loss` \u3092\u6c42\u3081\u3066\u3044\u308b\uff0e\n\n\n```py\n    # Tensor Declaration\n    x_t = T.matrix('x_t')\n    x = T.matrix('x')\n    y_ = T.vector('y_')\n    s0 = T.vector('s0')\n    y_hypo = T.vector('y_hypo')\n\n    net = simpleRNN(seq_len, 1, 1)  \n    y_t = net.state_update(x_t, s0)\n    y_hypo = y_t[-1]\n    loss = ((y_ - y_hypo) ** 2).sum()\n\n```\n\n\u3053\u3053\u307e\u3067\u6765\u308c\u3070\uff0c\u5f8c\u306f\u304a\u99b4\u67d3\u307f\u306e\u65b9\u6cd5\u3067\u5b66\u7fd2\u3092\u9032\u3081\u308b\u3053\u3068\u304c\u3067\u304d\u308b\uff0e\n\n```py\n# Train Net Model\n    params = [net.w_x, net.w_rec]\n    optimizer = GradientDescentOptimizer(params, learning_rate=1.e-5)\n    train_op = optimizer.minimize(loss)\n\n    # Compile ... define theano.function \n    train_model = theano.function(\n        inputs=[],\n        outputs=[loss],\n        updates=train_op,\n        givens=[(x_t, trX), (y_, trY), (s0, s0np)],\n        allow_input_downcast=True\n    )\n    \n    n_epochs = 2001\n    epoch = 0\n    \n    w_x_ini = (net.w_x).get_value()\n    w_rec_ini = (net.w_rec).get_value()\n    print('Initial weights: wx = %8.4f, wRec = %8.4f' \\\n                % (w_x_ini, w_rec_ini))\n    \n    while (epoch < n_epochs):\n        epoch += 1\n        loss = train_model()\n        if epoch % 100 == 0:\n            print('epoch[%5d] : cost =%8.4f' % (epoch, loss[0]))\n    \n    w_x_final = (net.w_x).get_value()\n    w_rec_final = (net.w_rec).get_value()\n    print('Final weights : wx = %8.4f, wRec = %8.4f' \\\n                % (w_x_final, w_rec_final))\n```\n\n\u4eca\u56de\uff0c\u30aa\u30d7\u30c6\u30a3\u30de\u30a4\u30b6\u306f\uff0cGradientDecent\uff08\u52fe\u914d\u964d\u4e0b\u6cd5\uff09\u3068RMSPropOptimizer(RMSProp\u6cd5)\u306e2\u3064\u7528\u610f\u3057\u3066\u7528\u3044\u305f\uff0e\uff08\u30aa\u30d7\u30c6\u30a3\u30de\u30a4\u30b6\u306e\u90e8\u5206\u306e\u30b3\u30fc\u30c9\u306f\uff0c\u4eca\u56de\u7701\u7565\u3044\u305f\u3057\u307e\u3059\uff0eRMSProp\u6cd5\u306b\u3064\u3044\u3066\u306f\uff0c\u5f8c\u306b\u793a\u3059Web\u30b5\u30a4\u30c8\u3092\u53c2\u7167\u3057\u307e\u3057\u305f\uff0e\uff09\n\n## \u5b9f\u884c\u7d50\u679c\n\n\u300cRNN\u306f\u4e00\u822c\u7684\u306b\u5b66\u7fd2\u3092\u9032\u307e\u305b\u308b\u304c\u306e\u96e3\u3057\u3044\u300d\u3068\u3044\u3046\u8a18\u8ff0\u306f\uff0c\u3044\u308d\u3044\u308d\u306a\u3068\u3053\u308d\u3067\u898b\u53d7\u3051\u3089\u308c\u308b\u304c\uff0c\u305d\u308c\u3092\u5b9f\u611f\u3055\u305b\u308b\u7d50\u679c\u3068\u306a\u3063\u305f\uff0e\n\n#### \u6761\u4ef6\uff11\uff0e\u52fe\u914d\u964d\u4e0b\u6cd5(GradientDescent), \u5b66\u7fd2\u7387= 1.0e-5\n\n```text\nInitial weights: wx =   0.0900, wRec =   0.0113\nepoch[  100] : cost =529.6915\nepoch[  200] : cost =504.5684\nepoch[  300] : cost =475.3019\nepoch[  400] : cost =435.9507\nepoch[  500] : cost =362.6525\nepoch[  600] : cost =  0.2677\nepoch[  700] : cost =  0.1585\nepoch[  800] : cost =  0.1484\nepoch[  900] : cost =  0.1389\nepoch[ 1000] : cost =  0.1300\nepoch[ 1100] : cost =  0.1216\nepoch[ 1200] : cost =  0.1138\nepoch[ 1300] : cost =  0.1064\nepoch[ 1400] : cost =  0.0995\nepoch[ 1500] : cost =  0.0930\nepoch[ 1600] : cost =  0.0870\nepoch[ 1700] : cost =  0.0813\nepoch[ 1800] : cost =  0.0760\nepoch[ 1900] : cost =  0.0710\nepoch[ 2000] : cost =  0.0663\nFinal weights : wx =   1.0597, wRec =   0.9863\n\n```\n\n\u5b66\u7fd2\u306e\u7d50\u679c\uff0c\u6b63\u89e3 [w_x, w_rec] = [1.0, 1.0] \u306e\u8fd1\u4f3c\u5024\u3092\u5f97\u308b\u3053\u3068\u304c\u3067\u304d\u3066\u3044\u308b\uff0e\u4e0b\u306e\u56f3\u306f\uff0c\u30b3\u30b9\u30c8\u95a2\u6570\u304c\u4f4e\u6e1b\u3059\u308b\u69d8\u5b50\u3092\u793a\u3057\u3066\u3044\u308b\uff0e\n\n**Fig. Loss curve (GradientDescent)**\n![rnn_loss_log1.PNG](https://qiita-image-store.s3.amazonaws.com/0/74152/e71b7399-604b-052c-f71c-08099a9a3918.png)\n\n#### \u6761\u4ef62. RMSProp\u6cd5\uff0c\u5b66\u7fd2\u7387=0.001\n\n```text\nInitial weights: wx =   0.0900, wRec =   0.0113\nepoch[  100] : cost =  5.7880\nepoch[  200] : cost =  0.3313\nepoch[  300] : cost =  0.0181\nepoch[  400] : cost =  0.0072\nepoch[  500] : cost =  0.0068\nepoch[  600] : cost =  0.0068\nepoch[  700] : cost =  0.0068\nepoch[  800] : cost =  0.0068\nepoch[  900] : cost =  0.0068\nepoch[ 1000] : cost =  0.0068\nepoch[ 1100] : cost =  0.0068\nepoch[ 1200] : cost =  0.0068\nepoch[ 1300] : cost =  0.0068\nepoch[ 1400] : cost =  0.0068\nepoch[ 1500] : cost =  0.0068\nepoch[ 1600] : cost =  0.0068\nepoch[ 1700] : cost =  0.0068\nepoch[ 1800] : cost =  0.0068\nepoch[ 1900] : cost =  0.0068\nepoch[ 2000] : cost =  0.0068\nFinal weights : wx =   0.9995, wRec =   0.9993\n\n```\n\n**Fig. Loss curve (RMSProp)**\n![rnn_loss_log2.PNG](https://qiita-image-store.s3.amazonaws.com/0/74152/55ddd3a0-102b-eb4f-d03e-5a6666391902.png)\n\n\u4eca\u56de\u306e\u30e2\u30c7\u30eb\u3067\u306f\uff0c\u30b3\u30b9\u30c8\u95a2\u6570 vs. parameters \u306e\u975e\u7dda\u5f62\u6027\u304c\u975e\u5e38\u306b\u5f37\u3044\u3082\u306e\u3068\u306a\u3063\u3066\u3044\u308b\uff0e\u5b66\u7fd2\u7387\u3092\u5927\u304d\u304f\u3068\u308b\u3068\u3059\u3050\u306b\u6570\u5024\u304c\u767a\u6563\u3057\u3066\u3057\u307e\u3046\u305f\u3081\uff0c\u52fe\u914d\u964d\u4e0b\u6cd5(Gradient Descent) \u3067\u306f\uff0c\u5b66\u7fd2\u7387 = 1.0e-5 \u3068\u304b\u306a\u308a\u5c0f\u3055\u304f\u8a2d\u5b9a\u3059\u308b\u5fc5\u8981\u304c\u3042\u3063\u305f\uff0e\u4e00\u65b9\u3067\uff0cRNN\u306b\u5411\u304f\u3068\u8a00\u308f\u308c\u308bRMSProp\u6cd5\u3067\u306f\uff0c\u5b66\u7fd2\u7387 = 0.001 \u3067\u3082\u554f\u984c\u306a\u304f\u5b66\u7fd2\u3092\u9032\u3081\u308b\u3053\u3068\u304c\u3067\u304d\u3066\u3044\u308b\uff0e\n\n\uff08\u88dc\u8db3\uff09\n\u53c2\u8003\u306b\u3057\u305f \"Peter's note\" \u306e\u30d6\u30ed\u30b0\u3067\u306f\uff0c\u30b3\u30b9\u30c8\u95a2\u6570\u306e\u72b6\u6cc1\u3068RMSProp\uff08\u5f15\u7528\u5143\u306e\u30d6\u30ed\u30b0\u3067\u306f\"Rprop\"\u3068\u3044\u3046\u547c\u3073\u540d\uff09\u306b\u3064\u3044\u3066\u8a73\u3057\u3044\u8aac\u660e\u304c\u63b2\u8f09\u3055\u308c\u3066\u3044\u307e\u3059\uff0e\u30b3\u30b9\u30c8\u95a2\u6570\u306e\u975e\u7dda\u5f62\u6027\u304c\u8272\u306e\u6fc3\u6de1\u3067Visual\u5316\u3055\u308c\u3066\u3044\u307e\u3059\u306e\u3067\u95a2\u5fc3\u306e\u3042\u308b\u65b9\u306f\u53c2\u7167\u3057\u3066\u307f\u3066\u304f\u3060\u3055\u3044\uff0e\uff08\u4e0b\u30ea\u30f3\u30af\u306b\u306a\u308a\u307e\u3059\uff0e\uff09\n\n\n## \u53c2\u8003\u6587\u732e (web site)\n- Peter's note - How to implement a recurrent neural network\n    http://peterroelants.github.io/\n- Python Theano function / scan \u306e\u6319\u52d5\u307e\u3068\u3081 - StatsFragments(sinhrks\u3055\u3093\u30d6\u30ed\u30b0\uff09\n    http://sinhrks.hatenablog.com/entry/2015/04/25/233025\n- Theano scan\u3000- Looping in Theano\n    http://deeplearning.net/software/theano/library/scan.html\n- Theano optimizers - Gist/ kastnerkyle/opimizers.py\n    https://gist.github.com/kastnerkyle/816134462577399ee8b2\n  (RMSProp\u6cd5\u30aa\u30d7\u30c6\u30a3\u30de\u30a4\u30b6\u30fc\u306e\u5b9f\u88c5\u4f8b\u3067\u3059\uff0e\u4eca\u56de\uff0c\u3053\u308c\u3092\u53c2\u8003\u306b\u3055\u305b\u3066\u3044\u305f\u3060\u304d\u307e\u3057\u305f\uff0e\uff09\n- \u6df1\u5c64\u5b66\u7fd2\uff0c\u8b1b\u8ac7\u793e\u6a5f\u68b0\u5b66\u7fd2\u30d7\u30ed\u30d5\u30a7\u30c3\u30b7\u30e7\u30ca\u30eb\u30b7\u30ea\u30fc\u30ba\n- \u4eca\u4e00\u5ea6Theano\u306e\u57fa\u672c\u3092\u5b66\u3076 - Qiita \n    http://qiita.com/TomokIshii/items/1f483e9d4bfeb05ae231\n \n\n  \n", "tags": ["Python", "\u6a5f\u68b0\u5b66\u7fd2", "MachineLearning", "Theano"]}