{"context": " More than 1 year has passed since last update.Odometry\uff08\u30aa\u30c9\u30e1\u30c8\u30ea\uff09\u3068\u306f\u3001\u4e00\u822c\u7684\u306b\u306f\u30a8\u30f3\u30b3\u30fc\u30c0\u3084\u52a0\u901f\u5ea6\u30bb\u30f3\u30b5\u304b\u3089\u5f97\u3089\u308c\u308b\u79fb\u52d5\u5909\u5316\u91cf\u306e\u3053\u3068\u3067\u3059\u304c\u3001RGB-D\u30ab\u30e1\u30e9\u3092\u7528\u3044\u305f\u30aa\u30c9\u30e1\u30c8\u30ea\uff08Visual Odometry\uff09\u3068\u3044\u3048\u3070\u3001\u30ab\u30e1\u30e9\u306e\u79fb\u52d5\u91cf\uff08\u56de\u8ee2\u884c\u5217\u3068\u5e73\u884c\u79fb\u52d5\u30d9\u30af\u30c8\u30eb\uff09\u306e\u3053\u3068\u3067\u3059\u3002SLAM\u306f\u3053\u308c\u306b\u52a0\u3048\u3066\u3001\u30de\u30c3\u30d7\u6700\u9069\u5316\u3084\u9589\u30eb\u30fc\u30d7\u691c\u51fa\u51e6\u7406\u304c\u306a\u3044\u3068\u3044\u3051\u307e\u305b\u3093\u3002\n\n\u30b5\u30f3\u30d7\u30eb\u30d7\u30ed\u30b0\u30e9\u30e0\nOpenCV\u306e\u30b5\u30f3\u30d7\u30eb\u30d7\u30ed\u30b0\u30e9\u30e0\u306b\u3042\u308brgbdodometry.cpp\u3092\u5b9f\u884c\u3057\u3066\u307f\u307e\u3057\u305f\u3002\n\u30a4\u30f3\u30af\u30eb\u30fc\u30c9\u30d5\u30a1\u30a4\u30eb\n#include \"opencv2/imgproc/imgproc.hpp\"\n#include \"opencv2/calib3d/calib3d.hpp\"\n#include \"opencv2/contrib/contrib.hpp\"\n#include \"opencv2/highgui/highgui.hpp\"\n#include <cstdio>\n#include <iostream>\n#include <ctime>\n\n\u30e9\u30a4\u30d6\u30e9\u30ea\u306e\u8a2d\u5b9a\n#include <opencv_lib.hpp>\n\n\u540d\u524d\u7a7a\u9593\nusing namespace cv;\nusing namespace std;\n\nDepth\u304b\u30893\u6b21\u5143\u70b9\u7fa4\u3092\u751f\u6210\u3059\u308b\u95a2\u6570\nstatic\nvoid cvtDepth2Cloud(const Mat& depth, Mat& cloud, const Mat& cameraMatrix)\n{\n    const float inv_fx = 1.f / cameraMatrix.at<float>(0, 0);\n    const float inv_fy = 1.f / cameraMatrix.at<float>(1, 1);\n    const float ox = cameraMatrix.at<float>(0, 2);\n    const float oy = cameraMatrix.at<float>(1, 2);\n    cloud.create(depth.size(), CV_32FC3);\n    for (int y = 0; y < cloud.rows; y++)\n    {\n        Point3f* cloud_ptr = (Point3f*)cloud.ptr(y);\n        const float* depth_prt = (const float*)depth.ptr(y);\n        for (int x = 0; x < cloud.cols; x++)\n        {\n            float z = depth_prt[x];\n            cloud_ptr[x].x = (x - ox) * z * inv_fx;\n            cloud_ptr[x].y = (y - oy) * z * inv_fy;\n            cloud_ptr[x].z = z;\n        }\n    }\n}\n\n\u5909\u63db\u884c\u5217\uff084\u00d74\uff09\u30673\u6b21\u5143\u70b9\u7fa4\u3092\u5909\u63db\u3059\u308b\u95a2\u6570\n\u203b\u30ab\u30e1\u30e9\uff10\uff08Image0\uff09\u304b\u3089\u30ab\u30e1\u30e9\uff11\uff08Image1\uff09\u3078\u5909\u63db\ntemplate<class ImageElemType>\nstatic void warpImage(const Mat& image, const Mat& depth,\n    const Mat& Rt, const Mat& cameraMatrix, const Mat& distCoeff,\n    Mat& warpedImage)\n{\n    const Rect rect = Rect(0, 0, image.cols, image.rows);\n\n    vector<Point2f> points2d;\n    Mat cloud, transformedCloud;\n\n    cvtDepth2Cloud(depth, cloud, cameraMatrix);\n    perspectiveTransform(cloud, transformedCloud, Rt);\n    projectPoints(transformedCloud.reshape(3, 1), Mat::eye(3, 3, CV_64FC1), Mat::zeros(3, 1, CV_64FC1), cameraMatrix, distCoeff, points2d);\n\n    Mat pointsPositions(points2d);\n    pointsPositions = pointsPositions.reshape(2, image.rows);\n\n    warpedImage.create(image.size(), image.type());\n    warpedImage = Scalar::all(0);\n\n    Mat zBuffer(image.size(), CV_32FC1, FLT_MAX);\n    for (int y = 0; y < image.rows; y++)\n    {\n        for (int x = 0; x < image.cols; x++)\n        {\n            const Point3f p3d = transformedCloud.at<Point3f>(y, x);\n            const Point p2d = pointsPositions.at<Point2f>(y, x);\n            if (!cvIsNaN(cloud.at<Point3f>(y, x).z) && cloud.at<Point3f>(y, x).z > 0 &&\n                rect.contains(p2d) && zBuffer.at<float>(p2d) > p3d.z)\n            {\n                warpedImage.at<ImageElemType>(p2d) = image.at<ImageElemType>(y, x);\n                zBuffer.at<float>(p2d) = p3d.z;\n            }\n        }\n    }\n}\n\n\n\u30e1\u30a4\u30f3\u95a2\u6570\nint main(int argc, char** argv)\n{\n\n\u2460vals\u306f\u30ab\u30e1\u30e9\u306e\u5185\u90e8\u30d1\u30e9\u30e1\u30fc\u30bf\uff08Kinect\u51fa\u8377\u6642\u306e\u5185\u90e8\u30d1\u30e9\u30e1\u30fc\u30bf\uff09\u3067\u3042\u308a\u3001\u7126\u70b9\u8ddd\u96e2(fx, fy)\u3001\u753b\u50cf\u4e2d\u5fc3(cx, cy)\u3068\u3059\u308b\u3068\u3001fx = 525, fy = 525, cx = 319.5, cy = 239.5\u3002\u30ab\u30e1\u30e9\u6b6a\uff08distCoeff\uff09\u306f\u306a\u3057\u3002\n    float vals[] = { 525., 0., 3.1950000000000000e+02,\n        0., 525., 2.3950000000000000e+02,\n        0., 0., 1. };\n\n    const Mat cameraMatrix = Mat(3, 3, CV_32FC1, vals);\n    const Mat distCoeff(1, 5, CV_32FC1, Scalar(0));\n\n\u2461\u753b\u50cf\u30bb\u30c3\u30c8\uff08RGB\u3068Depth\uff09\u30922\u3064\u8aad\u307f\u8fbc\u307f\u3001\n- \u525b\u4f53\u5909\u63db\n- \u56de\u8ee2\u884c\u5217\u306e\u307f\n- \u5e73\u884c\u79fb\u52d5\u30d9\u30af\u30c8\u30eb\u306e\u307f\n\u3092\u6c42\u3081\u308b\u30aa\u30d7\u30b7\u30e7\u30f3(-rbm, -r, -t)\u3092\u3064\u3051\u308b\u3002\n    if (argc != 5 && argc != 6)\n    {\n        cout << \"Format: image0 depth0 image1 depth1 [transformationType]\" << endl;\n        cout << \"Depth file must be 16U image stored depth in mm.\" << endl;\n        cout << \"Transformation types:\" << endl;\n        cout << \"   -rbm - rigid body motion (default)\" << endl;\n        cout << \"   -r   - rotation rotation only\" << endl;\n        cout << \"   -t   - translation only\" << endl;\n        return -1;\n    }\n\n    Mat colorImage0 = imread(argv[1]);\n    Mat depth0 = imread(argv[2], -1);\n\n    Mat colorImage1 = imread(argv[3]);\n    Mat depth1 = imread(argv[4], -1);\n\n    if (colorImage0.empty() || depth0.empty() || colorImage1.empty() || depth1.empty())\n    {\n        cout << \"Data (rgb or depth images) is empty.\";\n        return -1;\n    }\n\n    int transformationType = RIGID_BODY_MOTION;\n    if (argc == 6)\n    {\n        string ttype = argv[5];\n        if (ttype == \"-rbm\")\n        {\n            transformationType = RIGID_BODY_MOTION;\n        }\n        else if (ttype == \"-r\")\n        {\n            transformationType = ROTATION;\n        }\n        else if (ttype == \"-t\")\n        {\n            transformationType = TRANSLATION;\n        }\n        else\n        {\n            cout << \"Unsupported transformation type.\" << endl;\n            return -1;\n        }\n    }\n\n\u2462\u30ab\u30e9\u30fc\u753b\u50cf\u306f\u30b0\u30ec\u30fc\u30b9\u30b1\u30fc\u30eb\u306b\u5909\u63db\u3057\u3001Depth\u306f\u30e1\u30fc\u30c8\u30eb\u306b\u5909\u63db\u3059\u308b\u3002\u3053\u3053\u3067\u306f\u30010\uff5e4m\u306eDepth\u30c7\u30fc\u30bf\u306e\u307f\u3092\u7528\u3044\u3066\u3044\u308b\u3002\n    Mat grayImage0, grayImage1, depthFlt0, depthFlt1/*in meters*/;\n    cvtColor(colorImage0, grayImage0, COLOR_BGR2GRAY);\n    cvtColor(colorImage1, grayImage1, COLOR_BGR2GRAY);\n    depth0.convertTo(depthFlt0, CV_32FC1, 1. / 1000);\n    depth1.convertTo(depthFlt1, CV_32FC1, 1. / 1000);\n\n\n\u2463TickMeter tm;\u306f\u51e6\u7406\u6642\u9593\u3092\u6e2c\u308b\u3002tm.start();\u304b\u3089tm.stop();\u307e\u3067\u306e\u6642\u9593\u3092\u6e2c\u308b\u3053\u3068\u304c\u3067\u304d\u308b\u3002tm.getTimeMilli()\u3067\u6642\u9593[ms]\u3092\u8868\u793a\u3059\u308b\u3002\u3042\u3068\u306f\u3001\u5909\u63db\u884c\u5217\u3092\u6c42\u3081\u308b\u305f\u3081\u306e\u8a2d\u5b9a\uff08iterCounts, minGradMagnitudes\uff09\u3002\n    TickMeter tm;\n    Mat Rt;\n\n    vector<int> iterCounts(4);\n    iterCounts[0] = 7;\n    iterCounts[1] = 7;\n    iterCounts[2] = 7;\n    iterCounts[3] = 10;\n\n    vector<float> minGradMagnitudes(4);\n    minGradMagnitudes[0] = 12;\n    minGradMagnitudes[1] = 5;\n    minGradMagnitudes[2] = 3;\n    minGradMagnitudes[3] = 1;\n\n    const float minDepth = 0.f; //in meters\n    const float maxDepth = 4.f; //in meters\n    const float maxDepthDiff = 0.07f; //in meters\n\n\n\u2464\u30aa\u30c9\u30e1\u30c8\u30ea\u3092\u63a8\u5b9a\u3059\u308b\u95a2\u6570(Direct Method)\u3068\u5909\u63db\u884c\u5217\u306e\u8868\u793a\n    tm.start();\n    bool isFound = cv::RGBDOdometry(Rt, Mat(),\n        grayImage0, depthFlt0, Mat(),\n        grayImage1, depthFlt1, Mat(),\n        cameraMatrix, minDepth, maxDepth, maxDepthDiff,\n        iterCounts, minGradMagnitudes, transformationType);\n    tm.stop();\n\n    cout << \"Rt = \" << Rt << endl;\n    cout << \"Time = \" << tm.getTimeSec() << \" sec.\" << endl;\n\n    if (!isFound)\n    {\n        cout << \"Rigid body motion cann't be estimated for given RGBD data.\" << endl;\n        return -1;\n    }\n\n\u2465Image0\u3092Image1\u306b\u5909\u63db\u3057\u305f\u753b\u50cfwarpedImage0\u3092\u8868\u793a\u3057\u3066\u7d42\u4e86\u3002\n    Mat warpedImage0;\n    warpImage<Point3_<uchar> >(colorImage0, depthFlt0, Rt, cameraMatrix, distCoeff, warpedImage0);\n\n    imshow(\"image0\", colorImage0);\n    imshow(\"warped_image0\", warpedImage0);\n    imshow(\"image1\", colorImage1);\n    waitKey();\n\n    return 0;\n}\n\n\n\u30b5\u30f3\u30d7\u30eb\u306e\u753b\u50cf\u30bb\u30c3\u30c8\u306fOpenCV\u306e\u4e2d\u306b\u3042\u308a\u307e\u3059\u3002\n\\opencv249\\sources\\samples\\cpp\\rgbdodometry\\\n\nPPL\u3067\u4e26\u5217\u5316\u3057\u305f\u30bd\u30fc\u30b9\u30b3\u30fc\u30c9\u3092github\u306b\u3042\u3052\u307e\u3059\u3002\u901f\u5ea6\u306f\u5168\u7136\u5909\u308f\u308a\u307e\u305b\u3093\uff57\u3000\u5b9f\u884c\u3059\u308b\u969b\u3001Debugging\u306e\u8a2d\u5b9a\uff08\u30b3\u30de\u30f3\u30c9\u30e9\u30a4\u30f3\u304b\u3089\u5f15\u6570\u3092\u4e0e\u3048\u308b\uff09\u3092\u884c\u3063\u3066\u304f\u3060\u3055\u3044\u3002\nC:\\opencv249\\sources\\samples\\cpp\\rgbdodometry\\image_00000.png C:\\opencv249\\sources\\samples\\cpp\\rgbdodometry\\depth_00000.png C:\\opencv249\\sources\\samples\\cpp\\rgbdodometry\\image_00002.png C:\\opencv249\\sources\\samples\\cpp\\rgbdodometry\\depth_00002.png -rbm\n\n\n\u52d5\u4f5c\u74b0\u5883\n\nWindows8.1(RAM 8GB, 2 cores @ 2.1GHz)\nOpenCV2.4.9\nVisual Studio 2013\n\n\n\u51e6\u7406\u6642\u9593\n\nrgbdodometry\n\nppl\u3067\u4e26\u5217\u5316\uff082\u91cd\u30eb\u30fc\u30d7\u304f\u3089\u3044\u3058\u3083\u901f\u5ea6\u306f\u5909\u308f\u308a\u307e\u305b\u3093\uff09\n\n\nOdometry\uff08\u30aa\u30c9\u30e1\u30c8\u30ea\uff09\u3068\u306f\u3001\u4e00\u822c\u7684\u306b\u306f\u30a8\u30f3\u30b3\u30fc\u30c0\u3084\u52a0\u901f\u5ea6\u30bb\u30f3\u30b5\u304b\u3089\u5f97\u3089\u308c\u308b\u79fb\u52d5\u5909\u5316\u91cf\u306e\u3053\u3068\u3067\u3059\u304c\u3001RGB-D\u30ab\u30e1\u30e9\u3092\u7528\u3044\u305f\u30aa\u30c9\u30e1\u30c8\u30ea\uff08Visual Odometry\uff09\u3068\u3044\u3048\u3070\u3001\u30ab\u30e1\u30e9\u306e\u79fb\u52d5\u91cf\uff08\u56de\u8ee2\u884c\u5217\u3068\u5e73\u884c\u79fb\u52d5\u30d9\u30af\u30c8\u30eb\uff09\u306e\u3053\u3068\u3067\u3059\u3002SLAM\u306f\u3053\u308c\u306b\u52a0\u3048\u3066\u3001\u30de\u30c3\u30d7\u6700\u9069\u5316\u3084\u9589\u30eb\u30fc\u30d7\u691c\u51fa\u51e6\u7406\u304c\u306a\u3044\u3068\u3044\u3051\u307e\u305b\u3093\u3002\n\n## \u30b5\u30f3\u30d7\u30eb\u30d7\u30ed\u30b0\u30e9\u30e0\nOpenCV\u306e\u30b5\u30f3\u30d7\u30eb\u30d7\u30ed\u30b0\u30e9\u30e0\u306b\u3042\u308brgbdodometry.cpp\u3092\u5b9f\u884c\u3057\u3066\u307f\u307e\u3057\u305f\u3002\n\n\u30a4\u30f3\u30af\u30eb\u30fc\u30c9\u30d5\u30a1\u30a4\u30eb\n\n~~~\n#include \"opencv2/imgproc/imgproc.hpp\"\n#include \"opencv2/calib3d/calib3d.hpp\"\n#include \"opencv2/contrib/contrib.hpp\"\n#include \"opencv2/highgui/highgui.hpp\"\n#include <cstdio>\n#include <iostream>\n#include <ctime>\n~~~\n\n[\u30e9\u30a4\u30d6\u30e9\u30ea\u306e\u8a2d\u5b9a](http://qiita.com/SatoshiRobatoFujimoto/items/6899f7645c8bff99802d)\n\n~~~\n#include <opencv_lib.hpp>\n~~~\n\n\u540d\u524d\u7a7a\u9593\n\n~~~\nusing namespace cv;\nusing namespace std;\n~~~\n\nDepth\u304b\u30893\u6b21\u5143\u70b9\u7fa4\u3092\u751f\u6210\u3059\u308b\u95a2\u6570\n\n~~~\nstatic\nvoid cvtDepth2Cloud(const Mat& depth, Mat& cloud, const Mat& cameraMatrix)\n{\n\tconst float inv_fx = 1.f / cameraMatrix.at<float>(0, 0);\n\tconst float inv_fy = 1.f / cameraMatrix.at<float>(1, 1);\n\tconst float ox = cameraMatrix.at<float>(0, 2);\n\tconst float oy = cameraMatrix.at<float>(1, 2);\n\tcloud.create(depth.size(), CV_32FC3);\n\tfor (int y = 0; y < cloud.rows; y++)\n\t{\n\t\tPoint3f* cloud_ptr = (Point3f*)cloud.ptr(y);\n\t\tconst float* depth_prt = (const float*)depth.ptr(y);\n\t\tfor (int x = 0; x < cloud.cols; x++)\n\t\t{\n\t\t\tfloat z = depth_prt[x];\n\t\t\tcloud_ptr[x].x = (x - ox) * z * inv_fx;\n\t\t\tcloud_ptr[x].y = (y - oy) * z * inv_fy;\n\t\t\tcloud_ptr[x].z = z;\n\t\t}\n\t}\n}\n~~~\n\n\u5909\u63db\u884c\u5217\uff084\u00d74\uff09\u30673\u6b21\u5143\u70b9\u7fa4\u3092\u5909\u63db\u3059\u308b\u95a2\u6570\n\u203b\u30ab\u30e1\u30e9\uff10\uff08Image0\uff09\u304b\u3089\u30ab\u30e1\u30e9\uff11\uff08Image1\uff09\u3078\u5909\u63db\n\n~~~\ntemplate<class ImageElemType>\nstatic void warpImage(const Mat& image, const Mat& depth,\n\tconst Mat& Rt, const Mat& cameraMatrix, const Mat& distCoeff,\n\tMat& warpedImage)\n{\n\tconst Rect rect = Rect(0, 0, image.cols, image.rows);\n\n\tvector<Point2f> points2d;\n\tMat cloud, transformedCloud;\n\n\tcvtDepth2Cloud(depth, cloud, cameraMatrix);\n\tperspectiveTransform(cloud, transformedCloud, Rt);\n\tprojectPoints(transformedCloud.reshape(3, 1), Mat::eye(3, 3, CV_64FC1), Mat::zeros(3, 1, CV_64FC1), cameraMatrix, distCoeff, points2d);\n\n\tMat pointsPositions(points2d);\n\tpointsPositions = pointsPositions.reshape(2, image.rows);\n\n\twarpedImage.create(image.size(), image.type());\n\twarpedImage = Scalar::all(0);\n\n\tMat zBuffer(image.size(), CV_32FC1, FLT_MAX);\n\tfor (int y = 0; y < image.rows; y++)\n\t{\n\t\tfor (int x = 0; x < image.cols; x++)\n\t\t{\n\t\t\tconst Point3f p3d = transformedCloud.at<Point3f>(y, x);\n\t\t\tconst Point p2d = pointsPositions.at<Point2f>(y, x);\n\t\t\tif (!cvIsNaN(cloud.at<Point3f>(y, x).z) && cloud.at<Point3f>(y, x).z > 0 &&\n\t\t\t\trect.contains(p2d) && zBuffer.at<float>(p2d) > p3d.z)\n\t\t\t{\n\t\t\t\twarpedImage.at<ImageElemType>(p2d) = image.at<ImageElemType>(y, x);\n\t\t\t\tzBuffer.at<float>(p2d) = p3d.z;\n\t\t\t}\n\t\t}\n\t}\n}\n~~~\n\n## \u30e1\u30a4\u30f3\u95a2\u6570\n\n~~~\nint main(int argc, char** argv)\n{\n~~~\n\n\u2460vals\u306f\u30ab\u30e1\u30e9\u306e\u5185\u90e8\u30d1\u30e9\u30e1\u30fc\u30bf\uff08Kinect\u51fa\u8377\u6642\u306e\u5185\u90e8\u30d1\u30e9\u30e1\u30fc\u30bf\uff09\u3067\u3042\u308a\u3001\u7126\u70b9\u8ddd\u96e2(fx, fy)\u3001\u753b\u50cf\u4e2d\u5fc3(cx, cy)\u3068\u3059\u308b\u3068\u3001fx = 525, fy = 525, cx = 319.5, cy = 239.5\u3002\u30ab\u30e1\u30e9\u6b6a\uff08distCoeff\uff09\u306f\u306a\u3057\u3002\n\n~~~\n\tfloat vals[] = { 525., 0., 3.1950000000000000e+02,\n\t\t0., 525., 2.3950000000000000e+02,\n\t\t0., 0., 1. };\n\n\tconst Mat cameraMatrix = Mat(3, 3, CV_32FC1, vals);\n\tconst Mat distCoeff(1, 5, CV_32FC1, Scalar(0));\n~~~\n\n\u2461\u753b\u50cf\u30bb\u30c3\u30c8\uff08RGB\u3068Depth\uff09\u30922\u3064\u8aad\u307f\u8fbc\u307f\u3001\n- \u525b\u4f53\u5909\u63db\n- \u56de\u8ee2\u884c\u5217\u306e\u307f\n- \u5e73\u884c\u79fb\u52d5\u30d9\u30af\u30c8\u30eb\u306e\u307f\n\u3092\u6c42\u3081\u308b\u30aa\u30d7\u30b7\u30e7\u30f3(-rbm, -r, -t)\u3092\u3064\u3051\u308b\u3002\n\n~~~\n\tif (argc != 5 && argc != 6)\n\t{\n\t\tcout << \"Format: image0 depth0 image1 depth1 [transformationType]\" << endl;\n\t\tcout << \"Depth file must be 16U image stored depth in mm.\" << endl;\n\t\tcout << \"Transformation types:\" << endl;\n\t\tcout << \"   -rbm - rigid body motion (default)\" << endl;\n\t\tcout << \"   -r   - rotation rotation only\" << endl;\n\t\tcout << \"   -t   - translation only\" << endl;\n\t\treturn -1;\n\t}\n\n\tMat colorImage0 = imread(argv[1]);\n\tMat depth0 = imread(argv[2], -1);\n\n\tMat colorImage1 = imread(argv[3]);\n\tMat depth1 = imread(argv[4], -1);\n\n\tif (colorImage0.empty() || depth0.empty() || colorImage1.empty() || depth1.empty())\n\t{\n\t\tcout << \"Data (rgb or depth images) is empty.\";\n\t\treturn -1;\n\t}\n\n\tint transformationType = RIGID_BODY_MOTION;\n\tif (argc == 6)\n\t{\n\t\tstring ttype = argv[5];\n\t\tif (ttype == \"-rbm\")\n\t\t{\n\t\t\ttransformationType = RIGID_BODY_MOTION;\n\t\t}\n\t\telse if (ttype == \"-r\")\n\t\t{\n\t\t\ttransformationType = ROTATION;\n\t\t}\n\t\telse if (ttype == \"-t\")\n\t\t{\n\t\t\ttransformationType = TRANSLATION;\n\t\t}\n\t\telse\n\t\t{\n\t\t\tcout << \"Unsupported transformation type.\" << endl;\n\t\t\treturn -1;\n\t\t}\n\t}\n~~~\n\n\n\u2462\u30ab\u30e9\u30fc\u753b\u50cf\u306f\u30b0\u30ec\u30fc\u30b9\u30b1\u30fc\u30eb\u306b\u5909\u63db\u3057\u3001Depth\u306f\u30e1\u30fc\u30c8\u30eb\u306b\u5909\u63db\u3059\u308b\u3002\u3053\u3053\u3067\u306f\u30010\uff5e4m\u306eDepth\u30c7\u30fc\u30bf\u306e\u307f\u3092\u7528\u3044\u3066\u3044\u308b\u3002\n\n~~~\n\tMat grayImage0, grayImage1, depthFlt0, depthFlt1/*in meters*/;\n\tcvtColor(colorImage0, grayImage0, COLOR_BGR2GRAY);\n\tcvtColor(colorImage1, grayImage1, COLOR_BGR2GRAY);\n\tdepth0.convertTo(depthFlt0, CV_32FC1, 1. / 1000);\n\tdepth1.convertTo(depthFlt1, CV_32FC1, 1. / 1000);\n\n~~~\n\n\u2463TickMeter tm;\u306f\u51e6\u7406\u6642\u9593\u3092\u6e2c\u308b\u3002tm.start();\u304b\u3089tm.stop();\u307e\u3067\u306e\u6642\u9593\u3092\u6e2c\u308b\u3053\u3068\u304c\u3067\u304d\u308b\u3002tm.getTimeMilli()\u3067\u6642\u9593[ms]\u3092\u8868\u793a\u3059\u308b\u3002\u3042\u3068\u306f\u3001\u5909\u63db\u884c\u5217\u3092\u6c42\u3081\u308b\u305f\u3081\u306e\u8a2d\u5b9a\uff08iterCounts, minGradMagnitudes\uff09\u3002\n\n~~~\n\tTickMeter tm;\n\tMat Rt;\n\n\tvector<int> iterCounts(4);\n\titerCounts[0] = 7;\n\titerCounts[1] = 7;\n\titerCounts[2] = 7;\n\titerCounts[3] = 10;\n\n\tvector<float> minGradMagnitudes(4);\n\tminGradMagnitudes[0] = 12;\n\tminGradMagnitudes[1] = 5;\n\tminGradMagnitudes[2] = 3;\n\tminGradMagnitudes[3] = 1;\n\n\tconst float minDepth = 0.f; //in meters\n\tconst float maxDepth = 4.f; //in meters\n\tconst float maxDepthDiff = 0.07f; //in meters\n\n~~~\n\n\n\u2464\u30aa\u30c9\u30e1\u30c8\u30ea\u3092\u63a8\u5b9a\u3059\u308b\u95a2\u6570(Direct Method)\u3068\u5909\u63db\u884c\u5217\u306e\u8868\u793a\n\n~~~\n\ttm.start();\n\tbool isFound = cv::RGBDOdometry(Rt, Mat(),\n\t\tgrayImage0, depthFlt0, Mat(),\n\t\tgrayImage1, depthFlt1, Mat(),\n\t\tcameraMatrix, minDepth, maxDepth, maxDepthDiff,\n\t\titerCounts, minGradMagnitudes, transformationType);\n\ttm.stop();\n\n\tcout << \"Rt = \" << Rt << endl;\n\tcout << \"Time = \" << tm.getTimeSec() << \" sec.\" << endl;\n\n\tif (!isFound)\n\t{\n\t\tcout << \"Rigid body motion cann't be estimated for given RGBD data.\" << endl;\n\t\treturn -1;\n\t}\n~~~\n\n\u2465Image0\u3092Image1\u306b\u5909\u63db\u3057\u305f\u753b\u50cfwarpedImage0\u3092\u8868\u793a\u3057\u3066\u7d42\u4e86\u3002\n\n\n~~~\n\tMat warpedImage0;\n\twarpImage<Point3_<uchar> >(colorImage0, depthFlt0, Rt, cameraMatrix, distCoeff, warpedImage0);\n\n\timshow(\"image0\", colorImage0);\n\timshow(\"warped_image0\", warpedImage0);\n\timshow(\"image1\", colorImage1);\n\twaitKey();\n\n\treturn 0;\n}\n~~~\n\n![shuho.png](https://qiita-image-store.s3.amazonaws.com/0/63863/38a4fe5b-6f5d-c4c8-21f1-c6f7d99c9333.png)\n\n\n\u30b5\u30f3\u30d7\u30eb\u306e\u753b\u50cf\u30bb\u30c3\u30c8\u306fOpenCV\u306e\u4e2d\u306b\u3042\u308a\u307e\u3059\u3002\n\n~~~\n\\opencv249\\sources\\samples\\cpp\\rgbdodometry\\\n~~~\n\nPPL\u3067\u4e26\u5217\u5316\u3057\u305f[\u30bd\u30fc\u30b9\u30b3\u30fc\u30c9](https://github.com/SatoshiRobatoFujimoto/rgbdodometry2)\u3092github\u306b\u3042\u3052\u307e\u3059\u3002\u901f\u5ea6\u306f\u5168\u7136\u5909\u308f\u308a\u307e\u305b\u3093\uff57\u3000\u5b9f\u884c\u3059\u308b\u969b\u3001Debugging\u306e\u8a2d\u5b9a\uff08\u30b3\u30de\u30f3\u30c9\u30e9\u30a4\u30f3\u304b\u3089\u5f15\u6570\u3092\u4e0e\u3048\u308b\uff09\u3092\u884c\u3063\u3066\u304f\u3060\u3055\u3044\u3002\n\n~~~\nC:\\opencv249\\sources\\samples\\cpp\\rgbdodometry\\image_00000.png C:\\opencv249\\sources\\samples\\cpp\\rgbdodometry\\depth_00000.png C:\\opencv249\\sources\\samples\\cpp\\rgbdodometry\\image_00002.png C:\\opencv249\\sources\\samples\\cpp\\rgbdodometry\\depth_00002.png -rbm\n~~~\n\n# \u52d5\u4f5c\u74b0\u5883\n- Windows8.1(RAM 8GB, 2 cores @ 2.1GHz)\n- OpenCV2.4.9\n- Visual Studio 2013\n\n# \u51e6\u7406\u6642\u9593\n\n- rgbdodometry\n![console.png](https://qiita-image-store.s3.amazonaws.com/0/63863/2b54ed63-8304-bae5-e7bb-2475c8134b74.png)\n\n\n- ppl\u3067\u4e26\u5217\u5316\uff082\u91cd\u30eb\u30fc\u30d7\u304f\u3089\u3044\u3058\u3083\u901f\u5ea6\u306f\u5909\u308f\u308a\u307e\u305b\u3093\uff09\n![console2.png](https://qiita-image-store.s3.amazonaws.com/0/63863/5b08dfc5-f529-6c5d-cd80-5c2fd47c9023.png)\n\n", "tags": ["OpenCV", "VisualStudio", "3D", "C++", "\u753b\u50cf\u51e6\u7406"]}