{"context": "Chainer\u306e\u6700\u8fd1\u306e\u30d0\u30fc\u30b8\u30e7\u30f3\u3067\u306ftrainer\u3068\u3044\u3046\u306e\u3092\u4f7f\u3046\u3088\u3046\u306b\u306a\u3063\u3066\u3001\u62bd\u8c61\u5316\u304c\u9032\u307f\u307e\u3057\u305f\u3002\n\u4f8b\u3048\u3070\u3001\u3053\u306e\u8a18\u4e8b\u3001\nChainer\u306e\u65b0\u6a5f\u80fd\u304c\u3059\u3054\u3044\u52e2\u3044\u3067\u4ffa\u306e\u30bd\u30fc\u30b9\u30b3\u30fc\u30c9\u3092\u62bd\u8c61\u5316\u3057\u3066\u304f\u308b\n\u4f8b\u306b\u306fMNIST\u304c\u4f7f\u7528\u3055\u308c\u308b\u3053\u3068\u304c\u591a\u3044\u3067\u3059\u304c\u3001MINST\u306e\u30c7\u30fc\u30bf\u306f\u3001train, test = chainer.datasets.get_mnist()\u3067\u7c21\u5358\u306b\u8aad\u307f\u8fbc\u3081\u3066\u3057\u307e\u3046\u306e\u3067\u3001\u81ea\u5206\u306e\u30c7\u30fc\u30bf\u3092\u8aad\u307f\u8fbc\u3080\u3068\u304d\u3069\u3046\u3059\u308b\u306e\u304b\u3001\u3088\u304f\u308f\u304b\u308a\u307e\u305b\u3093\u3002\n\u53e4\u5178\u7684\u3067\u3059\u304c\u3001Iris dataset\u3092\u5206\u985e\u3057\u3066\u307f\u307e\u3057\u305f\u3002Iris\u306f\u3001\u4e00\u7d44\uff14\u3064\u306e\u5024\u304b\u3089\u3001\u82b1\u306e\u7a2e\u985e\uff13\u3064\u3092\u5f53\u3066\u308b\u3082\u306e\u3067\u3059\u3002\nIris\u306f\u3001\u4e0b\u8a18\u306e\u30b3\u30fc\u30c9\u3067\u8aad\u307f\u8fbc\u3081\u307e\u3059\u3002\nfrom sklearn.datasets import load_iris\n\niris = load_iris()\nX = iris.data\nX = X.astype(np.float32)\n\nY = iris.target\nY = Y.flatten().astype(np.int32)\n\n\u3061\u306a\u307f\u306b\n  > X[[0]]\nout: array([ 5.0999999 ,  3.5       ,  1.39999998,  0.2       ], dtype=float32)\n\n  > Y\nout: array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n       0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n       1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n       2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n       2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2], dtype=int32)\n\n\u3053\u3093\u306a\u611f\u3058\u3067\u3059\u3002\n\u30b3\u30fc\u30c9\u306fGithub\u306b\u304a\u3044\u3066\u304a\u304d\u307e\u3057\u305f\u304c\u3001\u4e0b\u8a18\u306e\u3088\u3046\u306b\u306a\u308a\u307e\u3059\u3002GPU\u306a\u3057\u3067CPU\u3067\u3084\u3063\u3066\u3044\u3066\u3001Jupyter\u3092\u4f7f\u3063\u3066\u3044\u307e\u3059\u3002\nimport chainer\nimport chainer.functions as F\nimport chainer.links as L\nfrom chainer import training, datasets\nfrom chainer.training import extensions\nimport numpy as np\nfrom sklearn.datasets import load_iris\n\niris = load_iris()\nX = iris.data\nX = X.astype(np.float32)\nY = iris.target\nY = Y.flatten().astype(np.int32)\n\ntrain ,test= datasets.split_dataset_random(chainer.datasets.TupleDataset(X,Y),100)\ntrain_iter = chainer.iterators.SerialIterator(train, 10)\ntest_iter = chainer.iterators.SerialIterator(test, 1,repeat=False, shuffle=False)\n\nclass IrisModel(chainer.Chain):\n    def __init__(self):\n        super(IrisModel,self).__init__(\n                l1 = L.Linear(4,100),\n                l2 = L.Linear(100,100),\n                l3 = L.Linear(100,3))\n\n    def __call__(self,x):    \n         h = F.relu(self.l1(x))\n         h = F.relu(self.l2(h))\n         return self.l3(h)\n\nmodel = L.Classifier(IrisModel())\noptimizer = chainer.optimizers.Adam()\noptimizer.setup(model)\n\nupdater = training.StandardUpdater(train_iter, optimizer, device=-1)\ntrainer = training.Trainer(updater, (30, 'epoch'), out=\"result\")\ntrainer.extend(extensions.Evaluator(test_iter, model, device=-1))\ntrainer.extend(extensions.LogReport())\ntrainer.extend(extensions.PrintReport( ['epoch', 'main/loss', 'validation/main/loss', 'main/accuracy', 'validation/main/accuracy']))\ntrainer.extend(extensions.ProgressBar())\n\ntrainer.run()\n\n\u3053\u308c\u3067\u4e0b\u8a18\u306e\u3088\u3046\u306b\u5b66\u7fd2\u304c\u59cb\u307e\u308a\u307e\u3059\u3002\nepoch       main/loss   validation/main/loss  main/accuracy  validation/main/accuracy\n1           1.23951     1.03659               0.42           0.56                      \n2           0.746208    0.694044              0.74           0.78                      \n3           0.555498    0.61899               0.77           0.56                      \n4           0.448438    0.501323              0.85           0.8                       \n5           0.384808    0.43386               0.85           0.88                      \n6           0.343886    0.397124              0.9            0.88                      \n7           0.311689    0.357416              0.92           0.9                       \n8           0.283019    0.319386              0.96           0.9                       \n9           0.257954    0.290414              0.97           0.94                      \n10          0.23681     0.268185              0.97           0.96                      \n11          0.217634    0.245335              0.96           0.96                      \n12          0.201869    0.226008              0.97           0.96                      \n13          0.188083    0.209219              0.97           0.96                      \n14          0.176332    0.194392              0.97           0.96                      \n15          0.166238    0.180978              0.97           0.96                      \n16          0.157597    0.169269              0.97           0.96                      \n17          0.150323    0.15905               0.97           0.96                      \n18          0.144024    0.150328              0.97           0.96                      \n19          0.138576    0.142811              0.97           0.96                      \n20          0.133919    0.136215              0.97           0.96                      \n21          0.129842    0.130394              0.97           0.96                      \n22          0.126315    0.125188              0.97           0.98                      \n23          0.123218    0.120566              0.96           0.98                      \n24          0.120436    0.116444              0.96           0.98                      \n25          0.117928    0.112616              0.96           0.98                      \n26          0.115631    0.109026              0.96           0.98                      \n27          0.11361     0.105685              0.96           0.98                      \n28          0.111719    0.102632              0.96           0.98                      \n29          0.11012     0.0997764             0.96           0.98                      \n30          0.108482    0.0973794             0.96           0.98                      \n\n\u4e88\u6e2c\u3092\u3059\u308b\u3068\u304d\u306f\u4e0b\u8a18\u306e\u3088\u3046\u306b\u3057\u307e\u3059\u3002\n  > F.softmax(np.array([test[0][0]])).data\nout: array([[ 0.76944584,  0.18974303,  0.03136431,  0.00944675]], dtype=float32)\n\n  > F.softmax(np.array([test[0][0]])).data.argmax(axis=1)\nout: array([0])\n\n  > y = model.predictor(np.array([[1,  1,  1,  1  ]]).astype(np.float32))\n  > F.softmax(y).data\nout: array([[ 0.25907731,  0.11319122,  0.6277315 ]], dtype=float32)\n\n  > F.softmax(y).data.argmax(axis=1)\nout: array([2])\n\nChainer\u306e\u6700\u8fd1\u306e\u30d0\u30fc\u30b8\u30e7\u30f3\u3067\u306ftrainer\u3068\u3044\u3046\u306e\u3092\u4f7f\u3046\u3088\u3046\u306b\u306a\u3063\u3066\u3001\u62bd\u8c61\u5316\u304c\u9032\u307f\u307e\u3057\u305f\u3002\n\n\u4f8b\u3048\u3070\u3001\u3053\u306e\u8a18\u4e8b\u3001\n[Chainer\u306e\u65b0\u6a5f\u80fd\u304c\u3059\u3054\u3044\u52e2\u3044\u3067\u4ffa\u306e\u30bd\u30fc\u30b9\u30b3\u30fc\u30c9\u3092\u62bd\u8c61\u5316\u3057\u3066\u304f\u308b](http://qiita.com/_329_/items/bcc306194d52f7b81b5a)\n\n\u4f8b\u306b\u306fMNIST\u304c\u4f7f\u7528\u3055\u308c\u308b\u3053\u3068\u304c\u591a\u3044\u3067\u3059\u304c\u3001MINST\u306e\u30c7\u30fc\u30bf\u306f\u3001`train, test = chainer.datasets.get_mnist()`\u3067\u7c21\u5358\u306b\u8aad\u307f\u8fbc\u3081\u3066\u3057\u307e\u3046\u306e\u3067\u3001\u81ea\u5206\u306e\u30c7\u30fc\u30bf\u3092\u8aad\u307f\u8fbc\u3080\u3068\u304d\u3069\u3046\u3059\u308b\u306e\u304b\u3001\u3088\u304f\u308f\u304b\u308a\u307e\u305b\u3093\u3002\n\n\u53e4\u5178\u7684\u3067\u3059\u304c\u3001[Iris dataset](https://archive.ics.uci.edu/ml/datasets/Iris)\u3092\u5206\u985e\u3057\u3066\u307f\u307e\u3057\u305f\u3002Iris\u306f\u3001\u4e00\u7d44\uff14\u3064\u306e\u5024\u304b\u3089\u3001\u82b1\u306e\u7a2e\u985e\uff13\u3064\u3092\u5f53\u3066\u308b\u3082\u306e\u3067\u3059\u3002\n\nIris\u306f\u3001\u4e0b\u8a18\u306e\u30b3\u30fc\u30c9\u3067\u8aad\u307f\u8fbc\u3081\u307e\u3059\u3002\n\n```py3:\nfrom sklearn.datasets import load_iris\n\niris = load_iris()\nX = iris.data\nX = X.astype(np.float32)\n\nY = iris.target\nY = Y.flatten().astype(np.int32)\n```\n\n\u3061\u306a\u307f\u306b\n\n```\n  > X[[0]]\nout: array([ 5.0999999 ,  3.5       ,  1.39999998,  0.2       ], dtype=float32)\n\n  > Y\nout: array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n       0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n       1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n       2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n       2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2], dtype=int32)\n```\n\n\u3053\u3093\u306a\u611f\u3058\u3067\u3059\u3002\n\n\n[\u30b3\u30fc\u30c9\u306fGithub\u306b\u304a\u3044\u3066\u304a\u304d\u307e\u3057\u305f\u304c\u3001](https://github.com/danpansa/Chainer_Iris/blob/master/iris%20chainer%201.12.ipynb)\u4e0b\u8a18\u306e\u3088\u3046\u306b\u306a\u308a\u307e\u3059\u3002GPU\u306a\u3057\u3067CPU\u3067\u3084\u3063\u3066\u3044\u3066\u3001Jupyter\u3092\u4f7f\u3063\u3066\u3044\u307e\u3059\u3002\n\n```py3\nimport chainer\nimport chainer.functions as F\nimport chainer.links as L\nfrom chainer import training, datasets\nfrom chainer.training import extensions\nimport numpy as np\nfrom sklearn.datasets import load_iris\n\niris = load_iris()\nX = iris.data\nX = X.astype(np.float32)\nY = iris.target\nY = Y.flatten().astype(np.int32)\n\ntrain ,test= datasets.split_dataset_random(chainer.datasets.TupleDataset(X,Y),100)\ntrain_iter = chainer.iterators.SerialIterator(train, 10)\ntest_iter = chainer.iterators.SerialIterator(test, 1,repeat=False, shuffle=False)\n\nclass IrisModel(chainer.Chain):\n    def __init__(self):\n        super(IrisModel,self).__init__(\n                l1 = L.Linear(4,100),\n                l2 = L.Linear(100,100),\n                l3 = L.Linear(100,3))\n\n    def __call__(self,x):    \n         h = F.relu(self.l1(x))\n         h = F.relu(self.l2(h))\n         return self.l3(h)\n\nmodel = L.Classifier(IrisModel())\noptimizer = chainer.optimizers.Adam()\noptimizer.setup(model)\n\nupdater = training.StandardUpdater(train_iter, optimizer, device=-1)\ntrainer = training.Trainer(updater, (30, 'epoch'), out=\"result\")\ntrainer.extend(extensions.Evaluator(test_iter, model, device=-1))\ntrainer.extend(extensions.LogReport())\ntrainer.extend(extensions.PrintReport( ['epoch', 'main/loss', 'validation/main/loss', 'main/accuracy', 'validation/main/accuracy']))\ntrainer.extend(extensions.ProgressBar())\n\ntrainer.run()\n```\n\n\u3053\u308c\u3067\u4e0b\u8a18\u306e\u3088\u3046\u306b\u5b66\u7fd2\u304c\u59cb\u307e\u308a\u307e\u3059\u3002\n\n```\nepoch       main/loss   validation/main/loss  main/accuracy  validation/main/accuracy\n1           1.23951     1.03659               0.42           0.56                      \n2           0.746208    0.694044              0.74           0.78                      \n3           0.555498    0.61899               0.77           0.56                      \n4           0.448438    0.501323              0.85           0.8                       \n5           0.384808    0.43386               0.85           0.88                      \n6           0.343886    0.397124              0.9            0.88                      \n7           0.311689    0.357416              0.92           0.9                       \n8           0.283019    0.319386              0.96           0.9                       \n9           0.257954    0.290414              0.97           0.94                      \n10          0.23681     0.268185              0.97           0.96                      \n11          0.217634    0.245335              0.96           0.96                      \n12          0.201869    0.226008              0.97           0.96                      \n13          0.188083    0.209219              0.97           0.96                      \n14          0.176332    0.194392              0.97           0.96                      \n15          0.166238    0.180978              0.97           0.96                      \n16          0.157597    0.169269              0.97           0.96                      \n17          0.150323    0.15905               0.97           0.96                      \n18          0.144024    0.150328              0.97           0.96                      \n19          0.138576    0.142811              0.97           0.96                      \n20          0.133919    0.136215              0.97           0.96                      \n21          0.129842    0.130394              0.97           0.96                      \n22          0.126315    0.125188              0.97           0.98                      \n23          0.123218    0.120566              0.96           0.98                      \n24          0.120436    0.116444              0.96           0.98                      \n25          0.117928    0.112616              0.96           0.98                      \n26          0.115631    0.109026              0.96           0.98                      \n27          0.11361     0.105685              0.96           0.98                      \n28          0.111719    0.102632              0.96           0.98                      \n29          0.11012     0.0997764             0.96           0.98                      \n30          0.108482    0.0973794             0.96           0.98                      \n```\n\n\u4e88\u6e2c\u3092\u3059\u308b\u3068\u304d\u306f\u4e0b\u8a18\u306e\u3088\u3046\u306b\u3057\u307e\u3059\u3002\n\n```\n  > F.softmax(np.array([test[0][0]])).data\nout: array([[ 0.76944584,  0.18974303,  0.03136431,  0.00944675]], dtype=float32)\n\n  > F.softmax(np.array([test[0][0]])).data.argmax(axis=1)\nout: array([0])\n\n  > y = model.predictor(np.array([[1,  1,  1,  1  ]]).astype(np.float32))\n  > F.softmax(y).data\nout: array([[ 0.25907731,  0.11319122,  0.6277315 ]], dtype=float32)\n\n  > F.softmax(y).data.argmax(axis=1)\nout: array([2])\n```\n", "tags": ["Chainer", "python3"]}