{"context": "\u30c7\u30fc\u30bf\u30bd\u30fc\u30b9\u306f\u3044\u308d\u3044\u308d\u3042\u308a\u306a\u304c\u3089\u3082\u3001\u53d6\u308a\u6025\u304e\u30d5\u30a1\u30a4\u30eb\u306e\u307e\u307e\u30b9\u30c8\u30ec\u30fc\u30b8\u306b\u5165\u308c\u3066\u304a\u304f\u306e\u304c\u30cf\u30fc\u30c9\u30eb\u306f\u4f4e\u305d\u3046\u3002Spark\u306e\u3088\u3046\u306a\u30d3\u30c3\u30b0\u30c7\u30fc\u30bf\u524d\u63d0\u3067\u3042\u308c\u3070\u30ed\u30b0\u30d5\u30a1\u30a4\u30eb\u306a\u3069\u304c\u60f3\u5b9a\u3055\u308c\u308b\u3053\u3068\u3082\u591a\u3044\u306e\u3060\u308d\u3046\u3051\u3069\u3001\u4e00\u822c\u7684\u306a\u30d3\u30b8\u30cd\u30b9\u30c7\u30fc\u30bf\u306f\u907f\u3051\u3066\u901a\u308c\u306a\u3044\u306e\u3067\u307e\u305a\u306fCSV\u3001\u3068\u3044\u3046\u3053\u3068\u3067CSV\u5468\u308a\u3092\u5c11\u3057\u8a66\u3057\u3066\u307f\u305f\u3068\u304d\u306e\u30e1\u30e2\u3002( IBM Data Scientist Experience , Python 2 with Spark 2.0 \u306b\u3066\uff09\n\n\u6e96\u5099\nCSV\u30d5\u30a1\u30a4\u30eb\u3092Swift\u30d9\u30fc\u30b9\u306eIBM Object Storage\u3078\u30a2\u30c3\u30d7\u30ed\u30fc\u30c9\u3057\u3066\u304a\u304f\u3002\u753b\u9762\u53f3\u306e\"Drop you file here or browse your files to add a new file \"\u3092\u4f7f\u7528\u3002\u30b9\u30af\u30ea\u30fc\u30f3\u30b7\u30e7\u30c3\u30c8\u306e\u3088\u3046\u306bbaseball.csv , cars.csv , whiskey.csv\u3092\u30a2\u30c3\u30d7\u30ed\u30fc\u30c9\u3057\u305f\u3002\n\n\nObject Storage \u304b\u3089\u30c7\u30fc\u30bf\u3092\u8aad\u307f\u8fbc\u3093\u3067\u307f\u305f\n\u307e\u305a\u306fDSX\u30b3\u30fc\u30c9\u304b\u3089\u30a4\u30f3\u30b5\u30fc\u30c8\u3055\u308c\u308b\u30b3\u30fc\u30c9\u3067\u8a66\u3057\u3066\u307f\u305f\n\n\u3053\u3061\u3089\u30b3\u30f3\u30d5\u30a3\u30b0\u30ec\u30fc\u30b7\u30e7\u30f3\u3092\u30bb\u30c3\u30c8\u3059\u308b\u51e6\u7406\u3068\u3001CSV\u30c7\u30fc\u30bf\u3092DataFrame\u306b\u30ed\u30fc\u30c9\u3059\u308b\u51e6\u7406\u304c\u3042\u308b\u3002\n(1) Spark\u304b\u3089Hadoop\u306e\u30b3\u30f3\u30d5\u30a3\u30b0\u30ec\u30fc\u30b7\u30e7\u30f3\u3092\u30bb\u30c3\u30c8\nAccessing OpenStack Swift from Spark\u306b\u8a18\u8f09\u3055\u308c\u305f\u69cb\u6210\u30d1\u30e9\u30e1\u30fc\u30bf\u304c\u3001IBM Object Storage \u306b\u30a2\u30c3\u30d7\u30ed\u30fc\u30c9\u3057\u305f\u30d5\u30a1\u30a4\u30eb\u306b\u5408\u308f\u305b\u3066\u30bb\u30c3\u30c8\u3055\u308c\u3066\u3044\u308b\u6a21\u69d8\u3002\n\ntest.py\n# @hidden_cell\nfrom pyspark.sql import SQLContext\nsqlContext = SQLContext(sc)\n\n# This function accesses a file in your Object Storage. The definition contains your credentials.\n# You might want to remove those credentials before you share (name):\ndef set_hadoop_config_with_credentials_xxxxxxxxxxxxxxxxxxcxxxxxcc(name):\n    \"\"\"This function sets the Hadoop configuration so it is possible to\n    access data from Bluemix Object Storage V3 using Spark\"\"\"\n\n    prefix = 'fs.swift.service.' + name\n    hconf = sc._jsc.hadoopConfiguration()\n    hconf.set(prefix + '.auth.url', 'https://identity.open.softlayer.com'+'/v3/auth/tokens')\n    hconf.set(prefix + '.auth.endpoint.prefix', 'endpoints')\n    hconf.set(prefix + '.tenant', '4dbbbca3a8ec42eea9349120fb91dcf9')\n    hconf.set(prefix + '.username', 'xxxxxxxxxcxxxxxxcccxxxxxccc')\n    hconf.set(prefix + '.password', 'Xxxxxxxxxxxxxxxxx')\n    hconf.setInt(prefix + '.http.port', 8080)\n    hconf.set(prefix + '.region', 'dallas')\n    hconf.setBoolean(prefix + '.public', True)\n\n# you can choose any name\nname = 'keystone'\nset_hadoop_config_with_credentials_Xxxxxxxxxxxxxxxxxxcxxxxxc(name)\n\n\n(2) Spark DataFrame\u3078CSV\u30c7\u30fc\u30bf\u3092\u30ed\u30fc\u30c9\n\ntest.py\ndf_data_1=sqlContext.read.format('com.databricks.spark.csv')\\\n    .options(header='true',inferschema='true')\\\n    .load(\"swift://PredictiveAnalyticsProject2.\" + name + \"/whiskey.csv\")\n\n\n\u3053\u308c\u306fSpark 2.0\u4ee5\u524d\u306f\u5fc5\u8981\u3060\u3063\u305fspark-csv\u3068\u3044\u3046\u30d1\u30c3\u30b1\u30fc\u30b8\u3092\u5229\u7528\u3057\u3066\u3044\u308b\u3082\u306e\u306e\u3088\u3046\u3067\u3059.\nspark2.0\u304b\u3089\u306fSpark DataFrame\u304c\u76f4\u63a5csv\u3092\u6271\u3048\u308b\u3088\u3046\u3067\u3001read.csv()\u3082\u4f7f\u3048\u3066\u4fbf\u5229\u306b\u306a\u3063\u3066\u3044\u308b\u3002\n\n\nObject Storage \u3078\u30c7\u30fc\u30bf\u3092\u66f8\u304d\u51fa\u3057\u3066\u307f\u305f\nwhisky.csv\u3092\u8aad\u307f\u8fbc\u3093\u3060Spark DataFrame\u306e\u5185\u5bb9\u3092, whiskey_new.csv\u3068\u3044\u3046\u540d\u524d\u3067Object Storage \u306b\u66f8\u304d\u51fa\u3057\u305f\u3002\n(1) Spark DataFrame\u306ewrite\u3067\u51fa\u529b\u3057\u3066\u307f\u305f\n\u30b7\u30f3\u30d7\u30eb \u306bwrite.csv\uff08\uff09\u3068\u66f8\u3051\u3070OK.\n\nmode\u306f\u3053\u3061\u3089\u306b\u3042\u308b\u3088\u3046\u306aSave Mode\u304c\u5229\u7528\u3067\u304d\u308b\u3088\u3046\u3067\u3059\u3002\n\u51fa\u529b\u3055\u308c\u308b\u30d5\u30a1\u30a4\u30eb\u3092\u898b\u308b\u3068\u3001\u4ee5\u4e0b\u306e\u30b9\u30af\u30ea\u30fc\u30f3\u30b7\u30e7\u30c3\u30c8\u306e\u3088\u3046\u306b\u4e00\u3064\u306eCSV\u3067\u306f\u306a\u304f\u3001\u8907\u6570\u306e\u30d5\u30a1\u30a4\u30eb\u306b\u5206\u5272\u3055\u308c\u3066\u51fa\u529b\u3055\u308c\u3066\u3044\u307e\u3057\u305f\u3002\u8907\u6570\u306e\u30ce\u30fc\u30c9\u3067\u51e6\u7406\u3057\u3066\u3044\u308b\u304b\u3089\u306a\u306e\u3060\u3068\u601d\u3044\u307e\u3059\u3002\uff08\u4e0d\u601d\u8b70\u306a\u3082\u306e\u3067?\u3001\u3053\u308c\u3092Spark\u304b\u3089\u518d\u5ea6read.csv\u3067\u8aad\u3080\u3068\u304d\u306f\u4e00\u3064\u306etextFile, csv\u3068\u3057\u3066\u6271\u308f\u308c\u308b\u304b\u3089\u554f\u984c\u306a\u3044\u307f\u305f\u3044\u3067\u3059\uff09\u3002\n\n\u3067\u3082\u4e00\u3064\u306e\u30d5\u30a1\u30a4\u30eb\u3067\u51fa\u3057\u305f\u3044\u3068\u8003\u3048\u308b\u4eba\u3082\u79c1\u4ee5\u5916\u306b\u3082\u3044\u308b\u3088\u3046\u3067\u3001\u4e00\u3064\u306e\u30d5\u30a1\u30a4\u30eb\u306b\u51fa\u529b\u3067\u304d\u306a\u3044\u304b\u554f\u3044\u5408\u308f\u305b\u3066\u3044\u308bQ&A\u3082\u3042\u308a\u307e\u3057\u305f\uff08http://stackoverflow.com/questions/31674530/write-single-csv-file-using-spark-csv\uff09\n(2) Spark\u3092\u5229\u7528\u305b\u305a\u3001REST API\u3092\u8a66\u3057\u3066\u307f\u305f\n\u5927\u91cf\u30c7\u30fc\u30bf\u3092\u6271\u3046\u5834\u5408\u306b\u306f\u5411\u3044\u3066\u3044\u306a\u3044\u3068\u601d\u3044\u307e\u3059\u304c\u3001\u4ee5\u4e0b\u306e\u3088\u3046\u306a\u30b3\u30fc\u30c9\u3067Object Storage\u4e0a\u306b\u4e00\u3064\u306eCSV\u3068\u3057\u3066put\u3067\u304d\u307e\u3059\u3002\uff08DSX\u304cPandas DataFrame\u4f5c\u6210\u7528\u306b\u30a4\u30f3\u30b5\u30fc\u30c8\u3059\u308b\u30b3\u30fc\u30c9\u306eget\u90e8\u5206\u3092put\u306b\u5909\u66f4\u3057\u3066\u3044\u308b\u3060\u3051\u3067\u3059\u3002\uff11\u56de\u76ee\u306eAPI\u30b3\u30fc\u30eb/POST\u3092\u3057\u3066\u8a8d\u8a3c\u60c5\u5831\u3092\u3082\u3089\u3044\u3064\u3064\u3001\u30ec\u30b9\u30dd\u30f3\u30b9\u304b\u3089\u30a2\u30c3\u30d7\u30ed\u30fc\u30c9\u3059\u308b\u305f\u3081\u306eput\u5148/url2\u3092\u7d44\u307f\u7acb\u3066\u3066\u3044\u308b\u3088\u3046\u3067\u3059\uff09\n\nput_sample.py\ndef put_object_storage_file_with_credentials_xxxxxxxxxx(container, filename, indata):\n    url1 = ''.join(['https://identity.open.softlayer.com', '/v3/auth/tokens'])\n    data = {'auth': {'identity': {'methods': ['password'],\n            'password': {'user': {'name': 'member_1825cd3bc875420fc629ccfd22c22e20433a7ac9','domain': {'id': '07e33cca1abe47d293b86de49f1aa8bc'},\n            'password': 'xxxxxxxxxx'}}}}}\n    headers1 = {'Content-Type': 'application/json'}\n    resp1 = requests.post(url=url1, data=json.dumps(data), headers=headers1)\n    resp1_body = resp1.json()\n    for e1 in resp1_body['token']['catalog']:\n        if(e1['type']=='object-store'):\n            for e2 in e1['endpoints']:\n                        if(e2['interface']=='public'and e2['region']=='dallas'):\n                            url2 = ''.join([e2['url'],'/', container, '/', filename])\n    s_subject_token = resp1.headers['x-subject-token']\n    headers2 = {'X-Auth-Token': s_subject_token, 'accept': 'application/json'}\n    resp2 = requests.put(url=url2, headers=headers2 , data=indata)\n    print resp2\n    return (resp2.content)\n\n\nput_object_storage_file_with_credentials_xxxxxxxxxx( 'PredictiveAnalyticsProject2', 'whiskey_new_s.csv' , df_data_2.to_csv( index = False ) )\n\n\n\n\n\u8ffd\u8a18\n\u4e0a\u8a18\u306eREST API\u3067Put\u3059\u308b\u30a4\u30e1\u30fc\u30b8\u3068\u3057\u3066 Python\u306eswiftclient\u3092\u5229\u7528\u3059\u308b\u65b9\u6cd5\u3082\u3042\u308b\u3088\u3046\u3067\u3059\u304c\u3001IBM\u306eData Scientist Experience\u74b0\u5883\u3067\u306f\u4f7f\u3048\u306a\u3044\u3088\u3046\u3067\u3057\u305f\u3002\nUsing IBM Object Storage in Bluemix, with Python\n\n\u30c7\u30fc\u30bf\u30bd\u30fc\u30b9\u306f\u3044\u308d\u3044\u308d\u3042\u308a\u306a\u304c\u3089\u3082\u3001\u53d6\u308a\u6025\u304e\u30d5\u30a1\u30a4\u30eb\u306e\u307e\u307e\u30b9\u30c8\u30ec\u30fc\u30b8\u306b\u5165\u308c\u3066\u304a\u304f\u306e\u304c\u30cf\u30fc\u30c9\u30eb\u306f\u4f4e\u305d\u3046\u3002Spark\u306e\u3088\u3046\u306a\u30d3\u30c3\u30b0\u30c7\u30fc\u30bf\u524d\u63d0\u3067\u3042\u308c\u3070\u30ed\u30b0\u30d5\u30a1\u30a4\u30eb\u306a\u3069\u304c\u60f3\u5b9a\u3055\u308c\u308b\u3053\u3068\u3082\u591a\u3044\u306e\u3060\u308d\u3046\u3051\u3069\u3001\u4e00\u822c\u7684\u306a\u30d3\u30b8\u30cd\u30b9\u30c7\u30fc\u30bf\u306f\u907f\u3051\u3066\u901a\u308c\u306a\u3044\u306e\u3067\u307e\u305a\u306fCSV\u3001\u3068\u3044\u3046\u3053\u3068\u3067CSV\u5468\u308a\u3092\u5c11\u3057\u8a66\u3057\u3066\u307f\u305f\u3068\u304d\u306e\u30e1\u30e2\u3002( IBM Data Scientist Experience , Python 2 with Spark 2.0 \u306b\u3066\uff09\n## \u6e96\u5099\nCSV\u30d5\u30a1\u30a4\u30eb\u3092Swift\u30d9\u30fc\u30b9\u306eIBM Object Storage\u3078\u30a2\u30c3\u30d7\u30ed\u30fc\u30c9\u3057\u3066\u304a\u304f\u3002\u753b\u9762\u53f3\u306e\"Drop you file here or browse your files to add a new file \"\u3092\u4f7f\u7528\u3002\u30b9\u30af\u30ea\u30fc\u30f3\u30b7\u30e7\u30c3\u30c8\u306e\u3088\u3046\u306bbaseball.csv , cars.csv , whiskey.csv\u3092\u30a2\u30c3\u30d7\u30ed\u30fc\u30c9\u3057\u305f\u3002\n<img width=\"316\" alt=\"Screen Shot 2016-11-23 at 21.22.24.png\" src=\"https://qiita-image-store.s3.amazonaws.com/0/149522/b8d9de63-fdc0-b1b0-0746-0035e6e4c0cc.png\">\n\n## Object Storage \u304b\u3089\u30c7\u30fc\u30bf\u3092\u8aad\u307f\u8fbc\u3093\u3067\u307f\u305f\n\u307e\u305a\u306fDSX\u30b3\u30fc\u30c9\u304b\u3089\u30a4\u30f3\u30b5\u30fc\u30c8\u3055\u308c\u308b\u30b3\u30fc\u30c9\u3067\u8a66\u3057\u3066\u307f\u305f\n<img width=\"298\" alt=\"Screen Shot 2016-11-23 at 21.20.47.png\" src=\"https://qiita-image-store.s3.amazonaws.com/0/149522/ae342671-70ee-2ae9-ead4-c98e104a260e.png\">\n\n\n\u3053\u3061\u3089\u30b3\u30f3\u30d5\u30a3\u30b0\u30ec\u30fc\u30b7\u30e7\u30f3\u3092\u30bb\u30c3\u30c8\u3059\u308b\u51e6\u7406\u3068\u3001CSV\u30c7\u30fc\u30bf\u3092DataFrame\u306b\u30ed\u30fc\u30c9\u3059\u308b\u51e6\u7406\u304c\u3042\u308b\u3002\n(1) Spark\u304b\u3089Hadoop\u306e\u30b3\u30f3\u30d5\u30a3\u30b0\u30ec\u30fc\u30b7\u30e7\u30f3\u3092\u30bb\u30c3\u30c8\n[Accessing OpenStack Swift from Spark](http://spark.apache.org/docs/latest/storage-openstack-swift.html)\u306b\u8a18\u8f09\u3055\u308c\u305f\u69cb\u6210\u30d1\u30e9\u30e1\u30fc\u30bf\u304c\u3001IBM Object Storage \u306b\u30a2\u30c3\u30d7\u30ed\u30fc\u30c9\u3057\u305f\u30d5\u30a1\u30a4\u30eb\u306b\u5408\u308f\u305b\u3066\u30bb\u30c3\u30c8\u3055\u308c\u3066\u3044\u308b\u6a21\u69d8\u3002\n\n```test.py\n# @hidden_cell\nfrom pyspark.sql import SQLContext\nsqlContext = SQLContext(sc)\n\n# This function accesses a file in your Object Storage. The definition contains your credentials.\n# You might want to remove those credentials before you share (name):\ndef set_hadoop_config_with_credentials_xxxxxxxxxxxxxxxxxxcxxxxxcc(name):\n    \"\"\"This function sets the Hadoop configuration so it is possible to\n    access data from Bluemix Object Storage V3 using Spark\"\"\"\n\n    prefix = 'fs.swift.service.' + name\n    hconf = sc._jsc.hadoopConfiguration()\n    hconf.set(prefix + '.auth.url', 'https://identity.open.softlayer.com'+'/v3/auth/tokens')\n    hconf.set(prefix + '.auth.endpoint.prefix', 'endpoints')\n    hconf.set(prefix + '.tenant', '4dbbbca3a8ec42eea9349120fb91dcf9')\n    hconf.set(prefix + '.username', 'xxxxxxxxxcxxxxxxcccxxxxxccc')\n    hconf.set(prefix + '.password', 'Xxxxxxxxxxxxxxxxx')\n    hconf.setInt(prefix + '.http.port', 8080)\n    hconf.set(prefix + '.region', 'dallas')\n    hconf.setBoolean(prefix + '.public', True)\n\n# you can choose any name\nname = 'keystone'\nset_hadoop_config_with_credentials_Xxxxxxxxxxxxxxxxxxcxxxxxc(name)\n```\n\n(2) Spark DataFrame\u3078CSV\u30c7\u30fc\u30bf\u3092\u30ed\u30fc\u30c9\n\n```test.py\ndf_data_1=sqlContext.read.format('com.databricks.spark.csv')\\\n    .options(header='true',inferschema='true')\\\n    .load(\"swift://PredictiveAnalyticsProject2.\" + name + \"/whiskey.csv\")\n```\n\u3053\u308c\u306fSpark 2.0\u4ee5\u524d\u306f\u5fc5\u8981\u3060\u3063\u305fspark-csv\u3068\u3044\u3046\u30d1\u30c3\u30b1\u30fc\u30b8\u3092\u5229\u7528\u3057\u3066\u3044\u308b\u3082\u306e\u306e\u3088\u3046\u3067\u3059.\nspark2.0\u304b\u3089\u306fSpark DataFrame\u304c\u76f4\u63a5csv\u3092\u6271\u3048\u308b\u3088\u3046\u3067\u3001read.csv()\u3082\u4f7f\u3048\u3066\u4fbf\u5229\u306b\u306a\u3063\u3066\u3044\u308b\u3002\n<img width=\"1058\" alt=\"Screen Shot 2016-11-23 at 21.38.46.png\" src=\"https://qiita-image-store.s3.amazonaws.com/0/149522/3e1ebf48-6e63-2d68-5e46-0b929ae03031.png\">\n\n## Object Storage \u3078\u30c7\u30fc\u30bf\u3092\u66f8\u304d\u51fa\u3057\u3066\u307f\u305f\nwhisky.csv\u3092\u8aad\u307f\u8fbc\u3093\u3060Spark DataFrame\u306e\u5185\u5bb9\u3092, whiskey_new.csv\u3068\u3044\u3046\u540d\u524d\u3067Object Storage \u306b\u66f8\u304d\u51fa\u3057\u305f\u3002\n(1) Spark DataFrame\u306ewrite\u3067\u51fa\u529b\u3057\u3066\u307f\u305f\n\u30b7\u30f3\u30d7\u30eb \u306bwrite.csv\uff08\uff09\u3068\u66f8\u3051\u3070OK.\n<img width=\"1035\" alt=\"Screen Shot 2016-11-23 at 21.50.24.png\" src=\"https://qiita-image-store.s3.amazonaws.com/0/149522/06ad16c9-d8f0-0856-9efd-35e94158d887.png\">\n\nmode\u306f[\u3053\u3061\u3089](http://spark.apache.org/docs/latest/sql-programming-guide.html)\u306b\u3042\u308b\u3088\u3046\u306aSave Mode\u304c\u5229\u7528\u3067\u304d\u308b\u3088\u3046\u3067\u3059\u3002\n\u51fa\u529b\u3055\u308c\u308b\u30d5\u30a1\u30a4\u30eb\u3092\u898b\u308b\u3068\u3001\u4ee5\u4e0b\u306e\u30b9\u30af\u30ea\u30fc\u30f3\u30b7\u30e7\u30c3\u30c8\u306e\u3088\u3046\u306b\u4e00\u3064\u306eCSV\u3067\u306f\u306a\u304f\u3001\u8907\u6570\u306e\u30d5\u30a1\u30a4\u30eb\u306b\u5206\u5272\u3055\u308c\u3066\u51fa\u529b\u3055\u308c\u3066\u3044\u307e\u3057\u305f\u3002\u8907\u6570\u306e\u30ce\u30fc\u30c9\u3067\u51e6\u7406\u3057\u3066\u3044\u308b\u304b\u3089\u306a\u306e\u3060\u3068\u601d\u3044\u307e\u3059\u3002\uff08\u4e0d\u601d\u8b70\u306a\u3082\u306e\u3067?\u3001\u3053\u308c\u3092Spark\u304b\u3089\u518d\u5ea6read.csv\u3067\u8aad\u3080\u3068\u304d\u306f\u4e00\u3064\u306etextFile, csv\u3068\u3057\u3066\u6271\u308f\u308c\u308b\u304b\u3089\u554f\u984c\u306a\u3044\u307f\u305f\u3044\u3067\u3059\uff09\u3002\n<img width=\"1342\" alt=\"Screen Shot 2016-11-23 at 21.49.21.png\" src=\"https://qiita-image-store.s3.amazonaws.com/0/149522/da5b7a4f-86c9-7510-6c1c-02a9ac983f37.png\">\n\u3067\u3082\u4e00\u3064\u306e\u30d5\u30a1\u30a4\u30eb\u3067\u51fa\u3057\u305f\u3044\u3068\u8003\u3048\u308b\u4eba\u3082\u79c1\u4ee5\u5916\u306b\u3082\u3044\u308b\u3088\u3046\u3067\u3001\u4e00\u3064\u306e\u30d5\u30a1\u30a4\u30eb\u306b\u51fa\u529b\u3067\u304d\u306a\u3044\u304b\u554f\u3044\u5408\u308f\u305b\u3066\u3044\u308bQ&A\u3082\u3042\u308a\u307e\u3057\u305f\uff08http://stackoverflow.com/questions/31674530/write-single-csv-file-using-spark-csv\uff09\n\n(2) Spark\u3092\u5229\u7528\u305b\u305a\u3001REST API\u3092\u8a66\u3057\u3066\u307f\u305f\n\u5927\u91cf\u30c7\u30fc\u30bf\u3092\u6271\u3046\u5834\u5408\u306b\u306f\u5411\u3044\u3066\u3044\u306a\u3044\u3068\u601d\u3044\u307e\u3059\u304c\u3001\u4ee5\u4e0b\u306e\u3088\u3046\u306a\u30b3\u30fc\u30c9\u3067Object Storage\u4e0a\u306b\u4e00\u3064\u306eCSV\u3068\u3057\u3066put\u3067\u304d\u307e\u3059\u3002\uff08DSX\u304cPandas DataFrame\u4f5c\u6210\u7528\u306b\u30a4\u30f3\u30b5\u30fc\u30c8\u3059\u308b\u30b3\u30fc\u30c9\u306eget\u90e8\u5206\u3092put\u306b\u5909\u66f4\u3057\u3066\u3044\u308b\u3060\u3051\u3067\u3059\u3002\uff11\u56de\u76ee\u306eAPI\u30b3\u30fc\u30eb/POST\u3092\u3057\u3066\u8a8d\u8a3c\u60c5\u5831\u3092\u3082\u3089\u3044\u3064\u3064\u3001\u30ec\u30b9\u30dd\u30f3\u30b9\u304b\u3089\u30a2\u30c3\u30d7\u30ed\u30fc\u30c9\u3059\u308b\u305f\u3081\u306eput\u5148/url2\u3092\u7d44\u307f\u7acb\u3066\u3066\u3044\u308b\u3088\u3046\u3067\u3059\uff09\n\n``` put_sample.py\ndef put_object_storage_file_with_credentials_xxxxxxxxxx(container, filename, indata):\n    url1 = ''.join(['https://identity.open.softlayer.com', '/v3/auth/tokens'])\n    data = {'auth': {'identity': {'methods': ['password'],\n            'password': {'user': {'name': 'member_1825cd3bc875420fc629ccfd22c22e20433a7ac9','domain': {'id': '07e33cca1abe47d293b86de49f1aa8bc'},\n            'password': 'xxxxxxxxxx'}}}}}\n    headers1 = {'Content-Type': 'application/json'}\n    resp1 = requests.post(url=url1, data=json.dumps(data), headers=headers1)\n    resp1_body = resp1.json()\n    for e1 in resp1_body['token']['catalog']:\n        if(e1['type']=='object-store'):\n            for e2 in e1['endpoints']:\n                        if(e2['interface']=='public'and e2['region']=='dallas'):\n                            url2 = ''.join([e2['url'],'/', container, '/', filename])\n    s_subject_token = resp1.headers['x-subject-token']\n    headers2 = {'X-Auth-Token': s_subject_token, 'accept': 'application/json'}\n    resp2 = requests.put(url=url2, headers=headers2 , data=indata)\n    print resp2\n    return (resp2.content)\n\n\nput_object_storage_file_with_credentials_xxxxxxxxxx( 'PredictiveAnalyticsProject2', 'whiskey_new_s.csv' , df_data_2.to_csv( index = False ) )\n\n```\n### \u8ffd\u8a18\n\u4e0a\u8a18\u306eREST API\u3067Put\u3059\u308b\u30a4\u30e1\u30fc\u30b8\u3068\u3057\u3066 Python\u306eswiftclient\u3092\u5229\u7528\u3059\u308b\u65b9\u6cd5\u3082\u3042\u308b\u3088\u3046\u3067\u3059\u304c\u3001IBM\u306eData Scientist Experience\u74b0\u5883\u3067\u306f\u4f7f\u3048\u306a\u3044\u3088\u3046\u3067\u3057\u305f\u3002\n[Using IBM Object Storage in Bluemix, with Python](https://developer.ibm.com/recipes/tutorials/using-ibm-object-storage-in-bluemix-with-python/)\n<img width=\"785\" alt=\"Screen Shot 2016-11-23 at 22.36.18.png\" src=\"https://qiita-image-store.s3.amazonaws.com/0/149522/0a0cec40-9cb6-bd7c-d483-f31e7a720e98.png\">\n\n\n\n\n\n", "tags": ["Python", "Spark", "Data"]}