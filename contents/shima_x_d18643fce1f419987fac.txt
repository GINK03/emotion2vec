{"context": " More than 1 year has passed since last update.\n\n\u52d5\u6a5f\n\u524d\u56de\u66f8\u3044\u305f\u30b3\u30fc\u30c9\u304c\u4fee\u6b63\u51fa\u6765\u305f\u306e\u3067\u3001\u4fee\u6b63\u8a18\u4e8b\u3092\u3042\u3052\u3055\u305b\u3066\u3044\u305f\u3060\u304d\u307e\u3057\u305f\u3002\n\u524d\u56de\u306e\u5185\u5bb9\u306f\u3053\u3061\u3089\u3092\u5fa1\u89a7\u304f\u3060\u3055\u3044\u3002\n\n\u53c2\u8003\u6587\u732e\n\u524d\u56de\u3068\u540c\u3058\u3067\u3059\u3002\u5ff5\u306e\u305f\u3081\u63b2\u8f09\u3057\u3066\u304a\u304d\u307e\u3059\u3002\n\n\n\u4e88\u6e2c\u306b\u3044\u304b\u3059\u7d71\u8a08\u30e2\u30c7\u30ea\u30f3\u30b0\u306e\u57fa\u672c\u2015\u30d9\u30a4\u30ba\u7d71\u8a08\u5165\u9580\u304b\u3089\u5fdc\u7528\u307e\u3067\n\n\n\u6642\u7cfb\u5217\u89e3\u6790\u5165\u9580\n\n\n\u30d9\u30a4\u30ba\u7d71\u8a08\u30c7\u30fc\u30bf\u89e3\u6790 (R\u3067\u5b66\u3076\u30c7\u30fc\u30bf\u30b5\u30a4\u30a8\u30f3\u30b9 3)\n\n\u77e5\u8b58\u767a\u898b\u3068\u81ea\u5df1\u7d44\u7e54\u578b\u306e\u7d71\u8a08\u30e2\u30c7\u30eb\n\u81ea\u5df1\u7d44\u7e54\u5316\u578b\u72b6\u614b\u7a7a\u9593\u30e2\u30c7\u30eb\u3092\u7528\u3044\u305f\u904b\u52d5\u8ecc\u8de1\u306e\u30d5\u30a3\u30eb\u30bf\u30ea\u30f3\u30b0\n\u521d\u671f\u5206\u5e03\u63a2\u7d22\u4ed8\u304d\u81ea\u5df1\u7d44\u7e54\u5316\u72b6\u614b\u7a7a\u9593\u30e2\u30c7\u30eb\u306b\u3088\u308b\u91d1\u878d\u6642\u7cfb\u5217\u89e3\u6790\u306e\u6700\u524d\u7dda\uff1at\u5206\u5e03\u4ed8\u304d\u78ba\u7387\u7684\u30dc\u30e9\u30c6\u30a3\u30ea\u30c6\u30a3\u5909\u52d5\u30e2\u30c7\u30eb\u3078\u306e\u5fdc\u7528\n\n\n\u53c2\u8003\u30b3\u30fc\u30c9\n\u6319\u52d5\u4e0d\u5be9\u3060\u3063\u305f\u539f\u56e0\u306f\u3001scipy.stats.cauchy.rvs\u3067size\u3092\u4e0e\u3048\u3066\u306a\u3044\u4e8b\u3067\u3057\u305f\u3002\n\u30d9\u30af\u30c8\u30eb\u306e\u8981\u7d20\u6570\u3092\u4e0e\u3048\u306a\u3044\u3068\u8b66\u544a\u3082\u7121\u3057\u306b\u610f\u5473\u4e0d\u660e\u306a\u5024\u3092\u8fd4\u3057\u3066\u304d\u307e\u3059\u3002\u3002\u3002\n\u3042\u3068\u306f\u3001\u591a\u5c11\u6c4e\u7528\u7684\u306b\u4f7f\u3048\u308b\u3088\u3046\u306b\u4fee\u6b63\u3057\u307e\u3057\u305f\u3002\n\u3068\u3044\u3063\u3066\u3082\u30e2\u30c7\u30eb\u304c\u5909\u308f\u308c\u3070\u3001\n(1)get_system_noise\u3001(2)calc_pred_particles\u3001(3)calc_particles_weight\u306e3\u3064\u306e\u95a2\u6570\u306f\u4fee\u6b63\u3059\u308b\u5fc5\u8981\u304c\u51fa\u3066\u304d\u307e\u3059\u3002\n\u3067\u306f\u3001\u4ee5\u4e0b\u306b\u4fee\u6b63\u3057\u305f\u30b3\u30fc\u30c9\u3092\u8a18\u8f09\u3057\u3066\u3044\u304d\u307e\u3059\u3002\n# coding: utf-8\n\nfrom math import log, pow, sqrt\nimport numpy as np\nfrom scipy.stats import norm, cauchy\nfrom numpy.random import uniform, multivariate_normal\nfrom multiprocessing import Pool\nimport matplotlib.pyplot as plt\n\n\nclass ParticleFilter:    \n    log_likelihood = 0.0 # \u5bfe\u6570\u5c24\u5ea6\n    TIME = 1\n    PR=8 # unmber of processing\n\n    def __init__(self, PARTICLES_NUM, k=1, ydim=1, sys_pdim=1, ob_pdim=1, sh_parameters=[0.01, 0.35]):\n        self.nois_sh_parameters = sh_parameters # nu:\u30b7\u30b9\u30c6\u30e0\u30ce\u30a4\u30ba\u306e\u4f4d\u7f6e\u8d85\u3005\u30d1\u30e9\u30e1\u30bf , xi:\u89b3\u6e2c\u30ce\u30a4\u30ba\u306e\u4f4d\u7f6e\u8d85\u3005\u30d1\u30e9\u30e1\u30bf\n        pdim = sys_pdim+ob_pdim\n        self.PARTICLES_NUM = PARTICLES_NUM # \u7c92\u5b50\u6570\n        self.TEETH_OF_COMB = np.arange(0, 1, float(1.0)/self.PARTICLES_NUM)\n        self.weights = np.zeros((ydim, self.PARTICLES_NUM), dtype=np.float64)\n        self.particles = np.zeros((k*ydim+pdim ,self.PARTICLES_NUM), dtype=np.float64)\n        self.predicted_particles = np.zeros((k*ydim+pdim , self.PARTICLES_NUM), dtype=np.float64)\n        np.random.seed(555)\n        self.predicted_value = []\n        self.filtered_value = []\n        self.sys_nois = []\n        self.ob_nois = []\n        self.LSM = np.zeros(ydim) # \uff12\u4e57\u8aa4\u5dee\n\n        self.F, self.G, self.H= self.FGHset(k, ydim, pdim)\n        self.k = k\n        self.ydim = ydim\n        self.pdim = pdim\n        self.sys_pdim = sys_pdim\n        self.ob_pdim = ob_pdim\n\n    def init_praticles_distribution(self, P, r):\n        \"\"\"initialize particles\n        x_0|0\n        tau_0|0\n        sigma_0|0\n        \"\"\"\n        data_particles = multivariate_normal([1]*self.ydim*self.k,\n                            np.eye(self.ydim*self.k)*10, self.PARTICLES_NUM).T\n        param_particles = np.zeros((self.pdim, self.PARTICLES_NUM))\n        for i in xrange(self.pdim):\n            param_particles[i,:] = uniform(P-r, P+r, self.PARTICLES_NUM)\n        self.particles = np.vstack((data_particles, param_particles))\n\n    def get_system_noise(self):\n        \"\"\"v_t vector\"\"\"\n        data_noise = np.zeros((self.ydim, self.PARTICLES_NUM), dtype=np.float64)\n        for i in xrange(self.ydim):\n            data_noise[i,:] = cauchy.rvs(loc=[0]*self.PARTICLES_NUM, scale=np.power(10,self.particles[self.ydim]),\n                                    size=self.PARTICLES_NUM)\n        data_noise[data_noise==float(\"-inf\")] = -1e308\n        data_noise[data_noise==float(\"inf\")] = 1e308\n\n        parameter_noises = np.zeros((self.pdim, self.PARTICLES_NUM), dtype=np.float64)\n        for i in xrange(self.pdim):\n            parameter_noises[i,:] = cauchy.rvs(loc=0, scale=self.nois_sh_parameters[i], size=self.PARTICLES_NUM)\n        return np.vstack((data_noise, parameter_noises))\n\n    def calc_pred_particles(self):\n        \"\"\"calculate system function\n        x_t|t-1 = F*x_t-1 + Gv_t\n        \"\"\"\n        return self.F.dot(self.particles) + self.G.dot(self.get_system_noise()) # linear non-Gaussian  \n\n    def calc_particles_weight(self,y):\n        \"\"\"calculate fitness probabilities between observation value and predicted value\n        w_t\n        \"\"\"\n        locs = self.calc_pred_particles()\n        self.predicted_particles = locs\n        scale=np.power(10,locs[-1])\n        scale[scale==0] = 1e-308\n\n        # \u591a\u5909\u91cf\u306e\u5834\u5408\u306a\u3069\u306f\u4fee\u6b63\u304c\u5fc5\u8981\n        self.weights = cauchy.pdf( np.array([y]*self.PARTICLES_NUM) - self.H.dot(locs), loc=[0]*self.PARTICLES_NUM,\n                                scale=scale, size=self.PARTICLES_NUM).flatten()\n\n    def calc_likelihood(self):\n        \"\"\"calculate likelihood at that point\n        p(y_t|y_1:t-1)\n        \"\"\"\n        res = np.sum(self.weights)/self.PARTICLES_NUM\n        self.log_likelihood += log(res)\n\n    def normalize_weights(self):\n        \"\"\"wtilda_t\"\"\"\n        self.weights = self.weights/np.sum(self.weights)\n\n    def resample(self,y):\n        \"\"\"x_t|t\"\"\"\n        self.normalize_weights()\n\n        self.memorize_predicted_value()\n\n        # accumulate weight\n        cum = np.cumsum(self.weights)\n\n        # create roulette pointer \n        base = uniform(0,float(1.0)/self.PARTICLES_NUM)\n        pointers = self.TEETH_OF_COMB + base\n\n        # select particles\n        selected_idx = [np.where(cum>=p)[0][0] for p in pointers]\n        \"\"\"\n        pool = Pool(processes=self.PR)\n        selected_idx = pool.map(get_slected_particles_idx, ((cum,p) for p in pointers))\n        pool.close()\n        pool.join()     \n        \"\"\"\n\n        self.particles = self.predicted_particles[:,selected_idx]\n        self.memorize_filtered_value(selected_idx, y)\n\n    def memorize_predicted_value(self):\n        predicted_value = np.sum(self.predicted_particles*self.weights, axis=1)[0]\n        self.predicted_value.append(predicted_value)\n\n    def memorize_filtered_value(self, selected_idx, y):\n        filtered_value = np.sum(self.particles*self.weights[selected_idx] , axis=1) \\\n                            /np.sum(self.weights[selected_idx])\n        self.filtered_value.append(filtered_value[:self.ydim])\n        self.sys_nois.append(np.power(10,filtered_value[self.ydim:self.ydim+self.sys_pdim]))\n        self.ob_nois.append(np.power(10,filtered_value[self.ydim+self.sys_pdim:]))\n        self.calculate_LSM(y,filtered_value[:self.ydim])\n\n    def calculate_LSM(self,y,filterd_value):\n        self.LSM += pow(y-filterd_value,2)\n\n    def forward(self,y):\n        \"\"\"compute system model and observation model\"\"\"\n        print 'calculating time at %d' % self.TIME\n        self.calc_pred_particles()\n        self.calc_particles_weight(y)\n        self.calc_likelihood()\n        self.resample(y)\n        self.TIME += 1\n\n    def FGHset(self, k, vn_y, n_h_parameters):\n        \"\"\"\u72b6\u614b\u7a7a\u9593\u8868\u73fe\u306e\u884c\u5217\u8a2d\u5b9a\n        vn_y:\u5165\u529b\u30d9\u30af\u30c8\u30eb\u306e\u6b21\u5143\n        n_h_parameters:\u30cf\u30a4\u30d1\u30fc\u30d1\u30e9\u30e1\u30bf\u6570\n        k\uff1a\u968e\u5dee\n        \"\"\"\n        G_upper_block = np.zeros((k*vn_y, vn_y+n_h_parameters))\n        G_lower_block = np.zeros((n_h_parameters, vn_y+n_h_parameters))\n        G_lower_block[-n_h_parameters:, -n_h_parameters:] = np.eye(n_h_parameters)\n        G_upper_block[:vn_y, :vn_y] = np.eye(vn_y)\n        G = np.vstack( (G_upper_block, G_lower_block) )\n\n        H = np.hstack( (np.eye(vn_y), \n                            np.zeros((vn_y, vn_y*(k-1)+n_h_parameters))\n                        ) )\n\n        # \u30c8\u30ec\u30f3\u30c9\u30e2\u30c7\u30eb\u306e\u30d6\u30ed\u30c3\u30af\u884c\u5217\u306e\u69cb\u7bc9\n        F_upper_block = np.zeros((k*vn_y, k*vn_y+n_h_parameters))\n        F_lower_block = np.zeros((n_h_parameters, k*vn_y+n_h_parameters))\n        F_lower_block[-n_h_parameters:, -n_h_parameters:] = np.eye(n_h_parameters)\n        if k==1:\n            F_upper_block[:vn_y, :vn_y] = np.eye(vn_y)\n        elif k==2:\n            F_upper_block[:vn_y, :vn_y] = np.eye(vn_y)*2\n            F_upper_block[:vn_y, vn_y:k*vn_y] = np.eye(vn_y)*-1\n            F_upper_block[vn_y:k*vn_y, :vn_y] = np.eye(vn_y)\n        F = np.vstack((F_upper_block, F_lower_block))\n\n        return F, G, H\n\ndef get_slected_particles_idx((cum,p)):\n    \"\"\"multiprocessing function\"\"\"\n    try:\n        return np.where(cum>=p)[0][0]\n    except Exception, e:\n        import sys\n        import traceback\n        sys.stderr.write(traceback.format_exc())    \n\nif __name__=='__main__':\n    n_particle = 1000\n    nu=0.01\n    xi=0.35\n    pf = ParticleFilter(n_particle, k=1, ydim=1, sys_pdim=1, ob_pdim=1, sh_parameters=[nu, xi])\n    pf.init_praticles_distribution(0, 8) # P, r\n\n    data = np.hstack((norm.rvs(0,1,size=20),norm.rvs(10,1,size=60),norm.rvs(-30,0.5,size=20)))\n\n    for d in data:\n        pf.forward(d)\n    print 'log likelihood:', pf.log_likelihood\n    print 'LSM:', pf.LSM\n\n    rng = range(100)\n    plt.plot(rng,data,label=u\"training data\")\n    plt.plot(rng,pf.predicted_value,label=u\"predicted data\")\n    plt.plot(rng,pf.filtered_value,label=u\"filtered data\")\n#    plt.plot(rng,pf.sys_nois,label=u\"system noise hyper parameter\")\n#    plt.plot(rng,pf.ob_nois,label=u\"observation noise hyper parameter\")\n    plt.xlabel('TIME',fontsize=18)\n    plt.ylabel('Value',fontsize=18)    \n    plt.legend(loc = 'upper left') \n    plt.show()\n\n\n\u5b9f\u9a13\u7d50\u679c\n\u8d85\u3005\u30d1\u30e9\u30e1\u30bf\u306e\u5024\u3068\u7c92\u5b50\u6570\u3092\u5909\u3048\u3066\u4f55\u5ea6\u304b\u5b9f\u9a13\u3057\u3066\u3057\u3066\u307f\u307e\u3057\u305f\u3002\n\u4ee5\u4e0b\u3001\u5b9f\u9a13\u3057\u305f\u56f3\u3092\u63b2\u8f09\u3057\u307e\u3059\u3002\n\n\u7c92\u5b50\u6570100, nu=0.1, xi=0.35\n\n\n\u7c92\u5b50\u65701000, nu=0.1, xi=0.35\n\n\n\u7c92\u5b50\u657010000, nu=0.1, xi=0.35\n\n\n\u7c92\u5b50\u657010000, nu=0.00001, xi=0.00001\n\n\n\u30ce\u30a4\u30ba\u30d1\u30e9\u30e1\u30bf(\u7c92\u5b50\u65701000, nu=0.0008, xi=0.35)\n\n\n\u30b3\u30e1\u30f3\u30c8\n\u7c92\u5b50\u6570\u304c\u5897\u3048\u308b\u306b\u3064\u308c\u3066\u7cbe\u5ea6\u304c\u9ad8\u307e\u3063\u3066\u3044\u308b\u3053\u3068\u304c\u308f\u304b\u308a\u307e\u3059\u3002\n\u307e\u305f\u3001\u5bb9\u91cf\u5236\u9650\u306e\u305f\u3081\u7c92\u5b50\u657010,000\u306e\u56f3\u30922\u70b9\u3057\u304b\u793a\u305b\u306a\u304b\u3063\u305f\u306e\u3067\u3059\u304c\u3001\u7c92\u5b50\u6570\u304c10,000\u3092\u8d85\u3048\u308b\u3068\u8d85\u3005\u30d1\u30e9\u30e1\u30bf\u306e\u5024\u306e\u5f71\u97ff\u304c\u5c11\u306a\u304f\u306a\u308a\u3001\u826f\u3044\u50be\u5411\u304c\u898b\u3089\u308c\u305f\u3068\u601d\u3044\u307e\u3059\u3002\n\u89b3\u6e2c\u30ce\u30a4\u30ba\u30d1\u30e9\u30e1\u30bf\u03c3^2\u03c3^2\u306b\u3064\u3044\u3066\u306f\u3001\u6025\u6fc0\u306b\u5024\u304c\u5909\u5316\u3057\u3066\u3044\u308b\u90e8\u5206\u3067\u5927\u304d\u306a\u5024\u3092\u3068\u3063\u3066\u3044\u307e\u3059\u3002\u3053\u308c\u3092\u898b\u308b\u3068\u81ea\u5df1\u7d44\u7e54\u578b\u30e2\u30c7\u30eb\u306e\u5229\u70b9\u304c\u898b\u3066\u53d6\u308c\u308b\u3068\u601d\u3044\u307e\u3059\u3002\n\n\u307e\u3068\u3081\n\u306a\u3093\u3068\u304b\u307e\u3068\u3082\u306b\u52d5\u304f\u3082\u306e\u304c\u51fa\u6765\u3066\u3088\u304b\u3063\u305f\u3067\u3059\uff57\n\u304a\u624b\u6570\u3067\u3059\u304c\u9593\u9055\u3044\u3042\u308a\u307e\u3057\u305f\u3089\u3001\u3054\u6307\u6458\u3044\u305f\u3060\u3051\u307e\u3059\u3068\u52a9\u304b\u308a\u307e\u3059\u3002\n# \u52d5\u6a5f\n\u524d\u56de\u66f8\u3044\u305f\u30b3\u30fc\u30c9\u304c\u4fee\u6b63\u51fa\u6765\u305f\u306e\u3067\u3001\u4fee\u6b63\u8a18\u4e8b\u3092\u3042\u3052\u3055\u305b\u3066\u3044\u305f\u3060\u304d\u307e\u3057\u305f\u3002\n\u524d\u56de\u306e\u5185\u5bb9\u306f[\u3053\u3061\u3089](http://qiita.com/shima_x/items/f1ba2dc676ce7b59c1ff)\u3092\u5fa1\u89a7\u304f\u3060\u3055\u3044\u3002\n\n# \u53c2\u8003\u6587\u732e\n\u524d\u56de\u3068\u540c\u3058\u3067\u3059\u3002\u5ff5\u306e\u305f\u3081\u63b2\u8f09\u3057\u3066\u304a\u304d\u307e\u3059\u3002\n\n* [\u4e88\u6e2c\u306b\u3044\u304b\u3059\u7d71\u8a08\u30e2\u30c7\u30ea\u30f3\u30b0\u306e\u57fa\u672c\u2015\u30d9\u30a4\u30ba\u7d71\u8a08\u5165\u9580\u304b\u3089\u5fdc\u7528\u307e\u3067](http://www.amazon.co.jp/gp/product/4061557955/ref=as_li_qf_sp_asin_tl?ie=UTF8&camp=247&creative=1211&creativeASIN=4061557955&linkCode=as2&tag=shimashimao06-22)<img src=\"http://ir-jp.amazon-adsystem.com/e/ir?t=shimashimao06-22&l=as2&o=9&a=4061557955\" width=\"1\" height=\"1\" border=\"0\" alt=\"\" style=\"border:none !important; margin:0px !important;\" />\n* [\u6642\u7cfb\u5217\u89e3\u6790\u5165\u9580](http://www.amazon.co.jp/gp/product/4000054554/ref=as_li_tf_tl?ie=UTF8&camp=247&creative=1211&creativeASIN=4000054554&linkCode=as2&tag=shimashimao06-22)<img src=\"http://ir-jp.amazon-adsystem.com/e/ir?t=shimashimao06-22&l=as2&o=9&a=4000054554\" width=\"1\" height=\"1\" border=\"0\" alt=\"\" style=\"border:none !important; margin:0px !important;\" />\n* [\u30d9\u30a4\u30ba\u7d71\u8a08\u30c7\u30fc\u30bf\u89e3\u6790 (R\u3067\u5b66\u3076\u30c7\u30fc\u30bf\u30b5\u30a4\u30a8\u30f3\u30b9 3)](http://www.amazon.co.jp/gp/product/4320019237/ref=as_li_qf_sp_asin_tl?ie=UTF8&camp=247&creative=1211&creativeASIN=4320019237&linkCode=as2&tag=shimashimao06-22)<img src=\"http://ir-jp.amazon-adsystem.com/e/ir?t=shimashimao06-22&l=as2&o=9&a=4320019237\" width=\"1\" height=\"1\" border=\"0\" alt=\"\" style=\"border:none !important; margin:0px !important;\" />\n* [\u77e5\u8b58\u767a\u898b\u3068\u81ea\u5df1\u7d44\u7e54\u578b\u306e\u7d71\u8a08\u30e2\u30c7\u30eb](http://tswww.ism.ac.jp/higuchi/index_e/papers/Bit00.pdf)\n* [\u81ea\u5df1\u7d44\u7e54\u5316\u578b\u72b6\u614b\u7a7a\u9593\u30e2\u30c7\u30eb\u3092\u7528\u3044\u305f\u904b\u52d5\u8ecc\u8de1\u306e\u30d5\u30a3\u30eb\u30bf\u30ea\u30f3\u30b0](https://staff.aist.go.jp/naoyuki.ichimura/research/nng_ssm/papers/sossm_cvim01july.pdf)\n* [\u521d\u671f\u5206\u5e03\u63a2\u7d22\u4ed8\u304d\u81ea\u5df1\u7d44\u7e54\u5316\u72b6\u614b\u7a7a\u9593\u30e2\u30c7\u30eb\u306b\u3088\u308b\u91d1\u878d\u6642\u7cfb\u5217\u89e3\u6790\u306e\u6700\u524d\u7dda\uff1at\u5206\u5e03\u4ed8\u304d\u78ba\u7387\u7684\u30dc\u30e9\u30c6\u30a3\u30ea\u30c6\u30a3\u5909\u52d5\u30e2\u30c7\u30eb\u3078\u306e\u5fdc\u7528](http://www.fsa.go.jp/frtc/nenpou/2006a/05.pdf)\n\n# \u53c2\u8003\u30b3\u30fc\u30c9\n\u6319\u52d5\u4e0d\u5be9\u3060\u3063\u305f\u539f\u56e0\u306f\u3001scipy.stats.cauchy.rvs\u3067size\u3092\u4e0e\u3048\u3066\u306a\u3044\u4e8b\u3067\u3057\u305f\u3002\n\u30d9\u30af\u30c8\u30eb\u306e\u8981\u7d20\u6570\u3092\u4e0e\u3048\u306a\u3044\u3068\u8b66\u544a\u3082\u7121\u3057\u306b\u610f\u5473\u4e0d\u660e\u306a\u5024\u3092\u8fd4\u3057\u3066\u304d\u307e\u3059\u3002\u3002\u3002\n\u3042\u3068\u306f\u3001\u591a\u5c11\u6c4e\u7528\u7684\u306b\u4f7f\u3048\u308b\u3088\u3046\u306b\u4fee\u6b63\u3057\u307e\u3057\u305f\u3002\n\u3068\u3044\u3063\u3066\u3082\u30e2\u30c7\u30eb\u304c\u5909\u308f\u308c\u3070\u3001\n(1)get_system_noise\u3001(2)calc_pred_particles\u3001(3)calc_particles_weight\u306e3\u3064\u306e\u95a2\u6570\u306f\u4fee\u6b63\u3059\u308b\u5fc5\u8981\u304c\u51fa\u3066\u304d\u307e\u3059\u3002\n\u3067\u306f\u3001\u4ee5\u4e0b\u306b\u4fee\u6b63\u3057\u305f\u30b3\u30fc\u30c9\u3092\u8a18\u8f09\u3057\u3066\u3044\u304d\u307e\u3059\u3002\n\n\n```py:\n# coding: utf-8\n\nfrom math import log, pow, sqrt\nimport numpy as np\nfrom scipy.stats import norm, cauchy\nfrom numpy.random import uniform, multivariate_normal\nfrom multiprocessing import Pool\nimport matplotlib.pyplot as plt\n\n\nclass ParticleFilter:    \n    log_likelihood = 0.0 # \u5bfe\u6570\u5c24\u5ea6\n    TIME = 1\n    PR=8 # unmber of processing\n    \n    def __init__(self, PARTICLES_NUM, k=1, ydim=1, sys_pdim=1, ob_pdim=1, sh_parameters=[0.01, 0.35]):\n        self.nois_sh_parameters = sh_parameters # nu:\u30b7\u30b9\u30c6\u30e0\u30ce\u30a4\u30ba\u306e\u4f4d\u7f6e\u8d85\u3005\u30d1\u30e9\u30e1\u30bf , xi:\u89b3\u6e2c\u30ce\u30a4\u30ba\u306e\u4f4d\u7f6e\u8d85\u3005\u30d1\u30e9\u30e1\u30bf\n        pdim = sys_pdim+ob_pdim\n        self.PARTICLES_NUM = PARTICLES_NUM # \u7c92\u5b50\u6570\n        self.TEETH_OF_COMB = np.arange(0, 1, float(1.0)/self.PARTICLES_NUM)\n        self.weights = np.zeros((ydim, self.PARTICLES_NUM), dtype=np.float64)\n        self.particles = np.zeros((k*ydim+pdim ,self.PARTICLES_NUM), dtype=np.float64)\n        self.predicted_particles = np.zeros((k*ydim+pdim , self.PARTICLES_NUM), dtype=np.float64)\n        np.random.seed(555)\n        self.predicted_value = []\n        self.filtered_value = []\n        self.sys_nois = []\n        self.ob_nois = []\n        self.LSM = np.zeros(ydim) # \uff12\u4e57\u8aa4\u5dee\n\n        self.F, self.G, self.H= self.FGHset(k, ydim, pdim)\n        self.k = k\n        self.ydim = ydim\n        self.pdim = pdim\n        self.sys_pdim = sys_pdim\n        self.ob_pdim = ob_pdim\n    \n    def init_praticles_distribution(self, P, r):\n        \"\"\"initialize particles\n        x_0|0\n        tau_0|0\n        sigma_0|0\n        \"\"\"\n        data_particles = multivariate_normal([1]*self.ydim*self.k,\n                            np.eye(self.ydim*self.k)*10, self.PARTICLES_NUM).T\n        param_particles = np.zeros((self.pdim, self.PARTICLES_NUM))\n        for i in xrange(self.pdim):\n            param_particles[i,:] = uniform(P-r, P+r, self.PARTICLES_NUM)\n        self.particles = np.vstack((data_particles, param_particles))\n        \n    def get_system_noise(self):\n        \"\"\"v_t vector\"\"\"\n        data_noise = np.zeros((self.ydim, self.PARTICLES_NUM), dtype=np.float64)\n        for i in xrange(self.ydim):\n            data_noise[i,:] = cauchy.rvs(loc=[0]*self.PARTICLES_NUM, scale=np.power(10,self.particles[self.ydim]),\n                                    size=self.PARTICLES_NUM)\n        data_noise[data_noise==float(\"-inf\")] = -1e308\n        data_noise[data_noise==float(\"inf\")] = 1e308\n        \n        parameter_noises = np.zeros((self.pdim, self.PARTICLES_NUM), dtype=np.float64)\n        for i in xrange(self.pdim):\n            parameter_noises[i,:] = cauchy.rvs(loc=0, scale=self.nois_sh_parameters[i], size=self.PARTICLES_NUM)\n        return np.vstack((data_noise, parameter_noises))\n        \n    def calc_pred_particles(self):\n        \"\"\"calculate system function\n        x_t|t-1 = F*x_t-1 + Gv_t\n        \"\"\"\n        return self.F.dot(self.particles) + self.G.dot(self.get_system_noise()) # linear non-Gaussian  \n        \n    def calc_particles_weight(self,y):\n        \"\"\"calculate fitness probabilities between observation value and predicted value\n        w_t\n        \"\"\"\n        locs = self.calc_pred_particles()\n        self.predicted_particles = locs\n        scale=np.power(10,locs[-1])\n        scale[scale==0] = 1e-308\n        \n        # \u591a\u5909\u91cf\u306e\u5834\u5408\u306a\u3069\u306f\u4fee\u6b63\u304c\u5fc5\u8981\n        self.weights = cauchy.pdf( np.array([y]*self.PARTICLES_NUM) - self.H.dot(locs), loc=[0]*self.PARTICLES_NUM,\n                                scale=scale, size=self.PARTICLES_NUM).flatten()\n    \n    def calc_likelihood(self):\n        \"\"\"calculate likelihood at that point\n        p(y_t|y_1:t-1)\n        \"\"\"\n        res = np.sum(self.weights)/self.PARTICLES_NUM\n        self.log_likelihood += log(res)\n      \n    def normalize_weights(self):\n        \"\"\"wtilda_t\"\"\"\n        self.weights = self.weights/np.sum(self.weights)\n      \n    def resample(self,y):\n        \"\"\"x_t|t\"\"\"\n        self.normalize_weights()\n\n        self.memorize_predicted_value()\n\n        # accumulate weight\n        cum = np.cumsum(self.weights)\n        \n        # create roulette pointer \n        base = uniform(0,float(1.0)/self.PARTICLES_NUM)\n        pointers = self.TEETH_OF_COMB + base\n\n        # select particles\n        selected_idx = [np.where(cum>=p)[0][0] for p in pointers]\n        \"\"\"\n        pool = Pool(processes=self.PR)\n        selected_idx = pool.map(get_slected_particles_idx, ((cum,p) for p in pointers))\n        pool.close()\n        pool.join()     \n        \"\"\"\n\n        self.particles = self.predicted_particles[:,selected_idx]\n        self.memorize_filtered_value(selected_idx, y)\n    \n    def memorize_predicted_value(self):\n        predicted_value = np.sum(self.predicted_particles*self.weights, axis=1)[0]\n        self.predicted_value.append(predicted_value)\n\n    def memorize_filtered_value(self, selected_idx, y):\n        filtered_value = np.sum(self.particles*self.weights[selected_idx] , axis=1) \\\n                            /np.sum(self.weights[selected_idx])\n        self.filtered_value.append(filtered_value[:self.ydim])\n        self.sys_nois.append(np.power(10,filtered_value[self.ydim:self.ydim+self.sys_pdim]))\n        self.ob_nois.append(np.power(10,filtered_value[self.ydim+self.sys_pdim:]))\n        self.calculate_LSM(y,filtered_value[:self.ydim])\n\n    def calculate_LSM(self,y,filterd_value):\n        self.LSM += pow(y-filterd_value,2)\n\n    def forward(self,y):\n        \"\"\"compute system model and observation model\"\"\"\n        print 'calculating time at %d' % self.TIME\n        self.calc_pred_particles()\n        self.calc_particles_weight(y)\n        self.calc_likelihood()\n        self.resample(y)\n        self.TIME += 1\n\n    def FGHset(self, k, vn_y, n_h_parameters):\n        \"\"\"\u72b6\u614b\u7a7a\u9593\u8868\u73fe\u306e\u884c\u5217\u8a2d\u5b9a\n        vn_y:\u5165\u529b\u30d9\u30af\u30c8\u30eb\u306e\u6b21\u5143\n        n_h_parameters:\u30cf\u30a4\u30d1\u30fc\u30d1\u30e9\u30e1\u30bf\u6570\n        k\uff1a\u968e\u5dee\n        \"\"\"\n        G_upper_block = np.zeros((k*vn_y, vn_y+n_h_parameters))\n        G_lower_block = np.zeros((n_h_parameters, vn_y+n_h_parameters))\n        G_lower_block[-n_h_parameters:, -n_h_parameters:] = np.eye(n_h_parameters)\n        G_upper_block[:vn_y, :vn_y] = np.eye(vn_y)\n        G = np.vstack( (G_upper_block, G_lower_block) )\n        \n        H = np.hstack( (np.eye(vn_y), \n                            np.zeros((vn_y, vn_y*(k-1)+n_h_parameters))\n                        ) )\n              \n        # \u30c8\u30ec\u30f3\u30c9\u30e2\u30c7\u30eb\u306e\u30d6\u30ed\u30c3\u30af\u884c\u5217\u306e\u69cb\u7bc9\n        F_upper_block = np.zeros((k*vn_y, k*vn_y+n_h_parameters))\n        F_lower_block = np.zeros((n_h_parameters, k*vn_y+n_h_parameters))\n        F_lower_block[-n_h_parameters:, -n_h_parameters:] = np.eye(n_h_parameters)\n        if k==1:\n            F_upper_block[:vn_y, :vn_y] = np.eye(vn_y)\n        elif k==2:\n            F_upper_block[:vn_y, :vn_y] = np.eye(vn_y)*2\n            F_upper_block[:vn_y, vn_y:k*vn_y] = np.eye(vn_y)*-1\n            F_upper_block[vn_y:k*vn_y, :vn_y] = np.eye(vn_y)\n        F = np.vstack((F_upper_block, F_lower_block))\n              \n        return F, G, H\n\ndef get_slected_particles_idx((cum,p)):\n    \"\"\"multiprocessing function\"\"\"\n    try:\n        return np.where(cum>=p)[0][0]\n    except Exception, e:\n        import sys\n        import traceback\n        sys.stderr.write(traceback.format_exc())    \n\nif __name__=='__main__':\n    n_particle = 1000\n    nu=0.01\n    xi=0.35\n    pf = ParticleFilter(n_particle, k=1, ydim=1, sys_pdim=1, ob_pdim=1, sh_parameters=[nu, xi])\n    pf.init_praticles_distribution(0, 8) # P, r\n    \n    data = np.hstack((norm.rvs(0,1,size=20),norm.rvs(10,1,size=60),norm.rvs(-30,0.5,size=20)))\n    \n    for d in data:\n        pf.forward(d)\n    print 'log likelihood:', pf.log_likelihood\n    print 'LSM:', pf.LSM\n    \n    rng = range(100)\n    plt.plot(rng,data,label=u\"training data\")\n    plt.plot(rng,pf.predicted_value,label=u\"predicted data\")\n    plt.plot(rng,pf.filtered_value,label=u\"filtered data\")\n#    plt.plot(rng,pf.sys_nois,label=u\"system noise hyper parameter\")\n#    plt.plot(rng,pf.ob_nois,label=u\"observation noise hyper parameter\")\n    plt.xlabel('TIME',fontsize=18)\n    plt.ylabel('Value',fontsize=18)    \n    plt.legend(loc = 'upper left') \n    plt.show()\n```\n\n# \u5b9f\u9a13\u7d50\u679c\n\u8d85\u3005\u30d1\u30e9\u30e1\u30bf\u306e\u5024\u3068\u7c92\u5b50\u6570\u3092\u5909\u3048\u3066\u4f55\u5ea6\u304b\u5b9f\u9a13\u3057\u3066\u3057\u3066\u307f\u307e\u3057\u305f\u3002\n\u4ee5\u4e0b\u3001\u5b9f\u9a13\u3057\u305f\u56f3\u3092\u63b2\u8f09\u3057\u307e\u3059\u3002\n\n## \u7c92\u5b50\u6570100, nu=0.1, xi=0.35\n![0.35_0.1_100.png](https://qiita-image-store.s3.amazonaws.com/0/12767/a0de85d7-999b-d7b3-3ac6-42458b2d43c1.png)\n\n## \u7c92\u5b50\u65701000, nu=0.1, xi=0.35\n![0.35_0.1_1000.png](https://qiita-image-store.s3.amazonaws.com/0/12767/a57518c0-baba-f3b4-b96f-ba8443ddb208.png)\n\n## \u7c92\u5b50\u657010000, nu=0.1, xi=0.35\n![0.35_0.1_10000.png](https://qiita-image-store.s3.amazonaws.com/0/12767/904a05cf-5062-1f1f-e89c-ceb90968e4ba.png)\n\n## \u7c92\u5b50\u657010000, nu=0.00001, xi=0.00001\n![0.00001_0.00001_10000.png](https://qiita-image-store.s3.amazonaws.com/0/12767/57c0600f-04ce-8c87-f141-0e922eca5e4b.png)\n\n## \u30ce\u30a4\u30ba\u30d1\u30e9\u30e1\u30bf(\u7c92\u5b50\u65701000, nu=0.0008, xi=0.35)\n![noise.png](https://qiita-image-store.s3.amazonaws.com/0/12767/991d0ed8-0331-32eb-dd70-a939717bd60f.png)\n\n## \u30b3\u30e1\u30f3\u30c8\n\u7c92\u5b50\u6570\u304c\u5897\u3048\u308b\u306b\u3064\u308c\u3066\u7cbe\u5ea6\u304c\u9ad8\u307e\u3063\u3066\u3044\u308b\u3053\u3068\u304c\u308f\u304b\u308a\u307e\u3059\u3002\n\u307e\u305f\u3001\u5bb9\u91cf\u5236\u9650\u306e\u305f\u3081\u7c92\u5b50\u657010,000\u306e\u56f3\u30922\u70b9\u3057\u304b\u793a\u305b\u306a\u304b\u3063\u305f\u306e\u3067\u3059\u304c\u3001\u7c92\u5b50\u6570\u304c10,000\u3092\u8d85\u3048\u308b\u3068\u8d85\u3005\u30d1\u30e9\u30e1\u30bf\u306e\u5024\u306e\u5f71\u97ff\u304c\u5c11\u306a\u304f\u306a\u308a\u3001\u826f\u3044\u50be\u5411\u304c\u898b\u3089\u308c\u305f\u3068\u601d\u3044\u307e\u3059\u3002\n\u89b3\u6e2c\u30ce\u30a4\u30ba\u30d1\u30e9\u30e1\u30bf$\u03c3^2$\u306b\u3064\u3044\u3066\u306f\u3001\u6025\u6fc0\u306b\u5024\u304c\u5909\u5316\u3057\u3066\u3044\u308b\u90e8\u5206\u3067\u5927\u304d\u306a\u5024\u3092\u3068\u3063\u3066\u3044\u307e\u3059\u3002\u3053\u308c\u3092\u898b\u308b\u3068\u81ea\u5df1\u7d44\u7e54\u578b\u30e2\u30c7\u30eb\u306e\u5229\u70b9\u304c\u898b\u3066\u53d6\u308c\u308b\u3068\u601d\u3044\u307e\u3059\u3002\n\n# \u307e\u3068\u3081\n\u306a\u3093\u3068\u304b\u307e\u3068\u3082\u306b\u52d5\u304f\u3082\u306e\u304c\u51fa\u6765\u3066\u3088\u304b\u3063\u305f\u3067\u3059\uff57\n\n\u304a\u624b\u6570\u3067\u3059\u304c\u9593\u9055\u3044\u3042\u308a\u307e\u3057\u305f\u3089\u3001\u3054\u6307\u6458\u3044\u305f\u3060\u3051\u307e\u3059\u3068\u52a9\u304b\u308a\u307e\u3059\u3002\n", "tags": ["Python2.7", "\u6a5f\u68b0\u5b66\u7fd2", "\u6642\u7cfb\u5217\u89e3\u6790"]}