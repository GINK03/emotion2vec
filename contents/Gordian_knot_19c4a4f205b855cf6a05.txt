{"tags": ["PRML", "\u6a5f\u68b0\u5b66\u7fd2", "Python", "\u30cb\u30e5\u30fc\u30e9\u30eb\u30cd\u30c3\u30c8\u30ef\u30fc\u30af"], "context": "\u524d\u56de\u306f\u666e\u901a\u306e\u30cb\u30e5\u30fc\u30e9\u30eb\u30cd\u30c3\u30c8\u30ef\u30fc\u30af\u3092tensorflow\u3084chainer\u306a\u3069\u306e\u30e9\u30a4\u30d6\u30e9\u30ea\u3092\u4f7f\u308f\u305a\u306b\u5b9f\u88c5\u3057\u307e\u3057\u305f\u3002\u305f\u3060\u3001\u305d\u306e\u985e\u306e\u5b9f\u88c5\u306f\u30cd\u30c3\u30c8\u4e0a\u306b\u3059\u3067\u306b\u305f\u304f\u3055\u3093\u3042\u308a\u3001\u305d\u308c\u3067\u306f\u3042\u307e\u308a\u9762\u767d\u307f\u304c\u3042\u308a\u307e\u305b\u3093\u306e\u3067\u3001\u524d\u56de\u306e\u306f\u3042\u304f\u307e\u3067\u6e96\u5099\u3068\u3057\u3066\u4eca\u56de\u306f\u6df7\u5408\u5bc6\u5ea6\u30cd\u30c3\u30c8\u30ef\u30fc\u30af\u3092\u5b9f\u88c5\u3057\u307e\u3057\u305f\u3002\u524d\u56de\u5b9f\u88c5\u3057\u305f\u30cb\u30e5\u30fc\u30e9\u30eb\u30cd\u30c3\u30c8\u30ef\u30fc\u30af\u306e\u30b3\u30fc\u30c9\u3092\u5229\u7528\u3059\u308b\u306e\u3067\u3001\u524d\u56de\u306e\u8a18\u4e8b\u3082\u9069\u5b9c\u53c2\u8003\u306b\u3057\u3066\u307f\u3066\u4e0b\u3055\u3044\u3002\n\n\u6df7\u5408\u5bc6\u5ea6\u30cd\u30c3\u30c8\u30ef\u30fc\u30af\n\n\u5f93\u6765\u30e2\u30c7\u30eb\u306e\u554f\u984c\u70b9\n\u56de\u5e30\u554f\u984c\u3092\u89e3\u304f\u3068\u304d\u306b\u3001\u4e8c\u4e57\u548c\u8aa4\u5dee\u95a2\u6570\u3092\u4f7f\u3063\u3066\u3044\u305f\u306e\u3067\u306f\u3046\u307e\u304f\u5bfe\u51e6\u3067\u304d\u306a\u3044\u5834\u5408\u304c\u3042\u308a\u307e\u3059\u3002\u4e0b\u306e\u56f3\uff08PRML\u56f35.19\u306e\u518d\u73fe\uff09\u306f\u3001\u9752\u70b9\u3092\u30c8\u30ec\u30fc\u30cb\u30f3\u30b0\u30c7\u30fc\u30bf\u3068\u3057\u3066\u3001\u4e8c\u4e57\u548c\u8aa4\u5dee\u95a2\u6570\u3092\u7528\u3044\u3066\u30cb\u30e5\u30fc\u30e9\u30eb\u30cd\u30c3\u30c8\u30ef\u30fc\u30af\u3092\u5b66\u7fd2\u3055\u305b\u305f\u3068\u304d\u306e\u7d50\u679c\u3092\u8868\u3057\u3066\u3044\u307e\u3059\u3002\n\nx=0.5x=0.5x=0.5\u306e\u3068\u304d\u306fyy\u306e\u5024\u304c0.2\u30010.5\u30010.8\u306e\u3069\u308c\u3067\u3082\u3088\u3055\u305d\u3046\u3067\u3059\u3002\u3057\u304b\u3057\u3001\u305d\u306e\u4e2d\u3067\u4e00\u3064\u3092\u9078\u3070\u306a\u3044\u3068\u3044\u3051\u306a\u3044\u306e\u30670.5\u306b\u306a\u308a\u3001\u4ed6\u306e\uff12\u3064\u306b\u30d5\u30a3\u30c3\u30c6\u30a3\u30f3\u30b0\u3057\u307e\u305b\u3093\u3002\u30cb\u30e5\u30fc\u30e9\u30eb\u30cd\u30c3\u30c8\u30ef\u30fc\u30af\u3092\u5b66\u7fd2\u3055\u305b\u305f\u306e\u306b\u3042\u307e\u308a\u30d5\u30a3\u30c3\u30c6\u30a3\u30f3\u30b0\u3067\u304d\u3066\u3044\u306a\u3044\u306e\u306f\u3001\u30b3\u30b9\u30c8\u95a2\u6570\u304c\u5358\u5cf0\u6027\u306e\u30ac\u30a6\u30b9\u5206\u5e03\u3067\u30e2\u30c7\u30eb\u3055\u308c\u3066\u3044\u308b\u304b\u3089\u3067\u3059\u3002\u5165\u529bxx\u3068\u30bf\u30fc\u30b2\u30c3\u30c8tt\u306e\u95a2\u4fc2\u3092\u3001\u30ac\u30a6\u30b9\u5206\u5e03\u3067\u4ee5\u4e0b\u306e\u3088\u3046\u306b\u8868\u3057\u3001\np(t|x) = \\mathcal{N}(t|\\mu(x),\\sigma^2),\np(t|x)=N(t|\u03bc(x),\u03c32),{p(t|x) = \\mathcal{N}(t|\\mu(x),\\sigma^2),\n}\n\u3053\u308c\u306b\u57fa\u3065\u3044\u3066\u30d5\u30a3\u30c3\u30c6\u30a3\u30f3\u30b0\u3001\u95a2\u6570\u03bc(x)\\mu(x)\u306e\u63a8\u5b9a\u3001\u3092\u884c\u3063\u3066\u3044\u307e\u3057\u305f\u3002\u305d\u3057\u3066\u3001\u63a8\u5b9a\u3057\u305f\u03bc(x)\\mu(x)\u304c\u4e0a\u306e\u56f3\u306e\u8d64\u8272\u3068\u306a\u3063\u3066\u3044\u3066\u3001\u30c0\u30e1\u30c0\u30e1\u306a\u7d50\u679c\u3068\u306a\u3063\u3066\u3057\u307e\u3044\u307e\u3057\u305f\u3002\n\n\u6df7\u5408\u30ac\u30a6\u30b9\u5206\u5e03\n\u6df7\u5408\u5bc6\u5ea6\u30cd\u30c3\u30c8\u30ef\u30fc\u30af\u3067\u306f\u30b3\u30b9\u30c8\u95a2\u6570\u306b\u591a\u5cf0\u6027\u306e\u6df7\u5408\u30ac\u30a6\u30b9\u5206\u5e03\u3067\u30e2\u30c7\u30eb\u3055\u308c\u305f\u3082\u306e\u3092\u7528\u3044\u308b\u3053\u3068\u3067\u3001\u4e0a\u306e\u554f\u984c\u3092\u89e3\u6c7a\u3057\u307e\u3059\u3002K\u500b\u306e\u30ac\u30a6\u30b9\u5206\u5e03\u306b\u4e00\u3064\u4e00\u3064\u6df7\u5408\u4fc2\u6570\u03c0k\\pi_k\u3092\u7528\u610f\u3057\u3066\u3001\u5165\u529bxx\u3068\u30bf\u30fc\u30b2\u30c3\u30c8tt\u306e\u95a2\u4fc2\u3092\np(t|x) = \\sum_{k=1}^K\\pi_k(x)\\mathcal{N}(t|\\mu_k(x),\\sigma^2_k(x))\np(t|x)=K\u2211k=1\u03c0k(x)N(t|\u03bck(x),\u03c32k(x)){p(t|x) = \\sum_{k=1}^K\\pi_k(x)\\mathcal{N}(t|\\mu_k(x),\\sigma^2_k(x))\n}\n\u3068\u30e2\u30c7\u30eb\u3057\u307e\u3059\u3002\u305f\u3060\u3057\u3001\u6df7\u5408\u4fc2\u6570\u306e\u548c\u306f1\u3068\u3057\u307e\u3059(\u2211k\u03c0k=1\\sum_k\\pi_k=1)\u3002\u4e0a\u306e\u30c8\u30ec\u30fc\u30cb\u30f3\u30b0\u30c7\u30fc\u30bf\u306e\u4f8b\u3060\u3068\u3001x=0.5x=0.5\u3067\u306fy=0.2,0.5,0.8y=0.2,0.5,0.8\u306e\u3042\u305f\u308a\u306b\uff13\u3064\u306e\u30c7\u30fc\u30bf\u70b9\u306e\u96c6\u5408\u304c\u3042\u308a\u307e\u3059\u3002\u3088\u3063\u3066\u3001K=3K=3\u3068\u3059\u308b\u306e\u304c\u826f\u3055\u305d\u3046\u3067\u3059\u30023\u500b\u306e\u30ac\u30a6\u30b9\u5206\u5e03\u304c\u305d\u308c\u305e\u308c\u5225\u306e\u30c7\u30fc\u30bf\u70b9\u306e\u96c6\u5408\u306b\u30d5\u30a3\u30c3\u30c6\u30a3\u30f3\u30b0\u3055\u308c\u308b\u3053\u3068\u3067\u3001\u591a\u5cf0\u6027\u306e\u3042\u308b\u30c7\u30fc\u30bf\u3067\u3082\u5bfe\u51e6\u3067\u304d\u307e\u3059\u3002\n\u3088\u3063\u3066\u3001\u30c8\u30ec\u30fc\u30cb\u30f3\u30b0\u30c7\u30fc\u30bf\u306e\u7d44{xn,tn}Nn=1\\{x_n,t_n\\}_{n=1}^N\u304c\u4e0e\u3048\u3089\u308c\u3066\u3044\u308b\u3068\u304d\u3001\u6700\u9069\u5316\u3059\u308b\u30b3\u30b9\u30c8\u95a2\u6570\u306f\n\\begin{align}\nE(w) &= \\sum_{n=1}^N E_n\\\\\n&= -\\sum_{n=1}^N \\ln p(t_n|x_n)\\\\\n&= -\\sum_{n=1}^N \\ln \\left\\{\\sum_{k=1}^K\\pi_k(x_n,w)\\mathcal{N}\\left(t_n|\\mu_k(x_n,w),\\sigma^2_k(x_n,w)\\right)\\right\\}\n\\end{align}\nE(w)=N\u2211n=1En=\u2212N\u2211n=1lnp(tn|xn)=\u2212N\u2211n=1ln{K\u2211k=1\u03c0k(xn,w)N(tn|\u03bck(xn,w),\u03c32k(xn,w))}{\\begin{align}\nE(w) &= \\sum_{n=1}^N E_n\\\\\n&= -\\sum_{n=1}^N \\ln p(t_n|x_n)\\\\\n&= -\\sum_{n=1}^N \\ln \\left\\{\\sum_{k=1}^K\\pi_k(x_n,w)\\mathcal{N}\\left(t_n|\\mu_k(x_n,w),\\sigma^2_k(x_n,w)\\right)\\right\\}\n\\end{align}\n}\n\u3068\u306a\u308a\u307e\u3059\u3002\u305d\u3057\u3066\u3001\u4e0a\u306e\u5f0f\u3092\u6700\u5c0f\u5316\u3059\u308b\u3088\u3046\u306a\u30d1\u30e9\u30e1\u30fc\u30bfww\u3092\u63a8\u5b9a\u3057\u307e\u3059\u3002\u95a2\u6570\u03c0k,\u03bck,\u03c3k\\pi_k,\\mu_k,\\sigma_k\u306b\u306f\u30cb\u30e5\u30fc\u30e9\u30eb\u30cd\u30c3\u30c8\u30ef\u30fc\u30af\u3092\u4f7f\u3044\u307e\u3059\u3002\u30d1\u30e9\u30e1\u30fc\u30bfww\u306e\u30cd\u30c3\u30c8\u30ef\u30fc\u30af\u306b\u5165\u529bxx\u3092\u5165\u308c\u308b\u3068\u3001\u6df7\u5408\u4fc2\u6570\u3001\u5e73\u5747\u3001\u5206\u6563\u304c\u51fa\u529b\u3055\u308c\u3001tt\u306e\u78ba\u7387\u5206\u5e03\u304c\u7b97\u51fa\u3055\u308c\u307e\u3059\u3002\n\n\u30cd\u30c3\u30c8\u30ef\u30fc\u30af\u69cb\u9020\n\u4eca\u56de\u306f\u4e0a\u306e\u56f3\u306e\u3088\u3046\u306a\u30c7\u30fc\u30bf\u306b\u5bfe\u3057\u3066\u56de\u5e30\u3092\u884c\u3046\u306e\u3067\u3001\u5165\u529bx{\\bf x}\u306f\uff11\u6b21\u5143\u3068\u306a\u308a\u307e\u3059\u3002\u4e2d\u9593z{\\bf z}\u306e\u30ce\u30fc\u30c9\u306e\u6570\u306fPRML\u306b\u306a\u3089\u3063\u30665\u3064\u3001\u51fa\u529by{\\bf y}\u306e\u30ce\u30fc\u30c9\u6570\u306f\uff19\u3064\u3068\u3057\u307e\u3059\u3002\u7b2c\u4e00\u5c64\u306e\u30d1\u30e9\u30e1\u30fc\u30bf\u3092W(1),b(1)W^{(1)},{\\bf b}^{(1)}\u3001\u6d3b\u6027\u5316\u95a2\u6570\u3092f(\u22c5)f(\\cdot)\u3001\u7b2c\u4e8c\u5c64\u306e\u30d1\u30e9\u30e1\u30fc\u30bf\u3092W(2),b(2)W^{(2)},{\\bf b}^{(2)}\u3068\u3057\u3066\u3001\u9806\u4f1d\u64ad\u306f\u6b21\u306e\u3088\u3046\u306b\u306a\u308a\u307e\u3059\u3002\n\\begin{align}\n{\\bf z} &= f(W^{(1)}{\\bf x} + {\\bf b}^{(1)})\\\\\n{\\bf y} &= W^{(2)}{\\bf z} + {\\bf b}^{(2)}\n\\end{align}\nz=f(W(1)x+b(1))y=W(2)z+b(2){\\begin{align}\n{\\bf z} &= f(W^{(1)}{\\bf x} + {\\bf b}^{(1)})\\\\\n{\\bf y} &= W^{(2)}{\\bf z} + {\\bf b}^{(2)}\n\\end{align}\n}\n\u3053\u306e\u51fa\u529b9\u3064\u306f\u6df7\u5408\u30ac\u30a6\u30b9\u5206\u5e03\u306e\u30d1\u30e9\u30e1\u30fc\u30bf\u03c0k,\u03bck,\u03c3k\\pi_k,\\mu_k,\\sigma_k\u306e\u6d3b\u6027\u3067\u3059\u3002\n\u307e\u305a\u3001\u51fa\u529by{\\bf y}\u306f\u4e0a\u304b\u3089\uff13\u3064\u305a\u3064\u03c0,\u03bc,\u03c3\\pi,\\mu,\\sigma\u306b\u5bfe\u5fdc\u3057\u3066\u3044\u308b\u6d3b\u6027\u3068\u3057\u307e\u3059\u3002\n{\\bf y} =\n\\begin{bmatrix}\na_{\\pi_1}\\\\\na_{\\pi_2}\\\\\na_{\\pi_3}\\\\\na_{\\mu_1}\\\\\na_{\\mu_2}\\\\\na_{\\mu_3}\\\\\na_{\\sigma_1}\\\\\na_{\\sigma_2}\\\\\na_{\\sigma_3}\n\\end{bmatrix}\ny=[a\u03c01a\u03c02a\u03c03a\u03bc1a\u03bc2a\u03bc3a\u03c31a\u03c32a\u03c33]{{\\bf y} =\n\\begin{bmatrix}\na_{\\pi_1}\\\\\na_{\\pi_2}\\\\\na_{\\pi_3}\\\\\na_{\\mu_1}\\\\\na_{\\mu_2}\\\\\na_{\\mu_3}\\\\\na_{\\sigma_1}\\\\\na_{\\sigma_2}\\\\\na_{\\sigma_3}\n\\end{bmatrix}\n}\n\u6df7\u5408\u4fc2\u6570\u03c0k\\pi_k\u306f\u2211k\u03c0k=1\\sum_k\\pi_k=1\u3068\u3044\u3046\u5236\u7d04\u6761\u4ef6\u304c\u3042\u308b\u306e\u3067\u3001\u30bd\u30d5\u30c8\u30de\u30c3\u30af\u30b9\u95a2\u6570\u306b\u3088\u308a\u6df7\u5408\u4fc2\u6570\u3092\u51fa\u529b\u3057\u307e\u3059\u3002\n\\pi_k = {\\exp(a_{\\pi_k})\\over\\sum_{l=1}^K\\exp(a_{\\pi_l})}\n\u03c0k=exp(a\u03c0k)\u2211Kl=1exp(a\u03c0l){\\pi_k = {\\exp(a_{\\pi_k})\\over\\sum_{l=1}^K\\exp(a_{\\pi_l})}\n}\n\u5e73\u5747\u306f\u975e\u7dda\u5f62\u5909\u63db\u3092\u7528\u3044\u305a\u306b\u03bck=a\u03bck\\mu_k = a_{\\mu_k}\u3068\u3057\u307e\u3059\u3002\n\u6a19\u6e96\u504f\u5dee\u03c3\\sigma\u306f\uff10\u4ee5\u4e0a\u306a\u306e\u3067\u6307\u6570\u95a2\u6570\u3092\u4f7f\u3063\u3066\u03c3k=exp(a\u03c3k)\\sigma_k = \\exp(a_{\\sigma_k})\u3002\n\u3053\u308c\u3067\u3001\u6df7\u5408\u30ac\u30a6\u30b9\u5206\u5e03\u3092\u8a08\u7b97\u3059\u308b\u306e\u306b\u5fc5\u8981\u306a\u95a2\u6570\u03c0k,\u03bck,\u03c3k\\pi_k,\\mu_k,\\sigma_k\u304c\u6c42\u307e\u308a\u307e\u3057\u305f\u3002\n\n\u52fe\u914d\n\u524d\u56de\u306e\u30cb\u30e5\u30fc\u30e9\u30eb\u30cd\u30c3\u30c8\u30ef\u30fc\u30af\u306e\u5b9f\u88c5\u3067\u66f8\u3044\u305f\u3088\u3046\u306b\u30cb\u30e5\u30fc\u30e9\u30eb\u30cd\u30c3\u30c8\u30ef\u30fc\u30af\u3092\u5b66\u7fd2\u3055\u305b\u308b\u306e\u306b\u306f\u30b3\u30b9\u30c8\u95a2\u6570\u3092\u30cb\u30e5\u30fc\u30e9\u30eb\u30cd\u30c3\u30c8\u30ef\u30fc\u30af\u306e\u51fa\u529b\u3067\u5fae\u5206\u3057\u305f\u52fe\u914d\u304c\u5fc5\u8981\u3067\u3059\u3002\u305d\u308c\u304c\u3042\u308c\u3070\u3001\u3042\u3068\u306f\u8aa4\u5dee\u9006\u4f1d\u64ad\u3092\u4f7f\u3063\u3066\u30b3\u30b9\u30c8\u95a2\u6570\u306e\u30d1\u30e9\u30e1\u30fc\u30bfww\u306b\u3064\u3044\u3066\u306e\u5fae\u5206\u3082\u8a08\u7b97\u3067\u304d\u307e\u3059\u3002\n\u305d\u306e\u30b3\u30b9\u30c8\u95a2\u6570\u306e\u30cb\u30e5\u30fc\u30e9\u30eb\u30cd\u30c3\u30c8\u30ef\u30fc\u30af\u306e\u51fa\u529b\u3067\u306e\u52fe\u914d\u306f\u3001\n\\gamma_{nk}(t_n|x_n) = {\\pi_k\\mathcal{N}(t_n|\\mu_k(x_n,w),\\sigma_k^2(x_n,w))\\over\\sum_l\\pi_l\\mathcal{N}(t_n|\\mu_l(x_n,w),\\sigma_l^2(x_n,w))}\n\u03b3nk(tn|xn)=\u03c0kN(tn|\u03bck(xn,w),\u03c32k(xn,w))\u2211l\u03c0lN(tn|\u03bcl(xn,w),\u03c32l(xn,w)){\\gamma_{nk}(t_n|x_n) = {\\pi_k\\mathcal{N}(t_n|\\mu_k(x_n,w),\\sigma_k^2(x_n,w))\\over\\sum_l\\pi_l\\mathcal{N}(t_n|\\mu_l(x_n,w),\\sigma_l^2(x_n,w))}\n}\n\u3092\u7528\u3044\u3066\u3001\n\\begin{align}\n{\\partial E_n\\over\\partial a_{\\pi_k}} &= \\pi_k - \\gamma_{nk}\\\\\n{\\partial E_n\\over\\partial a_{\\mu_k}} &= \\gamma_{nk}{\\mu_k - t_n\\over\\sigma^2_k}\\\\\n{\\partial E_n\\over\\partial a_{\\sigma_k}} &= \\gamma_{nk}\\left(1 - {||t_n - \\mu_k||^2\\over \\sigma^2_k}\\right)\n\\end{align}\n\u2202En\u2202a\u03c0k=\u03c0k\u2212\u03b3nk\u2202En\u2202a\u03bck=\u03b3nk\u03bck\u2212tn\u03c32k\u2202En\u2202a\u03c3k=\u03b3nk(1\u2212||tn\u2212\u03bck||2\u03c32k){\\begin{align}\n{\\partial E_n\\over\\partial a_{\\pi_k}} &= \\pi_k - \\gamma_{nk}\\\\\n{\\partial E_n\\over\\partial a_{\\mu_k}} &= \\gamma_{nk}{\\mu_k - t_n\\over\\sigma^2_k}\\\\\n{\\partial E_n\\over\\partial a_{\\sigma_k}} &= \\gamma_{nk}\\left(1 - {||t_n - \\mu_k||^2\\over \\sigma^2_k}\\right)\n\\end{align}\n}\n\u3068\u306a\u308a\u307e\u3059\u3002\u5f0f\u306e\u5c0e\u51fa\u306fPRML\u3067\u306f\u6f14\u7fd2\u554f\u984c\u306b\u306a\u3063\u3066\u3044\u308b\u306e\u3067\u305d\u306e\u56de\u7b54\u3001\u3082\u3057\u304f\u306f\u6df7\u5408\u5bc6\u5ea6\u30cd\u30c3\u30c8\u30ef\u30fc\u30af\u306e\u8ad6\u6587\u3092\u53c2\u7167\u3057\u3066\u304f\u3060\u3055\u3044\u3002\n\n\u5b9f\u88c5\n\n\u30b3\u30b9\u30c8\u95a2\u6570\n\u4e0a\u3067\u66f8\u3044\u305f\u6570\u5f0f\u3092\u30b3\u30fc\u30c9\u306b\u3059\u308b\u3068\u3001\u6b21\u306e\u3088\u3046\u306b\u306a\u308a\u307e\u3059\u3002\n# \u30b3\u30b9\u30c8\u95a2\u6570\u306e\u30af\u30e9\u30b9\nclass GaussianMixture(object):\n    \"\"\"Negative Log Likelihood of Gaussian Mixture model\"\"\"\n    def __init__(self, n_components):\n        # \u30ac\u30a6\u30b9\u5206\u5e03\u306e\u500b\u6570\u3001\u4eca\u307e\u3067\u306e\u4f8b\u3060\u30683\n        self.n_components = n_components\n\n    # \u30b3\u30b9\u30c8\u95a2\u6570\u306e\u5024\u3092\u8a08\u7b97\u3059\u308b\u30e1\u30bd\u30c3\u30c9\n    def __call__(self, X, targets):\n\n        # \u30cd\u30c3\u30c8\u30ef\u30fc\u30af\u306e\u51fa\u529bX\u3092\u6d3b\u6027\u5316\u95a2\u6570\u3067\u5909\u63db\u3057\u3066\u3001\u6a19\u6e96\u504f\u5dee\u3001\u6df7\u5408\u4fc2\u6570\u3001\u5e73\u5747\u3092\u8a08\u7b97\n        sigma, weight, mu = self.activate(X)\n\n        # \u30ac\u30a6\u30b9\u95a2\u6570N(t|mu,sigma^2)\u306e\u5024\u3092\u8a08\u7b97\n        gauss = self.gauss(mu, sigma, targets)\n\n        # \u6df7\u5408\u30ac\u30a6\u30b9\u5206\u5e03\u306e\u8ca0\u306e\u5bfe\u6570\u5c24\u5ea6E(w):PRML(\u5f0f5.153)\n        return -np.sum(np.log(np.sum(weight * gauss, axis=1)))\n\n    # \u6d3b\u6027\u5316\u95a2\u6570\u3067\u5909\u63db\n    def activate(self, X):\n        assert np.size(X, 1) == 3 * self.n_components\n\n        # X\u3092\u6a19\u6e96\u504f\u5dee\u3001\u6df7\u5408\u4fc2\u6570\u3001\u5e73\u5747\u306b\u5bfe\u5fdc\u3059\u308b\u3068\u3053\u308d\u306b\u5206\u5272\n        X_sigma, X_weight, X_mu = np.split(X, [self.n_components, 2 * self.n_components], axis=1)\n\n        # \u6a19\u6e96\u504f\u5dee\u3092\u6d3b\u6027\u5316\u95a2\u6570\u3067\u5909\u63db\n        sigma = np.exp(X_sigma)\n\n        # \u6df7\u5408\u4fc2\u6570\u3092\u6d3b\u6027\u5316\u95a2\u6570\u3067\u5909\u63db\u3001\u6841\u304c\u3042\u3075\u308c\u306a\u3044\u3088\u3046\u306b\u6700\u5927\u5024\u3067\u5f15\u304f\n        weight = np.exp(X_weight - np.max(X_weight, 1, keepdims=True))\n        weight /= np.sum(weight, axis=1, keepdims=True)\n\n        return sigma, weight, X_mu\n\n    # \u30ac\u30a6\u30b9\u95a2\u6570N(target|mu,sigma^2)\u3092\u8a08\u7b97\n    def gauss(self, mu, sigma, targets):\n        return np.exp(-0.5 * (mu - targets) ** 2 / np.square(sigma)) / np.sqrt(2 * np.pi * np.square(sigma))\n\n    # \u30b3\u30b9\u30c8\u95a2\u6570\u3092\u6d3b\u6027\u3067\u5fae\u5206\n    def delta(self, X, targets):\n        sigma, weight, mu = self.activate(X)\n        var = np.square(sigma)\n        gamma = weight * self.gauss(mu, sigma, targets)\n        gamma /= np.sum(gamma, axis=1, keepdims=True)\n\n        # \u305d\u308c\u305e\u308c\u306e\u5fae\u5206\u3092\u8a08\u7b97\n        delta_mu = gamma * (mu - targets) / var\n        delta_sigma = gamma * (1 - (mu - targets) ** 2 / var)\n        delta_weight = weight - gamma\n\n        # \u9023\u7d50\u3055\u305b\u3066\u304b\u3089\u8fd4\u3059\n        delta = np.hstack([delta_sigma, delta_weight, delta_mu])\n        return delta\n\n\n\u5b66\u7fd2\u30c7\u30fc\u30bf\u306e\u4f5c\u6210\n# \u95a2\u6570func\u306e\u9006\u95a2\u6570\u306b\u5f93\u3046\u3088\u3046\u306a\u5b66\u7fd2\u30c7\u30fc\u30bf\u3092\u4f5c\u6210\u3059\u308b\ndef create_toy_dataset(func, n=300):\n    t = np.random.uniform(size=(n, 1))\n    x = func(t) + np.random.uniform(-0.05, 0.05, size=(n, 1))\n    return x, t\n\n\n\u30df\u30cb\u30d0\u30c3\u30c1\u51e6\u7406\n\u5b66\u7fd2\u304c\u3046\u307e\u304f\u3044\u304b\u306a\u3044\u3053\u3068\u304c\u3042\u3063\u305f\u306e\u3067\u6025\u907d\u4f7f\u7528\u3057\u305f\u624b\u6cd5\u306e\u4e00\u3064\u3002\n\u5b66\u7fd2\u30c7\u30fc\u30bf\u5168\u3066\u3092\u4f7f\u3063\u3066\u52fe\u914d\u3092\u8a08\u7b97\u3059\u308b\u306e\u3067\u306f\u306a\u304f\u3001\u5b66\u7fd2\u30c7\u30fc\u30bf\u304b\u3089\u3044\u304f\u3064\u304b\u3092\u53d6\u3063\u3066\u304d\u3066\u52fe\u914d\u8a08\u7b97\u3092\u884c\u3046\u3002\u3053\u3046\u3059\u308b\u3053\u3068\u3067\u3001\u5c40\u6240\u89e3\u304b\u3089\u629c\u3051\u51fa\u305b\u308b\u304b\u3082\u3057\u308c\u307e\u305b\u3093\u3002\n# \u5b66\u7fd2\u30c7\u30fc\u30bf\u306e\u7d44x,t\u304b\u3089\u30e9\u30f3\u30c0\u30e0\u306b\u30da\u30a2\u3092n\u500b\u9078\u629e\u3059\u308b\ndef sample(x, t, n=None):\n    assert len(x) == len(t)\n    N = len(x)\n    if n is None:\n        n = N\n    indices = np.random.choice(N, n, replace=False)\n    return x[indices], t[indices]\n\n\n\u6df7\u5408\u5bc6\u5ea6\u30cd\u30c3\u30c8\u30ef\u30fc\u30af\u306e\u5b66\u7fd2\n\u6df7\u5408\u5bc6\u5ea6\u30cd\u30c3\u30c8\u30ef\u30fc\u30af\u3092\u5b66\u7fd2\u3057\u3066\u3001\u305d\u306e\u7d50\u679c\u3092\u56f3\u793a\u3059\u308b\u30e1\u30a4\u30f3\u306e\u95a2\u6570\u3067\u3059\u3002\ndef main():\n\n    def func(x):\n        return x + 0.3 * np.sin(2 * np.pi * x)\n\n    # \u95a2\u6570func\u306e\u9006\u95a2\u6570\u306b\u5f93\u3046\u30c7\u30fc\u30bf\u70b9\u3092\u751f\u6210\n    x, t = create_toy_dataset(func)\n\n    # \u30cb\u30e5\u30fc\u30e9\u30eb\u30cd\u30c3\u30c8\u30ef\u30fc\u30af\u306e\u69cb\u9020\u3092\u6c7a\u3081\u308b\u3002\n    layers = [TanhLayer(1, 5, std=0.1), LinearLayer(5, 9, std=0.1)]\n    # \u6700\u9069\u5316\u3059\u308b\u30b3\u30b9\u30c8\u95a2\u6570\u3092\u6c7a\u3081\u308b\n    cost_function = GaussianMixture(3)\n    # \u30cb\u30e5\u30fc\u30e9\u30eb\u30cd\u30c3\u30c8\u30ef\u30fc\u30af\u3092\u4f5c\u308b\n    nn = NeuralNetwork(layers, cost_function)\n    # \u5b9f\u88c5\u304c\u3046\u307e\u304f\u3044\u3063\u3066\u3044\u308b\u304b\u30c1\u30a7\u30c3\u30af\u3059\u308b\u5834\u5408\u306f\u3053\u306e\u4e0b\u306e\u884c\u3092\u30a2\u30f3\u30b3\u30e1\u30f3\u30c8\u3059\u308b\u3002\n    # nn._gradient_check(np.array([[0.5]]), np.array([[0.5]]))\n\n    # \u306f\u3058\u3081\u306e\u5b66\u7fd2\u4fc2\u6570\u3092\u8a2d\u5b9a\n    learning_rate = 1e-4\n    for i in xrange(500000):\n        # \u4e00\u4e07\u56de\u306b\u4e00\u56de\u30b3\u30b9\u30c8\u95a2\u6570\u306e\u5024\u3092\u7b97\u51fa\u3057\u3001\u5b66\u7fd2\u4fc2\u6570\u30920.9\u500d\u306b\u3059\u308b\n        if i % 10000 == 0:\n            print \"step %6d, cost %f\" % (i, nn.cost(x, t))\n            learning_rate *= 0.9\n        # \u30df\u30cb\u30d0\u30c3\u30c1\u51e6\u7406\n        batch = sample(x, t, n=100)\n        nn.fit(*batch, learning_rate=learning_rate)\n\n    # \u30c6\u30b9\u30c8\u7528\u30c7\u30fc\u30bf\u306e\u4f5c\u6210\n    x_test = np.linspace(x.min(), x.max(), 100)\n    y_test = np.linspace(t.min(), t.max(), 100)\n    X_test, Y_test = np.meshgrid(x_test, y_test)\n    test = np.array([X_test, Y_test]).transpose(1, 2, 0).reshape(-1, 2)\n\n    # \u30c6\u30b9\u30c8\u7528\u30c7\u30fc\u30bf\u306e\u5c24\u5ea6\u3092\u7b97\u51fa\n    sigma, weight, mu = nn(test[:, 0].reshape(-1, 1))\n    probs = cost_function.gauss(mu, sigma, test[:, 1].reshape(-1, 1))\n    probs = np.sum(weight * probs, axis=1)\n    Probs = probs.reshape(100, 100)\n\n    # PRML\u56f35.21(a)\u306e\u518d\u73fe\n    plt.plot(x_test, weight[:100, 0], color=\"blue\")\n    plt.plot(x_test, weight[:100, 1], color=\"red\")\n    plt.plot(x_test, weight[:100, 2], color=\"green\")\n    plt.title(\"weights\")\n    plt.show()\n\n    # PRML\u56f35.21(b)\u306e\u518d\u73fe\n    plt.plot(x_test, mu[:100, 0], color=\"blue\")\n    plt.plot(x_test, mu[:100, 1], color=\"red\")\n    plt.plot(x_test, mu[:100, 2], color=\"green\")\n    plt.title(\"means\")\n    plt.show()\n\n    # PRML\u56f35.21(c)\u306e\u518d\u73fe\n    plt.scatter(x, t, alpha=0.5, label=\"observation\")\n    levels_log = np.linspace(0, np.log(probs.max()), 21)\n    levels = np.exp(levels_log)\n    levels[0] = 0\n    plt.contourf(X_test, Y_test, Probs, levels, alpha=0.5)\n    plt.colorbar()\n    plt.xlim(x.min(), x.max())\n    plt.ylim(t.min(), t.max())\n    plt.show()\n\n\n\u5168\u4f53\u306e\u30b3\u30fc\u30c9\n3\u884c\u76ee\u306eneural_network\u306f\u524d\u56de\u5b9f\u88c5\u3057\u305fneural_network.py\u306e\u3053\u3068\u3067\u3059\u3002\u3053\u306e\u30b3\u30fc\u30c9\u3068\u540c\u3058\u30c7\u30a3\u30ec\u30af\u30c8\u30ea\u306b\u5165\u308c\u3066\u4e0b\u3055\u3044\u3002\n\nmixture_density_network.py\nimport matplotlib.pyplot as plt\nimport numpy as np\nfrom neural_network import TanhLayer, LinearLayer, NeuralNetwork\n\n\nclass GaussianMixture(object):\n    \"\"\"Negative Log Likelihood of Gaussian Mixture model\"\"\"\n    def __init__(self, n_components):\n        self.n_components = n_components\n\n    def __call__(self, X, targets):\n        sigma, weight, mu = self.activate(X)\n        gauss = self.gauss(mu, sigma, targets)\n        return -np.sum(np.log(np.sum(weight * gauss, axis=1)))\n\n    def activate(self, X):\n        assert np.size(X, 1) == 3 * self.n_components\n        X_sigma, X_weight, X_mu = np.split(X, [self.n_components, 2 * self.n_components], axis=1)\n        sigma = np.exp(X_sigma)\n        weight = np.exp(X_weight - np.max(X_weight, 1, keepdims=True))\n        weight /= np.sum(weight, axis=1, keepdims=True)\n        return sigma, weight, X_mu\n\n    def gauss(self, mu, sigma, targets):\n        return np.exp(-0.5 * (mu - targets) ** 2 / np.square(sigma)) / np.sqrt(2 * np.pi * np.square(sigma))\n\n    def delta(self, X, targets):\n        sigma, weight, mu = self.activate(X)\n        var = np.square(sigma)\n        gamma = weight * self.gauss(mu, sigma, targets)\n        gamma /= np.sum(gamma, axis=1, keepdims=True)\n\n        delta_mu = gamma * (mu - targets) / var\n        delta_sigma = gamma * (1 - (mu - targets) ** 2 / var)\n        delta_weight = weight - gamma\n        delta = np.hstack([delta_sigma, delta_weight, delta_mu])\n        return delta\n\n\ndef create_toy_dataset(func, n=300):\n    t = np.random.uniform(size=(n, 1))\n    x = func(t) + np.random.uniform(-0.05, 0.05, size=(n, 1))\n    return x, t\n\n\ndef sample(x, t, n=None):\n    assert len(x) == len(t)\n    N = len(x)\n    if n is None:\n        n = N\n    indices = np.random.choice(N, n, replace=False)\n    return x[indices], t[indices]\n\n\ndef main():\n\n    def func(x):\n        return x + 0.3 * np.sin(2 * np.pi * x)\n\n    x, t = create_toy_dataset(func)\n\n    layers = [TanhLayer(1, 5, std=0.1), LinearLayer(5, 9, std=0.1)]\n    cost_function = GaussianMixture(3)\n    nn = NeuralNetwork(layers, cost_function)\n    # nn._gradient_check(np.array([[0.5]]), np.array([[0.5]]))\n    learning_rate = 1e-4\n    for i in xrange(500000):\n        if i % 10000 == 0:\n            print \"step %6d, cost %f\" % (i, nn.cost(x, t))\n            learning_rate *= 0.9\n        batch = sample(x, t, n=100)\n        nn.fit(*batch, learning_rate=learning_rate)\n\n    x_test = np.linspace(x.min(), x.max(), 100)\n    y_test = np.linspace(t.min(), t.max(), 100)\n    X_test, Y_test = np.meshgrid(x_test, y_test)\n    test = np.array([X_test, Y_test]).transpose(1, 2, 0).reshape(-1, 2)\n\n    sigma, weight, mu = nn(test[:, 0].reshape(-1, 1))\n    probs = cost_function.gauss(mu, sigma, test[:, 1].reshape(-1, 1))\n    probs = np.sum(weight * probs, axis=1)\n    Probs = probs.reshape(100, 100)\n\n    plt.plot(x_test, weight[:100, 0], color=\"blue\")\n    plt.plot(x_test, weight[:100, 1], color=\"red\")\n    plt.plot(x_test, weight[:100, 2], color=\"green\")\n    plt.title(\"weights\")\n    plt.show()\n\n    plt.plot(x_test, mu[:100, 0], color=\"blue\")\n    plt.plot(x_test, mu[:100, 1], color=\"red\")\n    plt.plot(x_test, mu[:100, 2], color=\"green\")\n    plt.title(\"means\")\n    plt.show()\n\n    plt.scatter(x, t, alpha=0.5, label=\"observation\")\n    levels_log = np.linspace(0, np.log(probs.max()), 21)\n    levels = np.exp(levels_log)\n    levels[0] = 0\n    plt.contourf(X_test, Y_test, Probs, levels, alpha=0.5)\n    plt.colorbar()\n    plt.xlim(x.min(), x.max())\n    plt.ylim(t.min(), t.max())\n    plt.show()\n\n\nif __name__ == '__main__':\n    main()\n\n\n\n\u7d50\u679c\n\u9752\u70b9\u3092\u30c8\u30ec\u30fc\u30cb\u30f3\u30b0\u30c7\u30fc\u30bf\u70b9\u3068\u3057\u3066\u3001\u4e0a\u306e\u30b3\u30fc\u30c9\u3092\u8d70\u3089\u305b\u3066\u6df7\u5408\u5bc6\u5ea6\u30cd\u30c3\u30c8\u30ef\u30fc\u30af\u3092\u5b66\u7fd2\u3055\u305b\u305f\u7d50\u679c\u3001PRML\u306e\u56f35.21\u306e\u3088\u3046\u306a\u30b0\u30e9\u30d5\u306e\u518d\u73fe\u304c\u51fa\u6765\u307e\u3057\u305f\u3002\u305f\u3060\u3057\u3001\u7dda\u306e\u8272\u306a\u3069\u306f\u9055\u3046\u3053\u3068\u304c\u3042\u308a\u307e\u3059\u3002\uff13\u3064\u306e\u30ac\u30a6\u30b9\u5206\u5e03\u3001\u9752\u3001\u8d64\u3001\u7dd1\u3001\u306b\u3088\u3063\u3066\u30c8\u30ec\u30fc\u30cb\u30f3\u30b0\u30c7\u30fc\u30bf\u70b9\u306b\u30d5\u30a3\u30c3\u30c6\u30a3\u30f3\u30b0\u3055\u308c\u3066\u3044\u307e\u3059\u3002\n\n\n\n\n\u5b66\u7fd2\u306e\u69d8\u5b50\n\u524d\u56de\u540c\u69d8\u3001\u5b66\u7fd2\u306e\u904e\u7a0b\u3092\u52d5\u753b\u306b\u3082\u3057\u3066\u307f\u307e\u3057\u305f\u3002\n\n\n\u7d42\u308f\u308a\u306b\n\u6df7\u5408\u5bc6\u5ea6\u30cd\u30c3\u30c8\u30ef\u30fc\u30af\u3068\u3044\u3046\u3082\u306e\u3092PRML\u3067\u8aad\u3080\u307e\u3067\u805e\u3044\u305f\u3053\u3068\u304c\u306a\u304b\u3063\u305f\u306e\u3067\u30cd\u30c3\u30c8\u3067\u691c\u7d22\u3057\u3066\u307f\u308b\u3068\u3001PRML\u306e\u8457\u8005C\u30fbM\u30fb\u30d3\u30b7\u30e7\u30c3\u30d7\u3055\u3093\u304c1994\u5e74\u306b\u66f8\u304b\u308c\u305f\u8ad6\u6587\u304c\u30d2\u30c3\u30c8\u3057\u305f\u306e\u3067\u3001\u3053\u306e\u4eba\u81ea\u8eab\u304c\u63d0\u5531\u3057\u305f\u3082\u306e\u306a\u306e\u304b\u3082\u3057\u308c\u307e\u305b\u3093\u3002\u6df7\u5408\u5bc6\u5ea6\u30cd\u30c3\u30c8\u30ef\u30fc\u30af\u306f\u591a\u5cf0\u6027\u306e\u3042\u308b\u3082\u306e\u306a\u3089\u5f93\u6765\u306e\u30e2\u30c7\u30eb\u3088\u308a\u6709\u52b9\u3060\u3068\u601d\u308f\u308c\u308b\u306e\u3067\u3001\u3053\u308c\u3092\u4f55\u3089\u304b\u306e\u5b9f\u30c7\u30fc\u30bf\u306b\u5bfe\u3057\u3066\u9069\u7528\u3057\u3066\u307f\u305f\u3044\u3082\u306e\u3067\u3059\u3002\n\u524d\u56de\u306f\u666e\u901a\u306e\u30cb\u30e5\u30fc\u30e9\u30eb\u30cd\u30c3\u30c8\u30ef\u30fc\u30af\u3092tensorflow\u3084chainer\u306a\u3069\u306e\u30e9\u30a4\u30d6\u30e9\u30ea\u3092\u4f7f\u308f\u305a\u306b\u5b9f\u88c5\u3057\u307e\u3057\u305f\u3002\u305f\u3060\u3001\u305d\u306e\u985e\u306e\u5b9f\u88c5\u306f\u30cd\u30c3\u30c8\u4e0a\u306b\u3059\u3067\u306b\u305f\u304f\u3055\u3093\u3042\u308a\u3001\u305d\u308c\u3067\u306f\u3042\u307e\u308a\u9762\u767d\u307f\u304c\u3042\u308a\u307e\u305b\u3093\u306e\u3067\u3001\u524d\u56de\u306e\u306f\u3042\u304f\u307e\u3067\u6e96\u5099\u3068\u3057\u3066**\u4eca\u56de\u306f\u6df7\u5408\u5bc6\u5ea6\u30cd\u30c3\u30c8\u30ef\u30fc\u30af\u3092\u5b9f\u88c5**\u3057\u307e\u3057\u305f\u3002\u524d\u56de\u5b9f\u88c5\u3057\u305f\u30cb\u30e5\u30fc\u30e9\u30eb\u30cd\u30c3\u30c8\u30ef\u30fc\u30af\u306e\u30b3\u30fc\u30c9\u3092\u5229\u7528\u3059\u308b\u306e\u3067\u3001[\u524d\u56de\u306e\u8a18\u4e8b](http://qiita.com/cutting_the_Gordian_knot/items/507f2f1531b870a973bf)\u3082\u9069\u5b9c\u53c2\u8003\u306b\u3057\u3066\u307f\u3066\u4e0b\u3055\u3044\u3002\n\n# \u6df7\u5408\u5bc6\u5ea6\u30cd\u30c3\u30c8\u30ef\u30fc\u30af\n\n## \u5f93\u6765\u30e2\u30c7\u30eb\u306e\u554f\u984c\u70b9\n\u56de\u5e30\u554f\u984c\u3092\u89e3\u304f\u3068\u304d\u306b\u3001\u4e8c\u4e57\u548c\u8aa4\u5dee\u95a2\u6570\u3092\u4f7f\u3063\u3066\u3044\u305f\u306e\u3067\u306f\u3046\u307e\u304f\u5bfe\u51e6\u3067\u304d\u306a\u3044\u5834\u5408\u304c\u3042\u308a\u307e\u3059\u3002\u4e0b\u306e\u56f3\uff08PRML\u56f35.19\u306e\u518d\u73fe\uff09\u306f\u3001\u9752\u70b9\u3092\u30c8\u30ec\u30fc\u30cb\u30f3\u30b0\u30c7\u30fc\u30bf\u3068\u3057\u3066\u3001\u4e8c\u4e57\u548c\u8aa4\u5dee\u95a2\u6570\u3092\u7528\u3044\u3066\u30cb\u30e5\u30fc\u30e9\u30eb\u30cd\u30c3\u30c8\u30ef\u30fc\u30af\u3092\u5b66\u7fd2\u3055\u305b\u305f\u3068\u304d\u306e\u7d50\u679c\u3092\u8868\u3057\u3066\u3044\u307e\u3059\u3002\n![inverse_problem.png](https://qiita-image-store.s3.amazonaws.com/0/148017/0e404059-5716-2bc0-35fc-61851265ac0b.png)\n$x=0.5$\u306e\u3068\u304d\u306f$y$\u306e\u5024\u304c0.2\u30010.5\u30010.8\u306e\u3069\u308c\u3067\u3082\u3088\u3055\u305d\u3046\u3067\u3059\u3002\u3057\u304b\u3057\u3001\u305d\u306e\u4e2d\u3067\u4e00\u3064\u3092\u9078\u3070\u306a\u3044\u3068\u3044\u3051\u306a\u3044\u306e\u30670.5\u306b\u306a\u308a\u3001\u4ed6\u306e\uff12\u3064\u306b\u30d5\u30a3\u30c3\u30c6\u30a3\u30f3\u30b0\u3057\u307e\u305b\u3093\u3002**\u30cb\u30e5\u30fc\u30e9\u30eb\u30cd\u30c3\u30c8\u30ef\u30fc\u30af\u3092\u5b66\u7fd2\u3055\u305b\u305f\u306e\u306b\u3042\u307e\u308a\u30d5\u30a3\u30c3\u30c6\u30a3\u30f3\u30b0\u3067\u304d\u3066\u3044\u306a\u3044\u306e\u306f\u3001\u30b3\u30b9\u30c8\u95a2\u6570\u304c\u5358\u5cf0\u6027\u306e\u30ac\u30a6\u30b9\u5206\u5e03\u3067\u30e2\u30c7\u30eb\u3055\u308c\u3066\u3044\u308b\u304b\u3089**\u3067\u3059\u3002\u5165\u529b$x$\u3068\u30bf\u30fc\u30b2\u30c3\u30c8$t$\u306e\u95a2\u4fc2\u3092\u3001\u30ac\u30a6\u30b9\u5206\u5e03\u3067\u4ee5\u4e0b\u306e\u3088\u3046\u306b\u8868\u3057\u3001\n\n```math\np(t|x) = \\mathcal{N}(t|\\mu(x),\\sigma^2),\n```\n\u3053\u308c\u306b\u57fa\u3065\u3044\u3066\u30d5\u30a3\u30c3\u30c6\u30a3\u30f3\u30b0\u3001\u95a2\u6570$\\mu(x)$\u306e\u63a8\u5b9a\u3001\u3092\u884c\u3063\u3066\u3044\u307e\u3057\u305f\u3002\u305d\u3057\u3066\u3001\u63a8\u5b9a\u3057\u305f$\\mu(x)$\u304c\u4e0a\u306e\u56f3\u306e\u8d64\u8272\u3068\u306a\u3063\u3066\u3044\u3066\u3001\u30c0\u30e1\u30c0\u30e1\u306a\u7d50\u679c\u3068\u306a\u3063\u3066\u3057\u307e\u3044\u307e\u3057\u305f\u3002\n\n## \u6df7\u5408\u30ac\u30a6\u30b9\u5206\u5e03\n\u6df7\u5408\u5bc6\u5ea6\u30cd\u30c3\u30c8\u30ef\u30fc\u30af\u3067\u306f\u30b3\u30b9\u30c8\u95a2\u6570\u306b\u591a\u5cf0\u6027\u306e\u6df7\u5408\u30ac\u30a6\u30b9\u5206\u5e03\u3067\u30e2\u30c7\u30eb\u3055\u308c\u305f\u3082\u306e\u3092\u7528\u3044\u308b\u3053\u3068\u3067\u3001\u4e0a\u306e\u554f\u984c\u3092\u89e3\u6c7a\u3057\u307e\u3059\u3002K\u500b\u306e\u30ac\u30a6\u30b9\u5206\u5e03\u306b\u4e00\u3064\u4e00\u3064\u6df7\u5408\u4fc2\u6570$\\pi\\_k$\u3092\u7528\u610f\u3057\u3066\u3001\u5165\u529b$x$\u3068\u30bf\u30fc\u30b2\u30c3\u30c8$t$\u306e\u95a2\u4fc2\u3092\n\n```math\np(t|x) = \\sum_{k=1}^K\\pi_k(x)\\mathcal{N}(t|\\mu_k(x),\\sigma^2_k(x))\n```\n\u3068\u30e2\u30c7\u30eb\u3057\u307e\u3059\u3002\u305f\u3060\u3057\u3001\u6df7\u5408\u4fc2\u6570\u306e\u548c\u306f1\u3068\u3057\u307e\u3059($\\sum_k\\pi_k=1$)\u3002\u4e0a\u306e\u30c8\u30ec\u30fc\u30cb\u30f3\u30b0\u30c7\u30fc\u30bf\u306e\u4f8b\u3060\u3068\u3001$x=0.5$\u3067\u306f$y=0.2,0.5,0.8$\u306e\u3042\u305f\u308a\u306b\uff13\u3064\u306e\u30c7\u30fc\u30bf\u70b9\u306e\u96c6\u5408\u304c\u3042\u308a\u307e\u3059\u3002\u3088\u3063\u3066\u3001$K=3$\u3068\u3059\u308b\u306e\u304c\u826f\u3055\u305d\u3046\u3067\u3059\u30023\u500b\u306e\u30ac\u30a6\u30b9\u5206\u5e03\u304c\u305d\u308c\u305e\u308c\u5225\u306e\u30c7\u30fc\u30bf\u70b9\u306e\u96c6\u5408\u306b\u30d5\u30a3\u30c3\u30c6\u30a3\u30f3\u30b0\u3055\u308c\u308b\u3053\u3068\u3067\u3001\u591a\u5cf0\u6027\u306e\u3042\u308b\u30c7\u30fc\u30bf\u3067\u3082\u5bfe\u51e6\u3067\u304d\u307e\u3059\u3002\n\u3088\u3063\u3066\u3001\u30c8\u30ec\u30fc\u30cb\u30f3\u30b0\u30c7\u30fc\u30bf\u306e\u7d44$\\\\{x\\_n,t\\_n\\\\}_{n=1}^N$\u304c\u4e0e\u3048\u3089\u308c\u3066\u3044\u308b\u3068\u304d\u3001\u6700\u9069\u5316\u3059\u308b\u30b3\u30b9\u30c8\u95a2\u6570\u306f\n\n```math\n\\begin{align}\nE(w) &= \\sum_{n=1}^N E_n\\\\\n&= -\\sum_{n=1}^N \\ln p(t_n|x_n)\\\\\n&= -\\sum_{n=1}^N \\ln \\left\\{\\sum_{k=1}^K\\pi_k(x_n,w)\\mathcal{N}\\left(t_n|\\mu_k(x_n,w),\\sigma^2_k(x_n,w)\\right)\\right\\}\n\\end{align}\n```\n\u3068\u306a\u308a\u307e\u3059\u3002\u305d\u3057\u3066\u3001\u4e0a\u306e\u5f0f\u3092\u6700\u5c0f\u5316\u3059\u308b\u3088\u3046\u306a\u30d1\u30e9\u30e1\u30fc\u30bf$w$\u3092\u63a8\u5b9a\u3057\u307e\u3059\u3002\u95a2\u6570$\\pi_k,\\mu_k,\\sigma_k$\u306b\u306f\u30cb\u30e5\u30fc\u30e9\u30eb\u30cd\u30c3\u30c8\u30ef\u30fc\u30af\u3092\u4f7f\u3044\u307e\u3059\u3002\u30d1\u30e9\u30e1\u30fc\u30bf$w$\u306e\u30cd\u30c3\u30c8\u30ef\u30fc\u30af\u306b\u5165\u529b$x$\u3092\u5165\u308c\u308b\u3068\u3001\u6df7\u5408\u4fc2\u6570\u3001\u5e73\u5747\u3001\u5206\u6563\u304c\u51fa\u529b\u3055\u308c\u3001$t$\u306e\u78ba\u7387\u5206\u5e03\u304c\u7b97\u51fa\u3055\u308c\u307e\u3059\u3002\n\n## \u30cd\u30c3\u30c8\u30ef\u30fc\u30af\u69cb\u9020\n\u4eca\u56de\u306f\u4e0a\u306e\u56f3\u306e\u3088\u3046\u306a\u30c7\u30fc\u30bf\u306b\u5bfe\u3057\u3066\u56de\u5e30\u3092\u884c\u3046\u306e\u3067\u3001\u5165\u529b${\\bf x}$\u306f\uff11\u6b21\u5143\u3068\u306a\u308a\u307e\u3059\u3002\u4e2d\u9593${\\bf z}$\u306e\u30ce\u30fc\u30c9\u306e\u6570\u306fPRML\u306b\u306a\u3089\u3063\u30665\u3064\u3001\u51fa\u529b${\\bf y}$\u306e\u30ce\u30fc\u30c9\u6570\u306f\uff19\u3064\u3068\u3057\u307e\u3059\u3002\u7b2c\u4e00\u5c64\u306e\u30d1\u30e9\u30e1\u30fc\u30bf\u3092$W^{(1)},{\\bf b}^{(1)}$\u3001\u6d3b\u6027\u5316\u95a2\u6570\u3092$f(\\cdot)$\u3001\u7b2c\u4e8c\u5c64\u306e\u30d1\u30e9\u30e1\u30fc\u30bf\u3092$W^{(2)},{\\bf b}^{(2)}$\u3068\u3057\u3066\u3001\u9806\u4f1d\u64ad\u306f\u6b21\u306e\u3088\u3046\u306b\u306a\u308a\u307e\u3059\u3002\n\n```math\n\\begin{align}\n{\\bf z} &= f(W^{(1)}{\\bf x} + {\\bf b}^{(1)})\\\\\n{\\bf y} &= W^{(2)}{\\bf z} + {\\bf b}^{(2)}\n\\end{align}\n```\n\u3053\u306e\u51fa\u529b9\u3064\u306f\u6df7\u5408\u30ac\u30a6\u30b9\u5206\u5e03\u306e\u30d1\u30e9\u30e1\u30fc\u30bf$\\pi_k,\\mu_k,\\sigma_k$\u306e\u6d3b\u6027\u3067\u3059\u3002\n\u307e\u305a\u3001\u51fa\u529b${\\bf y}$\u306f\u4e0a\u304b\u3089\uff13\u3064\u305a\u3064$\\pi,\\mu,\\sigma$\u306b\u5bfe\u5fdc\u3057\u3066\u3044\u308b\u6d3b\u6027\u3068\u3057\u307e\u3059\u3002\n\n```math\n{\\bf y} =\n\\begin{bmatrix}\na_{\\pi_1}\\\\\na_{\\pi_2}\\\\\na_{\\pi_3}\\\\\na_{\\mu_1}\\\\\na_{\\mu_2}\\\\\na_{\\mu_3}\\\\\na_{\\sigma_1}\\\\\na_{\\sigma_2}\\\\\na_{\\sigma_3}\n\\end{bmatrix}\n```\n\u6df7\u5408\u4fc2\u6570$\\pi_k$\u306f$\\sum_k\\pi_k=1$\u3068\u3044\u3046\u5236\u7d04\u6761\u4ef6\u304c\u3042\u308b\u306e\u3067\u3001\u30bd\u30d5\u30c8\u30de\u30c3\u30af\u30b9\u95a2\u6570\u306b\u3088\u308a\u6df7\u5408\u4fc2\u6570\u3092\u51fa\u529b\u3057\u307e\u3059\u3002\n\n```math\n\\pi_k = {\\exp(a_{\\pi_k})\\over\\sum_{l=1}^K\\exp(a_{\\pi_l})}\n```\n\u5e73\u5747\u306f\u975e\u7dda\u5f62\u5909\u63db\u3092\u7528\u3044\u305a\u306b$\\mu_k = a_{\\mu_k}$\u3068\u3057\u307e\u3059\u3002\n\u6a19\u6e96\u504f\u5dee$\\sigma$\u306f\uff10\u4ee5\u4e0a\u306a\u306e\u3067\u6307\u6570\u95a2\u6570\u3092\u4f7f\u3063\u3066$\\sigma_k = \\exp(a_{\\sigma_k})$\u3002\n\u3053\u308c\u3067\u3001\u6df7\u5408\u30ac\u30a6\u30b9\u5206\u5e03\u3092\u8a08\u7b97\u3059\u308b\u306e\u306b\u5fc5\u8981\u306a\u95a2\u6570$\\pi_k,\\mu_k,\\sigma_k$\u304c\u6c42\u307e\u308a\u307e\u3057\u305f\u3002\n\n## \u52fe\u914d\n\u524d\u56de\u306e[\u30cb\u30e5\u30fc\u30e9\u30eb\u30cd\u30c3\u30c8\u30ef\u30fc\u30af\u306e\u5b9f\u88c5]()\u3067\u66f8\u3044\u305f\u3088\u3046\u306b\u30cb\u30e5\u30fc\u30e9\u30eb\u30cd\u30c3\u30c8\u30ef\u30fc\u30af\u3092\u5b66\u7fd2\u3055\u305b\u308b\u306e\u306b\u306f\u30b3\u30b9\u30c8\u95a2\u6570\u3092\u30cb\u30e5\u30fc\u30e9\u30eb\u30cd\u30c3\u30c8\u30ef\u30fc\u30af\u306e\u51fa\u529b\u3067\u5fae\u5206\u3057\u305f\u52fe\u914d\u304c\u5fc5\u8981\u3067\u3059\u3002\u305d\u308c\u304c\u3042\u308c\u3070\u3001\u3042\u3068\u306f\u8aa4\u5dee\u9006\u4f1d\u64ad\u3092\u4f7f\u3063\u3066\u30b3\u30b9\u30c8\u95a2\u6570\u306e\u30d1\u30e9\u30e1\u30fc\u30bf$w$\u306b\u3064\u3044\u3066\u306e\u5fae\u5206\u3082\u8a08\u7b97\u3067\u304d\u307e\u3059\u3002\n\u305d\u306e\u30b3\u30b9\u30c8\u95a2\u6570\u306e\u30cb\u30e5\u30fc\u30e9\u30eb\u30cd\u30c3\u30c8\u30ef\u30fc\u30af\u306e\u51fa\u529b\u3067\u306e\u52fe\u914d\u306f\u3001\n\n```math\n\\gamma_{nk}(t_n|x_n) = {\\pi_k\\mathcal{N}(t_n|\\mu_k(x_n,w),\\sigma_k^2(x_n,w))\\over\\sum_l\\pi_l\\mathcal{N}(t_n|\\mu_l(x_n,w),\\sigma_l^2(x_n,w))}\n```\n\u3092\u7528\u3044\u3066\u3001\n\n```math\n\\begin{align}\n{\\partial E_n\\over\\partial a_{\\pi_k}} &= \\pi_k - \\gamma_{nk}\\\\\n{\\partial E_n\\over\\partial a_{\\mu_k}} &= \\gamma_{nk}{\\mu_k - t_n\\over\\sigma^2_k}\\\\\n{\\partial E_n\\over\\partial a_{\\sigma_k}} &= \\gamma_{nk}\\left(1 - {||t_n - \\mu_k||^2\\over \\sigma^2_k}\\right)\n\\end{align}\n```\n\u3068\u306a\u308a\u307e\u3059\u3002\u5f0f\u306e\u5c0e\u51fa\u306fPRML\u3067\u306f\u6f14\u7fd2\u554f\u984c\u306b\u306a\u3063\u3066\u3044\u308b\u306e\u3067\u305d\u306e\u56de\u7b54\u3001\u3082\u3057\u304f\u306f\u6df7\u5408\u5bc6\u5ea6\u30cd\u30c3\u30c8\u30ef\u30fc\u30af\u306e\u8ad6\u6587\u3092\u53c2\u7167\u3057\u3066\u304f\u3060\u3055\u3044\u3002\n\n\n# \u5b9f\u88c5\n\n## \u30b3\u30b9\u30c8\u95a2\u6570\n\u4e0a\u3067\u66f8\u3044\u305f\u6570\u5f0f\u3092\u30b3\u30fc\u30c9\u306b\u3059\u308b\u3068\u3001\u6b21\u306e\u3088\u3046\u306b\u306a\u308a\u307e\u3059\u3002\n\n```python\n# \u30b3\u30b9\u30c8\u95a2\u6570\u306e\u30af\u30e9\u30b9\nclass GaussianMixture(object):\n    \"\"\"Negative Log Likelihood of Gaussian Mixture model\"\"\"\n    def __init__(self, n_components):\n        # \u30ac\u30a6\u30b9\u5206\u5e03\u306e\u500b\u6570\u3001\u4eca\u307e\u3067\u306e\u4f8b\u3060\u30683\n        self.n_components = n_components\n\n    # \u30b3\u30b9\u30c8\u95a2\u6570\u306e\u5024\u3092\u8a08\u7b97\u3059\u308b\u30e1\u30bd\u30c3\u30c9\n    def __call__(self, X, targets):\n\n        # \u30cd\u30c3\u30c8\u30ef\u30fc\u30af\u306e\u51fa\u529bX\u3092\u6d3b\u6027\u5316\u95a2\u6570\u3067\u5909\u63db\u3057\u3066\u3001\u6a19\u6e96\u504f\u5dee\u3001\u6df7\u5408\u4fc2\u6570\u3001\u5e73\u5747\u3092\u8a08\u7b97\n        sigma, weight, mu = self.activate(X)\n\n        # \u30ac\u30a6\u30b9\u95a2\u6570N(t|mu,sigma^2)\u306e\u5024\u3092\u8a08\u7b97\n        gauss = self.gauss(mu, sigma, targets)\n\n        # \u6df7\u5408\u30ac\u30a6\u30b9\u5206\u5e03\u306e\u8ca0\u306e\u5bfe\u6570\u5c24\u5ea6E(w):PRML(\u5f0f5.153)\n        return -np.sum(np.log(np.sum(weight * gauss, axis=1)))\n\n    # \u6d3b\u6027\u5316\u95a2\u6570\u3067\u5909\u63db\n    def activate(self, X):\n        assert np.size(X, 1) == 3 * self.n_components\n\n        # X\u3092\u6a19\u6e96\u504f\u5dee\u3001\u6df7\u5408\u4fc2\u6570\u3001\u5e73\u5747\u306b\u5bfe\u5fdc\u3059\u308b\u3068\u3053\u308d\u306b\u5206\u5272\n        X_sigma, X_weight, X_mu = np.split(X, [self.n_components, 2 * self.n_components], axis=1)\n\n        # \u6a19\u6e96\u504f\u5dee\u3092\u6d3b\u6027\u5316\u95a2\u6570\u3067\u5909\u63db\n        sigma = np.exp(X_sigma)\n\n        # \u6df7\u5408\u4fc2\u6570\u3092\u6d3b\u6027\u5316\u95a2\u6570\u3067\u5909\u63db\u3001\u6841\u304c\u3042\u3075\u308c\u306a\u3044\u3088\u3046\u306b\u6700\u5927\u5024\u3067\u5f15\u304f\n        weight = np.exp(X_weight - np.max(X_weight, 1, keepdims=True))\n        weight /= np.sum(weight, axis=1, keepdims=True)\n\n        return sigma, weight, X_mu\n\n    # \u30ac\u30a6\u30b9\u95a2\u6570N(target|mu,sigma^2)\u3092\u8a08\u7b97\n    def gauss(self, mu, sigma, targets):\n        return np.exp(-0.5 * (mu - targets) ** 2 / np.square(sigma)) / np.sqrt(2 * np.pi * np.square(sigma))\n\n    # \u30b3\u30b9\u30c8\u95a2\u6570\u3092\u6d3b\u6027\u3067\u5fae\u5206\n    def delta(self, X, targets):\n        sigma, weight, mu = self.activate(X)\n        var = np.square(sigma)\n        gamma = weight * self.gauss(mu, sigma, targets)\n        gamma /= np.sum(gamma, axis=1, keepdims=True)\n\n        # \u305d\u308c\u305e\u308c\u306e\u5fae\u5206\u3092\u8a08\u7b97\n        delta_mu = gamma * (mu - targets) / var\n        delta_sigma = gamma * (1 - (mu - targets) ** 2 / var)\n        delta_weight = weight - gamma\n\n        # \u9023\u7d50\u3055\u305b\u3066\u304b\u3089\u8fd4\u3059\n        delta = np.hstack([delta_sigma, delta_weight, delta_mu])\n        return delta\n```\n\n## \u5b66\u7fd2\u30c7\u30fc\u30bf\u306e\u4f5c\u6210\n```python\n# \u95a2\u6570func\u306e\u9006\u95a2\u6570\u306b\u5f93\u3046\u3088\u3046\u306a\u5b66\u7fd2\u30c7\u30fc\u30bf\u3092\u4f5c\u6210\u3059\u308b\ndef create_toy_dataset(func, n=300):\n    t = np.random.uniform(size=(n, 1))\n    x = func(t) + np.random.uniform(-0.05, 0.05, size=(n, 1))\n    return x, t\n```\n\n## \u30df\u30cb\u30d0\u30c3\u30c1\u51e6\u7406\n\u5b66\u7fd2\u304c\u3046\u307e\u304f\u3044\u304b\u306a\u3044\u3053\u3068\u304c\u3042\u3063\u305f\u306e\u3067\u6025\u907d\u4f7f\u7528\u3057\u305f\u624b\u6cd5\u306e\u4e00\u3064\u3002\n\u5b66\u7fd2\u30c7\u30fc\u30bf\u5168\u3066\u3092\u4f7f\u3063\u3066\u52fe\u914d\u3092\u8a08\u7b97\u3059\u308b\u306e\u3067\u306f\u306a\u304f\u3001\u5b66\u7fd2\u30c7\u30fc\u30bf\u304b\u3089\u3044\u304f\u3064\u304b\u3092\u53d6\u3063\u3066\u304d\u3066\u52fe\u914d\u8a08\u7b97\u3092\u884c\u3046\u3002\u3053\u3046\u3059\u308b\u3053\u3068\u3067\u3001\u5c40\u6240\u89e3\u304b\u3089\u629c\u3051\u51fa\u305b\u308b\u304b\u3082\u3057\u308c\u307e\u305b\u3093\u3002\n\n```python\n# \u5b66\u7fd2\u30c7\u30fc\u30bf\u306e\u7d44x,t\u304b\u3089\u30e9\u30f3\u30c0\u30e0\u306b\u30da\u30a2\u3092n\u500b\u9078\u629e\u3059\u308b\ndef sample(x, t, n=None):\n    assert len(x) == len(t)\n    N = len(x)\n    if n is None:\n        n = N\n    indices = np.random.choice(N, n, replace=False)\n    return x[indices], t[indices]\n```\n\n## \u6df7\u5408\u5bc6\u5ea6\u30cd\u30c3\u30c8\u30ef\u30fc\u30af\u306e\u5b66\u7fd2\n\u6df7\u5408\u5bc6\u5ea6\u30cd\u30c3\u30c8\u30ef\u30fc\u30af\u3092\u5b66\u7fd2\u3057\u3066\u3001\u305d\u306e\u7d50\u679c\u3092\u56f3\u793a\u3059\u308b\u30e1\u30a4\u30f3\u306e\u95a2\u6570\u3067\u3059\u3002\n\n```python\ndef main():\n\n    def func(x):\n        return x + 0.3 * np.sin(2 * np.pi * x)\n\n    # \u95a2\u6570func\u306e\u9006\u95a2\u6570\u306b\u5f93\u3046\u30c7\u30fc\u30bf\u70b9\u3092\u751f\u6210\n    x, t = create_toy_dataset(func)\n\n    # \u30cb\u30e5\u30fc\u30e9\u30eb\u30cd\u30c3\u30c8\u30ef\u30fc\u30af\u306e\u69cb\u9020\u3092\u6c7a\u3081\u308b\u3002\n    layers = [TanhLayer(1, 5, std=0.1), LinearLayer(5, 9, std=0.1)]\n    # \u6700\u9069\u5316\u3059\u308b\u30b3\u30b9\u30c8\u95a2\u6570\u3092\u6c7a\u3081\u308b\n    cost_function = GaussianMixture(3)\n    # \u30cb\u30e5\u30fc\u30e9\u30eb\u30cd\u30c3\u30c8\u30ef\u30fc\u30af\u3092\u4f5c\u308b\n    nn = NeuralNetwork(layers, cost_function)\n    # \u5b9f\u88c5\u304c\u3046\u307e\u304f\u3044\u3063\u3066\u3044\u308b\u304b\u30c1\u30a7\u30c3\u30af\u3059\u308b\u5834\u5408\u306f\u3053\u306e\u4e0b\u306e\u884c\u3092\u30a2\u30f3\u30b3\u30e1\u30f3\u30c8\u3059\u308b\u3002\n    # nn._gradient_check(np.array([[0.5]]), np.array([[0.5]]))\n\n    # \u306f\u3058\u3081\u306e\u5b66\u7fd2\u4fc2\u6570\u3092\u8a2d\u5b9a\n    learning_rate = 1e-4\n    for i in xrange(500000):\n        # \u4e00\u4e07\u56de\u306b\u4e00\u56de\u30b3\u30b9\u30c8\u95a2\u6570\u306e\u5024\u3092\u7b97\u51fa\u3057\u3001\u5b66\u7fd2\u4fc2\u6570\u30920.9\u500d\u306b\u3059\u308b\n        if i % 10000 == 0:\n            print \"step %6d, cost %f\" % (i, nn.cost(x, t))\n            learning_rate *= 0.9\n        # \u30df\u30cb\u30d0\u30c3\u30c1\u51e6\u7406\n        batch = sample(x, t, n=100)\n        nn.fit(*batch, learning_rate=learning_rate)\n\n    # \u30c6\u30b9\u30c8\u7528\u30c7\u30fc\u30bf\u306e\u4f5c\u6210\n    x_test = np.linspace(x.min(), x.max(), 100)\n    y_test = np.linspace(t.min(), t.max(), 100)\n    X_test, Y_test = np.meshgrid(x_test, y_test)\n    test = np.array([X_test, Y_test]).transpose(1, 2, 0).reshape(-1, 2)\n\n    # \u30c6\u30b9\u30c8\u7528\u30c7\u30fc\u30bf\u306e\u5c24\u5ea6\u3092\u7b97\u51fa\n    sigma, weight, mu = nn(test[:, 0].reshape(-1, 1))\n    probs = cost_function.gauss(mu, sigma, test[:, 1].reshape(-1, 1))\n    probs = np.sum(weight * probs, axis=1)\n    Probs = probs.reshape(100, 100)\n\n    # PRML\u56f35.21(a)\u306e\u518d\u73fe\n    plt.plot(x_test, weight[:100, 0], color=\"blue\")\n    plt.plot(x_test, weight[:100, 1], color=\"red\")\n    plt.plot(x_test, weight[:100, 2], color=\"green\")\n    plt.title(\"weights\")\n    plt.show()\n\n    # PRML\u56f35.21(b)\u306e\u518d\u73fe\n    plt.plot(x_test, mu[:100, 0], color=\"blue\")\n    plt.plot(x_test, mu[:100, 1], color=\"red\")\n    plt.plot(x_test, mu[:100, 2], color=\"green\")\n    plt.title(\"means\")\n    plt.show()\n\n    # PRML\u56f35.21(c)\u306e\u518d\u73fe\n    plt.scatter(x, t, alpha=0.5, label=\"observation\")\n    levels_log = np.linspace(0, np.log(probs.max()), 21)\n    levels = np.exp(levels_log)\n    levels[0] = 0\n    plt.contourf(X_test, Y_test, Probs, levels, alpha=0.5)\n    plt.colorbar()\n    plt.xlim(x.min(), x.max())\n    plt.ylim(t.min(), t.max())\n    plt.show()\n```\n\n## \u5168\u4f53\u306e\u30b3\u30fc\u30c9\n3\u884c\u76ee\u306e`neural_network`\u306f[\u524d\u56de](http://qiita.com/cutting_the_Gordian_knot/items/507f2f1531b870a973bf)\u5b9f\u88c5\u3057\u305f`neural_network.py`\u306e\u3053\u3068\u3067\u3059\u3002\u3053\u306e\u30b3\u30fc\u30c9\u3068\u540c\u3058\u30c7\u30a3\u30ec\u30af\u30c8\u30ea\u306b\u5165\u308c\u3066\u4e0b\u3055\u3044\u3002\n\n```python:mixture_density_network.py\nimport matplotlib.pyplot as plt\nimport numpy as np\nfrom neural_network import TanhLayer, LinearLayer, NeuralNetwork\n\n\nclass GaussianMixture(object):\n    \"\"\"Negative Log Likelihood of Gaussian Mixture model\"\"\"\n    def __init__(self, n_components):\n        self.n_components = n_components\n\n    def __call__(self, X, targets):\n        sigma, weight, mu = self.activate(X)\n        gauss = self.gauss(mu, sigma, targets)\n        return -np.sum(np.log(np.sum(weight * gauss, axis=1)))\n\n    def activate(self, X):\n        assert np.size(X, 1) == 3 * self.n_components\n        X_sigma, X_weight, X_mu = np.split(X, [self.n_components, 2 * self.n_components], axis=1)\n        sigma = np.exp(X_sigma)\n        weight = np.exp(X_weight - np.max(X_weight, 1, keepdims=True))\n        weight /= np.sum(weight, axis=1, keepdims=True)\n        return sigma, weight, X_mu\n\n    def gauss(self, mu, sigma, targets):\n        return np.exp(-0.5 * (mu - targets) ** 2 / np.square(sigma)) / np.sqrt(2 * np.pi * np.square(sigma))\n\n    def delta(self, X, targets):\n        sigma, weight, mu = self.activate(X)\n        var = np.square(sigma)\n        gamma = weight * self.gauss(mu, sigma, targets)\n        gamma /= np.sum(gamma, axis=1, keepdims=True)\n\n        delta_mu = gamma * (mu - targets) / var\n        delta_sigma = gamma * (1 - (mu - targets) ** 2 / var)\n        delta_weight = weight - gamma\n        delta = np.hstack([delta_sigma, delta_weight, delta_mu])\n        return delta\n\n\ndef create_toy_dataset(func, n=300):\n    t = np.random.uniform(size=(n, 1))\n    x = func(t) + np.random.uniform(-0.05, 0.05, size=(n, 1))\n    return x, t\n\n\ndef sample(x, t, n=None):\n    assert len(x) == len(t)\n    N = len(x)\n    if n is None:\n        n = N\n    indices = np.random.choice(N, n, replace=False)\n    return x[indices], t[indices]\n\n\ndef main():\n\n    def func(x):\n        return x + 0.3 * np.sin(2 * np.pi * x)\n\n    x, t = create_toy_dataset(func)\n\n    layers = [TanhLayer(1, 5, std=0.1), LinearLayer(5, 9, std=0.1)]\n    cost_function = GaussianMixture(3)\n    nn = NeuralNetwork(layers, cost_function)\n    # nn._gradient_check(np.array([[0.5]]), np.array([[0.5]]))\n    learning_rate = 1e-4\n    for i in xrange(500000):\n        if i % 10000 == 0:\n            print \"step %6d, cost %f\" % (i, nn.cost(x, t))\n            learning_rate *= 0.9\n        batch = sample(x, t, n=100)\n        nn.fit(*batch, learning_rate=learning_rate)\n\n    x_test = np.linspace(x.min(), x.max(), 100)\n    y_test = np.linspace(t.min(), t.max(), 100)\n    X_test, Y_test = np.meshgrid(x_test, y_test)\n    test = np.array([X_test, Y_test]).transpose(1, 2, 0).reshape(-1, 2)\n\n    sigma, weight, mu = nn(test[:, 0].reshape(-1, 1))\n    probs = cost_function.gauss(mu, sigma, test[:, 1].reshape(-1, 1))\n    probs = np.sum(weight * probs, axis=1)\n    Probs = probs.reshape(100, 100)\n\n    plt.plot(x_test, weight[:100, 0], color=\"blue\")\n    plt.plot(x_test, weight[:100, 1], color=\"red\")\n    plt.plot(x_test, weight[:100, 2], color=\"green\")\n    plt.title(\"weights\")\n    plt.show()\n\n    plt.plot(x_test, mu[:100, 0], color=\"blue\")\n    plt.plot(x_test, mu[:100, 1], color=\"red\")\n    plt.plot(x_test, mu[:100, 2], color=\"green\")\n    plt.title(\"means\")\n    plt.show()\n\n    plt.scatter(x, t, alpha=0.5, label=\"observation\")\n    levels_log = np.linspace(0, np.log(probs.max()), 21)\n    levels = np.exp(levels_log)\n    levels[0] = 0\n    plt.contourf(X_test, Y_test, Probs, levels, alpha=0.5)\n    plt.colorbar()\n    plt.xlim(x.min(), x.max())\n    plt.ylim(t.min(), t.max())\n    plt.show()\n\n\nif __name__ == '__main__':\n    main()\n```\n\n# \u7d50\u679c\n\u9752\u70b9\u3092\u30c8\u30ec\u30fc\u30cb\u30f3\u30b0\u30c7\u30fc\u30bf\u70b9\u3068\u3057\u3066\u3001\u4e0a\u306e\u30b3\u30fc\u30c9\u3092\u8d70\u3089\u305b\u3066\u6df7\u5408\u5bc6\u5ea6\u30cd\u30c3\u30c8\u30ef\u30fc\u30af\u3092\u5b66\u7fd2\u3055\u305b\u305f\u7d50\u679c\u3001PRML\u306e\u56f35.21\u306e\u3088\u3046\u306a\u30b0\u30e9\u30d5\u306e\u518d\u73fe\u304c\u51fa\u6765\u307e\u3057\u305f\u3002\u305f\u3060\u3057\u3001\u7dda\u306e\u8272\u306a\u3069\u306f\u9055\u3046\u3053\u3068\u304c\u3042\u308a\u307e\u3059\u3002\uff13\u3064\u306e\u30ac\u30a6\u30b9\u5206\u5e03\u3001\u9752\u3001\u8d64\u3001\u7dd1\u3001\u306b\u3088\u3063\u3066\u30c8\u30ec\u30fc\u30cb\u30f3\u30b0\u30c7\u30fc\u30bf\u70b9\u306b\u30d5\u30a3\u30c3\u30c6\u30a3\u30f3\u30b0\u3055\u308c\u3066\u3044\u307e\u3059\u3002\n![result_weights.png](https://qiita-image-store.s3.amazonaws.com/0/148017/c26c21c0-7f1d-c7ae-d3c9-c8e598a76152.png)\n![result_means.png](https://qiita-image-store.s3.amazonaws.com/0/148017/1f5c2d34-6cc4-a46b-bd04-42dd3c5f982c.png)\n![result_distributions.png](https://qiita-image-store.s3.amazonaws.com/0/148017/4b7f43c5-b753-ca60-5b7a-806956057ecf.png)\n\n# \u5b66\u7fd2\u306e\u69d8\u5b50\n\u524d\u56de\u540c\u69d8\u3001\u5b66\u7fd2\u306e\u904e\u7a0b\u3092\u52d5\u753b\u306b\u3082\u3057\u3066\u307f\u307e\u3057\u305f\u3002\n![anime_gaussian_mixture.gif](https://qiita-image-store.s3.amazonaws.com/0/148017/0da2f7ee-2480-fb88-2df7-663905a655e8.gif)\n\n\n# \u7d42\u308f\u308a\u306b\n\u6df7\u5408\u5bc6\u5ea6\u30cd\u30c3\u30c8\u30ef\u30fc\u30af\u3068\u3044\u3046\u3082\u306e\u3092PRML\u3067\u8aad\u3080\u307e\u3067\u805e\u3044\u305f\u3053\u3068\u304c\u306a\u304b\u3063\u305f\u306e\u3067\u30cd\u30c3\u30c8\u3067\u691c\u7d22\u3057\u3066\u307f\u308b\u3068\u3001PRML\u306e\u8457\u8005C\u30fbM\u30fb\u30d3\u30b7\u30e7\u30c3\u30d7\u3055\u3093\u304c1994\u5e74\u306b\u66f8\u304b\u308c\u305f\u8ad6\u6587\u304c\u30d2\u30c3\u30c8\u3057\u305f\u306e\u3067\u3001\u3053\u306e\u4eba\u81ea\u8eab\u304c\u63d0\u5531\u3057\u305f\u3082\u306e\u306a\u306e\u304b\u3082\u3057\u308c\u307e\u305b\u3093\u3002\u6df7\u5408\u5bc6\u5ea6\u30cd\u30c3\u30c8\u30ef\u30fc\u30af\u306f\u591a\u5cf0\u6027\u306e\u3042\u308b\u3082\u306e\u306a\u3089\u5f93\u6765\u306e\u30e2\u30c7\u30eb\u3088\u308a\u6709\u52b9\u3060\u3068\u601d\u308f\u308c\u308b\u306e\u3067\u3001\u3053\u308c\u3092\u4f55\u3089\u304b\u306e\u5b9f\u30c7\u30fc\u30bf\u306b\u5bfe\u3057\u3066\u9069\u7528\u3057\u3066\u307f\u305f\u3044\u3082\u306e\u3067\u3059\u3002\n"}