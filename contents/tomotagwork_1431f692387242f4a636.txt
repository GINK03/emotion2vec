{"context": "\n\n\u306f\u3058\u3081\u306b\nApache Spark\u52c9\u5f37\u7528\u306b\u3001Windows\u4e0a\u306bSpark\u74b0\u5883\u4f5c\u3063\u3066\u30a2\u30d7\u30ea\u30b1\u30fc\u30b7\u30e7\u30f3(\u3068\u308a\u3042\u3048\u305aScala)\u3092\u4f5c\u6210/\u30b3\u30f3\u30d1\u30a4\u30eb/\u5b9f\u884c\u3059\u308b\u3001\u3068\u3044\u3046\u6240\u307e\u3067\u3084\u3063\u3066\u307f\u307e\u3059\u3002\n\u8272\u3005\u773a\u3081\u3066\u3044\u308b\u3068\u958b\u767a\u74b0\u5883\u3068\u3057\u3066\u306fIntelliJ, Eclipse\u3042\u305f\u308a\u304c\u4e3b\u6d41\u306a\u3088\u3046\u3067\u3059\u3002\u3042\u3068\u306fJupyter Notebook\uff1f \u5408\u308f\u305b\u3066\u30d3\u30eb\u30c9\u30c4\u30fc\u30eb\u3068\u3057\u3066sbt, maven\u306a\u3069\u304c\u4f7f\u308f\u308c\u305f\u308a\u3059\u308b\u3088\u3046\u3067\u3059\u3002\u304c\u3001\u7d20\u4eba\u306b\u306f\u521d\u30e2\u30ce\u306e\u8981\u7d20\u304c\u76db\u308a\u3060\u304f\u3055\u3093\u3059\u304e\u3066\u30a2\u30ef\u30a2\u30ef\u3057\u306f\u3058\u3081\u305f\u306e\u3067\u3001\u6700\u4f4e\u9650sbt\u3060\u3051\u4f7f\u3063\u3066\u307e\u305a\u306f\u52d5\u304b\u3059\u6240\u307e\u3067\u306e\u624b\u9806\u3092\u6574\u7406\u3057\u3066\u304a\u304d\u307e\u3059\u3002\n\n\u74b0\u5883\u69cb\u7bc9\n\nApache Spark\u306e\u30a4\u30f3\u30b9\u30c8\u30fc\u30eb\n\u3053\u306e\u8fba\u306e\u8a18\u4e8b\u3092\u53c2\u8003\u306bSpark\u3092\u30a4\u30f3\u30b9\u30c8\u30fc\u30eb\u3057\u307e\u3059\u3002\nSpark\u30a2\u30d7\u30ea\u30b1\u30fc\u30b7\u30e7\u30f3\u306e\u57fa\u672c\u3068\u3001\u306f\u3058\u3081\u306b\u62bc\u3055\u3048\u3066\u304a\u304d\u305f\u3044\u91cd\u8981\u306a\u6982\u5ff5\n\u307e\u305a\u306fApache\u306e\u30b5\u30a4\u30c8\u304b\u3089\u30c0\u30a6\u30f3\u30ed\u30fc\u30c9\u3002\nhttps://spark.apache.org/downloads.html\n2017\u5e742\u6708\u6642\u70b9\u3067\u306f2.1.0\u304c\u6700\u65b0\u3067\u3059\u304c\u3001\u30bf\u30fc\u30b2\u30c3\u30c8\u3068\u3059\u308b\u74b0\u5883\u306e\u90fd\u5408\u306b\u3088\u308a\u30012.0.2\u3092\u4f7f\u3044\u305f\u3044\u306e\u3067\u3001Spark\u306e\u30d0\u30fc\u30b8\u30e7\u30f3\u306f2.0.2\u3092\u9078\u629e\u3057\u3066tgz\u30d5\u30a1\u30a4\u30eb\u3092\u30c0\u30a6\u30f3\u30ed\u30fc\u30c9\u3057\u307e\u3059\u3002\n\n7zip\u306a\u3069\u3092\u4f7f\u3063\u3066\u3001\u914d\u7f6e\u5148\u306e\u30d5\u30a9\u30eb\u30c0\u306btgz\u3092\u5c55\u958b\u3057\u307e\u3059\u3002\n(\u4f8b\u3048\u3070\u3001C:\\x\\spark-2.0.2-bin-hadoop2.7\\\u306b\u5c55\u958b\u3057\u307e\u3059)\n\u5148\u306e\u30ea\u30f3\u30af\u5148\u306e\u8a18\u4e8b\u306b\u5f93\u3063\u3066\u3001\u4ee5\u4e0b\u304b\u3089winutils.exe\u3092\u30c0\u30a6\u30f3\u30ed\u30fc\u30c9\u3057\u307e\u3059\u3002\nhttps://github.com/steveloughran/winutils/blob/master/hadoop-2.7.1/bin/winutils.exe\n\u30c0\u30a6\u30f3\u30ed\u30fc\u30c9\u3057\u305fwinutils.exe\u306f\u3001Spark\u30a4\u30f3\u30b9\u30c8\u30fc\u30eb\u5148\\bin\u306b\u914d\u7f6e\u3057\u307e\u3059\u3002\n(C:\\x\\spark-2.0.2-bin-hadoop2.7\\bin\\winutils.exe)\n\n\u74b0\u5883\u5909\u6570\u8a2d\u5b9a\n\u4ee5\u4e0b\u306e\u74b0\u5883\u5909\u6570\u3092\u8a2d\u5b9a\u3057\u3066\u304a\u304f\u3068\u3088\u3044\u3067\u3057\u3087\u3046\u3002\n\nPATH: Spark\u30a4\u30f3\u30b9\u30c8\u30fc\u30eb\u5148\\bin(c:C:\\x\\spark-2.0.2-bin-hadoop2.7\\bin)\u3092\u8ffd\u52a0\nHADOOP_HOME: Spark\u30a4\u30f3\u30b9\u30c8\u30fc\u30eb\u5148 (C:\\x\\spark-2.0.2-bin-hadoop2.7)\n\n\n\u52d5\u4f5c\u78ba\u8a8d\n\u30a4\u30f3\u30b9\u30c8\u30fc\u30eb\u306e\u78ba\u8a8d\u7528\u306b\u3001spark shell\u3092\u52d5\u304b\u3057\u3066\u307f\u307e\u3059\u3002\n\u30b3\u30de\u30f3\u30c9\u30fb\u30d7\u30ed\u30f3\u30d7\u30c8\u3092\u958b\u3044\u3066\u3001spark-shell\u3092\u5b9f\u884c\u3057\u307e\u3059\u3002\nc:\\>spark-shell\nUsing Spark's default log4j profile: org/apache/spark/log4j-defaults.properties\nSetting default log level to \"WARN\".\nTo adjust logging level use sc.setLogLevel(newLevel).\n17/02/02 14:35:12 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java cl\nasses where applicable\n17/02/02 14:35:13 WARN SparkContext: Use an existing SparkContext, some configuration may not take effect.\nSpark context Web UI available at http://192.168.47.1:4040\nSpark context available as 'sc' (master = local[*], app id = local-1486013713576).\nSpark session available as 'spark'.\nWelcome to\n      ____              __\n     / __/__  ___ _____/ /__\n    _\\ \\/ _ \\/ _ `/ __/  '_/\n   /___/ .__/\\_,_/_/ /_/\\_\\   version 2.0.2\n      /_/\n\nUsing Scala version 2.11.8 (Java HotSpot(TM) 64-Bit Server VM, Java 1.8.0_112)\nType in expressions to have them evaluated.\nType :help for more information.\n\nscala> \n\nspark-shell\u304c\u8d77\u52d5\u3057\u307e\u3057\u305f\u3002\n\u7c21\u5358\u306a\u30b3\u30fc\u30c9\u3092\u5b9f\u884c\u3057\u3066\u307f\u307e\u3059\u3002\nscala> sc\nres0: org.apache.spark.SparkContext = org.apache.spark.SparkContext@240a2619\n\nscala> val test=sc.parallelize(List(\"str01\",\"str02\",\"str03\",\"str04\",\"str05\"))\ntest: org.apache.spark.rdd.RDD[String] = ParallelCollectionRDD[0] at parallelize at <console>:24\n\nscala> test.take(3).foreach(println)\nstr01\nstr02\nstr03\n\n\nspark-shell\u8d77\u52d5\u6642\u306b\u300cSpark context Web UI available at http://192.168.47.1:4040\u300d\u3068\u3044\u3046\u30e1\u30c3\u30bb\u30fc\u30b8\u304c\u3067\u3066\u3044\u307e\u3059\u3002\u3053\u306e\u30a2\u30c9\u30ec\u30b9\u306b\u30d6\u30e9\u30a6\u30b6\u304b\u3089\u30a2\u30af\u30bb\u30b9\u3059\u308b\u3068\u3001Web UI\u306b\u3066\u72b6\u6cc1\u78ba\u8a8d\u7b49\u884c\u3046\u3053\u3068\u304c\u3067\u304d\u307e\u3059\u3002\n\n\u4e00\u901a\u308a\u52d5\u3044\u3066\u3044\u308b\u3088\u3046\u306a\u306e\u3067\u3001\u4e00\u65e6spark-shell\u306f \u300c:quit\u300d\u3067\u629c\u3051\u307e\u3059\u3002\n\nsbt\u306e\u30a4\u30f3\u30b9\u30c8\u30fc\u30eb\n\u30b9\u30bf\u30f3\u30c9\u30fb\u30a2\u30ed\u30fc\u30f3\u306e\u30a2\u30d7\u30ea\u30b1\u30fc\u30b7\u30e7\u30f3\u3068\u3057\u3066Spark\u306e\u30b3\u30fc\u30c9\u3092\u52d5\u304b\u3057\u305f\u3044\u306e\u3067\u3001\u305d\u306e\u305f\u3081\u306e\u30d3\u30eb\u30c9\u30c4\u30fc\u30eb\u3092\u30a4\u30f3\u30b9\u30c8\u30fc\u30eb\u3057\u307e\u3059\u3002\u3053\u3053\u3067\u306f\u30d3\u30eb\u30c9\u30c4\u30fc\u30eb\u3068\u3057\u3066sbt\u3092\u4f7f\u3046\u3053\u3068\u306b\u3057\u307e\u3059\u3002\n\u53c2\u8003: sbt\n\u4e0a\u306e\u30b5\u30a4\u30c8\u304b\u3089\u306f\u898b\u3064\u3051\u3089\u308c\u306a\u304b\u3063\u305f\u304c\u3001sbt\u3068\u3044\u3046\u306e\u306f\u5642\u306b\u3088\u308b\u3068simple build tool\u306e\u7565\u3089\u3057\u3044\u3002\n\u30a4\u30f3\u30b9\u30c8\u30fc\u30eb\u306e\u624b\u9806\u306f\u3053\u3061\u3089\u3092\u53c2\u8003\u306b\u3002\nhttp://www.scala-sbt.org/release/docs/Manual-Installation.html\nWindows\u306e\u5834\u5408\u3001Cygwin\u3092\u4f7f\u3046\u65b9\u6cd5\u3068\u4f7f\u308f\u306a\u3044\u65b9\u6cd5\u304c\u3042\u308b\u3089\u3057\u3044\u304c\u3001\u3053\u3053\u3067\u306fCygwin\u4f7f\u308f\u306a\u3044\u65b9\u6cd5\u3092\u9078\u629e\u3057\u307e\u3059\u3002\n\u30a4\u30f3\u30b9\u30c8\u30fc\u30eb\u3068\u306f\u8a00\u3063\u3066\u3082\u3001sbt-launch.jar \u3092\u30b3\u30b3\u304b\u3089\u30c0\u30a6\u30f3\u30ed\u30fc\u30c9\u3057\u3066\u3001\u540c\u3058\u30d5\u30a9\u30eb\u30c0\u306b\u4ee5\u4e0b\u306e\u30d0\u30c3\u30c1\u3092\u4f5c\u6210\u3059\u308b\u3060\u3051\u3067\u3059\u3002\n\nsbt.bat\nset SCRIPT_DIR=%~dp0\njava -Xms512M -Xmx1536M -Xss1M -XX:+CMSClassUnloadingEnabled -XX:MaxPermSize=256M -jar \"%SCRIPT_DIR%sbt-launch.jar\" %*\n\n\n\u4f8b\u3048\u3070\u3001sbt.bat, sbt-launch.jar\u3092\u3001c:\\sbt\\bin \u306b\u914d\u7f6e\u3057\u3066\u3001\u3053\u306e\u30d1\u30b9\u3092PATH\u74b0\u5883\u5909\u6570\u306b\u8ffd\u52a0\u3059\u308c\u3070OK\u3067\u3059\u3002\n\n\u52d5\u4f5c\u78ba\u8a8d\n\u30b3\u30de\u30f3\u30c9\u30fb\u30d7\u30ed\u30f3\u30d7\u30c8\u304b\u3089\u3001sbt about\u30b3\u30de\u30f3\u30c9\u3092\u5b9f\u884c\u3057\u3066\u307f\u307e\u3059\u3002\nC:\\Users\\IBM_ADMIN>sbt about\n\nC:\\Users\\IBM_ADMIN>set SCRIPT_DIR=C:\\x\\sbt\\bin\\\n\nC:\\Users\\IBM_ADMIN>java -Xms512M -Xmx1536M -Xss1M -XX:+CMSClassUnloadingEnabled -XX:MaxPermSize=256M -jar \"C:\\x\\sbt\\bin\\\nsbt-launch.jar\" about\nJava HotSpot(TM) 64-Bit Server VM warning: ignoring option MaxPermSize=256M; support was removed in 8.0\n[info] Set current project to ibm_admin (in build file:/C:/Users/IBM_ADMIN/)\n[info] This is sbt 0.13.13\n[info] The current project is {file:/C:/Users/IBM_ADMIN/}ibm_admin 0.1-SNAPSHOT\n[info] The current project is built against Scala 2.10.6\n[info] Available Plugins: sbt.plugins.IvyPlugin, sbt.plugins.JvmPlugin, sbt.plugins.CorePlugin, sbt.plugins.JUnitXmlRepo\nrtPlugin, sbt.plugins.Giter8TemplatePlugin\n[info] sbt, sbt plugins, and build definitions are using Scala 2.10.6\n\n\n\u30d0\u30fc\u30b8\u30e7\u30f3\u60c5\u5831\u306a\u3069\u304c\u78ba\u8a8d\u3067\u304d\u308c\u3070OK\u3067\u3059\u3002\n\n\u30b5\u30f3\u30d7\u30eb\u30fb\u30a2\u30d7\u30ea\u30b1\u30fc\u30b7\u30e7\u30f3\n\n\u30a2\u30d7\u30ea\u30b1\u30fc\u30b7\u30e7\u30f3\u4f5c\u6210\n\u4ee5\u4e0b\u306e\u8a18\u8ff0\u3092\u53c2\u8003\u306b\u3001\u30b5\u30f3\u30d7\u30eb\u30fb\u30a2\u30d7\u30ea\u30b1\u30fc\u30b7\u30e7\u30f3\u3092\u4f5c\u6210\u3057\u3066\u52d5\u304b\u3057\u3066\u307f\u307e\u3059\u3002\nQuick Start  - Self-Contained Applications\nsbt\u3092\u4f7f\u3046\u5834\u5408\u3001\u30d5\u30a9\u30eb\u30c0\u306e\u69cb\u9020\u306b\u3042\u308b\u7a0b\u5ea6\u7e1b\u308a\u304c\u3042\u308b\u3088\u3046\u306a\u306e\u3067\u3001\u4e8b\u524d\u306b\u898f\u5247\u306b\u5f93\u3063\u305f\u30d5\u30a9\u30eb\u30c0\u69cb\u9020\u3092\u4f5c\u3063\u3066\u304a\u304d\u307e\u3059\u3002\n\u9069\u5f53\u306a\u30d5\u30a9\u30eb\u30c0(\u3053\u3053\u3067\u306fscala-test01)\u3092\u4f5c\u6210\u3057\u3066\u3001\u305d\u306e\u914d\u4e0b\u306b\u4ee5\u4e0b\u306e\u3088\u3046\u306a\u30d5\u30a9\u30eb\u30c0\u3092\u4f5c\u308a\u307e\u3059\u3002\n\nscala-test01\\src\\main\\scala\\\u306b\u3001\u30bd\u30fc\u30b9\u3092\u4f5c\u6210\u3057\u307e\u3059\u3002(\u4e0a\u306eQuick Start\u306e\u30ea\u30f3\u30af\u5148\u306b\u3042\u308b\u30bd\u30fc\u30b9\u306e\u30b5\u30f3\u30d7\u30eb\u3092\u30b3\u30d4\u30fc\u3057\u3066\u3001logFile\u306e\u6307\u5b9a\u90e8\u5206\u3060\u3051\u4fee\u6b63\u3002)\n\nSimpleApp.scala\n/* SimpleApp.scala */\nimport org.apache.spark.SparkContext\nimport org.apache.spark.SparkContext._\nimport org.apache.spark.SparkConf\n\nobject SimpleApp {\n  def main(args: Array[String]) {\n    val logFile = \"testData01/README.md\" // Should be some file on your system\n    val conf = new SparkConf().setAppName(\"Simple Application\")\n    val sc = new SparkContext(conf)\n    val logData = sc.textFile(logFile, 2).cache()\n    val numAs = logData.filter(line => line.contains(\"a\")).count()\n    val numBs = logData.filter(line => line.contains(\"b\")).count()\n    println(s\"Lines with a: $numAs, Lines with b: $numBs\")\n    sc.stop()\n  }\n}\n\n\ntestData01/README.md \u30d5\u30a1\u30a4\u30eb\u3092\u8aad\u307f\u8fbc\u3080\u3088\u3046\u306b\u3057\u3066\u3044\u308b\u306e\u3067\u3001\u3053\u306e\u30d1\u30b9\u306b\u30d5\u30a1\u30a4\u30eb\u3092\u914d\u7f6e\u3057\u307e\u3059\u3002\n(scala-test01\\testData01\u30d5\u30a9\u30eb\u30c0\u3092\u4f5c\u6210\u3057\u3066\u3001Spark\u5c0e\u5165\u6642\u306b\u63d0\u4f9b\u3055\u308c\u308bREMADME.md\u30d5\u30a1\u30a4\u30eb\u3092\u30b3\u30d4\u30fc\u3057\u307e\u3059\u3002)\nscala-test01\\\u306b\u3001sbt\u30d5\u30a1\u30a4\u30eb\u3092\u4f5c\u6210\u3057\u307e\u3059\u3002\n\nsimple.sbt\nname := \"SimpleProject01\"\n\nversion := \"1.0\"\n\nscalaVersion := \"2.11.8\"\n\nlibraryDependencies += \"org.apache.spark\" %% \"spark-core\" % \"2.0.2\"\n\n\n\u30c7\u30a3\u30ec\u30af\u30c8\u30ea\u3001\u30d5\u30a1\u30a4\u30eb\u306e\u69cb\u9020\u3092\u78ba\u8a8d\u3059\u308b\u3068\u4ee5\u4e0b\u306e\u3088\u3046\u306b\u306a\u3063\u3066\u3044\u307e\u3059\u3002\nc:\\y\\temp\\Spark\\scala-test01>dir /s\n \u30c9\u30e9\u30a4\u30d6 C \u306e\u30dc\u30ea\u30e5\u30fc\u30e0 \u30e9\u30d9\u30eb\u304c\u3042\u308a\u307e\u305b\u3093\u3002\n \u30dc\u30ea\u30e5\u30fc\u30e0 \u30b7\u30ea\u30a2\u30eb\u756a\u53f7\u306f A8F7-9750 \u3067\u3059\n\n c:\\y\\temp\\Spark\\scala-test01 \u306e\u30c7\u30a3\u30ec\u30af\u30c8\u30ea\n\n2017/02/02  16:21    <DIR>          .\n2017/02/02  16:21    <DIR>          ..\n2017/02/02  16:12               144 simple.sbt\n2017/02/02  15:20    <DIR>          src\n2017/02/02  16:19    <DIR>          testData01\n               1 \u500b\u306e\u30d5\u30a1\u30a4\u30eb                 144 \u30d0\u30a4\u30c8\n\n c:\\y\\temp\\Spark\\scala-test01\\src \u306e\u30c7\u30a3\u30ec\u30af\u30c8\u30ea\n\n2017/02/02  15:20    <DIR>          .\n2017/02/02  15:20    <DIR>          ..\n2017/02/02  15:20    <DIR>          main\n               0 \u500b\u306e\u30d5\u30a1\u30a4\u30eb                   0 \u30d0\u30a4\u30c8\n\n c:\\y\\temp\\Spark\\scala-test01\\src\\main \u306e\u30c7\u30a3\u30ec\u30af\u30c8\u30ea\n\n2017/02/02  15:20    <DIR>          .\n2017/02/02  15:20    <DIR>          ..\n2017/02/02  15:20    <DIR>          scala\n               0 \u500b\u306e\u30d5\u30a1\u30a4\u30eb                   0 \u30d0\u30a4\u30c8\n\n c:\\y\\temp\\Spark\\scala-test01\\src\\main\\scala \u306e\u30c7\u30a3\u30ec\u30af\u30c8\u30ea\n\n2017/02/02  15:20    <DIR>          .\n2017/02/02  15:20    <DIR>          ..\n2017/02/02  16:21               643 SimpleApp.scala\n               1 \u500b\u306e\u30d5\u30a1\u30a4\u30eb                 643 \u30d0\u30a4\u30c8\n\n c:\\y\\temp\\Spark\\scala-test01\\testData01 \u306e\u30c7\u30a3\u30ec\u30af\u30c8\u30ea\n\n2017/02/02  16:19    <DIR>          .\n2017/02/02  16:19    <DIR>          ..\n2016/11/08  10:58             3,828 README.md\n               1 \u500b\u306e\u30d5\u30a1\u30a4\u30eb               3,828 \u30d0\u30a4\u30c8\n\n     \u30d5\u30a1\u30a4\u30eb\u306e\u7dcf\u6570:\n               3 \u500b\u306e\u30d5\u30a1\u30a4\u30eb               4,615 \u30d0\u30a4\u30c8\n              14 \u500b\u306e\u30c7\u30a3\u30ec\u30af\u30c8\u30ea  65,465,180,160 \u30d0\u30a4\u30c8\u306e\u7a7a\u304d\u9818\u57df\n\n\n\u30b3\u30f3\u30d1\u30a4\u30eb\nscala-test01\\\u306b\u79fb\u52d5\u3057\u3001sbt package\u30b3\u30de\u30f3\u30c9\u3067\u30b3\u30f3\u30d1\u30a4\u30eb\u3057\u307e\u3059\u3002\nc:\\y\\temp\\Spark\\scala-test01>sbt package\n\nc:\\y\\temp\\Spark\\scala-test01>set SCRIPT_DIR=C:\\x\\sbt\\bin\\\n\nc:\\y\\temp\\Spark\\scala-test01>java -Xms512M -Xmx1536M -Xss1M -XX:+CMSClassUnloadingEnabled -XX:MaxPermSize=256M -jar \"C:\\\nx\\sbt\\bin\\sbt-launch.jar\" package\nJava HotSpot(TM) 64-Bit Server VM warning: ignoring option MaxPermSize=256M; support was removed in 8.0\n[info] Set current project to SimpleProject01 (in build file:/C:/y/temp/Spark/scala-test01/)\n[info] Updating {file:/C:/y/temp/Spark/scala-test01/}scala-test01...\n[info] Resolving jline#jline;2.12.1 ...\n[info] Done updating.\n[info] Compiling 1 Scala source to C:\\y\\temp\\Spark\\scala-test01\\target\\scala-2.11\\classes...\n[info] Packaging C:\\y\\temp\\Spark\\scala-test01\\target\\scala-2.11\\simpleproject01_2.11-1.0.jar ...\n[info] Done packaging.\n[success] Total time: 19 s, completed 2017/02/02 16:35:36\n\n1\u5ea6\u76ee\u306f\u5fc5\u8981\u306a\u30d5\u30a1\u30a4\u30eb\u304c\u8272\u3005\u30c0\u30a6\u30f3\u30ed\u30fc\u30c9\u3055\u308c\u308b\u306e\u3067\u6642\u9593\u304c\u304b\u304b\u308b\u304b\u3082\u3057\u308c\u307e\u305b\u3093\u3002\ntarget\\scala-2.11\\simpleproject01_2.11-1.0.jar \u306b\u30b3\u30f3\u30d1\u30a4\u30eb\u3055\u308c\u305f\u7d50\u679c\u306ejar\u304c\u751f\u6210\u3055\u308c\u307e\u3059\u3002\n\n\u5b9f\u884c\n\u30b3\u30f3\u30d1\u30a4\u30eb\u3055\u308c\u305f\u30a2\u30d7\u30ea\u30b1\u30fc\u30b7\u30e7\u30f3\u3092\u5b9f\u884c\u3057\u3066\u307f\u307e\u3059\u3002\nSpark\u306e\u30a2\u30d7\u30ea\u30b1\u30fc\u30b7\u30e7\u30f3\u3092\u5b9f\u884c\u3059\u308b\u969b\u306f\u3001Spark\u63d0\u4f9b\u306espark-submit\u30b3\u30de\u30f3\u30c9\u3092\u4f7f\u3044\u307e\u3059\u3002\nc:\\y\\temp\\Spark\\scala-test01>spark-submit --class SimpleApp --master local[*] target\\scala-2.11\\simpleproject01_2.11-1.0\n.jar\nUsing Spark's default log4j profile: org/apache/spark/log4j-defaults.properties\n17/02/02 16:47:51 INFO SparkContext: Running Spark version 2.0.2\n17/02/02 16:47:51 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java cl\nasses where applicable\n17/02/02 16:47:52 INFO SecurityManager: Changing view acls to: AHA00527\n17/02/02 16:47:52 INFO SecurityManager: Changing modify acls to: AHA00527\n17/02/02 16:47:52 INFO SecurityManager: Changing view acls groups to:\n17/02/02 16:47:52 INFO SecurityManager: Changing modify acls groups to:\n17/02/02 16:47:52 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users  with view per\nmissions: Set(AHA00527); groups with view permissions: Set(); users  with modify permissions: Set(AHA00527); groups with\n modify permissions: Set()\n17/02/02 16:47:52 INFO Utils: Successfully started service 'sparkDriver' on port 57316.\n17/02/02 16:47:52 INFO SparkEnv: Registering MapOutputTracker\n17/02/02 16:47:52 INFO SparkEnv: Registering BlockManagerMaster\n17/02/02 16:47:52 INFO DiskBlockManager: Created local directory at C:\\Users\\IBM_ADMIN\\AppData\\Local\\Temp\\blockmgr-68343\n452-a98d-4f76-af91-3554f86d5fff\n17/02/02 16:47:52 INFO MemoryStore: MemoryStore started with capacity 366.3 MB\n17/02/02 16:47:53 INFO SparkEnv: Registering OutputCommitCoordinator\n17/02/02 16:47:53 INFO Utils: Successfully started service 'SparkUI' on port 4040.\n17/02/02 16:47:53 INFO SparkUI: Bound SparkUI to 0.0.0.0, and started at http://192.168.47.1:4040\n17/02/02 16:47:53 INFO SparkContext: Added JAR file:/c:/y/temp/Spark/scala-test01/target/scala-2.11/simpleproject01_2.11\n-1.0.jar at spark://192.168.47.1:57316/jars/simpleproject01_2.11-1.0.jar with timestamp 1486021673260\n17/02/02 16:47:53 INFO Executor: Starting executor ID driver on host localhost\n17/02/02 16:47:53 INFO Utils: Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on\n port 57337.\n17/02/02 16:47:53 INFO NettyBlockTransferService: Server created on 192.168.47.1:57337\n17/02/02 16:47:53 INFO BlockManagerMaster: Registering BlockManager BlockManagerId(driver, 192.168.47.1, 57337)\n17/02/02 16:47:53 INFO BlockManagerMasterEndpoint: Registering block manager 192.168.47.1:57337 with 366.3 MB RAM, Block\nManagerId(driver, 192.168.47.1, 57337)\n17/02/02 16:47:53 INFO BlockManagerMaster: Registered BlockManager BlockManagerId(driver, 192.168.47.1, 57337)\n17/02/02 16:47:54 INFO MemoryStore: Block broadcast_0 stored as values in memory (estimated size 236.5 KB, free 366.1 MB\n)\n17/02/02 16:47:54 INFO MemoryStore: Block broadcast_0_piece0 stored as bytes in memory (estimated size 22.9 KB, free 366\n.0 MB)\n17/02/02 16:47:54 INFO BlockManagerInfo: Added broadcast_0_piece0 in memory on 192.168.47.1:57337 (size: 22.9 KB, free:\n366.3 MB)\n17/02/02 16:47:54 INFO SparkContext: Created broadcast 0 from textFile at SimpleApp.scala:11\n17/02/02 16:47:54 INFO FileInputFormat: Total input paths to process : 1\n17/02/02 16:47:54 INFO SparkContext: Starting job: count at SimpleApp.scala:12\n17/02/02 16:47:54 INFO DAGScheduler: Got job 0 (count at SimpleApp.scala:12) with 2 output partitions\n17/02/02 16:47:54 INFO DAGScheduler: Final stage: ResultStage 0 (count at SimpleApp.scala:12)\n17/02/02 16:47:54 INFO DAGScheduler: Parents of final stage: List()\n17/02/02 16:47:54 INFO DAGScheduler: Missing parents: List()\n17/02/02 16:47:54 INFO DAGScheduler: Submitting ResultStage 0 (MapPartitionsRDD[2] at filter at SimpleApp.scala:12), whi\nch has no missing parents\n17/02/02 16:47:54 INFO MemoryStore: Block broadcast_1 stored as values in memory (estimated size 3.1 KB, free 366.0 MB)\n17/02/02 16:47:54 INFO MemoryStore: Block broadcast_1_piece0 stored as bytes in memory (estimated size 1892.0 B, free 36\n6.0 MB)\n17/02/02 16:47:54 INFO BlockManagerInfo: Added broadcast_1_piece0 in memory on 192.168.47.1:57337 (size: 1892.0 B, free:\n 366.3 MB)\n17/02/02 16:47:54 INFO SparkContext: Created broadcast 1 from broadcast at DAGScheduler.scala:1012\n17/02/02 16:47:54 INFO DAGScheduler: Submitting 2 missing tasks from ResultStage 0 (MapPartitionsRDD[2] at filter at Sim\npleApp.scala:12)\n17/02/02 16:47:54 INFO TaskSchedulerImpl: Adding task set 0.0 with 2 tasks\n17/02/02 16:47:54 INFO TaskSetManager: Starting task 0.0 in stage 0.0 (TID 0, localhost, partition 0, PROCESS_LOCAL, 540\n8 bytes)\n17/02/02 16:47:54 INFO TaskSetManager: Starting task 1.0 in stage 0.0 (TID 1, localhost, partition 1, PROCESS_LOCAL, 540\n8 bytes)\n17/02/02 16:47:54 INFO Executor: Running task 0.0 in stage 0.0 (TID 0)\n17/02/02 16:47:54 INFO Executor: Running task 1.0 in stage 0.0 (TID 1)\n17/02/02 16:47:54 INFO Executor: Fetching spark://192.168.47.1:57316/jars/simpleproject01_2.11-1.0.jar with timestamp 14\n86021673260\n17/02/02 16:47:54 INFO TransportClientFactory: Successfully created connection to /192.168.47.1:57316 after 28 ms (0 ms\nspent in bootstraps)\n17/02/02 16:47:54 INFO Utils: Fetching spark://192.168.47.1:57316/jars/simpleproject01_2.11-1.0.jar to C:\\Users\\IBM_ADMI\nN\\AppData\\Local\\Temp\\spark-223955fa-cadd-4f8b-81a9-29404e141304\\userFiles-7459d042-01ce-4726-81a6-6380c7349084\\fetchFile\nTemp9218846672522341371.tmp\n17/02/02 16:47:55 INFO Executor: Adding file:/C:/Users/IBM_ADMIN/AppData/Local/Temp/spark-223955fa-cadd-4f8b-81a9-29404e\n141304/userFiles-7459d042-01ce-4726-81a6-6380c7349084/simpleproject01_2.11-1.0.jar to class loader\n17/02/02 16:47:55 INFO HadoopRDD: Input split: file:/c:/y/temp/Spark/scala-test01/testData01/README.md:0+1914\n17/02/02 16:47:55 INFO HadoopRDD: Input split: file:/c:/y/temp/Spark/scala-test01/testData01/README.md:1914+1914\n17/02/02 16:47:55 INFO deprecation: mapred.tip.id is deprecated. Instead, use mapreduce.task.id\n17/02/02 16:47:55 INFO deprecation: mapred.task.id is deprecated. Instead, use mapreduce.task.attempt.id\n17/02/02 16:47:55 INFO deprecation: mapred.task.is.map is deprecated. Instead, use mapreduce.task.ismap\n17/02/02 16:47:55 INFO deprecation: mapred.task.partition is deprecated. Instead, use mapreduce.task.partition\n17/02/02 16:47:55 INFO deprecation: mapred.job.id is deprecated. Instead, use mapreduce.job.id\n17/02/02 16:47:55 INFO MemoryStore: Block rdd_1_1 stored as values in memory (estimated size 5.7 KB, free 366.0 MB)\n17/02/02 16:47:55 INFO MemoryStore: Block rdd_1_0 stored as values in memory (estimated size 5.5 KB, free 366.0 MB)\n17/02/02 16:47:55 INFO BlockManagerInfo: Added rdd_1_1 in memory on 192.168.47.1:57337 (size: 5.7 KB, free: 366.3 MB)\n17/02/02 16:47:55 INFO BlockManagerInfo: Added rdd_1_0 in memory on 192.168.47.1:57337 (size: 5.5 KB, free: 366.3 MB)\n17/02/02 16:47:55 INFO Executor: Finished task 0.0 in stage 0.0 (TID 0). 1676 bytes result sent to driver\n17/02/02 16:47:55 INFO Executor: Finished task 1.0 in stage 0.0 (TID 1). 1676 bytes result sent to driver\n17/02/02 16:47:55 INFO TaskSetManager: Finished task 0.0 in stage 0.0 (TID 0) in 421 ms on localhost (1/2)\n17/02/02 16:47:55 INFO TaskSetManager: Finished task 1.0 in stage 0.0 (TID 1) in 390 ms on localhost (2/2)\n17/02/02 16:47:55 INFO TaskSchedulerImpl: Removed TaskSet 0.0, whose tasks have all completed, from pool\n17/02/02 16:47:55 INFO DAGScheduler: ResultStage 0 (count at SimpleApp.scala:12) finished in 0.437 s\n17/02/02 16:47:55 INFO DAGScheduler: Job 0 finished: count at SimpleApp.scala:12, took 0.630785 s\n17/02/02 16:47:55 INFO SparkContext: Starting job: count at SimpleApp.scala:13\n17/02/02 16:47:55 INFO DAGScheduler: Got job 1 (count at SimpleApp.scala:13) with 2 output partitions\n17/02/02 16:47:55 INFO DAGScheduler: Final stage: ResultStage 1 (count at SimpleApp.scala:13)\n17/02/02 16:47:55 INFO DAGScheduler: Parents of final stage: List()\n17/02/02 16:47:55 INFO DAGScheduler: Missing parents: List()\n17/02/02 16:47:55 INFO DAGScheduler: Submitting ResultStage 1 (MapPartitionsRDD[3] at filter at SimpleApp.scala:13), whi\nch has no missing parents\n17/02/02 16:47:55 INFO MemoryStore: Block broadcast_2 stored as values in memory (estimated size 3.1 KB, free 366.0 MB)\n17/02/02 16:47:55 INFO MemoryStore: Block broadcast_2_piece0 stored as bytes in memory (estimated size 1897.0 B, free 36\n6.0 MB)\n17/02/02 16:47:55 INFO BlockManagerInfo: Added broadcast_2_piece0 in memory on 192.168.47.1:57337 (size: 1897.0 B, free:\n 366.3 MB)\n17/02/02 16:47:55 INFO SparkContext: Created broadcast 2 from broadcast at DAGScheduler.scala:1012\n17/02/02 16:47:55 INFO DAGScheduler: Submitting 2 missing tasks from ResultStage 1 (MapPartitionsRDD[3] at filter at Sim\npleApp.scala:13)\n17/02/02 16:47:55 INFO TaskSchedulerImpl: Adding task set 1.0 with 2 tasks\n17/02/02 16:47:55 INFO TaskSetManager: Starting task 0.0 in stage 1.0 (TID 2, localhost, partition 0, PROCESS_LOCAL, 540\n8 bytes)\n17/02/02 16:47:55 INFO TaskSetManager: Starting task 1.0 in stage 1.0 (TID 3, localhost, partition 1, PROCESS_LOCAL, 540\n8 bytes)\n17/02/02 16:47:55 INFO Executor: Running task 0.0 in stage 1.0 (TID 2)\n17/02/02 16:47:55 INFO Executor: Running task 1.0 in stage 1.0 (TID 3)\n17/02/02 16:47:55 INFO BlockManager: Found block rdd_1_0 locally\n17/02/02 16:47:55 INFO BlockManager: Found block rdd_1_1 locally\n17/02/02 16:47:55 INFO Executor: Finished task 1.0 in stage 1.0 (TID 3). 875 bytes result sent to driver\n17/02/02 16:47:55 INFO Executor: Finished task 0.0 in stage 1.0 (TID 2). 867 bytes result sent to driver\n17/02/02 16:47:55 INFO TaskSetManager: Finished task 1.0 in stage 1.0 (TID 3) in 32 ms on localhost (1/2)\n17/02/02 16:47:55 INFO TaskSetManager: Finished task 0.0 in stage 1.0 (TID 2) in 32 ms on localhost (2/2)\n17/02/02 16:47:55 INFO TaskSchedulerImpl: Removed TaskSet 1.0, whose tasks have all completed, from pool\n17/02/02 16:47:55 INFO DAGScheduler: ResultStage 1 (count at SimpleApp.scala:13) finished in 0.032 s\n17/02/02 16:47:55 INFO DAGScheduler: Job 1 finished: count at SimpleApp.scala:13, took 0.071460 s\nLines with a: 61, Lines with b: 27\n17/02/02 16:47:55 INFO SparkUI: Stopped Spark web UI at http://192.168.47.1:4040\n17/02/02 16:47:55 INFO MapOutputTrackerMasterEndpoint: MapOutputTrackerMasterEndpoint stopped!\n17/02/02 16:47:55 INFO MemoryStore: MemoryStore cleared\n17/02/02 16:47:55 INFO BlockManager: BlockManager stopped\n17/02/02 16:47:55 INFO BlockManagerMaster: BlockManagerMaster stopped\n17/02/02 16:47:55 INFO OutputCommitCoordinator$OutputCommitCoordinatorEndpoint: OutputCommitCoordinator stopped!\n17/02/02 16:47:55 INFO SparkContext: Successfully stopped SparkContext\n17/02/02 16:47:55 INFO ShutdownHookManager: Shutdown hook called\n17/02/02 16:47:55 INFO ShutdownHookManager: Deleting directory C:\\Users\\IBM_ADMIN\\AppData\\Local\\Temp\\spark-223955fa-cadd\n-4f8b-81a9-29404e141304\n\n\n--class\u30aa\u30d7\u30b7\u30e7\u30f3\u3067\u306f\u5b9f\u884c\u3059\u308b\u30af\u30e9\u30b9\u540d\u3092\u6307\u5b9a\u3057\u307e\u3059\u3002\n--master\u30aa\u30d7\u30b7\u30e7\u30f3\u3067\u306f\u5b9f\u884c\u74b0\u5883\u3092\u6307\u5b9a\u3057\u307e\u3059\u3002(local[*]\u306e\u5834\u5408\u3001\u30ed\u30fc\u30ab\u30eb\u30e2\u30fc\u30c9\u3067\u30b9\u30ec\u30c3\u30c9\u6570\u306fCPU\u306e\u30b3\u30a2\u6570)\n\u6700\u5f8c\u306b\u30b3\u30f3\u30d1\u30a4\u30eb\u3057\u3066\u751f\u6210\u3055\u308c\u305fjar\u30d5\u30a1\u30a4\u30eb\u3092\u6307\u5b9a\u3057\u3066\u3044\u307e\u3059\u3002\n\u51fa\u529b\u7d50\u679c\u306fINFO\u306e\u30e1\u30c3\u30bb\u30fc\u30b8\u304c\u305f\u304f\u3055\u3093\u51fa\u3066\u3044\u3066\u898b\u306b\u304f\u3044\u3067\u3059\u304c\u3001\u6700\u5f8c\u304b\u308910\u884c\u76ee\u304f\u3089\u3044\u306b\u3001\u300cLines with a: 61, Lines with b: 27\u300d\u3068\u3044\u3046\u884c\u304c\u51fa\u529b\u3055\u308c\u3066\u3044\u307e\u3059\u3002\n\u3053\u308c\u304c\u3001\u30d7\u30ed\u30b0\u30e9\u30e0\u3067\u96c6\u8a08\u3057\u305f\u7d50\u679c\u3092\u51fa\u529b\u3057\u3066\u3044\u308b\u90e8\u5206\u3067\u3059\u3002\n(\u8aad\u307f\u8fbc\u3093\u3060\u30c6\u30ad\u30b9\u30c8\u30d5\u30a1\u30a4\u30eb\u304b\u3089\u3001\"a\"\u3092\u542b\u3080\u884c\u6570\u3068\u3001\"b\"\u3092\u542b\u3080\u884c\u6570\u3092\u30ab\u30a6\u30f3\u30c8\u3057\u3066\u51fa\u529b\u3057\u3066\u3044\u307e\u3059\u3002)\n\u3053\u308c\u3067\u4e00\u901a\u308a\u30a2\u30d7\u30ea\u30b1\u30fc\u30b7\u30e7\u30f3\u3092\u52d5\u304b\u3059\u6240\u307e\u3067\u78ba\u8a8d\u3067\u304d\u307e\u3057\u305f\u3002\n\n\u304a\u308f\u308a\u306b\n\u30d7\u30ed\u30b8\u30a7\u30af\u30c8\u306e\u7ba1\u7406\u3068\u304b\u30c7\u30d0\u30c3\u30b0\u3068\u304b\u958b\u767a\u30c4\u30fc\u30eb\u3092\u4f7f\u3063\u3066\u30b9\u30de\u30fc\u30c8\u306b\u3084\u308a\u305f\u3044\u306e\u3067\u3059\u304c\u3001IntelliJ\u306b\u3057\u308dEclipse\u306b\u3057\u308dJupyter Notebook\u306b\u3057\u308d\u3001\u306a\u304b\u306a\u304b\u30ed\u30fc\u30ab\u30eb\u306b\u74b0\u5883\u3092\u4f5c\u308d\u3046\u3068\u3057\u3066\u3082\u4e00\u7b4b\u7e04\u3067\u306f\u3044\u304b\u306a\u3044\u3053\u3068\u304c\u591a\u304f\u3001\u3061\u3087\u3063\u3068\u30cf\u30fc\u30c9\u30eb\u304c\u9ad8\u3044\u611f\u3058\u3067\u3059\u3002\u958b\u767a\u74b0\u5883\u3068\u3057\u3066\u4f55\u3092\u3069\u3046\u6574\u5099\u3059\u308b\u306e\u304c\u3088\u3044\u306e\u304b\u4eca\u3072\u3068\u3064\u81ea\u5206\u306a\u308a\u306e\u6b63\u89e3\u304c\u898b\u3064\u3051\u3089\u308c\u3066\u3044\u307e\u305b\u3093\u3002\u305d\u306e\u8fba\u306f\u60a9\u307f\u306a\u304c\u3089\u307c\u3061\u307c\u3061\u3084\u3063\u3066\u3044\u3053\u3046\u3068\u601d\u3044\u307e\u3059\u3002\n#\u306f\u3058\u3081\u306b\nApache Spark\u52c9\u5f37\u7528\u306b\u3001Windows\u4e0a\u306bSpark\u74b0\u5883\u4f5c\u3063\u3066\u30a2\u30d7\u30ea\u30b1\u30fc\u30b7\u30e7\u30f3(\u3068\u308a\u3042\u3048\u305aScala)\u3092\u4f5c\u6210/\u30b3\u30f3\u30d1\u30a4\u30eb/\u5b9f\u884c\u3059\u308b\u3001\u3068\u3044\u3046\u6240\u307e\u3067\u3084\u3063\u3066\u307f\u307e\u3059\u3002\n\u8272\u3005\u773a\u3081\u3066\u3044\u308b\u3068\u958b\u767a\u74b0\u5883\u3068\u3057\u3066\u306fIntelliJ, Eclipse\u3042\u305f\u308a\u304c\u4e3b\u6d41\u306a\u3088\u3046\u3067\u3059\u3002\u3042\u3068\u306fJupyter Notebook\uff1f \u5408\u308f\u305b\u3066\u30d3\u30eb\u30c9\u30c4\u30fc\u30eb\u3068\u3057\u3066sbt, maven\u306a\u3069\u304c\u4f7f\u308f\u308c\u305f\u308a\u3059\u308b\u3088\u3046\u3067\u3059\u3002\u304c\u3001\u7d20\u4eba\u306b\u306f\u521d\u30e2\u30ce\u306e\u8981\u7d20\u304c\u76db\u308a\u3060\u304f\u3055\u3093\u3059\u304e\u3066\u30a2\u30ef\u30a2\u30ef\u3057\u306f\u3058\u3081\u305f\u306e\u3067\u3001\u6700\u4f4e\u9650sbt\u3060\u3051\u4f7f\u3063\u3066\u307e\u305a\u306f\u52d5\u304b\u3059\u6240\u307e\u3067\u306e\u624b\u9806\u3092\u6574\u7406\u3057\u3066\u304a\u304d\u307e\u3059\u3002\n\n#\u74b0\u5883\u69cb\u7bc9\n##Apache Spark\u306e\u30a4\u30f3\u30b9\u30c8\u30fc\u30eb\n\u3053\u306e\u8fba\u306e\u8a18\u4e8b\u3092\u53c2\u8003\u306bSpark\u3092\u30a4\u30f3\u30b9\u30c8\u30fc\u30eb\u3057\u307e\u3059\u3002\n[Spark\u30a2\u30d7\u30ea\u30b1\u30fc\u30b7\u30e7\u30f3\u306e\u57fa\u672c\u3068\u3001\u306f\u3058\u3081\u306b\u62bc\u3055\u3048\u3066\u304a\u304d\u305f\u3044\u91cd\u8981\u306a\u6982\u5ff5](http://codezine.jp/article/detail/9347)\n\n\u307e\u305a\u306fApache\u306e\u30b5\u30a4\u30c8\u304b\u3089\u30c0\u30a6\u30f3\u30ed\u30fc\u30c9\u3002\nhttps://spark.apache.org/downloads.html\n\n2017\u5e742\u6708\u6642\u70b9\u3067\u306f2.1.0\u304c\u6700\u65b0\u3067\u3059\u304c\u3001\u30bf\u30fc\u30b2\u30c3\u30c8\u3068\u3059\u308b\u74b0\u5883\u306e\u90fd\u5408\u306b\u3088\u308a\u30012.0.2\u3092\u4f7f\u3044\u305f\u3044\u306e\u3067\u3001Spark\u306e\u30d0\u30fc\u30b8\u30e7\u30f3\u306f2.0.2\u3092\u9078\u629e\u3057\u3066tgz\u30d5\u30a1\u30a4\u30eb\u3092\u30c0\u30a6\u30f3\u30ed\u30fc\u30c9\u3057\u307e\u3059\u3002\n![image01.jpg](https://qiita-image-store.s3.amazonaws.com/0/132331/5fc0bf80-3b94-2494-54e3-ae2514aa9fab.jpeg)\n\n7zip\u306a\u3069\u3092\u4f7f\u3063\u3066\u3001\u914d\u7f6e\u5148\u306e\u30d5\u30a9\u30eb\u30c0\u306btgz\u3092\u5c55\u958b\u3057\u307e\u3059\u3002\n(\u4f8b\u3048\u3070\u3001C:\\x\\spark-2.0.2-bin-hadoop2.7\\\u306b\u5c55\u958b\u3057\u307e\u3059)\n\n\u5148\u306e\u30ea\u30f3\u30af\u5148\u306e\u8a18\u4e8b\u306b\u5f93\u3063\u3066\u3001\u4ee5\u4e0b\u304b\u3089winutils.exe\u3092\u30c0\u30a6\u30f3\u30ed\u30fc\u30c9\u3057\u307e\u3059\u3002\nhttps://github.com/steveloughran/winutils/blob/master/hadoop-2.7.1/bin/winutils.exe\n\n\u30c0\u30a6\u30f3\u30ed\u30fc\u30c9\u3057\u305fwinutils.exe\u306f\u3001Spark\u30a4\u30f3\u30b9\u30c8\u30fc\u30eb\u5148\\bin\u306b\u914d\u7f6e\u3057\u307e\u3059\u3002\n(C:\\x\\spark-2.0.2-bin-hadoop2.7\\bin\\winutils.exe)\n\n###\u74b0\u5883\u5909\u6570\u8a2d\u5b9a\n\u4ee5\u4e0b\u306e\u74b0\u5883\u5909\u6570\u3092\u8a2d\u5b9a\u3057\u3066\u304a\u304f\u3068\u3088\u3044\u3067\u3057\u3087\u3046\u3002\n\n* PATH: Spark\u30a4\u30f3\u30b9\u30c8\u30fc\u30eb\u5148\\bin(c:C:\\x\\spark-2.0.2-bin-hadoop2.7\\bin)\u3092\u8ffd\u52a0\n* HADOOP_HOME: Spark\u30a4\u30f3\u30b9\u30c8\u30fc\u30eb\u5148 (C:\\x\\spark-2.0.2-bin-hadoop2.7)\n\n###\u52d5\u4f5c\u78ba\u8a8d\n\u30a4\u30f3\u30b9\u30c8\u30fc\u30eb\u306e\u78ba\u8a8d\u7528\u306b\u3001spark shell\u3092\u52d5\u304b\u3057\u3066\u307f\u307e\u3059\u3002\n\u30b3\u30de\u30f3\u30c9\u30fb\u30d7\u30ed\u30f3\u30d7\u30c8\u3092\u958b\u3044\u3066\u3001spark-shell\u3092\u5b9f\u884c\u3057\u307e\u3059\u3002\n\n```\nc:\\>spark-shell\nUsing Spark's default log4j profile: org/apache/spark/log4j-defaults.properties\nSetting default log level to \"WARN\".\nTo adjust logging level use sc.setLogLevel(newLevel).\n17/02/02 14:35:12 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java cl\nasses where applicable\n17/02/02 14:35:13 WARN SparkContext: Use an existing SparkContext, some configuration may not take effect.\nSpark context Web UI available at http://192.168.47.1:4040\nSpark context available as 'sc' (master = local[*], app id = local-1486013713576).\nSpark session available as 'spark'.\nWelcome to\n      ____              __\n     / __/__  ___ _____/ /__\n    _\\ \\/ _ \\/ _ `/ __/  '_/\n   /___/ .__/\\_,_/_/ /_/\\_\\   version 2.0.2\n      /_/\n\nUsing Scala version 2.11.8 (Java HotSpot(TM) 64-Bit Server VM, Java 1.8.0_112)\nType in expressions to have them evaluated.\nType :help for more information.\n\nscala> \n```\n\nspark-shell\u304c\u8d77\u52d5\u3057\u307e\u3057\u305f\u3002\n\u7c21\u5358\u306a\u30b3\u30fc\u30c9\u3092\u5b9f\u884c\u3057\u3066\u307f\u307e\u3059\u3002\n\n```\nscala> sc\nres0: org.apache.spark.SparkContext = org.apache.spark.SparkContext@240a2619\n\nscala> val test=sc.parallelize(List(\"str01\",\"str02\",\"str03\",\"str04\",\"str05\"))\ntest: org.apache.spark.rdd.RDD[String] = ParallelCollectionRDD[0] at parallelize at <console>:24\n\nscala> test.take(3).foreach(println)\nstr01\nstr02\nstr03\n\n```\n\nspark-shell\u8d77\u52d5\u6642\u306b\u300cSpark context Web UI available at http://192.168.47.1:4040\u300d\u3068\u3044\u3046\u30e1\u30c3\u30bb\u30fc\u30b8\u304c\u3067\u3066\u3044\u307e\u3059\u3002\u3053\u306e\u30a2\u30c9\u30ec\u30b9\u306b\u30d6\u30e9\u30a6\u30b6\u304b\u3089\u30a2\u30af\u30bb\u30b9\u3059\u308b\u3068\u3001Web UI\u306b\u3066\u72b6\u6cc1\u78ba\u8a8d\u7b49\u884c\u3046\u3053\u3068\u304c\u3067\u304d\u307e\u3059\u3002\n![image02.jpg](https://qiita-image-store.s3.amazonaws.com/0/132331/00a11e33-6015-a914-1cf0-eb825d1ecbd1.jpeg)\n\n\u4e00\u901a\u308a\u52d5\u3044\u3066\u3044\u308b\u3088\u3046\u306a\u306e\u3067\u3001\u4e00\u65e6spark-shell\u306f \u300c:quit\u300d\u3067\u629c\u3051\u307e\u3059\u3002\n\n##sbt\u306e\u30a4\u30f3\u30b9\u30c8\u30fc\u30eb\n\n\u30b9\u30bf\u30f3\u30c9\u30fb\u30a2\u30ed\u30fc\u30f3\u306e\u30a2\u30d7\u30ea\u30b1\u30fc\u30b7\u30e7\u30f3\u3068\u3057\u3066Spark\u306e\u30b3\u30fc\u30c9\u3092\u52d5\u304b\u3057\u305f\u3044\u306e\u3067\u3001\u305d\u306e\u305f\u3081\u306e\u30d3\u30eb\u30c9\u30c4\u30fc\u30eb\u3092\u30a4\u30f3\u30b9\u30c8\u30fc\u30eb\u3057\u307e\u3059\u3002\u3053\u3053\u3067\u306f\u30d3\u30eb\u30c9\u30c4\u30fc\u30eb\u3068\u3057\u3066sbt\u3092\u4f7f\u3046\u3053\u3068\u306b\u3057\u307e\u3059\u3002\n\n\u53c2\u8003: [sbt](http://www.scala-sbt.org/index.html)\n\n\u4e0a\u306e\u30b5\u30a4\u30c8\u304b\u3089\u306f\u898b\u3064\u3051\u3089\u308c\u306a\u304b\u3063\u305f\u304c\u3001sbt\u3068\u3044\u3046\u306e\u306f\u5642\u306b\u3088\u308b\u3068simple build tool\u306e\u7565\u3089\u3057\u3044\u3002\n\n\u30a4\u30f3\u30b9\u30c8\u30fc\u30eb\u306e\u624b\u9806\u306f\u3053\u3061\u3089\u3092\u53c2\u8003\u306b\u3002\nhttp://www.scala-sbt.org/release/docs/Manual-Installation.html\n\nWindows\u306e\u5834\u5408\u3001Cygwin\u3092\u4f7f\u3046\u65b9\u6cd5\u3068\u4f7f\u308f\u306a\u3044\u65b9\u6cd5\u304c\u3042\u308b\u3089\u3057\u3044\u304c\u3001\u3053\u3053\u3067\u306fCygwin\u4f7f\u308f\u306a\u3044\u65b9\u6cd5\u3092\u9078\u629e\u3057\u307e\u3059\u3002\n\n\u30a4\u30f3\u30b9\u30c8\u30fc\u30eb\u3068\u306f\u8a00\u3063\u3066\u3082\u3001sbt-launch.jar \u3092[\u30b3\u30b3](https://repo.typesafe.com/typesafe/ivy-releases/org.scala-sbt/sbt-launch/0.13.13/sbt-launch.jar)\u304b\u3089\u30c0\u30a6\u30f3\u30ed\u30fc\u30c9\u3057\u3066\u3001\u540c\u3058\u30d5\u30a9\u30eb\u30c0\u306b\u4ee5\u4e0b\u306e\u30d0\u30c3\u30c1\u3092\u4f5c\u6210\u3059\u308b\u3060\u3051\u3067\u3059\u3002\n\n```bat:sbt.bat\nset SCRIPT_DIR=%~dp0\njava -Xms512M -Xmx1536M -Xss1M -XX:+CMSClassUnloadingEnabled -XX:MaxPermSize=256M -jar \"%SCRIPT_DIR%sbt-launch.jar\" %*\n```\n\n\u4f8b\u3048\u3070\u3001sbt.bat, sbt-launch.jar\u3092\u3001c:\\sbt\\bin \u306b\u914d\u7f6e\u3057\u3066\u3001\u3053\u306e\u30d1\u30b9\u3092PATH\u74b0\u5883\u5909\u6570\u306b\u8ffd\u52a0\u3059\u308c\u3070OK\u3067\u3059\u3002\n\n###\u52d5\u4f5c\u78ba\u8a8d\n\u30b3\u30de\u30f3\u30c9\u30fb\u30d7\u30ed\u30f3\u30d7\u30c8\u304b\u3089\u3001```sbt about```\u30b3\u30de\u30f3\u30c9\u3092\u5b9f\u884c\u3057\u3066\u307f\u307e\u3059\u3002\n\n```\nC:\\Users\\IBM_ADMIN>sbt about\n\nC:\\Users\\IBM_ADMIN>set SCRIPT_DIR=C:\\x\\sbt\\bin\\\n\nC:\\Users\\IBM_ADMIN>java -Xms512M -Xmx1536M -Xss1M -XX:+CMSClassUnloadingEnabled -XX:MaxPermSize=256M -jar \"C:\\x\\sbt\\bin\\\nsbt-launch.jar\" about\nJava HotSpot(TM) 64-Bit Server VM warning: ignoring option MaxPermSize=256M; support was removed in 8.0\n[info] Set current project to ibm_admin (in build file:/C:/Users/IBM_ADMIN/)\n[info] This is sbt 0.13.13\n[info] The current project is {file:/C:/Users/IBM_ADMIN/}ibm_admin 0.1-SNAPSHOT\n[info] The current project is built against Scala 2.10.6\n[info] Available Plugins: sbt.plugins.IvyPlugin, sbt.plugins.JvmPlugin, sbt.plugins.CorePlugin, sbt.plugins.JUnitXmlRepo\nrtPlugin, sbt.plugins.Giter8TemplatePlugin\n[info] sbt, sbt plugins, and build definitions are using Scala 2.10.6\n\n```\n\n\u30d0\u30fc\u30b8\u30e7\u30f3\u60c5\u5831\u306a\u3069\u304c\u78ba\u8a8d\u3067\u304d\u308c\u3070OK\u3067\u3059\u3002\n\n#\u30b5\u30f3\u30d7\u30eb\u30fb\u30a2\u30d7\u30ea\u30b1\u30fc\u30b7\u30e7\u30f3\n##\u30a2\u30d7\u30ea\u30b1\u30fc\u30b7\u30e7\u30f3\u4f5c\u6210\n\u4ee5\u4e0b\u306e\u8a18\u8ff0\u3092\u53c2\u8003\u306b\u3001\u30b5\u30f3\u30d7\u30eb\u30fb\u30a2\u30d7\u30ea\u30b1\u30fc\u30b7\u30e7\u30f3\u3092\u4f5c\u6210\u3057\u3066\u52d5\u304b\u3057\u3066\u307f\u307e\u3059\u3002\n[Quick Start  - Self-Contained Applications](https://spark.apache.org/docs/2.0.2/quick-start.html#self-contained-applications)\n\nsbt\u3092\u4f7f\u3046\u5834\u5408\u3001\u30d5\u30a9\u30eb\u30c0\u306e\u69cb\u9020\u306b\u3042\u308b\u7a0b\u5ea6\u7e1b\u308a\u304c\u3042\u308b\u3088\u3046\u306a\u306e\u3067\u3001\u4e8b\u524d\u306b\u898f\u5247\u306b\u5f93\u3063\u305f\u30d5\u30a9\u30eb\u30c0\u69cb\u9020\u3092\u4f5c\u3063\u3066\u304a\u304d\u307e\u3059\u3002\n\u9069\u5f53\u306a\u30d5\u30a9\u30eb\u30c0(\u3053\u3053\u3067\u306fscala-test01)\u3092\u4f5c\u6210\u3057\u3066\u3001\u305d\u306e\u914d\u4e0b\u306b\u4ee5\u4e0b\u306e\u3088\u3046\u306a\u30d5\u30a9\u30eb\u30c0\u3092\u4f5c\u308a\u307e\u3059\u3002\n\n![image03.JPG](https://qiita-image-store.s3.amazonaws.com/0/132331/b954256b-0d69-2941-8ae1-eec1389005c0.jpeg)\n\nscala-test01\\src\\main\\scala\\\u306b\u3001\u30bd\u30fc\u30b9\u3092\u4f5c\u6210\u3057\u307e\u3059\u3002(\u4e0a\u306eQuick Start\u306e\u30ea\u30f3\u30af\u5148\u306b\u3042\u308b\u30bd\u30fc\u30b9\u306e\u30b5\u30f3\u30d7\u30eb\u3092\u30b3\u30d4\u30fc\u3057\u3066\u3001logFile\u306e\u6307\u5b9a\u90e8\u5206\u3060\u3051\u4fee\u6b63\u3002)\n\n```scala:SimpleApp.scala\n/* SimpleApp.scala */\nimport org.apache.spark.SparkContext\nimport org.apache.spark.SparkContext._\nimport org.apache.spark.SparkConf\n\nobject SimpleApp {\n  def main(args: Array[String]) {\n    val logFile = \"testData01/README.md\" // Should be some file on your system\n    val conf = new SparkConf().setAppName(\"Simple Application\")\n    val sc = new SparkContext(conf)\n    val logData = sc.textFile(logFile, 2).cache()\n    val numAs = logData.filter(line => line.contains(\"a\")).count()\n    val numBs = logData.filter(line => line.contains(\"b\")).count()\n    println(s\"Lines with a: $numAs, Lines with b: $numBs\")\n    sc.stop()\n  }\n}\n```\n\ntestData01/README.md \u30d5\u30a1\u30a4\u30eb\u3092\u8aad\u307f\u8fbc\u3080\u3088\u3046\u306b\u3057\u3066\u3044\u308b\u306e\u3067\u3001\u3053\u306e\u30d1\u30b9\u306b\u30d5\u30a1\u30a4\u30eb\u3092\u914d\u7f6e\u3057\u307e\u3059\u3002\n(scala-test01\\testData01\u30d5\u30a9\u30eb\u30c0\u3092\u4f5c\u6210\u3057\u3066\u3001Spark\u5c0e\u5165\u6642\u306b\u63d0\u4f9b\u3055\u308c\u308bREMADME.md\u30d5\u30a1\u30a4\u30eb\u3092\u30b3\u30d4\u30fc\u3057\u307e\u3059\u3002)\n\nscala-test01\\\u306b\u3001sbt\u30d5\u30a1\u30a4\u30eb\u3092\u4f5c\u6210\u3057\u307e\u3059\u3002\n\n```sbt:simple.sbt\nname := \"SimpleProject01\"\n\nversion := \"1.0\"\n\nscalaVersion := \"2.11.8\"\n\nlibraryDependencies += \"org.apache.spark\" %% \"spark-core\" % \"2.0.2\"\n```\n\n\u30c7\u30a3\u30ec\u30af\u30c8\u30ea\u3001\u30d5\u30a1\u30a4\u30eb\u306e\u69cb\u9020\u3092\u78ba\u8a8d\u3059\u308b\u3068\u4ee5\u4e0b\u306e\u3088\u3046\u306b\u306a\u3063\u3066\u3044\u307e\u3059\u3002\n\n```\nc:\\y\\temp\\Spark\\scala-test01>dir /s\n \u30c9\u30e9\u30a4\u30d6 C \u306e\u30dc\u30ea\u30e5\u30fc\u30e0 \u30e9\u30d9\u30eb\u304c\u3042\u308a\u307e\u305b\u3093\u3002\n \u30dc\u30ea\u30e5\u30fc\u30e0 \u30b7\u30ea\u30a2\u30eb\u756a\u53f7\u306f A8F7-9750 \u3067\u3059\n\n c:\\y\\temp\\Spark\\scala-test01 \u306e\u30c7\u30a3\u30ec\u30af\u30c8\u30ea\n\n2017/02/02  16:21    <DIR>          .\n2017/02/02  16:21    <DIR>          ..\n2017/02/02  16:12               144 simple.sbt\n2017/02/02  15:20    <DIR>          src\n2017/02/02  16:19    <DIR>          testData01\n               1 \u500b\u306e\u30d5\u30a1\u30a4\u30eb                 144 \u30d0\u30a4\u30c8\n\n c:\\y\\temp\\Spark\\scala-test01\\src \u306e\u30c7\u30a3\u30ec\u30af\u30c8\u30ea\n\n2017/02/02  15:20    <DIR>          .\n2017/02/02  15:20    <DIR>          ..\n2017/02/02  15:20    <DIR>          main\n               0 \u500b\u306e\u30d5\u30a1\u30a4\u30eb                   0 \u30d0\u30a4\u30c8\n\n c:\\y\\temp\\Spark\\scala-test01\\src\\main \u306e\u30c7\u30a3\u30ec\u30af\u30c8\u30ea\n\n2017/02/02  15:20    <DIR>          .\n2017/02/02  15:20    <DIR>          ..\n2017/02/02  15:20    <DIR>          scala\n               0 \u500b\u306e\u30d5\u30a1\u30a4\u30eb                   0 \u30d0\u30a4\u30c8\n\n c:\\y\\temp\\Spark\\scala-test01\\src\\main\\scala \u306e\u30c7\u30a3\u30ec\u30af\u30c8\u30ea\n\n2017/02/02  15:20    <DIR>          .\n2017/02/02  15:20    <DIR>          ..\n2017/02/02  16:21               643 SimpleApp.scala\n               1 \u500b\u306e\u30d5\u30a1\u30a4\u30eb                 643 \u30d0\u30a4\u30c8\n\n c:\\y\\temp\\Spark\\scala-test01\\testData01 \u306e\u30c7\u30a3\u30ec\u30af\u30c8\u30ea\n\n2017/02/02  16:19    <DIR>          .\n2017/02/02  16:19    <DIR>          ..\n2016/11/08  10:58             3,828 README.md\n               1 \u500b\u306e\u30d5\u30a1\u30a4\u30eb               3,828 \u30d0\u30a4\u30c8\n\n     \u30d5\u30a1\u30a4\u30eb\u306e\u7dcf\u6570:\n               3 \u500b\u306e\u30d5\u30a1\u30a4\u30eb               4,615 \u30d0\u30a4\u30c8\n              14 \u500b\u306e\u30c7\u30a3\u30ec\u30af\u30c8\u30ea  65,465,180,160 \u30d0\u30a4\u30c8\u306e\u7a7a\u304d\u9818\u57df\n```\n\n##\u30b3\u30f3\u30d1\u30a4\u30eb\n\nscala-test01\\\u306b\u79fb\u52d5\u3057\u3001sbt package\u30b3\u30de\u30f3\u30c9\u3067\u30b3\u30f3\u30d1\u30a4\u30eb\u3057\u307e\u3059\u3002\n\n```\nc:\\y\\temp\\Spark\\scala-test01>sbt package\n\nc:\\y\\temp\\Spark\\scala-test01>set SCRIPT_DIR=C:\\x\\sbt\\bin\\\n\nc:\\y\\temp\\Spark\\scala-test01>java -Xms512M -Xmx1536M -Xss1M -XX:+CMSClassUnloadingEnabled -XX:MaxPermSize=256M -jar \"C:\\\nx\\sbt\\bin\\sbt-launch.jar\" package\nJava HotSpot(TM) 64-Bit Server VM warning: ignoring option MaxPermSize=256M; support was removed in 8.0\n[info] Set current project to SimpleProject01 (in build file:/C:/y/temp/Spark/scala-test01/)\n[info] Updating {file:/C:/y/temp/Spark/scala-test01/}scala-test01...\n[info] Resolving jline#jline;2.12.1 ...\n[info] Done updating.\n[info] Compiling 1 Scala source to C:\\y\\temp\\Spark\\scala-test01\\target\\scala-2.11\\classes...\n[info] Packaging C:\\y\\temp\\Spark\\scala-test01\\target\\scala-2.11\\simpleproject01_2.11-1.0.jar ...\n[info] Done packaging.\n[success] Total time: 19 s, completed 2017/02/02 16:35:36\n```\n\n1\u5ea6\u76ee\u306f\u5fc5\u8981\u306a\u30d5\u30a1\u30a4\u30eb\u304c\u8272\u3005\u30c0\u30a6\u30f3\u30ed\u30fc\u30c9\u3055\u308c\u308b\u306e\u3067\u6642\u9593\u304c\u304b\u304b\u308b\u304b\u3082\u3057\u308c\u307e\u305b\u3093\u3002\ntarget\\scala-2.11\\simpleproject01_2.11-1.0.jar \u306b\u30b3\u30f3\u30d1\u30a4\u30eb\u3055\u308c\u305f\u7d50\u679c\u306ejar\u304c\u751f\u6210\u3055\u308c\u307e\u3059\u3002\n\n##\u5b9f\u884c\n\n\u30b3\u30f3\u30d1\u30a4\u30eb\u3055\u308c\u305f\u30a2\u30d7\u30ea\u30b1\u30fc\u30b7\u30e7\u30f3\u3092\u5b9f\u884c\u3057\u3066\u307f\u307e\u3059\u3002\nSpark\u306e\u30a2\u30d7\u30ea\u30b1\u30fc\u30b7\u30e7\u30f3\u3092\u5b9f\u884c\u3059\u308b\u969b\u306f\u3001Spark\u63d0\u4f9b\u306espark-submit\u30b3\u30de\u30f3\u30c9\u3092\u4f7f\u3044\u307e\u3059\u3002\n\n```\nc:\\y\\temp\\Spark\\scala-test01>spark-submit --class SimpleApp --master local[*] target\\scala-2.11\\simpleproject01_2.11-1.0\n.jar\nUsing Spark's default log4j profile: org/apache/spark/log4j-defaults.properties\n17/02/02 16:47:51 INFO SparkContext: Running Spark version 2.0.2\n17/02/02 16:47:51 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java cl\nasses where applicable\n17/02/02 16:47:52 INFO SecurityManager: Changing view acls to: AHA00527\n17/02/02 16:47:52 INFO SecurityManager: Changing modify acls to: AHA00527\n17/02/02 16:47:52 INFO SecurityManager: Changing view acls groups to:\n17/02/02 16:47:52 INFO SecurityManager: Changing modify acls groups to:\n17/02/02 16:47:52 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users  with view per\nmissions: Set(AHA00527); groups with view permissions: Set(); users  with modify permissions: Set(AHA00527); groups with\n modify permissions: Set()\n17/02/02 16:47:52 INFO Utils: Successfully started service 'sparkDriver' on port 57316.\n17/02/02 16:47:52 INFO SparkEnv: Registering MapOutputTracker\n17/02/02 16:47:52 INFO SparkEnv: Registering BlockManagerMaster\n17/02/02 16:47:52 INFO DiskBlockManager: Created local directory at C:\\Users\\IBM_ADMIN\\AppData\\Local\\Temp\\blockmgr-68343\n452-a98d-4f76-af91-3554f86d5fff\n17/02/02 16:47:52 INFO MemoryStore: MemoryStore started with capacity 366.3 MB\n17/02/02 16:47:53 INFO SparkEnv: Registering OutputCommitCoordinator\n17/02/02 16:47:53 INFO Utils: Successfully started service 'SparkUI' on port 4040.\n17/02/02 16:47:53 INFO SparkUI: Bound SparkUI to 0.0.0.0, and started at http://192.168.47.1:4040\n17/02/02 16:47:53 INFO SparkContext: Added JAR file:/c:/y/temp/Spark/scala-test01/target/scala-2.11/simpleproject01_2.11\n-1.0.jar at spark://192.168.47.1:57316/jars/simpleproject01_2.11-1.0.jar with timestamp 1486021673260\n17/02/02 16:47:53 INFO Executor: Starting executor ID driver on host localhost\n17/02/02 16:47:53 INFO Utils: Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on\n port 57337.\n17/02/02 16:47:53 INFO NettyBlockTransferService: Server created on 192.168.47.1:57337\n17/02/02 16:47:53 INFO BlockManagerMaster: Registering BlockManager BlockManagerId(driver, 192.168.47.1, 57337)\n17/02/02 16:47:53 INFO BlockManagerMasterEndpoint: Registering block manager 192.168.47.1:57337 with 366.3 MB RAM, Block\nManagerId(driver, 192.168.47.1, 57337)\n17/02/02 16:47:53 INFO BlockManagerMaster: Registered BlockManager BlockManagerId(driver, 192.168.47.1, 57337)\n17/02/02 16:47:54 INFO MemoryStore: Block broadcast_0 stored as values in memory (estimated size 236.5 KB, free 366.1 MB\n)\n17/02/02 16:47:54 INFO MemoryStore: Block broadcast_0_piece0 stored as bytes in memory (estimated size 22.9 KB, free 366\n.0 MB)\n17/02/02 16:47:54 INFO BlockManagerInfo: Added broadcast_0_piece0 in memory on 192.168.47.1:57337 (size: 22.9 KB, free:\n366.3 MB)\n17/02/02 16:47:54 INFO SparkContext: Created broadcast 0 from textFile at SimpleApp.scala:11\n17/02/02 16:47:54 INFO FileInputFormat: Total input paths to process : 1\n17/02/02 16:47:54 INFO SparkContext: Starting job: count at SimpleApp.scala:12\n17/02/02 16:47:54 INFO DAGScheduler: Got job 0 (count at SimpleApp.scala:12) with 2 output partitions\n17/02/02 16:47:54 INFO DAGScheduler: Final stage: ResultStage 0 (count at SimpleApp.scala:12)\n17/02/02 16:47:54 INFO DAGScheduler: Parents of final stage: List()\n17/02/02 16:47:54 INFO DAGScheduler: Missing parents: List()\n17/02/02 16:47:54 INFO DAGScheduler: Submitting ResultStage 0 (MapPartitionsRDD[2] at filter at SimpleApp.scala:12), whi\nch has no missing parents\n17/02/02 16:47:54 INFO MemoryStore: Block broadcast_1 stored as values in memory (estimated size 3.1 KB, free 366.0 MB)\n17/02/02 16:47:54 INFO MemoryStore: Block broadcast_1_piece0 stored as bytes in memory (estimated size 1892.0 B, free 36\n6.0 MB)\n17/02/02 16:47:54 INFO BlockManagerInfo: Added broadcast_1_piece0 in memory on 192.168.47.1:57337 (size: 1892.0 B, free:\n 366.3 MB)\n17/02/02 16:47:54 INFO SparkContext: Created broadcast 1 from broadcast at DAGScheduler.scala:1012\n17/02/02 16:47:54 INFO DAGScheduler: Submitting 2 missing tasks from ResultStage 0 (MapPartitionsRDD[2] at filter at Sim\npleApp.scala:12)\n17/02/02 16:47:54 INFO TaskSchedulerImpl: Adding task set 0.0 with 2 tasks\n17/02/02 16:47:54 INFO TaskSetManager: Starting task 0.0 in stage 0.0 (TID 0, localhost, partition 0, PROCESS_LOCAL, 540\n8 bytes)\n17/02/02 16:47:54 INFO TaskSetManager: Starting task 1.0 in stage 0.0 (TID 1, localhost, partition 1, PROCESS_LOCAL, 540\n8 bytes)\n17/02/02 16:47:54 INFO Executor: Running task 0.0 in stage 0.0 (TID 0)\n17/02/02 16:47:54 INFO Executor: Running task 1.0 in stage 0.0 (TID 1)\n17/02/02 16:47:54 INFO Executor: Fetching spark://192.168.47.1:57316/jars/simpleproject01_2.11-1.0.jar with timestamp 14\n86021673260\n17/02/02 16:47:54 INFO TransportClientFactory: Successfully created connection to /192.168.47.1:57316 after 28 ms (0 ms\nspent in bootstraps)\n17/02/02 16:47:54 INFO Utils: Fetching spark://192.168.47.1:57316/jars/simpleproject01_2.11-1.0.jar to C:\\Users\\IBM_ADMI\nN\\AppData\\Local\\Temp\\spark-223955fa-cadd-4f8b-81a9-29404e141304\\userFiles-7459d042-01ce-4726-81a6-6380c7349084\\fetchFile\nTemp9218846672522341371.tmp\n17/02/02 16:47:55 INFO Executor: Adding file:/C:/Users/IBM_ADMIN/AppData/Local/Temp/spark-223955fa-cadd-4f8b-81a9-29404e\n141304/userFiles-7459d042-01ce-4726-81a6-6380c7349084/simpleproject01_2.11-1.0.jar to class loader\n17/02/02 16:47:55 INFO HadoopRDD: Input split: file:/c:/y/temp/Spark/scala-test01/testData01/README.md:0+1914\n17/02/02 16:47:55 INFO HadoopRDD: Input split: file:/c:/y/temp/Spark/scala-test01/testData01/README.md:1914+1914\n17/02/02 16:47:55 INFO deprecation: mapred.tip.id is deprecated. Instead, use mapreduce.task.id\n17/02/02 16:47:55 INFO deprecation: mapred.task.id is deprecated. Instead, use mapreduce.task.attempt.id\n17/02/02 16:47:55 INFO deprecation: mapred.task.is.map is deprecated. Instead, use mapreduce.task.ismap\n17/02/02 16:47:55 INFO deprecation: mapred.task.partition is deprecated. Instead, use mapreduce.task.partition\n17/02/02 16:47:55 INFO deprecation: mapred.job.id is deprecated. Instead, use mapreduce.job.id\n17/02/02 16:47:55 INFO MemoryStore: Block rdd_1_1 stored as values in memory (estimated size 5.7 KB, free 366.0 MB)\n17/02/02 16:47:55 INFO MemoryStore: Block rdd_1_0 stored as values in memory (estimated size 5.5 KB, free 366.0 MB)\n17/02/02 16:47:55 INFO BlockManagerInfo: Added rdd_1_1 in memory on 192.168.47.1:57337 (size: 5.7 KB, free: 366.3 MB)\n17/02/02 16:47:55 INFO BlockManagerInfo: Added rdd_1_0 in memory on 192.168.47.1:57337 (size: 5.5 KB, free: 366.3 MB)\n17/02/02 16:47:55 INFO Executor: Finished task 0.0 in stage 0.0 (TID 0). 1676 bytes result sent to driver\n17/02/02 16:47:55 INFO Executor: Finished task 1.0 in stage 0.0 (TID 1). 1676 bytes result sent to driver\n17/02/02 16:47:55 INFO TaskSetManager: Finished task 0.0 in stage 0.0 (TID 0) in 421 ms on localhost (1/2)\n17/02/02 16:47:55 INFO TaskSetManager: Finished task 1.0 in stage 0.0 (TID 1) in 390 ms on localhost (2/2)\n17/02/02 16:47:55 INFO TaskSchedulerImpl: Removed TaskSet 0.0, whose tasks have all completed, from pool\n17/02/02 16:47:55 INFO DAGScheduler: ResultStage 0 (count at SimpleApp.scala:12) finished in 0.437 s\n17/02/02 16:47:55 INFO DAGScheduler: Job 0 finished: count at SimpleApp.scala:12, took 0.630785 s\n17/02/02 16:47:55 INFO SparkContext: Starting job: count at SimpleApp.scala:13\n17/02/02 16:47:55 INFO DAGScheduler: Got job 1 (count at SimpleApp.scala:13) with 2 output partitions\n17/02/02 16:47:55 INFO DAGScheduler: Final stage: ResultStage 1 (count at SimpleApp.scala:13)\n17/02/02 16:47:55 INFO DAGScheduler: Parents of final stage: List()\n17/02/02 16:47:55 INFO DAGScheduler: Missing parents: List()\n17/02/02 16:47:55 INFO DAGScheduler: Submitting ResultStage 1 (MapPartitionsRDD[3] at filter at SimpleApp.scala:13), whi\nch has no missing parents\n17/02/02 16:47:55 INFO MemoryStore: Block broadcast_2 stored as values in memory (estimated size 3.1 KB, free 366.0 MB)\n17/02/02 16:47:55 INFO MemoryStore: Block broadcast_2_piece0 stored as bytes in memory (estimated size 1897.0 B, free 36\n6.0 MB)\n17/02/02 16:47:55 INFO BlockManagerInfo: Added broadcast_2_piece0 in memory on 192.168.47.1:57337 (size: 1897.0 B, free:\n 366.3 MB)\n17/02/02 16:47:55 INFO SparkContext: Created broadcast 2 from broadcast at DAGScheduler.scala:1012\n17/02/02 16:47:55 INFO DAGScheduler: Submitting 2 missing tasks from ResultStage 1 (MapPartitionsRDD[3] at filter at Sim\npleApp.scala:13)\n17/02/02 16:47:55 INFO TaskSchedulerImpl: Adding task set 1.0 with 2 tasks\n17/02/02 16:47:55 INFO TaskSetManager: Starting task 0.0 in stage 1.0 (TID 2, localhost, partition 0, PROCESS_LOCAL, 540\n8 bytes)\n17/02/02 16:47:55 INFO TaskSetManager: Starting task 1.0 in stage 1.0 (TID 3, localhost, partition 1, PROCESS_LOCAL, 540\n8 bytes)\n17/02/02 16:47:55 INFO Executor: Running task 0.0 in stage 1.0 (TID 2)\n17/02/02 16:47:55 INFO Executor: Running task 1.0 in stage 1.0 (TID 3)\n17/02/02 16:47:55 INFO BlockManager: Found block rdd_1_0 locally\n17/02/02 16:47:55 INFO BlockManager: Found block rdd_1_1 locally\n17/02/02 16:47:55 INFO Executor: Finished task 1.0 in stage 1.0 (TID 3). 875 bytes result sent to driver\n17/02/02 16:47:55 INFO Executor: Finished task 0.0 in stage 1.0 (TID 2). 867 bytes result sent to driver\n17/02/02 16:47:55 INFO TaskSetManager: Finished task 1.0 in stage 1.0 (TID 3) in 32 ms on localhost (1/2)\n17/02/02 16:47:55 INFO TaskSetManager: Finished task 0.0 in stage 1.0 (TID 2) in 32 ms on localhost (2/2)\n17/02/02 16:47:55 INFO TaskSchedulerImpl: Removed TaskSet 1.0, whose tasks have all completed, from pool\n17/02/02 16:47:55 INFO DAGScheduler: ResultStage 1 (count at SimpleApp.scala:13) finished in 0.032 s\n17/02/02 16:47:55 INFO DAGScheduler: Job 1 finished: count at SimpleApp.scala:13, took 0.071460 s\nLines with a: 61, Lines with b: 27\n17/02/02 16:47:55 INFO SparkUI: Stopped Spark web UI at http://192.168.47.1:4040\n17/02/02 16:47:55 INFO MapOutputTrackerMasterEndpoint: MapOutputTrackerMasterEndpoint stopped!\n17/02/02 16:47:55 INFO MemoryStore: MemoryStore cleared\n17/02/02 16:47:55 INFO BlockManager: BlockManager stopped\n17/02/02 16:47:55 INFO BlockManagerMaster: BlockManagerMaster stopped\n17/02/02 16:47:55 INFO OutputCommitCoordinator$OutputCommitCoordinatorEndpoint: OutputCommitCoordinator stopped!\n17/02/02 16:47:55 INFO SparkContext: Successfully stopped SparkContext\n17/02/02 16:47:55 INFO ShutdownHookManager: Shutdown hook called\n17/02/02 16:47:55 INFO ShutdownHookManager: Deleting directory C:\\Users\\IBM_ADMIN\\AppData\\Local\\Temp\\spark-223955fa-cadd\n-4f8b-81a9-29404e141304\n\n```\n\n--class\u30aa\u30d7\u30b7\u30e7\u30f3\u3067\u306f\u5b9f\u884c\u3059\u308b\u30af\u30e9\u30b9\u540d\u3092\u6307\u5b9a\u3057\u307e\u3059\u3002\n--master\u30aa\u30d7\u30b7\u30e7\u30f3\u3067\u306f\u5b9f\u884c\u74b0\u5883\u3092\u6307\u5b9a\u3057\u307e\u3059\u3002(local[*]\u306e\u5834\u5408\u3001\u30ed\u30fc\u30ab\u30eb\u30e2\u30fc\u30c9\u3067\u30b9\u30ec\u30c3\u30c9\u6570\u306fCPU\u306e\u30b3\u30a2\u6570)\n\u6700\u5f8c\u306b\u30b3\u30f3\u30d1\u30a4\u30eb\u3057\u3066\u751f\u6210\u3055\u308c\u305fjar\u30d5\u30a1\u30a4\u30eb\u3092\u6307\u5b9a\u3057\u3066\u3044\u307e\u3059\u3002\n\n\u51fa\u529b\u7d50\u679c\u306fINFO\u306e\u30e1\u30c3\u30bb\u30fc\u30b8\u304c\u305f\u304f\u3055\u3093\u51fa\u3066\u3044\u3066\u898b\u306b\u304f\u3044\u3067\u3059\u304c\u3001\u6700\u5f8c\u304b\u308910\u884c\u76ee\u304f\u3089\u3044\u306b\u3001\u300cLines with a: 61, Lines with b: 27\u300d\u3068\u3044\u3046\u884c\u304c\u51fa\u529b\u3055\u308c\u3066\u3044\u307e\u3059\u3002\n\u3053\u308c\u304c\u3001\u30d7\u30ed\u30b0\u30e9\u30e0\u3067\u96c6\u8a08\u3057\u305f\u7d50\u679c\u3092\u51fa\u529b\u3057\u3066\u3044\u308b\u90e8\u5206\u3067\u3059\u3002\n(\u8aad\u307f\u8fbc\u3093\u3060\u30c6\u30ad\u30b9\u30c8\u30d5\u30a1\u30a4\u30eb\u304b\u3089\u3001\"a\"\u3092\u542b\u3080\u884c\u6570\u3068\u3001\"b\"\u3092\u542b\u3080\u884c\u6570\u3092\u30ab\u30a6\u30f3\u30c8\u3057\u3066\u51fa\u529b\u3057\u3066\u3044\u307e\u3059\u3002)\n\n\u3053\u308c\u3067\u4e00\u901a\u308a\u30a2\u30d7\u30ea\u30b1\u30fc\u30b7\u30e7\u30f3\u3092\u52d5\u304b\u3059\u6240\u307e\u3067\u78ba\u8a8d\u3067\u304d\u307e\u3057\u305f\u3002\n\n#\u304a\u308f\u308a\u306b\n\u30d7\u30ed\u30b8\u30a7\u30af\u30c8\u306e\u7ba1\u7406\u3068\u304b\u30c7\u30d0\u30c3\u30b0\u3068\u304b\u958b\u767a\u30c4\u30fc\u30eb\u3092\u4f7f\u3063\u3066\u30b9\u30de\u30fc\u30c8\u306b\u3084\u308a\u305f\u3044\u306e\u3067\u3059\u304c\u3001IntelliJ\u306b\u3057\u308dEclipse\u306b\u3057\u308dJupyter Notebook\u306b\u3057\u308d\u3001\u306a\u304b\u306a\u304b\u30ed\u30fc\u30ab\u30eb\u306b\u74b0\u5883\u3092\u4f5c\u308d\u3046\u3068\u3057\u3066\u3082\u4e00\u7b4b\u7e04\u3067\u306f\u3044\u304b\u306a\u3044\u3053\u3068\u304c\u591a\u304f\u3001\u3061\u3087\u3063\u3068\u30cf\u30fc\u30c9\u30eb\u304c\u9ad8\u3044\u611f\u3058\u3067\u3059\u3002\u958b\u767a\u74b0\u5883\u3068\u3057\u3066\u4f55\u3092\u3069\u3046\u6574\u5099\u3059\u308b\u306e\u304c\u3088\u3044\u306e\u304b\u4eca\u3072\u3068\u3064\u81ea\u5206\u306a\u308a\u306e\u6b63\u89e3\u304c\u898b\u3064\u3051\u3089\u308c\u3066\u3044\u307e\u305b\u3093\u3002\u305d\u306e\u8fba\u306f\u60a9\u307f\u306a\u304c\u3089\u307c\u3061\u307c\u3061\u3084\u3063\u3066\u3044\u3053\u3046\u3068\u601d\u3044\u307e\u3059\u3002\n", "tags": ["Apache", "Spark", "Scala", "sbt"]}