{"context": "\n\n\u306f\u3058\u3081\u306b\n\u3053\u308c\u307e\u3067\u3001Chainer\u3084TensorFlow\u3001Caffe\u3084Theano\u306a\u3069\u3092\u30a4\u30f3\u30b9\u30c8\u30fc\u30eb\u3057\u305f\u3002\u3053\u3053\u306b\u304d\u3066Torch\u3082\u5165\u308c\u308b\u5fc5\u8981\u304c\u51fa\u305f\u306e\u3067\u3001\u30a4\u30f3\u30b9\u30c8\u30fc\u30eb\u3059\u308b\u3002\nTorch\u30db\u30fc\u30e0\u30da\u30fc\u30b8\u306e\u624b\u9806\u306b\u5f93\u3063\u3066\u9032\u3081\u308b\u3002\nhttp://torch.ch/docs/getting-started.html#_\n\n\u74b0\u5883\nGPU:GTX1070\nOS:Ubuntu14.04\nCUDA:8.0 RC\ncuDNN:5.1\npython2.7.6\u306a\u3069\n\n\u30a4\u30f3\u30b9\u30c8\u30fc\u30eb\u6e08\u307f\u30d1\u30c3\u30b1\u30fc\u30b8\nChainer\nTensorFlow\nTheano\nCaffe\u306a\u3069\n\ndependencies\u3092\u30a4\u30f3\u30b9\u30c8\u30fc\u30eb\u3059\u308b\n\u307e\u305a\u30db\u30fc\u30e0\u76f4\u4e0b\u306bgit clone\u3057\u3066\u3001\u5fc5\u8981\u306adependencies\u3092\u5165\u308c\u308b\u3002\ngit clone https://github.com/torch/distro.git ~/torch --recursive\ncd ~/torch\nbash install-deps\n\n\nTroch\u3092\u30a4\u30f3\u30b9\u30c8\u30fc\u30eb\u3059\u308b\n\u6b21\u306b\u30a4\u30f3\u30b9\u30c8\u30fc\u30eb\u3059\u308b\u3002\n./install.sh\n.....\n.....\nDo you want to automatically prepend the Torch install location\nto PATH and LD_LIBRARY_PATH in your /home/ohmasa/.bashrc? (yes/no)\n[yes] >>> \nyes\n\n\u6700\u5f8c\u306bbashrc\u306bPATH\u3092\u66f8\u3044\u305f\u308d\u304b\uff1f\u3068\u805e\u3044\u3066\u304d\u305f\u306e\u3067\u3001yes\u3068\u3057\u305f\u3002PATH\u3092\u6709\u52b9\u306b\u3059\u308b\u3002\nsource ~/.bashrc\n\n\n\u52d5\u4f5c\u78ba\u8a8d\u3059\u308b\n\u3061\u3083\u3093\u3068\u30a4\u30f3\u30b9\u30c8\u30fc\u30eb\u51fa\u6765\u3066\u308b\u304b\u3001\u52d5\u4f5c\u78ba\u8a8d\u3059\u308b\u3002\n\u307e\u305ath\u3068\u6253\u3063\u3066\u8a66\u3057\u3066\u307f\u308b\u3002\nth\n\n  ______             __   |  Torch7 \n /_  __/__  ________/ /   |  Scientific computing for Lua. \n  / / / _ \\/ __/ __/ _ \\  |  Type ? for help \n /_/  \\___/_/  \\__/_//_/  |  https://github.com/torch \n                          |  http://torch.ch \n\nth> torch.Tensor(1,2,3)\n(1,.,.) = \n  0  0  0\n  0  0  0\n[torch.DoubleTensor of size 1x2x3]\n\n                                                                      [0.0005s] \nth> \n                                                                      [0.0000s] \nth> exit\nDo you really want to exit ([y]/n)? y\n\n\u4f55\u3092\u3084\u3063\u305f\u304b\u30a4\u30de\u30a4\u30c1\u308f\u304b\u3089\u3093\u304c\u3001\u3046\u307e\u304f\u52d5\u4f5c\u3057\u3066\u308b\u307f\u305f\u3044\u3002\n\u6b21\u306btest.sh\u3092\u5b9f\u884c\u3059\u308b\u3002\n./test.sh\n.....\n.....\n160/169 VolumetricDilatedMaxPooling_backward_batch ...................... [WAIT]THCudaCheck FAIL file=/home/ohmasa/torch/extra/cutorch/lib/THC/generic/THCStorage.cu line=65 error=2 : out of memory\n160/169 VolumetricDilatedMaxPooling_backward_batch ...................... [ERROR]\n161/169 SpatialReplicationPadding_forward ............................... [ERROR]\n162/169 PReLU_forward ................................................... [PASS]\n163/169 SpatialConvolutionMM_backward_batch ............................. [PASS]\n164/169 RReLU_forward ................................................... [PASS]\n165/169 ClassNLLCriterionMultipleTargetWeights .......................... [PASS]\n166/169 Sigmoid_forward ................................................. [PASS]\n167/169 Sqrt_forward .................................................... [PASS]\n168/169 Sqrt_zero ....................................................... [PASS]\n169/169 TemporalConvolution_backward .................................... [PASS]\nCompleted 1903 asserts in 169 tests with 0 failures and 2 errors\n--------------------------------------------------------------------------------\nVolumetricDilatedMaxPooling_backward_batch\n Function call failed\n.....\n.....\n An error was found while running tests!\n\n\u6700\u5f8c\u306e\u65b9\u3067\u30a8\u30e9\u30fc\u304c\u51fa\u305f\u3002max pooling\u306ebackward\u8a08\u7b97\u3042\u305f\u308a\u3067\u554f\u984c\u304c\u767a\u751f\u3057\u305f\u307f\u305f\u3044\u3002out of memory\u3068\u51fa\u3066\u308b\u306e\u3067GPU\u306ememory\u4e0d\u8db3\u3060\u308d\u3046\u304b\uff1f\n\u30cd\u30c3\u30c8\u3067\u691c\u7d22\u3057\u3066\u307f\u305f\u304c\u3001\u3053\u3053\nhttps://github.com/karpathy/neuraltalk2/issues/52\n\u306a\u3069\u8aad\u3080\u3068\u3001\u30c7\u30fc\u30bf\u306e\u30b5\u30a4\u30ba\u3092\u4e0b\u3052\u308b\u3053\u3068\u3067\u5bfe\u5fdc\u3067\u304d\u308b\u306e\u3067\u3001\u4eca\u56de\u306e\u30a4\u30f3\u30b9\u30c8\u30fc\u30eb\u306f\u6210\u529f\u3057\u305f\u3082\u306e\u3068\u307f\u306a\u3059\u3002\n##\u306f\u3058\u3081\u306b\n\u3053\u308c\u307e\u3067\u3001Chainer\u3084TensorFlow\u3001Caffe\u3084Theano\u306a\u3069\u3092\u30a4\u30f3\u30b9\u30c8\u30fc\u30eb\u3057\u305f\u3002\u3053\u3053\u306b\u304d\u3066Torch\u3082\u5165\u308c\u308b\u5fc5\u8981\u304c\u51fa\u305f\u306e\u3067\u3001\u30a4\u30f3\u30b9\u30c8\u30fc\u30eb\u3059\u308b\u3002\n\nTorch\u30db\u30fc\u30e0\u30da\u30fc\u30b8\u306e\u624b\u9806\u306b\u5f93\u3063\u3066\u9032\u3081\u308b\u3002\nhttp://torch.ch/docs/getting-started.html#_\n\n##\u74b0\u5883\nGPU:GTX1070\nOS:Ubuntu14.04\nCUDA:8.0 RC\ncuDNN:5.1\npython2.7.6\u306a\u3069\n\n##\u30a4\u30f3\u30b9\u30c8\u30fc\u30eb\u6e08\u307f\u30d1\u30c3\u30b1\u30fc\u30b8\nChainer\nTensorFlow\nTheano\nCaffe\u306a\u3069\n\n##dependencies\u3092\u30a4\u30f3\u30b9\u30c8\u30fc\u30eb\u3059\u308b\n\u307e\u305a\u30db\u30fc\u30e0\u76f4\u4e0b\u306bgit clone\u3057\u3066\u3001\u5fc5\u8981\u306adependencies\u3092\u5165\u308c\u308b\u3002\n\n```\ngit clone https://github.com/torch/distro.git ~/torch --recursive\ncd ~/torch\nbash install-deps\n```\n\n##Troch\u3092\u30a4\u30f3\u30b9\u30c8\u30fc\u30eb\u3059\u308b\n\u6b21\u306b\u30a4\u30f3\u30b9\u30c8\u30fc\u30eb\u3059\u308b\u3002\n\n```\n./install.sh\n.....\n.....\nDo you want to automatically prepend the Torch install location\nto PATH and LD_LIBRARY_PATH in your /home/ohmasa/.bashrc? (yes/no)\n[yes] >>> \nyes\n```\n\n\u6700\u5f8c\u306bbashrc\u306bPATH\u3092\u66f8\u3044\u305f\u308d\u304b\uff1f\u3068\u805e\u3044\u3066\u304d\u305f\u306e\u3067\u3001yes\u3068\u3057\u305f\u3002PATH\u3092\u6709\u52b9\u306b\u3059\u308b\u3002\n\n```\nsource ~/.bashrc\n```\n\n##\u52d5\u4f5c\u78ba\u8a8d\u3059\u308b\n\u3061\u3083\u3093\u3068\u30a4\u30f3\u30b9\u30c8\u30fc\u30eb\u51fa\u6765\u3066\u308b\u304b\u3001\u52d5\u4f5c\u78ba\u8a8d\u3059\u308b\u3002\n\n\u307e\u305ath\u3068\u6253\u3063\u3066\u8a66\u3057\u3066\u307f\u308b\u3002\n\n```\nth\n \n  ______             __   |  Torch7 \n /_  __/__  ________/ /   |  Scientific computing for Lua. \n  / / / _ \\/ __/ __/ _ \\  |  Type ? for help \n /_/  \\___/_/  \\__/_//_/  |  https://github.com/torch \n                          |  http://torch.ch \n\t\nth> torch.Tensor(1,2,3)\n(1,.,.) = \n  0  0  0\n  0  0  0\n[torch.DoubleTensor of size 1x2x3]\n\n                                                                      [0.0005s]\t\nth> \n                                                                      [0.0000s]\t\nth> exit\nDo you really want to exit ([y]/n)? y\n```\n\n\u4f55\u3092\u3084\u3063\u305f\u304b\u30a4\u30de\u30a4\u30c1\u308f\u304b\u3089\u3093\u304c\u3001\u3046\u307e\u304f\u52d5\u4f5c\u3057\u3066\u308b\u307f\u305f\u3044\u3002\n\n\u6b21\u306b`test.sh`\u3092\u5b9f\u884c\u3059\u308b\u3002\n\n```\n./test.sh\n.....\n.....\n160/169 VolumetricDilatedMaxPooling_backward_batch ...................... [WAIT]THCudaCheck FAIL file=/home/ohmasa/torch/extra/cutorch/lib/THC/generic/THCStorage.cu line=65 error=2 : out of memory\n160/169 VolumetricDilatedMaxPooling_backward_batch ...................... [ERROR]\n161/169 SpatialReplicationPadding_forward ............................... [ERROR]\n162/169 PReLU_forward ................................................... [PASS]\n163/169 SpatialConvolutionMM_backward_batch ............................. [PASS]\n164/169 RReLU_forward ................................................... [PASS]\n165/169 ClassNLLCriterionMultipleTargetWeights .......................... [PASS]\n166/169 Sigmoid_forward ................................................. [PASS]\n167/169 Sqrt_forward .................................................... [PASS]\n168/169 Sqrt_zero ....................................................... [PASS]\n169/169 TemporalConvolution_backward .................................... [PASS]\nCompleted 1903 asserts in 169 tests with 0 failures and 2 errors\n--------------------------------------------------------------------------------\nVolumetricDilatedMaxPooling_backward_batch\n Function call failed\n.....\n.....\n An error was found while running tests!\n```\n\n\u6700\u5f8c\u306e\u65b9\u3067\u30a8\u30e9\u30fc\u304c\u51fa\u305f\u3002`max pooling`\u306e`backward`\u8a08\u7b97\u3042\u305f\u308a\u3067\u554f\u984c\u304c\u767a\u751f\u3057\u305f\u307f\u305f\u3044\u3002`out of memory`\u3068\u51fa\u3066\u308b\u306e\u3067GPU\u306ememory\u4e0d\u8db3\u3060\u308d\u3046\u304b\uff1f\n\n\u30cd\u30c3\u30c8\u3067\u691c\u7d22\u3057\u3066\u307f\u305f\u304c\u3001\u3053\u3053\nhttps://github.com/karpathy/neuraltalk2/issues/52\n\u306a\u3069\u8aad\u3080\u3068\u3001\u30c7\u30fc\u30bf\u306e\u30b5\u30a4\u30ba\u3092\u4e0b\u3052\u308b\u3053\u3068\u3067\u5bfe\u5fdc\u3067\u304d\u308b\u306e\u3067\u3001\u4eca\u56de\u306e\u30a4\u30f3\u30b9\u30c8\u30fc\u30eb\u306f\u6210\u529f\u3057\u305f\u3082\u306e\u3068\u307f\u306a\u3059\u3002\n", "tags": ["DeepLearning", "Torch", "Ubuntu14.04"]}