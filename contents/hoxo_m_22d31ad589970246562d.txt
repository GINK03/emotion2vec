{"context": " More than 1 year has passed since last update.Spark 1.4.0 \u304b\u3089 SparkR \u304c\u6b63\u5f0f\u63a1\u7528\u3055\u308c\u307e\u3057\u305f\u3002\n\n\u300cApache Spark 1.4\u300d\u304c\u516c\u958b--R\u8a00\u8a9e\u3092\u30b5\u30dd\u30fc\u30c8\u3001\u6a5f\u68b0\u5b66\u7fd2\u30d1\u30a4\u30d7\u30e9\u30a4\u30f3API\u304c\u5b89\u5b9a\u7248\u306b\n\n\u3055\u3063\u305d\u304f\u3084\u3063\u3066\u307f\u305f\u3068\u3044\u3046\u65b9\u304b\u3089\u306e\u5831\u544a\u304c\u3042\u308a\u307e\u3059\u3002\n\nSpark 1.4.0 \u306e SparkR \u3092\u52d5\u304b\u3059\n\nSparkR \u306e\u7279\u5fb4\u3068\u3057\u3066\n\n\u4e3b\u306b DataFrame \u3092\u6271\u3046\u7528\nRDD \u3092\u6271\u3046\u95a2\u6570\u306f\u96a0\u853d\u3055\u308c\u3066\u3044\u308b\n\nmagrittr \u3068\u306e\u76f8\u6027\u304c\u826f\u3044\n\ndplyr \u30e9\u30a4\u30af\u306a\u30c7\u30fc\u30bf\u30cf\u30f3\u30c9\u30ea\u30f3\u30b0\n\u3057\u304b\u3057\u3001NSE \u304c\u4f7f\u3048\u306a\u3044\n\n\u3068\u3044\u3046\u611f\u3058\u3002\n\u30a4\u30f3\u30b9\u30c8\u30fc\u30eb\u306f\u3081\u3063\u3061\u3083\u7c21\u5358\u3067\u3001\u30d0\u30a4\u30ca\u30ea\u3092\u30c0\u30a6\u30f3\u30ed\u30fc\u30c9\u30fb\u89e3\u51cd\u3057\u3066\u9069\u5f53\u306a\u3068\u3053\u308d(\u30db\u30fc\u30e0\u306e\u4e0b\u3068\u304b)\u306b\u7f6e\u304d\u3001bin/sparkR \u3092\u53e9\u304f\u3060\u3051\u3067\u8d77\u52d5\u3067\u304d\u307e\u3059\u3002\n\u30d1\u30b9\u3092\u901a\u305b\u3070 RStudio \u304b\u3089\u4f7f\u3046\u3053\u3068\u3082\u3067\u304d\u307e\u3059\u3002\n\u79c1\u306f\u540c\u3058\u30b5\u30fc\u30d0\u306b RStudio Server \u3092\u7acb\u3066\u3066\u5b9f\u884c\u3057\u3066\u3044\u307e\u3059\u3002\n\nQuick Start\n\u3068\u308a\u3042\u3048\u305a\u52d5\u304f\u3053\u3068\u3092\u78ba\u8a8d\u3059\u308b\u305f\u3081\u306b\u3001Spark \u306e\u30db\u30fc\u30e0\u30da\u30fc\u30b8\u306b\u3042\u308b Quick Start \u3092 SparkR \u3067\u5b9f\u884c\u3057\u3066\u307f\u307e\u3059\u3002\nSparkR \u306e RDD \u64cd\u4f5c\u95a2\u6570\u306f\u30a8\u30af\u30b9\u30dd\u30fc\u30c8\u3055\u308c\u3066\u3044\u306a\u3044\u305f\u3081\u3001SparkR:::textFile() \u306e\u3088\u3046\u306b\u3001::: \u3092\u4f7f\u3063\u3066\u547c\u3073\u51fa\u3059\u5fc5\u8981\u304c\u3042\u308a\u307e\u3059\u3002\n\u307e\u305a\u306f\u3001RStudio \u3067\u52d5\u304b\u3059\u305f\u3081\u306b\u3001\u30d1\u30b9\u3092\u901a\u3057\u3066 Spark \u3092\u8d77\u52d5\u3057\u307e\u3059\u3002\n.Rprofile \u306b\u66f8\u3044\u3066\u304a\u3051\u3070\u3001R \u3092\u8d77\u52d5\u3057\u305f\u6bb5\u968e\u3067\u3053\u306e\u72b6\u614b\u306b\u3067\u304d\u307e\u3059\u3002\n\nR\n# Initialize for RStudio --------------------------------------------------\nSys.setenv(SPARK_HOME=\"/home/***/bin/spark\")\n.libPaths(c(file.path(Sys.getenv(\"SPARK_HOME\"), \"R\", \"lib\"), .libPaths()))\nlibrary(SparkR)\nsc <- sparkR.init(master=\"local\")\n\n\n\nBasics\nREADME.md \u3092\u8aad\u307f\u8fbc\u3093\u3067\u3001\u884c\u6570\u3092\u6570\u3048\u307e\u3059\u3002\n\nR\n# Basics ------------------------------------------------------------------\nlibrary(magrittr)\n\nfile <- file.path(Sys.getenv(\"SPARK_HOME\"), \"README.md\")\ntextFile <- sc %>% SparkR:::textFile(file) \n\ntextFile %>% count\n\n\n\n\u7d50\u679c\n[1] 98\n\n\n\u6700\u521d\u306e\u884c\u3092\u53d6\u5f97\u3057\u307e\u3059\u3002\n\nR\ntextFile %>% first\n\n\n\n\u7d50\u679c\n[1] \"# Apache Spark\"\n\n\nSpark \u3068\u3044\u3046\u6587\u5b57\u5217\u3092\u542b\u3080\u884c\u306e\u307f\u3092\u62bd\u51fa\u3057\u3001\u884c\u6570\u3092\u6570\u3048\u307e\u3059\u3002\n\nR\nlineWithSpark <- textFile %>% \n  SparkR:::filterRDD(function(line) grepl(\"Spark\", line))\n\nlineWithSpark %>% count\n\n\n\n\u7d50\u679c\n[1] 19\n\n\n\nMore on RDD Operations\n\u5358\u8a9e\u6570\u306e\u6700\u3082\u591a\u3044\u884c\u306e\u5358\u8a9e\u6570\u3092\u8a08\u7b97\u3057\u307e\u3059\u3002\n\nR\n# More on RDD Operations --------------------------------------------------\ntextFile %>% \n  SparkR:::map(function(line) length(strsplit(line, \" \")[[1]])) %>%\n  SparkR:::reduce(function(a, b) ifelse(a > b, a, b))\n\n\n\n\u7d50\u679c\n[1] 14\n\n\n\u4e0a\u3068\u540c\u3058\u3053\u3068\u3092\u3001max \u95a2\u6570\u3092\u7528\u3044\u3066\u884c\u3044\u307e\u3059\u3002\n\nR\ntextFile %>% \n  SparkR:::map(function(line) length(strsplit(line, \" \")[[1]])) %>%\n  SparkR:::reduce(max)\n\n\n\n\u7d50\u679c\n[1] 14\n\n\n\u6587\u7ae0\u4e2d\u306e\u5358\u8a9e\u3092\u6570\u3048\u307e\u3059\u3002\n\u7d50\u679c\u306f\u305d\u306e\u307e\u307e\u3067\u306f\u898b\u306b\u304f\u3044\u305f\u3081\u3001\u30c7\u30fc\u30bf\u30d5\u30ec\u30fc\u30e0\u306b\u3057\u3066\u3044\u307e\u3059\u3002\n\nR\nwordCounts <- textFile %>% \n  SparkR:::flatMap(function(line) strsplit(line, \" \")[[1]]) %>%\n  SparkR:::map(function(word) list(word, 1)) %>%\n  SparkR:::reduceByKey(function(a, b) a + b, 1)\n\n# wordCounts %>% collect # \u3053\u306e\u7d50\u679c\u306f R \u3067\u306f\u898b\u306b\u304f\u3044\n\nwordCounts %>% collect %>% \n  Map(function(x) data.frame(word=x[[1]], count=x[[2]]), .) %>%\n  Reduce(rbind, .) %>%\n  head\n\n\n\n\u7d50\u679c\n            word count\n1       programs     2\n2         online     1\n3   Thriftserver     1\n4        against     1\n5 Alternatively,     1\n6        Running     1\n\n\nSpark \u306e\u505c\u6b62\u306f\n\nR\nsparkR.stop()\n\n\n\nLambdarize\n\u3068\u308a\u3042\u3048\u305a Quick Start \u306e\u5b9f\u884c\u304c\u3067\u304d\u307e\u3057\u305f\u3002\n\u3057\u304b\u3057\u3001\u4e0a\u8a18\u306e\u30b3\u30fc\u30c9\u306f function \u3092\u3044\u3063\u3071\u3044\u66f8\u304b\u306a\u304f\u3066\u306f\u306a\u3089\u306a\u3044\u306e\u3067\u75b2\u308c\u307e\u3059\u306d\u3002\n\u305d\u3093\u306a\u3068\u304d\u306f\u3001lambdaR \u30d1\u30c3\u30b1\u30fc\u30b8\u3092\u4f7f\u3063\u3066 lambdarize \u3057\u305f\u95a2\u6570\u3092\u4f5c\u308b\u3053\u3068\u3067\u3001\u30e9\u30e0\u30c0\u5f0f\u3092\u4f7f\u3063\u305f\u7c21\u6f54\u306a\u66f8\u304d\u65b9\u304c\u3067\u304d\u308b\u3088\u3046\u306b\u306a\u308a\u307e\u3059\u3002\n\nR\n# Lambdarize --------------------------------------------------------------\n# devtools::install_github(\"hoxo-m/lambdaR\") # \u30a4\u30f3\u30b9\u30c8\u30fc\u30eb\nlibrary(lambdaR)\nlambdarize <- function(rdd_func) function(rdd, ...) rdd_func(rdd, lambda(...))\nfilterRDD_ <- lambdarize(SparkR:::filterRDD)\nmap_ <- lambdarize(SparkR:::map)\nreduce_ <- lambdarize(SparkR:::reduce)\nflatMap_ <- lambdarize(SparkR:::flatMap)\nreduceByKey_ <- function(rdd, ..., numPartitions) SparkR:::reduceByKey(rdd, lambda(...), numPartitions)\n\n# Basics ------------------------------------------------------------------\nlibrary(magrittr)\n\nfile <- file.path(Sys.getenv(\"SPARK_HOME\"), \"README.md\")\ntextFile <- sc %>% SparkR:::textFile(file) \n\ntextFile %>% count\ntextFile %>% first\n\nlineWithSpark <- textFile %>% \n  filterRDD_(line: grepl(\"Spark\", line))\n\nlineWithSpark %>% count\n\n# More on RDD Operations --------------------------------------------------\ntextFile %>% \n  map_(line: length(strsplit(line, \" \")[[1]])) %>%\n  reduce_(a, b: ifelse(a > b, a, b))\n\ntextFile %>% \n  map_(line: length(strsplit(line, \" \")[[1]])) %>%\n  reduce_(max)\n\nwordCounts <- textFile %>% \n  flatMap_(line: strsplit(line, \" \")[[1]]) %>%\n  map_(word: list(word, 1)) %>%\n  reduceByKey_(a, b: a + b, numPartitions=1)\n\nwordCounts %>% collect %>% \n  Map_(x: data.frame(word=x[[1]], count=x[[2]])) %>%\n  Reduce_(rbind) %>%\n  head\n\n\n\u3081\u3063\u3061\u3083\u3059\u3063\u304d\u308a\u3057\u307e\u3057\u305f\u3002\nlambdaR \u30d1\u30c3\u30b1\u30fc\u30b8\u306b\u3064\u3044\u3066\u306f\u3001\u4e0b\u8a18\u8a18\u4e8b\u3092\u3054\u53c2\u7167\u304f\u3060\u3055\u3044\u3002\n\nR \u306b\u30e9\u30e0\u30c0\u5f0f\u3092\u5c0e\u5165\u3059\u308b\u30d1\u30c3\u30b1\u30fc\u30b8 lambdaR \u3092\u4f5c\u3063\u305f\n\nEnjoy!\nSpark 1.4.0 \u304b\u3089 SparkR \u304c\u6b63\u5f0f\u63a1\u7528\u3055\u308c\u307e\u3057\u305f\u3002\n\n- [\u300cApache Spark 1.4\u300d\u304c\u516c\u958b--R\u8a00\u8a9e\u3092\u30b5\u30dd\u30fc\u30c8\u3001\u6a5f\u68b0\u5b66\u7fd2\u30d1\u30a4\u30d7\u30e9\u30a4\u30f3API\u304c\u5b89\u5b9a\u7248\u306b](http://japan.zdnet.com/article/35065902/)\n\n\u3055\u3063\u305d\u304f\u3084\u3063\u3066\u307f\u305f\u3068\u3044\u3046\u65b9\u304b\u3089\u306e\u5831\u544a\u304c\u3042\u308a\u307e\u3059\u3002\n\n- [Spark 1.4.0 \u306e SparkR \u3092\u52d5\u304b\u3059](http://qiita.com/qtwi/items/7abcfc53ba9568f20004)\n\nSparkR \u306e\u7279\u5fb4\u3068\u3057\u3066\n\n- \u4e3b\u306b DataFrame \u3092\u6271\u3046\u7528\n- RDD \u3092\u6271\u3046\u95a2\u6570\u306f\u96a0\u853d\u3055\u308c\u3066\u3044\u308b\n- `magrittr` \u3068\u306e\u76f8\u6027\u304c\u826f\u3044\n- `dplyr` \u30e9\u30a4\u30af\u306a\u30c7\u30fc\u30bf\u30cf\u30f3\u30c9\u30ea\u30f3\u30b0\n- \u3057\u304b\u3057\u3001NSE \u304c\u4f7f\u3048\u306a\u3044\n\n\u3068\u3044\u3046\u611f\u3058\u3002\n\n\u30a4\u30f3\u30b9\u30c8\u30fc\u30eb\u306f\u3081\u3063\u3061\u3083\u7c21\u5358\u3067\u3001\u30d0\u30a4\u30ca\u30ea\u3092\u30c0\u30a6\u30f3\u30ed\u30fc\u30c9\u30fb\u89e3\u51cd\u3057\u3066\u9069\u5f53\u306a\u3068\u3053\u308d(\u30db\u30fc\u30e0\u306e\u4e0b\u3068\u304b)\u306b\u7f6e\u304d\u3001`bin/sparkR` \u3092\u53e9\u304f\u3060\u3051\u3067\u8d77\u52d5\u3067\u304d\u307e\u3059\u3002\n\n\u30d1\u30b9\u3092\u901a\u305b\u3070 RStudio \u304b\u3089\u4f7f\u3046\u3053\u3068\u3082\u3067\u304d\u307e\u3059\u3002\n\u79c1\u306f\u540c\u3058\u30b5\u30fc\u30d0\u306b RStudio Server \u3092\u7acb\u3066\u3066\u5b9f\u884c\u3057\u3066\u3044\u307e\u3059\u3002\n\n## Quick Start\n\n\u3068\u308a\u3042\u3048\u305a\u52d5\u304f\u3053\u3068\u3092\u78ba\u8a8d\u3059\u308b\u305f\u3081\u306b\u3001Spark \u306e\u30db\u30fc\u30e0\u30da\u30fc\u30b8\u306b\u3042\u308b [Quick Start](https://spark.apache.org/docs/latest/quick-start.html) \u3092 SparkR \u3067\u5b9f\u884c\u3057\u3066\u307f\u307e\u3059\u3002\n\nSparkR \u306e RDD \u64cd\u4f5c\u95a2\u6570\u306f\u30a8\u30af\u30b9\u30dd\u30fc\u30c8\u3055\u308c\u3066\u3044\u306a\u3044\u305f\u3081\u3001`SparkR:::textFile()` \u306e\u3088\u3046\u306b\u3001`:::` \u3092\u4f7f\u3063\u3066\u547c\u3073\u51fa\u3059\u5fc5\u8981\u304c\u3042\u308a\u307e\u3059\u3002\n\n\u307e\u305a\u306f\u3001RStudio \u3067\u52d5\u304b\u3059\u305f\u3081\u306b\u3001\u30d1\u30b9\u3092\u901a\u3057\u3066 Spark \u3092\u8d77\u52d5\u3057\u307e\u3059\u3002\n`.Rprofile` \u306b\u66f8\u3044\u3066\u304a\u3051\u3070\u3001R \u3092\u8d77\u52d5\u3057\u305f\u6bb5\u968e\u3067\u3053\u306e\u72b6\u614b\u306b\u3067\u304d\u307e\u3059\u3002\n\n```r:R\n# Initialize for RStudio --------------------------------------------------\nSys.setenv(SPARK_HOME=\"/home/***/bin/spark\")\n.libPaths(c(file.path(Sys.getenv(\"SPARK_HOME\"), \"R\", \"lib\"), .libPaths()))\nlibrary(SparkR)\nsc <- sparkR.init(master=\"local\")\n```\n\n### Basics\n\n`README.md` \u3092\u8aad\u307f\u8fbc\u3093\u3067\u3001\u884c\u6570\u3092\u6570\u3048\u307e\u3059\u3002\n\n```r:R\n# Basics ------------------------------------------------------------------\nlibrary(magrittr)\n\nfile <- file.path(Sys.getenv(\"SPARK_HOME\"), \"README.md\")\ntextFile <- sc %>% SparkR:::textFile(file) \n\ntextFile %>% count\n```\n\n```:\u7d50\u679c\n[1] 98\n```\n\n\u6700\u521d\u306e\u884c\u3092\u53d6\u5f97\u3057\u307e\u3059\u3002\n\n```r:R\ntextFile %>% first\n```\n\n```:\u7d50\u679c\n[1] \"# Apache Spark\"\n```\n\nSpark \u3068\u3044\u3046\u6587\u5b57\u5217\u3092\u542b\u3080\u884c\u306e\u307f\u3092\u62bd\u51fa\u3057\u3001\u884c\u6570\u3092\u6570\u3048\u307e\u3059\u3002\n\n```r:R\nlineWithSpark <- textFile %>% \n  SparkR:::filterRDD(function(line) grepl(\"Spark\", line))\n\nlineWithSpark %>% count\n```\n\n```:\u7d50\u679c\n[1] 19\n```\n\n### More on RDD Operations\n\n\u5358\u8a9e\u6570\u306e\u6700\u3082\u591a\u3044\u884c\u306e\u5358\u8a9e\u6570\u3092\u8a08\u7b97\u3057\u307e\u3059\u3002\n\n```r:R\n# More on RDD Operations --------------------------------------------------\ntextFile %>% \n  SparkR:::map(function(line) length(strsplit(line, \" \")[[1]])) %>%\n  SparkR:::reduce(function(a, b) ifelse(a > b, a, b))\n```\n\n```:\u7d50\u679c\n[1] 14\n```\n\n\u4e0a\u3068\u540c\u3058\u3053\u3068\u3092\u3001`max` \u95a2\u6570\u3092\u7528\u3044\u3066\u884c\u3044\u307e\u3059\u3002\n\n```r:R\ntextFile %>% \n  SparkR:::map(function(line) length(strsplit(line, \" \")[[1]])) %>%\n  SparkR:::reduce(max)\n```\n\n```:\u7d50\u679c\n[1] 14\n```\n\n\u6587\u7ae0\u4e2d\u306e\u5358\u8a9e\u3092\u6570\u3048\u307e\u3059\u3002\n\u7d50\u679c\u306f\u305d\u306e\u307e\u307e\u3067\u306f\u898b\u306b\u304f\u3044\u305f\u3081\u3001\u30c7\u30fc\u30bf\u30d5\u30ec\u30fc\u30e0\u306b\u3057\u3066\u3044\u307e\u3059\u3002\n\n```r:R\nwordCounts <- textFile %>% \n  SparkR:::flatMap(function(line) strsplit(line, \" \")[[1]]) %>%\n  SparkR:::map(function(word) list(word, 1)) %>%\n  SparkR:::reduceByKey(function(a, b) a + b, 1)\n\n# wordCounts %>% collect # \u3053\u306e\u7d50\u679c\u306f R \u3067\u306f\u898b\u306b\u304f\u3044\n\nwordCounts %>% collect %>% \n  Map(function(x) data.frame(word=x[[1]], count=x[[2]]), .) %>%\n  Reduce(rbind, .) %>%\n  head\n```\n\n```:\u7d50\u679c\n            word count\n1       programs     2\n2         online     1\n3   Thriftserver     1\n4        against     1\n5 Alternatively,     1\n6        Running     1\n```\n\nSpark \u306e\u505c\u6b62\u306f\n\n```r:R\nsparkR.stop()\n```\n\n## Lambdarize\n\n\u3068\u308a\u3042\u3048\u305a Quick Start \u306e\u5b9f\u884c\u304c\u3067\u304d\u307e\u3057\u305f\u3002\n\u3057\u304b\u3057\u3001\u4e0a\u8a18\u306e\u30b3\u30fc\u30c9\u306f `function` \u3092\u3044\u3063\u3071\u3044\u66f8\u304b\u306a\u304f\u3066\u306f\u306a\u3089\u306a\u3044\u306e\u3067\u75b2\u308c\u307e\u3059\u306d\u3002\n\n\u305d\u3093\u306a\u3068\u304d\u306f\u3001`lambdaR` \u30d1\u30c3\u30b1\u30fc\u30b8\u3092\u4f7f\u3063\u3066 lambdarize \u3057\u305f\u95a2\u6570\u3092\u4f5c\u308b\u3053\u3068\u3067\u3001\u30e9\u30e0\u30c0\u5f0f\u3092\u4f7f\u3063\u305f\u7c21\u6f54\u306a\u66f8\u304d\u65b9\u304c\u3067\u304d\u308b\u3088\u3046\u306b\u306a\u308a\u307e\u3059\u3002\n\n```r:R\n# Lambdarize --------------------------------------------------------------\n# devtools::install_github(\"hoxo-m/lambdaR\") # \u30a4\u30f3\u30b9\u30c8\u30fc\u30eb\nlibrary(lambdaR)\nlambdarize <- function(rdd_func) function(rdd, ...) rdd_func(rdd, lambda(...))\nfilterRDD_ <- lambdarize(SparkR:::filterRDD)\nmap_ <- lambdarize(SparkR:::map)\nreduce_ <- lambdarize(SparkR:::reduce)\nflatMap_ <- lambdarize(SparkR:::flatMap)\nreduceByKey_ <- function(rdd, ..., numPartitions) SparkR:::reduceByKey(rdd, lambda(...), numPartitions)\n\n# Basics ------------------------------------------------------------------\nlibrary(magrittr)\n\nfile <- file.path(Sys.getenv(\"SPARK_HOME\"), \"README.md\")\ntextFile <- sc %>% SparkR:::textFile(file) \n\ntextFile %>% count\ntextFile %>% first\n\nlineWithSpark <- textFile %>% \n  filterRDD_(line: grepl(\"Spark\", line))\n\nlineWithSpark %>% count\n\n# More on RDD Operations --------------------------------------------------\ntextFile %>% \n  map_(line: length(strsplit(line, \" \")[[1]])) %>%\n  reduce_(a, b: ifelse(a > b, a, b))\n\ntextFile %>% \n  map_(line: length(strsplit(line, \" \")[[1]])) %>%\n  reduce_(max)\n\nwordCounts <- textFile %>% \n  flatMap_(line: strsplit(line, \" \")[[1]]) %>%\n  map_(word: list(word, 1)) %>%\n  reduceByKey_(a, b: a + b, numPartitions=1)\n\nwordCounts %>% collect %>% \n  Map_(x: data.frame(word=x[[1]], count=x[[2]])) %>%\n  Reduce_(rbind) %>%\n  head\n```\n\n\u3081\u3063\u3061\u3083\u3059\u3063\u304d\u308a\u3057\u307e\u3057\u305f\u3002\n\n`lambdaR` \u30d1\u30c3\u30b1\u30fc\u30b8\u306b\u3064\u3044\u3066\u306f\u3001\u4e0b\u8a18\u8a18\u4e8b\u3092\u3054\u53c2\u7167\u304f\u3060\u3055\u3044\u3002\n\n- [R \u306b\u30e9\u30e0\u30c0\u5f0f\u3092\u5c0e\u5165\u3059\u308b\u30d1\u30c3\u30b1\u30fc\u30b8 lambdaR \u3092\u4f5c\u3063\u305f](http://d.hatena.ne.jp/hoxo_m/20141204/p1)\n\nEnjoy!\n", "tags": ["Spark", "R"]}