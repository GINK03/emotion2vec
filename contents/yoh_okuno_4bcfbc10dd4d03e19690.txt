{"context": "\n\n\u306f\u3058\u3081\u306b\n\u30c7\u30a3\u30fc\u30d7\u30e9\u30fc\u30cb\u30f3\u30b0\u306b\u304a\u3051\u308bDropout\u306f\u5358\u7d14\u304b\u3064\u5f37\u529b\u306a\u6b63\u5247\u5316\u624b\u6cd5\u3068\u3057\u3066\u5e83\u304f\u4f7f\u308f\u308c\u3066\u3044\u307e\u3059\u304c\u3001RNN\u306e\u6642\u9593\u65b9\u5411\u306b\u9069\u7528\u3059\u308b\u3068\u30ce\u30a4\u30ba\u304c\u84c4\u7a4d\u3057\u3066\u3046\u307e\u304f\u5b66\u7fd2\u3067\u304d\u306a\u3044\u305f\u3081\u3001\u5165\u51fa\u529b\u5c64\u306b\u306e\u307f\u9069\u7528\u3059\u308b\u306e\u304c\u5e38\u8b58\u3068\u3055\u308c\u3066\u304d\u307e\u3057\u305f[Zaremba 2014]1\u3002\u3057\u304b\u3057\u6700\u8fd1\u306e\u7814\u7a76\u3067Dropout\u3092\u30d9\u30a4\u30ba\u7684\u306b\u89e3\u91c8\u3059\u308b\u3053\u3068\u3067RNN\u306e\u6642\u9593\u65b9\u5411\u306b\u3082Dropout\u3092\u9069\u7528\u3067\u304d\u3001\u8a00\u8a9e\u30e2\u30c7\u30eb\u306e\u30bf\u30b9\u30af\u3067\u5358\u4e00\u30e2\u30c7\u30eb\u3068\u3057\u3066\u6700\u9ad8\u7cbe\u5ea6\u3092\u9054\u6210\u3059\u308b\u3053\u3068\u304c\u793a\u3055\u308c\u307e\u3057\u305f[Gal 2016]2 \u4eca\u56de\u306f\u5909\u5206Dropout\u3068\u547c\u3070\u308c\u308b\u3053\u306e\u30e2\u30c7\u30eb\u3092TensorFlow\u3067\u5b9f\u88c5\u3057\u305f\u306e\u3067\u7d39\u4ecb\u3057\u305f\u3044\u3068\u601d\u3044\u307e\u3059\u3002\n\nDropout\u306e\u30d9\u30a4\u30ba\u7684\u89e3\u91c8\u3068RNN\u3078\u306e\u9069\u7528\n\u30cb\u30e5\u30fc\u30e9\u30eb\u30cd\u30c3\u30c8\u30ef\u30fc\u30af\u306e\u30d1\u30e9\u30e1\u30fc\u30bf\u306e\u4e8b\u5f8c\u5206\u5e03\u3092\u300c\u5b66\u7fd2\u3059\u308b\u901a\u5e38\u306e\u30d1\u30e9\u30e1\u30fc\u30bf\u300d\u3068\u300c\u5b66\u7fd2\u3057\u306a\u3044\u30d1\u30e9\u30e1\u30fc\u30bf\uff1d\uff10\u300d\u306e2\u3064\u3092\u4e2d\u5fc3\u3068\u3059\u308b\u6df7\u5408\u30ac\u30a6\u30b9\u5206\u5e03\u3067\u8fd1\u4f3c\u3059\u308b\u3053\u3068\u306b\u3088\u308aDropout\u3068\u540c\u69d8\u306e\u30a2\u30eb\u30b4\u30ea\u30ba\u30e0\u304c\u5f97\u3089\u308c\u308b\u3053\u3068\u304c\u308f\u304b\u3063\u3066\u3044\u307e\u3059\u3002Dropout\u306e\u89e3\u91c8\u3068\u3057\u3066\u7570\u306a\u308b\u30cd\u30c3\u30c8\u30ef\u30fc\u30af\u306e\u30a2\u30f3\u30b5\u30f3\u30d6\u30eb\u3092\u63a1\u7528\u3057\u305f\u5834\u5408\u3068\u7570\u306a\u308a\u3001\u3053\u306e\u89e3\u91c8\u3067\u306f\u30d1\u30e9\u30e1\u30fc\u30bf\u3092\u5171\u6709\u3059\u308b\u30ec\u30a4\u30e4\u30fc\u306f\u540c\u3058\u30e6\u30cb\u30c3\u30c8\u3092drop\u3059\u308b\u5fc5\u8981\u304c\u3042\u308a\u307e\u3059\u3002RNN\u3067\u306f\u6642\u9593\u65b9\u5411\u3067\u540c\u3058\u30d1\u30e9\u30e1\u30fc\u30bf\u3092\u5171\u6709\u3057\u307e\u3059\u304b\u3089\u3001\u3069\u306e\u30e6\u30cb\u30c3\u30c8\u3092drop\u3059\u308b\u304b\u3092\u6c7a\u3081\u308b0/1\u306e\u5024\u3092\u53d6\u308b\u30de\u30b9\u30af\u3092\u7570\u306a\u308b\u6642\u523b\u3067\u5171\u6709\u3059\u308b\u3053\u3068\u3067\u3053\u306e\u89e3\u91c8\u3092\u5b9f\u88c5\u3059\u308b\u3053\u3068\u304c\u3067\u304d\u307e\u3059\u3002\n\n\u56f3\u306b\u304a\u3051\u308b\u7570\u306a\u308b\u8272\u306fDropout\u306e\u30de\u30b9\u30af\u304c\u7570\u306a\u308b\u3053\u3068\u3092\u8868\u3057\u3001\u70b9\u7dda\u306fDropout\u304c\u9069\u7528\u3055\u308c\u306a\u3044\u3053\u3068\u3092\u8868\u3057\u3066\u3044\u307e\u3059\u3002\u5f93\u6765\u306eDropout\u304c\u6642\u9593\u65b9\u5411\u3078\u306e\u9069\u7528\u3092\u907f\u3051\u3066\u5165\u51fa\u529b\u5c64\u306b\u306e\u307f\u9069\u7528\u3055\u308c\u308b\u306e\u306b\u5bfe\u3057\u3001\u5909\u5206Dropout\u3067\u306f\u6642\u9593\u65b9\u5411\u306b\u3082\u9069\u7528\u3057\u6bce\u6642\u523b\u3067\u540c\u3058\u30de\u30b9\u30af\u3092\u5171\u6709\u3057\u307e\u3059\u3002\n\nTensorFlow\u306b\u3088\u308b\u5b9f\u88c5\nTensorFlow 0.10\u3092\u4f7f\u3063\u3066\u5909\u5206Dropout\u3092\u5b9f\u88c5\u3057\u307e\u3057\u305f\u3002TensorFlow\u306eRNN\u30c1\u30e5\u30fc\u30c8\u30ea\u30a2\u30eb\u3067\u306f[Zaremba 2014]\u3092\u5b9f\u88c5\u3057\u3066\u3044\u307e\u3059\u304b\u3089\u3001\u3053\u308c\u3092\u3082\u3068\u306b\u6539\u9020\u3057\u3066\u3044\u304d\u307e\u3059\u3002\u5b9f\u88c5\u3059\u308b\u306e\u306f\u8ad6\u6587\u4e2d\u306euntied(no MC)\u3067\u3059\u3002\n\nvariational_dropout_wrapper.py\nimport tensorflow as tf\nfrom tensorflow.python.ops.rnn_cell import RNNCell\n\n\ndef get_dropout_mask(keep_prob, shape):\n  keep_prob = tf.convert_to_tensor(keep_prob)\n  random_tensor = keep_prob + tf.random_uniform(shape)\n  binary_tensor = tf.floor(random_tensor)\n  dropout_mask = tf.inv(keep_prob) * binary_tensor\n  return dropout_mask\n\n\nclass VariationalDropoutWrapper(RNNCell):\n  def __init__(self, cell, batch_size, keep_prob):\n    self._cell = cell\n    self._output_dropout_mask = get_dropout_mask(keep_prob, [batch_size, cell.output_size])\n    self._state_dropout_mask = get_dropout_mask(keep_prob, [batch_size, int(cell.state_size / 2)])\n\n  @property\n  def state_size(self):\n    return self._cell.state_size\n\n  @property\n  def output_size(self):\n    return self._cell.output_size\n\n  def __call__(self, inputs, state, scope=None):\n    # TODO: suppport non-LSTM cells and state_is_tuple=True\n    c, h = tf.split(1, 2, state)\n    h *= self._state_dropout_mask\n    state = tf.concat(1, [c, h])\n    output, new_state = self._cell(inputs, state, scope)\n    output *= self._output_dropout_mask\n    return output, new_state\n\n\n\u3053\u306e\u30e2\u30b8\u30e5\u30fc\u30eb\u3092\u4f7f\u3063\u3066\u30c1\u30e5\u30fc\u30c8\u30ea\u30a2\u30eb\u306eptb_word_lm.py\u306b\u4ee5\u4e0b\u306e\u30d1\u30c3\u30c1\u3092\u5f53\u3066\u308c\u3070\u5909\u5206Dropout\u304c\u4f7f\u3048\u308b\u3088\u3046\u306b\u306a\u308a\u307e\u3059\uff08\u3053\u306e\u30b9\u30af\u30ea\u30d7\u30c8\u306fTensorFlow\u306e\u30d0\u30fc\u30b8\u30e7\u30f3\u306b\u3088\u3063\u3066\u5927\u304d\u304f\u5909\u308f\u308b\u306e\u3067\u6ce8\u610f\uff09\u3002\n65a66,67\n> from variational_dropout_wrapper import VariationalDropoutWrapper, get_dropout_mask\n>\n99,102c101,107\n<     if is_training and config.keep_prob < 1:\n<       lstm_cell = tf.nn.rnn_cell.DropoutWrapper(\n<           lstm_cell, output_keep_prob=config.keep_prob)\n<     cell = tf.nn.rnn_cell.MultiRNNCell([lstm_cell] * config.num_layers)\n---\n>\n>     # To avoid using same dropout mask in different layers, create new dropout wrapper per layer\n>     cells = []\n>     for i in range(config.num_layers):\n>       with tf.variable_scope(\"layer\" + i):\n>         cells.append(VariationalDropoutWrapper(lstm_cell, batch_size, keep_prob=config.keep_prob))\n>     cell = tf.nn.rnn_cell.MultiRNNCell(cells)\n112c117,119\n<       inputs = tf.nn.dropout(inputs, config.keep_prob)\n---\n>       # use same dropout mask across time steps, but keep different masks for samples and units\n>       dropout_mask = get_dropout_mask(config.keep_prob, [batch_size, size])\n>       inputs *= tf.expand_dims(dropout_mask, 1)\n\n\n\u5b9f\u9a13\u7d50\u679c\n[Zaremba 2014]\u306emedium\u8a2d\u5b9a\u306b\u5f93\u3044\u3001PennTreeBank\u30c7\u30fc\u30bf\u30bb\u30c3\u30c8\u306b\u304a\u3051\u308bLSTM\u8a00\u8a9e\u30e2\u30c7\u30eb\u306e\u6027\u80fd\u3092\u8a55\u4fa1\u3057\u307e\u3057\u305f\u3002Dropout\u306a\u3057\u306e\u5834\u5408\u3068\u5165\u51fa\u529b\u306e\u307fDropout\u306e\u5834\u5408\u306fZaremba\u3089\u306e\u8ad6\u6587\u306b\u8a18\u8f09\u3055\u308c\u3066\u3044\u308b\u306e\u3067\u3001\u5168\u5c64\u306bDropout\u3092\u9069\u7528\u3057\u3066\u6642\u523b\u3054\u3068\u306b\u30de\u30b9\u30af\u3092\u5171\u6709\u3057\u306a\u3044\u5834\u5408\uff08\u5168\u5c64Dropout\uff09\u3068\u3001\u6642\u523b\u3054\u3068\u306b\u30de\u30b9\u30af\u3092\u5171\u6709\u3059\u308b\u5834\u5408\uff08\u5909\u5206Dropout\uff09\u3092\u65b0\u3057\u304f\u5b9f\u9a13\u3057\u307e\u3057\u305f\u3002\n\n\n\n\u30e2\u30c7\u30eb\n\u30d1\u30fc\u30d7\u30ec\u30ad\u30b7\u30c6\u30a3\n\n\n\n\nDropout\u306a\u3057\n114.5\n\n\n\u5168\u5c64Dropout\n108.4\n\n\n\u5165\u51fa\u529b\u306e\u307fDropout\uff08Zaremba 2014\uff09\n82.7\n\n\n\u5909\u5206Dropout\uff08Gal 2016\uff09\n82.5\n\n\n\n\u30e2\u30c7\u30eb\u306e\u6027\u80fd\u3092\u8868\u3059\u30c6\u30b9\u30c8\u30bb\u30c3\u30c8\u30d1\u30fc\u30d7\u30ec\u30ad\u30b7\u30c6\u30a3\uff08\u4f4e\u3044\u307b\u3046\u304c\u6027\u80fd\u304c\u826f\u3044\uff09\u306b\u304a\u3044\u3066\u3001\u5909\u5206Dropout\u304c\u5168\u5c64Dropout\u3088\u308a\u3082\u5927\u304d\u304f\u52dd\u3063\u3066\u3044\u308b\u3053\u3068\u304c\u308f\u304b\u308a\u307e\u3059\u3002\u5358\u7d14\u306b\u6642\u9593\u65b9\u5411\u3082\u542b\u3081\u3066\u5168\u5c64\u306bDropout\u3092\u9069\u7528\u3057\u3066\u3057\u307e\u3046\u3068\u30ce\u30a4\u30ba\u304c\u7d2f\u7a4d\u3057\u3066\u5b66\u7fd2\u3067\u304d\u306a\u3044\u306e\u306b\u5bfe\u3057\u3001Dropout\u3092\u30d9\u30a4\u30ba\u7684\u306b\u89e3\u91c8\u3057\u305f\u5909\u5206Dropout\u3067\u306f\u52b9\u679c\u7684\u306b\u5b66\u7fd2\u3057\u306a\u304c\u3089\u3082\u904e\u5b66\u7fd2\u3092\u6291\u5236\u3067\u304d\u3066\u3044\u308b\u3068\u8003\u3048\u3089\u308c\u307e\u3059\u3002\n\u5165\u51fa\u529b\u306e\u307fDropout\u3092\u9069\u7528\u3057\u305f\u5834\u5408\u3068\u6bd4\u3079\u3066\u3082\u3001\u308f\u305a\u304b\u306a\u304c\u3089\u5909\u5206Dropout\u306e\u307b\u3046\u304c\u512a\u308c\u3066\u3044\u308b\u3053\u3068\u304c\u308f\u304b\u308a\u307e\u3059\u3002\u5143\u8ad6\u6587\u3067\u306f\u3055\u3089\u306b\u91cd\u307f\u6e1b\u8870\u3084\u5c64\u5225drop\u78ba\u7387\u306a\u3069\u306e\u30c1\u30e5\u30fc\u30cb\u30f3\u30b0\u3067\u6027\u80fd\u3092\u7a3c\u3044\u3067\u3044\u307e\u3059\u304c\u3001RNN\u306e\u6642\u9593\u65b9\u5411\u306e\u30d1\u30e9\u30e1\u30fc\u30bf\u6570\u306f\u5165\u51fa\u529b\u5c64\u3068\u6bd4\u3079\u3066\u304b\u306a\u308a\u5c11\u306a\u3044\uff08\u5b9f\u9a13\u8a2d\u5b9a\u30676%\u307b\u3069\uff09\u306e\u3067\u3082\u3068\u3082\u3068\u904e\u5b66\u7fd2\u3057\u306b\u304f\u304f\u3001\u6b63\u5247\u5316\u306e\u52b9\u679c\u3082\u5f31\u3044\u3068\u8003\u3048\u3089\u308c\u307e\u3059\u3002\n\n\u304a\u308f\u308a\u306b\n\u4ee5\u524d\u30cb\u30e5\u30fc\u30e9\u30eb\u304b\u306a\u6f22\u5b57\u5909\u63db\u3092\u5b9f\u88c5\u3057\u305f\u3068\u304d\u306bDropout\u306e\u91cd\u8981\u6027\u3092\u5b9f\u611f\u3057\u3066\u3044\u305f\u306e\u3067\u3001NIPS 2016\u3067Gal\u3089\u306e\u30dd\u30b9\u30bf\u30fc\u767a\u8868\u3092\u898b\u304b\u3051\u305f\u3068\u304d\u306b\u306f\u8208\u5473\u3092\u305d\u305d\u3089\u308c\u307e\u3057\u305f\u3002\u5b9f\u9a13\u7d50\u679c\u304b\u3089\u306f\u8ffd\u52a0\u306e\u30c1\u30e5\u30fc\u30cb\u30f3\u30b0\u306a\u3057\u3067\u65e2\u5b58\u624b\u6cd5\u3068\u5927\u304d\u306a\u5dee\u3092\u3064\u3051\u308b\u3053\u3068\u304c\u96e3\u3057\u3044\u3053\u3068\u304c\u4f3a\u3048\u308b\u3082\u306e\u306e\u3001\u7406\u8ad6\u7684\u306a\u8003\u5bdf\u304b\u3089\u30b7\u30f3\u30d7\u30eb\u306a\u624b\u6cd5\u3092\u63d0\u6848\u3057\u65e2\u5b58\u624b\u6cd5\u306e\u7cbe\u5ea6\u3092\u6539\u5584\u3059\u308b\u3068\u3044\u3046\u8ad6\u6587\u306e\u304a\u624b\u672c\u306e\u3088\u3046\u306a\u7814\u7a76\u3067\u3057\u305f\u3002\u306a\u304a\u4eca\u56de\u306e\u5b9f\u88c5\u306fgist\u306b\u3066\u516c\u958b\u3057\u3066\u3044\u307e\u3059\u3002\nTensorFlow implementation of Variational Dropout\n\n\n\n\nRecurrent Neural Network Regularization, Wojciech Zaremba, Ilya Sutskever, Oriol Vinyals, ICLR 2015.\u00a0\u21a9\n\n\nA Theoretically Grounded Application of Dropout in Recurrent Neural Networks, Yarin Gal, Zoubin Ghahramani, NIPS 2016.\u00a0\u21a9\n\n\n\n# \u306f\u3058\u3081\u306b\n\u30c7\u30a3\u30fc\u30d7\u30e9\u30fc\u30cb\u30f3\u30b0\u306b\u304a\u3051\u308bDropout\u306f\u5358\u7d14\u304b\u3064\u5f37\u529b\u306a\u6b63\u5247\u5316\u624b\u6cd5\u3068\u3057\u3066\u5e83\u304f\u4f7f\u308f\u308c\u3066\u3044\u307e\u3059\u304c\u3001RNN\u306e\u6642\u9593\u65b9\u5411\u306b\u9069\u7528\u3059\u308b\u3068\u30ce\u30a4\u30ba\u304c\u84c4\u7a4d\u3057\u3066\u3046\u307e\u304f\u5b66\u7fd2\u3067\u304d\u306a\u3044\u305f\u3081\u3001\u5165\u51fa\u529b\u5c64\u306b\u306e\u307f\u9069\u7528\u3059\u308b\u306e\u304c\u5e38\u8b58\u3068\u3055\u308c\u3066\u304d\u307e\u3057\u305f[Zaremba 2014][^Zaremba]\u3002\u3057\u304b\u3057\u6700\u8fd1\u306e\u7814\u7a76\u3067Dropout\u3092\u30d9\u30a4\u30ba\u7684\u306b\u89e3\u91c8\u3059\u308b\u3053\u3068\u3067RNN\u306e\u6642\u9593\u65b9\u5411\u306b\u3082Dropout\u3092\u9069\u7528\u3067\u304d\u3001\u8a00\u8a9e\u30e2\u30c7\u30eb\u306e\u30bf\u30b9\u30af\u3067\u5358\u4e00\u30e2\u30c7\u30eb\u3068\u3057\u3066\u6700\u9ad8\u7cbe\u5ea6\u3092\u9054\u6210\u3059\u308b\u3053\u3068\u304c\u793a\u3055\u308c\u307e\u3057\u305f[Gal 2016][^Gal] \u4eca\u56de\u306f\u5909\u5206Dropout\u3068\u547c\u3070\u308c\u308b\u3053\u306e\u30e2\u30c7\u30eb\u3092TensorFlow\u3067\u5b9f\u88c5\u3057\u305f\u306e\u3067\u7d39\u4ecb\u3057\u305f\u3044\u3068\u601d\u3044\u307e\u3059\u3002\n\n[^Zaremba]: [Recurrent Neural Network Regularization, Wojciech Zaremba, Ilya Sutskever, Oriol Vinyals, ICLR 2015.](https://arxiv.org/abs/1409.2329)\n[^Gal]: [A Theoretically Grounded Application of Dropout in Recurrent Neural Networks, Yarin Gal, Zoubin Ghahramani, NIPS 2016.](https://arxiv.org/abs/1512.05287)\n\n\n# Dropout\u306e\u30d9\u30a4\u30ba\u7684\u89e3\u91c8\u3068RNN\u3078\u306e\u9069\u7528\n\u30cb\u30e5\u30fc\u30e9\u30eb\u30cd\u30c3\u30c8\u30ef\u30fc\u30af\u306e\u30d1\u30e9\u30e1\u30fc\u30bf\u306e\u4e8b\u5f8c\u5206\u5e03\u3092\u300c\u5b66\u7fd2\u3059\u308b\u901a\u5e38\u306e\u30d1\u30e9\u30e1\u30fc\u30bf\u300d\u3068\u300c\u5b66\u7fd2\u3057\u306a\u3044\u30d1\u30e9\u30e1\u30fc\u30bf\uff1d\uff10\u300d\u306e2\u3064\u3092\u4e2d\u5fc3\u3068\u3059\u308b\u6df7\u5408\u30ac\u30a6\u30b9\u5206\u5e03\u3067\u8fd1\u4f3c\u3059\u308b\u3053\u3068\u306b\u3088\u308aDropout\u3068\u540c\u69d8\u306e\u30a2\u30eb\u30b4\u30ea\u30ba\u30e0\u304c\u5f97\u3089\u308c\u308b\u3053\u3068\u304c\u308f\u304b\u3063\u3066\u3044\u307e\u3059\u3002Dropout\u306e\u89e3\u91c8\u3068\u3057\u3066\u7570\u306a\u308b\u30cd\u30c3\u30c8\u30ef\u30fc\u30af\u306e\u30a2\u30f3\u30b5\u30f3\u30d6\u30eb\u3092\u63a1\u7528\u3057\u305f\u5834\u5408\u3068\u7570\u306a\u308a\u3001\u3053\u306e\u89e3\u91c8\u3067\u306f\u30d1\u30e9\u30e1\u30fc\u30bf\u3092\u5171\u6709\u3059\u308b\u30ec\u30a4\u30e4\u30fc\u306f\u540c\u3058\u30e6\u30cb\u30c3\u30c8\u3092drop\u3059\u308b\u5fc5\u8981\u304c\u3042\u308a\u307e\u3059\u3002RNN\u3067\u306f\u6642\u9593\u65b9\u5411\u3067\u540c\u3058\u30d1\u30e9\u30e1\u30fc\u30bf\u3092\u5171\u6709\u3057\u307e\u3059\u304b\u3089\u3001\u3069\u306e\u30e6\u30cb\u30c3\u30c8\u3092drop\u3059\u308b\u304b\u3092\u6c7a\u3081\u308b0/1\u306e\u5024\u3092\u53d6\u308b\u30de\u30b9\u30af\u3092\u7570\u306a\u308b\u6642\u523b\u3067\u5171\u6709\u3059\u308b\u3053\u3068\u3067\u3053\u306e\u89e3\u91c8\u3092\u5b9f\u88c5\u3059\u308b\u3053\u3068\u304c\u3067\u304d\u307e\u3059\u3002\n\n![Screen Shot 2016-12-21 at 16.18.36.png](https://qiita-image-store.s3.amazonaws.com/0/23665/cfae4889-e141-86b0-540e-18a1429f9066.png)\n\n\u56f3\u306b\u304a\u3051\u308b\u7570\u306a\u308b\u8272\u306fDropout\u306e\u30de\u30b9\u30af\u304c\u7570\u306a\u308b\u3053\u3068\u3092\u8868\u3057\u3001\u70b9\u7dda\u306fDropout\u304c\u9069\u7528\u3055\u308c\u306a\u3044\u3053\u3068\u3092\u8868\u3057\u3066\u3044\u307e\u3059\u3002\u5f93\u6765\u306eDropout\u304c\u6642\u9593\u65b9\u5411\u3078\u306e\u9069\u7528\u3092\u907f\u3051\u3066\u5165\u51fa\u529b\u5c64\u306b\u306e\u307f\u9069\u7528\u3055\u308c\u308b\u306e\u306b\u5bfe\u3057\u3001\u5909\u5206Dropout\u3067\u306f\u6642\u9593\u65b9\u5411\u306b\u3082\u9069\u7528\u3057\u6bce\u6642\u523b\u3067\u540c\u3058\u30de\u30b9\u30af\u3092\u5171\u6709\u3057\u307e\u3059\u3002\n\n# TensorFlow\u306b\u3088\u308b\u5b9f\u88c5\nTensorFlow 0.10\u3092\u4f7f\u3063\u3066\u5909\u5206Dropout\u3092\u5b9f\u88c5\u3057\u307e\u3057\u305f\u3002TensorFlow\u306e[RNN\u30c1\u30e5\u30fc\u30c8\u30ea\u30a2\u30eb](https://www.tensorflow.org/tutorials/recurrent/)\u3067\u306f[Zaremba 2014]\u3092\u5b9f\u88c5\u3057\u3066\u3044\u307e\u3059\u304b\u3089\u3001\u3053\u308c\u3092\u3082\u3068\u306b\u6539\u9020\u3057\u3066\u3044\u304d\u307e\u3059\u3002\u5b9f\u88c5\u3059\u308b\u306e\u306f\u8ad6\u6587\u4e2d\u306euntied(no MC)\u3067\u3059\u3002\n\n```py3:variational_dropout_wrapper.py\nimport tensorflow as tf\nfrom tensorflow.python.ops.rnn_cell import RNNCell\n\n\ndef get_dropout_mask(keep_prob, shape):\n  keep_prob = tf.convert_to_tensor(keep_prob)\n  random_tensor = keep_prob + tf.random_uniform(shape)\n  binary_tensor = tf.floor(random_tensor)\n  dropout_mask = tf.inv(keep_prob) * binary_tensor\n  return dropout_mask\n\n\nclass VariationalDropoutWrapper(RNNCell):\n  def __init__(self, cell, batch_size, keep_prob):\n    self._cell = cell\n    self._output_dropout_mask = get_dropout_mask(keep_prob, [batch_size, cell.output_size])\n    self._state_dropout_mask = get_dropout_mask(keep_prob, [batch_size, int(cell.state_size / 2)])\n\n  @property\n  def state_size(self):\n    return self._cell.state_size\n\n  @property\n  def output_size(self):\n    return self._cell.output_size\n\n  def __call__(self, inputs, state, scope=None):\n    # TODO: suppport non-LSTM cells and state_is_tuple=True\n    c, h = tf.split(1, 2, state)\n    h *= self._state_dropout_mask\n    state = tf.concat(1, [c, h])\n    output, new_state = self._cell(inputs, state, scope)\n    output *= self._output_dropout_mask\n    return output, new_state\n```\n\n\u3053\u306e\u30e2\u30b8\u30e5\u30fc\u30eb\u3092\u4f7f\u3063\u3066\u30c1\u30e5\u30fc\u30c8\u30ea\u30a2\u30eb\u306e[ptb_word_lm.py](https://github.com/tensorflow/tensorflow/blob/r0.10/tensorflow/models/rnn/ptb/ptb_word_lm.py)\u306b\u4ee5\u4e0b\u306e\u30d1\u30c3\u30c1\u3092\u5f53\u3066\u308c\u3070\u5909\u5206Dropout\u304c\u4f7f\u3048\u308b\u3088\u3046\u306b\u306a\u308a\u307e\u3059\uff08\u3053\u306e\u30b9\u30af\u30ea\u30d7\u30c8\u306fTensorFlow\u306e\u30d0\u30fc\u30b8\u30e7\u30f3\u306b\u3088\u3063\u3066\u5927\u304d\u304f\u5909\u308f\u308b\u306e\u3067\u6ce8\u610f\uff09\u3002\n\n```diff\n65a66,67\n> from variational_dropout_wrapper import VariationalDropoutWrapper, get_dropout_mask\n>\n99,102c101,107\n<     if is_training and config.keep_prob < 1:\n<       lstm_cell = tf.nn.rnn_cell.DropoutWrapper(\n<           lstm_cell, output_keep_prob=config.keep_prob)\n<     cell = tf.nn.rnn_cell.MultiRNNCell([lstm_cell] * config.num_layers)\n---\n>\n>     # To avoid using same dropout mask in different layers, create new dropout wrapper per layer\n>     cells = []\n>     for i in range(config.num_layers):\n>       with tf.variable_scope(\"layer\" + i):\n>         cells.append(VariationalDropoutWrapper(lstm_cell, batch_size, keep_prob=config.keep_prob))\n>     cell = tf.nn.rnn_cell.MultiRNNCell(cells)\n112c117,119\n<       inputs = tf.nn.dropout(inputs, config.keep_prob)\n---\n>       # use same dropout mask across time steps, but keep different masks for samples and units\n>       dropout_mask = get_dropout_mask(config.keep_prob, [batch_size, size])\n>       inputs *= tf.expand_dims(dropout_mask, 1)\n```\n\n# \u5b9f\u9a13\u7d50\u679c\n[Zaremba 2014]\u306emedium\u8a2d\u5b9a\u306b\u5f93\u3044\u3001PennTreeBank\u30c7\u30fc\u30bf\u30bb\u30c3\u30c8\u306b\u304a\u3051\u308bLSTM\u8a00\u8a9e\u30e2\u30c7\u30eb\u306e\u6027\u80fd\u3092\u8a55\u4fa1\u3057\u307e\u3057\u305f\u3002Dropout\u306a\u3057\u306e\u5834\u5408\u3068\u5165\u51fa\u529b\u306e\u307fDropout\u306e\u5834\u5408\u306fZaremba\u3089\u306e\u8ad6\u6587\u306b\u8a18\u8f09\u3055\u308c\u3066\u3044\u308b\u306e\u3067\u3001\u5168\u5c64\u306bDropout\u3092\u9069\u7528\u3057\u3066\u6642\u523b\u3054\u3068\u306b\u30de\u30b9\u30af\u3092\u5171\u6709\u3057\u306a\u3044\u5834\u5408\uff08\u5168\u5c64Dropout\uff09\u3068\u3001\u6642\u523b\u3054\u3068\u306b\u30de\u30b9\u30af\u3092\u5171\u6709\u3059\u308b\u5834\u5408\uff08\u5909\u5206Dropout\uff09\u3092\u65b0\u3057\u304f\u5b9f\u9a13\u3057\u307e\u3057\u305f\u3002\n\n| \u30e2\u30c7\u30eb | \u30d1\u30fc\u30d7\u30ec\u30ad\u30b7\u30c6\u30a3 |\n|:-:|:-:|\n| Dropout\u306a\u3057 | 114.5 |\n| \u5168\u5c64Dropout | 108.4  |\n| \u5165\u51fa\u529b\u306e\u307fDropout\uff08Zaremba 2014\uff09 | 82.7 |\n| \u5909\u5206Dropout\uff08Gal 2016\uff09 | **82.5** |\n\n\u30e2\u30c7\u30eb\u306e\u6027\u80fd\u3092\u8868\u3059\u30c6\u30b9\u30c8\u30bb\u30c3\u30c8\u30d1\u30fc\u30d7\u30ec\u30ad\u30b7\u30c6\u30a3\uff08\u4f4e\u3044\u307b\u3046\u304c\u6027\u80fd\u304c\u826f\u3044\uff09\u306b\u304a\u3044\u3066\u3001\u5909\u5206Dropout\u304c\u5168\u5c64Dropout\u3088\u308a\u3082\u5927\u304d\u304f\u52dd\u3063\u3066\u3044\u308b\u3053\u3068\u304c\u308f\u304b\u308a\u307e\u3059\u3002\u5358\u7d14\u306b\u6642\u9593\u65b9\u5411\u3082\u542b\u3081\u3066\u5168\u5c64\u306bDropout\u3092\u9069\u7528\u3057\u3066\u3057\u307e\u3046\u3068\u30ce\u30a4\u30ba\u304c\u7d2f\u7a4d\u3057\u3066\u5b66\u7fd2\u3067\u304d\u306a\u3044\u306e\u306b\u5bfe\u3057\u3001Dropout\u3092\u30d9\u30a4\u30ba\u7684\u306b\u89e3\u91c8\u3057\u305f\u5909\u5206Dropout\u3067\u306f\u52b9\u679c\u7684\u306b\u5b66\u7fd2\u3057\u306a\u304c\u3089\u3082\u904e\u5b66\u7fd2\u3092\u6291\u5236\u3067\u304d\u3066\u3044\u308b\u3068\u8003\u3048\u3089\u308c\u307e\u3059\u3002\n\n\u5165\u51fa\u529b\u306e\u307fDropout\u3092\u9069\u7528\u3057\u305f\u5834\u5408\u3068\u6bd4\u3079\u3066\u3082\u3001\u308f\u305a\u304b\u306a\u304c\u3089\u5909\u5206Dropout\u306e\u307b\u3046\u304c\u512a\u308c\u3066\u3044\u308b\u3053\u3068\u304c\u308f\u304b\u308a\u307e\u3059\u3002\u5143\u8ad6\u6587\u3067\u306f\u3055\u3089\u306b\u91cd\u307f\u6e1b\u8870\u3084\u5c64\u5225drop\u78ba\u7387\u306a\u3069\u306e\u30c1\u30e5\u30fc\u30cb\u30f3\u30b0\u3067\u6027\u80fd\u3092\u7a3c\u3044\u3067\u3044\u307e\u3059\u304c\u3001RNN\u306e\u6642\u9593\u65b9\u5411\u306e\u30d1\u30e9\u30e1\u30fc\u30bf\u6570\u306f\u5165\u51fa\u529b\u5c64\u3068\u6bd4\u3079\u3066\u304b\u306a\u308a\u5c11\u306a\u3044\uff08\u5b9f\u9a13\u8a2d\u5b9a\u30676%\u307b\u3069\uff09\u306e\u3067\u3082\u3068\u3082\u3068\u904e\u5b66\u7fd2\u3057\u306b\u304f\u304f\u3001\u6b63\u5247\u5316\u306e\u52b9\u679c\u3082\u5f31\u3044\u3068\u8003\u3048\u3089\u308c\u307e\u3059\u3002\n\n# \u304a\u308f\u308a\u306b\n\u4ee5\u524d[\u30cb\u30e5\u30fc\u30e9\u30eb\u304b\u306a\u6f22\u5b57\u5909\u63db](http://qiita.com/yoh_okuno/items/c4ad13daa48714bdb29e)\u3092\u5b9f\u88c5\u3057\u305f\u3068\u304d\u306bDropout\u306e\u91cd\u8981\u6027\u3092\u5b9f\u611f\u3057\u3066\u3044\u305f\u306e\u3067\u3001[NIPS 2016](http://qiita.com/yoh_okuno/items/2494bc79630eb57e81ba)\u3067Gal\u3089\u306e\u30dd\u30b9\u30bf\u30fc\u767a\u8868\u3092\u898b\u304b\u3051\u305f\u3068\u304d\u306b\u306f\u8208\u5473\u3092\u305d\u305d\u3089\u308c\u307e\u3057\u305f\u3002\u5b9f\u9a13\u7d50\u679c\u304b\u3089\u306f\u8ffd\u52a0\u306e\u30c1\u30e5\u30fc\u30cb\u30f3\u30b0\u306a\u3057\u3067\u65e2\u5b58\u624b\u6cd5\u3068\u5927\u304d\u306a\u5dee\u3092\u3064\u3051\u308b\u3053\u3068\u304c\u96e3\u3057\u3044\u3053\u3068\u304c\u4f3a\u3048\u308b\u3082\u306e\u306e\u3001\u7406\u8ad6\u7684\u306a\u8003\u5bdf\u304b\u3089\u30b7\u30f3\u30d7\u30eb\u306a\u624b\u6cd5\u3092\u63d0\u6848\u3057\u65e2\u5b58\u624b\u6cd5\u306e\u7cbe\u5ea6\u3092\u6539\u5584\u3059\u308b\u3068\u3044\u3046\u8ad6\u6587\u306e\u304a\u624b\u672c\u306e\u3088\u3046\u306a\u7814\u7a76\u3067\u3057\u305f\u3002\u306a\u304a\u4eca\u56de\u306e\u5b9f\u88c5\u306fgist\u306b\u3066\u516c\u958b\u3057\u3066\u3044\u307e\u3059\u3002\n[TensorFlow implementation of Variational Dropout](https://gist.github.com/yohokuno/8d6661d7e0c85ba4d03d5d7a2b15a2b6)\n", "tags": ["DeepLearning", "TensorFlow", "\u6a5f\u68b0\u5b66\u7fd2", "\u81ea\u7136\u8a00\u8a9e\u51e6\u7406"]}