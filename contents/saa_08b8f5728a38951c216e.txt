{"context": "\u30e1\u30e2\u3002\n\u306a\u305c\u304b\uff12\uff10\u500b\u307e\u3067\u3057\u304b\u30c0\u30a6\u30f3\u30ed\u30fc\u30c9\u3067\u304d\u306a\u3044\u3067\u3059\u304c\u3002\u3002\n\n7/13\u8ffd\u8a18\n\u30b3\u30e1\u30f3\u30c8\u3092\u9802\u3044\u305f\u901a\u308a\u3001selenium\u3092\u4f7f\u3063\u3066javascript\u3092\u6709\u52b9\u306b\u3057\u3064\u3064400dl\u307e\u3067\u5897\u3084\u3057\u307e\u3057\u305f\u3002\nchromedriver\u304c\u5fc5\u8981\u3067\u3059\u3002https://sites.google.com/a/chromium.org/chromedriver/downloads\n\nget_img.py\n#-*- coding:utf-8 -*-\nimport os\nimport urllib2\nimport re\nfrom bs4 import BeautifulSoup\n\ndef get_ulist_o(search_word):\n    #\u524d\u306e\u30d0\u30fc\u30b8\u30e7\u30f3\n    #http://stackoverflow.com/questions/20716842/python-download-images-from-google-image-search\n    url=\"https://www.google.co.in/search?q=\"+search_word+\"&source=lnms&tbm=isch\"\n    header = {'User-Agent': 'Mozilla/5.0'}\n    soup=BeautifulSoup(urllib2.urlopen(urllib2.Request(url,headers=header)),\"lxml\") \n    ulist = [a['src'] for a in soup.find_all(\"img\", {\"src\": re.compile(\"gstatic.com\")})]\n    return ulist\n\ndef get_ulist(search_word,n):\n    #\u65b0\u3057\u3044\u30d0\u30fc\u30b8\u30e7\u30f3\n    from selenium import webdriver\n    from ast import literal_eval\n    if n>400:print(\"n should be less than 400\");exit()\n\n    url=\"https://www.google.co.in/search?q=\"+search_word+\"&source=lnms&tbm=isch\"\n    chromedriver = \"./chromedriver\"\n    driver = webdriver.Chrome(chromedriver)\n    driver.get(url)\n\n    cnt=0\n    while (cnt<n):\n      driver.execute_script(\"window.scrollTo(0, document.body.scrollHeight);\")\n      page_source= driver.page_source\n      soup=BeautifulSoup(page_source,\"lxml\")\n      soup= soup.find_all('div', class_=\"rg_meta\")\n      cnt=len(soup)\n    else:\n      driver.quit()\n\n    ulist=[]\n    for i in soup:\n      dic=i.text.replace(\"false\",\"False\").replace(\"true\",\"True\")\n      ulist.append(literal_eval(dic)[\"ou\"])\n    return ulist[:n]\n\ndef get_img(search_word,n):\n    FOLDERNAME=str(search_word)\n    if os.path.exists(FOLDERNAME)==False:\n      os.mkdir(FOLDERNAME)\n\n    urls=get_ulist(search_word,n)\n\n    for cntr,img in enumerate(urls): \n      print \"[%03d]Donloading.. %s\"%(cntr,img)\n      try:\n          raw_img = urllib2.urlopen(img).read()\n          f = open('%s/%s_%03d.jpg' % (FOLDERNAME, search_word, cntr), 'wb')\n          f.write(raw_img)\n          f.close()\n      except:\n          pass\n\nget_img(\"\u306d\u3053 \u304b\u308f\u3044\u3044\",10)\n\n\n\n\n\n\u3055\u3044\u3054\u306b\n\u3044\u304b\u306a\u308b\u7528\u9014\u306b\u304a\u3044\u3066\u3082\u3001\u4f7f\u7528\u3059\u308b\u306e\u306f\u3084\u3081\u3066\u304f\u3060\u3055\u3044\u3002\n\n\u30e1\u30e2\u3002\n\u306a\u305c\u304b\uff12\uff10\u500b\u307e\u3067\u3057\u304b\u30c0\u30a6\u30f3\u30ed\u30fc\u30c9\u3067\u304d\u306a\u3044\u3067\u3059\u304c\u3002\u3002\n\n#7/13\u8ffd\u8a18\n\u30b3\u30e1\u30f3\u30c8\u3092\u9802\u3044\u305f\u901a\u308a\u3001selenium\u3092\u4f7f\u3063\u3066javascript\u3092\u6709\u52b9\u306b\u3057\u3064\u3064400dl\u307e\u3067\u5897\u3084\u3057\u307e\u3057\u305f\u3002\nchromedriver\u304c\u5fc5\u8981\u3067\u3059\u3002https://sites.google.com/a/chromium.org/chromedriver/downloads\n\n```py:get_img.py\n#-*- coding:utf-8 -*-\nimport os\nimport urllib2\nimport re\nfrom bs4 import BeautifulSoup\n\ndef get_ulist_o(search_word):\n    #\u524d\u306e\u30d0\u30fc\u30b8\u30e7\u30f3\n    #http://stackoverflow.com/questions/20716842/python-download-images-from-google-image-search\n    url=\"https://www.google.co.in/search?q=\"+search_word+\"&source=lnms&tbm=isch\"\n    header = {'User-Agent': 'Mozilla/5.0'}\n    soup=BeautifulSoup(urllib2.urlopen(urllib2.Request(url,headers=header)),\"lxml\") \n    ulist = [a['src'] for a in soup.find_all(\"img\", {\"src\": re.compile(\"gstatic.com\")})]\n    return ulist\n\ndef get_ulist(search_word,n):\n    #\u65b0\u3057\u3044\u30d0\u30fc\u30b8\u30e7\u30f3\n    from selenium import webdriver\n    from ast import literal_eval\n    if n>400:print(\"n should be less than 400\");exit()\n\n    url=\"https://www.google.co.in/search?q=\"+search_word+\"&source=lnms&tbm=isch\"\n    chromedriver = \"./chromedriver\"\n    driver = webdriver.Chrome(chromedriver)\n    driver.get(url)\n\n    cnt=0\n    while (cnt<n):\n      driver.execute_script(\"window.scrollTo(0, document.body.scrollHeight);\")\n      page_source= driver.page_source\n      soup=BeautifulSoup(page_source,\"lxml\")\n      soup= soup.find_all('div', class_=\"rg_meta\")\n      cnt=len(soup)\n    else:\n      driver.quit()\n\n    ulist=[]\n    for i in soup:\n      dic=i.text.replace(\"false\",\"False\").replace(\"true\",\"True\")\n      ulist.append(literal_eval(dic)[\"ou\"])\n    return ulist[:n]\n\ndef get_img(search_word,n):\n    FOLDERNAME=str(search_word)\n    if os.path.exists(FOLDERNAME)==False:\n      os.mkdir(FOLDERNAME)\n\n    urls=get_ulist(search_word,n)\n\n    for cntr,img in enumerate(urls): \n      print \"[%03d]Donloading.. %s\"%(cntr,img)\n      try:\n          raw_img = urllib2.urlopen(img).read()\n          f = open('%s/%s_%03d.jpg' % (FOLDERNAME, search_word, cntr), 'wb')\n          f.write(raw_img)\n          f.close()\n      except:\n          pass\n\nget_img(\"\u306d\u3053 \u304b\u308f\u3044\u3044\",10)\n\n\n```\n\n\n#\u3055\u3044\u3054\u306b\n\u3044\u304b\u306a\u308b\u7528\u9014\u306b\u304a\u3044\u3066\u3082\u3001\u4f7f\u7528\u3059\u308b\u306e\u306f\u3084\u3081\u3066\u304f\u3060\u3055\u3044\u3002\n", "tags": ["Python", "Selenium"]}