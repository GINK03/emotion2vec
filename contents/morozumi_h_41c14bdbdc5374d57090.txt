{"context": " More than 1 year has passed since last update.\n\nApache Spark\u3092EC2\u4e0a\u3067\u52d5\u304b\u3059\nApache Spark 1.0 \u304c\u30ea\u30ea\u30fc\u30b9\u3055\u308c\u307e\u3057\u305f\u3002\nEC2\u4e0a\u3067\u52d5\u304b\u3059Script\u304c\u7528\u610f\u3055\u308c\u3066\u3044\u308b\u3068\u306e\u3053\u3068\u306a\u306e\u3067\u65e9\u901f\u8a66\u3057\u3066\u307f\u307e\u3057\u305f\u3002\n\nApache Spark \u30a4\u30f3\u30b9\u30c8\u30fc\u30eb\nCloudera\u306e\u30ea\u30dd\u30b8\u30c8\u30ea\u306b\u307e\u30601.0\u304c\u4e0a\u304c\u3063\u3066\u3044\u306a\u3044\u305f\u3081\u624b\u52d5\u3067\u30a4\u30f3\u30b9\u30c8\u30fc\u30eb\u3059\u308b\u3053\u3068\u306b\u3057\u307e\u3059\u3002\n\nCloudera\u306e\u30ea\u30dd\u30b8\u30c8\u30ea\u304b\u3089\u30a4\u30f3\u30b9\u30c8\u30fc\u30eb\u3059\u308b\u5834\u5408\nsudo yum install http://archive.cloudera.com/cdh5/one-click-install/redhat/6/x86_64/cloudera-cdh-5-0.x86_64.rpm\nsudo rpm --import http://archive.cloudera.com/cdh5/redhat/6/x86_64/cdh/RPM-GPG-KEY-cloudera\nsudo yum install spark-core spark-master spark-worker spark-history-server spark-python\n\n\u203b\u3053\u306e\u30ea\u30dd\u30b8\u30c8\u30ea\u3067\u306fSpark\u306e\u30d0\u30fc\u30b8\u30e7\u30f3\u306f0.9.0\u306a\u306e\u3067\u6ce8\u610f\n\n\u624b\u52d5\u3067\u30a4\u30f3\u30b9\u30c8\u30fc\u30eb\u3059\u308b\nwget http://d3kbcqa49mib13.cloudfront.net/spark-1.0.0-bin-hadoop2.tgz\ntar xzvf spark-1.0.0-bin-hadoop2.tgz\n\n\n\u52d5\u4f5c\u78ba\u8a8d\n\u53c2\u8003\u30b5\u30a4\u30c8\uff1a\nSpark Overview - Spark 1.0.0 Documentation\nSpark\u306e\u30a4\u30f3\u30b9\u30c8\u30fc\u30eb\u30c7\u30a3\u30ec\u30af\u30c8\u30ea\u3078\u79fb\u52d5\u3057\u3001\u4e0b\u8a18\u30b3\u30de\u30f3\u30c9\u3092\u5b9f\u884c\u3059\u308b\u3002\n./bin/run-example SparkPi 10\n\n\u30ed\u30b0\u304c\u51fa\u529b\u3055\u308c\u3001\u7d50\u679c\u304c\u8868\u793a\u3055\u308c\u307e\u3057\u305f\u3002\nPi is roughly 3.142832\n\n\n\u30a4\u30f3\u30bf\u30e9\u30af\u30c6\u30a3\u30d6\u30b7\u30a7\u30eb\u3092\u8a66\u3057\u3066\u307f\u308b\n\u53c2\u8003\u30b5\u30a4\u30c8\uff1a\nQuick Start - Spark 1.0.0 Documentation\nApache Spark \u30c9\u30ad\u30e5\u30e1\u30f3\u30c8\u548c\u8a33 - Quick Start - Qiita\n./bin/spark-shell\n\n...\n...\nWelcome to\n      ____              __\n     / __/__  ___ _____/ /__\n    _\\ \\/ _ \\/ _ `/ __/  '_/\n   /___/ .__/\\_,_/_/ /_/\\_\\   version 1.0.0\n      /_/\n\nUsing Scala version 2.10.4 (OpenJDK 64-Bit Server VM, Java 1.7.0_55)\nType in expressions to have them evaluated.\n...\n...\nSpark context available as sc.\n\nscala> \n\nscala> val textFile = sc.textFile(\"README.md\")\ntextFile: org.apache.spark.rdd.RDD[String] = MappedRDD[1] at textFile at <console>:12\n\nscala> textFile.count()\nres0: Long = 127\n\nscala> textFile.first()\nres1: String = # Apache Spark\n\n\u4ed6\u306b\u3082\u30b5\u30f3\u30d7\u30eb\u3084QuickStart\u304c\u3042\u308b\u306e\u3067\u8a66\u3057\u3066\u307f\u3066\u304f\u3060\u3055\u3044\u3002\n\nspark-ec2 script\n\u53c2\u8003\u306b\u3057\u305f\u30b5\u30a4\u30c8\uff1a\nRunning Spark on EC2 - Spark 1.0.0 Documentation\nApache Spark \u30c9\u30ad\u30e5\u30e1\u30f3\u30c8\u548c\u8a33 - Apache Spark on AWS EC2 - Qiita\n\n\u4e8b\u524d\u4f5c\u696d\nKey Pair\u3092\u4f5c\u6210\u3057\u3066\u304a\u304f\u5fc5\u8981\u304c\u3042\u308a\u307e\u3059\u3002\n\u4eca\u56de\u306f\u3001spark-demo.pem\u3092\u4f5c\u6210\u3057\u307e\u3057\u305f\u3002\n\n\u74b0\u5883\u5909\u6570\u3092\u8a2d\u5b9a\nexport AWS_ACCESS_KEY_ID=XXXXXXXX\nexport AWS_SECRET_ACCESS_KEY=YYYYYYYY\n\n\u203b\u672c\u756a\u3067\u306f\u3001- IAM roles for EC2 instances\u3092\u4f7f\u3046\u3053\u3068\u306b\u306a\u308b\u304b\u3068\u601d\u3044\u307e\u3059\u3002\n\n\u30af\u30e9\u30b9\u30bf\u3092\u8d77\u52d5\u3059\u308b\nec2\u30c7\u30a3\u30ec\u30af\u30c8\u30ea\u3078\u79fb\u52d5\u3059\u308b\ncd spark-1.0.0-bin-hadoop2/ec2\n\n\u4ee5\u4e0b\u306e\u30b3\u30de\u30f3\u30c9\u3092\u5b9f\u884c\u3059\u308b\n./spark-ec2 -k spark-demo -i spark-demo.pem -s 2 launch spark-demo --instance-type t1.micro --region ap-northeast-1\n\n\n\u8d77\u52d5\u3057\u307e\u3057\u305f\u304c\u3001\u30b3\u30f3\u30bd\u30fc\u30eb\u4e0a\u306b\u30a8\u30e9\u30fc\u304c\u51fa\u3066\u3044\u307e\u3059\u3002\nSetting up security groups...\nCreating security group spark-demo-master\nCreating security group spark-demo-slaves\nSearching for existing cluster spark-demo...\nSpark AMI: ami-c7bfd4c6\nLaunching instances...\nLaunched 2 slaves in ap-northeast-1c, regid = r-713a2977\nLaunched master in ap-northeast-1c, regid = r-c7392ac1\nWaiting for instances to start up...\nWaiting 120 more seconds...\nGenerating cluster's SSH key on master...\nssh: connect to host ec2-xx-xxx-xx-xxx.ap-northeast-1.compute.amazonaws.com port 22: Connection refused\nError executing remote command, retrying after 30 seconds: Command '['ssh', '-o', 'StrictHostKeyChecking=no', '-i', 'spark-demo.pem', '-t', '-t', u'root@ec2-xx-xxx-xx-xxx.ap-northeast-1.compute.amazonaws.com', \"\\n      [ -f ~/.ssh/id_rsa ] ||\\n        (ssh-keygen -q -t rsa -N '' -f ~/.ssh/id_rsa &&\\n         cat ~/.ssh/id_rsa.pub >> ~/.ssh/authorized_keys)\\n    \"]' returned non-zero exit status 255\nssh: connect to host ec2-xx-xxx-xx-xxx.ap-northeast-1.compute.amazonaws.com port 22: Connection refused\nError executing remote command, retrying after 30 seconds: Command '['ssh', '-o', 'StrictHostKeyChecking=no', '-i', 'spark-demo.pem', '-t', '-t', u'root@ec2-xx-xxx-xx-xxx.ap-northeast-1.compute.amazonaws.com', \"\\n      [ -f ~/.ssh/id_rsa ] ||\\n        (ssh-keygen -q -t rsa -N '' -f ~/.ssh/id_rsa &&\\n         cat ~/.ssh/id_rsa.pub >> ~/.ssh/authorized_keys)\\n    \"]' returned non-zero exit status 255\nssh: connect to host ec2-xx-xxx-xx-xxx.ap-northeast-1.compute.amazonaws.com port 22: Connection refused\nError executing remote command, retrying after 30 seconds: Command '['ssh', '-o', 'StrictHostKeyChecking=no', '-i', 'spark-demo.pem', '-t', '-t', u'root@ec2-xx-xxx-xx-xxx.ap-northeast-1.compute.amazonaws.com', \"\\n      [ -f ~/.ssh/id_rsa ] ||\\n        (ssh-keygen -q -t rsa -N '' -f ~/.ssh/id_rsa &&\\n         cat ~/.ssh/id_rsa.pub >> ~/.ssh/authorized_keys)\\n    \"]' returned non-zero exit status 255\nssh: connect to host ec2-xx-xxx-xx-xxx.ap-northeast-1.compute.amazonaws.com port 22: Connection refused\nError executing remote command, retrying after 30 seconds: Command '['ssh', '-o', 'StrictHostKeyChecking=no', '-i', 'spark-demo.pem', '-t', '-t', u'root@ec2-xx-xxx-xx-xxx.ap-northeast-1.compute.amazonaws.com', \"\\n      [ -f ~/.ssh/id_rsa ] ||\\n        (ssh-keygen -q -t rsa -N '' -f ~/.ssh/id_rsa &&\\n         cat ~/.ssh/id_rsa.pub >> ~/.ssh/authorized_keys)\\n    \"]' returned non-zero exit status 255\nWarning: Permanently added 'ec2-xx-xxx-xx-xxx.ap-northeast-1.compute.amazonaws.com,xx-xxx-xx-xxx' (ECDSA) to the list of known hosts.\nConnection to ec2-xx-xxx-xx-xxx.ap-northeast-1.compute.amazonaws.com closed.\nTraceback (most recent call last):\n  File \"./spark_ec2.py\", line 823, in <module>\n    main()\n  File \"./spark_ec2.py\", line 815, in main\n    real_main()\n  File \"./spark_ec2.py\", line 700, in real_main\n    setup_cluster(conn, master_nodes, slave_nodes, opts, True)\n  File \"./spark_ec2.py\", line 430, in setup_cluster\n    dot_ssh_tar = ssh_read(master, opts, ['tar', 'c', '.ssh'])\n  File \"./spark_ec2.py\", line 637, in ssh_read\n    return subprocess.check_output(\nAttributeError: 'module' object has no attribute 'check_output'\n\n\u4e0b\u8a18\u30b3\u30de\u30f3\u30c9\u3067SSH\u3092\u4f7f\u7528\u3057\u3066\u30af\u30e9\u30b9\u30bf\u306b\u30ed\u30b0\u30a4\u30f3\u3092\u884c\u3046\n./spark-ec2 -k <keypair> -i <key-file> login <cluster-name>\n\n\u30c0\u30e1\u3067\u3059\u306d\u3002\u3002\u3002\n\u30af\u30e9\u30b9\u30bf\u3092\u505c\u6b62\u3057\u3066\u307f\u308b\u3002\n./spark-ec2 stop spark-demo\n\n\u6b62\u307e\u3089\u306a\u3044\u30fb\u30fb\u30fb\n\u30af\u30e9\u30b9\u30bf\u3092\u7834\u68c4\u3057\u3066\u307f\u308b\u3002\n./spark-ec2 destroy spark-demo\n\n\u30bf\u30fc\u30df\u30cd\u30fc\u30c8\u3055\u308c\u306a\u3044\u3002\u3002\u3002\n\u3068\u308a\u3042\u3048\u305a\u3001\u624b\u52d5\u3067\u505c\u6b62\u3057\u3066\u307f\u307e\u3057\u305f\u3002\n\u7d9a\u304d\u306f\u4eca\u5ea6\u3002\n# Apache Spark\u3092EC2\u4e0a\u3067\u52d5\u304b\u3059\nApache Spark 1.0 \u304c\u30ea\u30ea\u30fc\u30b9\u3055\u308c\u307e\u3057\u305f\u3002\nEC2\u4e0a\u3067\u52d5\u304b\u3059Script\u304c\u7528\u610f\u3055\u308c\u3066\u3044\u308b\u3068\u306e\u3053\u3068\u306a\u306e\u3067\u65e9\u901f\u8a66\u3057\u3066\u307f\u307e\u3057\u305f\u3002\n\n# Apache Spark \u30a4\u30f3\u30b9\u30c8\u30fc\u30eb\nCloudera\u306e\u30ea\u30dd\u30b8\u30c8\u30ea\u306b\u307e\u30601.0\u304c\u4e0a\u304c\u3063\u3066\u3044\u306a\u3044\u305f\u3081\u624b\u52d5\u3067\u30a4\u30f3\u30b9\u30c8\u30fc\u30eb\u3059\u308b\u3053\u3068\u306b\u3057\u307e\u3059\u3002\n\n## Cloudera\u306e\u30ea\u30dd\u30b8\u30c8\u30ea\u304b\u3089\u30a4\u30f3\u30b9\u30c8\u30fc\u30eb\u3059\u308b\u5834\u5408\n```shell-session\nsudo yum install http://archive.cloudera.com/cdh5/one-click-install/redhat/6/x86_64/cloudera-cdh-5-0.x86_64.rpm\nsudo rpm --import http://archive.cloudera.com/cdh5/redhat/6/x86_64/cdh/RPM-GPG-KEY-cloudera\nsudo yum install spark-core spark-master spark-worker spark-history-server spark-python\n```\n\n\u203b\u3053\u306e\u30ea\u30dd\u30b8\u30c8\u30ea\u3067\u306fSpark\u306e\u30d0\u30fc\u30b8\u30e7\u30f3\u306f0.9.0\u306a\u306e\u3067\u6ce8\u610f\n\n## \u624b\u52d5\u3067\u30a4\u30f3\u30b9\u30c8\u30fc\u30eb\u3059\u308b\n```shell-session\nwget http://d3kbcqa49mib13.cloudfront.net/spark-1.0.0-bin-hadoop2.tgz\ntar xzvf spark-1.0.0-bin-hadoop2.tgz\n```\n\n# \u52d5\u4f5c\u78ba\u8a8d\n\n\u53c2\u8003\u30b5\u30a4\u30c8\uff1a\n[Spark Overview - Spark 1.0.0 Documentation](http://spark.apache.org/docs/latest/)\n\nSpark\u306e\u30a4\u30f3\u30b9\u30c8\u30fc\u30eb\u30c7\u30a3\u30ec\u30af\u30c8\u30ea\u3078\u79fb\u52d5\u3057\u3001\u4e0b\u8a18\u30b3\u30de\u30f3\u30c9\u3092\u5b9f\u884c\u3059\u308b\u3002\n\n```shell-session\n./bin/run-example SparkPi 10\n```\n\n\u30ed\u30b0\u304c\u51fa\u529b\u3055\u308c\u3001\u7d50\u679c\u304c\u8868\u793a\u3055\u308c\u307e\u3057\u305f\u3002\n\n```\nPi is roughly 3.142832\n```\n\n# \u30a4\u30f3\u30bf\u30e9\u30af\u30c6\u30a3\u30d6\u30b7\u30a7\u30eb\u3092\u8a66\u3057\u3066\u307f\u308b\n\u53c2\u8003\u30b5\u30a4\u30c8\uff1a\n[Quick Start - Spark 1.0.0 Documentation](http://spark.apache.org/docs/latest/quick-start.html)\n[Apache Spark \u30c9\u30ad\u30e5\u30e1\u30f3\u30c8\u548c\u8a33 - Quick Start - Qiita](http://qiita.com/mychaelstyle/items/46440cd27ef641892a58)\n\n```shell-session\n./bin/spark-shell\n\n...\n...\nWelcome to\n      ____              __\n     / __/__  ___ _____/ /__\n    _\\ \\/ _ \\/ _ `/ __/  '_/\n   /___/ .__/\\_,_/_/ /_/\\_\\   version 1.0.0\n      /_/\n\nUsing Scala version 2.10.4 (OpenJDK 64-Bit Server VM, Java 1.7.0_55)\nType in expressions to have them evaluated.\n...\n...\nSpark context available as sc.\n\nscala> \n```\n\n```scala\nscala> val textFile = sc.textFile(\"README.md\")\ntextFile: org.apache.spark.rdd.RDD[String] = MappedRDD[1] at textFile at <console>:12\n\nscala> textFile.count()\nres0: Long = 127\n\nscala> textFile.first()\nres1: String = # Apache Spark\n```\n\n\u4ed6\u306b\u3082\u30b5\u30f3\u30d7\u30eb\u3084QuickStart\u304c\u3042\u308b\u306e\u3067\u8a66\u3057\u3066\u307f\u3066\u304f\u3060\u3055\u3044\u3002\n\n# spark-ec2 script\n\n\u53c2\u8003\u306b\u3057\u305f\u30b5\u30a4\u30c8\uff1a\n[Running Spark on EC2 - Spark 1.0.0 Documentation](http://spark.apache.org/docs/latest/ec2-scripts.html)\n[Apache Spark \u30c9\u30ad\u30e5\u30e1\u30f3\u30c8\u548c\u8a33 - Apache Spark on AWS EC2 - Qiita](http://qiita.com/mychaelstyle/items/b752087a0bee6e41c182)\n\n## \u4e8b\u524d\u4f5c\u696d\nKey Pair\u3092\u4f5c\u6210\u3057\u3066\u304a\u304f\u5fc5\u8981\u304c\u3042\u308a\u307e\u3059\u3002\n\u4eca\u56de\u306f\u3001spark-demo.pem\u3092\u4f5c\u6210\u3057\u307e\u3057\u305f\u3002\n\n### \u74b0\u5883\u5909\u6570\u3092\u8a2d\u5b9a\n```shell-session\nexport AWS_ACCESS_KEY_ID=XXXXXXXX\nexport AWS_SECRET_ACCESS_KEY=YYYYYYYY\n```\n\u203b\u672c\u756a\u3067\u306f\u3001- IAM roles for EC2 instances\u3092\u4f7f\u3046\u3053\u3068\u306b\u306a\u308b\u304b\u3068\u601d\u3044\u307e\u3059\u3002\n\n## \u30af\u30e9\u30b9\u30bf\u3092\u8d77\u52d5\u3059\u308b\nec2\u30c7\u30a3\u30ec\u30af\u30c8\u30ea\u3078\u79fb\u52d5\u3059\u308b\n\n```shell-session\ncd spark-1.0.0-bin-hadoop2/ec2\n```\n\n\u4ee5\u4e0b\u306e\u30b3\u30de\u30f3\u30c9\u3092\u5b9f\u884c\u3059\u308b\n\n```shell-session\n./spark-ec2 -k spark-demo -i spark-demo.pem -s 2 launch spark-demo --instance-type t1.micro --region ap-northeast-1\n```\n\n![\u30b9\u30af\u30ea\u30fc\u30f3\u30b7\u30e7\u30c3\u30c8 2014-06-12 2.25.20.png](https://qiita-image-store.s3.amazonaws.com/0/18582/1440c614-3b26-c37e-5dee-d85eb0e0e787.png)\n\n\u8d77\u52d5\u3057\u307e\u3057\u305f\u304c\u3001\u30b3\u30f3\u30bd\u30fc\u30eb\u4e0a\u306b\u30a8\u30e9\u30fc\u304c\u51fa\u3066\u3044\u307e\u3059\u3002\n\n```\nSetting up security groups...\nCreating security group spark-demo-master\nCreating security group spark-demo-slaves\nSearching for existing cluster spark-demo...\nSpark AMI: ami-c7bfd4c6\nLaunching instances...\nLaunched 2 slaves in ap-northeast-1c, regid = r-713a2977\nLaunched master in ap-northeast-1c, regid = r-c7392ac1\nWaiting for instances to start up...\nWaiting 120 more seconds...\nGenerating cluster's SSH key on master...\nssh: connect to host ec2-xx-xxx-xx-xxx.ap-northeast-1.compute.amazonaws.com port 22: Connection refused\nError executing remote command, retrying after 30 seconds: Command '['ssh', '-o', 'StrictHostKeyChecking=no', '-i', 'spark-demo.pem', '-t', '-t', u'root@ec2-xx-xxx-xx-xxx.ap-northeast-1.compute.amazonaws.com', \"\\n      [ -f ~/.ssh/id_rsa ] ||\\n        (ssh-keygen -q -t rsa -N '' -f ~/.ssh/id_rsa &&\\n         cat ~/.ssh/id_rsa.pub >> ~/.ssh/authorized_keys)\\n    \"]' returned non-zero exit status 255\nssh: connect to host ec2-xx-xxx-xx-xxx.ap-northeast-1.compute.amazonaws.com port 22: Connection refused\nError executing remote command, retrying after 30 seconds: Command '['ssh', '-o', 'StrictHostKeyChecking=no', '-i', 'spark-demo.pem', '-t', '-t', u'root@ec2-xx-xxx-xx-xxx.ap-northeast-1.compute.amazonaws.com', \"\\n      [ -f ~/.ssh/id_rsa ] ||\\n        (ssh-keygen -q -t rsa -N '' -f ~/.ssh/id_rsa &&\\n         cat ~/.ssh/id_rsa.pub >> ~/.ssh/authorized_keys)\\n    \"]' returned non-zero exit status 255\nssh: connect to host ec2-xx-xxx-xx-xxx.ap-northeast-1.compute.amazonaws.com port 22: Connection refused\nError executing remote command, retrying after 30 seconds: Command '['ssh', '-o', 'StrictHostKeyChecking=no', '-i', 'spark-demo.pem', '-t', '-t', u'root@ec2-xx-xxx-xx-xxx.ap-northeast-1.compute.amazonaws.com', \"\\n      [ -f ~/.ssh/id_rsa ] ||\\n        (ssh-keygen -q -t rsa -N '' -f ~/.ssh/id_rsa &&\\n         cat ~/.ssh/id_rsa.pub >> ~/.ssh/authorized_keys)\\n    \"]' returned non-zero exit status 255\nssh: connect to host ec2-xx-xxx-xx-xxx.ap-northeast-1.compute.amazonaws.com port 22: Connection refused\nError executing remote command, retrying after 30 seconds: Command '['ssh', '-o', 'StrictHostKeyChecking=no', '-i', 'spark-demo.pem', '-t', '-t', u'root@ec2-xx-xxx-xx-xxx.ap-northeast-1.compute.amazonaws.com', \"\\n      [ -f ~/.ssh/id_rsa ] ||\\n        (ssh-keygen -q -t rsa -N '' -f ~/.ssh/id_rsa &&\\n         cat ~/.ssh/id_rsa.pub >> ~/.ssh/authorized_keys)\\n    \"]' returned non-zero exit status 255\nWarning: Permanently added 'ec2-xx-xxx-xx-xxx.ap-northeast-1.compute.amazonaws.com,xx-xxx-xx-xxx' (ECDSA) to the list of known hosts.\nConnection to ec2-xx-xxx-xx-xxx.ap-northeast-1.compute.amazonaws.com closed.\nTraceback (most recent call last):\n  File \"./spark_ec2.py\", line 823, in <module>\n    main()\n  File \"./spark_ec2.py\", line 815, in main\n    real_main()\n  File \"./spark_ec2.py\", line 700, in real_main\n    setup_cluster(conn, master_nodes, slave_nodes, opts, True)\n  File \"./spark_ec2.py\", line 430, in setup_cluster\n    dot_ssh_tar = ssh_read(master, opts, ['tar', 'c', '.ssh'])\n  File \"./spark_ec2.py\", line 637, in ssh_read\n    return subprocess.check_output(\nAttributeError: 'module' object has no attribute 'check_output'\n```\n\n\u4e0b\u8a18\u30b3\u30de\u30f3\u30c9\u3067SSH\u3092\u4f7f\u7528\u3057\u3066\u30af\u30e9\u30b9\u30bf\u306b\u30ed\u30b0\u30a4\u30f3\u3092\u884c\u3046\n\n```\n./spark-ec2 -k <keypair> -i <key-file> login <cluster-name>\n```\n\n\u30c0\u30e1\u3067\u3059\u306d\u3002\u3002\u3002\n\n\u30af\u30e9\u30b9\u30bf\u3092\u505c\u6b62\u3057\u3066\u307f\u308b\u3002\n\n```\n./spark-ec2 stop spark-demo\n```\n\n\u6b62\u307e\u3089\u306a\u3044\u30fb\u30fb\u30fb\n\n\u30af\u30e9\u30b9\u30bf\u3092\u7834\u68c4\u3057\u3066\u307f\u308b\u3002\n\n```\n./spark-ec2 destroy spark-demo\n```\n\n\u30bf\u30fc\u30df\u30cd\u30fc\u30c8\u3055\u308c\u306a\u3044\u3002\u3002\u3002\n\n\u3068\u308a\u3042\u3048\u305a\u3001\u624b\u52d5\u3067\u505c\u6b62\u3057\u3066\u307f\u307e\u3057\u305f\u3002\n\u7d9a\u304d\u306f\u4eca\u5ea6\u3002\n", "tags": ["AWS", "Spark1.0.0"]}