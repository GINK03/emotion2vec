{"context": "\n\n\u306f\u3058\u3081\u306b\n\u76f8\u5834\u5206\u6790\u3067\u4f7f\u3046\u30c6\u30af\u30cb\u30ab\u30eb\u6307\u6a19\u306b\u306f\u3001\u305f\u304f\u3055\u3093\u306e\u7a2e\u985e\u304c\u3042\u308a\u307e\u3059\u304c\u3001\u57fa\u672c\u7684\u306b\u306f\u904e\u53bb\u306e\uff14\u672c\u5024\u3092\u5165\u529b\u30c7\u30fc\u30bf\u3068\u3057\u3066\u3001\u305d\u308c\u306b\u4f55\u3089\u304b\u306e\u8a08\u7b97\u3092\u3057\u3066\u51fa\u529b\u3057\u307e\u3059\u3002\n\u3067\u306f\u3001\u5165\u529b\u30c7\u30fc\u30bf\u3068\u51fa\u529b\u30c7\u30fc\u30bf\u304c\u308f\u304b\u3063\u3066\u3044\u308b\u3068\u304d\u306b\u3001\u3069\u3046\u3044\u3046\u8a08\u7b97\u3092\u3057\u3066\u3044\u308b\u304b\u3092\u63a8\u5b9a\u3059\u308b\u3053\u3068\u306f\u3067\u304d\u308b\u3067\u3057\u3087\u3046\u304b\uff1f\u8a08\u7b97\u30e2\u30c7\u30eb\u304c\u308f\u304b\u3063\u3066\u3044\u3066\u3001\u305d\u306e\u306a\u304b\u306b\u51fa\u3066\u304f\u308b\u30d1\u30e9\u30e1\u30fc\u30bf\u3092\u6c7a\u3081\u308b\u3060\u3051\u306a\u3089\u3001\u30b7\u30b9\u30c6\u30e0\u540c\u5b9a\u3068\u304b\u3001\u6700\u9069\u5316\u30a2\u30eb\u30b4\u30ea\u30ba\u30e0\u3068\u304b\u6c42\u3081\u308b\u624b\u6cd5\u306f\u8272\u3005\u3068\u3042\u308a\u307e\u3059\u3002\n\u305f\u3060\u3001\u8a08\u7b97\u30e2\u30c7\u30eb\u307e\u3067\u63a8\u5b9a\u3059\u308b\u3068\u3044\u3046\u3053\u3068\u3060\u3068\u3061\u3087\u3063\u3068\u96e3\u3057\u3044\u3067\u3057\u3087\u3046\u304c\u3001\u4eca\u6d41\u884c\u308a\u306e\u4eba\u5de5\u77e5\u80fd\u3001\u30c7\u30a3\u30fc\u30d7\u30e9\u30fc\u30cb\u30f3\u30b0\u304c\u300c\u4e07\u80fd\u300d\u306a\u3089\u3001\u305d\u308c\u304f\u3089\u3044\u3067\u304d\u308b\u3067\u3057\u3087\u3046\u3002\u3044\u3084\u3001\u305d\u308c\u304f\u3089\u3044\u3067\u304d\u306a\u3051\u308c\u3070\u4eba\u5de5\u77e5\u80fd\u3068\u540d\u4e57\u308b\u3079\u304d\u3067\u306f\u306a\u3044\u3067\u3057\u3087\u3046\u3002\n\u305d\u308c\u306f\u3055\u3066\u304a\u304d\u3001\u4eca\u56de\u3001\u4e88\u3081\u308f\u304b\u3063\u3066\u3044\u308b\u30c6\u30af\u30cb\u30ab\u30eb\u6307\u6a19\u304c\u5b66\u7fd2\u3067\u304d\u308b\u304b\u3069\u3046\u304bTFlearn\u3067\u8a66\u3057\u3066\u307f\u307e\u3057\u305f\u3002\n\n\u5b66\u7fd2\u3055\u305b\u308b\u30c6\u30af\u30cb\u30ab\u30eb\u6307\u6a19\n\u30c6\u30af\u30cb\u30ab\u30eb\u6307\u6a19\u3067\u6700\u3082\u57fa\u672c\u7684\u306a\u3082\u306e\u306f\u79fb\u52d5\u5e73\u5747\u3067\u3059\u3002\u3053\u308c\u306f\u5358\u7d14\u306a\u7dda\u5f62\u51e6\u7406\u306a\u306e\u3067\u3001\u30cb\u30e5\u30fc\u30e9\u30eb\u30cd\u30c3\u30c8\u30ef\u30fc\u30af\u3092\u4f7f\u3046\u307e\u3067\u3082\u3042\u308a\u307e\u305b\u3093\u304c\u3001\u5358\u7d14\u3059\u304e\u3066\u56f0\u308b\u3053\u3068\u306f\u3042\u308a\u307e\u305b\u3093\u3002\u307b\u3093\u3068\u306b\u7c21\u5358\u306a\u3082\u306e\u304b\u3089\u8a66\u3057\u3066\u307f\u307e\u3059\u3002\n\u5165\u529b\uff11\u500b\u3058\u3083\u5e73\u5747\u3082\u53d6\u308c\u306a\u3044\u306e\u3067\u3001\u3068\u308a\u3042\u3048\u305a\uff12\u500b\u4f7f\u3044\u307e\u3059\u3002\u305f\u3060\u3057\u3001\u91cd\u307f\u306f1/3\u30682/3\u3068\u5909\u3048\u3066\u304a\u304d\u307e\u3059\u3002\n$$y(n)=\\frac{1}{3}x(n-1)+\\frac{2}{3}x(n)$$\n\u3053\u308c\u306f\u3001\u3044\u308f\u3086\u308b\u671f\u9593\uff12\u306e\u7dda\u5f62\u52a0\u91cd\u79fb\u52d5\u5e73\u5747\uff08LWMA\uff09\u3067\u3001MT5\u3060\u3068\u3001\niMA(_Symbol, 0, 2, 0, MODE_LWMA, PRICE_CLOSE);\n\n\u306e\u95a2\u6570\u3092\u4f7f\u3048\u3070\u7b97\u51fa\u3067\u304d\u307e\u3059\u3002MT5\u306e\u30d7\u30ed\u30b0\u30e9\u30e0\u3067\u3001USDJPY\u306e\u65e5\u8db3\u30c7\u30fc\u30bf\u3068\u4e00\u7dd2\u306b\u51fa\u529b\u3055\u305b\u305f\u30d5\u30a1\u30a4\u30eb\u304c\u4ee5\u4e0b\u3067\u3059\u3002\n\nUSDJPY.f16408.txt\nTime,Open,High,Low,Close,Ind0\n2015.01.02 00:00,120.416,120.74,119.805,120.458,120.257999999996\n2015.01.05 00:00,120.531,120.646,119.371,119.631,119.906666666662\n2015.01.06 00:00,119.285,119.504,118.05,118.363,118.785666666662\n2015.01.07 00:00,118.587,119.647,118.504,119.249,118.953666666662\n2015.01.08 00:00,119.314,119.961,119.157,119.652,119.517666666662\n2015.01.09 00:00,119.727,119.876,118.415,118.509,118.889999999995\n2015.01.12 00:00,118.315,119.315,118.098,118.346,118.400333333328\n2015.01.13 00:00,118.363,118.849,117.534,117.925,118.065333333328\n2015.01.14 00:00,117.89,117.937,116.067,117.335,117.531666666662\n2015.01.15 00:00,117.257,117.941,116.151,116.165,116.554999999995\n2015.01.16 00:00,116.183,117.764,115.849,117.541,117.082333333328\n2015.01.19 00:00,117.426,117.78,116.919,117.557,117.551666666661\n2015.01.20 00:00,117.654,118.866,117.64,118.766,118.362999999995\n2015.01.21 00:00,118.67,118.759,117.179,117.956,118.225999999994\n2015.01.22 00:00,117.917,118.665,117.245,118.469,118.297999999994\n2015.01.23 00:00,118.633,118.813,117.534,117.754,117.992333333328\n2015.01.26 00:00,117.634,118.497,117.263,118.447,118.215999999994\n2015.01.27 00:00,118.413,118.657,117.334,117.861,118.056333333327\n2015.01.28 00:00,117.746,118.262,117.249,117.536,117.644333333327\n2015.01.29 00:00,117.489,118.486,117.385,118.257,118.016666666661\n2015.01.30 00:00,118.336,118.459,117.296,117.542,117.780333333327\n  :\n\n\n\n\u6559\u5e2b\u30c7\u30fc\u30bf\u306e\u4f5c\u6210\n\u4e0a\u306e\u30d5\u30a1\u30a4\u30eb\u3092\u8aad\u307f\u8fbc\u3093\u3067\u3001\u6559\u5e2b\u30c7\u30fc\u30bf\u3092\u4f5c\u6210\u3057\u307e\u3059\u3002\u30d5\u30a1\u30a4\u30eb\u306b\u306f\uff14\u672c\u5024\u3068\u6307\u6a19\u5024\u304c\u5165\u3063\u3066\u3044\u307e\u3059\u304c\u3001\u3053\u3053\u3067\u4f7f\u3046\u306e\u306f\u3001\u7d42\u5024Close\u3068\u6307\u6a19\u5024Ind0\u3060\u3051\u3067\u3059\u3002\nX\u306b\u5165\u529b\u30c7\u30fc\u30bf\uff08\u4eca\u56de\u306f\uff12\u500b\uff09\u3001Y\u306b\u6307\u6a19\u51fa\u529b\u5024\u3092\u305d\u308c\u305e\u308c200\u30b5\u30f3\u30d7\u30eb\u307b\u3069\u4f5c\u308a\u307e\u3059\u3002\nimport numpy as np\nimport pandas as pd\nimport tensorflow as tf\nimport tflearn\n\nfile = 'USDJPY.f16408.txt'\nohlc = pd.read_csv(file, index_col='Time', parse_dates=True)\nclose = ohlc.Close.values\nind0 = ohlc.Ind0.values\n\nN = 2\nX = np.empty((0,N))\nY = np.empty((0,1))\nfor i in range(200):\n    X = np.vstack((X, close[i:i+N]))\n    Y = np.vstack((Y, ind0[i+N-1:i+N]))\n\n\n\u30b0\u30e9\u30d5\u306e\u5b9a\u7fa9\nTFlearn\u3067\u4f7f\u3046\u30b0\u30e9\u30d5\u306e\u5b9a\u7fa9\u3067\u3059\u304c\u3001\u4eca\u56de\u306f\u7dda\u5f62\u30e2\u30c7\u30eb\u3060\u3068\u308f\u304b\u3063\u3066\u3044\u308b\u3082\u306e\u3068\u3057\u3066\u3001\u5358\u306b\u5165\u529b\u5c64\u304b\u3089\u7dda\u5f62\u7d50\u5408\u3055\u305b\u305f\u3082\u306e\u3092\u5b9a\u7fa9\u3057\u307e\u3059\u3002\u3042\u3068\u3001\u30d0\u30a4\u30a2\u30b9\u3082\u4f7f\u308f\u306a\u3044\u306e\u3067\u3001bias=False\u3068\u3057\u3066\u304a\u304d\u307e\u3059\u3002\n\u305f\u3060\u3001regression\u306b\u3064\u3044\u3066\u306f\u3001\u30c7\u30d5\u30a9\u30eb\u30c8\u306e\u307e\u307e\u3060\u3068\u3042\u307e\u308a\u3088\u3044\u7d50\u679c\u304c\u3067\u306a\u304b\u3063\u305f\u306e\u3067\u3001SGD\u30e1\u30bd\u30c3\u30c9\u3092\u4f7f\u3063\u3066\u5b66\u7fd2\u7387\u3092\u5f90\u3005\u306b\u4e0b\u3052\u3066\u3044\u304f\u3088\u3046\u8abf\u6574\u3092\u884c\u3044\u307e\u3057\u305f\u3002\n# Graph definition\nlayer_in = tflearn.input_data(shape=[None, N])\nlayer1 = tflearn.fully_connected(layer_in, 1, activation='linear', bias=False)\nsgd = tflearn.optimizers.SGD(learning_rate=0.01, lr_decay=0.95, decay_step=100)\nregression = tflearn.regression(layer1, optimizer=sgd, loss='mean_square')\n\n\n\u5b66\u7fd2\nTFlearn\u3092\u4f7f\u3046\u3068\u5b66\u7fd2\u306e\u8a18\u8ff0\u306f\u7c21\u5358\u3067\u3059\u300210000\u4e16\u4ee3\u307e\u3067\u5b66\u7fd2\u3055\u305b\u307e\u3059\u3002\n# Model training\nm = tflearn.DNN(regression)\nm.fit(X, Y, n_epoch=10000, snapshot_epoch=False, run_id='MAlearn')\n\n\n\u7d50\u679c\n\u5b66\u7fd2\u7d50\u679c\u3068\u3057\u3066\u91cd\u307f\u4fc2\u6570\u3092\u51fa\u529b\u3055\u305b\u307e\u3059\u3002\n# Weights\nprint('\\nweights')\nfor i in range(N):\n    print('W['+str(i)+'] =' ,m.get_weights(layer1.W)[i])\n\n\u4ee5\u4e0b\u304c\u5b66\u7fd2\u7d50\u679c\u306e\u51fa\u529b\u3067\u3059\u3002\n---------------------------------\nRun id: MAlearn\nLog directory: /tmp/tflearn_logs/\n---------------------------------\nTraining samples: 200\nValidation samples: 0\n--\nTraining Step: 40000  | total loss: 0.61673\n| SGD | epoch: 10000 | loss: 0.61673 -- iter: 200/200\n--\n\nweights\nW[0] = [ 0.43885291]\nW[1] = [ 0.56114811]\n\n\u6b63\u78ba\u306a\u91cd\u307f\u306fW[0]=0.3333, W[1]=0.6777\u306a\u306e\u3067\u3001\u3061\u3083\u3093\u3068\u5b66\u7fd2\u3067\u304d\u3066\u3044\u308b\u3088\u3046\u306b\u306f\u898b\u3048\u307e\u305b\u3093\u3002\n\n\u6559\u5e2b\u30c7\u30fc\u30bf\u306e\u51e6\u7406\n\u4eca\u56de\u306e\u4f8b\u306f\u3001\uff12\u5165\u529b\u306e\u7dda\u5f62\u548c\u3092\u6c42\u3081\u308b\u3060\u3051\u306e\u30e2\u30c7\u30eb\u3060\u3063\u305f\u306e\u3067\u3059\u304c\u3001\u4e8c\u3064\u306e\u5165\u529b\u30c7\u30fc\u30bf\u306e\u5dee\u304c\u5c0f\u3055\u3044\u3068\u8aa4\u5dee\u304c\u5c0f\u3055\u304f\u306a\u3063\u3066\u3057\u307e\u3044\u3001\u5b66\u7fd2\u304c\u3046\u307e\u304f\u3067\u304d\u3066\u3044\u307e\u305b\u3093\u3067\u3057\u305f\u3002\u305d\u3053\u3067\u3001\u3053\u3093\u3069\u306f\u3001\u4e8c\u3064\u306e\u30c7\u30fc\u30bf\u306e\u5dee\u304c\uff11\u4ee5\u4e0a\u306e\u307f\u3092\u6559\u5e2b\u30c7\u30fc\u30bf\u3068\u3057\u3066\u307f\u307e\u3057\u305f\u3002\nN = 2\nX = np.empty((0,N))\nY = np.empty((0,1))\nfor i in range(200):\n    if abs(close[i]-close[i+1]) >= 1.0:\n        X = np.vstack((X, close[i:i+N]))\n        Y = np.vstack((Y, ind0[i+N-1:i+N]))\n\n\u7d50\u679c\u3067\u3059\u3002\n---------------------------------\nRun id: MAlearn\nLog directory: /tmp/tflearn_logs/\n---------------------------------\nTraining samples: 22\nValidation samples: 0\n--\nTraining Step: 10000  | total loss: 1.94699\n| SGD | epoch: 10000 | loss: 1.94699 -- iter: 22/22\n--\n\nweights\nW[0] = [ 0.33961287]\nW[1] = [ 0.66053367]\n\n\u30b5\u30f3\u30d7\u30eb\u6570\u304c22\u500b\u3068\u6e1b\u3063\u3066\u3057\u307e\u3044\u307e\u3057\u305f\u304c\u3001\u524d\u3088\u308a\u306f\u91cd\u307f\u304c\u771f\u5024\u306b\u8fd1\u304f\u306a\u308a\u307e\u3057\u305f\u3002\n\n\u30ce\u30a4\u30ba\u5165\u308a\u306e\u6559\u5e2b\u30c7\u30fc\u30bf\n\u305d\u3082\u305d\u3082\u30cb\u30e5\u30fc\u30e9\u30eb\u30cd\u30c3\u30c8\u30ef\u30fc\u30af\u306f\u3001\u6b63\u78ba\u306a\u6570\u5024\u4e88\u6e2c\u306e\u305f\u3081\u3067\u306f\u306a\u304f\u3001\u7d50\u69cb\u30a2\u30d0\u30a6\u30c8\u306a\u4e88\u6e2c\u3092\u884c\u3046\u305f\u3081\u306e\u3082\u306e\u3067\u3059\u3002\n\u305d\u3053\u3067\u3001\u3053\u3093\u3069\u306f\u6307\u6a19\u5024\u306b\u5e73\u57470\u3001\u6a19\u6e96\u504f\u5dee0.1\u306e\u30ac\u30a6\u30b9\u30ce\u30a4\u30ba\u3092\u4ed8\u52a0\u3057\u305f\u3082\u306e\u3092\u6559\u5e2b\u30c7\u30fc\u30bf\u3068\u3057\u3066\u307f\u307e\u3057\u305f\u3002\nN = 2\nX = np.empty((0,N))\nY = np.empty((0,1))\nfor i in range(200):\n    if abs(close[i]-close[i+1]) >= 1.0:\n        X = np.vstack((X, close[i:i+N]))\n        noise = np.random.normal(0,0.1)\n        Y = np.vstack((Y, ind0[i+N-1:i+N]+noise))\n\n\u7d50\u679c\u3067\u3059\u3002\n---------------------------------\nRun id: MAlearn\nLog directory: /tmp/tflearn_logs/\n---------------------------------\nTraining samples: 22\nValidation samples: 0\n--\nTraining Step: 10000  | total loss: 3.79990\n| SGD | epoch: 10000 | loss: 3.79990 -- iter: 22/22\n--\n\nweights\nW[0] = [ 0.32918188]\nW[1] = [ 0.67114329]\n\n\u7d50\u679c\u306f\u6bce\u56de\u5fae\u5999\u306b\u5909\u308f\u308a\u307e\u3059\u304c\u3001\u3060\u3044\u305f\u3044\u5b66\u7fd2\u3067\u304d\u3066\u3044\u308b\u3053\u3068\u304c\u308f\u304b\u308a\u307e\u3059\u3002\u30ce\u30a4\u30ba\u304c\u5165\u3063\u3066\u3082\u306a\u3093\u3068\u306a\u304f\u4e88\u6e2c\u3067\u304d\u308b\u3068\u3044\u3046\u306e\u304c\u30cb\u30e5\u30fc\u30e9\u30eb\u30cd\u30c3\u30c8\u30ef\u30fc\u30af\u306e\u30e1\u30ea\u30c3\u30c8\u3067\u3057\u3087\u3046\u3002\n\n\u307e\u3068\u3081\n\u30b3\u30fc\u30c9\u4e2d\u306eN\u3092\u5909\u3048\u308c\u3070\uff13\u500b\u4ee5\u4e0a\u306e\u30c7\u30fc\u30bf\u306b\u3082\u5bfe\u5fdc\u53ef\u80fd\u3067\u3059\u304c\u3001\u5b9f\u969b\u3001\uff13\u5165\u529b\u4ee5\u4e0a\u3060\u3068\u91cd\u307f\u4fc2\u6570\u306f\u3042\u307e\u308a\u3044\u3044\u7cbe\u5ea6\u3067\u306f\u6c42\u307e\u308a\u307e\u305b\u3093\u3067\u3057\u305f\u3002\u7d50\u679c\u306f\u7701\u7565\u3057\u307e\u3059\u3002\n\u3068\u3044\u3046\u3053\u3068\u3067\u3001\u4efb\u610f\u306e\u30c6\u30af\u30cb\u30ab\u30eb\u6307\u6a19\u306e\u5b66\u7fd2\u3055\u305b\u308b\u306b\u306f\u3001\u307e\u3060\u307e\u3060\u9053\u306f\u9060\u305d\u3046\u3067\u3059\u3002\u3068\u308a\u3042\u3048\u305a\u3001\u6e96\u5099\u3068\u3044\u3046\u7a0b\u5ea6\u306e\u8a18\u4e8b\u3067\u3057\u305f\u3002\n\u307e\u3042\u3001\u30a2\u30a4\u30c7\u30a2\u304c\u3044\u3044\u304b\u3069\u3046\u304b\u3092\u77ed\u671f\u9593\u3067\u691c\u8a3c\u3067\u304d\u308b\u3068\u3044\u3046\u3053\u3068\u304c\u3001TFlearn\u3092\u4f7f\u3046\u30e1\u30ea\u30c3\u30c8\u3068\u3044\u3046\u3053\u3068\u3067\u3057\u3087\u3046\u3002\n# \u306f\u3058\u3081\u306b\n\u76f8\u5834\u5206\u6790\u3067\u4f7f\u3046\u30c6\u30af\u30cb\u30ab\u30eb\u6307\u6a19\u306b\u306f\u3001\u305f\u304f\u3055\u3093\u306e\u7a2e\u985e\u304c\u3042\u308a\u307e\u3059\u304c\u3001\u57fa\u672c\u7684\u306b\u306f\u904e\u53bb\u306e\uff14\u672c\u5024\u3092\u5165\u529b\u30c7\u30fc\u30bf\u3068\u3057\u3066\u3001\u305d\u308c\u306b\u4f55\u3089\u304b\u306e\u8a08\u7b97\u3092\u3057\u3066\u51fa\u529b\u3057\u307e\u3059\u3002\n\n\u3067\u306f\u3001\u5165\u529b\u30c7\u30fc\u30bf\u3068\u51fa\u529b\u30c7\u30fc\u30bf\u304c\u308f\u304b\u3063\u3066\u3044\u308b\u3068\u304d\u306b\u3001\u3069\u3046\u3044\u3046\u8a08\u7b97\u3092\u3057\u3066\u3044\u308b\u304b\u3092\u63a8\u5b9a\u3059\u308b\u3053\u3068\u306f\u3067\u304d\u308b\u3067\u3057\u3087\u3046\u304b\uff1f\u8a08\u7b97\u30e2\u30c7\u30eb\u304c\u308f\u304b\u3063\u3066\u3044\u3066\u3001\u305d\u306e\u306a\u304b\u306b\u51fa\u3066\u304f\u308b\u30d1\u30e9\u30e1\u30fc\u30bf\u3092\u6c7a\u3081\u308b\u3060\u3051\u306a\u3089\u3001\u30b7\u30b9\u30c6\u30e0\u540c\u5b9a\u3068\u304b\u3001\u6700\u9069\u5316\u30a2\u30eb\u30b4\u30ea\u30ba\u30e0\u3068\u304b\u6c42\u3081\u308b\u624b\u6cd5\u306f\u8272\u3005\u3068\u3042\u308a\u307e\u3059\u3002\n\n\u305f\u3060\u3001\u8a08\u7b97\u30e2\u30c7\u30eb\u307e\u3067\u63a8\u5b9a\u3059\u308b\u3068\u3044\u3046\u3053\u3068\u3060\u3068\u3061\u3087\u3063\u3068\u96e3\u3057\u3044\u3067\u3057\u3087\u3046\u304c\u3001\u4eca\u6d41\u884c\u308a\u306e\u4eba\u5de5\u77e5\u80fd\u3001\u30c7\u30a3\u30fc\u30d7\u30e9\u30fc\u30cb\u30f3\u30b0\u304c\u300c\u4e07\u80fd\u300d\u306a\u3089\u3001\u305d\u308c\u304f\u3089\u3044\u3067\u304d\u308b\u3067\u3057\u3087\u3046\u3002\u3044\u3084\u3001\u305d\u308c\u304f\u3089\u3044\u3067\u304d\u306a\u3051\u308c\u3070\u4eba\u5de5\u77e5\u80fd\u3068\u540d\u4e57\u308b\u3079\u304d\u3067\u306f\u306a\u3044\u3067\u3057\u3087\u3046\u3002\n\n\u305d\u308c\u306f\u3055\u3066\u304a\u304d\u3001\u4eca\u56de\u3001\u4e88\u3081\u308f\u304b\u3063\u3066\u3044\u308b\u30c6\u30af\u30cb\u30ab\u30eb\u6307\u6a19\u304c\u5b66\u7fd2\u3067\u304d\u308b\u304b\u3069\u3046\u304bTFlearn\u3067\u8a66\u3057\u3066\u307f\u307e\u3057\u305f\u3002\n\n#\u5b66\u7fd2\u3055\u305b\u308b\u30c6\u30af\u30cb\u30ab\u30eb\u6307\u6a19\n\u30c6\u30af\u30cb\u30ab\u30eb\u6307\u6a19\u3067\u6700\u3082\u57fa\u672c\u7684\u306a\u3082\u306e\u306f\u79fb\u52d5\u5e73\u5747\u3067\u3059\u3002\u3053\u308c\u306f\u5358\u7d14\u306a\u7dda\u5f62\u51e6\u7406\u306a\u306e\u3067\u3001\u30cb\u30e5\u30fc\u30e9\u30eb\u30cd\u30c3\u30c8\u30ef\u30fc\u30af\u3092\u4f7f\u3046\u307e\u3067\u3082\u3042\u308a\u307e\u305b\u3093\u304c\u3001\u5358\u7d14\u3059\u304e\u3066\u56f0\u308b\u3053\u3068\u306f\u3042\u308a\u307e\u305b\u3093\u3002\u307b\u3093\u3068\u306b\u7c21\u5358\u306a\u3082\u306e\u304b\u3089\u8a66\u3057\u3066\u307f\u307e\u3059\u3002\n\n\u5165\u529b\uff11\u500b\u3058\u3083\u5e73\u5747\u3082\u53d6\u308c\u306a\u3044\u306e\u3067\u3001\u3068\u308a\u3042\u3048\u305a\uff12\u500b\u4f7f\u3044\u307e\u3059\u3002\u305f\u3060\u3057\u3001\u91cd\u307f\u306f1/3\u30682/3\u3068\u5909\u3048\u3066\u304a\u304d\u307e\u3059\u3002\n\n$$y(n)=\\frac{1}{3}x(n-1)+\\frac{2}{3}x(n)$$\n\n\u3053\u308c\u306f\u3001\u3044\u308f\u3086\u308b\u671f\u9593\uff12\u306e\u7dda\u5f62\u52a0\u91cd\u79fb\u52d5\u5e73\u5747\uff08LWMA\uff09\u3067\u3001MT5\u3060\u3068\u3001\n\n````\niMA(_Symbol, 0, 2, 0, MODE_LWMA, PRICE_CLOSE);\n````\n\u306e\u95a2\u6570\u3092\u4f7f\u3048\u3070\u7b97\u51fa\u3067\u304d\u307e\u3059\u3002[MT5\u306e\u30d7\u30ed\u30b0\u30e9\u30e0](https://github.com/toyolab/MT5IndicatorsPy/blob/master/OutputRates.mq5)\u3067\u3001USDJPY\u306e\u65e5\u8db3\u30c7\u30fc\u30bf\u3068\u4e00\u7dd2\u306b\u51fa\u529b\u3055\u305b\u305f\u30d5\u30a1\u30a4\u30eb\u304c\u4ee5\u4e0b\u3067\u3059\u3002\n\n````USDJPY.f16408.txt\nTime,Open,High,Low,Close,Ind0\n2015.01.02 00:00,120.416,120.74,119.805,120.458,120.257999999996\n2015.01.05 00:00,120.531,120.646,119.371,119.631,119.906666666662\n2015.01.06 00:00,119.285,119.504,118.05,118.363,118.785666666662\n2015.01.07 00:00,118.587,119.647,118.504,119.249,118.953666666662\n2015.01.08 00:00,119.314,119.961,119.157,119.652,119.517666666662\n2015.01.09 00:00,119.727,119.876,118.415,118.509,118.889999999995\n2015.01.12 00:00,118.315,119.315,118.098,118.346,118.400333333328\n2015.01.13 00:00,118.363,118.849,117.534,117.925,118.065333333328\n2015.01.14 00:00,117.89,117.937,116.067,117.335,117.531666666662\n2015.01.15 00:00,117.257,117.941,116.151,116.165,116.554999999995\n2015.01.16 00:00,116.183,117.764,115.849,117.541,117.082333333328\n2015.01.19 00:00,117.426,117.78,116.919,117.557,117.551666666661\n2015.01.20 00:00,117.654,118.866,117.64,118.766,118.362999999995\n2015.01.21 00:00,118.67,118.759,117.179,117.956,118.225999999994\n2015.01.22 00:00,117.917,118.665,117.245,118.469,118.297999999994\n2015.01.23 00:00,118.633,118.813,117.534,117.754,117.992333333328\n2015.01.26 00:00,117.634,118.497,117.263,118.447,118.215999999994\n2015.01.27 00:00,118.413,118.657,117.334,117.861,118.056333333327\n2015.01.28 00:00,117.746,118.262,117.249,117.536,117.644333333327\n2015.01.29 00:00,117.489,118.486,117.385,118.257,118.016666666661\n2015.01.30 00:00,118.336,118.459,117.296,117.542,117.780333333327\n  :\n````\n\n# \u6559\u5e2b\u30c7\u30fc\u30bf\u306e\u4f5c\u6210\n\u4e0a\u306e\u30d5\u30a1\u30a4\u30eb\u3092\u8aad\u307f\u8fbc\u3093\u3067\u3001\u6559\u5e2b\u30c7\u30fc\u30bf\u3092\u4f5c\u6210\u3057\u307e\u3059\u3002\u30d5\u30a1\u30a4\u30eb\u306b\u306f\uff14\u672c\u5024\u3068\u6307\u6a19\u5024\u304c\u5165\u3063\u3066\u3044\u307e\u3059\u304c\u3001\u3053\u3053\u3067\u4f7f\u3046\u306e\u306f\u3001\u7d42\u5024`Close`\u3068\u6307\u6a19\u5024`Ind0`\u3060\u3051\u3067\u3059\u3002\n\n`X`\u306b\u5165\u529b\u30c7\u30fc\u30bf\uff08\u4eca\u56de\u306f\uff12\u500b\uff09\u3001`Y`\u306b\u6307\u6a19\u51fa\u529b\u5024\u3092\u305d\u308c\u305e\u308c200\u30b5\u30f3\u30d7\u30eb\u307b\u3069\u4f5c\u308a\u307e\u3059\u3002\n\n````py\nimport numpy as np\nimport pandas as pd\nimport tensorflow as tf\nimport tflearn\n\nfile = 'USDJPY.f16408.txt'\nohlc = pd.read_csv(file, index_col='Time', parse_dates=True)\nclose = ohlc.Close.values\nind0 = ohlc.Ind0.values\n\nN = 2\nX = np.empty((0,N))\nY = np.empty((0,1))\nfor i in range(200):\n    X = np.vstack((X, close[i:i+N]))\n    Y = np.vstack((Y, ind0[i+N-1:i+N]))\n````\n\n# \u30b0\u30e9\u30d5\u306e\u5b9a\u7fa9\nTFlearn\u3067\u4f7f\u3046\u30b0\u30e9\u30d5\u306e\u5b9a\u7fa9\u3067\u3059\u304c\u3001\u4eca\u56de\u306f\u7dda\u5f62\u30e2\u30c7\u30eb\u3060\u3068\u308f\u304b\u3063\u3066\u3044\u308b\u3082\u306e\u3068\u3057\u3066\u3001\u5358\u306b\u5165\u529b\u5c64\u304b\u3089\u7dda\u5f62\u7d50\u5408\u3055\u305b\u305f\u3082\u306e\u3092\u5b9a\u7fa9\u3057\u307e\u3059\u3002\u3042\u3068\u3001\u30d0\u30a4\u30a2\u30b9\u3082\u4f7f\u308f\u306a\u3044\u306e\u3067\u3001`bias=False`\u3068\u3057\u3066\u304a\u304d\u307e\u3059\u3002\n\n\u305f\u3060\u3001`regression`\u306b\u3064\u3044\u3066\u306f\u3001\u30c7\u30d5\u30a9\u30eb\u30c8\u306e\u307e\u307e\u3060\u3068\u3042\u307e\u308a\u3088\u3044\u7d50\u679c\u304c\u3067\u306a\u304b\u3063\u305f\u306e\u3067\u3001SGD\u30e1\u30bd\u30c3\u30c9\u3092\u4f7f\u3063\u3066\u5b66\u7fd2\u7387\u3092\u5f90\u3005\u306b\u4e0b\u3052\u3066\u3044\u304f\u3088\u3046\u8abf\u6574\u3092\u884c\u3044\u307e\u3057\u305f\u3002\n\n````py\n# Graph definition\nlayer_in = tflearn.input_data(shape=[None, N])\nlayer1 = tflearn.fully_connected(layer_in, 1, activation='linear', bias=False)\nsgd = tflearn.optimizers.SGD(learning_rate=0.01, lr_decay=0.95, decay_step=100)\nregression = tflearn.regression(layer1, optimizer=sgd, loss='mean_square')\n````\n\n# \u5b66\u7fd2\nTFlearn\u3092\u4f7f\u3046\u3068\u5b66\u7fd2\u306e\u8a18\u8ff0\u306f\u7c21\u5358\u3067\u3059\u300210000\u4e16\u4ee3\u307e\u3067\u5b66\u7fd2\u3055\u305b\u307e\u3059\u3002\n\n````py\n# Model training\nm = tflearn.DNN(regression)\nm.fit(X, Y, n_epoch=10000, snapshot_epoch=False, run_id='MAlearn')\n````\n\n# \u7d50\u679c\n\u5b66\u7fd2\u7d50\u679c\u3068\u3057\u3066\u91cd\u307f\u4fc2\u6570\u3092\u51fa\u529b\u3055\u305b\u307e\u3059\u3002\n\n````py\n# Weights\nprint('\\nweights')\nfor i in range(N):\n    print('W['+str(i)+'] =' ,m.get_weights(layer1.W)[i])\n````\n\u4ee5\u4e0b\u304c\u5b66\u7fd2\u7d50\u679c\u306e\u51fa\u529b\u3067\u3059\u3002\n\n````\n---------------------------------\nRun id: MAlearn\nLog directory: /tmp/tflearn_logs/\n---------------------------------\nTraining samples: 200\nValidation samples: 0\n--\nTraining Step: 40000  | total loss: 0.61673\n| SGD | epoch: 10000 | loss: 0.61673 -- iter: 200/200\n--\n\nweights\nW[0] = [ 0.43885291]\nW[1] = [ 0.56114811]\n````\n\u6b63\u78ba\u306a\u91cd\u307f\u306f`W[0]=0.3333`, `W[1]=0.6777`\u306a\u306e\u3067\u3001\u3061\u3083\u3093\u3068\u5b66\u7fd2\u3067\u304d\u3066\u3044\u308b\u3088\u3046\u306b\u306f\u898b\u3048\u307e\u305b\u3093\u3002\n\n# \u6559\u5e2b\u30c7\u30fc\u30bf\u306e\u51e6\u7406\n\u4eca\u56de\u306e\u4f8b\u306f\u3001\uff12\u5165\u529b\u306e\u7dda\u5f62\u548c\u3092\u6c42\u3081\u308b\u3060\u3051\u306e\u30e2\u30c7\u30eb\u3060\u3063\u305f\u306e\u3067\u3059\u304c\u3001\u4e8c\u3064\u306e\u5165\u529b\u30c7\u30fc\u30bf\u306e\u5dee\u304c\u5c0f\u3055\u3044\u3068\u8aa4\u5dee\u304c\u5c0f\u3055\u304f\u306a\u3063\u3066\u3057\u307e\u3044\u3001\u5b66\u7fd2\u304c\u3046\u307e\u304f\u3067\u304d\u3066\u3044\u307e\u305b\u3093\u3067\u3057\u305f\u3002\u305d\u3053\u3067\u3001\u3053\u3093\u3069\u306f\u3001\u4e8c\u3064\u306e\u30c7\u30fc\u30bf\u306e\u5dee\u304c\uff11\u4ee5\u4e0a\u306e\u307f\u3092\u6559\u5e2b\u30c7\u30fc\u30bf\u3068\u3057\u3066\u307f\u307e\u3057\u305f\u3002\n\n````py\nN = 2\nX = np.empty((0,N))\nY = np.empty((0,1))\nfor i in range(200):\n    if abs(close[i]-close[i+1]) >= 1.0:\n        X = np.vstack((X, close[i:i+N]))\n        Y = np.vstack((Y, ind0[i+N-1:i+N]))\n````\n\n\u7d50\u679c\u3067\u3059\u3002\n\n````\n---------------------------------\nRun id: MAlearn\nLog directory: /tmp/tflearn_logs/\n---------------------------------\nTraining samples: 22\nValidation samples: 0\n--\nTraining Step: 10000  | total loss: 1.94699\n| SGD | epoch: 10000 | loss: 1.94699 -- iter: 22/22\n--\n\nweights\nW[0] = [ 0.33961287]\nW[1] = [ 0.66053367]\n````\n\n\u30b5\u30f3\u30d7\u30eb\u6570\u304c22\u500b\u3068\u6e1b\u3063\u3066\u3057\u307e\u3044\u307e\u3057\u305f\u304c\u3001\u524d\u3088\u308a\u306f\u91cd\u307f\u304c\u771f\u5024\u306b\u8fd1\u304f\u306a\u308a\u307e\u3057\u305f\u3002\n\n# \u30ce\u30a4\u30ba\u5165\u308a\u306e\u6559\u5e2b\u30c7\u30fc\u30bf\n\u305d\u3082\u305d\u3082\u30cb\u30e5\u30fc\u30e9\u30eb\u30cd\u30c3\u30c8\u30ef\u30fc\u30af\u306f\u3001\u6b63\u78ba\u306a\u6570\u5024\u4e88\u6e2c\u306e\u305f\u3081\u3067\u306f\u306a\u304f\u3001\u7d50\u69cb\u30a2\u30d0\u30a6\u30c8\u306a\u4e88\u6e2c\u3092\u884c\u3046\u305f\u3081\u306e\u3082\u306e\u3067\u3059\u3002\n\n\u305d\u3053\u3067\u3001\u3053\u3093\u3069\u306f\u6307\u6a19\u5024\u306b\u5e73\u57470\u3001\u6a19\u6e96\u504f\u5dee0.1\u306e\u30ac\u30a6\u30b9\u30ce\u30a4\u30ba\u3092\u4ed8\u52a0\u3057\u305f\u3082\u306e\u3092\u6559\u5e2b\u30c7\u30fc\u30bf\u3068\u3057\u3066\u307f\u307e\u3057\u305f\u3002\n\n````py\nN = 2\nX = np.empty((0,N))\nY = np.empty((0,1))\nfor i in range(200):\n    if abs(close[i]-close[i+1]) >= 1.0:\n        X = np.vstack((X, close[i:i+N]))\n        noise = np.random.normal(0,0.1)\n        Y = np.vstack((Y, ind0[i+N-1:i+N]+noise))\n````\n\u7d50\u679c\u3067\u3059\u3002\n\n````\n---------------------------------\nRun id: MAlearn\nLog directory: /tmp/tflearn_logs/\n---------------------------------\nTraining samples: 22\nValidation samples: 0\n--\nTraining Step: 10000  | total loss: 3.79990\n| SGD | epoch: 10000 | loss: 3.79990 -- iter: 22/22\n--\n\nweights\nW[0] = [ 0.32918188]\nW[1] = [ 0.67114329]\n````\n\u7d50\u679c\u306f\u6bce\u56de\u5fae\u5999\u306b\u5909\u308f\u308a\u307e\u3059\u304c\u3001\u3060\u3044\u305f\u3044\u5b66\u7fd2\u3067\u304d\u3066\u3044\u308b\u3053\u3068\u304c\u308f\u304b\u308a\u307e\u3059\u3002\u30ce\u30a4\u30ba\u304c\u5165\u3063\u3066\u3082\u306a\u3093\u3068\u306a\u304f\u4e88\u6e2c\u3067\u304d\u308b\u3068\u3044\u3046\u306e\u304c\u30cb\u30e5\u30fc\u30e9\u30eb\u30cd\u30c3\u30c8\u30ef\u30fc\u30af\u306e\u30e1\u30ea\u30c3\u30c8\u3067\u3057\u3087\u3046\u3002\n\n#\u307e\u3068\u3081\n\u30b3\u30fc\u30c9\u4e2d\u306e`N`\u3092\u5909\u3048\u308c\u3070\uff13\u500b\u4ee5\u4e0a\u306e\u30c7\u30fc\u30bf\u306b\u3082\u5bfe\u5fdc\u53ef\u80fd\u3067\u3059\u304c\u3001\u5b9f\u969b\u3001\uff13\u5165\u529b\u4ee5\u4e0a\u3060\u3068\u91cd\u307f\u4fc2\u6570\u306f\u3042\u307e\u308a\u3044\u3044\u7cbe\u5ea6\u3067\u306f\u6c42\u307e\u308a\u307e\u305b\u3093\u3067\u3057\u305f\u3002\u7d50\u679c\u306f\u7701\u7565\u3057\u307e\u3059\u3002\n\n\u3068\u3044\u3046\u3053\u3068\u3067\u3001\u4efb\u610f\u306e\u30c6\u30af\u30cb\u30ab\u30eb\u6307\u6a19\u306e\u5b66\u7fd2\u3055\u305b\u308b\u306b\u306f\u3001\u307e\u3060\u307e\u3060\u9053\u306f\u9060\u305d\u3046\u3067\u3059\u3002\u3068\u308a\u3042\u3048\u305a\u3001\u6e96\u5099\u3068\u3044\u3046\u7a0b\u5ea6\u306e\u8a18\u4e8b\u3067\u3057\u305f\u3002\n\n\u307e\u3042\u3001\u30a2\u30a4\u30c7\u30a2\u304c\u3044\u3044\u304b\u3069\u3046\u304b\u3092\u77ed\u671f\u9593\u3067\u691c\u8a3c\u3067\u304d\u308b\u3068\u3044\u3046\u3053\u3068\u304c\u3001TFlearn\u3092\u4f7f\u3046\u30e1\u30ea\u30c3\u30c8\u3068\u3044\u3046\u3053\u3068\u3067\u3057\u3087\u3046\u3002\n", "tags": ["Python", "TensorFlow", "TFLearn", "\u30c6\u30af\u30cb\u30ab\u30eb\u6307\u6a19", "\u5b66\u7fd2"]}