{"tags": ["borgWarp", "Python", "link"], "context": "\n\u52d5\u4f5c\u74b0\u5883\nGeForce GTX 1070 (8GB)\nASRock Z170M Pro4S [Intel Z170chipset]\nUbuntu 14.04 LTS desktop amd64\nTensorFlow v0.11\ncuDNN v5.1 for Linux\nCUDA v8.0\nPython 2.7.6\nIPython 5.1.0 -- An enhanced Interactive Python.\n\n\nTensorFlow\u3068\u3044\u3046Deep Learning\u306e\u30d5\u30ec\u30fc\u30e0\u30ef\u30fc\u30af\u306e\u5b66\u7fd2\u4e2d\u3002\nhttps://indico.io/blog/tensorflow-data-inputs-part1-placeholders-protobufs-queues/\n\u306e\uff11\u3064\u76ee\u306e\u30b3\u30fc\u30c9\u3067\u898b\u305f\u3053\u3068\u304c\u306a\u3044\u8a18\u8ff0\u306b\u51fa\u304f\u308f\u3057\u305f\u3002\n...\ndef data_iterator():\n    \"\"\" A simple data iterator \"\"\"\n    batch_idx = 0\n    while True:\n        # shuffle labels and features\n        idxs = np.arange(0, len(features))\n        np.random.shuffle(idxs)\n        shuf_features = features[idxs]\n        shuf_labels = labels[idxs]\n        batch_size = 128\n        for batch_idx in range(0, len(features), batch_size):\n            images_batch = shuf_features[batch_idx:batch_idx+batch_size] / 255.\n            images_batch = images_batch.astype(\"float32\")\n            labels_batch = shuf_labels[batch_idx:batch_idx+batch_size]\n            yield images_batch, labels_batch\n\n\niter_ = data_iterator()\nwhile True:\n    # get a batch of data\n    images_batch_val, labels_batch_val = iter_.next()\n    # pass it in as through feed_dict\n    _, loss_val = sess.run([train_op, loss_mean], feed_dict={\n                    images_batch:images_batch_val,\n                    labels_batch:labels_batch_val\n                    })\n    print loss_val\n\n\u4e0a\u8a18\u3067\u3071\u3063\u3068\u307f\u3066\u5206\u304b\u3089\u306a\u304b\u3063\u305f\u306e\u306f\u300citer_.next()\u306enext()\u306f\u3069\u3053\u3067\u5b9a\u7fa9\u3055\u308c\u3066\u3044\u308b\u306e\u304b\u300d\u3068\u3044\u3046\u3053\u3068\u3060\u3063\u305f\u3002\niter_\u306e\u30af\u30e9\u30b9data_iterator()\u306b\u306fnext()\u306e\u5b9a\u7fa9\u306f\u306a\u3044\u3002\n\u4e00\u65b9\u3067\u3001yield\u3068\u3044\u3046\u8a18\u8ff0\u304c\u3042\u308b\u3002\n\u3053\u308c\u306fUnity\u3067\u30bd\u30d5\u30c8\u3092\u4f5c\u3063\u305f\u6642\u306b\u51fa\u3066\u304d\u305f\u3088\u3046\u306a\u6c17\u304c\u3059\u308b\u3002\nhttp://qiita.com/7of9/items/194e1c7f4b87a79dd129\nnext()\u3068yield\u3067\u691c\u7d22\u3059\u308b\u3068Qiita\u8a18\u4e8b\u304c\u898b\u3064\u304b\u3063\u305f\u3002\nhttp://qiita.com/tomotaka_ito/items/35f3eb108f587022fa09#yield\u3092\u4f7f\u3063\u305f\u30b8\u30a7\u30cd\u30ec\u30fc\u30bf\u306e\u5b9f\u88c5\n\u3084\u306f\u308aUnity\u3067\u4f7f\u3063\u305fyield\u3068\u540c\u3058\u3088\u3046\u306a\u4f7f\u3044\u65b9\u304c\u3067\u304d\u308b\u3088\u3046\u3060\u3002\n```txt:\u52d5\u4f5c\u74b0\u5883\nGeForce GTX 1070 (8GB)\nASRock Z170M Pro4S [Intel Z170chipset]\nUbuntu 14.04 LTS desktop amd64\nTensorFlow v0.11\ncuDNN v5.1 for Linux\nCUDA v8.0\nPython 2.7.6\nIPython 5.1.0 -- An enhanced Interactive Python.\n```\n\nTensorFlow\u3068\u3044\u3046Deep Learning\u306e\u30d5\u30ec\u30fc\u30e0\u30ef\u30fc\u30af\u306e\u5b66\u7fd2\u4e2d\u3002\n\nhttps://indico.io/blog/tensorflow-data-inputs-part1-placeholders-protobufs-queues/\n\u306e\uff11\u3064\u76ee\u306e\u30b3\u30fc\u30c9\u3067\u898b\u305f\u3053\u3068\u304c\u306a\u3044\u8a18\u8ff0\u306b\u51fa\u304f\u308f\u3057\u305f\u3002\n\n```py\n...\ndef data_iterator():\n    \"\"\" A simple data iterator \"\"\"\n    batch_idx = 0\n    while True:\n        # shuffle labels and features\n        idxs = np.arange(0, len(features))\n        np.random.shuffle(idxs)\n        shuf_features = features[idxs]\n        shuf_labels = labels[idxs]\n        batch_size = 128\n        for batch_idx in range(0, len(features), batch_size):\n            images_batch = shuf_features[batch_idx:batch_idx+batch_size] / 255.\n            images_batch = images_batch.astype(\"float32\")\n            labels_batch = shuf_labels[batch_idx:batch_idx+batch_size]\n            yield images_batch, labels_batch\n\n\niter_ = data_iterator()\nwhile True:\n    # get a batch of data\n    images_batch_val, labels_batch_val = iter_.next()\n    # pass it in as through feed_dict\n    _, loss_val = sess.run([train_op, loss_mean], feed_dict={\n                    images_batch:images_batch_val,\n                    labels_batch:labels_batch_val\n                    })\n    print loss_val\n```\n\n\u4e0a\u8a18\u3067\u3071\u3063\u3068\u307f\u3066\u5206\u304b\u3089\u306a\u304b\u3063\u305f\u306e\u306f\u300citer_.next()\u306enext()\u306f\u3069\u3053\u3067\u5b9a\u7fa9\u3055\u308c\u3066\u3044\u308b\u306e\u304b\u300d\u3068\u3044\u3046\u3053\u3068\u3060\u3063\u305f\u3002\n\niter_\u306e\u30af\u30e9\u30b9data_iterator()\u306b\u306fnext()\u306e\u5b9a\u7fa9\u306f\u306a\u3044\u3002\n\n\u4e00\u65b9\u3067\u3001yield\u3068\u3044\u3046\u8a18\u8ff0\u304c\u3042\u308b\u3002\n\u3053\u308c\u306fUnity\u3067\u30bd\u30d5\u30c8\u3092\u4f5c\u3063\u305f\u6642\u306b\u51fa\u3066\u304d\u305f\u3088\u3046\u306a\u6c17\u304c\u3059\u308b\u3002\nhttp://qiita.com/7of9/items/194e1c7f4b87a79dd129\n\nnext()\u3068yield\u3067\u691c\u7d22\u3059\u308b\u3068Qiita\u8a18\u4e8b\u304c\u898b\u3064\u304b\u3063\u305f\u3002\nhttp://qiita.com/tomotaka_ito/items/35f3eb108f587022fa09#yield\u3092\u4f7f\u3063\u305f\u30b8\u30a7\u30cd\u30ec\u30fc\u30bf\u306e\u5b9f\u88c5\n\n\u3084\u306f\u308aUnity\u3067\u4f7f\u3063\u305fyield\u3068\u540c\u3058\u3088\u3046\u306a\u4f7f\u3044\u65b9\u304c\u3067\u304d\u308b\u3088\u3046\u3060\u3002\n\n\n\n"}