{"context": " More than 1 year has passed since last update.\u5165\u9580\u81ea\u7136\u8a00\u8a9e\u51e6\u7406\u3092\u9806\u8abf\u306b\u8aad\u307f\u9032\u3081\u3066\u3044\u305f\u6240\u3001\u7b2c\uff16\u7ae0\u7df4\u7fd2\u554f\u984c5\u306b\u3066\u5f15\u3063\u304b\u304b\u308b\u3002\n\u6587\u66f8\u5206\u985e\u3092\u6700\u5927\u30a8\u30f3\u30c8\u30ed\u30d4\u30fc\u5206\u985e\u3092\u7528\u3044\u3066\u884c\u304a\u3046\u3068\u3057\u305f\u6240\u3001\u30a8\u30e9\u30fc\u3092\u5410\u304d\u307e\u304f\u3063\u3066\u3046\u3054\u3044\u3066\u304f\u308c\u306a\u3044\u3002\n# -*- coding: utf-8 -*-\n#from __future__ import division\nimport nltk,re\nimport random\nimport numpy\n#\u6620\u753b\u30ec\u30d3\u30e5\u30fc\u304c\u80af\u5b9a\u7684\u304b\u5426\u5b9a\u7684\u304b\u5206\u985e\u3059\u308b\n\n#\u30c7\u30fc\u30bf\nfrom nltk.corpus import movie_reviews\ndocuments = [(list(movie_reviews.words(fileid)),category)\n             for category in movie_reviews.categories()\n             for fileid in movie_reviews.fileids(category)]\nrandom.shuffle(documents)\n\n#\u7d20\u6027\u62bd\u51fa\u5668\nall_words = nltk.FreqDist(w.lower() for w in movie_reviews.words())\nword_features = all_words.keys()[:2000]#\u983b\u51fa\u30ef\u30fc\u30c92000\n\ndef document_features(document):\n  document_words = set(document)\n  features = {}\n  for w in word_features:\n    features['contains(%s)' % w] = (w in document)  #top2000\u306e\u6587\u5b57\u304cdoc\u306b\u5165\u3063\u3066\u3044\u308b\u304b\u3069\u3046\u304b\n  return features\n\n#\u5206\u985e\u5668\u306e\u8a13\u7df4\u3068\u30c6\u30b9\u30c8\nfeaturesets = [(document_features(d),c) for (d,c) in documents]\ntrain_set,test_set = featuresets[100:],featuresets[:100]\n\n#\u6700\u5927\u30a8\u30f3\u30c8\u30ed\u30d4\u30fc\u5206\u985e\nmaxentclassifier = nltk.MaxentClassifier.train(train_set)\n\n#test\nprint \"MaxentClassifier\"\nprint nltk.classify.accuracy(maxentclassifier,test_set)\nprint maxentclassifier.show_most_informative_features(5)\n\n\u30a8\u30e9\u30fc\u306f\u3053\u3093\u306a\u611f\u3058\n  ==> Training (100 iterations)\n\n      Iteration    Log Likelihood    Accuracy\n      ---------------------------------------\n             1          -0.69315        0.498\n/usr/local/lib/python2.7/site-packages/nltk/classify/maxent.py:1332: RuntimeWarning: overflow encountered in power\n  exp_nf_delta = 2 ** nf_delta\n/usr/local/lib/python2.7/site-packages/nltk/classify/maxent.py:1334: RuntimeWarning: invalid value encountered in multiply\n  sum1 = numpy.sum(exp_nf_delta * A, axis=0)\n/usr/local/lib/python2.7/site-packages/nltk/classify/maxent.py:1335: RuntimeWarning: invalid value encountered in multiply\n  sum2 = numpy.sum(nf_exp_nf_delta * A, axis=0)\n/usr/local/lib/python2.7/site-packages/nltk/classify/maxent.py:1341: RuntimeWarning: invalid value encountered in divide\n  deltas -= (ffreq_empirical - sum1) / -sum2\n         Final               nan        0.502\n\n\n\u3069\u3046\u3084\u3089maxent.py\u306e\u521d\u671f\u8a2d\u5b9a\u72b6\u614b\u306e\u5909\u6570\u304c\u3001overflow\u3092\u8d77\u3053\u3057\u3066\u3044\u308b\u3053\u3068\u304c\u539f\u56e0\u3067\u30a8\u30e9\u30fc\u3092\u5410\u3044\u3066\u3044\u308b\u3088\u3046\u3067\u3042\u308b\u3002\n\u3067\u3001\u3044\u308d\u3044\u308d\u30b0\u30b0\u3063\u3066\u307f\u307e\u3057\u305f\u304c\u65e5\u672c\u8a9e\u60c5\u5831\u306a\u304b\u306a\u304b\u51fa\u3066\u3053\u306a\u304b\u3063\u305f\u306e\u3067\u30e1\u30e2\u3002\n\u3053\u3053\u3092\u53c2\u8003\u306b\u4fee\u6b63\u3057\u307e\u3057\u305f\u3002\n\nHello Dmitry,\nwill this change affect the performance? Based on my test, the improvement between iterations drops a lot, comparing to GIS algorithm with default set.\nthe accuracy could reach to 70% after three iterations using GIS, but only 58% after using the modified IIS.\n\u5728 2012\u5e745\u67087\u65e5\u661f\u671f\u4e00UTC-4\u4e0b\u53486\u65f605\u520638\u79d2\uff0cDmitry Sergeev\u5199\u9053\uff1a\nIt seems that changing exp_nf_delta = 2 ** nf_delta (maxent.py line ~1350) to  exp_nf_delta = 2 ** numpy.sqrt(nf_delta) do the trick.\n\n\u3063\u3066\u3053\u3068\u3067\u3001\nsudo vi /usr/local/lib/python2.7/site-packages/nltk/classify/maxent.py\n\n\nmaxent.py\n.\n.\n.\n\nfor rangenum in range(MAX_NEWTON):\n    nf_delta = numpy.outer(nfarray, deltas)\n    #exp_nf_delta = 2 ** nf_delt\u3000\u3000\u3000\u3000\u3000\u3000\u3000 # \u3053\u3053\u304b\u3089\n    exp_nf_delta = 2 ** numpy.sqrt(nf_delta)    #\u3053\u308c\u306b\u5909\u66f4\n    nf_exp_nf_delta = nftranspose * exp_nf_delta\n    sum1 = numpy.sum(exp_nf_delta * A, axis=0)\n    sum2 = numpy.sum(nf_exp_nf_delta * A, axis=0)\n.\n.\n.\n\n\n\u3067\u518d\u5ea6\u8a66\u3057\u3066\u307f\u305f\u3089\u6210\u529f\u3057\u307e\u3057\u305f\u3002\n\u306a\u304b\u306a\u304b\u65e5\u672c\u8a9e\u306e\u60c5\u5831\u304c\u5c11\u306a\u304f\u3066\u5b66\u7fd2\u3082\u5927\u5909\u3067\u3059\u304c\u3001\u81ea\u7136\u8a00\u8a9e\u51e6\u7406\u3001\u3057\u3063\u304b\u308a\u7fd2\u5f97\u3057\u305f\u3044\u3067\u3059\u306d\uff01\n\n\u5165\u9580\u81ea\u7136\u8a00\u8a9e\u51e6\u7406\u3092\u9806\u8abf\u306b\u8aad\u307f\u9032\u3081\u3066\u3044\u305f\u6240\u3001\u7b2c\uff16\u7ae0\u7df4\u7fd2\u554f\u984c5\u306b\u3066\u5f15\u3063\u304b\u304b\u308b\u3002\n\u6587\u66f8\u5206\u985e\u3092\u6700\u5927\u30a8\u30f3\u30c8\u30ed\u30d4\u30fc\u5206\u985e\u3092\u7528\u3044\u3066\u884c\u304a\u3046\u3068\u3057\u305f\u6240\u3001\u30a8\u30e9\u30fc\u3092\u5410\u304d\u307e\u304f\u3063\u3066\u3046\u3054\u3044\u3066\u304f\u308c\u306a\u3044\u3002\n\n```\n# -*- coding: utf-8 -*-\n#from __future__ import division\nimport nltk,re\nimport random\nimport numpy\n#\u6620\u753b\u30ec\u30d3\u30e5\u30fc\u304c\u80af\u5b9a\u7684\u304b\u5426\u5b9a\u7684\u304b\u5206\u985e\u3059\u308b\n\n#\u30c7\u30fc\u30bf\nfrom nltk.corpus import movie_reviews\ndocuments = [(list(movie_reviews.words(fileid)),category)\n             for category in movie_reviews.categories()\n             for fileid in movie_reviews.fileids(category)]\nrandom.shuffle(documents)\n\n#\u7d20\u6027\u62bd\u51fa\u5668\nall_words = nltk.FreqDist(w.lower() for w in movie_reviews.words())\nword_features = all_words.keys()[:2000]#\u983b\u51fa\u30ef\u30fc\u30c92000\n\ndef document_features(document):\n  document_words = set(document)\n  features = {}\n  for w in word_features:\n    features['contains(%s)' % w] = (w in document)  #top2000\u306e\u6587\u5b57\u304cdoc\u306b\u5165\u3063\u3066\u3044\u308b\u304b\u3069\u3046\u304b\n  return features\n\n#\u5206\u985e\u5668\u306e\u8a13\u7df4\u3068\u30c6\u30b9\u30c8\nfeaturesets = [(document_features(d),c) for (d,c) in documents]\ntrain_set,test_set = featuresets[100:],featuresets[:100]\n\n#\u6700\u5927\u30a8\u30f3\u30c8\u30ed\u30d4\u30fc\u5206\u985e\nmaxentclassifier = nltk.MaxentClassifier.train(train_set)\n\n#test\nprint \"MaxentClassifier\"\nprint nltk.classify.accuracy(maxentclassifier,test_set)\nprint maxentclassifier.show_most_informative_features(5)\n```\n\u30a8\u30e9\u30fc\u306f\u3053\u3093\u306a\u611f\u3058\n\n```\n  ==> Training (100 iterations)\n\n      Iteration    Log Likelihood    Accuracy\n      ---------------------------------------\n             1          -0.69315        0.498\n/usr/local/lib/python2.7/site-packages/nltk/classify/maxent.py:1332: RuntimeWarning: overflow encountered in power\n  exp_nf_delta = 2 ** nf_delta\n/usr/local/lib/python2.7/site-packages/nltk/classify/maxent.py:1334: RuntimeWarning: invalid value encountered in multiply\n  sum1 = numpy.sum(exp_nf_delta * A, axis=0)\n/usr/local/lib/python2.7/site-packages/nltk/classify/maxent.py:1335: RuntimeWarning: invalid value encountered in multiply\n  sum2 = numpy.sum(nf_exp_nf_delta * A, axis=0)\n/usr/local/lib/python2.7/site-packages/nltk/classify/maxent.py:1341: RuntimeWarning: invalid value encountered in divide\n  deltas -= (ffreq_empirical - sum1) / -sum2\n         Final               nan        0.502\n\n```\n\u3069\u3046\u3084\u3089maxent.py\u306e\u521d\u671f\u8a2d\u5b9a\u72b6\u614b\u306e\u5909\u6570\u304c\u3001overflow\u3092\u8d77\u3053\u3057\u3066\u3044\u308b\u3053\u3068\u304c\u539f\u56e0\u3067\u30a8\u30e9\u30fc\u3092\u5410\u3044\u3066\u3044\u308b\u3088\u3046\u3067\u3042\u308b\u3002\n\u3067\u3001\u3044\u308d\u3044\u308d\u30b0\u30b0\u3063\u3066\u307f\u307e\u3057\u305f\u304c\u65e5\u672c\u8a9e\u60c5\u5831\u306a\u304b\u306a\u304b\u51fa\u3066\u3053\u306a\u304b\u3063\u305f\u306e\u3067\u30e1\u30e2\u3002\n\n[\u3053\u3053](https://groups.google.com/forum/#!msg/nltk-users/_2-eiF69zVE/7lA7TOP5jEAJ)\u3092\u53c2\u8003\u306b\u4fee\u6b63\u3057\u307e\u3057\u305f\u3002\n\n>Hello Dmitry,\n\n>will this change affect the performance? Based on my test, the improvement between iterations drops a lot, comparing to GIS algorithm with default set.\nthe accuracy could reach to 70% after three iterations using GIS, but only 58% after using the modified IIS.\n\n>\u5728 2012\u5e745\u67087\u65e5\u661f\u671f\u4e00UTC-4\u4e0b\u53486\u65f605\u520638\u79d2\uff0cDmitry Sergeev\u5199\u9053\uff1a\n>It seems that changing exp_nf_delta = 2 ** nf_delta (maxent.py line ~1350) to  exp_nf_delta = 2 ** numpy.sqrt(nf_delta) do the trick.\n\n\u3063\u3066\u3053\u3068\u3067\u3001\n\n    sudo vi /usr/local/lib/python2.7/site-packages/nltk/classify/maxent.py\n```:maxent.py\n.\n.\n.\n\nfor rangenum in range(MAX_NEWTON):\n    nf_delta = numpy.outer(nfarray, deltas)\n    #exp_nf_delta = 2 ** nf_delt\u3000\u3000\u3000\u3000\u3000\u3000\u3000 # \u3053\u3053\u304b\u3089\n    exp_nf_delta = 2 ** numpy.sqrt(nf_delta)    #\u3053\u308c\u306b\u5909\u66f4\n    nf_exp_nf_delta = nftranspose * exp_nf_delta\n    sum1 = numpy.sum(exp_nf_delta * A, axis=0)\n    sum2 = numpy.sum(nf_exp_nf_delta * A, axis=0)\n.\n.\n.\n```\n\n\u3067\u518d\u5ea6\u8a66\u3057\u3066\u307f\u305f\u3089\u6210\u529f\u3057\u307e\u3057\u305f\u3002\n\u306a\u304b\u306a\u304b\u65e5\u672c\u8a9e\u306e\u60c5\u5831\u304c\u5c11\u306a\u304f\u3066\u5b66\u7fd2\u3082\u5927\u5909\u3067\u3059\u304c\u3001\u81ea\u7136\u8a00\u8a9e\u51e6\u7406\u3001\u3057\u3063\u304b\u308a\u7fd2\u5f97\u3057\u305f\u3044\u3067\u3059\u306d\uff01\n\n\n\n\n\n\n\n", "tags": ["Python", "nltk", "\u81ea\u7136\u8a00\u8a9e\u51e6\u7406"]}