{"context": "\n\n\uff08 \u95a2\u9023\u8a18\u4e8b \uff09\n\n\nHirofumiYashima Qiita\u8a18\u4e8b \u300cKeras \u306e Convolution1D\u5c64 \u3068 MaxPooling1D\u5c64 \u3067\u30011d-CNN \u30e2\u30c7\u30eb \u3092 \u4f5c\u3063\u3066\u3001\u6587\u66f8\u30c7\u30fc\u30bf\u4ee5\u5916 \u306e \uff11\u5909\u91cf\u30fb\u591a\u5909\u91cf \u6570\u5024 \u6642\u7cfb\u5217\u30c7\u30fc\u30bf \u306e \u5206\u985e\u30fb\u56de\u5e30\u554f\u984c \u3092 \u89e3\u304f\u300d\n\n\n\n\u591a\u5909\u91cf \u6570\u5024\u6642\u7cfb\u5217\u30c7\u30fc\u30bf\u3000\u3092 \u6271\u3046 \u30b3\u30fc\u30c9\u4f8b\n\ninput_shape() \u3067 \u591a\u5909\u91cf\u306e\u6642\u7cfb\u5217\u30c7\u30fc\u30bf \u3092 \u6e21\u3057\u3066\u3044\u308b\u3002\n\nconvolutional neural network (CNN) for timeseries prediction\n\n\nExample of using Keras to implement a 1D convolutional neural network (CNN) for timeseries prediction.: \ntimeseries_cnn.py\n\n\n\uff08 \u91cd\u8981\u30dd\u30a4\u30f3\u30c8 \uff09\n\n\n\n\"\"\"\n\n\uff08 \u4e2d\u7565 \uff09\n\n:param int nb_input_series: The number of input timeseries; 1 for a single timeseries.\n\n\uff08 \u4e2d\u7565 \uff09\n\nFor example, for `window_size` = 3 and `nb_input_series` = 1 (a single timeseries),\none instance could be ``[[0], [1], [2]]\n\n\uff08 \u4e2d\u7565 \uff09\n\n:param int nb_outputs: The output dimension, often equal to the number of inputs.\nFor each input instance (array with shape ``(window_size, nb_input_series)``), the output is a vector of size `nb_outputs`,\nusually the value(s) predicted to come after the last value in that input instance, i.e., the next value in the sequence.\n\"\"\"\n\n\n\ninput_shape=(window_size, nb_input_series))\n\n\u5909\u6570\u540d \u304c \u307e\u304e\u3089\u308f\u3057\u3044 \u3067\u3059 \u304c\u3001\ninput_shape\u306b\u6e21\u3059\u7b2c\u4e00\u5f15\u6570 \u3067\u3042\u308b \nwindow_size = 3 \n\u3068\u306f\u3001\n1\u6b21\u5143\u7573\u307f\u8fbc\u307f\u30d5\u30a3\u30eb\u30bf \u306e \u9577\u3055 \n\u3067\u306f\u306a\u304f\u3001\n\u5165\u529b\u30c7\u30fc\u30bf \u306e \u500b\u6570\uff08\u6642\u7cfb\u5217\u30c7\u30fc\u30bf\u306e\u500b\u6570\uff09\n\u306e\u3088\u3046\u3067\u3059\u3002\n\u307e\u305f\u3001input_shape\u306b\u6e21\u3059\u7b2c\u4e8c\u5f15\u6570 \u3067\u3042\u308b \nnb_input_series \n\u306f\u3001\u6642\u7cfb\u5217\u30c7\u30fc\u30bf 1\u4ef6\u304c\u3082\u3064\u671f\u9593\u6570\u306e\u3088\u3046\u3067\u3059\u3002\n\nFor example, for `window_size` = 3 and `nb_input_series` = 1 (a single timeseries),\none instance could be ``[[0], [1], [2]]\n\n\n[[0], [1], [2]] \u306f\u3001\u671f\u9593\u6570 1\u671f \u306e\u6642\u7cfb\u5217\u30c7\u30fc\u30bf \u3092 3\u500b \u6301\u3064 \u5165\u529b\u30c7\u30fc\u30bf\u3067\u3059\u3002\ninput_shape \u306b \u6e21\u3059 \u5f15\u6570 \u306f\u3001\n\u4e8c\u91cd\u30ea\u30b9\u30c8 \u3067\u3042\u308b\u3001\n\u3068 Keras Document \u306e 1D Convolution\u5c64\u306e\u30b3\u30f3\u30b9\u30c8\u30e9\u30af\u30bf\u30e1\u30bd\u30c3\u30c9 \u306b\u306f \u66f8\u3044\u3066\u3042\u308a\u307e\u3059\u3002\n\nKeras Documentation Convolution1D\n\n\n\u7b2c\u4e00\u5f15\u6570 \u3067\u3042\u308b window_size \u306f\u3001\u3053\u306e\u4e8c\u91cd\u30ea\u30b9\u30c8 \u306e \u5916\u5074 \u306e \u8981\u7d20\u6570 \u3092\u3001\n\u7b2c\u4e8c\u5f15\u6570 \u3067\u3042\u308b nb_input_series \u306f\u3001\u4e8c\u91cd\u30ea\u30b9\u30c8\u306e\u5185\u5074\u306e\u8981\u7d20\u6570 \u3092 \n\u6307\u5b9a\u3057\u3066\u3044\u307e\u3059\u3002\nwindow_size \u3092 2\u4ee5\u4e0a\u306b\u3059\u308b\u3068\u3001\nGDP \u8907\u6570\u671f\u9593\u30c7\u30fc\u30bf \n\u3068 \n\u5b9f\u8cea\u91d1\u5229 \u8907\u6570\u671f\u9593\u30c7\u30fc\u30bf\n\u306e\u3088\u3046\u306b\u3001\n\u5185\u5bb9\u306e\u7570\u306a\u308b\u591a\u5909\u91cf\u6642\u7cfb\u5217\u30c7\u30fc\u30bf\u3092\u6e21\u305b\u308b\n\u3068\u3044\u3046\u3053\u3068\u3067\u3057\u3087\u3046\u304b\u3002\n\u306a\u304a\u3001\u4ee5\u4e0b \u3067\u3001\n\nnb_input_series=1 : \u6642\u7cfb\u5217\u30c7\u30fc\u30bf\u306e\u671f\u9593\u6570 \u306f\u30011\u671f\u9593\u306e\u307f\nnb_outputs=1 : output \u306f 1\u3064\nnb_filter=4 : \u7573\u307f\u8fbc\u307f\u30d5\u30a3\u30eb\u30bf \u306f 4\u3064\n\n\u304c \u5f15\u6570\u306e\u30c7\u30d5\u30a9\u30eb\u30c8\u5024 \u3068\u3057\u3066 \u8a2d\u5b9a\u3055\u308c\u3066\u3044\u308b\u3002\ndef make_timeseries_regressor(window_size, filter_length, nb_input_series=1, nb_outputs=1, nb_filter=4):\n    \"\"\":Return: a Keras Model for predicting the next value in a timeseries given a fixed-size lookback window of previous values.\n\n\"window_size\"\u3000\u306f\u3001main\u30e1\u30bd\u30c3\u30c9 \u306e \u4e2d\u3067\u3001\nmain() \u306e\u3046\u3061\u3001\n'\\nSimple single timeseries vector prediction' \u3067\u306f\u3001\n\nnp.arange(1000) \n\n\u3067 \u671f\u9593\u6570 1,000 \u306e \u6642\u7cfb\u5217 \u6570\u5024\u7cfb\u5217 \u3092 \u751f\u6210\u3057\u3001\n\n\"window_size\" = 50 \n\n\u3067\u3001\nwindow_size = 50\n\u304c \u5b9f\u884c \u3055\u308c\u3066\u3044\u307e\u3059\u3002\n\ndef main():\n   \"\"\"Prepare input data, build model, evaluate.\"\"\"\n   np.set_printoptions(threshold=25)\n   ts_length = 1000\n   window_size = 50\n\n   print('\\nSimple single timeseries vector prediction')\n   timeseries = np.arange(ts_length)                   # The timeseries f(t) = t\n   evaluate_timeseries(timeseries, window_size)\n\n   print('\\nMultiple-input, multiple-output prediction')\n   timeseries = np.array([np.arange(ts_length), -np.arange(ts_length)]).T      # The timeseries f(t) = [t, -t]\n   evaluate_timeseries(timeseries, window_size)\n\n\nwindow_size = 50\n\u306a\u306e\u3067\u3001\u5165\u529b\u30c7\u30fc\u30bf \u306e \u500b\u6570\uff08\u6642\u7cfb\u5217\u30c7\u30fc\u30bf\u306e\u500b\u6570\uff09\u306f 50\u500b\u3002\n\u305d\u3057\u3066\u3001\u5148\u307b\u3069\u898b\u305f\u3088\u3046\u306b\u3001\n\nnb_input_series=1 : \u6642\u7cfb\u5217\u30c7\u30fc\u30bf\u306e\u671f\u9593\u6570 \u306f\u30011\u671f\u9593\u306e\u307f\n\n\u306a\u306e\u3067\u3001\n\n\n\u671f\u9593\u6570 1\u6642\u70b9\u3000\u306e \u6642\u7cfb\u5217\u30c7\u30fc\u30bf\n\n\u304c\n\n50\u500b\n\n\uff11\u6b21\u5143CNN\u30e2\u30c7\u30eb \u306b \u5165\u529b \u3055\u308c\u308b \n\n\u3053\u3068 \u306b \u306a\u308a\u307e\u3059\u3002\n\ndef evaluate_timeseries(timeseries, window_size):\n   \"\"\"Create a 1D CNN regressor to predict the next value in a `timeseries` using the preceding `window_size` elements\n   as input features and evaluate its performance.\n\n   :param ndarray timeseries: Timeseries data with time increasing down the rows (the leading dimension/axis).\n   :param int window_size: The number of previous timeseries values to use to predict the next.\n   \"\"\"\n\n\n\u3053\u306e\u7d50\u679c\u3001\n\n\uff08\u5165\u529b\u5024\uff09 \u76f4\u524d\u306e50\u6642\u70b9\uff0850\u671f\u5206\uff09 \u306e \u8981\u7d20\uff08elements\uff09 \n\n\u3092 \u624b\u304c\u304b\u308a \u306b\u3001\n\n\u6b21 \u306e \u6570\u5024 \uff08next value\uff09\n\n\u3092 \u4e88\u6e2c\u3059\u308b\u30001D CNN regressor  \u304c create \u3055\u308c\u308b \u3068 \u66f8\u304b\u308c\u3066\u3044\u307e\u3059\u3002\n\n   \"\"\"Create a 1D CNN regressor to predict the next value in a `timeseries` using the preceding `window_size` elements\n   as input features and evaluate its performance.\n\n\n\u4ee5\u4e0b \u3067\u306f\u3001\u3053\u306e 1D CNN regressor \u3092\u3001\u300c\u6b21\u306e\u6570\u5024\u3092\u4e88\u6e2c\u300d \u3059\u308b \u56de\u5e30\u554f\u984c \u3092 \u89e3\u304f\u30e2\u30c7\u30eb \u306b\u3059\u308b\u305f\u3081\u306e\u8a2d\u5b9a \u304c \u884c\u306a\u308f\u308c\u3066\u3044\u307e\u3059\u3002\n\nFlatten()\n\nlinear\u95a2\u6570\n\nDense(nb_outputs, activation='linear'), \n\n\u4ee5\u4e0b \u3067\u3001'mse'\uff08\u8aa4\u5dee\u4e8c\u4e57\u6cd5\uff09\u3067\u6570\u5024\u306e\u56de\u5e30\u4e88\u6e2c\u554f\u984c \u3092 \u884c\u3046 \u640d\u5931\u95a2\u6570 \u3092 \u8a2d\u5b9a \u3057\u3066\u3044\u308b\u3002\n\nmodel.compile(loss='mse', optimizer='adam', metrics=['mae'])\n\n\nmodel = Sequential((\n\n\uff08 \u4e2d\u7565 \uff09\n\nConvolution1D(nb_filter=nb_filter, filter_length=filter_length, activation='relu', input_shape=(window_size, nb_input_series)),\n\n\uff08 \u4e2d\u7565 \uff09\n\nMaxPooling1D(),\nFlatten(),\nDense(nb_outputs, activation='linear'),     # For binary classification, change the activation to 'sigmoid'\nmodel.compile(loss='mse', optimizer='adam', metrics=['mae'])\n ))\n\n\n\n\uff08 \u8003\u5bdf \uff09\n\n\u4ee5\u4e0b \u306e 3\u5909\u91cf \u306e \u6642\u7cfb\u5217\u30c7\u30fc\u30bf\uff08\u3044\u305a\u308c\u308214\u671f\u9593\u5206\uff09   \n\n\uff08\u65e5\u6b21\uff09 \u65e5\u7d4c\u5e73\u5747\u682a\u4fa1\u30dc\u30e9\u30c6\u30a3\u30ea\u30c6\u30a3 14\u671f\u9593\n\uff08\u65e5\u6b21\uff09 \u7d4c\u6e08\u653f\u7b56\u4e0d\u78ba\u5b9f\u6027\u6307\u6570 14\u671f\u9593\n\uff08\u65e5\u6b21\uff09 VIX\u6307\u6570\uff08\u6050\u6016\u6307\u6570\uff09 14\u671f\u9593\n\n\u3092 \u5165\u529b\u5024 \u3068\u3057\u3066\u53d7\u3051\u53d6\u308a\u3001\n\u6b21 \u306e 1\u65e5\uff08\u7fcc\u65e5\uff09 \u306e \u5e02\u6cc1\u5b89\u5b9a\u5ea6\u6570\u5024\n\u3092 \uff08\u5b66\u7fd2\u30c7\u30fc\u30bf\u304b\u3089\u5b66\u7fd2\u3057\uff09\u4e88\u6e2c\u3059\u308b \n\u30e2\u30c7\u30eb \u3092 \u69cb\u7bc9\u3059\u308b \u306b\u306f\u3001\n\nwindow_size = 3 \uff083\u5909\u91cf\uff09\nnb_input_series = 14\n\n\u3068\u3057\u3001\n\u5165\u529b\u30c7\u30fc\u30bf \u306f\u3001\n\n[ [ \u8981\u7d20\u657014 \u306e \u6570\u5024\u30ea\u30b9\u30c8 ],  [ \u8981\u7d20\u657014 \u306e \u6570\u5024\u30ea\u30b9\u30c8 ],  [ \u8981\u7d20\u657014 \u306e \u6570\u5024\u30ea\u30b9\u30c8 ] ]\n\n\n\u306b \u3059\u308c\u3070\u826f\u3044 \u3068 \u8003\u3048\u3089\u308c\u307e\u3059\u3002\n\n\n\uff08 \u7cbe\u8aad\u3057\u305f\u30b3\u30fc\u30c9 \u306e \u5168\u6587 \uff09\n\n\nkeras\n#!/usr/bin/env python\n\"\"\"\nExample of using Keras to implement a 1D convolutional neural network (CNN) for timeseries prediction.\n\"\"\"\n\nfrom __future__ import print_function, division\n\nimport numpy as np\nfrom keras.layers import Convolution1D, Dense, MaxPooling1D, Flatten\nfrom keras.models import Sequential\n\n\n__date__ = '2016-07-22'\n\n\ndef make_timeseries_regressor(window_size, filter_length, nb_input_series=1, nb_outputs=1, nb_filter=4):\n    \"\"\":Return: a Keras Model for predicting the next value in a timeseries given a fixed-size lookback window of previous values.\n\n    The model can handle multiple input timeseries (`nb_input_series`) and multiple prediction targets (`nb_outputs`).\n\n    :param int window_size: The number of previous timeseries values to use as input features.  Also called lag or lookback.\n    :param int nb_input_series: The number of input timeseries; 1 for a single timeseries.\n      The `X` input to ``fit()`` should be an array of shape ``(n_instances, window_size, nb_input_series)``; \n      each instance is a 2D array of shape ``(window_size, nb_input_series)``. \n      For example, for `window_size` = 3 and `nb_input_series` = 1 (a single timeseries), \n              one instance could be ``[[0], [1], [2]]``.\n      See ``make_timeseries_instances()``.\n    :param int nb_outputs: The output dimension, often equal to the number of inputs.\n      For each input instance (array with shape ``(window_size, nb_input_series)``), the output is a vector of size `nb_outputs`,\n      usually the value(s) predicted to come after the last value in that input instance, i.e., the next value\n      in the sequence.\n     The `y` input to ``fit()`` should be an array of shape ``(n_instances, nb_outputs)``.\n    :param int filter_length: the size (along the `window_size` dimension) of the sliding window that gets convolved with\n      each position along each instance. \n     The difference between 1D and 2D convolution is that a 1D filter's \"height\" is fixed to the number of input timeseries (its \"width\" being `filter_length`), and it can only slide along the window dimension. \n     This is useful as generally the input timeseries have no spatial/ordinal relationship, so it's not\n      meaningful to look for patterns that are invariant with respect to subsets of the timeseries.\n    :param int nb_filter: The number of different filters to learn (roughly, input patterns to recognize).\n    \"\"\"\n    model = Sequential((\n        # The first conv layer learns `nb_filter` filters (aka kernels), each of size ``(filter_length, nb_input_series)``.\n        # Its output will have shape (None, window_size - filter_length + 1, nb_filter), i.e., for each position in\n        # the input timeseries, the activation of each filter at that position.\n        Convolution1D(nb_filter=nb_filter, filter_length=filter_length, activation='relu', input_shape=(window_size, nb_input_series)),\n        MaxPooling1D(),     # Downsample the output of convolution by 2X.\n        Convolution1D(nb_filter=nb_filter, filter_length=filter_length, activation='relu'),\n        MaxPooling1D(),\n        Flatten(),\n        Dense(nb_outputs, activation='linear'),     # For binary classification, change the activation to 'sigmoid'\n    ))\n    model.compile(loss='mse', optimizer='adam', metrics=['mae'])\n    # To perform (binary) classification instead:\n    # model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['binary_accuracy'])\n    return model\n\n\ndef make_timeseries_instances(timeseries, window_size):\n    \"\"\"Make input features and prediction targets from a `timeseries` for use in machine learning.\n\n    :return: A tuple of `(X, y, q)`.  `X` are the inputs to a predictor, a 3D ndarray with shape\n      ``(timeseries.shape[0] - window_size, window_size, timeseries.shape[1] or 1)``.  For each row of `X`, the\n      corresponding row of `y` is the next value in the timeseries.  The `q` or query is the last instance, what you would use\n      to predict a hypothetical next (unprovided) value in the `timeseries`.\n    :param ndarray timeseries: Either a simple vector, or a matrix of shape ``(timestep, series_num)``, i.e., time is axis 0 (the\n      row) and the series is axis 1 (the column).\n    :param int window_size: The number of samples to use as input prediction features (also called the lag or lookback).\n    \"\"\"\n    timeseries = np.asarray(timeseries)\n    assert 0 < window_size < timeseries.shape[0]\n    X = np.atleast_3d(np.array([timeseries[start:start + window_size] for start in range(0, timeseries.shape[0] - window_size)]))\n    y = timeseries[window_size:]\n    q = np.atleast_3d([timeseries[-window_size:]])\n    return X, y, q\n\n\ndef evaluate_timeseries(timeseries, window_size):\n    \"\"\"Create a 1D CNN regressor to predict the next value in a `timeseries` using the preceding `window_size` elements\n    as input features and evaluate its performance.\n\n    :param ndarray timeseries: Timeseries data with time increasing down the rows (the leading dimension/axis).\n    :param int window_size: The number of previous timeseries values to use to predict the next.\n    \"\"\"\n    filter_length = 5\n    nb_filter = 4\n    timeseries = np.atleast_2d(timeseries)\n    if timeseries.shape[0] == 1:\n        timeseries = timeseries.T       # Convert 1D vectors to 2D column vectors\n\n    nb_samples, nb_series = timeseries.shape\n    print('\\n\\nTimeseries ({} samples by {} series):\\n'.format(nb_samples, nb_series), timeseries)\n    model = make_timeseries_regressor(window_size=window_size, filter_length=filter_length, nb_input_series=nb_series, nb_outputs=nb_series, nb_filter=nb_filter)\n    print('\\n\\nModel with input size {}, output size {}, {} conv filters of length {}'.format(model.input_shape, model.output_shape, nb_filter, filter_length))\n    model.summary()\n\n    X, y, q = make_timeseries_instances(timeseries, window_size)\n    print('\\n\\nInput features:', X, '\\n\\nOutput labels:', y, '\\n\\nQuery vector:', q, sep='\\n')\n    test_size = int(0.01 * nb_samples)           # In real life you'd want to use 0.2 - 0.5\n    X_train, X_test, y_train, y_test = X[:-test_size], X[-test_size:], y[:-test_size], y[-test_size:]\n    model.fit(X_train, y_train, nb_epoch=25, batch_size=2, validation_data=(X_test, y_test))\n\n    pred = model.predict(X_test)\n    print('\\n\\nactual', 'predicted', sep='\\t')\n    for actual, predicted in zip(y_test, pred.squeeze()):\n        print(actual.squeeze(), predicted, sep='\\t')\n    print('next', model.predict(q).squeeze(), sep='\\t')\n\n\ndef main():\n    \"\"\"Prepare input data, build model, evaluate.\"\"\"\n    np.set_printoptions(threshold=25)\n    ts_length = 1000\n    window_size = 50\n\n    print('\\nSimple single timeseries vector prediction')\n    timeseries = np.arange(ts_length)                   # The timeseries f(t) = t\n    evaluate_timeseries(timeseries, window_size)\n\n    print('\\nMultiple-input, multiple-output prediction')\n    timeseries = np.array([np.arange(ts_length), -np.arange(ts_length)]).T      # The timeseries f(t) = [t, -t]\n    evaluate_timeseries(timeseries, window_size)\n\n\nif __name__ == '__main__':\n    main()\n\n\n###__\uff08 \u95a2\u9023\u8a18\u4e8b \uff09__\n\n* [HirofumiYashima Qiita\u8a18\u4e8b \u300cKeras \u306e Convolution1D\u5c64 \u3068 MaxPooling1D\u5c64 \u3067\u30011d-CNN \u30e2\u30c7\u30eb \u3092 \u4f5c\u3063\u3066\u3001\u6587\u66f8\u30c7\u30fc\u30bf\u4ee5\u5916 \u306e \uff11\u5909\u91cf\u30fb\u591a\u5909\u91cf \u6570\u5024 \u6642\u7cfb\u5217\u30c7\u30fc\u30bf \u306e \u5206\u985e\u30fb\u56de\u5e30\u554f\u984c \u3092 \u89e3\u304f\u300d](http://qiita.com/HirofumiYashima/items/2aee883b736ee600899b)\n\n___\n\n\n###__\u591a\u5909\u91cf \u6570\u5024\u6642\u7cfb\u5217\u30c7\u30fc\u30bf\u3000\u3092 \u6271\u3046 \u30b3\u30fc\u30c9\u4f8b__\n\n**input_shape() \u3067 \u591a\u5909\u91cf\u306e\u6642\u7cfb\u5217\u30c7\u30fc\u30bf \u3092 \u6e21\u3057\u3066\u3044\u308b\u3002**\n\n* [convolutional neural network (CNN) for timeseries prediction](https://www.snip2code.com/Snippet/1371069/Example-of-using-Keras-to-implement-a-1D)\n\n> Example of using Keras to implement a 1D convolutional neural network (CNN) for timeseries prediction.: \ntimeseries_cnn.py\n\n\n###__\uff08 \u91cd\u8981\u30dd\u30a4\u30f3\u30c8 \uff09__\n___\n\n>```{python:}\n>\"\"\"\n>\n> \uff08 \u4e2d\u7565 \uff09\n>\n> :param int nb_input_series: The number of input timeseries; 1 for a single timeseries.\n>\n> \uff08 \u4e2d\u7565 \uff09\n>\n> For example, for `window_size` = 3 and `nb_input_series` = 1 (a single timeseries),\n> one instance could be ``[[0], [1], [2]]\n>\n> \uff08 \u4e2d\u7565 \uff09\n>\n> :param int nb_outputs: The output dimension, often equal to the number of inputs.\n> For each input instance (array with shape ``(window_size, nb_input_series)``), the output is a vector of size `nb_outputs`,\n> usually the value(s) predicted to come after the last value in that input instance, i.e., the next value in the sequence.\n>\"\"\"\n>```\n\n* input_shape=(window_size, nb_input_series))\n\n\n\u5909\u6570\u540d \u304c \u307e\u304e\u3089\u308f\u3057\u3044 \u3067\u3059 \u304c\u3001\ninput_shape\u306b\u6e21\u3059\u7b2c\u4e00\u5f15\u6570 \u3067\u3042\u308b \n `window_size` = 3 \n\u3068\u306f\u3001\n1\u6b21\u5143\u7573\u307f\u8fbc\u307f\u30d5\u30a3\u30eb\u30bf \u306e \u9577\u3055 \n\u3067\u306f\u306a\u304f\u3001\n\u5165\u529b\u30c7\u30fc\u30bf \u306e \u500b\u6570\uff08\u6642\u7cfb\u5217\u30c7\u30fc\u30bf\u306e\u500b\u6570\uff09\n\u306e\u3088\u3046\u3067\u3059\u3002\n\n\u307e\u305f\u3001input_shape\u306b\u6e21\u3059\u7b2c\u4e8c\u5f15\u6570 \u3067\u3042\u308b \n\n `nb_input_series` \n\n\u306f\u3001\u6642\u7cfb\u5217\u30c7\u30fc\u30bf 1\u4ef6\u304c\u3082\u3064\u671f\u9593\u6570\u306e\u3088\u3046\u3067\u3059\u3002\n\n>```{python:}\n>For example, for `window_size` = 3 and `nb_input_series` = 1 (a single timeseries),\n>one instance could be ``[[0], [1], [2]]\n>```\n\n[[0], [1], [2]] \u306f\u3001\u671f\u9593\u6570 1\u671f \u306e\u6642\u7cfb\u5217\u30c7\u30fc\u30bf \u3092 3\u500b \u6301\u3064 \u5165\u529b\u30c7\u30fc\u30bf\u3067\u3059\u3002\n\ninput_shape \u306b \u6e21\u3059 \u5f15\u6570 \u306f\u3001\n\u4e8c\u91cd\u30ea\u30b9\u30c8 \u3067\u3042\u308b\u3001\n\u3068 Keras Document \u306e 1D Convolution\u5c64\u306e\u30b3\u30f3\u30b9\u30c8\u30e9\u30af\u30bf\u30e1\u30bd\u30c3\u30c9 \u306b\u306f \u66f8\u3044\u3066\u3042\u308a\u307e\u3059\u3002\n\n* [Keras Documentation _Convolution1D_](https://keras.io/layers/convolutional/)\n\n<img width=\"1206\" alt=\"\u30b9\u30af\u30ea\u30fc\u30f3\u30b7\u30e7\u30c3\u30c8 2017-02-28 21.20.18.png\" src=\"https://qiita-image-store.s3.amazonaws.com/0/43487/4fe24727-a061-1fb5-4616-b75cac6800a3.png\">\n\n\n\u7b2c\u4e00\u5f15\u6570 \u3067\u3042\u308b window_size \u306f\u3001\u3053\u306e\u4e8c\u91cd\u30ea\u30b9\u30c8 \u306e \u5916\u5074 \u306e \u8981\u7d20\u6570 \u3092\u3001\n\u7b2c\u4e8c\u5f15\u6570 \u3067\u3042\u308b nb_input_series \u306f\u3001\u4e8c\u91cd\u30ea\u30b9\u30c8\u306e\u5185\u5074\u306e\u8981\u7d20\u6570 \u3092 \n\u6307\u5b9a\u3057\u3066\u3044\u307e\u3059\u3002\n\n `window_size` \u3092 2\u4ee5\u4e0a\u306b\u3059\u308b\u3068\u3001\nGDP \u8907\u6570\u671f\u9593\u30c7\u30fc\u30bf \n\u3068 \n\u5b9f\u8cea\u91d1\u5229 \u8907\u6570\u671f\u9593\u30c7\u30fc\u30bf\n\u306e\u3088\u3046\u306b\u3001\n\u5185\u5bb9\u306e\u7570\u306a\u308b\u591a\u5909\u91cf\u6642\u7cfb\u5217\u30c7\u30fc\u30bf\u3092\u6e21\u305b\u308b\n\u3068\u3044\u3046\u3053\u3068\u3067\u3057\u3087\u3046\u304b\u3002\n\n\u306a\u304a\u3001\u4ee5\u4e0b \u3067\u3001\n\n* nb_input_series=1 : \u6642\u7cfb\u5217\u30c7\u30fc\u30bf\u306e\u671f\u9593\u6570 \u306f\u30011\u671f\u9593\u306e\u307f\n* nb_outputs=1 : output \u306f 1\u3064\n* nb_filter=4 : \u7573\u307f\u8fbc\u307f\u30d5\u30a3\u30eb\u30bf \u306f 4\u3064\n\n\u304c \u5f15\u6570\u306e\u30c7\u30d5\u30a9\u30eb\u30c8\u5024 \u3068\u3057\u3066 \u8a2d\u5b9a\u3055\u308c\u3066\u3044\u308b\u3002\n\n```{python:}\ndef make_timeseries_regressor(window_size, filter_length, nb_input_series=1, nb_outputs=1, nb_filter=4):\n    \"\"\":Return: a Keras Model for predicting the next value in a timeseries given a fixed-size lookback window of previous values.\n```\n\n\"window_size\"\u3000\u306f\u3001main\u30e1\u30bd\u30c3\u30c9 \u306e \u4e2d\u3067\u3001\n\n\n*main()* \u306e\u3046\u3061\u3001\n'\\nSimple single timeseries vector prediction' \u3067\u306f\u3001\n\n* np.arange(1000) \n\n\u3067 \u671f\u9593\u6570 1,000 \u306e \u6642\u7cfb\u5217 \u6570\u5024\u7cfb\u5217 \u3092 \u751f\u6210\u3057\u3001\n\n* \"window_size\" = 50 \n\n\u3067\u3001\n\nwindow_size = 50\n\n\u304c \u5b9f\u884c \u3055\u308c\u3066\u3044\u307e\u3059\u3002\n\n\n>```{python:}\n>def main():\n>    \"\"\"Prepare input data, build model, evaluate.\"\"\"\n>    np.set_printoptions(threshold=25)\n>    ts_length = 1000\n>    window_size = 50\n>\n>    print('\\nSimple single timeseries vector prediction')\n>    timeseries = np.arange(ts_length)                   # The timeseries f(t) = t\n>    evaluate_timeseries(timeseries, window_size)\n>\n>    print('\\nMultiple-input, multiple-output prediction')\n>    timeseries = np.array([np.arange(ts_length), -np.arange(ts_length)]).T      # The timeseries f(t) = [t, -t]\n>    evaluate_timeseries(timeseries, window_size)\n>```\n\nwindow_size = 50\n\n\u306a\u306e\u3067\u3001\u5165\u529b\u30c7\u30fc\u30bf \u306e \u500b\u6570\uff08\u6642\u7cfb\u5217\u30c7\u30fc\u30bf\u306e\u500b\u6570\uff09\u306f 50\u500b\u3002\n\n\u305d\u3057\u3066\u3001\u5148\u307b\u3069\u898b\u305f\u3088\u3046\u306b\u3001\n\n* nb_input_series=1 : \u6642\u7cfb\u5217\u30c7\u30fc\u30bf\u306e\u671f\u9593\u6570 \u306f\u30011\u671f\u9593\u306e\u307f\n\n\u306a\u306e\u3067\u3001\n\n___\n\n* \u671f\u9593\u6570 1\u6642\u70b9\u3000\u306e \u6642\u7cfb\u5217\u30c7\u30fc\u30bf\n\n\u304c\n\n* 50\u500b\n\n\uff11\u6b21\u5143CNN\u30e2\u30c7\u30eb \u306b \u5165\u529b \u3055\u308c\u308b \n\n___\n\n\u3053\u3068 \u306b \u306a\u308a\u307e\u3059\u3002\n\n\n>```{python:}\n>def evaluate_timeseries(timeseries, window_size):\n>    \"\"\"Create a 1D CNN regressor to predict the next value in a `timeseries` using the preceding `window_size` elements\n>    as input features and evaluate its performance.\n>\n>    :param ndarray timeseries: Timeseries data with time increasing down the rows (the leading dimension/axis).\n>    :param int window_size: The number of previous timeseries values to use to predict the next.\n>    \"\"\"\n>```\n\n\u3053\u306e\u7d50\u679c\u3001\n\n* \uff08\u5165\u529b\u5024\uff09 \u76f4\u524d\u306e50\u6642\u70b9\uff0850\u671f\u5206\uff09 \u306e \u8981\u7d20\uff08*elements*\uff09 \n\n\u3092 \u624b\u304c\u304b\u308a \u306b\u3001\n\n* \u6b21 \u306e \u6570\u5024 \uff08*next value*\uff09\n\n\u3092 \u4e88\u6e2c\u3059\u308b\u3000*1D CNN regressor*  \u304c *create* \u3055\u308c\u308b \u3068 \u66f8\u304b\u308c\u3066\u3044\u307e\u3059\u3002\n\n>```{python:}\n>    \"\"\"Create a 1D CNN regressor to predict the next value in a `timeseries` using the preceding `window_size` elements\n>    as input features and evaluate its performance.\n>```\n\n\u4ee5\u4e0b \u3067\u306f\u3001\u3053\u306e *1D CNN regressor* \u3092\u3001\u300c\u6b21\u306e\u6570\u5024\u3092\u4e88\u6e2c\u300d \u3059\u308b \u56de\u5e30\u554f\u984c \u3092 \u89e3\u304f\u30e2\u30c7\u30eb \u306b\u3059\u308b\u305f\u3081\u306e\u8a2d\u5b9a \u304c \u884c\u306a\u308f\u308c\u3066\u3044\u307e\u3059\u3002\n\n* Flatten()\n\n__linear\u95a2\u6570__\n\n* Dense(nb_outputs, activation='linear'), \n\n__\u4ee5\u4e0b \u3067\u3001'mse'\uff08\u8aa4\u5dee\u4e8c\u4e57\u6cd5\uff09\u3067\u6570\u5024\u306e\u56de\u5e30\u4e88\u6e2c\u554f\u984c \u3092 \u884c\u3046 \u640d\u5931\u95a2\u6570 \u3092 \u8a2d\u5b9a \u3057\u3066\u3044\u308b\u3002__\n\n* model.compile(loss='mse', optimizer='adam', metrics=['mae'])\n\n>```{python:}\n> model = Sequential((\n>\n> \uff08 \u4e2d\u7565 \uff09\n>\n> Convolution1D(nb_filter=nb_filter, filter_length=filter_length, activation='relu', input_shape=(window_size, nb_input_series)),\n>\n> \uff08 \u4e2d\u7565 \uff09\n>\n> MaxPooling1D(),\n> Flatten(),\n> Dense(nb_outputs, activation='linear'),     # For binary classification, change the activation to 'sigmoid'\n> model.compile(loss='mse', optimizer='adam', metrics=['mae'])\n>  ))\n>```\n\n##__\uff08 \u8003\u5bdf \uff09__\n\n\u4ee5\u4e0b \u306e 3\u5909\u91cf \u306e \u6642\u7cfb\u5217\u30c7\u30fc\u30bf\uff08\u3044\u305a\u308c\u308214\u671f\u9593\u5206\uff09   \n\n* \uff08\u65e5\u6b21\uff09 \u65e5\u7d4c\u5e73\u5747\u682a\u4fa1\u30dc\u30e9\u30c6\u30a3\u30ea\u30c6\u30a3 14\u671f\u9593\n* \uff08\u65e5\u6b21\uff09 \u7d4c\u6e08\u653f\u7b56\u4e0d\u78ba\u5b9f\u6027\u6307\u6570 14\u671f\u9593\n* \uff08\u65e5\u6b21\uff09 VIX\u6307\u6570\uff08\u6050\u6016\u6307\u6570\uff09 14\u671f\u9593\n\n\u3092 \u5165\u529b\u5024 \u3068\u3057\u3066\u53d7\u3051\u53d6\u308a\u3001\n\n\u6b21 \u306e 1\u65e5\uff08\u7fcc\u65e5\uff09 \u306e \u5e02\u6cc1\u5b89\u5b9a\u5ea6\u6570\u5024\n\n\u3092 \uff08\u5b66\u7fd2\u30c7\u30fc\u30bf\u304b\u3089\u5b66\u7fd2\u3057\uff09\u4e88\u6e2c\u3059\u308b \n\n\u30e2\u30c7\u30eb \u3092 \u69cb\u7bc9\u3059\u308b \u306b\u306f\u3001\n\n* window_size = 3 \uff083\u5909\u91cf\uff09\n* nb_input_series = 14\n\n\u3068\u3057\u3001\n\n\u5165\u529b\u30c7\u30fc\u30bf \u306f\u3001\n\n>```{python:}\n> [ [ \u8981\u7d20\u657014 \u306e \u6570\u5024\u30ea\u30b9\u30c8 ],  [ \u8981\u7d20\u657014 \u306e \u6570\u5024\u30ea\u30b9\u30c8 ],  [ \u8981\u7d20\u657014 \u306e \u6570\u5024\u30ea\u30b9\u30c8 ] ]\n>```\n\n\u306b \u3059\u308c\u3070\u826f\u3044 \u3068 \u8003\u3048\u3089\u308c\u307e\u3059\u3002\n\n\n___\n\n##__\uff08 \u7cbe\u8aad\u3057\u305f\u30b3\u30fc\u30c9 \u306e \u5168\u6587 \uff09__\n\n\n```{python:keras}\n#!/usr/bin/env python\n\"\"\"\nExample of using Keras to implement a 1D convolutional neural network (CNN) for timeseries prediction.\n\"\"\"\n\nfrom __future__ import print_function, division\n\nimport numpy as np\nfrom keras.layers import Convolution1D, Dense, MaxPooling1D, Flatten\nfrom keras.models import Sequential\n\n\n__date__ = '2016-07-22'\n\n\ndef make_timeseries_regressor(window_size, filter_length, nb_input_series=1, nb_outputs=1, nb_filter=4):\n    \"\"\":Return: a Keras Model for predicting the next value in a timeseries given a fixed-size lookback window of previous values.\n\n    The model can handle multiple input timeseries (`nb_input_series`) and multiple prediction targets (`nb_outputs`).\n\n    :param int window_size: The number of previous timeseries values to use as input features.  Also called lag or lookback.\n    :param int nb_input_series: The number of input timeseries; 1 for a single timeseries.\n      The `X` input to ``fit()`` should be an array of shape ``(n_instances, window_size, nb_input_series)``; \n      each instance is a 2D array of shape ``(window_size, nb_input_series)``. \n      For example, for `window_size` = 3 and `nb_input_series` = 1 (a single timeseries), \n              one instance could be ``[[0], [1], [2]]``.\n      See ``make_timeseries_instances()``.\n    :param int nb_outputs: The output dimension, often equal to the number of inputs.\n      For each input instance (array with shape ``(window_size, nb_input_series)``), the output is a vector of size `nb_outputs`,\n      usually the value(s) predicted to come after the last value in that input instance, i.e., the next value\n      in the sequence.\n     The `y` input to ``fit()`` should be an array of shape ``(n_instances, nb_outputs)``.\n    :param int filter_length: the size (along the `window_size` dimension) of the sliding window that gets convolved with\n      each position along each instance. \n     The difference between 1D and 2D convolution is that a 1D filter's \"height\" is fixed to the number of input timeseries (its \"width\" being `filter_length`), and it can only slide along the window dimension. \n     This is useful as generally the input timeseries have no spatial/ordinal relationship, so it's not\n      meaningful to look for patterns that are invariant with respect to subsets of the timeseries.\n    :param int nb_filter: The number of different filters to learn (roughly, input patterns to recognize).\n    \"\"\"\n    model = Sequential((\n        # The first conv layer learns `nb_filter` filters (aka kernels), each of size ``(filter_length, nb_input_series)``.\n        # Its output will have shape (None, window_size - filter_length + 1, nb_filter), i.e., for each position in\n        # the input timeseries, the activation of each filter at that position.\n        Convolution1D(nb_filter=nb_filter, filter_length=filter_length, activation='relu', input_shape=(window_size, nb_input_series)),\n        MaxPooling1D(),     # Downsample the output of convolution by 2X.\n        Convolution1D(nb_filter=nb_filter, filter_length=filter_length, activation='relu'),\n        MaxPooling1D(),\n        Flatten(),\n        Dense(nb_outputs, activation='linear'),     # For binary classification, change the activation to 'sigmoid'\n    ))\n    model.compile(loss='mse', optimizer='adam', metrics=['mae'])\n    # To perform (binary) classification instead:\n    # model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['binary_accuracy'])\n    return model\n\n\ndef make_timeseries_instances(timeseries, window_size):\n    \"\"\"Make input features and prediction targets from a `timeseries` for use in machine learning.\n\n    :return: A tuple of `(X, y, q)`.  `X` are the inputs to a predictor, a 3D ndarray with shape\n      ``(timeseries.shape[0] - window_size, window_size, timeseries.shape[1] or 1)``.  For each row of `X`, the\n      corresponding row of `y` is the next value in the timeseries.  The `q` or query is the last instance, what you would use\n      to predict a hypothetical next (unprovided) value in the `timeseries`.\n    :param ndarray timeseries: Either a simple vector, or a matrix of shape ``(timestep, series_num)``, i.e., time is axis 0 (the\n      row) and the series is axis 1 (the column).\n    :param int window_size: The number of samples to use as input prediction features (also called the lag or lookback).\n    \"\"\"\n    timeseries = np.asarray(timeseries)\n    assert 0 < window_size < timeseries.shape[0]\n    X = np.atleast_3d(np.array([timeseries[start:start + window_size] for start in range(0, timeseries.shape[0] - window_size)]))\n    y = timeseries[window_size:]\n    q = np.atleast_3d([timeseries[-window_size:]])\n    return X, y, q\n\n\ndef evaluate_timeseries(timeseries, window_size):\n    \"\"\"Create a 1D CNN regressor to predict the next value in a `timeseries` using the preceding `window_size` elements\n    as input features and evaluate its performance.\n\n    :param ndarray timeseries: Timeseries data with time increasing down the rows (the leading dimension/axis).\n    :param int window_size: The number of previous timeseries values to use to predict the next.\n    \"\"\"\n    filter_length = 5\n    nb_filter = 4\n    timeseries = np.atleast_2d(timeseries)\n    if timeseries.shape[0] == 1:\n        timeseries = timeseries.T       # Convert 1D vectors to 2D column vectors\n\n    nb_samples, nb_series = timeseries.shape\n    print('\\n\\nTimeseries ({} samples by {} series):\\n'.format(nb_samples, nb_series), timeseries)\n    model = make_timeseries_regressor(window_size=window_size, filter_length=filter_length, nb_input_series=nb_series, nb_outputs=nb_series, nb_filter=nb_filter)\n    print('\\n\\nModel with input size {}, output size {}, {} conv filters of length {}'.format(model.input_shape, model.output_shape, nb_filter, filter_length))\n    model.summary()\n\n    X, y, q = make_timeseries_instances(timeseries, window_size)\n    print('\\n\\nInput features:', X, '\\n\\nOutput labels:', y, '\\n\\nQuery vector:', q, sep='\\n')\n    test_size = int(0.01 * nb_samples)           # In real life you'd want to use 0.2 - 0.5\n    X_train, X_test, y_train, y_test = X[:-test_size], X[-test_size:], y[:-test_size], y[-test_size:]\n    model.fit(X_train, y_train, nb_epoch=25, batch_size=2, validation_data=(X_test, y_test))\n\n    pred = model.predict(X_test)\n    print('\\n\\nactual', 'predicted', sep='\\t')\n    for actual, predicted in zip(y_test, pred.squeeze()):\n        print(actual.squeeze(), predicted, sep='\\t')\n    print('next', model.predict(q).squeeze(), sep='\\t')\n\n\ndef main():\n    \"\"\"Prepare input data, build model, evaluate.\"\"\"\n    np.set_printoptions(threshold=25)\n    ts_length = 1000\n    window_size = 50\n\n    print('\\nSimple single timeseries vector prediction')\n    timeseries = np.arange(ts_length)                   # The timeseries f(t) = t\n    evaluate_timeseries(timeseries, window_size)\n\n    print('\\nMultiple-input, multiple-output prediction')\n    timeseries = np.array([np.arange(ts_length), -np.arange(ts_length)]).T      # The timeseries f(t) = [t, -t]\n    evaluate_timeseries(timeseries, window_size)\n\n\nif __name__ == '__main__':\n    main()\n```\n    \n", "tags": ["Keras", "DeepLearning", "\u6df1\u5c64\u5b66\u7fd2", "\u6642\u7cfb\u5217\u89e3\u6790", "\u4eba\u5de5\u77e5\u80fd"]}