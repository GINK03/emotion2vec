{"context": "\n\nRecurrent Neural Network (\u30ea\u30ab\u30ec\u30f3\u30c8\u30cb\u30e5\u30fc\u30e9\u30eb\u30cd\u30c3\u30c8\u30ef\u30fc\u30af)\n\u6642\u7cfb\u5217\u30c7\u30fc\u30bf\u306a\u3069\u9023\u7d9a\u5024\u3067\u76f8\u95a2\u304c\u3042\u308a\u305d\u3046\u306a\u3082\u306e\u306b\u5bfe\u3057\u3066\u3001\u5165\u529b\u3092\u4e00\u3064\u3065\u3064\u51e6\u7406\u3057\u3064\u3064\u30cd\u30c3\u30c8\u30ef\u30fc\u30af\u5185\u90e8\u3067\u72b6\u614b\u5024\u3092\u4fdd\u6301\u3057\u3066\u3001\u5165\u529b\u304c\u5168\u3066\u7d42\u308f\u3063\u305f\u5f8c\u306b\u6700\u7d42\u7684\u306a\u51fa\u529b\u3092\u3057\u3066\u304f\u308c\u308bRNN\u3055\u3093\u3002\n\u5b9f\u4e16\u754c\u306e\u6642\u7cfb\u5217\u30c7\u30fc\u30bf\u3060\u3068\u30ce\u30a4\u30ba\u304c\u5165\u308a\u3059\u304e\u308b\u3057\u3001Tensorflow\u306e\u30c1\u30e5\u30fc\u30c8\u30ea\u30a2\u30eb\u306e\u3088\u3046\u306a\u8a00\u8a9e\u7cfb\u3060\u3068\u30a4\u30de\u30a4\u30c1\"\u6642\u7cfb\u5217\"\u3068\u3057\u3066\u306e\u30a4\u30e1\u30fc\u30b8\u304c\u96e3\u3057\u3044\u3002\n\u305d\u3057\u3066\u30a4\u30de\u30a4\u30c1RNNCell\u30af\u30e9\u30b9\u306e\u4ed5\u69d8\u304c\u3064\u304b\u3081\u306a\u3044\u306e\u3067\u3001\u8ae6\u3081\u3066\u5b9f\u9a13\u7684\u306b\u7c21\u5358\u306a\u81ea\u5df1\u30d5\u30a3\u30fc\u30c9\u30d0\u30c3\u30af\u306e\u30e2\u30c7\u30eb\u3092\u4f5c\u3063\u3066\u307f\u307e\u3059\u3002\n\n\u691c\u8a3c\u5bfe\u8c61 : \u30ab\u30aa\u30b9\u529b\u5b66\n\u30d0\u30bf\u30d5\u30e9\u30a4\u30a8\u30d5\u30a7\u30af\u30c8\u3067\u6709\u540d\u306a\u30ab\u30aa\u30b9\u3067\u3059\u304c\u3001\u4e00\u898b\u30e9\u30f3\u30c0\u30e0\u306b\u898b\u3048\u308b\u3093\u3060\u3051\u3069\u5b9f\u306f\u3042\u308b\u6cd5\u5247\u307f\u305f\u3044\u306a\u3082\u306e\u304c\u3042\u308b\u4e8b\u8c61\u3092\u5206\u6790\u3059\u308b\u4e0a\u3067\u5f79\u306b\u7acb\u3064\u3084\u3064\u3067\u3059\u3002\n\u305d\u306e\u4e2d\u3067\u3082\u500b\u4eba\u7684\u306b\u4e00\u756a\u5206\u304b\u308a\u3084\u3059\u3044 Logistic Map(\u30ed\u30b8\u30b9\u30c6\u30a3\u30c3\u30af\u5199\u50cf)\u3092\u4f8b\u306b\u304a\u8a71\u3092\u3057\u307e\u3059\u3002\n\n\u96e2\u6563\u578b\u30ed\u30b8\u30b9\u30c6\u30a3\u30c3\u30af\u65b9\u7a0b\u5f0f\n\u3042\u308b\u6642\u70b9 tt \u306b\u304a\u3051\u308b x(t)x(t) \u306e\u5024\u304c\u3001\u4e00\u3064\u524d\u306e\u6642\u70b9 x(t\u22121)x(t-1) \u306e\u5024\u3068\u56fa\u6709\u306e\u30d1\u30e9\u30e1\u30fc\u30bf rr \u304b\u3089\u5c0e\u304d\u51fa\u305b\u308b\u4e0b\u8a18\u306e\u8d85\u7c21\u5358\u306a\u5f0f\u304c\u3042\u308a\u307e\u3059\u3002\nx_t = rx_{t-1}(1-x_{t-1})\n\nxt=rxt\u22121(1\u2212xt\u22121){x_t = rx_{t-1}(1-x_{t-1})\n\n}\n\u3082\u3057\u304f\u306f\u4e00\u3064\u5148\u306e\u6642\u70b9\u3092\u4e88\u6e2c\u3057\u305f\u3044\u306e\u3067\u3042\u308c\u3070\u3001\u3053\u3046\u306a\u308a\u307e\u3059\u3002\nx_{t+1} = rx_t(1-x_t)\nxt+1=rxt(1\u2212xt){x_{t+1} = rx_t(1-x_t)\n}\nxx\u306f0 \u2264 x \u2264 1 rr\u306f0 \u2264 r \u2264 4\n\u3053\u308c\u306e\u3069\u3053\u304b\u30ab\u30aa\u30b9\u306a\u306e\u304b\u3068\u3044\u3046\u3068\u3001\u3053\u306e\u6570\u5f0f\u306f rr \u304c 3.6\u3042\u305f\u308a\u304b\u3089xx\u306e\u3068\u308a\u3048\u308b\u5024\u304c\u83ab\u5927\u306b\u5897\u3048\u307e\u3059\u3002\n\nxx\u3092\u6642\u7cfb\u5217\u30c7\u30fc\u30bf\u3068\u3057\u3066\u307f\u308b\u3068\u3001\u898b\u4e8b\u306a\u4e71\u6570\u306b\u306a\u3063\u3066\u307e\u3059\u3002\n\n\u5b8c\u5168\u306b\u30e9\u30f3\u30c0\u30e0\u306a\u5024\u3068\u6642\u7cfb\u5217\u3067\u6bd4\u3079\u308b\u3068\u4f55\u3082\u8a00\u308f\u308c\u306a\u3051\u308c\u3070\u9055\u3044\u304c\u5206\u304b\u3089\u306a\u305d\u3046\u3067\u3059\u3002\n\n\u30ab\u30aa\u30b9\u304c\u7d20\u6674\u3089\u3057\u3044\u306e\u306f\u3053\u3053\u3067\u3001xtx_t \u3068 xt+1x_{t+1}\u3092\u6563\u5e03\u56f3\u306b\u3057\u3066\u3044\u304f\u3068\u3001\u306a\u306b\u3084\u3089\u30ab\u30c3\u30b3\u3044\u3044\u5f62(\u30d5\u30e9\u30af\u30bf\u30eb)\u304c\u3067\u3066\u304d\u307e\u3059\u3002\u3055\u304d\u307b\u3069\u306e\u30e9\u30f3\u30c0\u30e0\u306a\u5024\u3068\u6bd4\u3079\u3066\u3082\u9055\u3044\u306f\u660e\u3089\u304b\u3067\u3059\u306d\u3002\n\nrr\u3092\u8d77\u70b9\u306b\u3057\u3066\u3044\u308b\u3088\u3046\u3067\u3059\u3002\u3042\u30fc\u7f8e\u3057\u3044\u3002\n\n\n\u30ab\u30aa\u30b9\u529b\u5b66\u306e\u77ed\u671f\u4e88\u6e2c\n\u3055\u3066\u3055\u3066\u305d\u3093\u306a\u7f8e\u3057\u3044\u30ab\u30aa\u30b9\u3067\u3059\u304c\u3001\u30e9\u30f3\u30c0\u30e0\u306b\u898b\u3048\u3066\u3082\u6cd5\u5247\u306b\u3057\u305f\u304c\u3063\u3066\u3044\u308b\u306a\u3089\u7c21\u5358\u306b\u4e88\u6e2c\u3067\u304d\u305d\u3046\u3067\u3059\u3088\u306d\u3002\u3068\u3053\u308d\u304c\u3069\u3063\u3053\u3044\u3002\u30ab\u30aa\u30b9\u304c\u30ab\u30aa\u30b9\u305f\u308b\u6240\u4ee5\u306a\u306e\u3067\u3059\u304c\u3001\u521d\u671f\u5024\u3084\u30d1\u30e9\u30e1\u30fc\u30bf\u30fc\u304c\u307b\u3093\u306e\u50c5\u304b\u9055\u3046\u3060\u3051\u3067\u307e\u3063\u305f\u304f\u9055\u3046\u5024\u306b\u306a\u3063\u3066\u3057\u307e\u3046\u305f\u3081\u3001\u9023\u7d9a\u3057\u305f\u30c7\u30fc\u30bf\u306e\u4e88\u6e2c\u304c\u96e3\u3057\u3044\u306e\u3067\u3059\u3002\n\u9069\u5f53\u306b\u6bd4\u3079\u3066\u307f\u307e\u3057\u3087\u3046\u3002\n\ngenerator.py\n\ndef logistic(r, t_first, num_steps):\n  array = []                        \n  for i in range(num_steps):        \n    if \"t\" not in locals():         \n      t = t_first                   \n    else:                           \n      t = tt                        \n    tt = r*t*(1-t)                  \n\n    array.append(tt)                \n  return array                      \n\ninitial = 0.5\ndata1 = logistic(3.91, initial, 100)\ndata2 = logistic(3.9100000000001, initial, 100)\ndata3 = logistic(3.91, initial+0.0000001, 100)\n\n\n\n\u203b\u7dd1\u304cdata1\ndata1 vs data2\n\ndata1 vs data3\n\n\u63a8\u5b9a\u5024\u306e\u8aa4\u5dee\u304c1e-10%\u4ee5\u4e0b\u306e\u8d85\u8d85\u9ad8\u7cbe\u5ea6\u3060\u3063\u305f\u3068\u3057\u3066\u3082\u300160\u30c7\u30fc\u30bf\u5148\u3067\u306f\u3082\u3046\u4e88\u6e2c\u304c\u56f0\u96e3\u306b\u306a\u3063\u3066\u3057\u307e\u3044\u307e\u3059\u3002\n\u9006\u306b\u8a00\u3046\u306a\u3089\u3070rr\u3092\u63a2\u3059\u3088\u3046\u306a\u56de\u5e30\u3092\u884c\u3048\u3070\u3001\u77ed\u671f\u306e\u4e88\u6e2c\u306f\u3042\u308b\u7a0b\u5ea6\u3067\u304d\u308b\u3093\u3058\u3083\u306a\u304b\u308d\u3046\u304b\u3002\n\nlogistic_rnn.py\nimport os, sys\nimport numpy as np\nimport tensorflow as tf\n\nnum_steps = 1 # Number of inputs. logistic map only needs a current input\nbatch_size = 100\nepoch_size = 10000\ninitial = 0.5  # 0 <= x <= 1: to generate data\n\nL = 0.01 # learing rate\nPRE_STEPS = 30 # Number of predictions. how far do you want to predict?\nN_HIDDEN = 30 # Hidden nodes\n\n\n'''\ngenerate data\n'''\ndef logistic(r, t_first, num_steps):\n    array = []\n    for i in range(num_steps):\n        if \"t\" not in locals():\n            t = t_first\n        else:\n            t = tt\n        tt = r*t*(1-t)\n\n        array.append(tt)\n    return array\n\ndef logmap_iterator(raw_data, batch_size, num_steps, prediction_steps):\n    raw_data = np.array(raw_data)\n    data_len = len(raw_data)\n    batch_len = data_len // batch_size\n    data = np.zeros([batch_size, batch_len])\n    for i in range(batch_size):\n        data[i] = raw_data[batch_len * i:batch_len * (i + 1)]\n\n    epoch_size = (batch_len - 1) // num_steps\n    if epoch_size == 0:\n        raise ValueError(\"epoch_size == 0, decrease batch_size or num_steps\")\n    for i in range(epoch_size):\n        x = data[:, i*num_steps:(i+1)*num_steps]\n        y = data[:, (i+1)*num_steps:(i+1)*num_steps+(prediction_steps)]\n\n        yield(x, y)\n\nraw_data = logistic(3.91, initial, num_steps*batch_size*epoch_size)\n\n'''\nmini-RNN Model\n'''\nx = tf.placeholder(\"float\", [None, num_steps])\ny = tf.placeholder(\"float\", [None, PRE_STEPS])\n\nweights = {\n            'hidden': tf.get_variable(\"hidden\", shape=[1, N_HIDDEN], initializer=tf.truncated_normal_initializer(stddev=0.1)),\n            'out': tf.get_variable(\"out\", shape=[N_HIDDEN, 1],  initializer=tf.truncated_normal_initializer(stddev=0.1))\n}\nbiases = {\n            'hidden': tf.get_variable(\"b_hidden\", shape=[N_HIDDEN], initializer=tf.truncated_normal_initializer(stddev=0.1)),\n            'out': tf.get_variable(\"b_out\", shape=[1],  initializer=tf.truncated_normal_initializer(stddev=0.1))\n}\n\ndef simple_reg(x, _weights, _biases, K = 1.0):\n    with tf.variable_scope(\"weight\"):\n        h1 = tf.matmul(x, _weights['hidden']) + _biases['hidden'] \n        h1 = tf.nn.dropout(tf.nn.sigmoid(h1), K)\n        o1 = tf.matmul(h1, _weights['out']) + _biases['out']\n\n    with tf.variable_scope(\"weight\", reuse=True):\n        h2 = tf.matmul(o1, _weights['hidden']) + _biases['hidden'] \n        h2 = tf.nn.dropout(tf.nn.sigmoid(h2), K)\n        o2 = tf.matmul(h2, _weights['out']) + _biases['out'] \n\n    o = tf.concat(1, [o1, o2])\n\n    def more_step(predicted_value, o):\n        with tf.variable_scope(\"weight\", reuse=True):\n            h = tf.matmul(predicted_value, _weights['hidden']) + _biases['hidden'] \n            h = tf.nn.dropout(tf.nn.sigmoid(h), K)\n            o_v = tf.matmul(h, _weights['out']) + _biases['out'] \n        o = tf.concat(1, [o, o_v])\n        return o, o_v\n\n    for i in range(PRE_STEPS-2):\n        if \"o_v\" not in locals():\n            o, o_v = more_step(o2, o)\n        else:\n            print o_v\n            o, o_v = more_step(o_v, o)\n    return o, o1\n\no, o1 = simple_reg(x, weights, biases)\nz = tf.split(1, PRE_STEPS, y) \nz = z[0]\n\ncost = tf.reduce_sum(tf.square(o1 - z))\noptimizer = tf.train.AdamOptimizer(L).minimize(cost)\n\ninit = tf.initialize_all_variables()\n\nwith tf.Session() as sess:\n    saver = tf.train.Saver()\n    sess.run(init)\n    for step in range(10):\n        gen = logmap_iterator(raw_data, batch_size, num_steps, PRE_STEPS)\n        for i in range(epoch_size-batch_size):\n            s, a  = gen.next()\n            training = sess.run([optimizer, o, cost], {x:s, y:a})\n            if i % 100 == 0:\n                print \"i\", i, \"cost\", training[2]\n                print \"initial input\", s[0][:5]\n                print \"pred\", training[1][0][:5]\n                print \"answ\", a[0][:5]\n            if i % 2000 == 2000:\n                L = L/2\n    save_path = saver.save(sess, \"dynamic_model.ckpt\")\n\n\n\n\u30e2\u30c7\u30eb\u306e\u5f62\u3068\u3057\u3066\u306f\u3053\u3093\u306a\u611f\u3058\u3067\u3059\u304b\u306d\u3002\u3000\u4e45\u3057\u3076\u308a\u306b\u30a4\u30e9\u30b9\u30c8\u30ec\u30fc\u30bf\u30fc\u89e6\u3063\u305f...\n\n\u96a0\u308c\u5c64\u306e\u6570\u306f\u9069\u5f53\u3067\u3001sigmoidsigmoid\u3092\u4f7f\u3063\u3066\u3044\u308b\u7406\u7531\u306f\u5358\u7d14\u306b\u51fa\u529b\u304cbetween 0 and 1\u3067\u53ce\u307e\u308b\u304b\u3089\u3067\u3059\u3002\n\u5165\u529b\u306f\uff11\u3064\u3060\u3051\u306e\u6570\u5024\u306b\u306a\u3063\u3066\u3044\u307e\u3059\u304c\u3001\u3053\u308c\u306fxt+1x_{t+1}\u3092\u6c42\u3081\u308b\u305f\u3081\u306bxtx_t\u4ee5\u5916\u610f\u5473\u3092\u306a\u3055\u306a\u3044\u305f\u3081\u3067\u3059\u3002\u305d\u306e\u305f\u3081\u30cd\u30c3\u30c8\u30ef\u30fc\u30af\u5185\u90e8\u306e\u72b6\u614b\u5024\u306e\u5171\u6709\u3068\u304b\u306f\u3042\u308a\u307e\u305b\u3093\u3002\n(\u672c\u5f53\u306f\u5165\u529b\u3092\u5897\u3084\u3059\u3068loss\u304c\u3046\u307e\u304f\u6e1b\u5c11\u3057\u306a\u304b\u3063\u305f\u306e\u306f\u5185\u7dd2)\n\u3053\u308c\u3092\u6b63\u5f0f\u306bRNN\u3068\u306f\u547c\u3079\u306a\u3044\u306e\u3067\u3057\u3087\u3046\u304c\u3001\u307e\u3041\u4e00\u5fdcFeedloop\u306a\u306e\u3067\u3002\n(\u672c\u5f53\u306f\u9023\u7d9a\u3057\u305f\u2208xn\\in x_n\u304b\u3089 rr \u3092\u63a8\u5b9a\u3057\u3066 xn+1x_{n+1}\u3092\u51fa\u529b\u3001\u305d\u306e xn+1x_{n+1} \u3092\u307e\u305f\u5165\u529b\u306b\u52a0\u3048\u3066xn+...x_{n+...} \u3068\u3057\u305f\u307b\u3046\u304c\u7cbe\u5ea6\u3082\u3042\u304c\u308b\u3093\u3058\u3083\u306a\u3044\u304b\u306a\u3068\u3082\u601d\u3046\u3051\u3069\u3001Tensorflow\u306eRNNCell\u304c\u30a4\u30de\u30a4\u30c1\u3046\u307e\u304f\u4f7f\u3048\u306a\u304b\u3063\u305f\u3002)\n\u3068\u308a\u3042\u3048\u305a\u500b\u4eba\u7684\u306b\u306f\u6e80\u8db3\u3059\u308b\u7d50\u679c\u304c\u51fa\u307e\u3057\u305f\u3002\n\u5b66\u7fd2\u521d\u671f\u306e\u69d8\u5b50\n\n\n\u6700\u7d42\u7684\u306b\u306floss\u304c\u5927\u4f531e-5\u3042\u305f\u308a\u306b\u843d\u3061\u7740\u3044\u3066\u3001\u30d9\u30b9\u30c8\u306a\u4e88\u6e2c\u3067\u3053\u3093\u306a\u611f\u3058\u306b\u306a\u308a\u307e\u3059\u3002\n\n\u203b\u4e00\u5ea6\u30a2\u30c3\u30d7\u3057\u305f\u8a18\u4e8b\u306a\u3093\u3067\u3059\u304c\u3001\u9ad8\u7cbe\u5ea6\u306a\u30e2\u30c7\u30eb\u3092\u6a21\u7d22\u3057\u3066\u308b\u9593\u3060\u3051\u975e\u516c\u958b\u306b\u3057\u3066\u307e\u3057\u305f\u3002\n\u9ad8\u7cbe\u5ea6\u306a\u30e2\u30c7\u30eb\u306f\u30a4\u30de\u30a4\u30c1\u767a\u898b\u3067\u304d\u306a\u304b\u3063\u305f\u306e\u3067\u3001\u5358\u7d14\u306bloss\u30921e-6\u304f\u3089\u3044\u307e\u3067\u4e0b\u3052\u7d9a\u3051\u305f\u7d50\u679c\u306f35\u30b9\u30c6\u30c3\u30d7\u5148\u307e\u3067\u3042\u3089\u304b\u305f\u4e88\u6e2c\u3067\u304d\u308b\uff08\u3068\u3044\u3046\u304brr\u304c\u3067\u304d\u308b\u3060\u3051\u8fd1\u4f3c\u3057\u305f\uff09\u72b6\u614b\u306b\u306a\u308a\u307e\u3057\u305f\u3002\n\n\n\u3053\u308c\u304c\u30ed\u30fc\u30ec\u30f3\u30c4\u306a\u3069\u4ed6\u306e\u30ab\u30aa\u30b9\u7cfb\u65b9\u7a0b\u5f0f\u306b\u4f7f\u3048\u308b\u304b\u306f\u307e\u3060\u8a66\u3057\u3066\u306a\u3044\u306e\u3067\u308f\u304b\u308a\u307e\u305b\u3093\u3002\n\n#Recurrent Neural Network (\u30ea\u30ab\u30ec\u30f3\u30c8\u30cb\u30e5\u30fc\u30e9\u30eb\u30cd\u30c3\u30c8\u30ef\u30fc\u30af)\n\u6642\u7cfb\u5217\u30c7\u30fc\u30bf\u306a\u3069\u9023\u7d9a\u5024\u3067\u76f8\u95a2\u304c\u3042\u308a\u305d\u3046\u306a\u3082\u306e\u306b\u5bfe\u3057\u3066\u3001\u5165\u529b\u3092\u4e00\u3064\u3065\u3064\u51e6\u7406\u3057\u3064\u3064\u30cd\u30c3\u30c8\u30ef\u30fc\u30af\u5185\u90e8\u3067\u72b6\u614b\u5024\u3092\u4fdd\u6301\u3057\u3066\u3001\u5165\u529b\u304c\u5168\u3066\u7d42\u308f\u3063\u305f\u5f8c\u306b\u6700\u7d42\u7684\u306a\u51fa\u529b\u3092\u3057\u3066\u304f\u308c\u308bRNN\u3055\u3093\u3002\n\n\u5b9f\u4e16\u754c\u306e\u6642\u7cfb\u5217\u30c7\u30fc\u30bf\u3060\u3068\u30ce\u30a4\u30ba\u304c\u5165\u308a\u3059\u304e\u308b\u3057\u3001Tensorflow\u306e\u30c1\u30e5\u30fc\u30c8\u30ea\u30a2\u30eb\u306e\u3088\u3046\u306a\u8a00\u8a9e\u7cfb\u3060\u3068\u30a4\u30de\u30a4\u30c1\"\u6642\u7cfb\u5217\"\u3068\u3057\u3066\u306e\u30a4\u30e1\u30fc\u30b8\u304c\u96e3\u3057\u3044\u3002\n\u305d\u3057\u3066\u30a4\u30de\u30a4\u30c1`RNNCell`\u30af\u30e9\u30b9\u306e\u4ed5\u69d8\u304c\u3064\u304b\u3081\u306a\u3044\u306e\u3067\u3001\u8ae6\u3081\u3066\u5b9f\u9a13\u7684\u306b\u7c21\u5358\u306a\u81ea\u5df1\u30d5\u30a3\u30fc\u30c9\u30d0\u30c3\u30af\u306e\u30e2\u30c7\u30eb\u3092\u4f5c\u3063\u3066\u307f\u307e\u3059\u3002\n\n\n#\u691c\u8a3c\u5bfe\u8c61 : \u30ab\u30aa\u30b9\u529b\u5b66\n\u30d0\u30bf\u30d5\u30e9\u30a4\u30a8\u30d5\u30a7\u30af\u30c8\u3067\u6709\u540d\u306a\u30ab\u30aa\u30b9\u3067\u3059\u304c\u3001\u4e00\u898b\u30e9\u30f3\u30c0\u30e0\u306b\u898b\u3048\u308b\u3093\u3060\u3051\u3069\u5b9f\u306f\u3042\u308b\u6cd5\u5247\u307f\u305f\u3044\u306a\u3082\u306e\u304c\u3042\u308b\u4e8b\u8c61\u3092\u5206\u6790\u3059\u308b\u4e0a\u3067\u5f79\u306b\u7acb\u3064\u3084\u3064\u3067\u3059\u3002\n\n\u305d\u306e\u4e2d\u3067\u3082\u500b\u4eba\u7684\u306b\u4e00\u756a\u5206\u304b\u308a\u3084\u3059\u3044 Logistic Map(\u30ed\u30b8\u30b9\u30c6\u30a3\u30c3\u30af\u5199\u50cf)\u3092\u4f8b\u306b\u304a\u8a71\u3092\u3057\u307e\u3059\u3002\n\n##\u96e2\u6563\u578b\u30ed\u30b8\u30b9\u30c6\u30a3\u30c3\u30af\u65b9\u7a0b\u5f0f\n\u3042\u308b\u6642\u70b9 $t$ \u306b\u304a\u3051\u308b $x(t)$ \u306e\u5024\u304c\u3001\u4e00\u3064\u524d\u306e\u6642\u70b9 $x(t-1)$ \u306e\u5024\u3068\u56fa\u6709\u306e\u30d1\u30e9\u30e1\u30fc\u30bf $r$ \u304b\u3089\u5c0e\u304d\u51fa\u305b\u308b\u4e0b\u8a18\u306e\u8d85\u7c21\u5358\u306a\u5f0f\u304c\u3042\u308a\u307e\u3059\u3002\n\n```math \nx_t = rx_{t-1}(1-x_{t-1})\n\n```\n\u3082\u3057\u304f\u306f\u4e00\u3064\u5148\u306e\u6642\u70b9\u3092\u4e88\u6e2c\u3057\u305f\u3044\u306e\u3067\u3042\u308c\u3070\u3001\u3053\u3046\u306a\u308a\u307e\u3059\u3002\n\n```math \nx_{t+1} = rx_t(1-x_t)\n```\n$x$\u306f`0 \u2264 x \u2264 1` $r$\u306f`0 \u2264 r \u2264 4`\n\n\u3053\u308c\u306e\u3069\u3053\u304b\u30ab\u30aa\u30b9\u306a\u306e\u304b\u3068\u3044\u3046\u3068\u3001\u3053\u306e\u6570\u5f0f\u306f $r$ \u304c `3.6`\u3042\u305f\u308a\u304b\u3089$x$\u306e\u3068\u308a\u3048\u308b\u5024\u304c\u83ab\u5927\u306b\u5897\u3048\u307e\u3059\u3002\n<img width=\"300\" src=\"https://upload.wikimedia.org/wikipedia/commons/7/7d/LogisticMap_BifurcationDiagram.png\" />\n\n$x$\u3092\u6642\u7cfb\u5217\u30c7\u30fc\u30bf\u3068\u3057\u3066\u307f\u308b\u3068\u3001\u898b\u4e8b\u306a\u4e71\u6570\u306b\u306a\u3063\u3066\u307e\u3059\u3002\n<img src=\"https://upload.wikimedia.org/wikipedia/commons/1/1f/Logistic_map_animation.gif\" />\n\u5b8c\u5168\u306b\u30e9\u30f3\u30c0\u30e0\u306a\u5024\u3068\u6642\u7cfb\u5217\u3067\u6bd4\u3079\u308b\u3068\u4f55\u3082\u8a00\u308f\u308c\u306a\u3051\u308c\u3070\u9055\u3044\u304c\u5206\u304b\u3089\u306a\u305d\u3046\u3067\u3059\u3002\n<img width=\"300\" src=\"http://i1.wp.com/geoffboeing.com/wp-content/uploads/2015/03/chaos-random-time-series.png\" />\n\n\u30ab\u30aa\u30b9\u304c\u7d20\u6674\u3089\u3057\u3044\u306e\u306f\u3053\u3053\u3067\u3001$x_t$ \u3068 $x_{t+1}$\u3092\u6563\u5e03\u56f3\u306b\u3057\u3066\u3044\u304f\u3068\u3001\u306a\u306b\u3084\u3089\u30ab\u30c3\u30b3\u3044\u3044\u5f62(\u30d5\u30e9\u30af\u30bf\u30eb)\u304c\u3067\u3066\u304d\u307e\u3059\u3002\u3055\u304d\u307b\u3069\u306e\u30e9\u30f3\u30c0\u30e0\u306a\u5024\u3068\u6bd4\u3079\u3066\u3082\u9055\u3044\u306f\u660e\u3089\u304b\u3067\u3059\u306d\u3002\n<img src=\"http://i1.wp.com/geoffboeing.com/wp-content/uploads/2015/03/poincare-plots-chaos-vs-random.png\">\n$r$\u3092\u8d77\u70b9\u306b\u3057\u3066\u3044\u308b\u3088\u3046\u3067\u3059\u3002\u3042\u30fc\u7f8e\u3057\u3044\u3002\n<img src=\"http://i2.wp.com/geoffboeing.com/wp-content/uploads/2015/03/poincare-plots-logistic-chaos1.png?\" />\n\n#\u30ab\u30aa\u30b9\u529b\u5b66\u306e\u77ed\u671f\u4e88\u6e2c\n\u3055\u3066\u3055\u3066\u305d\u3093\u306a\u7f8e\u3057\u3044\u30ab\u30aa\u30b9\u3067\u3059\u304c\u3001\u30e9\u30f3\u30c0\u30e0\u306b\u898b\u3048\u3066\u3082\u6cd5\u5247\u306b\u3057\u305f\u304c\u3063\u3066\u3044\u308b\u306a\u3089\u7c21\u5358\u306b\u4e88\u6e2c\u3067\u304d\u305d\u3046\u3067\u3059\u3088\u306d\u3002\u3068\u3053\u308d\u304c\u3069\u3063\u3053\u3044\u3002\u30ab\u30aa\u30b9\u304c\u30ab\u30aa\u30b9\u305f\u308b\u6240\u4ee5\u306a\u306e\u3067\u3059\u304c\u3001\u521d\u671f\u5024\u3084\u30d1\u30e9\u30e1\u30fc\u30bf\u30fc\u304c\u307b\u3093\u306e\u50c5\u304b\u9055\u3046\u3060\u3051\u3067\u307e\u3063\u305f\u304f\u9055\u3046\u5024\u306b\u306a\u3063\u3066\u3057\u307e\u3046\u305f\u3081\u3001\u9023\u7d9a\u3057\u305f\u30c7\u30fc\u30bf\u306e\u4e88\u6e2c\u304c\u96e3\u3057\u3044\u306e\u3067\u3059\u3002\n\n\u9069\u5f53\u306b\u6bd4\u3079\u3066\u307f\u307e\u3057\u3087\u3046\u3002\n\n```generator.py\n           \ndef logistic(r, t_first, num_steps):\n  array = []                        \n  for i in range(num_steps):        \n    if \"t\" not in locals():         \n      t = t_first                   \n    else:                           \n      t = tt                        \n    tt = r*t*(1-t)                  \n                                    \n    array.append(tt)                \n  return array                      \n\ninitial = 0.5\ndata1 = logistic(3.91, initial, 100)\ndata2 = logistic(3.9100000000001, initial, 100)\ndata3 = logistic(3.91, initial+0.0000001, 100)\n\n```\n\u203b\u7dd1\u304cdata1\ndata1 vs data2\n![1.png](https://qiita-image-store.s3.amazonaws.com/0/63543/7755497f-3420-7c24-332e-930c40cbe602.png)\ndata1 vs data3\n![2.png](https://qiita-image-store.s3.amazonaws.com/0/63543/adbcf03b-36c1-919b-d9d1-7fed333b3450.png)\n\n\n\u63a8\u5b9a\u5024\u306e\u8aa4\u5dee\u304c1e-10%\u4ee5\u4e0b\u306e\u8d85\u8d85\u9ad8\u7cbe\u5ea6\u3060\u3063\u305f\u3068\u3057\u3066\u3082\u300160\u30c7\u30fc\u30bf\u5148\u3067\u306f\u3082\u3046\u4e88\u6e2c\u304c\u56f0\u96e3\u306b\u306a\u3063\u3066\u3057\u307e\u3044\u307e\u3059\u3002\n\n**\u9006\u306b\u8a00\u3046\u306a\u3089\u3070$r$\u3092\u63a2\u3059\u3088\u3046\u306a\u56de\u5e30\u3092\u884c\u3048\u3070\u3001\u77ed\u671f\u306e\u4e88\u6e2c\u306f\u3042\u308b\u7a0b\u5ea6\u3067\u304d\u308b\u3093\u3058\u3083\u306a\u304b\u308d\u3046\u304b\u3002**\n\n```logistic_rnn.py\nimport os, sys\nimport numpy as np\nimport tensorflow as tf\n\nnum_steps = 1 # Number of inputs. logistic map only needs a current input\nbatch_size = 100\nepoch_size = 10000\ninitial = 0.5  # 0 <= x <= 1: to generate data\n\nL = 0.01 # learing rate\nPRE_STEPS = 30 # Number of predictions. how far do you want to predict?\nN_HIDDEN = 30 # Hidden nodes\n\n\n'''\ngenerate data\n'''\ndef logistic(r, t_first, num_steps):\n\tarray = []\n\tfor i in range(num_steps):\n\t\tif \"t\" not in locals():\n\t\t\tt = t_first\n\t\telse:\n\t\t\tt = tt\n\t\ttt = r*t*(1-t)\n\t\t\n\t\tarray.append(tt)\n\treturn array\n\ndef logmap_iterator(raw_data, batch_size, num_steps, prediction_steps):\n\traw_data = np.array(raw_data)\n\tdata_len = len(raw_data)\n\tbatch_len = data_len // batch_size\n\tdata = np.zeros([batch_size, batch_len])\n\tfor i in range(batch_size):\n\t\tdata[i] = raw_data[batch_len * i:batch_len * (i + 1)]\n\n\tepoch_size = (batch_len - 1) // num_steps\n\tif epoch_size == 0:\n\t\traise ValueError(\"epoch_size == 0, decrease batch_size or num_steps\")\n\tfor i in range(epoch_size):\n\t\tx = data[:, i*num_steps:(i+1)*num_steps]\n\t\ty = data[:, (i+1)*num_steps:(i+1)*num_steps+(prediction_steps)]\n\n\t\tyield(x, y)\n\nraw_data = logistic(3.91, initial, num_steps*batch_size*epoch_size)\n\n'''\nmini-RNN Model\n'''\nx = tf.placeholder(\"float\", [None, num_steps])\ny = tf.placeholder(\"float\", [None, PRE_STEPS])\n\nweights = {\n  \t        'hidden': tf.get_variable(\"hidden\", shape=[1, N_HIDDEN], initializer=tf.truncated_normal_initializer(stddev=0.1)),\n\t        'out': tf.get_variable(\"out\", shape=[N_HIDDEN, 1],  initializer=tf.truncated_normal_initializer(stddev=0.1))\n}\nbiases = {\n  \t        'hidden': tf.get_variable(\"b_hidden\", shape=[N_HIDDEN], initializer=tf.truncated_normal_initializer(stddev=0.1)),\n  \t        'out': tf.get_variable(\"b_out\", shape=[1],  initializer=tf.truncated_normal_initializer(stddev=0.1))\n}\n\t\ndef simple_reg(x, _weights, _biases, K = 1.0):\n\twith tf.variable_scope(\"weight\"):\n\t\th1 = tf.matmul(x, _weights['hidden']) + _biases['hidden'] \n\t\th1 = tf.nn.dropout(tf.nn.sigmoid(h1), K)\n\t\to1 = tf.matmul(h1, _weights['out']) + _biases['out']\n\n\twith tf.variable_scope(\"weight\", reuse=True):\n\t\th2 = tf.matmul(o1, _weights['hidden']) + _biases['hidden'] \n\t\th2 = tf.nn.dropout(tf.nn.sigmoid(h2), K)\n\t\to2 = tf.matmul(h2, _weights['out']) + _biases['out'] \n\n\to = tf.concat(1, [o1, o2])\n\n\tdef more_step(predicted_value, o):\n\t\twith tf.variable_scope(\"weight\", reuse=True):\n\t\t\th = tf.matmul(predicted_value, _weights['hidden']) + _biases['hidden'] \n\t\t\th = tf.nn.dropout(tf.nn.sigmoid(h), K)\n\t\t\to_v = tf.matmul(h, _weights['out']) + _biases['out'] \n\t\to = tf.concat(1, [o, o_v])\n\t\treturn o, o_v\n\t\n\tfor i in range(PRE_STEPS-2):\n\t\tif \"o_v\" not in locals():\n\t\t\to, o_v = more_step(o2, o)\n\t\telse:\n\t\t\tprint o_v\n\t\t\to, o_v = more_step(o_v, o)\n\treturn o, o1\n\no, o1 = simple_reg(x, weights, biases)\nz = tf.split(1, PRE_STEPS, y) \nz = z[0]\n\ncost = tf.reduce_sum(tf.square(o1 - z))\noptimizer = tf.train.AdamOptimizer(L).minimize(cost)\n\ninit = tf.initialize_all_variables()\n\nwith tf.Session() as sess:\n\tsaver = tf.train.Saver()\n\tsess.run(init)\n\tfor step in range(10):\n\t\tgen = logmap_iterator(raw_data, batch_size, num_steps, PRE_STEPS)\n\t\tfor i in range(epoch_size-batch_size):\n\t\t\ts, a  = gen.next()\n\t\t\ttraining = sess.run([optimizer, o, cost], {x:s, y:a})\n\t\t\tif i % 100 == 0:\n\t\t\t\tprint \"i\", i, \"cost\", training[2]\n\t\t\t\tprint \"initial input\", s[0][:5]\n\t\t\t\tprint \"pred\", training[1][0][:5]\n\t\t\t\tprint \"answ\", a[0][:5]\n\t\t\tif i % 2000 == 2000:\n\t\t\t\tL = L/2\n    save_path = saver.save(sess, \"dynamic_model.ckpt\")\n\n```\n\n\u30e2\u30c7\u30eb\u306e\u5f62\u3068\u3057\u3066\u306f\u3053\u3093\u306a\u611f\u3058\u3067\u3059\u304b\u306d\u3002\u3000\u4e45\u3057\u3076\u308a\u306b\u30a4\u30e9\u30b9\u30c8\u30ec\u30fc\u30bf\u30fc\u89e6\u3063\u305f...\n<img width=\"600\" src=\"https://qiita-image-store.s3.amazonaws.com/0/63543/31e878bf-3cce-2473-f746-f96ad5d9e4ab.png\" />\n\n\u96a0\u308c\u5c64\u306e\u6570\u306f\u9069\u5f53\u3067\u3001$sigmoid$\u3092\u4f7f\u3063\u3066\u3044\u308b\u7406\u7531\u306f\u5358\u7d14\u306b\u51fa\u529b\u304c`between 0 and 1`\u3067\u53ce\u307e\u308b\u304b\u3089\u3067\u3059\u3002\n\u5165\u529b\u306f\uff11\u3064\u3060\u3051\u306e\u6570\u5024\u306b\u306a\u3063\u3066\u3044\u307e\u3059\u304c\u3001\u3053\u308c\u306f$x_{t+1}$\u3092\u6c42\u3081\u308b\u305f\u3081\u306b$x_t$\u4ee5\u5916\u610f\u5473\u3092\u306a\u3055\u306a\u3044\u305f\u3081\u3067\u3059\u3002\u305d\u306e\u305f\u3081\u30cd\u30c3\u30c8\u30ef\u30fc\u30af\u5185\u90e8\u306e\u72b6\u614b\u5024\u306e\u5171\u6709\u3068\u304b\u306f\u3042\u308a\u307e\u305b\u3093\u3002\n(\u672c\u5f53\u306f\u5165\u529b\u3092\u5897\u3084\u3059\u3068loss\u304c\u3046\u307e\u304f\u6e1b\u5c11\u3057\u306a\u304b\u3063\u305f\u306e\u306f\u5185\u7dd2)\n\u3053\u308c\u3092\u6b63\u5f0f\u306bRNN\u3068\u306f\u547c\u3079\u306a\u3044\u306e\u3067\u3057\u3087\u3046\u304c\u3001\u307e\u3041\u4e00\u5fdcFeedloop\u306a\u306e\u3067\u3002\n\n(\u672c\u5f53\u306f\u9023\u7d9a\u3057\u305f$\\in x_n$\u304b\u3089 $r$ \u3092\u63a8\u5b9a\u3057\u3066 $x_{n+1}$\u3092\u51fa\u529b\u3001\u305d\u306e $x_{n+1}$ \u3092\u307e\u305f\u5165\u529b\u306b\u52a0\u3048\u3066$x_{n+...}$ \u3068\u3057\u305f\u307b\u3046\u304c\u7cbe\u5ea6\u3082\u3042\u304c\u308b\u3093\u3058\u3083\u306a\u3044\u304b\u306a\u3068\u3082\u601d\u3046\u3051\u3069\u3001Tensorflow\u306e`RNNCell`\u304c\u30a4\u30de\u30a4\u30c1\u3046\u307e\u304f\u4f7f\u3048\u306a\u304b\u3063\u305f\u3002)\n\n\n\u3068\u308a\u3042\u3048\u305a\u500b\u4eba\u7684\u306b\u306f\u6e80\u8db3\u3059\u308b\u7d50\u679c\u304c\u51fa\u307e\u3057\u305f\u3002\n\n\u5b66\u7fd2\u521d\u671f\u306e\u69d8\u5b50\n![scatter.gif](https://qiita-image-store.s3.amazonaws.com/0/63543/c9f8dfeb-87f5-445a-59ac-260784844906.gif)\n\n![line.gif](https://qiita-image-store.s3.amazonaws.com/0/63543/063c61c5-ffc2-4b10-c3e6-0234fa13fc4c.gif)\n\n\n\u6700\u7d42\u7684\u306b\u306floss\u304c\u5927\u4f53`1e-5`\u3042\u305f\u308a\u306b\u843d\u3061\u7740\u3044\u3066\u3001\u30d9\u30b9\u30c8\u306a\u4e88\u6e2c\u3067\u3053\u3093\u306a\u611f\u3058\u306b\u306a\u308a\u307e\u3059\u3002\n![424700.png](https://qiita-image-store.s3.amazonaws.com/0/63543/371382ac-b5df-d462-1e6f-7105cf5f843a.png)\n\n\n\u203b\u4e00\u5ea6\u30a2\u30c3\u30d7\u3057\u305f\u8a18\u4e8b\u306a\u3093\u3067\u3059\u304c\u3001\u9ad8\u7cbe\u5ea6\u306a\u30e2\u30c7\u30eb\u3092\u6a21\u7d22\u3057\u3066\u308b\u9593\u3060\u3051\u975e\u516c\u958b\u306b\u3057\u3066\u307e\u3057\u305f\u3002\n\u9ad8\u7cbe\u5ea6\u306a\u30e2\u30c7\u30eb\u306f\u30a4\u30de\u30a4\u30c1\u767a\u898b\u3067\u304d\u306a\u304b\u3063\u305f\u306e\u3067\u3001\u5358\u7d14\u306bloss\u3092`1e-6`\u304f\u3089\u3044\u307e\u3067\u4e0b\u3052\u7d9a\u3051\u305f\u7d50\u679c\u306f35\u30b9\u30c6\u30c3\u30d7\u5148\u307e\u3067\u3042\u3089\u304b\u305f\u4e88\u6e2c\u3067\u304d\u308b\uff08\u3068\u3044\u3046\u304b$r$\u304c\u3067\u304d\u308b\u3060\u3051\u8fd1\u4f3c\u3057\u305f\uff09\u72b6\u614b\u306b\u306a\u308a\u307e\u3057\u305f\u3002\n\n![42300.png](https://qiita-image-store.s3.amazonaws.com/0/63543/f7f941ef-01f8-3b89-c2a1-a88246f0a1ad.png)\n![8300.png](https://qiita-image-store.s3.amazonaws.com/0/63543/cb16dbeb-dba9-4590-7dc7-a790017652cb.png)\n\n\u3053\u308c\u304c\u30ed\u30fc\u30ec\u30f3\u30c4\u306a\u3069\u4ed6\u306e\u30ab\u30aa\u30b9\u7cfb\u65b9\u7a0b\u5f0f\u306b\u4f7f\u3048\u308b\u304b\u306f\u307e\u3060\u8a66\u3057\u3066\u306a\u3044\u306e\u3067\u308f\u304b\u308a\u307e\u305b\u3093\u3002\n", "tags": ["TensorFlow", "Python", "DeepLearning", "\u6a5f\u68b0\u5b66\u7fd2", "\u6642\u7cfb\u5217\u89e3\u6790"]}