{"context": " More than 1 year has passed since last update.In this post, I would like to introduce my implementation of \"object co-localization\" proposed in \n\"Co-localization in Real World Images\" [Tang+, CVPR2014].\nIn particular, I used this co-localization for face recognition. The method aims to find specific people who commonly appear in an image set. Object proposals are generated via face detection. Prior is calculated as the probability of skin pixels.\nThis implementation requires IBM CPlex to solve a binary quadratic programming problem. As suggested in the original paper, you could rely on a continuous QP instead by modifying __disc_clustering function.\n\ncolocalize.py\n'''\nObject co-localization for face recognition\nJan 30, 2015\n@jellied_unagi\n'''\n\nfrom pycpx import CPlexModel\nimport cv2\nfrom skimage.io import ImageCollection\nfrom skimage.feature import local_binary_pattern\nfrom skimage.color import rgb2gray\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.cluster import AffinityPropagation\nimport numpy as np\nimport matplotlib.pyplot as plt\n\n\nclass colocalize():\n\n    '''\n    This class implements \"Co-localization in Real World Images\" [Tang+, CVPR2014] for localizing people\n    who commonly appear in an image set. \n    - Object proposals are generated via face detection.\n    - Prior is calculated as the probability of skin pixels.\n    - Optimization is done based on IBM CPLex withouth convex relaxation though the original implementation \n    relies on continuous QP instead of BQP.\n    '''\n\n    def __init__(self, fsize=100, mn=3, th=0.3, lbp_rad=8, lbp_max=66, method='default', kappa=1e-3, alpha=1e-3):\n\n        # Face detector for object proposals\n        self.detector = [cv2.CascadeClassifier(x) \n                         for x in ['haarcascade_frontalface_default.xml',\n                                   'haarcascade_frontalface_alt.xml',\n                                   'haarcascade_frontalface_alt2.xml', \n                                   'haarcascade_frontalface_alt_tree.xml', \n                                   'haarcascade_profileface.xml']]\n        self.fsize = fsize  # minimum face size\n        self.mn = mn   # minimum support for detecting faces (larger for more precise detection)\n        self.th = th  # threshold for non-maximum supporession\n\n        # Parameters for local binary pattern histograms\n        self.lbp_rad = lbp_rad\n        self.lbp_np = 8 * lbp_rad\n        self.lbp_max = lbp_max\n        self.method = method\n        self.ss = StandardScaler()\n\n        # Parameters for co-localization\n        self.kappa = kappa  # ridge parameter\n        self.alpha = alpha  # importance of prior\n\n        # Data holder\n        self.image_list = []\n        self.face_list = []\n        self.feat_list = []\n        self.prior_list = []\n        self.result_list = []\n\n    def register(self, image):\n\n        '''\n        Registering an image to the list\n        '''\n\n        print 'Registering image...',\n        im_gray = rgb2gray(image)\n        face = self.__detect_face(image, size=self.fsize, mn=self.mn, th=self.th)\n        if(len(face) == 0):\n            print 'Cound not find faces'\n            return 0\n\n        skin = self.__detect_skin(image)\n        lbp = local_binary_pattern(im_gray, self.lbp_np, self.lbp_rad, self.method)\n        feat = []\n        prior = []\n        for f in face:\n            feat.append(np.histogram(lbp[f[1]:f[3], f[0]:f[2]].ravel(), \n                                     self.lbp_max, normed=True)[0])\n            prior.append(np.mean(skin[f[1]:f[3], f[0]:f[2]].ravel() / 255.))\n\n        self.image_list.append(image)\n        self.face_list.append(face)\n        self.feat_list.append(np.vstack(feat))\n        self.prior_list.append(np.vstack(prior))\n\n        print 'done.'\n\n    def localize(self):\n\n\n        '''\n        Performing co-localization on the registered images\n        '''\n\n\n        # Scaling features\n        self.ss.fit(np.vstack(self.feat_list))\n        feat_list = [self.ss.transform(x.copy()) for x in self.feat_list]\n\n        print 'Solving BQP ...',\n        idx = self.__disc_clustering(feat_list, self.prior_list)\n        self.result_list = [x[y] for (x, y) in zip(self.face_list, idx)]\n        print 'done.'\n\n        self.show_results()\n\n    def show_results(self, is_all=True):\n\n        '''\n        Visualizing results\n        '''\n\n        plt.figure(figsize=(16, 16))\n        n_images = len(self.image_list)\n        for i in range(n_images):\n            if(is_all):\n                plt.subplot(np.sqrt(n_images) + 1, np.sqrt(n_images) + 1, i + 1)\n            else:\n                plt.show()\n                plt.figure(figsize=(16, 16))\n            img = self.image_list[i]\n            face = self.result_list[i]\n            plt.imshow(img)\n            for f in self.face_list[i]:\n                plt.plot([f[0], f[0], f[2], f[2], f[0]],\n                         [f[1], f[3], f[3], f[1], f[1]], 'b', lw=6)\n            plt.plot([face[0], face[0], face[2], face[2], face[0]],\n                     [face[1], face[3], face[3], face[1], face[1]], 'r', lw=6)\n\n            plt.axis('off')\n\n    def __detect_face(self, image, size=80, mn=1, th=0.3):\n\n        '''\n        Running the VJ face detector implemented in OpenCV\n        '''\n\n        face = [x.detectMultiScale(image, scaleFactor=1.1, minNeighbors=mn,\n                                     minSize=(size, size), flags=cv2.cv.CV_HAAR_SCALE_IMAGE) for x in self.detector]\n        if (np.sum([len(x) for x in face]) == 0):\n            if(size==0):\n                print 'Could not find faces'\n                return []\n            else:\n                size = np.max((size - 10, 10))\n                mn = np.max((mn - 1, 1))\n                print 'searching face...(size %d)' % size\n                return self.__detect_face(image, size=size, mn=mn, th=th)\n\n        face = np.vstack([x for x in face if len(x) > 0])\n        face[:, 2:] += face[:, :2]\n        face = self.__nms(face, th=th)\n\n        return face\n\n    def __nms(self, face, th=.3):\n\n        '''\n        non-maximum suppression of detected faces\n        '''\n\n        n_faces = len(face)\n        fzero = np.zeros((np.max(face[:, 3]), np.max(face[:, 2])))\n        fmat = []\n        fsum = []\n        for i in range(n_faces):\n            tmp = fzero.copy()\n            tmp[face[i, 1]:face[i, 3], face[i, 0]:face[i, 2]] = 1\n            fmat.append(tmp.ravel().astype('bool'))\n            fsum.append(np.sum(tmp))\n\n        rem = np.ones(n_faces)\n        for i in range(n_faces):\n            for j in range(n_faces):\n                if i != j:\n                    fand = np.sum(fmat[i] & fmat[j])\n                    if((fsum[i] < fsum[j]) & ((fand * 1. / fsum[i]) > th)):\n                        rem[i] = 0\n\n        return face[rem == 1, :]\n\n    def __disc_clustering(self, feat_list, prior_list):\n\n        '''\n        Performing discriminative clustering via BQP\n        '''\n\n        X = np.matrix(np.vstack(feat_list))\n        nb = X.shape[0] * 1.\n        I_nb = np.matrix(np.eye(X.shape[0]))\n        I1_nb = np.matrix(np.ones(X.shape[0])).T\n        I = np.matrix(np.eye(X.shape[1]))\n        cpmat = I_nb - I1_nb * I1_nb.T / nb\n        A = cpmat * (I_nb - X * np.linalg.inv(X.T * cpmat * X + nb * self.kappa * I) * X.T) * cpmat / nb\n        P = np.matrix(np.vstack(prior_list))\n        print np.max(A), np.max(P)\n\n        n_cand = np.array([len(x) for x in feat_list])\n        cand_idx = np.hstack((0, np.cumsum(n_cand)))\n        B = np.matrix(np.zeros((len(n_cand), A.shape[0])))\n        for i in range(len(cand_idx) - 1):\n            B[i, cand_idx[i]:cand_idx[i + 1]] = 1\n\n        m = CPlexModel()\n        U = m.new((A.shape[0]), vtype = bool)\n        b = np.ones(len(n_cand))\n        m.constrain(B * U == b)\n        m.minimize(U.T * A * U - self.alpha * P.T * U)\n        idx = np.argwhere(m[U]==1).flatten() - cand_idx[:-1]\n\n        return idx\n\n    def __detect_skin(self, image):\n\n        '''\n        Calculating prior\n        '''\n\n        lower = np.array([0, 48, 80], dtype = \"uint8\")\n        upper = np.array([20, 255, 255], dtype = \"uint8\")\n        hsv = cv2.cvtColor(image, cv2.cv.CV_RGB2HSV)\n        skinMask = cv2.inRange(hsv, lower, upper)\n\n        return skinMask\n\n\n\n\nIn this post, I would like to introduce my implementation of \"object co-localization\" proposed in \n[\"Co-localization in Real World Images\" [Tang+, CVPR2014]](http://ai.stanford.edu/~kdtang/papers/cvpr14-coloc.pdf).\nIn particular, I used this co-localization for face recognition. The method aims to find specific people who commonly appear in an image set. Object proposals are generated via face detection. Prior is calculated as the probability of skin pixels.\n\nThis implementation requires [IBM CPlex](http://www-01.ibm.com/software/commerce/optimization/cplex-optimizer/) to solve a binary quadratic programming problem. As suggested in the original paper, you could rely on a continuous QP instead by modifying ```__disc_clustering``` function.\n\n\n```py:colocalize.py\n'''\nObject co-localization for face recognition\nJan 30, 2015\n@jellied_unagi\n'''\n\nfrom pycpx import CPlexModel\nimport cv2\nfrom skimage.io import ImageCollection\nfrom skimage.feature import local_binary_pattern\nfrom skimage.color import rgb2gray\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.cluster import AffinityPropagation\nimport numpy as np\nimport matplotlib.pyplot as plt\n\n\nclass colocalize():\n    \n    '''\n    This class implements \"Co-localization in Real World Images\" [Tang+, CVPR2014] for localizing people\n    who commonly appear in an image set. \n    - Object proposals are generated via face detection.\n    - Prior is calculated as the probability of skin pixels.\n    - Optimization is done based on IBM CPLex withouth convex relaxation though the original implementation \n    relies on continuous QP instead of BQP.\n    '''\n    \n    def __init__(self, fsize=100, mn=3, th=0.3, lbp_rad=8, lbp_max=66, method='default', kappa=1e-3, alpha=1e-3):\n        \n        # Face detector for object proposals\n        self.detector = [cv2.CascadeClassifier(x) \n                         for x in ['haarcascade_frontalface_default.xml',\n                                   'haarcascade_frontalface_alt.xml',\n                                   'haarcascade_frontalface_alt2.xml', \n                                   'haarcascade_frontalface_alt_tree.xml', \n                                   'haarcascade_profileface.xml']]\n        self.fsize = fsize  # minimum face size\n        self.mn = mn   # minimum support for detecting faces (larger for more precise detection)\n        self.th = th  # threshold for non-maximum supporession\n        \n        # Parameters for local binary pattern histograms\n        self.lbp_rad = lbp_rad\n        self.lbp_np = 8 * lbp_rad\n        self.lbp_max = lbp_max\n        self.method = method\n        self.ss = StandardScaler()\n        \n        # Parameters for co-localization\n        self.kappa = kappa  # ridge parameter\n        self.alpha = alpha  # importance of prior\n        \n        # Data holder\n        self.image_list = []\n        self.face_list = []\n        self.feat_list = []\n        self.prior_list = []\n        self.result_list = []\n    \n    def register(self, image):\n        \n        '''\n        Registering an image to the list\n        '''\n        \n        print 'Registering image...',\n        im_gray = rgb2gray(image)\n        face = self.__detect_face(image, size=self.fsize, mn=self.mn, th=self.th)\n        if(len(face) == 0):\n            print 'Cound not find faces'\n            return 0\n        \n        skin = self.__detect_skin(image)\n        lbp = local_binary_pattern(im_gray, self.lbp_np, self.lbp_rad, self.method)\n        feat = []\n        prior = []\n        for f in face:\n            feat.append(np.histogram(lbp[f[1]:f[3], f[0]:f[2]].ravel(), \n                                     self.lbp_max, normed=True)[0])\n            prior.append(np.mean(skin[f[1]:f[3], f[0]:f[2]].ravel() / 255.))\n        \n        self.image_list.append(image)\n        self.face_list.append(face)\n        self.feat_list.append(np.vstack(feat))\n        self.prior_list.append(np.vstack(prior))\n        \n        print 'done.'\n        \n    def localize(self):\n        \n                \n        '''\n        Performing co-localization on the registered images\n        '''\n        \n        \n        # Scaling features\n        self.ss.fit(np.vstack(self.feat_list))\n        feat_list = [self.ss.transform(x.copy()) for x in self.feat_list]\n        \n        print 'Solving BQP ...',\n        idx = self.__disc_clustering(feat_list, self.prior_list)\n        self.result_list = [x[y] for (x, y) in zip(self.face_list, idx)]\n        print 'done.'\n        \n        self.show_results()\n    \n    def show_results(self, is_all=True):\n        \n        '''\n        Visualizing results\n        '''\n        \n        plt.figure(figsize=(16, 16))\n        n_images = len(self.image_list)\n        for i in range(n_images):\n            if(is_all):\n                plt.subplot(np.sqrt(n_images) + 1, np.sqrt(n_images) + 1, i + 1)\n            else:\n                plt.show()\n                plt.figure(figsize=(16, 16))\n            img = self.image_list[i]\n            face = self.result_list[i]\n            plt.imshow(img)\n            for f in self.face_list[i]:\n                plt.plot([f[0], f[0], f[2], f[2], f[0]],\n                         [f[1], f[3], f[3], f[1], f[1]], 'b', lw=6)\n            plt.plot([face[0], face[0], face[2], face[2], face[0]],\n                     [face[1], face[3], face[3], face[1], face[1]], 'r', lw=6)\n                \n            plt.axis('off')\n        \n    def __detect_face(self, image, size=80, mn=1, th=0.3):\n        \n        '''\n        Running the VJ face detector implemented in OpenCV\n        '''\n        \n        face = [x.detectMultiScale(image, scaleFactor=1.1, minNeighbors=mn,\n                                     minSize=(size, size), flags=cv2.cv.CV_HAAR_SCALE_IMAGE) for x in self.detector]\n        if (np.sum([len(x) for x in face]) == 0):\n            if(size==0):\n                print 'Could not find faces'\n                return []\n            else:\n                size = np.max((size - 10, 10))\n                mn = np.max((mn - 1, 1))\n                print 'searching face...(size %d)' % size\n                return self.__detect_face(image, size=size, mn=mn, th=th)\n        \n        face = np.vstack([x for x in face if len(x) > 0])\n        face[:, 2:] += face[:, :2]\n        face = self.__nms(face, th=th)\n        \n        return face\n    \n    def __nms(self, face, th=.3):\n        \n        '''\n        non-maximum suppression of detected faces\n        '''\n        \n        n_faces = len(face)\n        fzero = np.zeros((np.max(face[:, 3]), np.max(face[:, 2])))\n        fmat = []\n        fsum = []\n        for i in range(n_faces):\n            tmp = fzero.copy()\n            tmp[face[i, 1]:face[i, 3], face[i, 0]:face[i, 2]] = 1\n            fmat.append(tmp.ravel().astype('bool'))\n            fsum.append(np.sum(tmp))\n\n        rem = np.ones(n_faces)\n        for i in range(n_faces):\n            for j in range(n_faces):\n                if i != j:\n                    fand = np.sum(fmat[i] & fmat[j])\n                    if((fsum[i] < fsum[j]) & ((fand * 1. / fsum[i]) > th)):\n                        rem[i] = 0\n\n        return face[rem == 1, :]\n\n    def __disc_clustering(self, feat_list, prior_list):\n        \n        '''\n        Performing discriminative clustering via BQP\n        '''\n        \n        X = np.matrix(np.vstack(feat_list))\n        nb = X.shape[0] * 1.\n        I_nb = np.matrix(np.eye(X.shape[0]))\n        I1_nb = np.matrix(np.ones(X.shape[0])).T\n        I = np.matrix(np.eye(X.shape[1]))\n        cpmat = I_nb - I1_nb * I1_nb.T / nb\n        A = cpmat * (I_nb - X * np.linalg.inv(X.T * cpmat * X + nb * self.kappa * I) * X.T) * cpmat / nb\n        P = np.matrix(np.vstack(prior_list))\n        print np.max(A), np.max(P)\n        \n        n_cand = np.array([len(x) for x in feat_list])\n        cand_idx = np.hstack((0, np.cumsum(n_cand)))\n        B = np.matrix(np.zeros((len(n_cand), A.shape[0])))\n        for i in range(len(cand_idx) - 1):\n            B[i, cand_idx[i]:cand_idx[i + 1]] = 1\n            \n        m = CPlexModel()\n        U = m.new((A.shape[0]), vtype = bool)\n        b = np.ones(len(n_cand))\n        m.constrain(B * U == b)\n        m.minimize(U.T * A * U - self.alpha * P.T * U)\n        idx = np.argwhere(m[U]==1).flatten() - cand_idx[:-1]\n        \n        return idx\n    \n    def __detect_skin(self, image):\n        \n        '''\n        Calculating prior\n        '''\n        \n        lower = np.array([0, 48, 80], dtype = \"uint8\")\n        upper = np.array([20, 255, 255], dtype = \"uint8\")\n        hsv = cv2.cvtColor(image, cv2.cv.CV_RGB2HSV)\n        skinMask = cv2.inRange(hsv, lower, upper)\n        \n        return skinMask\n        \n```\n", "tags": ["Python", "OpenCV"]}