{"context": "\n\n\u539f\u6587\n\u5f37\u5316\u5b66\u7fd2\u306b\u304a\u3051\u308b\u81ea\u5df1\u7b26\u53f7\u5316\u5668\u4ed8\u304d\u6df1\u5c64\u30cb\u30e5\u30fc\u30e9\u30eb\u30cd\u30c3\u30c8\u30ef\u30fc\u30af(Deep Auto-Encoder Neural Networks in Reinforcement Learning)\nSascha Lange and Martin Riedmiller (2010)\n\n1. \u8981\u7d04\n\n(\u30e1\u30e2\u30ea\u57fa\u76e4\u306e)\u30d0\u30c3\u30c1\u5f37\u5316\u5b66\u7fd2(Reinforcement Learning; RL)\u30a2\u30eb\u30b4\u30ea\u30ba\u30e0\u3092\u8003\u6848\u3057\u305f\u3002\u3053\u308c\u306b\u3088\u308a\u3001\u81ea\u5df1\u7b26\u53f7\u5316\u5668\u3067DNN (Deep Neural Network)\u3092\u5b66\u7fd2\u3057\u3001\u7279\u5fb4\u7a7a\u9593\u3092\u5275\u51fa\u3059\u308b\u3053\u3068\u304c\u3067\u304d\u308b\u3002\n\u30e1\u30a4\u30f3\u306e\u6a5f\u68b0\u5b66\u7fd2\u30a2\u30eb\u30b4\u30ea\u30ba\u30e0\u306f\u3001MLP(Multi Layer Perceptions) \u3001\u3044\u308f\u3086\u308b\u591a\u5c64\u81ea\u5df1\u7b26\u53f7\u5316\u5668\u3092\u4f7f\u3046\u3002\n\n\n2. \u80cc\u666f\n\u5f37\u5316\u5b66\u7fd2\u306f\u3001\u6b21\u306e2\u30b9\u30c6\u30c3\u30d7\u304b\u3089\u306a\u308b\u3002\n\u2460\u5165\u529b\u30c7\u30fc\u30bf\u304b\u3089\u7279\u5fb4\u3092\u62bd\u51fa\u3059\u308b\n\u2461\u7279\u5fb4\u7a7a\u9593\u304b\u3089\u3001\u6559\u7fa9(Policy)\u3092\u5b66\u3073\u3001\u884c\u52d5\u306b\u843d\u3068\u3057\u3053\u3080\n\u3053\u308c\u307e\u3067\u3001\u2460\u306f\u4eba\u306e\u624b\u3067\u884c\u308f\u308c\u3066\u304d\u305f\u304c\u3001Deep Learning\u304c\u53d6\u3063\u3066\u4ee3\u308f\u308b\u3088\u3046\u306b\u671f\u5f85\u3055\u308c\u3066\u3044\u308b\u3002\n\n3. \u9aa8\u5b50\u306e\u7406\u8ad6\n\u5168\u4f53\u306e\u5206\u6790\u69cb\u56f3\u3092\u4ee5\u4e0b\u306b\u793a\u3059\u3002\n\u30dd\u30a4\u30f3\u30c8\u306f\u3001DL\u3067\u53d6\u5f97\u3057\u305f\u7279\u5fb4\u7a7a\u9593\u3092\u3001\u5f93\u6765\u306eRL\u306e\u5b66\u7fd2\u30a2\u30eb\u30b4\u30ea\u30ba\u30e0(Fitted Q-Iteration)\u306b\u7d44\u307f\u8fbc\u3080\u70b9\u3067\u3042\u308b\u3002\n\u5f37\u5316\u5b66\u7fd2\u306e\u57fa\u790e\u306f\u3001\u4ed6\u66f8\u306b\u8b72\u308b\u304c\u3001\u30a8\u30fc\u30b8\u30a7\u30f3\u30c8(\u5b66\u7fd2\u3059\u308b\u4e3b\u4f53)\u306f\u3001Q\u5024(\u95a2\u6570)\u3092\u8caa\u6b32\u6cd5(Greedy method)\u3068\u3044\u3046\u8a08\u7b97\u898f\u5247\u3067\u7b97\u51fa\u3057\u3001\u305d\u306e\u5024\u306b\u57fa\u3044\u3066\u3001\u884c\u52d5\u898f\u7bc4(Policy)\u3092\u6c7a\u5b9a\u3059\u308b\u3002\n\n\n\n3. \u30e2\u30c7\u30eb\u9069\u7528\u4f8b\n6*6=36\u30d4\u30af\u30bb\u30eb\u306e\u753b\u50cf\u3092\u7528\u610f\u3057\u3001\u30a2\u30eb\u30b4\u30ea\u30ba\u30e0\u306e\u3082\u3068\u3067\u4e8b\u524d\u5b66\u7fd2(\u7279\u5fb4\u62bd\u51fa)\u3002\n400\u30a8\u30dd\u30c3\u30af\u3067\u3001\u5206\u985e\u304c\u5b8c\u6210\u3057\u305f\u3002\n\n\u4e0a\u56f3\u306e\u5206\u985e\u306f\u3001\u81ea\u5df1\u7b26\u53f7\u5316\u5668\u306e\u6587\u8108\u3067\u884c\u308f\u308c\u3066\u3044\u308b\u3002\u5165\u529b\u30c7\u30fc\u30bf\u306e\u518d\u69cb\u6210\u6642\u306e\u5143\u30c7\u30fc\u30bf\u3068\u306e\u8aa4\u5dee\u306b\u3064\u3044\u3066\u3001\u305d\u306e\u4ed6\u306e\u624b\u6cd5\u3068\u6bd4\u8f03\u3057\u305f\u3002\n\n\u4e3b\u6210\u5206\u5206\u6790\u306b\u6bd4\u3079\u3066\u3001\u8aa4\u5dee\u304c\u62ee\u6297\u3057\u3066\u3044\u308b\u70b9\u3082\u3042\u308b\u3002\n\u3060\u304c\u3001\u30de\u30cb\u30e5\u30a2\u30eb\u306e\u7279\u5fb4\u62bd\u51fa\u304c\u53ef\u80fd\u306a\u70b9\u3067\u3001\u3053\u306e\u624b\u6cd5\u306e\u512a\u4f4d\u6027\u304c\u7acb\u3064\u3002\n\u6700\u5f8c\u306b\u3001\u5b66\u7fd2\u3055\u305b\u305f\u30d1\u30bf\u30fc\u30f3\u306b\u57fa\u3065\u304d\u3001\u30a8\u30fc\u30b8\u30a7\u30f3\u30c8\u306b\u884c\u52d5\u3055\u305b\u305f\u6642\u306e\u5831\u916c(Reward)\u95a2\u6570\u306e\u7d50\u679c\u3092\u793a\u3059(\u3053\u308c\u306f\u5f37\u5316\u5b66\u7fd2\u306e\u6587\u8108)\u3002\n300\u56de\u3042\u305f\u308a\u3067\u3001\u6975\u5927\u306b\u8fd1\u3065\u304d\u3001600\u30a8\u30d4\u30bd\u30fc\u30c9\u7d4c\u904e\u3057\u305f\u3068\u3053\u308d\u3067\u3001\u307b\u307c\u6700\u5927\u5831\u916c\u306b\u53ce\u675f\u3057\u305f\u3002\n\n## \u539f\u6587 \n[\u5f37\u5316\u5b66\u7fd2\u306b\u304a\u3051\u308b\u81ea\u5df1\u7b26\u53f7\u5316\u5668\u4ed8\u304d\u6df1\u5c64\u30cb\u30e5\u30fc\u30e9\u30eb\u30cd\u30c3\u30c8\u30ef\u30fc\u30af(Deep Auto-Encoder Neural Networks in Reinforcement Learning)](http://goo.gl/Ck4oSS)\nSascha Lange and Martin Riedmiller (2010)\n\n\n\n\n\n## 1. \u8981\u7d04\n* (\u30e1\u30e2\u30ea\u57fa\u76e4\u306e)\u30d0\u30c3\u30c1\u5f37\u5316\u5b66\u7fd2(Reinforcement Learning; RL)\u30a2\u30eb\u30b4\u30ea\u30ba\u30e0\u3092\u8003\u6848\u3057\u305f\u3002\u3053\u308c\u306b\u3088\u308a\u3001\u81ea\u5df1\u7b26\u53f7\u5316\u5668\u3067DNN (Deep Neural Network)\u3092\u5b66\u7fd2\u3057\u3001\u7279\u5fb4\u7a7a\u9593\u3092\u5275\u51fa\u3059\u308b\u3053\u3068\u304c\u3067\u304d\u308b\u3002\n* \u30e1\u30a4\u30f3\u306e\u6a5f\u68b0\u5b66\u7fd2\u30a2\u30eb\u30b4\u30ea\u30ba\u30e0\u306f\u3001MLP(Multi Layer Perceptions) \u3001\u3044\u308f\u3086\u308b\u591a\u5c64\u81ea\u5df1\u7b26\u53f7\u5316\u5668\u3092\u4f7f\u3046\u3002\n\n\n## 2. \u80cc\u666f\n\u5f37\u5316\u5b66\u7fd2\u306f\u3001\u6b21\u306e2\u30b9\u30c6\u30c3\u30d7\u304b\u3089\u306a\u308b\u3002\n\u2460\u5165\u529b\u30c7\u30fc\u30bf\u304b\u3089\u7279\u5fb4\u3092\u62bd\u51fa\u3059\u308b\n\u2461\u7279\u5fb4\u7a7a\u9593\u304b\u3089\u3001\u6559\u7fa9(Policy)\u3092\u5b66\u3073\u3001\u884c\u52d5\u306b\u843d\u3068\u3057\u3053\u3080\n\u3053\u308c\u307e\u3067\u3001\u2460\u306f\u4eba\u306e\u624b\u3067\u884c\u308f\u308c\u3066\u304d\u305f\u304c\u3001Deep Learning\u304c\u53d6\u3063\u3066\u4ee3\u308f\u308b\u3088\u3046\u306b\u671f\u5f85\u3055\u308c\u3066\u3044\u308b\u3002\n\n\n## 3. \u9aa8\u5b50\u306e\u7406\u8ad6\n\u5168\u4f53\u306e\u5206\u6790\u69cb\u56f3\u3092\u4ee5\u4e0b\u306b\u793a\u3059\u3002\n\u30dd\u30a4\u30f3\u30c8\u306f\u3001DL\u3067\u53d6\u5f97\u3057\u305f\u7279\u5fb4\u7a7a\u9593\u3092\u3001\u5f93\u6765\u306eRL\u306e\u5b66\u7fd2\u30a2\u30eb\u30b4\u30ea\u30ba\u30e0(Fitted Q-Iteration)\u306b\u7d44\u307f\u8fbc\u3080\u70b9\u3067\u3042\u308b\u3002\n\u5f37\u5316\u5b66\u7fd2\u306e\u57fa\u790e\u306f\u3001\u4ed6\u66f8\u306b\u8b72\u308b\u304c\u3001\u30a8\u30fc\u30b8\u30a7\u30f3\u30c8(\u5b66\u7fd2\u3059\u308b\u4e3b\u4f53)\u306f\u3001Q\u5024(\u95a2\u6570)\u3092\u8caa\u6b32\u6cd5(Greedy method)\u3068\u3044\u3046\u8a08\u7b97\u898f\u5247\u3067\u7b97\u51fa\u3057\u3001\u305d\u306e\u5024\u306b\u57fa\u3044\u3066\u3001\u884c\u52d5\u898f\u7bc4(Policy)\u3092\u6c7a\u5b9a\u3059\u308b\u3002\n\n![151125112601_1.JPG](https://qiita-image-store.s3.amazonaws.com/0/127228/4eb897f7-2621-f217-ac7d-356c84f40059.jpeg)\n\n\n![151125112601_2.JPG](https://qiita-image-store.s3.amazonaws.com/0/127228/32cd1285-6778-fa62-cf78-4c610dd3bbe3.jpeg)\n\n\n\n\n## 3. \u30e2\u30c7\u30eb\u9069\u7528\u4f8b\n6*6=36\u30d4\u30af\u30bb\u30eb\u306e\u753b\u50cf\u3092\u7528\u610f\u3057\u3001\u30a2\u30eb\u30b4\u30ea\u30ba\u30e0\u306e\u3082\u3068\u3067\u4e8b\u524d\u5b66\u7fd2(\u7279\u5fb4\u62bd\u51fa)\u3002\n400\u30a8\u30dd\u30c3\u30af\u3067\u3001\u5206\u985e\u304c\u5b8c\u6210\u3057\u305f\u3002\n\n![151125112601_3.JPG](https://qiita-image-store.s3.amazonaws.com/0/127228/e568190d-0b0c-3d99-a177-f5c2ac50ab7d.jpeg)\n\n\u4e0a\u56f3\u306e\u5206\u985e\u306f\u3001\u81ea\u5df1\u7b26\u53f7\u5316\u5668\u306e\u6587\u8108\u3067\u884c\u308f\u308c\u3066\u3044\u308b\u3002\u5165\u529b\u30c7\u30fc\u30bf\u306e\u518d\u69cb\u6210\u6642\u306e\u5143\u30c7\u30fc\u30bf\u3068\u306e\u8aa4\u5dee\u306b\u3064\u3044\u3066\u3001\u305d\u306e\u4ed6\u306e\u624b\u6cd5\u3068\u6bd4\u8f03\u3057\u305f\u3002\n\n![151125112601_4.JPG](https://qiita-image-store.s3.amazonaws.com/0/127228/84dc0902-b83d-4b32-1944-e2a3bdec5075.jpeg)\n\n\u4e3b\u6210\u5206\u5206\u6790\u306b\u6bd4\u3079\u3066\u3001\u8aa4\u5dee\u304c\u62ee\u6297\u3057\u3066\u3044\u308b\u70b9\u3082\u3042\u308b\u3002\n\u3060\u304c\u3001\u30de\u30cb\u30e5\u30a2\u30eb\u306e\u7279\u5fb4\u62bd\u51fa\u304c\u53ef\u80fd\u306a\u70b9\u3067\u3001\u3053\u306e\u624b\u6cd5\u306e\u512a\u4f4d\u6027\u304c\u7acb\u3064\u3002\n\u6700\u5f8c\u306b\u3001\u5b66\u7fd2\u3055\u305b\u305f\u30d1\u30bf\u30fc\u30f3\u306b\u57fa\u3065\u304d\u3001\u30a8\u30fc\u30b8\u30a7\u30f3\u30c8\u306b\u884c\u52d5\u3055\u305b\u305f\u6642\u306e\u5831\u916c(Reward)\u95a2\u6570\u306e\u7d50\u679c\u3092\u793a\u3059(\u3053\u308c\u306f\u5f37\u5316\u5b66\u7fd2\u306e\u6587\u8108)\u3002\n300\u56de\u3042\u305f\u308a\u3067\u3001\u6975\u5927\u306b\u8fd1\u3065\u304d\u3001600\u30a8\u30d4\u30bd\u30fc\u30c9\u7d4c\u904e\u3057\u305f\u3068\u3053\u308d\u3067\u3001\u307b\u307c\u6700\u5927\u5831\u916c\u306b\u53ce\u675f\u3057\u305f\u3002\n\n![151125112601_5.JPG](https://qiita-image-store.s3.amazonaws.com/0/127228/df149f56-fd2d-3f2f-bce0-4d68d0fbcdf2.jpeg)\n", "tags": ["\u5f37\u5316\u5b66\u7fd2", "\u30cb\u30e5\u30fc\u30e9\u30eb\u30cd\u30c3\u30c8\u30ef\u30fc\u30af", "\u6df1\u5c64\u5b66\u7fd2", "DeepLearning"]}