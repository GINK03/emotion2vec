{"context": " More than 1 year has passed since last update.\u305a\u3044\u3076\u3093\u4e0b\u66f8\u304d\u3067\u7720\u3063\u3066\u3044\u305f\u306e\u3067\u3001\u66f8\u3044\u3066\u3044\u308b\u9014\u4e2d\u3067\u3059\u304c\u516c\u958b\u3057\u307e\u3059\u3002\nChainer \u304c\u6d41\u884c\u3063\u3066\u3044\u307e\u3059\u306e\u3067\u3001\u305d\u308c\u4ee5\u5916\u306b\u3064\u3044\u3066\u307e\u3068\u3081\u307e\u3059\u3002\n\u500b\u4eba\u7684\u306b\u306f\u3001Python\u4f7f\u3044\u3067\u3042\u308c\u3070 Keras\u3001Java/Scala \u306a\u65b9\u306f DeepLearning4J \u304c\u4f7f\u3044\u3084\u3059\u3044\u3068\u601d\u3044\u307e\u3059\u3002\n\nKeras\nKeras \u306f Theano \u30d9\u30fc\u30b9\u306e\u30e9\u30a4\u30d6\u30e9\u30ea\u3067\u3059\u3002\n\u3042\u307e\u308a\u30e1\u30b8\u30e3\u30fc\u3067\u306f\u3042\u308a\u307e\u305b\u3093\u304c\u3001\u6d3b\u767a\u306b\u958b\u767a\u304c\u9032\u3081\u3089\u308c\u3066\u304a\u308a\u3001\u8a2d\u8a08\u304c\u30b7\u30f3\u30d7\u30eb\u3067\u3001\u304b\u306a\u308a\u81ea\u7531\u5ea6\u304c\u9ad8\u304f\u3001\u307e\u305f\u975e\u5e38\u306b\u4f7f\u3044\u3084\u3059\u3044\u305f\u3081\u3001\u3068\u3066\u3082\u304a\u3059\u3059\u3081\u3067\u3059\u3002\n\nKeras \u306e\u30a4\u30f3\u30b9\u30c8\u30fc\u30eb\npip \u3067\u30a4\u30f3\u30b9\u30c8\u30fc\u30eb\u3059\u308b\u3053\u3068\u304c\u51fa\u6765\u307e\u3059\u3002\n$ pip install keras \n\n\u6700\u65b0\u7248\u3092\u4f7f\u3044\u305f\u3044\u5834\u5408\u306f\u4ee5\u4e0b\u306e\u3088\u3046\u306b\u3057\u307e\u3059\u3002\n$ pip install git+https://github.com/fchollet/keras.git\n\nKeras \u306f Theano \u3092\u901a\u3058\u3066 GPU \u3092\u5229\u7528\u3059\u308b\u3053\u3068\u3082\u51fa\u6765\u307e\u3059\u3002\nTheano \u3067 GPU \u3092\u4f7f\u3046\u8a2d\u5b9a\u3068\u306a\u3063\u3066\u3044\u308b\u5834\u5408\u306f\u3001\u7279\u5225\u306a\u8a2d\u5b9a\u306a\u3057\u306b GPU \u3092\u5229\u7528\u3067\u304d\u307e\u3059\u3002\n\nKeras \u3067 MNIST\nKeras \u3067\u306f\u3001\u30e2\u30c7\u30eb\u306b\u5bfe\u5fdc\u3059\u308b keras.models.Sequential \u306b\u30ec\u30a4\u30e4\u3092\u8ffd\u52a0\u3057\u3066\u3044\u304f\u3053\u3068\u3067\u30cd\u30c3\u30c8\u30ef\u30fc\u30af\u3092\u69cb\u7bc9\u3057\u307e\u3059\u3002\u4ee5\u4e0b\u306f\u3001\u3044\u308f\u3086\u308bMLP\u3067 MNIST \u30c7\u30fc\u30bf\u309210\u30af\u30e9\u30b9\u5206\u985e\u3059\u308b\u4f8b\u3067\u3059\u304c\u3001\u975e\u5e38\u306b\u7c21\u5358\u3067\u3042\u308b\u3053\u3068\u304c\u308f\u304b\u308b\u3068\u601d\u3044\u307e\u3059\u3002\nfrom sklearn import datasets, preprocessing\nfrom keras import models, layers\nimport numpy as np\n\ntrain_size = 60000\ndropout = 0.2\nbatch_size = 128\nnb_epoch = 100\n\n# \u30c7\u30fc\u30bf\u30bb\u30c3\u30c8\u306e\u6e96\u5099\nmnist = datasets.fetch_mldata('MNIST original')\nx = mnist.data.astype(float)\nx /= 255 # [0,1] \u306b\u6b63\u898f\u5316\ny = preprocessing.LabelBinarizer().fit_transform(mnist.target) # 0 -1 \u5909\u6570\u306b\u5909\u63db\u3059\u308b\n\n# \u8a13\u7df4\u7528\u3068\u30c6\u30b9\u30c8\u8981\u306b\u5206\u5272\nx_train, x_test = np.split(x, [train_size])\ny_train, y_test = np.split(y, [train_size])\n\n# \u30cd\u30c3\u30c8\u30ef\u30fc\u30af\u69cb\u7bc9\nmodel = models.Sequential()\nmodel.add(layers.core.Dense(28*28, 128, activation='relu'))\nmodel.add(layers.core.Dropout(dropout))\nmodel.add(layers.core.Dense(128, 128, activation='relu'))\nmodel.add(layers.core.Dropout(dropout))\nmodel.add(layers.core.Dense(128, 10, activation='softmax'))\n\n# \u30e2\u30c7\u30eb\u3092\u30b3\u30f3\u30d1\u30a4\u30eb\nmodel.compile(loss='categorical_crossentropy', optimizer='adam')\n\n# \u5b66\u7fd2\nmodel.fit(x_train, y_train, batch_size=batch_size, nb_epoch=nb_epoch, show_accuracy=True, validation_data=[x_test, y_test])\n\n# \u4e88\u6e2c\nmodel.predict(x_test)\n\n\nCaffe\nCaffe \u306f\u8a00\u308f\u305a\u3068\u77e5\u308c\u305f\u6df1\u5c64\u5b66\u7fd2\u30e9\u30a4\u30d6\u30e9\u30ea\u3067\u3059\u3002C++\u3067\u8a18\u8ff0\u3055\u308c\u3066\u304a\u308a\u3001\u975e\u5e38\u306b\u9ad8\u901f\u3067\u3059\u3002\u305f\u3060\u3057\u3001\u30cd\u30c3\u30c8\u30ef\u30fc\u30af\u8a18\u8ff0\u7b49\u306f\u5c02\u7528\u306e\u8a2d\u5b9a\u30d5\u30a1\u30a4\u30eb\u3067\u884c\u3046\u305f\u3081\u3001\u6163\u308c\u308b\u306e\u306b\u6642\u9593\u304c\u304b\u304b\u308a\u307e\u3059\u3057\u3001\u57fa\u672c\u7684\u306b Convolutional Network \u306e\u305f\u3081\u306e\u30e9\u30a4\u30d6\u30e9\u30ea\u306e\u305f\u3081\u3001\u305d\u306e\u4ed6\u306e\u7528\u9014\u306b\u4f7f\u3046\u306b\u306f\u5de5\u592b\u304c\u5fc5\u8981\u3067\u3059\u3002\n\u305f\u3060\u3057\u3001\u6700\u8fd1\u306f NVIDIA \u304b\u3089 DIGITS \u3068\u3044\u3046\u30e9\u30c3\u30d1\u304c\u516c\u958b\u3055\u308c\u3066\u304a\u308a\u3001GUI\u306e\u64cd\u4f5c\u3067 Caffe \u3092\u64cd\u4f5c\u3059\u308b\u3053\u3068\u304c\u3067\u304d\u308b\u3088\u3046\u306b\u306a\u3063\u3066\u3044\u308b\u305f\u3081\u3001\u9650\u5b9a\u7684\u306a\u7528\u9014\u306a\u3089\u3070\u4f7f\u3044\u3084\u3059\u3044\u3068\u3044\u3063\u3066\u3082\u826f\u3044\u304b\u3068\u601d\u3044\u307e\u3059\u3002\n\nCaffe \u306e\u30a4\u30f3\u30b9\u30c8\u30fc\u30eb\nCaffe \u306f\u4f9d\u5b58\u30e9\u30a4\u30d6\u30e9\u30ea\u304c\u591a\u304f\u3001\u30a4\u30f3\u30b9\u30c8\u30fc\u30eb\u3082\u82e5\u5e72\u5384\u4ecb\u3067\u3059\u3002\u3053\u3053\u3067\u306f OSX \u3067\u306eCPU\u30e2\u30fc\u30c9\u3067\u306e\u30a4\u30f3\u30b9\u30c8\u30fc\u30eb\u65b9\u6cd5\u3092\u7d39\u4ecb\u3057\u307e\u3059\u3002(GPU\u30e2\u30fc\u30c9\u3067\u306e\u30a4\u30f3\u30b9\u30c8\u30fc\u30eb\u306b\u3064\u3044\u3066\u306f\u82e5\u5e72\u8907\u96d1\u306a\u305f\u3081\u3001\u5225\u306e\u6a5f\u4f1a\u306b\u7d39\u4ecb\u3057\u307e\u3059)\n\n\u4f9d\u5b58\u30e9\u30a4\u30d6\u30e9\u30ea\u306e\u30a4\u30f3\u30b9\u30c8\u30fc\u30eb\nhomebrew \u3092\u7528\u3044\u3066\u3001\u4f9d\u5b58\u30e9\u30a4\u30d6\u30e9\u30ea\u3092\u30a4\u30f3\u30b9\u30c8\u30fc\u30eb\u3057\u307e\u3059\u3002\n$ brew tap homebrew/science\n$ brew install protobuf glog gflags\n$ brew install hdf5 leveldb snappy lmdb\n$ brew install boost\n$ brew install opencv\n\n\nCaffe \u30bd\u30fc\u30b9\u30b3\u30fc\u30c9\u306e\u53d6\u5f97\ngithub \u3088\u308a\u30bd\u30fc\u30b9\u30b3\u30fc\u30c9\u3092\u30c0\u30a6\u30f3\u30ed\u30fc\u30c9\u3057\u307e\u3059\u3002\n$ git clone https://github.com/BVLC/caffe.git\n\n\n\u30b3\u30a2\u30e9\u30a4\u30d6\u30e9\u30ea\u306e\u30d3\u30eb\u30c9\nCaffe \u3092\u30d3\u30eb\u30c9\u3059\u308b\u306b\u306f\u3001 Makefile.config \u304c\u5fc5\u8981\u3067\u3059\u3002\u3053\u306e\u30d5\u30a1\u30a4\u30eb\u306f\u3001 Makefile.config.example \u3092\u9069\u5b9c\u4fee\u6b63\u3057\u3066\u4f5c\u6210\u3057\u307e\u3059\u3002\n$ cd caffe\n$ cp Makefile.config{.example,}\n$ vi Makefile.config\n\nMakefile.config \u306e CPU_ONLY \u306e\u30b3\u30e1\u30f3\u30c8\u30a2\u30a6\u30c8\u3092\u5916\u3057\u307e\u3059\u3002\n# CPU-only switch (uncomment to build without GPU support).\nCPU_ONLY := 1 # \u30b3\u30e1\u30f3\u30c8\u30a2\u30a6\u30c8\u3092\u5916\u3059\n\n\u5f8c\u306f make \u3059\u308c\u3070\u3001\u3072\u3068\u307e\u305a\u52d5\u304d\u307e\u3059\u3002\n$ make\n\nMakefile.config \u3067\u306f\u3001 blas \u3084 gpu \u5229\u7528\u306e\u6709\u7121\u306a\u3069\u3001\u69d8\u3005\u306a\u8a2d\u5b9a\u304c\u3067\u304d\u307e\u3059\u304c\u3001\u307e\u305a\u306f\u3053\u3053\u3067\u793a\u3057\u305f\u3088\u3046\u306a\u30b7\u30f3\u30d7\u30eb\u306a\u8a2d\u5b9a\u3067\u30b3\u30f3\u30d1\u30a4\u30eb\u304c\u901a\u308b\u3053\u3068\u3092\u78ba\u8a8d\u3057\u3001\u5fc5\u8981\u306b\u5fdc\u3058\u3066\u5f90\u3005\u306b\u8a2d\u5b9a\u3092\u5909\u66f4\u3057\u3066\u3044\u304f\u306e\u304c\u3088\u3044\u3067\u3057\u3087\u3046\u3002\u4f8b\u3048\u3070\u6a19\u6e96\u306e atlas \u3067\u306f\u306a\u304f\u9ad8\u901f\u306a openblas \u3092\u4f7f\u3046\u306b\u306f\u3001\n$ brew install openblas\n\n\u306e\u5f8c\u3001Makefile.config \u306e BLAS \u3092 open \u306b\u3001 BLAS_INCLUDE\u3001 BLAS_LIB \u306e\u30b3\u30e1\u30f3\u30c8\u30a2\u30a6\u30c8\u3092\u524a\u9664\u3057\u307e\u3059\u3002\n# BLAS choice:\n# atlas for ATLAS (default)\n# mkl for MKL\n# open for OpenBlas\n# BLAS := atlas\nBLAS := open\n# Custom (MKL/ATLAS/OpenBLAS) include and lib directories.\n# Leave commented to accept the defaults for your choice of BLAS\n# (which should work)!\n# BLAS_INCLUDE := /path/to/your/blas\n# BLAS_LIB := /path/to/your/blas\n\n# Homebrew puts openblas in a directory that is not on the standard search path\nBLAS_INCLUDE := $(shell brew --prefix openblas)/include\nBLAS_LIB := $(shell brew --prefix openblas)/lib\n\n\u6700\u5f8c\u306b make \u3057\u306a\u304a\u305b\u3070 OK \u3067\u3059\u3002\n$ make clean\n$ make\n\n\npycaffe \u306e\u30d3\u30eb\u30c9\ncaffe \u3092 python \u304b\u3089\u5229\u7528\u3059\u308b\u306b\u306f\u3001 pycaffe \u306e\u30d3\u30eb\u30c9\u304c\u5fc5\u8981\u3067\u3059\u3002\npycaffe \u306b\u306fboost-python \u304c\u5fc5\u8981\u3067\u3059\u304c\u3001\u5358\u7d14\u306b HomeBrew \u3067\u30a4\u30f3\u30b9\u30c8\u30fc\u30eb\u3059\u308b\u3068\u3001\u4ee5\u4e0b\u306e\u3088\u3046\u306a\u30a8\u30e9\u30fc\u304c\u3067\u3066\u3057\u307e\u3044\u307e\u3059\u3002\ncaffe Fatal Python error: PyThreadState_Get: no current thread\n\n\u3053\u306e\u30a8\u30e9\u30fc\u3092\u89e3\u6c7a\u3059\u308b\u306b\u306f\u3001boost-python \u3092\u30bd\u30fc\u30b9\u304b\u3089\u30d3\u30eb\u30c9\u3057\u307e\u3059\u3002\n$ brew --build-from-source --fresh -vd boost-python\n\n\u305d\u306e\u4ed6\u306e\u4f9d\u5b58\u30e9\u30a4\u30d6\u30e9\u30ea\u3082\u30a4\u30f3\u30b9\u30c8\u30fc\u30eb\u3057\u307e\u3059\u3002\n$ cd python\n$ pip install -r requirements.txt\n\nMakefile.config \u306f PYTHON_INCLUDE \u3068 PYTHON_LIB \u306e\u4fee\u6b63\u304c\u5fc5\u8981\u3067\u3059\u3002\n\u305d\u308c\u305e\u308c\u3001\u74b0\u5883\u306b\u5408\u308f\u305b\u3066\u8a2d\u5b9a\u3057\u3066\u304f\u3060\u3055\u3044\u3002\u79c1\u306e\u5834\u5408\u306f\u3001\u4ee5\u4e0b\u306e\u3088\u3046\u306bPython\u3092\u5b9f\u884c\u3057\u3066\u30d1\u30b9\u3092\u53d6\u5f97\u3059\u308b\u3088\u3046\u306b\u3057\u3066\u3044\u307e\u3059\u304c\u3001\u30d1\u30b9\u3092\u30d9\u30bf\u66f8\u304d\u3057\u3066\u3057\u307e\u3063\u305f\u307b\u3046\u304c\u5b89\u5168\u304b\u3082\u3057\u308c\u307e\u305b\u3093\u3002\n...\nPYTHON_INCLUDE := $(dir $(shell python -c 'import os; print(os.__file__).replace(\"lib\", \"include\")'))\nPYTHON_INCLUDE += $(dir $(shell python -c 'import numpy.core; print(numpy.core.__file__)'))/include\n...\nPYTHON_LIB := $(dir $(dir $(shell python -c 'import os; print(os.__file__)')))\n\npyenv \u3084 virtualenv \u3092\u5229\u7528\u3057\u3066\u3044\u3066\u30a8\u30e9\u30fc\u304c\u51fa\u308b\u5834\u5408\u306f\u3001 libboost_python.dylib \u3084 _caffe.so \u304c\u9069\u5207\u306aPython\u5171\u6709\u30e9\u30a4\u30d6\u30e9\u30ea (libpythonx.x.dylib) \u3092\u898b\u3066\u3044\u308b\u304b\u78ba\u8a8d\u3057\u3066\u4e0b\u3055\u3044\u3002\u78ba\u8a8d\u306b\u306f otool \u304c\u4f7f\u3048\u307e\u3059\u3002\n$ otool -L /usr/local/Cellar/boost-python/1.57.0/lib/libboost_python.dylib\n/usr/local/Cellar/boost-python/1.57.0/lib/libboost_python.dylib:\n    /usr/local/lib/libboost_python.dylib (compatibility version 0.0.0, current version 0.0.0)\n    /Users/xxx/.pyenv/versions/2.7.9/lib/libpython2.7.dylib (compatibility version 2.7.0, current version 2.7.0)\n    /usr/lib/libc++.1.dylib (compatibility version 1.0.0, current version 120.0.0)\n    /usr/lib/libSystem.B.dylib (compatibility version 1.0.0, current version 1213.0.0)\n\n\nCaffe \u3067 MNIST\n\nMNIST\u30c7\u30fc\u30bf\u306e\u30c0\u30f3\u30ed\u30fc\u30c9\u30fb\u5909\u63db\nCaffe \u306b\u306f\u3001MNIST \u3092\u30c0\u30a6\u30f3\u30ed\u30fc\u30c9\u3057\u3001Caffe\u306e\u53d6\u308a\u6271\u3048\u308b\u5f62\u5f0f\u306b\u5909\u63db\u3059\u308b\u30b9\u30af\u30ea\u30d7\u30c8\u304c\u542b\u307e\u308c\u3066\u3044\u307e\u3059\u306e\u3067\u3001\u4eca\u56de\u306f\u305d\u3061\u3089\u3092\u5229\u7528\u3057\u307e\u3059\u3002\n\u4ee5\u4e0b\u306e\u30b3\u30de\u30f3\u30c9\u306f caffe \u30c7\u30a3\u30ec\u30af\u30c8\u30ea\u76f4\u4e0b\u3067\u5b9f\u884c\u3057\u307e\u3059\u3002\n$ data/mnist/get_mnist.sh\n$ examples/mnist/create_mnist.sh\n\n\n\u8a2d\u5b9a\u30d5\u30a1\u30a4\u30eb\u4f5c\u6210\n\u30cd\u30c3\u30c8\u30ef\u30fc\u30af\u306e\u8a2d\u5b9a\u3084\u3001\u5b66\u7fd2\u65b9\u6cd5\u306e\u8a2d\u5b9a\u306f\u4ee5\u4e0b\u306e\u3088\u3046\u306b\u8a2d\u5b9a\u3057\u307e\u3059\u3002\u5185\u5bb9\u306f\u4f55\u3068\u306a\u304f\u5206\u304b\u308b\u304b\u3068\u601d\u3044\u307e\u3059\u304c\u3001\u304d\u3061\u3093\u3068\u3057\u305f\u7406\u89e3\u306b\u306f\u30aa\u30d5\u30a3\u30b7\u30e3\u30eb\u306e\u30c1\u30e5\u30fc\u30c8\u30ea\u30a2\u30eb\u3084\u6771\u90a6\u5927\u5b66\u30fb\u5c71\u5185\u5148\u751f\u306e\u30da\u30fc\u30b8 \u304c\u5f79\u306b\u7acb\u3061\u307e\u3059\u3002\n\u6ce8\u610f\u3057\u306a\u3044\u3068\u3044\u3051\u306a\u3044\u306e\u306f\u3001\u30cd\u30c3\u30c8\u30ef\u30fc\u30af\u306e\u8a2d\u5b9a\u30d5\u30a1\u30a4\u30eb\u306e weight_filter \u3067\u3059\u3002\u3053\u3053\u3067\u30cd\u30c3\u30c8\u30ef\u30fc\u30af\u306e\u91cd\u307f\u306e\u521d\u671f\u5316\u65b9\u6cd5\u3092\u8a2d\u5b9a\u3057\u3066\u3044\u308b\u306e\u3067\u3059\u304c\u3001\u3053\u3061\u3089\u3092\u304d\u3061\u3093\u3068\u6307\u5b9a\u3057\u306a\u3044\u3068\u53ce\u675f\u3057\u307e\u305b\u3093\u3002\nmnist_solver.prototxt (\u5b66\u7fd2\u65b9\u6cd5\u306e\u8a2d\u5b9a)\nnet: \"mnist.prototxt\" # \u30cd\u30c3\u30c8\u30ef\u30fc\u30af\u306e\u8a2d\u5b9a\u30d5\u30a1\u30a4\u30eb\ntest_iter: 100 # \u30c6\u30b9\u30c8\u3067\u306e\u7e70\u308a\u8fd4\u3057(batch)\u56de\u6570\ntest_interval: 1000 # \u30c6\u30b9\u30c8\u306e\u9593\u9694\ntest_compute_loss: true\nbase_lr: 0.01 # \u5b66\u7fd2\u7387\u306e\u521d\u671f\u5024\nlr_policy: \"inv\" # \u5b66\u7fd2\u7387\u3092\u5c0f\u3055\u304f\u3059\u308b\u30dd\u30ea\u30b7\u30fc\ndisplay: 100 # \u753b\u9762\u306b\u60c5\u5831\u3092\u8868\u793a\u3059\u308b\u9593\u9694\nmax_iter: 65000 # \u7e70\u308a\u8fd4\u3057(batch)\u56de\u6570\nsolver_type: 2 # \u6700\u9069\u5316\u624b\u6cd5 (2: AdaGrad)\nsolver_mode: CPU # CPU \u3082\u3057\u304f\u306f GPU\n\nmnist.prototxt (\u5b66\u7fd2\u6642\u306e\u30cd\u30c3\u30c8\u30ef\u30fc\u30af\u8a2d\u5b9a)\nname: \"MNIST\"\nlayer {\n  name: \"mnist\"\n  type: \"Data\"\n  top: \"data\"\n  top: \"label\"\n  include {\n    phase: TRAIN\n  }\n  transform_param {\n    scale: 0.00390625\n  }\n  data_param {\n    source: \"examples/mnist/mnist_train_lmdb\"\n    batch_size: 128 \n    backend: LMDB\n  }\n}\nlayer {\n  name: \"mnist\"\n  type: \"Data\"\n  top: \"data\"\n  top: \"label\"\n  include {\n    phase: TEST\n  }\n  transform_param {\n    scale: 0.00390625\n  }\n  data_param {\n    source: \"examples/mnist/mnist_test_lmdb\"\n    batch_size: 128\n    backend: LMDB\n  }\n}\nlayer {\n  name: \"ip1\"\n  type: \"InnerProduct\"\n  bottom: \"data\"\n  top: \"ip1\"\n  param {\n    lr_mult: 1\n  }\n  param {\n    lr_mult: 2\n  }\n  inner_product_param {\n    num_output: 128 \n    weight_filler {\n      type: \"xavier\"\n    }\n  }\n}\nlayer {\n  name: \"relu1\"\n  type: \"ReLU\"\n  bottom: \"ip1\"\n  top: \"ip1\"\n}\nlayer {\n  name: \"drop1\"\n  type: \"Dropout\"\n  bottom: \"ip1\"\n  top: \"ip1\"\n  dropout_param {\n    dropout_ratio: 0.25\n  }\n}\nlayer {\n  name: \"ip2\"\n  type: \"InnerProduct\"\n  bottom: \"ip1\"\n  top: \"ip2\"\n  param {\n    lr_mult: 1\n  }\n  param {\n    lr_mult: 2\n  }\n  inner_product_param {\n    num_output: 128\n    weight_filler {\n      type: \"xavier\"\n    }\n  }\n}\nlayer {\n  name: \"relu2\"\n  type: \"ReLU\"\n  bottom: \"ip2\"\n  top: \"ip2\"\n}\nlayer {\n  name: \"drop2\"\n  type: \"Dropout\"\n  bottom: \"ip2\"\n  top: \"ip2\"\n  dropout_param {\n    dropout_ratio: 0.25\n  }\n} \nlayer {\n  name: \"ip3\"\n  type: \"InnerProduct\"\n  bottom: \"ip2\"\n  top: \"ip3\"\n  param {\n    lr_mult: 1\n  }\n  param {\n    lr_mult: 2\n  }\n  inner_product_param {\n    num_output: 10\n    weight_filler {\n      type: \"xavier\"\n    }\n  }\n}\nlayer {\n  name: \"accuracy\"\n  type: \"Accuracy\"\n  bottom: \"ip3\"\n  bottom: \"label\"\n  top: \"accuracy\"\n  include {\n    phase: TEST\n  }\n}\nlayer {\n  name: \"loss\"\n  type: \"SoftmaxWithLoss\"\n  bottom: \"ip3\"\n  bottom: \"label\"\n  top: \"loss\"\n}\n\nmnist_deploy.prototxt (\u4e88\u6e2c\u6642\u306e\u30cd\u30c3\u30c8\u30ef\u30fc\u30af\u8a2d\u5b9a)\n\u57fa\u672c\u7684\u306b mnisit.prototxt \u3068\u540c\u3058\u3067\u3059\u304c\u3001 Data \u30ec\u30a4\u30e4\u30fc\u304c\u306a\u304f\u306a\u3063\u3066\u3001\u4ee3\u308f\u308a\u306b input \u3092\u6307\u5b9a\u3057\u3066\u3044\u307e\u3059\u3002\u307e\u305f\u3001\u51fa\u529b\u3082 accuracy \u304c\u306a\u304f\u306a\u308a\u3001 SoftmaxWithLoss \u304c Softmax \u306b\u304b\u308f\u3063\u3066\u3044\u307e\u3059\u3002\nname: \"MNIST\"\ninput: \"data\"\ninput_dim: 10 # \u30d0\u30c3\u30c1\u30b5\u30a4\u30ba\ninput_dim: 1 # \u753b\u50cf\u30c1\u30e3\u30cd\u30eb\u6570(\u30e2\u30ce\u30af\u30ed\u306a\u306e\u30671)\ninput_dim: 28 # \u753b\u50cf\u30b5\u30a4\u30ba(y)\ninput_dim: 28 # \u753b\u50cf\u30b5\u30a4\u30ba(x)\nlayer {\n  name: \"ip1\"\n  type: \"InnerProduct\"\n  bottom: \"data\"\n  top: \"ip1\"\n  param {\n    lr_mult: 1\n  }\n  param {\n    lr_mult: 2\n  }\n  inner_product_param {\n    num_output: 128 \n    weight_filler {\n      type: \"xavier\"\n    }\n  }\n}\nlayer {\n  name: \"relu1\"\n  type: \"ReLU\"\n  bottom: \"ip1\"\n  top: \"ip1\"\n}\nlayer {\n  name: \"drop1\"\n  type: \"Dropout\"\n  bottom: \"ip1\"\n  top: \"ip1\"\n  dropout_param {\n    dropout_ratio: 0.25\n  }\n}\nlayer {\n  name: \"ip2\"\n  type: \"InnerProduct\"\n  bottom: \"ip1\"\n  top: \"ip2\"\n  param {\n    lr_mult: 1\n  }\n  param {\n    lr_mult: 2\n  }\n  inner_product_param {\n    num_output: 128\n    weight_filler {\n      type: \"xavier\"\n    }\n  }\n}\nlayer {\n  name: \"relu2\"\n  type: \"ReLU\"\n  bottom: \"ip2\"\n  top: \"ip2\"\n}\nlayer {\n  name: \"drop2\"\n  type: \"Dropout\"\n  bottom: \"ip2\"\n  top: \"ip2\"\n  dropout_param {\n    dropout_ratio: 0.25\n  }\n} \nlayer {\n  name: \"ip3\"\n  type: \"InnerProduct\"\n  bottom: \"ip2\"\n  top: \"ip3\"\n  param {\n    lr_mult: 1\n  }\n  param {\n    lr_mult: 2\n  }\n  inner_product_param {\n    num_output: 10\n    weight_filler {\n      type: \"xavier\"\n    }\n  }\n}\nlayer {\n  name: \"prob\"\n  type: \"Softmax\"\n  bottom: \"ip3\"\n  top: \"prob\"\n}\n\n\n\u5b66\u7fd2\ncaffe \u30b3\u30de\u30f3\u30c9\u3092\u4f7f\u3063\u3066\u5b66\u7fd2\u3057\u307e\u3059\u3002caffe\u30b3\u30de\u30f3\u30c9\u306f build/tools/ \u4ee5\u4e0b\u306b\u3042\u308a\u307e\u3059\u3002\n$ build/tools/caffe train -solver mnist_solver.prototxt\n\n\u5b66\u7fd2\u7d50\u679c\u306f\u3001\u30c7\u30d5\u30a9\u30eb\u30c8\u3067\u306f\u30ab\u30ec\u30f3\u30c8\u30c7\u30a3\u30ec\u30af\u30c8\u30ea\u306b *.caffemodel \u3068\u3044\u3046\u30d5\u30a1\u30a4\u30eb\u540d\u3067\u4fdd\u5b58\u3055\u308c\u307e\u3059\u3002\n$ ls *.caffemodel\n_iter_65000.caffemodel\n\n\n\u4e88\u6e2c\n\u3053\u3053\u3067\u306f pycaffe \u3092\u4f7f\u3063\u3066\u4e88\u6e2c\u3057\u307e\u3059\u3002\n#!/usr/bin/env python\n# -*- coding:utf-8 -*-\n\nimport struct\n\nimport caffe\nimport numpy as np\n\nMNIST_DATA_PATH = 'data/mnist/t10k-images-idx3-ubyte'\nPROTO_PATH = 'mnist_deploy.prototxt'\nMODEL_PATH = '_iter_65000.caffemodel'\n\n\ndef load_image(fp):\n    header = fp.read(16)\n    contents = fp.read()\n    magic, n_images, row, col = struct.unpack('>4i', header)\n    assert(magic == 2051)\n    images = np.array(\n        struct.unpack('>%dB' % len(contents), contents),\n        dtype=np.float64).reshape(n_images, row, col, 1)\n    return images/256 # \u5024\u304c [0, 1] \u3068\u306a\u308b\u3088\u3046\u5909\u63db\n\n\nwith open(MNIST_DATA_PATH) as i_:\n    images = load_image(i_)\n\nnet = caffe.Classifier(\n    PROTO_PATH,\n    MODEL_PATH,\n    image_dims=images.shape[1:]\n)\n\nnet.predict(images)\n\n\u3075\u3046\u3063\u3001\u3068\u3044\u3063\u305f\u611f\u3058\u3067\u3059\u306d\u3002\n\nDeepLearning4J\nDeepLearning4J \u306f Skymind\u793e\u304c\u63d0\u4f9b\u3059\u308b\u3001 Java\u88fd\u306e\u6df1\u5c64\u5b66\u7fd2\u30e9\u30a4\u30d6\u30e9\u30ea\u3067\u3059\u3002maven\u30ea\u30dd\u30b8\u30c8\u30ea\u306b\u3082\u767b\u9332\u3055\u308c\u3066\u3044\u3066\u74b0\u5883\u69cb\u7bc9\u306f\u975e\u5e38\u306b\u7c21\u5358\u3067\u3059\u3002\n\nDeepLearning4J \u306e\u30a4\u30f3\u30b9\u30c8\u30fc\u30eb\nmaven \u304c\u5165\u3063\u3066\u3044\u308b\u3053\u3068\u3092\u524d\u63d0\u3068\u3057\u307e\u3059\u3002\u307e\u305a\u306f\u30d7\u30ed\u30b8\u30a7\u30af\u30c8\u3092\u4f5c\u6210\u3057\u307e\u3057\u3087\u3046\u3002\n$ mvn archetype:generate -DarchetypeArtifactId=maven-archetype-quickstart\n\n\u9014\u4e2d\u3067 groupId \u3084 artifactId \u306a\u3069\u3092\u805e\u304b\u308c\u308b\u306e\u3067\u3001\u9069\u5f53\u306b\u7b54\u3048\u307e\u3059\u3002(\u4f8b: groupId: mygroup artifactId: dl4jtest)\nmaven \u30b3\u30de\u30f3\u30c9\u304c\u7d42\u4e86\u3059\u308b\u3068\u3001\u30d7\u30ed\u30b8\u30a7\u30af\u30c8\u30c7\u30a3\u30ec\u30af\u30c8\u30ea\u304c\u3067\u304d\u308b\u3066\u3044\u308b\u306e\u3067\u3001\u305d\u3061\u3089\u306b\u79fb\u52d5\u3057\u3001 pom.xml \u3092\u7de8\u96c6\u3057\u307e\u3059\u3002\n$ cd dl4jtest\n$ vi pom.xml\n\n\n\n\nMocha\nMocha \u306f\u9ad8\u901f\u306a\u79d1\u5b66\u8a08\u7b97\u8a00\u8a9e Julia \u306e DeepLearning \u7528\u30d1\u30c3\u30b1\u30fc\u30b8\u3067\u3059\u3002\nJulia \u304c\u30a4\u30f3\u30b9\u30c8\u30fc\u30eb\u3055\u308c\u3066\u3044\u308c\u3070\u3001Mocha \u306e\u30a4\u30f3\u30b9\u30c8\u30fc\u30eb\u306f\u7c21\u5358\u3067\u3001\nPkg.add(\"Mocha\")\n\n\u3068\u3059\u308b\u3060\u3051\u3067\u3059\u3002\u6700\u65b0\u7248\u3092\u4f7f\u3044\u305f\u3044\u5834\u5408\u306f\nPkg.clone(\"https://github.com/pluskid/Mocha.jl.git\")\n\n\u3068\u3057\u307e\u3059\u3002\n\n\u5b66\u7fd2\nuse_gpu = true\n\nif use_gpu\n  ENV[\"MOCHA_USE_CUDA\"] = \"true\"\nelse\n  ENV[\"MOCHA_USE_NATIVE_EXT\"] = \"true\"\n  ENV[\"OMP_NUM_THREADS\"] = 1\n  blas_set_num_threads(1)\nend\n\nusing Mocha\nsrand(12345678)\n\ndata_layer  = AsyncHDF5DataLayer(name=\"train-data\", source=\"data/train.txt\", batch_size=64, shuffle=true)\nconv_layer  = ConvolutionLayer(name=\"conv1\", n_filter=20, kernel=(5,5), bottoms=[:data], tops=[:conv])\npool_layer  = PoolingLayer(name=\"pool1\", kernel=(2,2), stride=(2,2), bottoms=[:conv], tops=[:pool])\nconv2_layer = ConvolutionLayer(name=\"conv2\", n_filter=50, kernel=(5,5), bottoms=[:pool], tops=[:conv2])\npool2_layer = PoolingLayer(name=\"pool2\", kernel=(2,2), stride=(2,2), bottoms=[:conv2], tops=[:pool2])\nfc1_layer   = InnerProductLayer(name=\"ip1\", output_dim=500, neuron=Neurons.ReLU(), bottoms=[:pool2], tops=[:ip1])\nfc2_layer   = InnerProductLayer(name=\"ip2\", output_dim=10, bottoms=[:ip1], tops=[:ip2])\nloss_layer  = SoftmaxLossLayer(name=\"loss\", bottoms=[:ip2,:label])\n\nbackend = use_gpu ? GPUBackend() : CPUBackend()\ninit(backend)\n\ncommon_layers = [conv_layer, pool_layer, conv2_layer, pool2_layer, fc1_layer, fc2_layer]\nnet = Net(\"MNIST-train\", backend, [data_layer, common_layers..., loss_layer])\n\nexp_dir = \"snapshots$(use_gpu ? \"-gpu\" : \"-cpu\")\"\n\nparams = SolverParameters(max_iter=10000, regu_coef=0.0005,\n    mom_policy=MomPolicy.Fixed(0.9),\n    lr_policy=LRPolicy.Inv(0.01, 0.0001, 0.75),\n    load_from=exp_dir)\nsolver = SGD(params)\n\nsetup_coffee_lounge(solver, save_into=\"$exp_dir/statistics.jld\", every_n_iter=1000)\n\n# report training progress every 100 iterations\nadd_coffee_break(solver, TrainingSummary(), every_n_iter=100)\n\n# save snapshots every 5000 iterations\nadd_coffee_break(solver, Snapshot(exp_dir), every_n_iter=5000)\n\n# show performance on test data every 1000 iterations\ndata_layer_test = HDF5DataLayer(name=\"test-data\", source=\"data/test.txt\", batch_size=100)\nacc_layer = AccuracyLayer(name=\"test-accuracy\", bottoms=[:ip2, :label])\ntest_net = Net(\"MNIST-test\", backend, [data_layer_test, common_layers..., acc_layer])\nadd_coffee_break(solver, ValidationPerformance(test_net), every_n_iter=1000)\n\nsolve(solver, net)\n\n#Profile.init(int(1e8), 0.001)\n#@profile solve(solver, net)\n#open(\"profile.txt\", \"w\") do out\n#  Profile.print(out)\n#end\n\ndestroy(net)\ndestroy(test_net)\nshutdown(backend)\n\n\u305a\u3044\u3076\u3093\u4e0b\u66f8\u304d\u3067\u7720\u3063\u3066\u3044\u305f\u306e\u3067\u3001\u66f8\u3044\u3066\u3044\u308b\u9014\u4e2d\u3067\u3059\u304c\u516c\u958b\u3057\u307e\u3059\u3002\n\n\nChainer \u304c\u6d41\u884c\u3063\u3066\u3044\u307e\u3059\u306e\u3067\u3001\u305d\u308c\u4ee5\u5916\u306b\u3064\u3044\u3066\u307e\u3068\u3081\u307e\u3059\u3002\n\u500b\u4eba\u7684\u306b\u306f\u3001Python\u4f7f\u3044\u3067\u3042\u308c\u3070 Keras\u3001Java/Scala \u306a\u65b9\u306f DeepLearning4J \u304c\u4f7f\u3044\u3084\u3059\u3044\u3068\u601d\u3044\u307e\u3059\u3002\n\n\n# Keras\n\n[Keras](http://keras.io/) \u306f Theano \u30d9\u30fc\u30b9\u306e\u30e9\u30a4\u30d6\u30e9\u30ea\u3067\u3059\u3002\n\u3042\u307e\u308a\u30e1\u30b8\u30e3\u30fc\u3067\u306f\u3042\u308a\u307e\u305b\u3093\u304c\u3001\u6d3b\u767a\u306b\u958b\u767a\u304c\u9032\u3081\u3089\u308c\u3066\u304a\u308a\u3001\u8a2d\u8a08\u304c\u30b7\u30f3\u30d7\u30eb\u3067\u3001\u304b\u306a\u308a\u81ea\u7531\u5ea6\u304c\u9ad8\u304f\u3001\u307e\u305f\u975e\u5e38\u306b\u4f7f\u3044\u3084\u3059\u3044\u305f\u3081\u3001\u3068\u3066\u3082\u304a\u3059\u3059\u3081\u3067\u3059\u3002\n\n## Keras \u306e\u30a4\u30f3\u30b9\u30c8\u30fc\u30eb\n\npip \u3067\u30a4\u30f3\u30b9\u30c8\u30fc\u30eb\u3059\u308b\u3053\u3068\u304c\u51fa\u6765\u307e\u3059\u3002\n\n```bash\n$ pip install keras \n```\n\n\u6700\u65b0\u7248\u3092\u4f7f\u3044\u305f\u3044\u5834\u5408\u306f\u4ee5\u4e0b\u306e\u3088\u3046\u306b\u3057\u307e\u3059\u3002\n\n```bash\n$ pip install git+https://github.com/fchollet/keras.git\n```\n\nKeras \u306f Theano \u3092\u901a\u3058\u3066 GPU \u3092\u5229\u7528\u3059\u308b\u3053\u3068\u3082\u51fa\u6765\u307e\u3059\u3002\nTheano \u3067 GPU \u3092\u4f7f\u3046\u8a2d\u5b9a\u3068\u306a\u3063\u3066\u3044\u308b\u5834\u5408\u306f\u3001\u7279\u5225\u306a\u8a2d\u5b9a\u306a\u3057\u306b GPU \u3092\u5229\u7528\u3067\u304d\u307e\u3059\u3002\n\n## Keras \u3067 MNIST\n\nKeras \u3067\u306f\u3001\u30e2\u30c7\u30eb\u306b\u5bfe\u5fdc\u3059\u308b `keras.models.Sequential` \u306b\u30ec\u30a4\u30e4\u3092\u8ffd\u52a0\u3057\u3066\u3044\u304f\u3053\u3068\u3067\u30cd\u30c3\u30c8\u30ef\u30fc\u30af\u3092\u69cb\u7bc9\u3057\u307e\u3059\u3002\u4ee5\u4e0b\u306f\u3001\u3044\u308f\u3086\u308bMLP\u3067 MNIST \u30c7\u30fc\u30bf\u309210\u30af\u30e9\u30b9\u5206\u985e\u3059\u308b\u4f8b\u3067\u3059\u304c\u3001\u975e\u5e38\u306b\u7c21\u5358\u3067\u3042\u308b\u3053\u3068\u304c\u308f\u304b\u308b\u3068\u601d\u3044\u307e\u3059\u3002\n\n```py\nfrom sklearn import datasets, preprocessing\nfrom keras import models, layers\nimport numpy as np\n\ntrain_size = 60000\ndropout = 0.2\nbatch_size = 128\nnb_epoch = 100\n\n# \u30c7\u30fc\u30bf\u30bb\u30c3\u30c8\u306e\u6e96\u5099\nmnist = datasets.fetch_mldata('MNIST original')\nx = mnist.data.astype(float)\nx /= 255 # [0,1] \u306b\u6b63\u898f\u5316\ny = preprocessing.LabelBinarizer().fit_transform(mnist.target) # 0 -1 \u5909\u6570\u306b\u5909\u63db\u3059\u308b\n\n# \u8a13\u7df4\u7528\u3068\u30c6\u30b9\u30c8\u8981\u306b\u5206\u5272\nx_train, x_test = np.split(x, [train_size])\ny_train, y_test = np.split(y, [train_size])\n\n# \u30cd\u30c3\u30c8\u30ef\u30fc\u30af\u69cb\u7bc9\nmodel = models.Sequential()\nmodel.add(layers.core.Dense(28*28, 128, activation='relu'))\nmodel.add(layers.core.Dropout(dropout))\nmodel.add(layers.core.Dense(128, 128, activation='relu'))\nmodel.add(layers.core.Dropout(dropout))\nmodel.add(layers.core.Dense(128, 10, activation='softmax'))\n\n# \u30e2\u30c7\u30eb\u3092\u30b3\u30f3\u30d1\u30a4\u30eb\nmodel.compile(loss='categorical_crossentropy', optimizer='adam')\n\n# \u5b66\u7fd2\nmodel.fit(x_train, y_train, batch_size=batch_size, nb_epoch=nb_epoch, show_accuracy=True, validation_data=[x_test, y_test])\n\n# \u4e88\u6e2c\nmodel.predict(x_test)\n``` \n\n# Caffe\n\n[Caffe](http://caffe.berkeleyvision.org/) \u306f\u8a00\u308f\u305a\u3068\u77e5\u308c\u305f\u6df1\u5c64\u5b66\u7fd2\u30e9\u30a4\u30d6\u30e9\u30ea\u3067\u3059\u3002C++\u3067\u8a18\u8ff0\u3055\u308c\u3066\u304a\u308a\u3001\u975e\u5e38\u306b\u9ad8\u901f\u3067\u3059\u3002\u305f\u3060\u3057\u3001\u30cd\u30c3\u30c8\u30ef\u30fc\u30af\u8a18\u8ff0\u7b49\u306f\u5c02\u7528\u306e\u8a2d\u5b9a\u30d5\u30a1\u30a4\u30eb\u3067\u884c\u3046\u305f\u3081\u3001\u6163\u308c\u308b\u306e\u306b\u6642\u9593\u304c\u304b\u304b\u308a\u307e\u3059\u3057\u3001\u57fa\u672c\u7684\u306b Convolutional Network \u306e\u305f\u3081\u306e\u30e9\u30a4\u30d6\u30e9\u30ea\u306e\u305f\u3081\u3001\u305d\u306e\u4ed6\u306e\u7528\u9014\u306b\u4f7f\u3046\u306b\u306f\u5de5\u592b\u304c\u5fc5\u8981\u3067\u3059\u3002\n\u305f\u3060\u3057\u3001\u6700\u8fd1\u306f NVIDIA \u304b\u3089 DIGITS \u3068\u3044\u3046\u30e9\u30c3\u30d1\u304c\u516c\u958b\u3055\u308c\u3066\u304a\u308a\u3001GUI\u306e\u64cd\u4f5c\u3067 Caffe \u3092\u64cd\u4f5c\u3059\u308b\u3053\u3068\u304c\u3067\u304d\u308b\u3088\u3046\u306b\u306a\u3063\u3066\u3044\u308b\u305f\u3081\u3001\u9650\u5b9a\u7684\u306a\u7528\u9014\u306a\u3089\u3070\u4f7f\u3044\u3084\u3059\u3044\u3068\u3044\u3063\u3066\u3082\u826f\u3044\u304b\u3068\u601d\u3044\u307e\u3059\u3002\n\n## Caffe \u306e\u30a4\u30f3\u30b9\u30c8\u30fc\u30eb\n\nCaffe \u306f\u4f9d\u5b58\u30e9\u30a4\u30d6\u30e9\u30ea\u304c\u591a\u304f\u3001\u30a4\u30f3\u30b9\u30c8\u30fc\u30eb\u3082\u82e5\u5e72\u5384\u4ecb\u3067\u3059\u3002\u3053\u3053\u3067\u306f OSX \u3067\u306eCPU\u30e2\u30fc\u30c9\u3067\u306e\u30a4\u30f3\u30b9\u30c8\u30fc\u30eb\u65b9\u6cd5\u3092\u7d39\u4ecb\u3057\u307e\u3059\u3002(GPU\u30e2\u30fc\u30c9\u3067\u306e\u30a4\u30f3\u30b9\u30c8\u30fc\u30eb\u306b\u3064\u3044\u3066\u306f\u82e5\u5e72\u8907\u96d1\u306a\u305f\u3081\u3001\u5225\u306e\u6a5f\u4f1a\u306b\u7d39\u4ecb\u3057\u307e\u3059)\n\n### \u4f9d\u5b58\u30e9\u30a4\u30d6\u30e9\u30ea\u306e\u30a4\u30f3\u30b9\u30c8\u30fc\u30eb\n\nhomebrew \u3092\u7528\u3044\u3066\u3001\u4f9d\u5b58\u30e9\u30a4\u30d6\u30e9\u30ea\u3092\u30a4\u30f3\u30b9\u30c8\u30fc\u30eb\u3057\u307e\u3059\u3002\n\n```bash\n$ brew tap homebrew/science\n$ brew install protobuf glog gflags\n$ brew install hdf5 leveldb snappy lmdb\n$ brew install boost\n$ brew install opencv\n``` \n\n### Caffe \u30bd\u30fc\u30b9\u30b3\u30fc\u30c9\u306e\u53d6\u5f97\n\ngithub \u3088\u308a\u30bd\u30fc\u30b9\u30b3\u30fc\u30c9\u3092\u30c0\u30a6\u30f3\u30ed\u30fc\u30c9\u3057\u307e\u3059\u3002\n\n```bash\n$ git clone https://github.com/BVLC/caffe.git\n```\n\n### \u30b3\u30a2\u30e9\u30a4\u30d6\u30e9\u30ea\u306e\u30d3\u30eb\u30c9\n\nCaffe \u3092\u30d3\u30eb\u30c9\u3059\u308b\u306b\u306f\u3001 Makefile.config \u304c\u5fc5\u8981\u3067\u3059\u3002\u3053\u306e\u30d5\u30a1\u30a4\u30eb\u306f\u3001 Makefile.config.example \u3092\u9069\u5b9c\u4fee\u6b63\u3057\u3066\u4f5c\u6210\u3057\u307e\u3059\u3002\n\n```bash\n$ cd caffe\n$ cp Makefile.config{.example,}\n$ vi Makefile.config\n```\n\nMakefile.config \u306e CPU_ONLY \u306e\u30b3\u30e1\u30f3\u30c8\u30a2\u30a6\u30c8\u3092\u5916\u3057\u307e\u3059\u3002\n\n```\n# CPU-only switch (uncomment to build without GPU support).\nCPU_ONLY := 1 # \u30b3\u30e1\u30f3\u30c8\u30a2\u30a6\u30c8\u3092\u5916\u3059\n```\n\n\u5f8c\u306f make \u3059\u308c\u3070\u3001\u3072\u3068\u307e\u305a\u52d5\u304d\u307e\u3059\u3002\n\n```\n$ make\n```\n\nMakefile.config \u3067\u306f\u3001 blas \u3084 gpu \u5229\u7528\u306e\u6709\u7121\u306a\u3069\u3001\u69d8\u3005\u306a\u8a2d\u5b9a\u304c\u3067\u304d\u307e\u3059\u304c\u3001\u307e\u305a\u306f\u3053\u3053\u3067\u793a\u3057\u305f\u3088\u3046\u306a\u30b7\u30f3\u30d7\u30eb\u306a\u8a2d\u5b9a\u3067\u30b3\u30f3\u30d1\u30a4\u30eb\u304c\u901a\u308b\u3053\u3068\u3092\u78ba\u8a8d\u3057\u3001\u5fc5\u8981\u306b\u5fdc\u3058\u3066\u5f90\u3005\u306b\u8a2d\u5b9a\u3092\u5909\u66f4\u3057\u3066\u3044\u304f\u306e\u304c\u3088\u3044\u3067\u3057\u3087\u3046\u3002\u4f8b\u3048\u3070\u6a19\u6e96\u306e atlas \u3067\u306f\u306a\u304f\u9ad8\u901f\u306a openblas \u3092\u4f7f\u3046\u306b\u306f\u3001\n\n```bash\n$ brew install openblas\n```\n\n\u306e\u5f8c\u3001Makefile.config \u306e BLAS \u3092 open \u306b\u3001 BLAS_INCLUDE\u3001 BLAS_LIB \u306e\u30b3\u30e1\u30f3\u30c8\u30a2\u30a6\u30c8\u3092\u524a\u9664\u3057\u307e\u3059\u3002\n\n```\n# BLAS choice:\n# atlas for ATLAS (default)\n# mkl for MKL\n# open for OpenBlas\n# BLAS := atlas\nBLAS := open\n# Custom (MKL/ATLAS/OpenBLAS) include and lib directories.\n# Leave commented to accept the defaults for your choice of BLAS\n# (which should work)!\n# BLAS_INCLUDE := /path/to/your/blas\n# BLAS_LIB := /path/to/your/blas\n\n# Homebrew puts openblas in a directory that is not on the standard search path\nBLAS_INCLUDE := $(shell brew --prefix openblas)/include\nBLAS_LIB := $(shell brew --prefix openblas)/lib\n```\n\n\u6700\u5f8c\u306b make \u3057\u306a\u304a\u305b\u3070 OK \u3067\u3059\u3002\n\n```bash\n$ make clean\n$ make\n```\n\n### pycaffe \u306e\u30d3\u30eb\u30c9\n\ncaffe \u3092 python \u304b\u3089\u5229\u7528\u3059\u308b\u306b\u306f\u3001 pycaffe \u306e\u30d3\u30eb\u30c9\u304c\u5fc5\u8981\u3067\u3059\u3002\npycaffe \u306b\u306fboost-python \u304c\u5fc5\u8981\u3067\u3059\u304c\u3001\u5358\u7d14\u306b HomeBrew \u3067\u30a4\u30f3\u30b9\u30c8\u30fc\u30eb\u3059\u308b\u3068\u3001\u4ee5\u4e0b\u306e\u3088\u3046\u306a\u30a8\u30e9\u30fc\u304c\u3067\u3066\u3057\u307e\u3044\u307e\u3059\u3002\n\n```\ncaffe Fatal Python error: PyThreadState_Get: no current thread\n``` \n\n\u3053\u306e\u30a8\u30e9\u30fc\u3092\u89e3\u6c7a\u3059\u308b\u306b\u306f\u3001boost-python \u3092\u30bd\u30fc\u30b9\u304b\u3089\u30d3\u30eb\u30c9\u3057\u307e\u3059\u3002\n\n```bash\n$ brew --build-from-source --fresh -vd boost-python\n```\n\n\u305d\u306e\u4ed6\u306e\u4f9d\u5b58\u30e9\u30a4\u30d6\u30e9\u30ea\u3082\u30a4\u30f3\u30b9\u30c8\u30fc\u30eb\u3057\u307e\u3059\u3002\n\n```bash\n$ cd python\n$ pip install -r requirements.txt\n```\n\nMakefile.config \u306f PYTHON_INCLUDE \u3068 PYTHON_LIB \u306e\u4fee\u6b63\u304c\u5fc5\u8981\u3067\u3059\u3002\n\u305d\u308c\u305e\u308c\u3001\u74b0\u5883\u306b\u5408\u308f\u305b\u3066\u8a2d\u5b9a\u3057\u3066\u304f\u3060\u3055\u3044\u3002\u79c1\u306e\u5834\u5408\u306f\u3001\u4ee5\u4e0b\u306e\u3088\u3046\u306bPython\u3092\u5b9f\u884c\u3057\u3066\u30d1\u30b9\u3092\u53d6\u5f97\u3059\u308b\u3088\u3046\u306b\u3057\u3066\u3044\u307e\u3059\u304c\u3001\u30d1\u30b9\u3092\u30d9\u30bf\u66f8\u304d\u3057\u3066\u3057\u307e\u3063\u305f\u307b\u3046\u304c\u5b89\u5168\u304b\u3082\u3057\u308c\u307e\u305b\u3093\u3002\n\n```\n...\nPYTHON_INCLUDE := $(dir $(shell python -c 'import os; print(os.__file__).replace(\"lib\", \"include\")'))\nPYTHON_INCLUDE += $(dir $(shell python -c 'import numpy.core; print(numpy.core.__file__)'))/include\n...\nPYTHON_LIB := $(dir $(dir $(shell python -c 'import os; print(os.__file__)')))\n```\n\npyenv \u3084 virtualenv \u3092\u5229\u7528\u3057\u3066\u3044\u3066\u30a8\u30e9\u30fc\u304c\u51fa\u308b\u5834\u5408\u306f\u3001 libboost_python.dylib \u3084 _caffe.so \u304c\u9069\u5207\u306aPython\u5171\u6709\u30e9\u30a4\u30d6\u30e9\u30ea (libpythonx.x.dylib) \u3092\u898b\u3066\u3044\u308b\u304b\u78ba\u8a8d\u3057\u3066\u4e0b\u3055\u3044\u3002\u78ba\u8a8d\u306b\u306f otool \u304c\u4f7f\u3048\u307e\u3059\u3002\n\n```bash\n$ otool -L /usr/local/Cellar/boost-python/1.57.0/lib/libboost_python.dylib\n/usr/local/Cellar/boost-python/1.57.0/lib/libboost_python.dylib:\n\t/usr/local/lib/libboost_python.dylib (compatibility version 0.0.0, current version 0.0.0)\n\t/Users/xxx/.pyenv/versions/2.7.9/lib/libpython2.7.dylib (compatibility version 2.7.0, current version 2.7.0)\n\t/usr/lib/libc++.1.dylib (compatibility version 1.0.0, current version 120.0.0)\n\t/usr/lib/libSystem.B.dylib (compatibility version 1.0.0, current version 1213.0.0)\n```\n\n## Caffe \u3067 MNIST\n\n### MNIST\u30c7\u30fc\u30bf\u306e\u30c0\u30f3\u30ed\u30fc\u30c9\u30fb\u5909\u63db\n\nCaffe \u306b\u306f\u3001MNIST \u3092\u30c0\u30a6\u30f3\u30ed\u30fc\u30c9\u3057\u3001Caffe\u306e\u53d6\u308a\u6271\u3048\u308b\u5f62\u5f0f\u306b\u5909\u63db\u3059\u308b\u30b9\u30af\u30ea\u30d7\u30c8\u304c\u542b\u307e\u308c\u3066\u3044\u307e\u3059\u306e\u3067\u3001\u4eca\u56de\u306f\u305d\u3061\u3089\u3092\u5229\u7528\u3057\u307e\u3059\u3002\n\u4ee5\u4e0b\u306e\u30b3\u30de\u30f3\u30c9\u306f caffe \u30c7\u30a3\u30ec\u30af\u30c8\u30ea\u76f4\u4e0b\u3067\u5b9f\u884c\u3057\u307e\u3059\u3002\n\n```bash\n$ data/mnist/get_mnist.sh\n$ examples/mnist/create_mnist.sh\n```\n### \u8a2d\u5b9a\u30d5\u30a1\u30a4\u30eb\u4f5c\u6210\n\n\u30cd\u30c3\u30c8\u30ef\u30fc\u30af\u306e\u8a2d\u5b9a\u3084\u3001\u5b66\u7fd2\u65b9\u6cd5\u306e\u8a2d\u5b9a\u306f\u4ee5\u4e0b\u306e\u3088\u3046\u306b\u8a2d\u5b9a\u3057\u307e\u3059\u3002\u5185\u5bb9\u306f\u4f55\u3068\u306a\u304f\u5206\u304b\u308b\u304b\u3068\u601d\u3044\u307e\u3059\u304c\u3001\u304d\u3061\u3093\u3068\u3057\u305f\u7406\u89e3\u306b\u306f[\u30aa\u30d5\u30a3\u30b7\u30e3\u30eb\u306e\u30c1\u30e5\u30fc\u30c8\u30ea\u30a2\u30eb](http://caffe.berkeleyvision.org/tutorial/)\u3084[\u6771\u90a6\u5927\u5b66\u30fb\u5c71\u5185\u5148\u751f\u306e\u30da\u30fc\u30b8](http://pepper.is.sci.toho-u.ac.jp/index.php?%A5%CE%A1%BC%A5%C8%2FCaffe%A4%CE%A5%E2%A5%B8%A5%E5%A1%BC%A5%EB%B5%AD%BD%D2%C8%B4%BF%E8%A1%CAcaffe.prototxt%A1%CB) \u304c\u5f79\u306b\u7acb\u3061\u307e\u3059\u3002\n\n\u6ce8\u610f\u3057\u306a\u3044\u3068\u3044\u3051\u306a\u3044\u306e\u306f\u3001\u30cd\u30c3\u30c8\u30ef\u30fc\u30af\u306e\u8a2d\u5b9a\u30d5\u30a1\u30a4\u30eb\u306e weight_filter \u3067\u3059\u3002\u3053\u3053\u3067\u30cd\u30c3\u30c8\u30ef\u30fc\u30af\u306e\u91cd\u307f\u306e\u521d\u671f\u5316\u65b9\u6cd5\u3092\u8a2d\u5b9a\u3057\u3066\u3044\u308b\u306e\u3067\u3059\u304c\u3001\u3053\u3061\u3089\u3092\u304d\u3061\u3093\u3068\u6307\u5b9a\u3057\u306a\u3044\u3068\u53ce\u675f\u3057\u307e\u305b\u3093\u3002\n\nmnist_solver.prototxt (\u5b66\u7fd2\u65b9\u6cd5\u306e\u8a2d\u5b9a)\n\n```\nnet: \"mnist.prototxt\" # \u30cd\u30c3\u30c8\u30ef\u30fc\u30af\u306e\u8a2d\u5b9a\u30d5\u30a1\u30a4\u30eb\ntest_iter: 100 # \u30c6\u30b9\u30c8\u3067\u306e\u7e70\u308a\u8fd4\u3057(batch)\u56de\u6570\ntest_interval: 1000 # \u30c6\u30b9\u30c8\u306e\u9593\u9694\ntest_compute_loss: true\nbase_lr: 0.01 # \u5b66\u7fd2\u7387\u306e\u521d\u671f\u5024\nlr_policy: \"inv\" # \u5b66\u7fd2\u7387\u3092\u5c0f\u3055\u304f\u3059\u308b\u30dd\u30ea\u30b7\u30fc\ndisplay: 100 # \u753b\u9762\u306b\u60c5\u5831\u3092\u8868\u793a\u3059\u308b\u9593\u9694\nmax_iter: 65000 # \u7e70\u308a\u8fd4\u3057(batch)\u56de\u6570\nsolver_type: 2 # \u6700\u9069\u5316\u624b\u6cd5 (2: AdaGrad)\nsolver_mode: CPU # CPU \u3082\u3057\u304f\u306f GPU\n```\n\nmnist.prototxt (\u5b66\u7fd2\u6642\u306e\u30cd\u30c3\u30c8\u30ef\u30fc\u30af\u8a2d\u5b9a)\n\n```\nname: \"MNIST\"\nlayer {\n  name: \"mnist\"\n  type: \"Data\"\n  top: \"data\"\n  top: \"label\"\n  include {\n    phase: TRAIN\n  }\n  transform_param {\n    scale: 0.00390625\n  }\n  data_param {\n    source: \"examples/mnist/mnist_train_lmdb\"\n    batch_size: 128 \n    backend: LMDB\n  }\n}\nlayer {\n  name: \"mnist\"\n  type: \"Data\"\n  top: \"data\"\n  top: \"label\"\n  include {\n    phase: TEST\n  }\n  transform_param {\n    scale: 0.00390625\n  }\n  data_param {\n    source: \"examples/mnist/mnist_test_lmdb\"\n    batch_size: 128\n    backend: LMDB\n  }\n}\nlayer {\n  name: \"ip1\"\n  type: \"InnerProduct\"\n  bottom: \"data\"\n  top: \"ip1\"\n  param {\n    lr_mult: 1\n  }\n  param {\n    lr_mult: 2\n  }\n  inner_product_param {\n    num_output: 128 \n    weight_filler {\n      type: \"xavier\"\n    }\n  }\n}\nlayer {\n  name: \"relu1\"\n  type: \"ReLU\"\n  bottom: \"ip1\"\n  top: \"ip1\"\n}\nlayer {\n  name: \"drop1\"\n  type: \"Dropout\"\n  bottom: \"ip1\"\n  top: \"ip1\"\n  dropout_param {\n    dropout_ratio: 0.25\n  }\n}\nlayer {\n  name: \"ip2\"\n  type: \"InnerProduct\"\n  bottom: \"ip1\"\n  top: \"ip2\"\n  param {\n    lr_mult: 1\n  }\n  param {\n    lr_mult: 2\n  }\n  inner_product_param {\n    num_output: 128\n    weight_filler {\n      type: \"xavier\"\n    }\n  }\n}\nlayer {\n  name: \"relu2\"\n  type: \"ReLU\"\n  bottom: \"ip2\"\n  top: \"ip2\"\n}\nlayer {\n  name: \"drop2\"\n  type: \"Dropout\"\n  bottom: \"ip2\"\n  top: \"ip2\"\n  dropout_param {\n    dropout_ratio: 0.25\n  }\n} \nlayer {\n  name: \"ip3\"\n  type: \"InnerProduct\"\n  bottom: \"ip2\"\n  top: \"ip3\"\n  param {\n    lr_mult: 1\n  }\n  param {\n    lr_mult: 2\n  }\n  inner_product_param {\n    num_output: 10\n    weight_filler {\n      type: \"xavier\"\n    }\n  }\n}\nlayer {\n  name: \"accuracy\"\n  type: \"Accuracy\"\n  bottom: \"ip3\"\n  bottom: \"label\"\n  top: \"accuracy\"\n  include {\n    phase: TEST\n  }\n}\nlayer {\n  name: \"loss\"\n  type: \"SoftmaxWithLoss\"\n  bottom: \"ip3\"\n  bottom: \"label\"\n  top: \"loss\"\n}\n```\n\nmnist_deploy.prototxt (\u4e88\u6e2c\u6642\u306e\u30cd\u30c3\u30c8\u30ef\u30fc\u30af\u8a2d\u5b9a)\n\u57fa\u672c\u7684\u306b mnisit.prototxt \u3068\u540c\u3058\u3067\u3059\u304c\u3001 Data \u30ec\u30a4\u30e4\u30fc\u304c\u306a\u304f\u306a\u3063\u3066\u3001\u4ee3\u308f\u308a\u306b input \u3092\u6307\u5b9a\u3057\u3066\u3044\u307e\u3059\u3002\u307e\u305f\u3001\u51fa\u529b\u3082 accuracy \u304c\u306a\u304f\u306a\u308a\u3001 SoftmaxWithLoss \u304c Softmax \u306b\u304b\u308f\u3063\u3066\u3044\u307e\u3059\u3002\n\n```\nname: \"MNIST\"\ninput: \"data\"\ninput_dim: 10 # \u30d0\u30c3\u30c1\u30b5\u30a4\u30ba\ninput_dim: 1 # \u753b\u50cf\u30c1\u30e3\u30cd\u30eb\u6570(\u30e2\u30ce\u30af\u30ed\u306a\u306e\u30671)\ninput_dim: 28 # \u753b\u50cf\u30b5\u30a4\u30ba(y)\ninput_dim: 28 # \u753b\u50cf\u30b5\u30a4\u30ba(x)\nlayer {\n  name: \"ip1\"\n  type: \"InnerProduct\"\n  bottom: \"data\"\n  top: \"ip1\"\n  param {\n    lr_mult: 1\n  }\n  param {\n    lr_mult: 2\n  }\n  inner_product_param {\n    num_output: 128 \n    weight_filler {\n      type: \"xavier\"\n    }\n  }\n}\nlayer {\n  name: \"relu1\"\n  type: \"ReLU\"\n  bottom: \"ip1\"\n  top: \"ip1\"\n}\nlayer {\n  name: \"drop1\"\n  type: \"Dropout\"\n  bottom: \"ip1\"\n  top: \"ip1\"\n  dropout_param {\n    dropout_ratio: 0.25\n  }\n}\nlayer {\n  name: \"ip2\"\n  type: \"InnerProduct\"\n  bottom: \"ip1\"\n  top: \"ip2\"\n  param {\n    lr_mult: 1\n  }\n  param {\n    lr_mult: 2\n  }\n  inner_product_param {\n    num_output: 128\n    weight_filler {\n      type: \"xavier\"\n    }\n  }\n}\nlayer {\n  name: \"relu2\"\n  type: \"ReLU\"\n  bottom: \"ip2\"\n  top: \"ip2\"\n}\nlayer {\n  name: \"drop2\"\n  type: \"Dropout\"\n  bottom: \"ip2\"\n  top: \"ip2\"\n  dropout_param {\n    dropout_ratio: 0.25\n  }\n} \nlayer {\n  name: \"ip3\"\n  type: \"InnerProduct\"\n  bottom: \"ip2\"\n  top: \"ip3\"\n  param {\n    lr_mult: 1\n  }\n  param {\n    lr_mult: 2\n  }\n  inner_product_param {\n    num_output: 10\n    weight_filler {\n      type: \"xavier\"\n    }\n  }\n}\nlayer {\n  name: \"prob\"\n  type: \"Softmax\"\n  bottom: \"ip3\"\n  top: \"prob\"\n}\n```\n\n\n### \u5b66\u7fd2\n\ncaffe \u30b3\u30de\u30f3\u30c9\u3092\u4f7f\u3063\u3066\u5b66\u7fd2\u3057\u307e\u3059\u3002caffe\u30b3\u30de\u30f3\u30c9\u306f build/tools/ \u4ee5\u4e0b\u306b\u3042\u308a\u307e\u3059\u3002\n\n```bash\n$ build/tools/caffe train -solver mnist_solver.prototxt\n```\n\n\u5b66\u7fd2\u7d50\u679c\u306f\u3001\u30c7\u30d5\u30a9\u30eb\u30c8\u3067\u306f\u30ab\u30ec\u30f3\u30c8\u30c7\u30a3\u30ec\u30af\u30c8\u30ea\u306b *.caffemodel \u3068\u3044\u3046\u30d5\u30a1\u30a4\u30eb\u540d\u3067\u4fdd\u5b58\u3055\u308c\u307e\u3059\u3002\n\n```bash\n$ ls *.caffemodel\n_iter_65000.caffemodel\n```\n\n### \u4e88\u6e2c\n\n\u3053\u3053\u3067\u306f pycaffe \u3092\u4f7f\u3063\u3066\u4e88\u6e2c\u3057\u307e\u3059\u3002\n\n```py\n#!/usr/bin/env python\n# -*- coding:utf-8 -*-\n\nimport struct\n\nimport caffe\nimport numpy as np\n\nMNIST_DATA_PATH = 'data/mnist/t10k-images-idx3-ubyte'\nPROTO_PATH = 'mnist_deploy.prototxt'\nMODEL_PATH = '_iter_65000.caffemodel'\n\n\ndef load_image(fp):\n    header = fp.read(16)\n    contents = fp.read()\n    magic, n_images, row, col = struct.unpack('>4i', header)\n    assert(magic == 2051)\n    images = np.array(\n        struct.unpack('>%dB' % len(contents), contents),\n        dtype=np.float64).reshape(n_images, row, col, 1)\n    return images/256 # \u5024\u304c [0, 1] \u3068\u306a\u308b\u3088\u3046\u5909\u63db\n\n\nwith open(MNIST_DATA_PATH) as i_:\n    images = load_image(i_)\n\nnet = caffe.Classifier(\n    PROTO_PATH,\n    MODEL_PATH,\n    image_dims=images.shape[1:]\n)\n\nnet.predict(images)\n```\n\n\u3075\u3046\u3063\u3001\u3068\u3044\u3063\u305f\u611f\u3058\u3067\u3059\u306d\u3002\n\n\n# DeepLearning4J\n\nDeepLearning4J \u306f Skymind\u793e\u304c\u63d0\u4f9b\u3059\u308b\u3001 Java\u88fd\u306e\u6df1\u5c64\u5b66\u7fd2\u30e9\u30a4\u30d6\u30e9\u30ea\u3067\u3059\u3002maven\u30ea\u30dd\u30b8\u30c8\u30ea\u306b\u3082\u767b\u9332\u3055\u308c\u3066\u3044\u3066\u74b0\u5883\u69cb\u7bc9\u306f\u975e\u5e38\u306b\u7c21\u5358\u3067\u3059\u3002\n\n## DeepLearning4J \u306e\u30a4\u30f3\u30b9\u30c8\u30fc\u30eb\n\nmaven \u304c\u5165\u3063\u3066\u3044\u308b\u3053\u3068\u3092\u524d\u63d0\u3068\u3057\u307e\u3059\u3002\u307e\u305a\u306f\u30d7\u30ed\u30b8\u30a7\u30af\u30c8\u3092\u4f5c\u6210\u3057\u307e\u3057\u3087\u3046\u3002\n\n```bash\n$ mvn archetype:generate -DarchetypeArtifactId=maven-archetype-quickstart\n```\n\n\u9014\u4e2d\u3067 groupId \u3084 artifactId \u306a\u3069\u3092\u805e\u304b\u308c\u308b\u306e\u3067\u3001\u9069\u5f53\u306b\u7b54\u3048\u307e\u3059\u3002(\u4f8b: groupId: mygroup artifactId: dl4jtest)\nmaven \u30b3\u30de\u30f3\u30c9\u304c\u7d42\u4e86\u3059\u308b\u3068\u3001\u30d7\u30ed\u30b8\u30a7\u30af\u30c8\u30c7\u30a3\u30ec\u30af\u30c8\u30ea\u304c\u3067\u304d\u308b\u3066\u3044\u308b\u306e\u3067\u3001\u305d\u3061\u3089\u306b\u79fb\u52d5\u3057\u3001 pom.xml \u3092\u7de8\u96c6\u3057\u307e\u3059\u3002\n\n```bash\n$ cd dl4jtest\n$ vi pom.xml\n```\n\n```xml\n\n```\n\n# Mocha\n\n[Mocha](https://github.com/pluskid/Mocha.jl) \u306f\u9ad8\u901f\u306a\u79d1\u5b66\u8a08\u7b97\u8a00\u8a9e [Julia](http://julialang.org/) \u306e DeepLearning \u7528\u30d1\u30c3\u30b1\u30fc\u30b8\u3067\u3059\u3002\nJulia \u304c\u30a4\u30f3\u30b9\u30c8\u30fc\u30eb\u3055\u308c\u3066\u3044\u308c\u3070\u3001Mocha \u306e\u30a4\u30f3\u30b9\u30c8\u30fc\u30eb\u306f\u7c21\u5358\u3067\u3001\n\n```jl\nPkg.add(\"Mocha\")\n```\n\n\u3068\u3059\u308b\u3060\u3051\u3067\u3059\u3002\u6700\u65b0\u7248\u3092\u4f7f\u3044\u305f\u3044\u5834\u5408\u306f\n\n```jl\nPkg.clone(\"https://github.com/pluskid/Mocha.jl.git\")\n```\n\n\u3068\u3057\u307e\u3059\u3002\n\n### \u5b66\u7fd2\n\n```jl\nuse_gpu = true\n\nif use_gpu\n  ENV[\"MOCHA_USE_CUDA\"] = \"true\"\nelse\n  ENV[\"MOCHA_USE_NATIVE_EXT\"] = \"true\"\n  ENV[\"OMP_NUM_THREADS\"] = 1\n  blas_set_num_threads(1)\nend\n\nusing Mocha\nsrand(12345678)\n\ndata_layer  = AsyncHDF5DataLayer(name=\"train-data\", source=\"data/train.txt\", batch_size=64, shuffle=true)\nconv_layer  = ConvolutionLayer(name=\"conv1\", n_filter=20, kernel=(5,5), bottoms=[:data], tops=[:conv])\npool_layer  = PoolingLayer(name=\"pool1\", kernel=(2,2), stride=(2,2), bottoms=[:conv], tops=[:pool])\nconv2_layer = ConvolutionLayer(name=\"conv2\", n_filter=50, kernel=(5,5), bottoms=[:pool], tops=[:conv2])\npool2_layer = PoolingLayer(name=\"pool2\", kernel=(2,2), stride=(2,2), bottoms=[:conv2], tops=[:pool2])\nfc1_layer   = InnerProductLayer(name=\"ip1\", output_dim=500, neuron=Neurons.ReLU(), bottoms=[:pool2], tops=[:ip1])\nfc2_layer   = InnerProductLayer(name=\"ip2\", output_dim=10, bottoms=[:ip1], tops=[:ip2])\nloss_layer  = SoftmaxLossLayer(name=\"loss\", bottoms=[:ip2,:label])\n\nbackend = use_gpu ? GPUBackend() : CPUBackend()\ninit(backend)\n\ncommon_layers = [conv_layer, pool_layer, conv2_layer, pool2_layer, fc1_layer, fc2_layer]\nnet = Net(\"MNIST-train\", backend, [data_layer, common_layers..., loss_layer])\n\nexp_dir = \"snapshots$(use_gpu ? \"-gpu\" : \"-cpu\")\"\n\nparams = SolverParameters(max_iter=10000, regu_coef=0.0005,\n    mom_policy=MomPolicy.Fixed(0.9),\n    lr_policy=LRPolicy.Inv(0.01, 0.0001, 0.75),\n    load_from=exp_dir)\nsolver = SGD(params)\n\nsetup_coffee_lounge(solver, save_into=\"$exp_dir/statistics.jld\", every_n_iter=1000)\n\n# report training progress every 100 iterations\nadd_coffee_break(solver, TrainingSummary(), every_n_iter=100)\n\n# save snapshots every 5000 iterations\nadd_coffee_break(solver, Snapshot(exp_dir), every_n_iter=5000)\n\n# show performance on test data every 1000 iterations\ndata_layer_test = HDF5DataLayer(name=\"test-data\", source=\"data/test.txt\", batch_size=100)\nacc_layer = AccuracyLayer(name=\"test-accuracy\", bottoms=[:ip2, :label])\ntest_net = Net(\"MNIST-test\", backend, [data_layer_test, common_layers..., acc_layer])\nadd_coffee_break(solver, ValidationPerformance(test_net), every_n_iter=1000)\n\nsolve(solver, net)\n\n#Profile.init(int(1e8), 0.001)\n#@profile solve(solver, net)\n#open(\"profile.txt\", \"w\") do out\n#  Profile.print(out)\n#end\n\ndestroy(net)\ndestroy(test_net)\nshutdown(backend)\n```\n\n", "tags": ["DeepLearning", "Keras", "\u6df1\u5c64\u5b66\u7fd2", "\u6a5f\u68b0\u5b66\u7fd2", "Theano"]}