{"context": "\n\n\u76ee\u7684\niOS\u6a19\u6e96\u306e\u30ab\u30e1\u30e9\u3068\u540c\u3058\u3001\u30d4\u30f3\u30c1\u30a4\u30f3\u30fb\u30d4\u30f3\u30c1\u30a2\u30a6\u30c8\u306b\u3088\u308b\u30ba\u30fc\u30e0\u6a5f\u80fd\u3084\u30bf\u30c3\u30d7\u306b\u3088\u308b\u30d4\u30f3\u30c8\u8abf\u7bc0\u3092\u6301\u3064\u7121\u97f3\u30ab\u30e1\u30e9\u306e\u5b9f\u88c5\n\n\u30b3\u30fc\u30c9\nimport UIKit\nimport AVFoundation\n\nclass CameraViewController: UIViewController, AVCaptureVideoDataOutputSampleBufferDelegate, UIGestureRecognizerDelegate  {\n\n    var input:AVCaptureDeviceInput!\n    var output:AVCaptureVideoDataOutput!\n    var session:AVCaptureSession!\n    var camera:AVCaptureDevice!\n    var imageView:UIImageView!\n\n    override func viewDidLoad() {\n        super.viewDidLoad()\n\n        // \u753b\u9762\u30bf\u30c3\u30d7\u3067\u30d4\u30f3\u30c8\u3092\u3042\u308f\u305b\u308b\n        let tapGesture = UITapGestureRecognizer(target: self, action: #selector(CameraViewController.tappedScreen(_:)))\n        let pinchGesture = UIPinchGestureRecognizer(target: self, action: #selector(CameraViewController.pinchedGesture(_:)))\n\n        // \u30c7\u30ea\u30b2\u30fc\u30c8\u3092\u30bb\u30c3\u30c8\n        tapGesture.delegate = self\n\n        // View\u306b\u30bf\u30c3\u30d7\u3001\u30d4\u30f3\u30c1\u306e\u30b8\u30a7\u30b9\u30c1\u30e3\u30fc\u3092\u8ffd\u52a0\n        self.view.addGestureRecognizer(tapGesture)\n        self.view.addGestureRecognizer(pinchGesture)\n\n        let underView = UIView(frame: CGRect(origin: CGPointZero, size: CGSize(width: self.view.frame.size.width, height:self.view.frame.size.height/8)))\n        underView.center = CGPoint(x: self.view.frame.size.width/2, y: self.view.frame.size.height-underView.frame.size.height/2)\n        underView.backgroundColor = UIColor.blackColor().colorWithAlphaComponent(0.4)\n        self.view.addSubview(underView)\n\n        let shutterButton = UIButton(frame: CGRect(origin: CGPointZero, size: CGSize(width: underView.frame.size.height-15, height: underView.frame.size.height-15)))\n        shutterButton.center = CGPoint(x: underView.frame.size.width/2, y: underView.frame.size.height/2)\n        shutterButton.backgroundColor = UIColor.whiteColor().colorWithAlphaComponent(0)\n        shutterButton.layer.masksToBounds = true\n        shutterButton.layer.cornerRadius = shutterButton.frame.size.width/2\n        shutterButton.layer.borderColor = UIColor.whiteColor().CGColor\n        shutterButton.layer.borderWidth = 6\n        shutterButton.addTarget(self, action: #selector(tapedShutterButton(_:)), forControlEvents: .TouchUpInside)\n        underView.addSubview(shutterButton)\n\n        let shutterShadowView = UIView(frame: CGRect(origin: CGPointZero, size: CGSize(width: shutterButton.frame.size.height-18, height: shutterButton.frame.size.height-18)))\n        shutterShadowView.center = CGPoint(x: shutterButton.frame.size.width/2, y: shutterButton.frame.size.height/2)\n        shutterShadowView.backgroundColor = UIColor.whiteColor()\n        shutterShadowView.layer.masksToBounds = true\n        shutterShadowView.layer.cornerRadius = shutterShadowView.frame.size.width/2\n        // shutterShadowView.layer.borderColor = UIColor.blackColor().CGColor\n        // shutterShadowView.layer.borderWidth = 3\n        shutterShadowView.userInteractionEnabled = false\n        shutterButton.addSubview(shutterShadowView)\n\n        let closeButton = UIButton()\n        closeButton.setTitle(\"\u9589\u3058\u308b\", forState: .Normal)\n        closeButton.setTitleColor(UIColor.whiteColor(), forState: .Normal)\n        closeButton.sizeToFit()\n        closeButton.center = CGPoint(x: (underView.frame.size.width+shutterButton.center.x+shutterButton.frame.size.width/2)/2, y: underView.frame.size.height/2)\n        closeButton.addTarget(self, action: #selector(tapedCloseButton(_:)), forControlEvents: .TouchUpInside)\n        underView.addSubview(closeButton)\n    }\n\n    override func viewWillAppear(animated: Bool) {\n        // \u30b9\u30af\u30ea\u30fc\u30f3\u8a2d\u5b9a\n        setupDisplay()\n\n        // \u30ab\u30e1\u30e9\u306e\u8a2d\u5b9a\n        setupCamera()\n    }\n\n    // \u30e1\u30e2\u30ea\u89e3\u653e\n    override func viewDidDisappear(animated: Bool) {\n        // camera stop \u30e1\u30e2\u30ea\u89e3\u653e\n        session.stopRunning()\n\n        for output in session.outputs {\n            session.removeOutput(output as? AVCaptureOutput)\n        }\n\n        for input in session.inputs {\n            session.removeInput(input as? AVCaptureInput)\n        }\n\n        session = nil\n        camera = nil\n    }\n\n    func setupDisplay(){\n        //\u30b9\u30af\u30ea\u30fc\u30f3\u306e\u5e45\n        let screenWidth = UIScreen.mainScreen().bounds.size.width;\n        //\u30b9\u30af\u30ea\u30fc\u30f3\u306e\u9ad8\u3055\n        let screenHeight = UIScreen.mainScreen().bounds.size.height;\n\n        // \u30ab\u30e1\u30e9\u304b\u3089\u306e\u6620\u50cf\u3092\u6620\u3059imageView\u306e\u4f5c\u6210\n        if let iv = imageView {\n            //\u4ee5\u524d\u306eimageView\u304c\u3042\u308c\u3070\u5265\u304c\u3057\u3066\u304a\u304f\n            iv.removeFromSuperview()\n        }\n        imageView = UIImageView()\n        imageView.frame = CGRectMake(0.0, 0.0, screenWidth, screenHeight)\n        view.addSubview(imageView)\n        view.sendSubviewToBack(imageView)\n    }\n\n    func setupCamera(){\n        // AVCaptureSession: \u30ad\u30e3\u30d7\u30c1\u30e3\u306b\u95a2\u3059\u308b\u5165\u529b\u3068\u51fa\u529b\u306e\u7ba1\u7406\n        session = AVCaptureSession()\n\n        // sessionPreset: \u30ad\u30e3\u30d7\u30c1\u30e3\u30fb\u30af\u30aa\u30ea\u30c6\u30a3\u306e\u8a2d\u5b9a\n        session.sessionPreset = AVCaptureSessionPresetHigh\n\n        // AVCaptureDevice: \u30ab\u30e1\u30e9\u3084\u30de\u30a4\u30af\u306a\u3069\u306e\u30c7\u30d0\u30a4\u30b9\u3092\u8a2d\u5b9a\n        for caputureDevice: AnyObject in AVCaptureDevice.devices() {\n            // \u80cc\u9762\u30ab\u30e1\u30e9\u3092\u53d6\u5f97\n            if caputureDevice.position == AVCaptureDevicePosition.Back {\n                camera = caputureDevice as? AVCaptureDevice\n            }\n        }\n\n        // \u30ab\u30e1\u30e9\u304b\u3089\u306e\u5165\u529b\u30c7\u30fc\u30bf\n        do {\n            input = try AVCaptureDeviceInput(device: camera) as AVCaptureDeviceInput\n        } catch let error as NSError {\n            print(error)\n        }\n\n        // \u5165\u529b\u3092\u30bb\u30c3\u30b7\u30e7\u30f3\u306b\u8ffd\u52a0\n        if(session.canAddInput(input)) {\n            session.addInput(input)\n        }\n\n        // AVCaptureVideoDataOutput:\u52d5\u753b\u30d5\u30ec\u30fc\u30e0\u30c7\u30fc\u30bf\u3092\u51fa\u529b\u306b\u8a2d\u5b9a\n        output = AVCaptureVideoDataOutput()\n\n        // \u51fa\u529b\u3092\u30bb\u30c3\u30b7\u30e7\u30f3\u306b\u8ffd\u52a0\n        if(session.canAddOutput(output)) {\n            session.addOutput(output)\n        }\n\n        // \u30d4\u30af\u30bb\u30eb\u30d5\u30a9\u30fc\u30de\u30c3\u30c8\u3092 32bit BGR + A \u3068\u3059\u308b\n        output.videoSettings = [kCVPixelBufferPixelFormatTypeKey : Int(kCVPixelFormatType_32BGRA)]\n\n        // \u30d5\u30ec\u30fc\u30e0\u3092\u30ad\u30e3\u30d7\u30c1\u30e3\u3059\u308b\u305f\u3081\u306e\u30b5\u30d6\u30b9\u30ec\u30c3\u30c9\u7528\u306e\u30b7\u30ea\u30a2\u30eb\u30ad\u30e5\u30fc\u3092\u7528\u610f\n        output.setSampleBufferDelegate(self, queue: dispatch_get_main_queue())\n\n        output.alwaysDiscardsLateVideoFrames = true\n\n        session.startRunning()\n\n        // device\u3092\u30ed\u30c3\u30af\u3057\u3066\u8a2d\u5b9a\n        do {\n            try camera.lockForConfiguration()\n            // \u30d5\u30ec\u30fc\u30e0\u30ec\u30fc\u30c8\n            camera.activeVideoMinFrameDuration = CMTimeMake(1, 30)\n            camera.unlockForConfiguration()\n        } catch _ {\n        }\n    }\n\n\n    // \u65b0\u3057\u3044\u30ad\u30e3\u30d7\u30c1\u30e3\u306e\u8ffd\u52a0\u3067\u547c\u3070\u308c\u308b\n    func captureOutput(captureOutput: AVCaptureOutput!, didOutputSampleBuffer sampleBuffer: CMSampleBuffer!, fromConnection connection: AVCaptureConnection!) {\n\n        // \u30ad\u30e3\u30d7\u30c1\u30e3\u3057\u305fsampleBuffer\u304b\u3089UIImage\u3092\u4f5c\u6210\n        let image:UIImage = self.captureImage(sampleBuffer)\n\n        // \u30ab\u30e1\u30e9\u306e\u753b\u50cf\u3092\u753b\u9762\u306b\u8868\u793a\n        dispatch_async(dispatch_get_main_queue()) {\n            self.imageView.image = image\n        }\n    }\n\n    // sampleBuffer\u304b\u3089UIImage\u3092\u4f5c\u6210\n    func captureImage(sampleBuffer:CMSampleBufferRef) -> UIImage{\n\n        // Sampling Buffer\u304b\u3089\u753b\u50cf\u3092\u53d6\u5f97\n        let imageBuffer:CVImageBufferRef = CMSampleBufferGetImageBuffer(sampleBuffer)!\n\n        // pixel buffer \u306e\u30d9\u30fc\u30b9\u30a2\u30c9\u30ec\u30b9\u3092\u30ed\u30c3\u30af\n        CVPixelBufferLockBaseAddress(imageBuffer, 0)\n\n        let baseAddress:UnsafeMutablePointer<Void> = CVPixelBufferGetBaseAddressOfPlane(imageBuffer, 0)\n\n        let bytesPerRow:Int = CVPixelBufferGetBytesPerRow(imageBuffer)\n        let width:Int = CVPixelBufferGetWidth(imageBuffer)\n        let height:Int = CVPixelBufferGetHeight(imageBuffer)\n\n        // \u8272\u7a7a\u9593\n        let colorSpace:CGColorSpaceRef = CGColorSpaceCreateDeviceRGB()!\n\n        let newContext:CGContextRef = CGBitmapContextCreate(baseAddress, width, height, 8, bytesPerRow, colorSpace,  CGImageAlphaInfo.PremultipliedFirst.rawValue|CGBitmapInfo.ByteOrder32Little.rawValue)!\n\n        let imageRef:CGImageRef = CGBitmapContextCreateImage(newContext)!\n        let resultImage = UIImage(CGImage: imageRef, scale: 1.0, orientation: UIImageOrientation.Right)\n\n        return resultImage\n    }\n\n\n    // \u30bf\u30c3\u30d7\u30a4\u30d9\u30f3\u30c8.\n    func tapedShutterButton(sender: UIButton) {\n        takeStillPicture()\n\n        self.imageView.alpha = 0.4\n\n        UIView.animateWithDuration(0.5, animations: {\n            self.imageView.alpha = 1\n        })\n    }\n\n    func takeStillPicture(){\n        if var _:AVCaptureConnection? = output.connectionWithMediaType(AVMediaTypeVideo){\n            // \u30a2\u30eb\u30d0\u30e0\u306b\u8ffd\u52a0\n            UIImageWriteToSavedPhotosAlbum(self.imageView.image!, self, nil, nil)\n        }\n    }\n\n    func tapedCloseButton(sender: UIButton) {\n        print(\"Close\")\n\n        // \u524d\u306e\u753b\u9762\u306b\u623b\u308b\u3068\u304d\n        // self.dismissViewControllerAnimated(true, completion: nil)\n    }\n\n    let focusView = UIView()\n\n    func tappedScreen(gestureRecognizer: UITapGestureRecognizer) {\n        let tapCGPoint = gestureRecognizer.locationOfTouch(0, inView: gestureRecognizer.view)\n        focusView.frame.size = CGSize(width: 120, height: 120)\n        focusView.center = tapCGPoint\n        focusView.backgroundColor = UIColor.whiteColor().colorWithAlphaComponent(0)\n        focusView.layer.borderColor = UIColor.whiteColor().CGColor\n        focusView.layer.borderWidth = 2\n        focusView.alpha = 1\n        imageView.addSubview(focusView)\n\n        UIView.animateWithDuration(0.5, animations: {\n            self.focusView.frame.size = CGSize(width: 80, height: 80)\n            self.focusView.center = tapCGPoint\n            }, completion: { Void in\n                UIView.animateWithDuration(0.5, animations: {\n                    self.focusView.alpha = 0\n                })\n        })\n\n        self.focusWithMode(AVCaptureFocusMode.AutoFocus, exposeWithMode: AVCaptureExposureMode.AutoExpose, atDevicePoint: tapCGPoint, motiorSubjectAreaChange: true)\n    }\n\n    var oldZoomScale: CGFloat = 1.0\n\n    func pinchedGesture(gestureRecgnizer: UIPinchGestureRecognizer) {\n        do {\n            try camera.lockForConfiguration()\n            // \u30ba\u30fc\u30e0\u306e\u6700\u5927\u5024\n            let maxZoomScale: CGFloat = 6.0\n            // \u30ba\u30fc\u30e0\u306e\u6700\u5c0f\u5024\n            let minZoomScale: CGFloat = 1.0\n            // \u73fe\u5728\u306e\u30ab\u30e1\u30e9\u306e\u30ba\u30fc\u30e0\u5ea6\n            var currentZoomScale: CGFloat = camera.videoZoomFactor\n            // \u30d4\u30f3\u30c1\u306e\u5ea6\u5408\u3044\n            let pinchZoomScale: CGFloat = gestureRecgnizer.scale\n\n            // \u30d4\u30f3\u30c1\u30a2\u30a6\u30c8\u306e\u6642\u3001\u524d\u56de\u306e\u30ba\u30fc\u30e0\u306b\u4eca\u56de\u306e\u30ba\u30fc\u30e0-1\u3092\u6307\u5b9a\n            // \u4f8b: \u524d\u56de3.0, \u4eca\u56de1.2\u306e\u3068\u304d\u3001currentZoomScale=3.2\n            if pinchZoomScale > 1.0 {\n                currentZoomScale = oldZoomScale+pinchZoomScale-1\n            } else {\n                currentZoomScale = oldZoomScale-(1-pinchZoomScale)*oldZoomScale\n            }\n\n            // \u6700\u5c0f\u5024\u3088\u308a\u5c0f\u3055\u304f\u3001\u6700\u5927\u5024\u3088\u308a\u5927\u304d\u304f\u306a\u3089\u306a\u3044\u3088\u3046\u306b\u3059\u308b\n            if currentZoomScale < minZoomScale {\n                currentZoomScale = minZoomScale\n            }\n            else if currentZoomScale > maxZoomScale {\n                currentZoomScale = maxZoomScale\n            }\n\n            // \u753b\u9762\u304b\u3089\u6307\u304c\u96e2\u308c\u305f\u3068\u304d\u3001state\u304cEnded\u306b\u306a\u308b\u3002\n            if gestureRecgnizer.state == .Ended {\n                oldZoomScale = currentZoomScale\n            }\n\n            camera.videoZoomFactor = currentZoomScale\n            camera.unlockForConfiguration()\n        } catch {\n            // handle error\n            return\n        }\n    }\n\n    func focusWithMode(focusMode : AVCaptureFocusMode, exposeWithMode expusureMode :AVCaptureExposureMode, atDevicePoint point:CGPoint, motiorSubjectAreaChange monitorSubjectAreaChange:Bool) {\n\n        dispatch_async(dispatch_queue_create(\"session queue\", DISPATCH_QUEUE_SERIAL), {\n            let device : AVCaptureDevice = self.input.device\n\n            do {\n                try device.lockForConfiguration()\n                if(device.focusPointOfInterestSupported && device.isFocusModeSupported(focusMode)){\n                    device.focusPointOfInterest = point\n                    device.focusMode = focusMode\n                }\n                if(device.exposurePointOfInterestSupported && device.isExposureModeSupported(expusureMode)){\n                    device.exposurePointOfInterest = point\n                    device.exposureMode = expusureMode\n                }\n\n                device.subjectAreaChangeMonitoringEnabled = monitorSubjectAreaChange\n                device.unlockForConfiguration()\n\n            } catch let error as NSError {\n                print(error.debugDescription)\n            }\n\n        })\n    }\n\n    override func didReceiveMemoryWarning() {\n        super.didReceiveMemoryWarning()\n        // Dispose of any resources that can be recreated.\n    }\n}\n\n\n\u88dc\u8db3\n\u30ab\u30e1\u30e9\u306e\u30d4\u30f3\u30c1\u30a2\u30a6\u30c8\u3001\u30d4\u30f3\u30c1\u30a4\u30f3\u3067\u30ba\u30fc\u30e0\u3055\u305b\u308b\u6a5f\u80fd\u306e\u5b9f\u88c5\u306b\u6642\u9593\u304c\u304b\u304b\u3063\u3066\u3057\u307e\u3044\u307e\u3057\u305f\u3002\u4e00\u5ea6\u5206\u304b\u3063\u3066\u3057\u307e\u3046\u3068\u305d\u308c\u307b\u3069\u5927\u3057\u305f\u3053\u3068\u3067\u306f\u306a\u304b\u3063\u305f\u306e\u3067\u30e1\u30e2\n\u6307\u304c\uff12\u672c\u753b\u9762\u306b\u89e6\u308c\u305f\u6642\u70b9\u3067\u305d\u306e\u8ddd\u96e2\u3092\uff11\u3068\u3057\u307e\u3059\n\n\u6b21\u306b\u3001\u30d4\u30f3\u30c1\u30a2\u30a6\u30c8\uff08\u62e1\u5927)\u3057\u307e\u3059\u3002\u62e1\u5927\u3057\u305f\u5927\u304d\u3055\u306f\uff14\u3068\u306a\u308a\u307e\u3059\n\n\u305d\u3057\u3066\u3001\u6307\u3092\u96e2\u3057\u3082\u3046\u4e00\u5ea6\u540c\u3058\u3068\u3053\u308d\u306b\u3075\u308c\u308b\u3068\u3001\u305d\u306e\u8ddd\u96e2\u304c\uff11\u3068\u306a\u308a\u307e\u3059\n\n\u305d\u3057\u3066\u3001\u534a\u5206\u307b\u3069\u6307\u3092\u8fd1\u3065\u3051\u30d4\u30f3\u30c1\u30a4\u30f3(\u7e2e\u5c0f)\u3057\u307e\u3059\u3002\u7e2e\u5c0f\u3057\u305f\u5927\u304d\u3055\u306f0.5\u3068\u306a\u308a\u307e\u3059\u3002\n\n\u3053\u3053\u3067\u3001\u30d4\u30f3\u30c1\u3068\u30ba\u30fc\u30e0\u306e\u95a2\u4fc2\u3092\u8003\u3048\u308b\u3068\u3001\u6700\u521d\u306e\u62e1\u5927\u30671\u21924\u306b\u306a\u308a\u3001\u6307\u3092\u8a71\u3057\u305f\u5f8c\u306e\u7e2e\u5c0f\u3067\u534a\u5206\u7e2e\u3081\u305f\u306e\u30674\u21922\u306b\u306a\u308b\u3079\u304d\u3067\u3059\u3002\n\u3057\u304b\u3057\u3001\u6307\u3092\u96e2\u3057\u305f\u5f8c\u306e\u8ddd\u96e2\u306f\uff11\u306b\u306a\u3063\u3066\u3044\u308b\u306e\u3067\u7e2e\u5c0f\u3057\u305f\u5927\u304d\u3055\u306f0.5\u306b\u306a\u3063\u3066\u3044\u307e\u3059\u3002\n\u305d\u3053\u3067\u3001\u524d\u56de\uff08\u6307\u3092\u96e2\u3059\u524d)\u306e\u5927\u304d\u30554\u3092\u639b\u3051\u3066\u3084\u308b\u5fc5\u8981\u304c\u3042\u308a\u307e\u3059\u3002\n\u3088\u3063\u3066\n// 2 = 4-(1-0.5)*4\ncurrentZoomScale = oldZoomScale-(1-pinchZoomScale)*oldZoomScale\n\n\u3068\u3044\u3046\u98a8\u306b\u306a\u308a\u307e\u3059\u3002\n# \u76ee\u7684\niOS\u6a19\u6e96\u306e\u30ab\u30e1\u30e9\u3068\u540c\u3058\u3001\u30d4\u30f3\u30c1\u30a4\u30f3\u30fb\u30d4\u30f3\u30c1\u30a2\u30a6\u30c8\u306b\u3088\u308b\u30ba\u30fc\u30e0\u6a5f\u80fd\u3084\u30bf\u30c3\u30d7\u306b\u3088\u308b\u30d4\u30f3\u30c8\u8abf\u7bc0\u3092\u6301\u3064\u7121\u97f3\u30ab\u30e1\u30e9\u306e\u5b9f\u88c5\n\n# \u30b3\u30fc\u30c9\n```swift\nimport UIKit\nimport AVFoundation\n\nclass CameraViewController: UIViewController, AVCaptureVideoDataOutputSampleBufferDelegate, UIGestureRecognizerDelegate  {\n    \n    var input:AVCaptureDeviceInput!\n    var output:AVCaptureVideoDataOutput!\n    var session:AVCaptureSession!\n    var camera:AVCaptureDevice!\n    var imageView:UIImageView!\n    \n    override func viewDidLoad() {\n        super.viewDidLoad()\n        \n        // \u753b\u9762\u30bf\u30c3\u30d7\u3067\u30d4\u30f3\u30c8\u3092\u3042\u308f\u305b\u308b\n        let tapGesture = UITapGestureRecognizer(target: self, action: #selector(CameraViewController.tappedScreen(_:)))\n        let pinchGesture = UIPinchGestureRecognizer(target: self, action: #selector(CameraViewController.pinchedGesture(_:)))\n        \n        // \u30c7\u30ea\u30b2\u30fc\u30c8\u3092\u30bb\u30c3\u30c8\n        tapGesture.delegate = self\n        \n        // View\u306b\u30bf\u30c3\u30d7\u3001\u30d4\u30f3\u30c1\u306e\u30b8\u30a7\u30b9\u30c1\u30e3\u30fc\u3092\u8ffd\u52a0\n        self.view.addGestureRecognizer(tapGesture)\n        self.view.addGestureRecognizer(pinchGesture)\n        \n        let underView = UIView(frame: CGRect(origin: CGPointZero, size: CGSize(width: self.view.frame.size.width, height:self.view.frame.size.height/8)))\n        underView.center = CGPoint(x: self.view.frame.size.width/2, y: self.view.frame.size.height-underView.frame.size.height/2)\n        underView.backgroundColor = UIColor.blackColor().colorWithAlphaComponent(0.4)\n        self.view.addSubview(underView)\n        \n        let shutterButton = UIButton(frame: CGRect(origin: CGPointZero, size: CGSize(width: underView.frame.size.height-15, height: underView.frame.size.height-15)))\n        shutterButton.center = CGPoint(x: underView.frame.size.width/2, y: underView.frame.size.height/2)\n        shutterButton.backgroundColor = UIColor.whiteColor().colorWithAlphaComponent(0)\n        shutterButton.layer.masksToBounds = true\n        shutterButton.layer.cornerRadius = shutterButton.frame.size.width/2\n        shutterButton.layer.borderColor = UIColor.whiteColor().CGColor\n        shutterButton.layer.borderWidth = 6\n        shutterButton.addTarget(self, action: #selector(tapedShutterButton(_:)), forControlEvents: .TouchUpInside)\n        underView.addSubview(shutterButton)\n        \n        let shutterShadowView = UIView(frame: CGRect(origin: CGPointZero, size: CGSize(width: shutterButton.frame.size.height-18, height: shutterButton.frame.size.height-18)))\n        shutterShadowView.center = CGPoint(x: shutterButton.frame.size.width/2, y: shutterButton.frame.size.height/2)\n        shutterShadowView.backgroundColor = UIColor.whiteColor()\n        shutterShadowView.layer.masksToBounds = true\n        shutterShadowView.layer.cornerRadius = shutterShadowView.frame.size.width/2\n        // shutterShadowView.layer.borderColor = UIColor.blackColor().CGColor\n        // shutterShadowView.layer.borderWidth = 3\n        shutterShadowView.userInteractionEnabled = false\n        shutterButton.addSubview(shutterShadowView)\n        \n        let closeButton = UIButton()\n        closeButton.setTitle(\"\u9589\u3058\u308b\", forState: .Normal)\n        closeButton.setTitleColor(UIColor.whiteColor(), forState: .Normal)\n        closeButton.sizeToFit()\n        closeButton.center = CGPoint(x: (underView.frame.size.width+shutterButton.center.x+shutterButton.frame.size.width/2)/2, y: underView.frame.size.height/2)\n        closeButton.addTarget(self, action: #selector(tapedCloseButton(_:)), forControlEvents: .TouchUpInside)\n        underView.addSubview(closeButton)\n    }\n    \n    override func viewWillAppear(animated: Bool) {\n        // \u30b9\u30af\u30ea\u30fc\u30f3\u8a2d\u5b9a\n        setupDisplay()\n        \n        // \u30ab\u30e1\u30e9\u306e\u8a2d\u5b9a\n        setupCamera()\n    }\n    \n    // \u30e1\u30e2\u30ea\u89e3\u653e\n    override func viewDidDisappear(animated: Bool) {\n        // camera stop \u30e1\u30e2\u30ea\u89e3\u653e\n        session.stopRunning()\n        \n        for output in session.outputs {\n            session.removeOutput(output as? AVCaptureOutput)\n        }\n        \n        for input in session.inputs {\n            session.removeInput(input as? AVCaptureInput)\n        }\n        \n        session = nil\n        camera = nil\n    }\n    \n    func setupDisplay(){\n        //\u30b9\u30af\u30ea\u30fc\u30f3\u306e\u5e45\n        let screenWidth = UIScreen.mainScreen().bounds.size.width;\n        //\u30b9\u30af\u30ea\u30fc\u30f3\u306e\u9ad8\u3055\n        let screenHeight = UIScreen.mainScreen().bounds.size.height;\n        \n        // \u30ab\u30e1\u30e9\u304b\u3089\u306e\u6620\u50cf\u3092\u6620\u3059imageView\u306e\u4f5c\u6210\n        if let iv = imageView {\n            //\u4ee5\u524d\u306eimageView\u304c\u3042\u308c\u3070\u5265\u304c\u3057\u3066\u304a\u304f\n            iv.removeFromSuperview()\n        }\n        imageView = UIImageView()\n        imageView.frame = CGRectMake(0.0, 0.0, screenWidth, screenHeight)\n        view.addSubview(imageView)\n        view.sendSubviewToBack(imageView)\n    }\n    \n    func setupCamera(){\n        // AVCaptureSession: \u30ad\u30e3\u30d7\u30c1\u30e3\u306b\u95a2\u3059\u308b\u5165\u529b\u3068\u51fa\u529b\u306e\u7ba1\u7406\n        session = AVCaptureSession()\n        \n        // sessionPreset: \u30ad\u30e3\u30d7\u30c1\u30e3\u30fb\u30af\u30aa\u30ea\u30c6\u30a3\u306e\u8a2d\u5b9a\n        session.sessionPreset = AVCaptureSessionPresetHigh\n        \n        // AVCaptureDevice: \u30ab\u30e1\u30e9\u3084\u30de\u30a4\u30af\u306a\u3069\u306e\u30c7\u30d0\u30a4\u30b9\u3092\u8a2d\u5b9a\n        for caputureDevice: AnyObject in AVCaptureDevice.devices() {\n            // \u80cc\u9762\u30ab\u30e1\u30e9\u3092\u53d6\u5f97\n            if caputureDevice.position == AVCaptureDevicePosition.Back {\n                camera = caputureDevice as? AVCaptureDevice\n            }\n        }\n        \n        // \u30ab\u30e1\u30e9\u304b\u3089\u306e\u5165\u529b\u30c7\u30fc\u30bf\n        do {\n            input = try AVCaptureDeviceInput(device: camera) as AVCaptureDeviceInput\n        } catch let error as NSError {\n            print(error)\n        }\n        \n        // \u5165\u529b\u3092\u30bb\u30c3\u30b7\u30e7\u30f3\u306b\u8ffd\u52a0\n        if(session.canAddInput(input)) {\n            session.addInput(input)\n        }\n        \n        // AVCaptureVideoDataOutput\b:\u52d5\u753b\u30d5\u30ec\u30fc\u30e0\u30c7\u30fc\u30bf\u3092\u51fa\u529b\u306b\u8a2d\u5b9a\n        output = AVCaptureVideoDataOutput()\n        \n        // \u51fa\u529b\u3092\u30bb\u30c3\u30b7\u30e7\u30f3\u306b\u8ffd\u52a0\n        if(session.canAddOutput(output)) {\n            session.addOutput(output)\n        }\n        \n        // \u30d4\u30af\u30bb\u30eb\u30d5\u30a9\u30fc\u30de\u30c3\u30c8\u3092 32bit BGR + A \u3068\u3059\u308b\n        output.videoSettings = [kCVPixelBufferPixelFormatTypeKey : Int(kCVPixelFormatType_32BGRA)]\n        \n        // \u30d5\u30ec\u30fc\u30e0\u3092\u30ad\u30e3\u30d7\u30c1\u30e3\u3059\u308b\u305f\u3081\u306e\u30b5\u30d6\u30b9\u30ec\u30c3\u30c9\u7528\u306e\u30b7\u30ea\u30a2\u30eb\u30ad\u30e5\u30fc\u3092\u7528\u610f\n        output.setSampleBufferDelegate(self, queue: dispatch_get_main_queue())\n        \n        output.alwaysDiscardsLateVideoFrames = true\n        \n        session.startRunning()\n        \n        // device\u3092\u30ed\u30c3\u30af\u3057\u3066\u8a2d\u5b9a\n        do {\n            try camera.lockForConfiguration()\n            // \u30d5\u30ec\u30fc\u30e0\u30ec\u30fc\u30c8\n            camera.activeVideoMinFrameDuration = CMTimeMake(1, 30)\n            camera.unlockForConfiguration()\n        } catch _ {\n        }\n    }\n    \n    \n    // \u65b0\u3057\u3044\u30ad\u30e3\u30d7\u30c1\u30e3\u306e\u8ffd\u52a0\u3067\u547c\u3070\u308c\u308b\n    func captureOutput(captureOutput: AVCaptureOutput!, didOutputSampleBuffer sampleBuffer: CMSampleBuffer!, fromConnection connection: AVCaptureConnection!) {\n        \n        // \u30ad\u30e3\u30d7\u30c1\u30e3\u3057\u305fsampleBuffer\u304b\u3089UIImage\u3092\u4f5c\u6210\n        let image:UIImage = self.captureImage(sampleBuffer)\n        \n        // \u30ab\u30e1\u30e9\u306e\u753b\u50cf\u3092\u753b\u9762\u306b\u8868\u793a\n        dispatch_async(dispatch_get_main_queue()) {\n            self.imageView.image = image\n        }\n    }\n    \n    // sampleBuffer\u304b\u3089UIImage\u3092\u4f5c\u6210\n    func captureImage(sampleBuffer:CMSampleBufferRef) -> UIImage{\n        \n        // Sampling Buffer\u304b\u3089\u753b\u50cf\u3092\u53d6\u5f97\n        let imageBuffer:CVImageBufferRef = CMSampleBufferGetImageBuffer(sampleBuffer)!\n        \n        // pixel buffer \u306e\u30d9\u30fc\u30b9\u30a2\u30c9\u30ec\u30b9\u3092\u30ed\u30c3\u30af\n        CVPixelBufferLockBaseAddress(imageBuffer, 0)\n        \n        let baseAddress:UnsafeMutablePointer<Void> = CVPixelBufferGetBaseAddressOfPlane(imageBuffer, 0)\n        \n        let bytesPerRow:Int = CVPixelBufferGetBytesPerRow(imageBuffer)\n        let width:Int = CVPixelBufferGetWidth(imageBuffer)\n        let height:Int = CVPixelBufferGetHeight(imageBuffer)\n        \n        // \u8272\u7a7a\u9593\n        let colorSpace:CGColorSpaceRef = CGColorSpaceCreateDeviceRGB()!\n        \n        let newContext:CGContextRef = CGBitmapContextCreate(baseAddress, width, height, 8, bytesPerRow, colorSpace,  CGImageAlphaInfo.PremultipliedFirst.rawValue|CGBitmapInfo.ByteOrder32Little.rawValue)!\n        \n        let imageRef:CGImageRef = CGBitmapContextCreateImage(newContext)!\n        let resultImage = UIImage(CGImage: imageRef, scale: 1.0, orientation: UIImageOrientation.Right)\n        \n        return resultImage\n    }\n    \n    \n    // \u30bf\u30c3\u30d7\u30a4\u30d9\u30f3\u30c8.\n    func tapedShutterButton(sender: UIButton) {\n        takeStillPicture()\n        \n        self.imageView.alpha = 0.4\n        \n        UIView.animateWithDuration(0.5, animations: {\n            self.imageView.alpha = 1\n        })\n    }\n    \n    func takeStillPicture(){\n        if var _:AVCaptureConnection? = output.connectionWithMediaType(AVMediaTypeVideo){\n            // \u30a2\u30eb\u30d0\u30e0\u306b\u8ffd\u52a0\n            UIImageWriteToSavedPhotosAlbum(self.imageView.image!, self, nil, nil)\n        }\n    }\n    \n    func tapedCloseButton(sender: UIButton) {\n        print(\"Close\")\n        \n        // \u524d\u306e\u753b\u9762\u306b\u623b\u308b\u3068\u304d\n        // self.dismissViewControllerAnimated(true, completion: nil)\n    }\n    \n    let focusView = UIView()\n    \n    func tappedScreen(gestureRecognizer: UITapGestureRecognizer) {\n        let tapCGPoint = gestureRecognizer.locationOfTouch(0, inView: gestureRecognizer.view)\n        focusView.frame.size = CGSize(width: 120, height: 120)\n        focusView.center = tapCGPoint\n        focusView.backgroundColor = UIColor.whiteColor().colorWithAlphaComponent(0)\n        focusView.layer.borderColor = UIColor.whiteColor().CGColor\n        focusView.layer.borderWidth = 2\n        focusView.alpha = 1\n        imageView.addSubview(focusView)\n        \n        UIView.animateWithDuration(0.5, animations: {\n            self.focusView.frame.size = CGSize(width: 80, height: 80)\n            self.focusView.center = tapCGPoint\n            }, completion: { Void in\n                UIView.animateWithDuration(0.5, animations: {\n                    self.focusView.alpha = 0\n                })\n        })\n        \n        self.focusWithMode(AVCaptureFocusMode.AutoFocus, exposeWithMode: AVCaptureExposureMode.AutoExpose, atDevicePoint: tapCGPoint, motiorSubjectAreaChange: true)\n    }\n    \n    var oldZoomScale: CGFloat = 1.0\n    \n    func pinchedGesture(gestureRecgnizer: UIPinchGestureRecognizer) {\n        do {\n            try camera.lockForConfiguration()\n            // \u30ba\u30fc\u30e0\u306e\u6700\u5927\u5024\n            let maxZoomScale: CGFloat = 6.0\n            // \u30ba\u30fc\u30e0\u306e\u6700\u5c0f\u5024\n            let minZoomScale: CGFloat = 1.0\n            // \u73fe\u5728\u306e\u30ab\u30e1\u30e9\u306e\u30ba\u30fc\u30e0\u5ea6\n            var currentZoomScale: CGFloat = camera.videoZoomFactor\n            // \u30d4\u30f3\u30c1\u306e\u5ea6\u5408\u3044\n            let pinchZoomScale: CGFloat = gestureRecgnizer.scale\n            \n            // \u30d4\u30f3\u30c1\u30a2\u30a6\u30c8\u306e\u6642\u3001\u524d\u56de\u306e\u30ba\u30fc\u30e0\u306b\u4eca\u56de\u306e\u30ba\u30fc\u30e0-1\u3092\u6307\u5b9a\n            // \u4f8b: \u524d\u56de3.0, \u4eca\u56de1.2\u306e\u3068\u304d\u3001currentZoomScale=3.2\n            if pinchZoomScale > 1.0 {\n                currentZoomScale = oldZoomScale+pinchZoomScale-1\n            } else {\n                currentZoomScale = oldZoomScale-(1-pinchZoomScale)*oldZoomScale\n            }\n            \n            // \u6700\u5c0f\u5024\u3088\u308a\u5c0f\u3055\u304f\u3001\u6700\u5927\u5024\u3088\u308a\u5927\u304d\u304f\u306a\u3089\u306a\u3044\u3088\u3046\u306b\u3059\u308b\n            if currentZoomScale < minZoomScale {\n                currentZoomScale = minZoomScale\n            }\n            else if currentZoomScale > maxZoomScale {\n                currentZoomScale = maxZoomScale\n            }\n            \n            // \u753b\u9762\u304b\u3089\u6307\u304c\u96e2\u308c\u305f\u3068\u304d\u3001state\u304cEnded\u306b\u306a\u308b\u3002\n            if gestureRecgnizer.state == .Ended {\n                oldZoomScale = currentZoomScale\n            }\n            \n            camera.videoZoomFactor = currentZoomScale\n            camera.unlockForConfiguration()\n        } catch {\n            // handle error\n            return\n        }\n    }\n    \n    func focusWithMode(focusMode : AVCaptureFocusMode, exposeWithMode expusureMode :AVCaptureExposureMode, atDevicePoint point:CGPoint, motiorSubjectAreaChange monitorSubjectAreaChange:Bool) {\n        \n        dispatch_async(dispatch_queue_create(\"session queue\", DISPATCH_QUEUE_SERIAL), {\n            let device : AVCaptureDevice = self.input.device\n            \n            do {\n                try device.lockForConfiguration()\n                if(device.focusPointOfInterestSupported && device.isFocusModeSupported(focusMode)){\n                    device.focusPointOfInterest = point\n                    device.focusMode = focusMode\n                }\n                if(device.exposurePointOfInterestSupported && device.isExposureModeSupported(expusureMode)){\n                    device.exposurePointOfInterest = point\n                    device.exposureMode = expusureMode\n                }\n                \n                device.subjectAreaChangeMonitoringEnabled = monitorSubjectAreaChange\n                device.unlockForConfiguration()\n                \n            } catch let error as NSError {\n                print(error.debugDescription)\n            }\n            \n        })\n    }\n    \n    override func didReceiveMemoryWarning() {\n        super.didReceiveMemoryWarning()\n        // Dispose of any resources that can be recreated.\n    }\n}\n```\n\n# \u88dc\u8db3\n\u30ab\u30e1\u30e9\u306e\u30d4\u30f3\u30c1\u30a2\u30a6\u30c8\u3001\u30d4\u30f3\u30c1\u30a4\u30f3\u3067\u30ba\u30fc\u30e0\u3055\u305b\u308b\u6a5f\u80fd\u306e\u5b9f\u88c5\u306b\u6642\u9593\u304c\u304b\u304b\u3063\u3066\u3057\u307e\u3044\u307e\u3057\u305f\u3002\u4e00\u5ea6\u5206\u304b\u3063\u3066\u3057\u307e\u3046\u3068\u305d\u308c\u307b\u3069\u5927\u3057\u305f\u3053\u3068\u3067\u306f\u306a\u304b\u3063\u305f\u306e\u3067\u30e1\u30e2\n\n\u6307\u304c\uff12\u672c\u753b\u9762\u306b\u89e6\u308c\u305f\u6642\u70b9\u3067\u305d\u306e\u8ddd\u96e2\u3092\uff11\u3068\u3057\u307e\u3059\n![Artboard 1.png](https://qiita-image-store.s3.amazonaws.com/0/111677/e043c428-4947-de6e-c169-84ecebde71d8.png)\n\n\n\n\u6b21\u306b\u3001\u30d4\u30f3\u30c1\u30a2\u30a6\u30c8\uff08\u62e1\u5927)\u3057\u307e\u3059\u3002\u62e1\u5927\u3057\u305f\u5927\u304d\u3055\u306f\uff14\u3068\u306a\u308a\u307e\u3059\n![Artboard 2.png](https://qiita-image-store.s3.amazonaws.com/0/111677/9b464a04-74a1-5fd2-37f9-014070410dce.png)\n\n\n\u305d\u3057\u3066\u3001\u6307\u3092\u96e2\u3057\u3082\u3046\u4e00\u5ea6\u540c\u3058\u3068\u3053\u308d\u306b\u3075\u308c\u308b\u3068\u3001\u305d\u306e\u8ddd\u96e2\u304c\uff11\u3068\u306a\u308a\u307e\u3059\n![Artboard 3.png](https://qiita-image-store.s3.amazonaws.com/0/111677/371178e6-cefc-a99d-b227-c12ee21d473d.png)\n\n\n\u305d\u3057\u3066\u3001\u534a\u5206\u307b\u3069\u6307\u3092\u8fd1\u3065\u3051\u30d4\u30f3\u30c1\u30a4\u30f3(\u7e2e\u5c0f)\u3057\u307e\u3059\u3002\u7e2e\u5c0f\u3057\u305f\u5927\u304d\u3055\u306f0.5\u3068\u306a\u308a\u307e\u3059\u3002\n![Artboard 4.png](https://qiita-image-store.s3.amazonaws.com/0/111677/9ec3e9be-c7ec-ea53-19e7-e0825efd9def.png)\n\n\u3053\u3053\u3067\u3001\u30d4\u30f3\u30c1\u3068\u30ba\u30fc\u30e0\u306e\u95a2\u4fc2\u3092\u8003\u3048\u308b\u3068\u3001\u6700\u521d\u306e\u62e1\u5927\u30671\u21924\u306b\u306a\u308a\u3001\u6307\u3092\u8a71\u3057\u305f\u5f8c\u306e\u7e2e\u5c0f\u3067\u534a\u5206\u7e2e\u3081\u305f\u306e\u30674\u21922\u306b\u306a\u308b\u3079\u304d\u3067\u3059\u3002\n\u3057\u304b\u3057\u3001\u6307\u3092\u96e2\u3057\u305f\u5f8c\u306e\u8ddd\u96e2\u306f\uff11\u306b\u306a\u3063\u3066\u3044\u308b\u306e\u3067\u7e2e\u5c0f\u3057\u305f\u5927\u304d\u3055\u306f0.5\u306b\u306a\u3063\u3066\u3044\u307e\u3059\u3002\n\n\u305d\u3053\u3067\u3001\u524d\u56de\uff08\u6307\u3092\u96e2\u3059\u524d)\u306e\u5927\u304d\u30554\u3092\u639b\u3051\u3066\u3084\u308b\u5fc5\u8981\u304c\u3042\u308a\u307e\u3059\u3002\n\u3088\u3063\u3066\n\n```swift\n// 2 = 4-(1-0.5)*4\ncurrentZoomScale = oldZoomScale-(1-pinchZoomScale)*oldZoomScale\n```\n\n\u3068\u3044\u3046\u98a8\u306b\u306a\u308a\u307e\u3059\u3002\n\n\n\n\n\n\n", "tags": ["Swift", "iOS", "avfoundation"]}