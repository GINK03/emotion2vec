{"context": " More than 1 year has passed since last update.streamingAPI\u3063\u3066\u65e5\u672c\u8a9e\u306efiltering\u306b\u5bfe\u5fdc\u3057\u3066\u306a\u3044\u3057\u30011%\u7a0b\u5ea6\u306etweet\u3057\u304b\u62fe\u3048\u7121\u3044\u3057\u3001\u4f7f\u3044\u52dd\u624b\u304c\u3044\u307e\u3044\u3061\u3060\u306a\u3063\u3066\u601d\u3063\u3066\u3044\u308b\u4eba\u591a\u3044\u3068\u601d\u3044\u307e\u3059\u3002\u305d\u3093\u306astreamingAPI\u306e\u4f7f\u3044\u9053\u3063\u3066\u4f55\u304b\u306a\u3044\u304b\u306a\u30fc\u3063\u3066\u601d\u3063\u3066\u306a\u3093\u3068\u306a\u304f\u601d\u3044\u3064\u3044\u305f\u306e\u3067\u4f5c\u3063\u3066\u307f\u307e\u3057\u305f\u3002\n\n\u6e96\u5099\n\u5fc5\u8981\u306a\u306e\u306ftwitter\u306estreamingAPI\u304b\u3089\u53d6\u5f97\u3057\u305f10\u5206\u304a\u304d\u306e\u5358\u8a9e\u306e\u30ab\u30a6\u30f3\u30c8\u30c7\u30fc\u30bf\uff08sqlite\u306b\u683c\u7d0d\uff09\u306e\u307f\u3067\u3059\u3002DB\u306e\u30d5\u30a3\u30fc\u30eb\u30c9\u306fymd, hour, minute, word_dict, tweet_cnt\u3068\u3057\u307e\u3057\u305f\u3002\n\u305d\u308c\u305e\u308c\u3001\u5e74\u6708\u65e5('2014-06-01'), \u6642\u9593('22'), \u5206('10'(00\uff5e50\u307e\u3067\u306e10\u5206\u523b\u307f)), pickle\u3057\u305f\u8f9e\u66f8\u578b\u306e\u5358\u8a9e\u96c6\u5408, 10\u5206\u9593\u6bce\u306e\u30c4\u30a4\u30fc\u30c8\u6570\u3067\u3059\u3002\n\u4f5c\u3063\u305f\u3042\u3068\u3067\u601d\u3063\u305f\u3093\u3067\u3059\u304c\u3001DB\u306e\u8a2d\u8a08\u30df\u30b9\u308a\u307e\u3057\u305f\u3002\u5e74\u6708\u65e5\u3001\u6642\u9593\u3001\u5206\u3068\u304b\u5206\u3051\u308b\u610f\u5473\u3042\u3093\u307e\u308a\u306a\u304b\u3063\u305f\u3067\u3059\u306d\u3002\u3002\u30a2\u30db\u3084\u3063\u305f\u3068\u601d\u3063\u3066\u307e\u3059\u3001\u306f\u3044\u3002\ntwitterAPI\u306e\u4f7f\u3044\u65b9\u3068\u304b\u306ftwitter\u306e\u30c7\u30fc\u30bf\u3092SPAM\u3068HAM\u306b\u5206\u3051\u3066\u307f\u308b\u306b\u8a18\u8f09\u304c\u3042\u308b\u30da\u30fc\u30b8\u3092\u3054\u53c2\u7167\u304f\u3060\u3055\u3044\u3002\n\n\u3084\u3063\u305f\u4e8b\n\n10\u5206\u9593\u9694\u306e\u30c7\u30fc\u30bf\u309210\u5206\u4ee5\u4e0a\u306e\u6642\u9593\u3067\u518d\u96c6\u8a08\u3057\u305f\n\u518d\u96c6\u8a08\u3057\u305f\u6642\u9593\u9593\u9694\u306e\u4f55window\u304b\u5206\u306eTopN\u4ee5\u5185\u306e\u5358\u8a9e\u3068\u88ab\u308a\u306e\u7121\u3044\u5358\u8a9e\u3092\u62bd\u51fa\u3057\u305f\n\u540c\u3058\u4e8b\u3092\u91cf\u7684\u306b\u975e\u985e\u4f3c\u5ea6\u3068\u3057\u3066\u30b3\u30b5\u30a4\u30f3\u985e\u4f3c\u5ea6\u3067\u6570\u5024\u5316\u3057\u305f\uff082\u5024\u5316\u3057\u305f\u30c7\u30fc\u30bf\u3067\u985e\u4f3c\u5ea6\u3092\u6e2c\u3063\u3066\u3044\u307e\u3059\uff09\n\n\n\u53c2\u8003\u30b3\u30fc\u30c9\n# coding: utf-8\n\nimport sqlite3 as sqlite\nfrom collections import defaultdict\nimport cPickle as pickle\nimport copy\nimport matplotlib.pyplot as plt\nimport re, unicodedata\nfrom normalizewords import Replace # !!!!!\u3092!!!\u306b\u3059\u308b\u3068\u304b\u3001\u5927\u6587\u5b57\u5316\u3001\u5168\u89d2\u5316\u3068\u304b\nfrom math import floor, sqrt\n\nstopword = ('\u7d75\u6587\u5b57\u3068\u304b\u3001\u7528\u9014\u306b\u5408\u308f\u305b\u3066\u8a18\u8ff0\u3057\u3066\u304f\u3060\u3055\u3044',)\n\nclass DataCreater:\n    date = []\n    tweet_cnt = []\n    ex_words_store = []\n    now_words_store = []\n    new_break_words = set()\n    bin_cnt = 0\n    p = re.compile(\"[!-/:-@[-`{-~]\")\n\n    def __init__(self, dbname, word_limit, ofname, oftcntname,ofnewword,ofcos):\n        self.con = sqlite.connect(dbname)\n        self.word_limit = word_limit\n        self.ofword = open(ofname, 'w',1000)\n        self.oftcnt = open(oftcntname, 'w',1000)\n        self.ofnewwords = open(ofnewword,'w',1000)\n        self.ofcos = open(ofcos,'w',1000)\n\n    def __def__(self):\n        self.ofword.close()\n        self.oftcnt.close()\n        self.ofnewwords.close()\n        self.ofcos.close()\n\n    def re_aggregate(self,span,con_bin=10):\n        response = self.get_data_yeald()\n        itr, tweet_cnt, word_cnt = self.initiarize_cnt()\n        s_date = None\n        while 1:\n            res = response.fetchone()\n            if res is None: break\n\n            #print res[0]+', '+res[1]+', '+res[2]+', '+str(res[4])\n            tweet_cnt += int(res[4])\n            word_cnt = self.aggregate_word_cnt(pickle.loads(str(res[3])), word_cnt) \n\n            if itr==0:\n                s_date = res[0]+' '+res[1].zfill(2)+':'+res[2]\n\n            if itr == span-1:\n                date = res[0]+' '+res[1].zfill(2)+':'+res[2]\n                sorted_word_list = self.sort_word_dict(word_cnt)\n                self.output_topN_word(s_date, sorted_word_list)\n                self.output_tweet_cnt(s_date, tweet_cnt)\n                self.date.append(s_date)\n                self.tweet_cnt.append(tweet_cnt)\n                s_date = date                \n\n                self.bin_cnt += 1\n                self.store_now_dict(sorted_word_list[:self.word_limit])\n                print len(self.now_words_store)\n                if self.bin_cnt >= con_bin:\n                    if len(self.ex_words_store)!=0:\n                        self.store_new_words(sorted_word_list[:self.word_limit])\n                        cos_sim = self.calculate_cos_similarity(sorted_word_list[:self.word_limit])\n                        self.output_new_words(s_date)\n                        self.output_cos_sim(s_date,cos_sim)\n                        self.ex_words_store = copy.deepcopy( self.now_words_store )\n                        self.now_words_store.pop(0)\n                        self.new_break_words = set()\n                    else:\n                        self.ex_words_store = copy.deepcopy( self.now_words_store )\n                        self.now_words_store.pop(0)\n\n                itr, tweet_cnt, word_cnt = self.initiarize_cnt()\n            else:\n                itr += 1\n\n    def get_data_yeald(self, start_date=None, end_date=None):        \n        return self.con.execute(\"select ymd, hour, minute, word_dict,tweet_cnt from word_count\")            \n\n    def initiarize_cnt(self):\n        return 0, 0, defaultdict(int)\n\n    def aggregate_word_cnt(self, new_word_dic, orig_word_dic):\n        for k,v in new_word_dic.items():\n            if k not in stopword:\n                m = self.p.search(unicodedata.normalize('NFKC', unicode(k)))\n                if m is None:\n                    orig_word_dic[k] += v\n        return orig_word_dic\n\n    def sort_word_dict(self, word_dict):\n        lst = word_dict.items()\n        lst.sort(lambda p0,p1: cmp(p1[1],p0[1])) # get Top N data\n        return lst\n\n    def calculate_cos_similarity(self, sorted_wordlist):\n        ex_words =[]\n        now_word_list = []\n        for w_list in self.ex_words_store:\n            ex_words +=w_list  \n        for k,_ in sorted_wordlist:\n            now_word_list.append(k)\n        numerator = sum([1 for c in now_word_list if c in ex_words])\n        denominator =  sqrt(len(ex_words) * len(now_word_list))\n        return 1-float(numerator) / denominator if denominator != 0 else 1        \n\n    def output_topN_word(self, date, sorted_word_list):\n        if len(sorted_word_list) >=self.word_limit:\n            s_list = [ st[0]+':'+str(st[1]) for st in sorted_word_list[:self.word_limit]]\n            s = '\\t'.join(s_list)\n            self.ofword.write(date+'\\t'+s+'\\n')\n        else:\n            s_list = [ st[0]+':'+str(st[1]) for st in sorted_word_list[:self.word_limit]]\n            s = '\\t'.join(s_list)\n            self.ofword.write(date+'\\t'+s+'\\n')\n\n    def output_tweet_cnt(self, date, cnt):\n        s = date+'\\t'+str(cnt)\n        self.oftcnt.write(s+'\\n')\n\n    def output_new_words(self,date):\n        s = '\\t'.join(list(self.new_break_words))\n        print date, s\n        self.ofnewwords.write(date+'\\t'+s+'\\n')\n\n    def output_cos_sim(self, date, cos_sim):\n        self.ofcos.write(date+'\\t'+str(cos_sim)+'\\n')\n\n    def store_now_dict(self, sorted_wordlist):\n        words = [k for k,_ in sorted_wordlist]\n        self.now_words_store.append(words)\n\n    def store_new_words(self, sorted_wordlist):\n        ex_words =[]\n        for w_list in self.ex_words_store:\n            ex_words +=w_list  \n        for k,_ in sorted_wordlist:\n            if k not in ex_words:\n                self.new_break_words.add(k)\n\nif __name__=='__main__':\n    dbname = 'stream_word_cnt.db'\n    ofname = 'topN_words'\n    oftcnt = 'tweet_count'\n    ofnewword = 'new_word'\n    ofcos = 'cos_simularity'\n    word_top = 100 # top\u4f55\u30ef\u30fc\u30c9\u3092\u53d6\u5f97\u3059\u308b\u304b\n    span = 6 # 10\u5206\u5358\u4f4d\u306e\u30ab\u30a6\u30f3\u30c8\u4f55\u500b\u5206\u3092\u7d50\u5408\u3057\u3066\u518d\u96c6\u8a08\u3059\u308b\u304b\n\n    dc = DataCreater(dbname, word_top, ofname, oftcnt,ofnewword,ofcos)\n    dc.re_aggregate(span,con_bin=24) #con_bin\u306f\u985e\u4f3c\u5ea6\u3092\u6bd4\u8f03\u3059\u308bspan\u306e\u500b\u6570\n\n    tick = int(floor(len(dc.tweet_cnt)/7))\n\n    plt.plot(range(len(dc.tweet_cnt)), dc.tweet_cnt)\n    plt.xticks(range(0, len(dc.tweet_cnt), tick), dc.date[::tick], rotation=40)\n    plt.show()\n\n\n\u5b9f\u9a13\u7d50\u679c\n6\u670810\u65e5\u304f\u3089\u3044\u304b\u308925\u65e5\u307e\u3067\u8caf\u3081\u3066\u304a\u3044\u305f\u30c7\u30fc\u30bf\u304c\u3042\u3063\u305f\u306e\u3067\u305d\u308c\u3067\u5b9f\u9a13\u3057\u3066\u307f\u307e\u3057\u305f\u3002\n\u7d50\u679c\u306f\u30ef\u30fc\u30eb\u30c9\u30ab\u30c3\u30d7\u95a2\u4fc2\u306e\u30ef\u30fc\u30c9\u304c\u671d\u65b95\u6642\u304f\u3089\u3044\u306b\u3068\u308c\u305f\u308a\u300116\u65e5\u306b\u3042\u3063\u305f\u5730\u9707\u95a2\u4fc2\u306e\u30ef\u30fc\u30c9\u304c\u3068\u308c\u3066\u3044\u305f\u308a\u3001\u5927\u96e8\u306e\u65e5\u306b\u306f\u8c6a\u96e8\u3068\u304b\u3001\u96f7\u3068\u3044\u3046\u30ef\u30fc\u30c9\u304c\u62bd\u51fa\u3055\u308c\u307e\u3057\u305f\u3002\n\u3084\u3063\u3066\u308b\u4e8b\u306f\u975e\u5e38\u306b\u5358\u7d14\u306a\u3093\u3067\u3059\u304c\u3001\u4e2d\u3005\u826f\u3044\u611f\u3058\u306e\u30c7\u30fc\u30bf\u304c\u51fa\u307e\u3057\u305f\u3002\n\u30b3\u30b5\u30a4\u30f3\u985e\u4f3c\u5ea6\u3067\u7b97\u51fa\u3057\u305f\u975e\u985e\u4f3c\u5ea6\u3082\u30ef\u30fc\u30eb\u30c9\u30ab\u30c3\u30d7\uff08\u7279\u306b\u65e5\u672c\u6226\u306e\u653e\u9001\u304c\u3042\u3063\u305f\u6642\u9593\uff09\u3068\u5730\u9707\u306e\u3042\u3063\u305f\u6642\u9593\u306b\u5927\u304d\u304f\u53cd\u5fdc\u3057\u307e\u3057\u305f\u3002\n\n\u307e\u3068\u3081\nTop10\u306e\u30ef\u30fc\u30c9\u898b\u3066\u3044\u3066\u601d\u3063\u305f\u3093\u3067\u3059\u304c\u3001\u307b\u3068\u3093\u3069spam\u30c4\u30a4\u30fc\u30c8\u306e\u30ef\u30fc\u30c9\u304c\u4e0a\u4f4d\u306b\u4e0a\u304c\u3063\u3066\u304d\u307e\u3059\u3002\u3053\u306espam\u306b\u542b\u307e\u308c\u308b\u30ef\u30fc\u30c9\u3092\u9664\u53bb\u3059\u308b\u3068\u3044\u3046\u624b\u6bb5\uff08\u30e1\u30f3\u30c6\u306e\u8981\u3089\u306a\u3044\u7c21\u6613\u7684\u306a\u30b9\u30d1\u30e0\u30d5\u30a3\u30eb\u30bf\uff09\u306b\u3082\u4f7f\u3048\u305d\u3046\u3067\u3059\u3002\n\u3053\u3046\u3044\u3046\u4f7f\u3044\u65b9\u306a\u3089streamingAPI\u306e\u30c7\u30fc\u30bf\u3082\u591a\u5c11\u4f7f\u3048\u305d\u3046\u306a\u4e88\u611f\u304c\u3057\u307e\u3059\u3002\n\u304a\u624b\u6570\u3067\u3059\u304c\u304a\u304b\u3057\u306a\u70b9\u304c\u3042\u308a\u307e\u3057\u305f\u3089\u30b3\u30e1\u30f3\u30c8\u9802\u3051\u307e\u3059\u3068\u52a9\u304b\u308a\u307e\u3059\u3002\nstreamingAPI\u3063\u3066\u65e5\u672c\u8a9e\u306efiltering\u306b\u5bfe\u5fdc\u3057\u3066\u306a\u3044\u3057\u30011%\u7a0b\u5ea6\u306etweet\u3057\u304b\u62fe\u3048\u7121\u3044\u3057\u3001\u4f7f\u3044\u52dd\u624b\u304c\u3044\u307e\u3044\u3061\u3060\u306a\u3063\u3066\u601d\u3063\u3066\u3044\u308b\u4eba\u591a\u3044\u3068\u601d\u3044\u307e\u3059\u3002\u305d\u3093\u306astreamingAPI\u306e\u4f7f\u3044\u9053\u3063\u3066\u4f55\u304b\u306a\u3044\u304b\u306a\u30fc\u3063\u3066\u601d\u3063\u3066\u306a\u3093\u3068\u306a\u304f\u601d\u3044\u3064\u3044\u305f\u306e\u3067\u4f5c\u3063\u3066\u307f\u307e\u3057\u305f\u3002\n\n# \u6e96\u5099\n\u5fc5\u8981\u306a\u306e\u306ftwitter\u306estreamingAPI\u304b\u3089\u53d6\u5f97\u3057\u305f10\u5206\u304a\u304d\u306e\u5358\u8a9e\u306e\u30ab\u30a6\u30f3\u30c8\u30c7\u30fc\u30bf\uff08sqlite\u306b\u683c\u7d0d\uff09\u306e\u307f\u3067\u3059\u3002DB\u306e\u30d5\u30a3\u30fc\u30eb\u30c9\u306fymd, hour, minute, word_dict, tweet_cnt\u3068\u3057\u307e\u3057\u305f\u3002\n\u305d\u308c\u305e\u308c\u3001\u5e74\u6708\u65e5('2014-06-01'), \u6642\u9593('22'), \u5206('10'(00\uff5e50\u307e\u3067\u306e10\u5206\u523b\u307f)), pickle\u3057\u305f\u8f9e\u66f8\u578b\u306e\u5358\u8a9e\u96c6\u5408, 10\u5206\u9593\u6bce\u306e\u30c4\u30a4\u30fc\u30c8\u6570\u3067\u3059\u3002\n\u4f5c\u3063\u305f\u3042\u3068\u3067\u601d\u3063\u305f\u3093\u3067\u3059\u304c\u3001DB\u306e\u8a2d\u8a08\u30df\u30b9\u308a\u307e\u3057\u305f\u3002\u5e74\u6708\u65e5\u3001\u6642\u9593\u3001\u5206\u3068\u304b\u5206\u3051\u308b\u610f\u5473\u3042\u3093\u307e\u308a\u306a\u304b\u3063\u305f\u3067\u3059\u306d\u3002\u3002\u30a2\u30db\u3084\u3063\u305f\u3068\u601d\u3063\u3066\u307e\u3059\u3001\u306f\u3044\u3002\ntwitterAPI\u306e\u4f7f\u3044\u65b9\u3068\u304b\u306f[twitter\u306e\u30c7\u30fc\u30bf\u3092SPAM\u3068HAM\u306b\u5206\u3051\u3066\u307f\u308b](http://qiita.com/shima_x/items/8b8caa82ad4718ef2790)\u306b\u8a18\u8f09\u304c\u3042\u308b\u30da\u30fc\u30b8\u3092\u3054\u53c2\u7167\u304f\u3060\u3055\u3044\u3002\n\n# \u3084\u3063\u305f\u4e8b\n* 10\u5206\u9593\u9694\u306e\u30c7\u30fc\u30bf\u309210\u5206\u4ee5\u4e0a\u306e\u6642\u9593\u3067\u518d\u96c6\u8a08\u3057\u305f\n* \u518d\u96c6\u8a08\u3057\u305f\u6642\u9593\u9593\u9694\u306e\u4f55window\u304b\u5206\u306eTopN\u4ee5\u5185\u306e\u5358\u8a9e\u3068\u88ab\u308a\u306e\u7121\u3044\u5358\u8a9e\u3092\u62bd\u51fa\u3057\u305f\n* \u540c\u3058\u4e8b\u3092\u91cf\u7684\u306b\u975e\u985e\u4f3c\u5ea6\u3068\u3057\u3066\u30b3\u30b5\u30a4\u30f3\u985e\u4f3c\u5ea6\u3067\u6570\u5024\u5316\u3057\u305f\uff082\u5024\u5316\u3057\u305f\u30c7\u30fc\u30bf\u3067\u985e\u4f3c\u5ea6\u3092\u6e2c\u3063\u3066\u3044\u307e\u3059\uff09\n\n# \u53c2\u8003\u30b3\u30fc\u30c9\n```py:\n# coding: utf-8\n\nimport sqlite3 as sqlite\nfrom collections import defaultdict\nimport cPickle as pickle\nimport copy\nimport matplotlib.pyplot as plt\nimport re, unicodedata\nfrom normalizewords import Replace # !!!!!\u3092!!!\u306b\u3059\u308b\u3068\u304b\u3001\u5927\u6587\u5b57\u5316\u3001\u5168\u89d2\u5316\u3068\u304b\nfrom math import floor, sqrt\n\nstopword = ('\u7d75\u6587\u5b57\u3068\u304b\u3001\u7528\u9014\u306b\u5408\u308f\u305b\u3066\u8a18\u8ff0\u3057\u3066\u304f\u3060\u3055\u3044',)\n\nclass DataCreater:\n    date = []\n    tweet_cnt = []\n    ex_words_store = []\n    now_words_store = []\n    new_break_words = set()\n    bin_cnt = 0\n    p = re.compile(\"[!-/:-@[-`{-~]\")\n    \n    def __init__(self, dbname, word_limit, ofname, oftcntname,ofnewword,ofcos):\n        self.con = sqlite.connect(dbname)\n        self.word_limit = word_limit\n        self.ofword = open(ofname, 'w',1000)\n        self.oftcnt = open(oftcntname, 'w',1000)\n        self.ofnewwords = open(ofnewword,'w',1000)\n        self.ofcos = open(ofcos,'w',1000)\n    \n    def __def__(self):\n        self.ofword.close()\n        self.oftcnt.close()\n        self.ofnewwords.close()\n        self.ofcos.close()\n\n    def re_aggregate(self,span,con_bin=10):\n        response = self.get_data_yeald()\n        itr, tweet_cnt, word_cnt = self.initiarize_cnt()\n        s_date = None\n        while 1:\n            res = response.fetchone()\n            if res is None: break\n\n            #print res[0]+', '+res[1]+', '+res[2]+', '+str(res[4])\n            tweet_cnt += int(res[4])\n            word_cnt = self.aggregate_word_cnt(pickle.loads(str(res[3])), word_cnt) \n            \n            if itr==0:\n                s_date = res[0]+' '+res[1].zfill(2)+':'+res[2]\n                \n            if itr == span-1:\n                date = res[0]+' '+res[1].zfill(2)+':'+res[2]\n                sorted_word_list = self.sort_word_dict(word_cnt)\n                self.output_topN_word(s_date, sorted_word_list)\n                self.output_tweet_cnt(s_date, tweet_cnt)\n                self.date.append(s_date)\n                self.tweet_cnt.append(tweet_cnt)\n                s_date = date                \n                    \n                self.bin_cnt += 1\n                self.store_now_dict(sorted_word_list[:self.word_limit])\n                print len(self.now_words_store)\n                if self.bin_cnt >= con_bin:\n                    if len(self.ex_words_store)!=0:\n                        self.store_new_words(sorted_word_list[:self.word_limit])\n                        cos_sim = self.calculate_cos_similarity(sorted_word_list[:self.word_limit])\n                        self.output_new_words(s_date)\n                        self.output_cos_sim(s_date,cos_sim)\n                        self.ex_words_store = copy.deepcopy( self.now_words_store )\n                        self.now_words_store.pop(0)\n                        self.new_break_words = set()\n                    else:\n                        self.ex_words_store = copy.deepcopy( self.now_words_store )\n                        self.now_words_store.pop(0)\n                    \n                itr, tweet_cnt, word_cnt = self.initiarize_cnt()\n            else:\n                itr += 1\n                \n    def get_data_yeald(self, start_date=None, end_date=None):        \n        return self.con.execute(\"select ymd, hour, minute, word_dict,tweet_cnt from word_count\")            \n                \n    def initiarize_cnt(self):\n        return 0, 0, defaultdict(int)\n\n    def aggregate_word_cnt(self, new_word_dic, orig_word_dic):\n        for k,v in new_word_dic.items():\n            if k not in stopword:\n                m = self.p.search(unicodedata.normalize('NFKC', unicode(k)))\n                if m is None:\n                    orig_word_dic[k] += v\n        return orig_word_dic\n    \n    def sort_word_dict(self, word_dict):\n        lst = word_dict.items()\n        lst.sort(lambda p0,p1: cmp(p1[1],p0[1])) # get Top N data\n        return lst\n            \n    def calculate_cos_similarity(self, sorted_wordlist):\n        ex_words =[]\n        now_word_list = []\n        for w_list in self.ex_words_store:\n            ex_words +=w_list  \n        for k,_ in sorted_wordlist:\n            now_word_list.append(k)\n        numerator = sum([1 for c in now_word_list if c in ex_words])\n        denominator =  sqrt(len(ex_words) * len(now_word_list))\n        return 1-float(numerator) / denominator if denominator != 0 else 1        \n            \n    def output_topN_word(self, date, sorted_word_list):\n        if len(sorted_word_list) >=self.word_limit:\n            s_list = [ st[0]+':'+str(st[1]) for st in sorted_word_list[:self.word_limit]]\n            s = '\\t'.join(s_list)\n            self.ofword.write(date+'\\t'+s+'\\n')\n        else:\n            s_list = [ st[0]+':'+str(st[1]) for st in sorted_word_list[:self.word_limit]]\n            s = '\\t'.join(s_list)\n            self.ofword.write(date+'\\t'+s+'\\n')\n\n    def output_tweet_cnt(self, date, cnt):\n        s = date+'\\t'+str(cnt)\n        self.oftcnt.write(s+'\\n')\n\n    def output_new_words(self,date):\n        s = '\\t'.join(list(self.new_break_words))\n        print date, s\n        self.ofnewwords.write(date+'\\t'+s+'\\n')\n        \n    def output_cos_sim(self, date, cos_sim):\n        self.ofcos.write(date+'\\t'+str(cos_sim)+'\\n')\n        \n    def store_now_dict(self, sorted_wordlist):\n        words = [k for k,_ in sorted_wordlist]\n        self.now_words_store.append(words)\n    \n    def store_new_words(self, sorted_wordlist):\n        ex_words =[]\n        for w_list in self.ex_words_store:\n            ex_words +=w_list  \n        for k,_ in sorted_wordlist:\n            if k not in ex_words:\n                self.new_break_words.add(k)\n\nif __name__=='__main__':\n    dbname = 'stream_word_cnt.db'\n    ofname = 'topN_words'\n    oftcnt = 'tweet_count'\n    ofnewword = 'new_word'\n    ofcos = 'cos_simularity'\n    word_top = 100 # top\u4f55\u30ef\u30fc\u30c9\u3092\u53d6\u5f97\u3059\u308b\u304b\n    span = 6 # 10\u5206\u5358\u4f4d\u306e\u30ab\u30a6\u30f3\u30c8\u4f55\u500b\u5206\u3092\u7d50\u5408\u3057\u3066\u518d\u96c6\u8a08\u3059\u308b\u304b\n    \n    dc = DataCreater(dbname, word_top, ofname, oftcnt,ofnewword,ofcos)\n    dc.re_aggregate(span,con_bin=24) #con_bin\u306f\u985e\u4f3c\u5ea6\u3092\u6bd4\u8f03\u3059\u308bspan\u306e\u500b\u6570\n    \n    tick = int(floor(len(dc.tweet_cnt)/7))\n    \n    plt.plot(range(len(dc.tweet_cnt)), dc.tweet_cnt)\n    plt.xticks(range(0, len(dc.tweet_cnt), tick), dc.date[::tick], rotation=40)\n    plt.show()\n```\n\n# \u5b9f\u9a13\u7d50\u679c\n6\u670810\u65e5\u304f\u3089\u3044\u304b\u308925\u65e5\u307e\u3067\u8caf\u3081\u3066\u304a\u3044\u305f\u30c7\u30fc\u30bf\u304c\u3042\u3063\u305f\u306e\u3067\u305d\u308c\u3067\u5b9f\u9a13\u3057\u3066\u307f\u307e\u3057\u305f\u3002\n\u7d50\u679c\u306f\u30ef\u30fc\u30eb\u30c9\u30ab\u30c3\u30d7\u95a2\u4fc2\u306e\u30ef\u30fc\u30c9\u304c\u671d\u65b95\u6642\u304f\u3089\u3044\u306b\u3068\u308c\u305f\u308a\u300116\u65e5\u306b\u3042\u3063\u305f\u5730\u9707\u95a2\u4fc2\u306e\u30ef\u30fc\u30c9\u304c\u3068\u308c\u3066\u3044\u305f\u308a\u3001\u5927\u96e8\u306e\u65e5\u306b\u306f\u8c6a\u96e8\u3068\u304b\u3001\u96f7\u3068\u3044\u3046\u30ef\u30fc\u30c9\u304c\u62bd\u51fa\u3055\u308c\u307e\u3057\u305f\u3002\n\u3084\u3063\u3066\u308b\u4e8b\u306f\u975e\u5e38\u306b\u5358\u7d14\u306a\u3093\u3067\u3059\u304c\u3001\u4e2d\u3005\u826f\u3044\u611f\u3058\u306e\u30c7\u30fc\u30bf\u304c\u51fa\u307e\u3057\u305f\u3002\n\u30b3\u30b5\u30a4\u30f3\u985e\u4f3c\u5ea6\u3067\u7b97\u51fa\u3057\u305f\u975e\u985e\u4f3c\u5ea6\u3082\u30ef\u30fc\u30eb\u30c9\u30ab\u30c3\u30d7\uff08\u7279\u306b\u65e5\u672c\u6226\u306e\u653e\u9001\u304c\u3042\u3063\u305f\u6642\u9593\uff09\u3068\u5730\u9707\u306e\u3042\u3063\u305f\u6642\u9593\u306b\u5927\u304d\u304f\u53cd\u5fdc\u3057\u307e\u3057\u305f\u3002\n\n# \u307e\u3068\u3081\nTop10\u306e\u30ef\u30fc\u30c9\u898b\u3066\u3044\u3066\u601d\u3063\u305f\u3093\u3067\u3059\u304c\u3001\u307b\u3068\u3093\u3069spam\u30c4\u30a4\u30fc\u30c8\u306e\u30ef\u30fc\u30c9\u304c\u4e0a\u4f4d\u306b\u4e0a\u304c\u3063\u3066\u304d\u307e\u3059\u3002\u3053\u306espam\u306b\u542b\u307e\u308c\u308b\u30ef\u30fc\u30c9\u3092\u9664\u53bb\u3059\u308b\u3068\u3044\u3046\u624b\u6bb5\uff08\u30e1\u30f3\u30c6\u306e\u8981\u3089\u306a\u3044\u7c21\u6613\u7684\u306a\u30b9\u30d1\u30e0\u30d5\u30a3\u30eb\u30bf\uff09\u306b\u3082\u4f7f\u3048\u305d\u3046\u3067\u3059\u3002\n\u3053\u3046\u3044\u3046\u4f7f\u3044\u65b9\u306a\u3089streamingAPI\u306e\u30c7\u30fc\u30bf\u3082\u591a\u5c11\u4f7f\u3048\u305d\u3046\u306a\u4e88\u611f\u304c\u3057\u307e\u3059\u3002\n\n\u304a\u624b\u6570\u3067\u3059\u304c\u304a\u304b\u3057\u306a\u70b9\u304c\u3042\u308a\u307e\u3057\u305f\u3089\u30b3\u30e1\u30f3\u30c8\u9802\u3051\u307e\u3059\u3068\u52a9\u304b\u308a\u307e\u3059\u3002\n", "tags": ["Python", "\u6a5f\u68b0\u5b66\u7fd2", "Twitter", "NLP"]}