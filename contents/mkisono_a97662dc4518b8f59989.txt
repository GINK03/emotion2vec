{"context": "dlib\u306e\u7269\u4f53\u691c\u51fa\u306f\u3001\u7c21\u5358\u306b\u4f7f\u3048\u308b\u3057\u3001\u7d20\u6674\u3089\u3057\u3044\u6027\u80fd\u3067\u3059\u304c\u3001\u6642\u3005\u8aa4\u691c\u51fa\u304c\u767a\u751f\u3059\u308b\u3053\u3068\u3082\u3042\u308a\u307e\u3059\u3002\u3053\u306e\u30d6\u30ed\u30b0\u3067\u7d39\u4ecb\u3055\u308c\u3066\u3044\u308bdeep learning\u3092\u5229\u7528\u3057\u305f\u7269\u4f53\u691c\u51fa\u306f\u3001HOG\u306e\u691c\u51fa\u5668\u3088\u308a\u3082\u6027\u80fd\u3088\u3055\u305d\u3046\u306a\u306e\u3067\u8a66\u3057\u3066\u307f\u307e\u3057\u305f\u3002\n\ndnn_mmod_ex.cpp\n\u5b66\u7fd2\u30c7\u30fc\u30bf\u304b\u3089\u30e2\u30c7\u30eb\u3092\u30c8\u30ec\u30fc\u30cb\u30f3\u30b0\u3059\u308b\u30b5\u30f3\u30d7\u30eb\u3067\u3059\u3002\u30d3\u30eb\u30c9\u65b9\u6cd5\u306f\u3053\u3061\u3089\u3092\u53c2\u8003\u306b\u3002\n\u3055\u3066\u3001\u3053\u306e\u30b5\u30f3\u30d7\u30eb\u3092\u5b9f\u884c\u3057\u305f\u6642\u3001\u79c1\u306e\u3088\u3046\u306bGPU\u304c\u3057\u3087\u307c\u3044\u74b0\u5883\u3060\u3068\u3001\u4ee5\u4e0b\u306e\u3088\u3046\u306a\u30a8\u30e9\u30fc\u304c\u51fa\u308b\u3068\u601d\u3044\u307e\u3059\u3002\nError while calling cudaMalloc(&data, new_size*sizeof(float)) in file\n/Users/mkisono/work/dlib/dlib/dnn/gpu_data.cpp:191. code: 2, \nreason: out of memory\n\n\u3053\u306e\u30b5\u30f3\u30d7\u30eb\u3092\u52d5\u304b\u3059\u305f\u3081\u306b\u306f\u30015GB\u4ee5\u4e0a\u306eRAM\u304c\u5fc5\u8981\u307f\u305f\u3044\u3067\u3059\u3002\u79c1\u304c\u4f7f\u3063\u3066\u3044\u308biMac\u306eGPU\u306f\u30e1\u30e2\u30ea\u304c1GB\u3057\u304b\u3042\u308a\u307e\u305b\u3093\u3002\n/Users/mkisono/NVIDIA_CUDA-8.0_Samples/1_Utilities/deviceQuery/deviceQuery Starting...\n\nCUDA Device Query (Runtime API) version (CUDART static linking)\n\nDetected 1 CUDA Capable device(s)\n\nDevice 0: \"GeForce GT 755M\"\n  CUDA Driver Version / Runtime Version          8.0 / 8.0\n  CUDA Capability Major/Minor version number:    3.0\n  Total amount of global memory:                 1024 MBytes (1073283072 bytes)\n  ( 2) Multiprocessors, (192) CUDA Cores/MP:     384 CUDA Cores\n  GPU Max Clock rate:                            1085 MHz (1.09 GHz)\n  Memory Clock rate:                             2500 Mhz\n  Memory Bus Width:                              128-bit\n  L2 Cache Size:                                 262144 bytes\n  Maximum Texture Dimension Size (x,y,z)         1D=(65536), 2D=(65536, 65536), 3D=(4096, 4096, 4096)\n  Maximum Layered 1D Texture Size, (num) layers  1D=(16384), 2048 layers\n  Maximum Layered 2D Texture Size, (num) layers  2D=(16384, 16384), 2048 layers\n  Total amount of constant memory:               65536 bytes\n  Total amount of shared memory per block:       49152 bytes\n  Total number of registers available per block: 65536\n  Warp size:                                     32\n  Maximum number of threads per multiprocessor:  2048\n  Maximum number of threads per block:           1024\n  Max dimension size of a thread block (x,y,z): (1024, 1024, 64)\n  Max dimension size of a grid size    (x,y,z): (2147483647, 65535, 65535)\n  Maximum memory pitch:                          2147483647 bytes\n  Texture alignment:                             512 bytes\n  Concurrent copy and kernel execution:          Yes with 1 copy engine(s)\n  Run time limit on kernels:                     Yes\n  Integrated GPU sharing Host Memory:            No\n  Support host page-locked memory mapping:       Yes\n  Alignment requirement for Surfaces:            Yes\n  Device has ECC support:                        Disabled\n  Device supports Unified Addressing (UVA):      Yes\n  Device PCI Domain ID / Bus ID / location ID:   0 / 1 / 0\n  Compute Mode:\n     < Default (multiple host threads can use ::cudaSetDevice() with device simultaneously) >\n\ndeviceQuery, CUDA Driver = CUDART, CUDA Driver Version = 8.0, CUDA Runtime Version = 8.0, NumDevs = 1, Device0 = GeForce GT 755M\nResult = PASS\n\n\u30d0\u30c3\u30c1\u30b5\u30a4\u30ba\u3092\u5c0f\u3055\u304f\u3057\u3066\u5bfe\u5fdc\u3057\u307e\u3059\u3002cropper\u3067\u6307\u5b9a\u3057\u3066\u3044\u308b150\u30925\u306b\u5909\u66f4\u3057\u307e\u3057\u305f(\u3053\u308c\u4ee5\u4e0a\u306e\u5024\u3060\u3068\u30a8\u30e9\u30fc\u306b\u306a\u3063\u305f\u30fb\u30fb)\n\ndnn_mmod_ex.cpp\n    while(trainer.get_learning_rate() >= 1e-4)\n    {\n        // cropper(150, images_train, face_boxes_train, mini_batch_samples, mini_batch_labels);\n        cropper(5, images_train, face_boxes_train, mini_batch_samples, mini_batch_labels);\n        // We can also randomly jitter the colors and that often helps a detector\n        // generalize better to new images.\n        for (auto&& img : mini_batch_samples)\n            disturb_colors(img, rnd);\n\n        trainer.train_one_step(mini_batch_samples, mini_batch_labels);\n    }\n\n\n\u4e00\u3064\u306e\u30b9\u30c6\u30c3\u30d7\u3067\u51e6\u7406\u3059\u308b\u30d0\u30c3\u30c1\u304c\u3050\u3063\u3068\u5c0f\u3055\u304f\u306a\u3063\u305f\u306e\u3067\u3001learning rate\u3092\u4e0b\u3052\u308b\u95be\u5024\u306f\u5927\u304d\u304f\u3057\u3066\u304a\u304d\u307e\u3059\u3002\u3053\u306e\u5024\u3092\u5909\u66f4\u3057\u306a\u3044\u3068\u3001\u76f4\u3050\u306blearning rate\u304c\u5c0f\u3055\u304f\u306a\u3063\u3066\u3057\u307e\u3044\u3001\u30e2\u30c7\u30eb\u306e\u5b66\u7fd2\u304c\u3046\u307e\u304f\u3044\u304d\u307e\u305b\u3093\u3002\u5143\u306f 300 \u3060\u3063\u305f\u5024\u3092 3000 \u306b\u5909\u66f4\u3057\u307e\u3057\u305f(\u3082\u3063\u3068\u5927\u304d\u3044\u5024\u3067\u3082\u3044\u3044\u304b\u3082)\u3002\n\ndnn_mmod_ex.cpp\n    trainer.set_iterations_without_progress_threshold(3000);\n\n\n\u3053\u308c\u3067\u3068\u308a\u3042\u3048\u305a\u5b66\u7fd2\u306f\u59cb\u307e\u308a\u307e\u3057\u305f\u3002\u3068\u306f\u3044\u3048\u3001\u3069\u308c\u304f\u3089\u3044\u6642\u9593\u304c\u304b\u304b\u308b\u306e\u304b\u5206\u304b\u3089\u306a\u3044\u306e\u3067\u4e2d\u65ad\u3057\u307e\u3057\u305f\u3002\u30b5\u30f3\u30d7\u30eb\u3067\u306f5\u5206\u3054\u3068\u306b\u30e2\u30c7\u30eb\u304c\u4fdd\u5b58\u3055\u308c\u3066\u3044\u308b\u306e\u3067\u3001\u6b21\u306b\u5b66\u7fd2\u3092\u518d\u958b\u3057\u305f\u6642\u306f\u305d\u3053\u304b\u3089\u7d9a\u304d\u304c\u51fa\u6765\u307e\u3059\u3002\n% ./dnn_mmod_ex ../faces\nnum training images: 4\nnum testing images:  5\ndetection window width,height:      40,40\noverlap NMS IOU thresh:             0.0781701\noverlap NMS percent covered thresh: 0.257122\nstep#: 0     learning rate: 0.1   average loss: 0           steps without apparent progress: 0\nstep#: 312   learning rate: 0.1   average loss: 3.70172     steps without apparent progress: 81\nstep#: 625   learning rate: 0.1   average loss: 1.93546     steps without apparent progress: 122\nstep#: 941   learning rate: 0.1   average loss: 1.72469     steps without apparent progress: 325\nstep#: 1242  learning rate: 0.1   average loss: 1.6436      steps without apparent progress: 336\nstep#: 1547  learning rate: 0.1   average loss: 1.55475     steps without apparent progress: 262\nstep#: 1859  learning rate: 0.1   average loss: 1.55434     steps without apparent progress: 594\nstep#: 2171  learning rate: 0.1   average loss: 1.52154     steps without apparent progress: 121\nSaved state to mmod_sync\nstep#: 2482  learning rate: 0.1   average loss: 1.41587     steps without apparent progress: 244\nstep#: 2792  learning rate: 0.1   average loss: 1.30095     steps without apparent progress: 313\nstep#: 3105  learning rate: 0.1   average loss: 1.13682     steps without apparent progress: 259\nstep#: 3401  learning rate: 0.1   average loss: 0.979448    steps without apparent progress: 186\nstep#: 3712  learning rate: 0.1   average loss: 0.906737    steps without apparent progress: 273\nstep#: 4018  learning rate: 0.1   average loss: 0.809688    steps without apparent progress: 194\nstep#: 4322  learning rate: 0.1   average loss: 0.781587    steps without apparent progress: 224\nSaved state to mmod_sync\nstep#: 4620  learning rate: 0.1   average loss: 0.727887    steps without apparent progress: 553\nstep#: 4936  learning rate: 0.1   average loss: 0.654706    steps without apparent progress: 145\nstep#: 5249  learning rate: 0.1   average loss: 0.588801    steps without apparent progress: 180\nstep#: 5560  learning rate: 0.1   average loss: 0.580081    steps without apparent progress: 574\nstep#: 5872  learning rate: 0.1   average loss: 0.599059    steps without apparent progress: 909\nstep#: 6182  learning rate: 0.1   average loss: 0.504902    steps without apparent progress: 395\nstep#: 6495  learning rate: 0.1   average loss: 0.537297    steps without apparent progress: 753\nstep#: 6808  learning rate: 0.1   average loss: 0.539641    steps without apparent progress: 1104\nSaved state to mmod_sync\nstep#: 7118  learning rate: 0.1   average loss: 0.503599    steps without apparent progress: 1350\nstep#: 7428  learning rate: 0.1   average loss: 0.486274    steps without apparent progress: 578\nstep#: 7746  learning rate: 0.1   average loss: 0.479272    steps without apparent progress: 892\nstep#: 8059  learning rate: 0.1   average loss: 0.448152    steps without apparent progress: 548\nstep#: 8374  learning rate: 0.1   average loss: 0.462102    steps without apparent progress: 519\nstep#: 8684  learning rate: 0.1   average loss: 0.460537    steps without apparent progress: 1184\nstep#: 8996  learning rate: 0.1   average loss: 0.474958    steps without apparent progress: 1592\nSaved state to mmod_sync\nstep#: 9312  learning rate: 0.1   average loss: 0.424878    steps without apparent progress: 1453\nstep#: 9627  learning rate: 0.1   average loss: 0.421029    steps without apparent progress: 86\nstep#: 9943  learning rate: 0.1   average loss: 0.445149    steps without apparent progress: 956\nstep#: 10257  learning rate: 0.1   average loss: 0.407989    steps without apparent progress: 1087\nstep#: 10570  learning rate: 0.1   average loss: 0.44248     steps without apparent progress: 1576\nstep#: 10884  learning rate: 0.1   average loss: 0.46317     steps without apparent progress: 2187\nstep#: 11194  learning rate: 0.1   average loss: 0.431704    steps without apparent progress: 2360\nstep#: 11502  learning rate: 0.1   average loss: 0.404676    steps without apparent progress: 2509\n\n\ndnn_mmod_face_detection_ex.cpp\n\u9854\u691c\u51fa\u306e\u30b5\u30f3\u30d7\u30eb\u3067\u3059\u3002\u5b66\u7fd2\u6e08\u307f\u306e\u30c7\u30fc\u30bf\u3092\u30c0\u30a6\u30f3\u30ed\u30fc\u30c9\u3057\u3066\u4f7f\u3044\u307e\u3059\u3002\n% ./dnn_mmod_face_detection_ex\nCall this program like this:\n./dnn_mmod_face_detection_ex mmod_human_face_detector.dat faces/*.jpg\n\nYou can get the mmod_human_face_detector.dat file from:\nhttp://dlib.net/files/mmod_human_face_detector.dat.bz2\n\n\u5b9f\u884c\u3057\u3066\u307f\u308b\u3068\u3001\u307e\u305f\u30e1\u30e2\u30ea\u4e0d\u8db3\u3002\n% ./dnn_mmod_face_detection_ex mmod_human_face_detector.dat ../faces/*.jpg\nError while calling cudaMalloc(&backward_filters_workspace, backward_filters_workspace_size_in_bytes) in file /Users/mkisono/work/dlib/dlib/dnn/cudnn_dlibapi.cpp:948. code: 2, reason: out of memory\n\n\u8ae6\u3081\u3066\u3001CUDA\u3092\u5916\u3057\u3066\u30b5\u30f3\u30d7\u30eb\u3092\u30d3\u30eb\u30c9\u4ed5\u76f4\u3057(cmake\u3067 -DDLIB_USE_CUDA=OFF \u3092\u8ffd\u52a0)\u5b9f\u884c\u3057\u307e\u3057\u305f\u3002\n\u305d\u306e\u5834\u5408\u3082\u3001\u753b\u50cf\u306e\u62e1\u5927\u7387\u3092\u3084\u3084\u6291\u3048\u306a\u3044\u3068\u5b9f\u884c\u3067\u304d\u307e\u305b\u3093\u3067\u3057\u305f\u3002\n\ndnn_mmod_face_detection_ex.cpp\n        while(img.size() < 1000*1000)\n            pyramid_up(img);\n\n\n\u5b9f\u884c\u4f8b\n\n\u3061\u306a\u307f\u306b\u3001dnn_mmod_ex.cpp\u3067\u5b66\u7fd2\u3055\u305b\u305f\u30e2\u30c7\u30eb\u3092 dnn_mmod_face_detection_ex.cpp \u3067\u4f7f\u3046\u5834\u5408\u306f\u3001\u30e2\u30c7\u30eb\u306e\u5b9a\u7fa9\u304c\u9055\u3046\u306e\u3067\u305d\u306e\u307e\u307e\u3067\u306f\u52d5\u304d\u307e\u305b\u3093\u3002dnn_mmod_face_detection_ex.cpp \u306b\u8a18\u8f09\u304c\u3042\u308b\u901a\u308a\u3067\u3059\u3002\n    TRAINING THE MODEL\n        Finally, users interested in how the face detector was trained should\n        read the dnn_mmod_ex.cpp example program.  It should be noted that the\n        face detector used in this example uses a bigger training dataset and\n        larger CNN architecture than what is shown in dnn_mmod_ex.cpp, but\n        otherwise training is the same.  If you compare the net_type statements\n        in this file and dnn_mmod_ex.cpp you will see that they are very similar\n        except that the number of parameters has been increased.\n\n\n\u611f\u60f3\nGPU\u304c\u3042\u308c\u3070\u975e\u5e38\u306b\u9ad8\u901f\u306b\u51e6\u7406\u3067\u304d\u308b\u3057\u3001\u6027\u80fd\u3082\u30d0\u30c3\u30c1\u30ea\u306a\u611f\u3058\u304c\u3057\u307e\u3059\u3002\n\u3053\u308c\u304cPython\u304b\u3089\u4f7f\u3048\u305f\u3089\u3069\u3093\u306a\u306b\u4fbf\u5229\u304b\u30fb\u30fb\u30fb\u3000\u5bfe\u5fdc\u4e88\u5b9a\u306f\u7121\u3055\u305d\u3046\u3067\u3059\u304c\u3001\u30e2\u30c7\u30eb\u3092\u4f7f\u3063\u305fpredict\u304cPython\u304b\u3089\u51fa\u6765\u308b\u3060\u3051\u3067\u3082\u3046\u308c\u3057\u3044\u306a\u3002\n\nPython\u304b\u3089\u4f7f\u3046 (\u8ffd\u8a18)\nboost::python \u4f7f\u3048\u3070\u3067\u304d\u308b\u304b\u306a\u3068\u601d\u3044\u3001\u8a66\u4f5c\u3092\u59cb\u3081\u305f\u3068\u3053\u308d\u3067\u3053\u308c\u3092\u898b\u3064\u3051\u307e\u3057\u305f\u3002pybind11\u306a\u308b\u3082\u306e\u3092\u4f7f\u3063\u3066Python\u30d0\u30a4\u30f3\u30c7\u30a3\u30f3\u30b0\u3057\u3066\u3044\u308b\u5148\u4eba\u304c\u304a\u308a\u307e\u3057\u305f\u3002\u3053\u308c\u3092\u53c2\u8003\u306b\u3057\u3066\u3084\u3063\u3066\u307f\u305f\u3089\u51fa\u6765\u307e\u3057\u305f\u3002\n\u3061\u306a\u307f\u306b\u3001dlib\u306ePython\u30d0\u30a4\u30f3\u30c7\u30a3\u30f3\u30b0\u81ea\u4f53\u3092pybind11\u306b\u3057\u3088\u3046\u304b\u3068\u3044\u3046\u8a71\u984c\u3082\u3042\u308a\u307e\u3059\u3002\npybind11\u306f\u521d\u3081\u3066\u4f7f\u3063\u3066\u307f\u307e\u3057\u305f\u304c\u3001boost:python\u3088\u308a\u826f\u3055\u305d\u3046\u306b\u601d\u3044\u307e\u3057\u305f\u3002\n\u53c2\u8003\u30ea\u30f3\u30af pybind11\u3092\u4f7f\u3063\u3066Python\u304b\u3089C++\u30b3\u30fc\u30c9\u3092\u5b9f\u884c\u3059\u308b\u65b9\u6cd5\n[dlib\u306e\u7269\u4f53\u691c\u51fa](http://qiita.com/atotto/items/ef34c046c2222adf1679)\u306f\u3001\u7c21\u5358\u306b\u4f7f\u3048\u308b\u3057\u3001\u7d20\u6674\u3089\u3057\u3044\u6027\u80fd\u3067\u3059\u304c\u3001\u6642\u3005\u8aa4\u691c\u51fa\u304c\u767a\u751f\u3059\u308b\u3053\u3068\u3082\u3042\u308a\u307e\u3059\u3002[\u3053\u306e\u30d6\u30ed\u30b0](http://blog.dlib.net/2016/10/easily-create-high-quality-object.html)\u3067\u7d39\u4ecb\u3055\u308c\u3066\u3044\u308bdeep learning\u3092\u5229\u7528\u3057\u305f\u7269\u4f53\u691c\u51fa\u306f\u3001HOG\u306e\u691c\u51fa\u5668\u3088\u308a\u3082\u6027\u80fd\u3088\u3055\u305d\u3046\u306a\u306e\u3067\u8a66\u3057\u3066\u307f\u307e\u3057\u305f\u3002\n\n## dnn_mmod_ex.cpp\n\n\u5b66\u7fd2\u30c7\u30fc\u30bf\u304b\u3089\u30e2\u30c7\u30eb\u3092\u30c8\u30ec\u30fc\u30cb\u30f3\u30b0\u3059\u308b[\u30b5\u30f3\u30d7\u30eb](http://dlib.net/dnn_mmod_ex.cpp.html)\u3067\u3059\u3002\u30d3\u30eb\u30c9\u65b9\u6cd5\u306f[\u3053\u3061\u3089](http://qiita.com/mkisono/items/5456b97b5e2d75d33737)\u3092\u53c2\u8003\u306b\u3002\n\n\u3055\u3066\u3001\u3053\u306e\u30b5\u30f3\u30d7\u30eb\u3092\u5b9f\u884c\u3057\u305f\u6642\u3001\u79c1\u306e\u3088\u3046\u306bGPU\u304c\u3057\u3087\u307c\u3044\u74b0\u5883\u3060\u3068\u3001\u4ee5\u4e0b\u306e\u3088\u3046\u306a\u30a8\u30e9\u30fc\u304c\u51fa\u308b\u3068\u601d\u3044\u307e\u3059\u3002\n\n```\nError while calling cudaMalloc(&data, new_size*sizeof(float)) in file\n/Users/mkisono/work/dlib/dlib/dnn/gpu_data.cpp:191. code: 2, \nreason: out of memory\n```\n\n\u3053\u306e\u30b5\u30f3\u30d7\u30eb\u3092\u52d5\u304b\u3059\u305f\u3081\u306b\u306f\u3001[5GB\u4ee5\u4e0a\u306eRAM\u304c\u5fc5\u8981](https://github.com/davisking/dlib/issues/252)\u307f\u305f\u3044\u3067\u3059\u3002\u79c1\u304c\u4f7f\u3063\u3066\u3044\u308biMac\u306eGPU\u306f\u30e1\u30e2\u30ea\u304c1GB\u3057\u304b\u3042\u308a\u307e\u305b\u3093\u3002\n\n```\n/Users/mkisono/NVIDIA_CUDA-8.0_Samples/1_Utilities/deviceQuery/deviceQuery Starting...\n\nCUDA Device Query (Runtime API) version (CUDART static linking)\n\nDetected 1 CUDA Capable device(s)\n\nDevice 0: \"GeForce GT 755M\"\n  CUDA Driver Version / Runtime Version          8.0 / 8.0\n  CUDA Capability Major/Minor version number:    3.0\n  Total amount of global memory:                 1024 MBytes (1073283072 bytes)\n  ( 2) Multiprocessors, (192) CUDA Cores/MP:     384 CUDA Cores\n  GPU Max Clock rate:                            1085 MHz (1.09 GHz)\n  Memory Clock rate:                             2500 Mhz\n  Memory Bus Width:                              128-bit\n  L2 Cache Size:                                 262144 bytes\n  Maximum Texture Dimension Size (x,y,z)         1D=(65536), 2D=(65536, 65536), 3D=(4096, 4096, 4096)\n  Maximum Layered 1D Texture Size, (num) layers  1D=(16384), 2048 layers\n  Maximum Layered 2D Texture Size, (num) layers  2D=(16384, 16384), 2048 layers\n  Total amount of constant memory:               65536 bytes\n  Total amount of shared memory per block:       49152 bytes\n  Total number of registers available per block: 65536\n  Warp size:                                     32\n  Maximum number of threads per multiprocessor:  2048\n  Maximum number of threads per block:           1024\n  Max dimension size of a thread block (x,y,z): (1024, 1024, 64)\n  Max dimension size of a grid size    (x,y,z): (2147483647, 65535, 65535)\n  Maximum memory pitch:                          2147483647 bytes\n  Texture alignment:                             512 bytes\n  Concurrent copy and kernel execution:          Yes with 1 copy engine(s)\n  Run time limit on kernels:                     Yes\n  Integrated GPU sharing Host Memory:            No\n  Support host page-locked memory mapping:       Yes\n  Alignment requirement for Surfaces:            Yes\n  Device has ECC support:                        Disabled\n  Device supports Unified Addressing (UVA):      Yes\n  Device PCI Domain ID / Bus ID / location ID:   0 / 1 / 0\n  Compute Mode:\n     < Default (multiple host threads can use ::cudaSetDevice() with device simultaneously) >\n\ndeviceQuery, CUDA Driver = CUDART, CUDA Driver Version = 8.0, CUDA Runtime Version = 8.0, NumDevs = 1, Device0 = GeForce GT 755M\nResult = PASS\n```\n\n\u30d0\u30c3\u30c1\u30b5\u30a4\u30ba\u3092\u5c0f\u3055\u304f\u3057\u3066\u5bfe\u5fdc\u3057\u307e\u3059\u3002cropper\u3067\u6307\u5b9a\u3057\u3066\u3044\u308b150\u30925\u306b\u5909\u66f4\u3057\u307e\u3057\u305f(\u3053\u308c\u4ee5\u4e0a\u306e\u5024\u3060\u3068\u30a8\u30e9\u30fc\u306b\u306a\u3063\u305f\u30fb\u30fb)\n\n```dnn_mmod_ex.cpp\n    while(trainer.get_learning_rate() >= 1e-4)\n    {\n        // cropper(150, images_train, face_boxes_train, mini_batch_samples, mini_batch_labels);\n        cropper(5, images_train, face_boxes_train, mini_batch_samples, mini_batch_labels);\n        // We can also randomly jitter the colors and that often helps a detector\n        // generalize better to new images.\n        for (auto&& img : mini_batch_samples)\n            disturb_colors(img, rnd);\n\n        trainer.train_one_step(mini_batch_samples, mini_batch_labels);\n    }\n```\n\n\u4e00\u3064\u306e\u30b9\u30c6\u30c3\u30d7\u3067\u51e6\u7406\u3059\u308b\u30d0\u30c3\u30c1\u304c\u3050\u3063\u3068\u5c0f\u3055\u304f\u306a\u3063\u305f\u306e\u3067\u3001learning rate\u3092\u4e0b\u3052\u308b\u95be\u5024\u306f\u5927\u304d\u304f\u3057\u3066\u304a\u304d\u307e\u3059\u3002\u3053\u306e\u5024\u3092\u5909\u66f4\u3057\u306a\u3044\u3068\u3001\u76f4\u3050\u306blearning rate\u304c\u5c0f\u3055\u304f\u306a\u3063\u3066\u3057\u307e\u3044\u3001\u30e2\u30c7\u30eb\u306e\u5b66\u7fd2\u304c\u3046\u307e\u304f\u3044\u304d\u307e\u305b\u3093\u3002\u5143\u306f 300 \u3060\u3063\u305f\u5024\u3092 3000 \u306b\u5909\u66f4\u3057\u307e\u3057\u305f(\u3082\u3063\u3068\u5927\u304d\u3044\u5024\u3067\u3082\u3044\u3044\u304b\u3082)\u3002\n\n```dnn_mmod_ex.cpp\n    trainer.set_iterations_without_progress_threshold(3000);\n```\n\n\u3053\u308c\u3067\u3068\u308a\u3042\u3048\u305a\u5b66\u7fd2\u306f\u59cb\u307e\u308a\u307e\u3057\u305f\u3002\u3068\u306f\u3044\u3048\u3001\u3069\u308c\u304f\u3089\u3044\u6642\u9593\u304c\u304b\u304b\u308b\u306e\u304b\u5206\u304b\u3089\u306a\u3044\u306e\u3067\u4e2d\u65ad\u3057\u307e\u3057\u305f\u3002\u30b5\u30f3\u30d7\u30eb\u3067\u306f5\u5206\u3054\u3068\u306b\u30e2\u30c7\u30eb\u304c\u4fdd\u5b58\u3055\u308c\u3066\u3044\u308b\u306e\u3067\u3001\u6b21\u306b\u5b66\u7fd2\u3092\u518d\u958b\u3057\u305f\u6642\u306f\u305d\u3053\u304b\u3089\u7d9a\u304d\u304c\u51fa\u6765\u307e\u3059\u3002\n\n```\n% ./dnn_mmod_ex ../faces\nnum training images: 4\nnum testing images:  5\ndetection window width,height:      40,40\noverlap NMS IOU thresh:             0.0781701\noverlap NMS percent covered thresh: 0.257122\nstep#: 0     learning rate: 0.1   average loss: 0           steps without apparent progress: 0\nstep#: 312   learning rate: 0.1   average loss: 3.70172     steps without apparent progress: 81\nstep#: 625   learning rate: 0.1   average loss: 1.93546     steps without apparent progress: 122\nstep#: 941   learning rate: 0.1   average loss: 1.72469     steps without apparent progress: 325\nstep#: 1242  learning rate: 0.1   average loss: 1.6436      steps without apparent progress: 336\nstep#: 1547  learning rate: 0.1   average loss: 1.55475     steps without apparent progress: 262\nstep#: 1859  learning rate: 0.1   average loss: 1.55434     steps without apparent progress: 594\nstep#: 2171  learning rate: 0.1   average loss: 1.52154     steps without apparent progress: 121\nSaved state to mmod_sync\nstep#: 2482  learning rate: 0.1   average loss: 1.41587     steps without apparent progress: 244\nstep#: 2792  learning rate: 0.1   average loss: 1.30095     steps without apparent progress: 313\nstep#: 3105  learning rate: 0.1   average loss: 1.13682     steps without apparent progress: 259\nstep#: 3401  learning rate: 0.1   average loss: 0.979448    steps without apparent progress: 186\nstep#: 3712  learning rate: 0.1   average loss: 0.906737    steps without apparent progress: 273\nstep#: 4018  learning rate: 0.1   average loss: 0.809688    steps without apparent progress: 194\nstep#: 4322  learning rate: 0.1   average loss: 0.781587    steps without apparent progress: 224\nSaved state to mmod_sync\nstep#: 4620  learning rate: 0.1   average loss: 0.727887    steps without apparent progress: 553\nstep#: 4936  learning rate: 0.1   average loss: 0.654706    steps without apparent progress: 145\nstep#: 5249  learning rate: 0.1   average loss: 0.588801    steps without apparent progress: 180\nstep#: 5560  learning rate: 0.1   average loss: 0.580081    steps without apparent progress: 574\nstep#: 5872  learning rate: 0.1   average loss: 0.599059    steps without apparent progress: 909\nstep#: 6182  learning rate: 0.1   average loss: 0.504902    steps without apparent progress: 395\nstep#: 6495  learning rate: 0.1   average loss: 0.537297    steps without apparent progress: 753\nstep#: 6808  learning rate: 0.1   average loss: 0.539641    steps without apparent progress: 1104\nSaved state to mmod_sync\nstep#: 7118  learning rate: 0.1   average loss: 0.503599    steps without apparent progress: 1350\nstep#: 7428  learning rate: 0.1   average loss: 0.486274    steps without apparent progress: 578\nstep#: 7746  learning rate: 0.1   average loss: 0.479272    steps without apparent progress: 892\nstep#: 8059  learning rate: 0.1   average loss: 0.448152    steps without apparent progress: 548\nstep#: 8374  learning rate: 0.1   average loss: 0.462102    steps without apparent progress: 519\nstep#: 8684  learning rate: 0.1   average loss: 0.460537    steps without apparent progress: 1184\nstep#: 8996  learning rate: 0.1   average loss: 0.474958    steps without apparent progress: 1592\nSaved state to mmod_sync\nstep#: 9312  learning rate: 0.1   average loss: 0.424878    steps without apparent progress: 1453\nstep#: 9627  learning rate: 0.1   average loss: 0.421029    steps without apparent progress: 86\nstep#: 9943  learning rate: 0.1   average loss: 0.445149    steps without apparent progress: 956\nstep#: 10257  learning rate: 0.1   average loss: 0.407989    steps without apparent progress: 1087\nstep#: 10570  learning rate: 0.1   average loss: 0.44248     steps without apparent progress: 1576\nstep#: 10884  learning rate: 0.1   average loss: 0.46317     steps without apparent progress: 2187\nstep#: 11194  learning rate: 0.1   average loss: 0.431704    steps without apparent progress: 2360\nstep#: 11502  learning rate: 0.1   average loss: 0.404676    steps without apparent progress: 2509\n```\n\n## dnn_mmod_face_detection_ex.cpp\n\n\u9854\u691c\u51fa\u306e[\u30b5\u30f3\u30d7\u30eb](http://dlib.net/dnn_mmod_face_detection_ex.cpp.html)\u3067\u3059\u3002\u5b66\u7fd2\u6e08\u307f\u306e\u30c7\u30fc\u30bf\u3092\u30c0\u30a6\u30f3\u30ed\u30fc\u30c9\u3057\u3066\u4f7f\u3044\u307e\u3059\u3002\n\n```\n% ./dnn_mmod_face_detection_ex\nCall this program like this:\n./dnn_mmod_face_detection_ex mmod_human_face_detector.dat faces/*.jpg\n\nYou can get the mmod_human_face_detector.dat file from:\nhttp://dlib.net/files/mmod_human_face_detector.dat.bz2\n```\n\n\u5b9f\u884c\u3057\u3066\u307f\u308b\u3068\u3001\u307e\u305f\u30e1\u30e2\u30ea\u4e0d\u8db3\u3002\n\n```\n% ./dnn_mmod_face_detection_ex mmod_human_face_detector.dat ../faces/*.jpg\nError while calling cudaMalloc(&backward_filters_workspace, backward_filters_workspace_size_in_bytes) in file /Users/mkisono/work/dlib/dlib/dnn/cudnn_dlibapi.cpp:948. code: 2, reason: out of memory\n```\n\n\u8ae6\u3081\u3066\u3001CUDA\u3092\u5916\u3057\u3066\u30b5\u30f3\u30d7\u30eb\u3092\u30d3\u30eb\u30c9\u4ed5\u76f4\u3057(cmake\u3067 -DDLIB_USE_CUDA=OFF \u3092\u8ffd\u52a0)\u5b9f\u884c\u3057\u307e\u3057\u305f\u3002\n\u305d\u306e\u5834\u5408\u3082\u3001\u753b\u50cf\u306e\u62e1\u5927\u7387\u3092\u3084\u3084\u6291\u3048\u306a\u3044\u3068\u5b9f\u884c\u3067\u304d\u307e\u305b\u3093\u3067\u3057\u305f\u3002\n\n```dnn_mmod_face_detection_ex.cpp\n        while(img.size() < 1000*1000)\n            pyramid_up(img);\n```\n\n\u5b9f\u884c\u4f8b\n![\u30b9\u30af\u30ea\u30fc\u30f3\u30b7\u30e7\u30c3\u30c8 2017-01-17 16.14.09.png](https://qiita-image-store.s3.amazonaws.com/0/42252/8e4ede86-4f38-526e-1d4a-0115eccee739.png)\n\n\n\u3061\u306a\u307f\u306b\u3001dnn_mmod_ex.cpp\u3067\u5b66\u7fd2\u3055\u305b\u305f\u30e2\u30c7\u30eb\u3092 dnn_mmod_face_detection_ex.cpp \u3067\u4f7f\u3046\u5834\u5408\u306f\u3001\u30e2\u30c7\u30eb\u306e\u5b9a\u7fa9\u304c\u9055\u3046\u306e\u3067\u305d\u306e\u307e\u307e\u3067\u306f\u52d5\u304d\u307e\u305b\u3093\u3002dnn_mmod_face_detection_ex.cpp \u306b\u8a18\u8f09\u304c\u3042\u308b\u901a\u308a\u3067\u3059\u3002\n\n```\n    TRAINING THE MODEL\n        Finally, users interested in how the face detector was trained should\n        read the dnn_mmod_ex.cpp example program.  It should be noted that the\n        face detector used in this example uses a bigger training dataset and\n        larger CNN architecture than what is shown in dnn_mmod_ex.cpp, but\n        otherwise training is the same.  If you compare the net_type statements\n        in this file and dnn_mmod_ex.cpp you will see that they are very similar\n        except that the number of parameters has been increased.\n```\n\n## \u611f\u60f3\n\nGPU\u304c\u3042\u308c\u3070\u975e\u5e38\u306b\u9ad8\u901f\u306b\u51e6\u7406\u3067\u304d\u308b\u3057\u3001\u6027\u80fd\u3082\u30d0\u30c3\u30c1\u30ea\u306a\u611f\u3058\u304c\u3057\u307e\u3059\u3002\n\u3053\u308c\u304cPython\u304b\u3089\u4f7f\u3048\u305f\u3089\u3069\u3093\u306a\u306b\u4fbf\u5229\u304b\u30fb\u30fb\u30fb\u3000[\u5bfe\u5fdc\u4e88\u5b9a\u306f\u7121\u3055\u305d\u3046](https://github.com/davisking/dlib/issues/254)\u3067\u3059\u304c\u3001\u30e2\u30c7\u30eb\u3092\u4f7f\u3063\u305fpredict\u304cPython\u304b\u3089\u51fa\u6765\u308b\u3060\u3051\u3067\u3082\u3046\u308c\u3057\u3044\u306a\u3002\n\n## Python\u304b\u3089\u4f7f\u3046 (\u8ffd\u8a18)\n\nboost::python \u4f7f\u3048\u3070\u3067\u304d\u308b\u304b\u306a\u3068\u601d\u3044\u3001\u8a66\u4f5c\u3092\u59cb\u3081\u305f\u3068\u3053\u308d\u3067[\u3053\u308c](https://github.com/davisking/dlib/issues/330)\u3092\u898b\u3064\u3051\u307e\u3057\u305f\u3002pybind11\u306a\u308b\u3082\u306e\u3092\u4f7f\u3063\u3066Python\u30d0\u30a4\u30f3\u30c7\u30a3\u30f3\u30b0\u3057\u3066\u3044\u308b\u5148\u4eba\u304c\u304a\u308a\u307e\u3057\u305f\u3002\u3053\u308c\u3092\u53c2\u8003\u306b\u3057\u3066\u3084\u3063\u3066\u307f\u305f\u3089\u51fa\u6765\u307e\u3057\u305f\u3002\n\u3061\u306a\u307f\u306b\u3001[dlib\u306ePython\u30d0\u30a4\u30f3\u30c7\u30a3\u30f3\u30b0\u81ea\u4f53\u3092pybind11\u306b\u3057\u3088\u3046\u304b](https://github.com/davisking/dlib/issues/293)\u3068\u3044\u3046\u8a71\u984c\u3082\u3042\u308a\u307e\u3059\u3002\npybind11\u306f\u521d\u3081\u3066\u4f7f\u3063\u3066\u307f\u307e\u3057\u305f\u304c\u3001boost:python\u3088\u308a\u826f\u3055\u305d\u3046\u306b\u601d\u3044\u307e\u3057\u305f\u3002\n\n\u53c2\u8003\u30ea\u30f3\u30af [pybind11\u3092\u4f7f\u3063\u3066Python\u304b\u3089C++\u30b3\u30fc\u30c9\u3092\u5b9f\u884c\u3059\u308b\u65b9\u6cd5](http://myenigma.hatenablog.com/entry/2016/12/17/075812)\n", "tags": ["dlib", "DeepLearning", "pybind11"]}