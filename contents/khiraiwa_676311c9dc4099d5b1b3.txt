{"context": " More than 1 year has passed since last update.Apache Spark\u304cHadoop\u3088\u308a\u3044\u3051\u3066\u305d\u3046\u306a\u306e\u3067\u8abf\u3079\u3066\u4f7f\u3063\u3066\u307f\u307e\u3057\u305f\u3002\n\nApache Spark\u306b\u3064\u3044\u3066\n\n\u6982\u8981\nSpark\u3068\u306fHadoop(MapReduce)\u3092\u62e1\u5f35\u3057\u305f\u6b21\u4e16\u4ee3\u306e\u30d3\u30c3\u30af\u30c7\u30fc\u30bf\u89e3\u6790\u30a8\u30f3\u30b8\u30f3\u3002\n\n\u30ea\u30c3\u30c1\u306aAPI\u304c\u3042\u308b\u306e\u3067\u3001\u4f7f\u3046\u306e\u304c\u3088\u308a\u7c21\u5358\n\u3088\u308a\u9ad8\u901f\n\u5bfe\u8a71\u7684\u30af\u30a8\u30ea\u3001\u30b9\u30c8\u30ea\u30fc\u30df\u30f3\u30b0\u3001\u30de\u30b7\u30f3\u30e9\u30fc\u30cb\u30f3\u30b0\u3001\u30b0\u30e9\u30d5\u51e6\u7406\u306a\u3069\u3092\u30b5\u30dd\u30fc\u30c8\n\nHadoop\u306eMapReduce\u306e\u6642\u306fdisk\u4e0a\u3067\u8a08\u7b97\u304c\u8d70\u3063\u3066\u3044\u305f\u3051\u308c\u3069\u3001\u30e1\u30e2\u30ea\u4e0a\u3067\u8d70\u3089\u305b\u308b\u3053\u3068\u304c\u9ad8\u901f\u5316\u306e\u8981\u56e0\u306e\u4e00\u3064\u306e\u3088\u3046\u3067\u3059\u3002\n\n\u30b3\u30f3\u30dd\u30fc\u30cd\u30f3\u30c8\n\u4e0b\u8a18\u306e\u4ee3\u8868\u7684\u306a\u30b3\u30f3\u30dd\u30fc\u30cd\u30f3\u30c8\u304c\u3042\u308b\u3088\u3046\u3067\u3059\u3002\n\nSpark Core\nSpark\u306e\u57fa\u672c\u6a5f\u80fd\u3092\u542b\u3080\u30b3\u30f3\u30dd\u30fc\u30cd\u30f3\u30c8\nSpark SQL\nApache Hive\u306e\u3088\u3046\u306bSQL\u3092\u901a\u3057\u3066\u30c7\u30fc\u30bf\u306b\u30a2\u30af\u30bb\u30b9\nSpark Streaming\n\u30c7\u30fc\u30bf\u306e\u30e9\u30a4\u30d6\u30b9\u30c8\u30ea\u30fc\u30df\u30f3\u30b0\u3092\u53ef\u80fd\u306b\u3059\u308b\u30b3\u30f3\u30dd\u30fc\u30cd\u30f3\u30c8\nMLlib\n\u30de\u30b7\u30f3\u30e9\u30fc\u30cb\u30f3\u30b0\u306e\u30a2\u30eb\u30b4\u30ea\u30ba\u30e0\u3092\u63d0\u4f9b\u3059\u308b\u30b3\u30f3\u30dd\u30fc\u30cd\u30f3\u30c8\nGraphX\n\u30b0\u30e9\u30d5\u30c7\u30fc\u30bf\u51e6\u7406\u306e\u305f\u3081\u306e\u30b3\u30f3\u30dd\u30fc\u30cd\u30f3\u30c8\nCluster Managers\n\u30af\u30e9\u30b9\u30bf\u7ba1\u7406\n\n\nAPI\u3067\u4f7f\u3048\u308b\u8a00\u8a9e\n\u4e0b\u8a18\u306e\u8a00\u8a9e\u306e\u3082\u306e\u304c\u4f7f\u7528\u3067\u304d\u308b\u3088\u3046\u3067\u3059\u3002\n\nPython\nJava\nScala\nSQL\n\nSpark\u81ea\u8eab\u306fScala\u3067\u66f8\u304b\u308c\u3066\u3044\u307e\u3059\u3002\n\nRDDs\u306b\u3064\u3044\u3066\nRDDs(resilient distributed data\u2010 sets)\u3068\u306f\u8907\u6570\u306e\u30af\u30e9\u30b9\u30bf\u306b\u307e\u305f\u304c\u3063\u3066\u4e26\u5217\u5b9f\u884c\u3055\u308c\u308b\u30a2\u30a4\u30c6\u30e0\u306e\u30b3\u30ec\u30af\u30b7\u30e7\u30f3\u306e\u3053\u3068\u3002 \nSpark\u306f\u305d\u308c\u3092\u69cb\u7bc9\u3001\u64cd\u4f5c\u3059\u308bAPI\u3092\u4f7f\u3046\u3053\u3068\u3067\u30d7\u30ed\u30b0\u30e9\u30df\u30f3\u30b0\u3092\u62bd\u8c61\u5316\u3057\u3066\u3044\u308b\u3068\u306e\u3053\u3068\u3067\u3059\u3002\n\nApache Spark\u3092\u8a66\u3057\u3066\u307f\u308b\n\n\u74b0\u5883\n\u8a66\u3057\u305f\u74b0\u5883\u306f\u4ee5\u4e0b\u306e\u3068\u304a\u308a\u3067\u3059\u3002\n\n\n\n\u74b0\u5883\n\u30d0\u30fc\u30b8\u30e7\u30f3\u306a\u3069\n\n\n\n\nOS\nMac OS X Yosemite(10.10.4)\n\n\nJava\n1.7.0\n\n\nScala\n2.11.7\n\n\nGradle\n2.0\n\n\n\n\u203bSpark\u306fscala\u3092\u5185\u5305\u3057\u3066\u3044\u308b\u3088\u3046\u306a\u306e\u3067\u3001spark-shell\u306e\u5b9f\u884c\u3060\u3051\u306a\u3089Scala\u306f\u5fc5\u8981\u3042\u308a\u307e\u305b\u3093\u3002(Gradle\u3082)\n\n\u30a4\u30f3\u30b9\u30c8\u30fc\u30eb\n\u30a4\u30f3\u30b9\u30c8\u30fc\u30eb\u306fMac\u3067\u3042\u308c\u3070homebrew\u3067\u3002\n$ brew install apache-spark\n\n\u5b9f\u884c\u3059\u308b\u3068\u4e0b\u8a18\u306b\u30a4\u30f3\u30b9\u30c8\u30fc\u30eb\u3055\u308c\u307e\u3057\u305f\u3002\n\u73fe\u5728\u306e\u6700\u65b0\u306f1.4.1\u306a\u306e\u3067\u3001\u305d\u308c\u3088\u308a\u306f\u53e4\u3044\u3067\u3059\u3002\n/usr/local/Cellar/apache-spark/1.4.0\n\n\u3061\u306a\u307f\u306bhomebrew\u3060\u3068spark\u3068\u3044\u3046\u30d1\u30c3\u30b1\u30fc\u30b8\u3082\u898b\u3064\u304b\u308b\u306e\u3067\u3059\u304c\u3001\u3053\u308c\u306f\u5225\u7269\u306a\u306e\u3067\u6ce8\u610f\u3057\u3066\u304f\u3060\u3055\u3044\u3002\n[MAC]\u9593\u9055\u3063\u305fspark\u3092\u30a4\u30f3\u30b9\u30c8\u30fc\u30eb\u3057\u3066\u307f\u305f\n\nSpark-shell\u3092\u4f7f\u3063\u3066\u307f\u308b\n\u81ea\u52d5\u7684\u306bPATH\u304c\u901a\u3063\u3066\u3044\u308b\u306e\u3067\u3001\u4e0b\u8a18\u306e\u30b3\u30de\u30f3\u30c9\u3067spark-shell\u3092\u8d77\u52d5\u3057\u307e\u3059\u3002\n$ spark-shell\n\n\u3059\u308b\u3068\u3001\u306a\u3093\u3068Scala\u306e\u30b7\u30a7\u30eb\u304c\u8d77\u52d5\u3057\u307e\u3059\u3002\n\u3061\u306a\u307f\u306b\u3001log4j\u306e\u30ed\u30b0\u304c\u51fa\u307e\u3059\u304c\u3001\u30c7\u30d5\u30a9\u30eb\u30c8\u3060\u3068\u4e0b\u8a18\u306e\u5834\u6240\u306btemplate\u304c\u3042\u308b\u306e\u3067\u3001\u3053\u308c\u3092log4j.properties\u3068\u3044\u3046\u540d\u524d\u3067\u540c\u3058\u30c7\u30a3\u30ec\u30af\u30c8\u30ea\u306b\u30b3\u30d4\u30fc\u3059\u308c\u3070\u30ed\u30b0\u30ec\u30d9\u30eb\u306a\u3069\u3044\u3058\u308c\u307e\u3059\u3002\n/usr/local/Cellar/apache-spark/1.4.0/libexec/conf/log4j.properties.template\n\n\u4f8b\u3048\u3070\u3001\u4e0b\u8a18\u306e\u3088\u3046\u306b\u3059\u308c\u3070WARN\u306e\u307f\u8868\u793a\u3057\u307e\u3059\u3002\n\nlog4j.properties.template\nlog4j.rootCategory=WARN, console\n\n\n\u307e\u305f\u3001spark-shell\u3092\u8d77\u52d5\u3055\u305b\u305f\u72b6\u614b\u3067\u3042\u308c\u3070\u3001\u30d6\u30e9\u30a6\u30b6\u3067\u4e0b\u8a18\u306b\u30a2\u30af\u30bb\u30b9\u3059\u308c\u3070Spark UI\u3092\u307f\u308b\u3053\u3068\u304c\u3067\u304d\u307e\u3059\u3002\n\nhttp://localhost:4040/\n\n\n\u3061\u306a\u307f\u306b\u3001spark-shell\u3092\u8d77\u52d5\u3057\u305f\u6642\u306e\u51fa\u529b\u7d50\u679c\u306f\u4e0b\u8a18\u306e\u901a\u308a\u3067\u3059\u3002\nINFO\u306e\u30ed\u30b0\u304c\u305f\u304f\u3055\u3093\u3042\u3063\u305f\u306e\u3067\u3001\u30ed\u30b0\u30ec\u30d9\u30eb\u3092WARN\u306e\u307f\u306b\u3057\u3066\u8868\u793a\u3057\u3066\u3044\u307e\u3059\u3002\nbash-3.2$ spark-shell\n15/08/09 12:17:58 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\nWelcome to\n      ____              __\n     / __/__  ___ _____/ /__\n    _\\ \\/ _ \\/ _ `/ __/  '_/\n   /___/ .__/\\_,_/_/ /_/\\_\\   version 1.4.0\n      /_/\n\nUsing Scala version 2.10.4 (Java HotSpot(TM) 64-Bit Server VM, Java 1.7.0_60)\nType in expressions to have them evaluated.\nType :help for more information.\nSpark context available as sc.\n15/08/09 12:18:05 WARN Connection: BoneCP specified but not present in CLASSPATH (or one of dependencies)\n15/08/09 12:18:05 WARN Connection: BoneCP specified but not present in CLASSPATH (or one of dependencies)\n15/08/09 12:18:09 WARN ObjectStore: Version information not found in metastore. hive.metastore.schema.verification is not enabled so recording the schema version 0.13.1aa\nSQL context available as sqlContext.\n\n\u6c17\u306b\u306a\u3063\u305f\u3053\u3068\u3068\u3057\u3066\u3002\u3002\u3002\n\nnative-hadoop library\u304cload\u3067\u304d\u3066\u3044\u306a\u3044\nhadoop\u81ea\u4f53\u306f\u30a4\u30f3\u30b9\u30c8\u30fc\u30eb\u3057\u3066\u3044\u305f\u3093\u3060\u3051\u308c\u3069\u3002\u3002\u3002\n\u591a\u5206conf\u306e\u8a2d\u5b9a\u304b\u306a\u3002\nScala\u306e\u30d0\u30fc\u30b8\u30e7\u30f3\u306f2.10.4\n2.11\u7cfb\u3067\u306f\u306a\u3044\u3088\u3046\u3067\u3059\u3002\n\u6700\u65b0\u7248\u306e1.4.1\u306e\u30c9\u30ad\u30e5\u30e1\u30f3\u30c8\u3092\u898b\u308b\u3068\u3001\u4e0b\u8a18\u306e\u3088\u3046\u306b\u66f8\u3044\u3066\u3042\u308a\u3001\u30d3\u30eb\u30c9\u3059\u308c\u3070\u826f\u3044\u69d8\u5b50\u3002\nBuilding for Scala 2.11\n\u305f\u3060\u3057\u3001JDBC\u30b3\u30f3\u30dd\u30fc\u30cd\u30f3\u30c8\u304c2.11\u306b\u5bfe\u5fdc\u3057\u3066\u3044\u306a\u3044\u3089\u3057\u304f\u3001\u307e\u30602.10\u3092\u4f7f\u3046\u306e\u304c\u7121\u96e3\u306a\u3088\u3046\u3067\u3059\u3002\nSpark context\u306a\u308b\u3082\u306e\u3092sc\u3068\u3057\u3066\u4f7f\u3048\u308b\n\u3053\u308c\u306f\u8907\u6570\u306e\u8a08\u7b97\u30af\u30e9\u30b9\u30bf\u306b\u63a5\u7d9a\u3059\u308b\u305f\u3081\u306e\u30aa\u30d6\u30b8\u30a7\u30af\u30c8\u3002\n\u30af\u30e9\u30b9\u30bf\u3078\u306e\u30a2\u30af\u30bb\u30b9\u306fRDDs\u3092\u4ecb\u3057\u3066\u884c\u3046\u306e\u3067\u62bd\u8c61\u5316\u3055\u308c\u3066\u3044\u308b\u3002\nSQL context\u306a\u308b\u3082\u306e\u3092sqlContext\u3068\u3057\u3066\u4f7f\u3048\u308b\n\u4f7f\u3044\u65b9\u306f\u672a\u8abf\u67fb\u3002\n\n\u305d\u308c\u3067\u306f\u5b9f\u969b\u306b\u3001spark-shell\u3092\u89e6\u3063\u3066\u307f\u307e\u3059\u3002\nSpark\u306eQuick Start\u3088\u308a\u3001README.md\u306e\u884c\u6570\u3092\u8abf\u3079\u3066\u307f\u307e\u3059\u3002\nscala> val textFile = sc.textFile(\"/usr/local/Cellar/apache-spark/1.4.0/README.md\")\ntextFile: org.apache.spark.rdd.RDD[String] = MapPartitionsRDD[5] at textFile at <console>:21\n\nscala> textFile.count()\ntextFile.count()\nres3: Long = 98\n\nscala> textFile.first()\ntextFile.first()\nres4: String = # Apache Spark\n\n\u3053\u3053\u3067\u3001\u3053\u306etextFile\u304cRDD\u3068\u547c\u3070\u308c\u308b\u30b3\u30ec\u30af\u30b7\u30e7\u30f3\u306b\u3042\u305f\u308a\u307e\u3059\u3002\nFilter\u3082\u4f7f\u3048\u307e\u3059\u3002Spark\u306eword\u304c\u542b\u307e\u308c\u308bline\u306e\u307f\u3092\u629c\u304d\u51fa\u3057\u3066count\u3092\u8868\u793a\u3055\u305b\u308b\u5834\u5408\u306f\u3001\nscala> val linesWithSpark = textFile.filter(line => line.contains(\"Spark\"))\nval linesWithSpark = textFile.filter(line => line.contains(\"Spark\"))\nlinesWithSpark: org.apache.spark.rdd.RDD[String] = MapPartitionsRDD[6] at filter at <console>:23\n\nscala> linesWithSpark.count()\nlinesWithSpark.count()\nres6: Long = 19\n\nscala> textFile.filter(line => line.contains(\"Spark\")).count()\ntextFile.filter(line => line.contains(\"Spark\")).count()\nres7: Long = 19\n\nFilter\u306e\u3088\u3046\u64cd\u4f5c\u3082\u30af\u30e9\u30b9\u30bf\u306b\u307e\u305f\u304c\u3063\u3066\u5b9f\u884c\u3055\u308c\u308b\u3088\u3046\u3067\u3059\u3002\n\u203bSpark\u306b\u306fAction\u3068Transition\u306e\u95a2\u6570\u304c\u3042\u308a\u3001Transition\u306f\u8907\u6570\u306e\u30ef\u30fc\u30ab\u30fc\u30ce\u30fc\u30c9\u306b\u307e\u305f\u304c\u3063\u3066\u5b9f\u884c\u3055\u308c\u308b(8/15\u8ffd\u8a18)\n\u3061\u306a\u307f\u306b\u3001Scala\u3067\u306f\u306a\u304fPython\u306espark-shell\u3082\u3042\u308a\u307e\u3059\u3002\u305d\u3061\u3089\u3092\u4f7f\u3044\u305f\u3044\u5834\u5408\u306f\u4e0b\u8a18\u3092\u5b9f\u884c\u3057\u307e\u3059\u3002\n$ pyspark\n\n\nStandalone\u30a2\u30d7\u30ea\u30b1\u30fc\u30b7\u30e7\u30f3\u3068\u3057\u3066\u5b9f\u884c\u3057\u3066\u307f\u308b\n\u4eca\u5ea6\u306fspark-shell\u3067\u3084\u3063\u305f\u3053\u3068\u3092Standalone\u306a\u30d7\u30ed\u30b0\u30e9\u30e0\u3067\u5b9f\u884c\u3057\u3066\u307f\u307e\u3059\u3002\n\u30b3\u30fc\u30c9\u306f https://github.com/khiraiwa/spark-learning \u306b\u3042\u308a\u307e\u3059\u3002\nspark-standalone-sample\u3068\u3044\u3046\u30d7\u30ed\u30b8\u30a7\u30af\u30c8\u3067\u3059\u3002\n\n\u30bd\u30fc\u30b9\u30b3\u30fc\u30c9\n\u4e0b\u8a18\u306e\u3088\u3046\u306b\u306a\u308a\u307e\u3059\u3002Document\u306eQuickStart\u3092\u5143\u306b\u3057\u3066\u3044\u307e\u3059\u3002\npackage sample\n\nimport org.apache.spark.{SparkContext, SparkConf}\n\nobject SimpleApp {\n  val file = \"/usr/local/Cellar/apache-spark/1.4.0/README.md\"\n\n  def main(args: Array[String]) {\n\n    // SparkContext\u306e\u521d\u671f\u5316\n    // local\u3092\u6307\u5b9a\u3057\u3066\u3001\u30ed\u30fc\u30ab\u30eb\u30671 thead\u3067\u5b9f\u884c\n    // setMaster\u306f\u7701\u7565\u53ef\n    val conf = new SparkConf().setMaster(\"local\").setAppName(\"spark-standalone-sample\")\n    val sc = new SparkContext(conf)\n\n    // \u30d5\u30a1\u30a4\u30eb\u3092\u8aad\u307f\u8fbc\u307f\u307e\u3059\n    // \u7b2c\u4e8c\u5f15\u6570\u306f\u6700\u5c0f\u30d1\u30fc\u30c6\u30a3\u30b7\u30e7\u30f3(\u5165\u529b\u30c7\u30fc\u30bf\u5206\u5272)\u6570\u3068\u306e\u3053\u3068.\u7701\u7565\u53ef\u80fd.\n    // cache()\u3092\u547c\u3076\u3068\u30af\u30e9\u30b9\u30bf\u30fc\u9593\u3067in-memory\u30ad\u30e3\u30b7\u30e5\u3055\u308c\u307e\u3059\n    val fileData = sc.textFile(file, 2).cache()\n\n    // \u30ab\u30a6\u30f3\u30c8\u3057\u307e\u3059\n    val numAs = fileData.filter(line => line.contains(\"spark\")).count()\n    val numBs = fileData.filter(line => line.contains(\"scala\")).count()\n    println(\"Lines with a: %s, Lines with b: %s\".format(numAs, numBs))\n  }\n}\n\n\u307b\u3068\u3093\u3069spark-shell\u3067\u3084\u3063\u3066\u3044\u305f\u3053\u3068\u3001\u305d\u306e\u307e\u307e\u3067\u3059\u3002\n\n\u30d3\u30eb\u30c9\u3068\u5b9f\u884c\nQuickStart\u3067\u306fsbt\u3067\u3084\u3063\u3066\u3044\u307e\u3059\u304c\u3001\u3053\u3053\u3067\u306fGradle\u3067\u3084\u3063\u3066\u307f\u307e\u3057\u305f\u3002\n\u5b9f\u884c\u306b\u306fSpark Core\u306e\u30b3\u30f3\u30dd\u30fc\u30cd\u30f3\u30c8\u304c\u5fc5\u8981\u3067\u3059\u3002\n2.11\u7cfb\u306espark-core\u30e9\u30a4\u30d6\u30e9\u30ea\u304cMaven Central\u306b\u4e0a\u304c\u3063\u3066\u3044\u308b\u306e\u3067\u3001build.gradle\u306b\u4e0b\u8a18\u306e\u3088\u3046\u306b\u66f8\u304f\u3060\u3051\u30672.11\u7cfb\u5bfe\u5fdc\u306espark\u304c\u4f7f\u3048\u307e\u3059\u3002  \n\u307e\u305f\u3001manifest\u306eMain-Class\u3092\u6307\u5b9a\u3057\u3066\u304a\u304b\u306a\u3044\u3068\u3001\u5b9f\u884c\u6642\u306b--class\u30aa\u30d7\u30b7\u30e7\u30f3\u3067\u30af\u30e9\u30b9\u540d\u3092\u6e21\u3059\u5fc5\u8981\u304c\u51fa\u3066\u304d\u307e\u3059\u3002\n\nspark-standalone-sample/build.gradle\ndependencies {\n  compile \"org.scala-lang:scala-compiler:2.11.7\"\n  compile \"org.scala-lang:scala-library:2.11.7\"\n  compile \"org.apache.spark:spark-core_2.11:1.4.1\"\n}\n\njar {\n  manifest {\n    attributes \"Main-Class\" : \"sample.SimpleApp\"\n  }\n  from configurations.compile.collect { it.isDirectory() ? it : zipTree(it) }\n}\n\n\n\u5b9f\u884c\u306f\u3001\u4e0b\u8a18\u306e\u3088\u3046\u306b\u3001spark-submit\u30b3\u30de\u30f3\u30c9\u3092\u4f7f\u3044\u307e\u3059\u3002\n$ git clone git@github.com:khiraiwa/spark-learning.git\n$ cd cd spark-learning/spark-standalone-sample/\n$ gradle shadowJar\n:compileJava UP-TO-DATE\n:compileScala\n:processResources UP-TO-DATE\n:classes\n:shadowJar\n\nBUILD SUCCESSFUL\n\nTotal time: 45.596 secs\n$ spark-submit build/libs/spark-standalone-sample-0.1-all.jar \n15/08/09 16:47:27 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\nLines with a: 11, Lines with b: 1\n\n\u6b63\u3057\u304f\u7d50\u679c\u304c\u8868\u793a\u3055\u308c\u307e\u3057\u305f\u3002\n\u3061\u306a\u307f\u306b\u30a2\u30d7\u30ea\u30b1\u30fc\u30b7\u30e7\u30f3\u5b9f\u884c\u4e2d\u3082\u3001\u4e0a\u8a18\u306eSpark UI\u306b\u30a2\u30af\u30bb\u30b9\u3057\u3066\u9032\u6357\u306a\u3069\u898b\u308c\u308b\u3088\u3046\u3067\u3059\u3002\n\n\u88dc\u8db3\n\u666e\u901a\u306bgradle jar\u30b3\u30de\u30f3\u30c9\u7b49\u3067\u4f5c\u3063\u305fJAR\u30d5\u30a1\u30a4\u30eb\u3092\u5b9f\u884c\u3059\u308b\u3068\u4e0b\u8a18\u306eException\u304c\u51fa\u3066\u7d42\u4e86\u3057\u3066\u3057\u307e\u3044\u307e\u3059\u3002\nbash-3.2$ spark-submit build/libs/spark-standalone-sample-0.1.jar \nspark-submit build/libs/spark-standalone-sample-0.1.jar \nException in thread \"main\" java.lang.SecurityException: Invalid signature file digest for Manifest main attributes\n\n\u3069\u3046\u3084\u3089META-INF\u306e\u4e2d\u306esignature file\u306e\u554f\u984c\u306e\u3088\u3046\u3067\u3059\u3002\n\u89e3\u6c7a\u65b9\u6cd5\u306fJAR\u30d5\u30a1\u30a4\u30eb\u306e\u4e2d\u306eMETA-INF/ECLIPSEF.RSA\u3092\u524a\u9664\u3057\u3066\u518d\u3073JAR\u306b\u623b\u305b\u3070\u826f\u3044\u306e\u3067\u4e0b\u8a18\u306e\u3088\u3046\u306b\u3059\u308c\u3070\u3088\u3044\u3067\u3059\u3002\nzip -d spark-standalone-sample-0.1.jar META-INF/*.RSA META-INF/*.DSA\n\n\u3057\u304b\u3057\u3001\u6bce\u56de\u4f5c\u308a\u306a\u304a\u3059\u306e\u306f\u9762\u5012\u3060\u3057\u3001\u4eca\u56de\u306fGradle\u3092\u4f7f\u3063\u3066\u3044\u308b\u306e\u3067\u3001Gradle Shadow\u30d7\u30e9\u30b0\u30a4\u30f3\u3092\u4f7f\u3063\u3066JAR\u30d5\u30a1\u30a4\u30eb\u4f5c\u6210\u6642\u306bExclude\u3059\u308b\u3088\u3046\u306b\u3057\u307e\u3057\u305f\u3002\n\nspark-standalone-sample/build.gradle\nshadowJar {\n  mergeServiceFiles {\n    exclude 'META-INF/ECLIPSEF.RSA'\n  }\n}\n\n\n\u4eca\u65e5\u306e\u3068\u3053\u308d\u306f\u3053\u3053\u307e\u3067\u3002\n\n\u53c2\u8003\n\nLearning Spark\n\nSpark\u306eDocument\n\nApache Spark\u304cHadoop\u3088\u308a\u3044\u3051\u3066\u305d\u3046\u306a\u306e\u3067\u8abf\u3079\u3066\u4f7f\u3063\u3066\u307f\u307e\u3057\u305f\u3002\n\n# Apache Spark\u306b\u3064\u3044\u3066\n## \u6982\u8981\nSpark\u3068\u306fHadoop(MapReduce)\u3092\u62e1\u5f35\u3057\u305f\u6b21\u4e16\u4ee3\u306e\u30d3\u30c3\u30af\u30c7\u30fc\u30bf\u89e3\u6790\u30a8\u30f3\u30b8\u30f3\u3002\n\n* \u30ea\u30c3\u30c1\u306aAPI\u304c\u3042\u308b\u306e\u3067\u3001\u4f7f\u3046\u306e\u304c\u3088\u308a\u7c21\u5358\n* \u3088\u308a\u9ad8\u901f\n* \u5bfe\u8a71\u7684\u30af\u30a8\u30ea\u3001\u30b9\u30c8\u30ea\u30fc\u30df\u30f3\u30b0\u3001\u30de\u30b7\u30f3\u30e9\u30fc\u30cb\u30f3\u30b0\u3001\u30b0\u30e9\u30d5\u51e6\u7406\u306a\u3069\u3092\u30b5\u30dd\u30fc\u30c8\n\nHadoop\u306eMapReduce\u306e\u6642\u306fdisk\u4e0a\u3067\u8a08\u7b97\u304c\u8d70\u3063\u3066\u3044\u305f\u3051\u308c\u3069\u3001\u30e1\u30e2\u30ea\u4e0a\u3067\u8d70\u3089\u305b\u308b\u3053\u3068\u304c\u9ad8\u901f\u5316\u306e\u8981\u56e0\u306e\u4e00\u3064\u306e\u3088\u3046\u3067\u3059\u3002\n\n## \u30b3\u30f3\u30dd\u30fc\u30cd\u30f3\u30c8\n\u4e0b\u8a18\u306e\u4ee3\u8868\u7684\u306a\u30b3\u30f3\u30dd\u30fc\u30cd\u30f3\u30c8\u304c\u3042\u308b\u3088\u3046\u3067\u3059\u3002\n\n* Spark Core  \nSpark\u306e\u57fa\u672c\u6a5f\u80fd\u3092\u542b\u3080\u30b3\u30f3\u30dd\u30fc\u30cd\u30f3\u30c8\n* Spark SQL  \nApache Hive\u306e\u3088\u3046\u306bSQL\u3092\u901a\u3057\u3066\u30c7\u30fc\u30bf\u306b\u30a2\u30af\u30bb\u30b9\n* Spark Streaming  \n\u30c7\u30fc\u30bf\u306e\u30e9\u30a4\u30d6\u30b9\u30c8\u30ea\u30fc\u30df\u30f3\u30b0\u3092\u53ef\u80fd\u306b\u3059\u308b\u30b3\u30f3\u30dd\u30fc\u30cd\u30f3\u30c8\n* MLlib  \n\u30de\u30b7\u30f3\u30e9\u30fc\u30cb\u30f3\u30b0\u306e\u30a2\u30eb\u30b4\u30ea\u30ba\u30e0\u3092\u63d0\u4f9b\u3059\u308b\u30b3\u30f3\u30dd\u30fc\u30cd\u30f3\u30c8\n* GraphX  \n\u30b0\u30e9\u30d5\u30c7\u30fc\u30bf\u51e6\u7406\u306e\u305f\u3081\u306e\u30b3\u30f3\u30dd\u30fc\u30cd\u30f3\u30c8\n* Cluster Managers  \n\u30af\u30e9\u30b9\u30bf\u7ba1\u7406\n\n## API\u3067\u4f7f\u3048\u308b\u8a00\u8a9e\n\u4e0b\u8a18\u306e\u8a00\u8a9e\u306e\u3082\u306e\u304c\u4f7f\u7528\u3067\u304d\u308b\u3088\u3046\u3067\u3059\u3002\n\n* Python\n* Java\n* Scala\n* SQL\n\nSpark\u81ea\u8eab\u306fScala\u3067\u66f8\u304b\u308c\u3066\u3044\u307e\u3059\u3002\n\n## RDDs\u306b\u3064\u3044\u3066\nRDDs(resilient distributed data\u2010 sets)\u3068\u306f\u8907\u6570\u306e\u30af\u30e9\u30b9\u30bf\u306b\u307e\u305f\u304c\u3063\u3066\u4e26\u5217\u5b9f\u884c\u3055\u308c\u308b\u30a2\u30a4\u30c6\u30e0\u306e\u30b3\u30ec\u30af\u30b7\u30e7\u30f3\u306e\u3053\u3068\u3002 \nSpark\u306f\u305d\u308c\u3092\u69cb\u7bc9\u3001\u64cd\u4f5c\u3059\u308bAPI\u3092\u4f7f\u3046\u3053\u3068\u3067\u30d7\u30ed\u30b0\u30e9\u30df\u30f3\u30b0\u3092\u62bd\u8c61\u5316\u3057\u3066\u3044\u308b\u3068\u306e\u3053\u3068\u3067\u3059\u3002\n\n# Apache Spark\u3092\u8a66\u3057\u3066\u307f\u308b\n## \u74b0\u5883\n\u8a66\u3057\u305f\u74b0\u5883\u306f\u4ee5\u4e0b\u306e\u3068\u304a\u308a\u3067\u3059\u3002\n\n|\u74b0\u5883         |              \u30d0\u30fc\u30b8\u30e7\u30f3\u306a\u3069|\n|:-----------|-------------------------:|\n| OS         |Mac OS X Yosemite(10.10.4)|\n| Java       |                    1.7.0 |\n| Scala      |                   2.11.7 |\n| Gradle     |                      2.0 |\n\n\u203bSpark\u306fscala\u3092\u5185\u5305\u3057\u3066\u3044\u308b\u3088\u3046\u306a\u306e\u3067\u3001spark-shell\u306e\u5b9f\u884c\u3060\u3051\u306a\u3089Scala\u306f\u5fc5\u8981\u3042\u308a\u307e\u305b\u3093\u3002(Gradle\u3082)\n\n## \u30a4\u30f3\u30b9\u30c8\u30fc\u30eb\n\u30a4\u30f3\u30b9\u30c8\u30fc\u30eb\u306fMac\u3067\u3042\u308c\u3070homebrew\u3067\u3002\n\n```bash\n$ brew install apache-spark\n```\n\n\u5b9f\u884c\u3059\u308b\u3068\u4e0b\u8a18\u306b\u30a4\u30f3\u30b9\u30c8\u30fc\u30eb\u3055\u308c\u307e\u3057\u305f\u3002  \n\u73fe\u5728\u306e\u6700\u65b0\u306f1.4.1\u306a\u306e\u3067\u3001\u305d\u308c\u3088\u308a\u306f\u53e4\u3044\u3067\u3059\u3002\n\n```\n/usr/local/Cellar/apache-spark/1.4.0\n```\n\n\u3061\u306a\u307f\u306bhomebrew\u3060\u3068spark\u3068\u3044\u3046\u30d1\u30c3\u30b1\u30fc\u30b8\u3082\u898b\u3064\u304b\u308b\u306e\u3067\u3059\u304c\u3001\u3053\u308c\u306f\u5225\u7269\u306a\u306e\u3067\u6ce8\u610f\u3057\u3066\u304f\u3060\u3055\u3044\u3002\n[[MAC]\u9593\u9055\u3063\u305fspark\u3092\u30a4\u30f3\u30b9\u30c8\u30fc\u30eb\u3057\u3066\u307f\u305f](http://qiita.com/imura81gt/items/bc1e3142a2534523a69d)\n\n## Spark-shell\u3092\u4f7f\u3063\u3066\u307f\u308b\n\n\u81ea\u52d5\u7684\u306bPATH\u304c\u901a\u3063\u3066\u3044\u308b\u306e\u3067\u3001\u4e0b\u8a18\u306e\u30b3\u30de\u30f3\u30c9\u3067spark-shell\u3092\u8d77\u52d5\u3057\u307e\u3059\u3002\n\n```bash\n$ spark-shell\n```\n\u3059\u308b\u3068\u3001\u306a\u3093\u3068Scala\u306e\u30b7\u30a7\u30eb\u304c\u8d77\u52d5\u3057\u307e\u3059\u3002\n\n\u3061\u306a\u307f\u306b\u3001log4j\u306e\u30ed\u30b0\u304c\u51fa\u307e\u3059\u304c\u3001\u30c7\u30d5\u30a9\u30eb\u30c8\u3060\u3068\u4e0b\u8a18\u306e\u5834\u6240\u306btemplate\u304c\u3042\u308b\u306e\u3067\u3001\u3053\u308c\u3092log4j.properties\u3068\u3044\u3046\u540d\u524d\u3067\u540c\u3058\u30c7\u30a3\u30ec\u30af\u30c8\u30ea\u306b\u30b3\u30d4\u30fc\u3059\u308c\u3070\u30ed\u30b0\u30ec\u30d9\u30eb\u306a\u3069\u3044\u3058\u308c\u307e\u3059\u3002\n\n```\n/usr/local/Cellar/apache-spark/1.4.0/libexec/conf/log4j.properties.template\n```\n\n\u4f8b\u3048\u3070\u3001\u4e0b\u8a18\u306e\u3088\u3046\u306b\u3059\u308c\u3070WARN\u306e\u307f\u8868\u793a\u3057\u307e\u3059\u3002\n\n```bash:log4j.properties.template\nlog4j.rootCategory=WARN, console\n```\n\n\u307e\u305f\u3001spark-shell\u3092\u8d77\u52d5\u3055\u305b\u305f\u72b6\u614b\u3067\u3042\u308c\u3070\u3001\u30d6\u30e9\u30a6\u30b6\u3067\u4e0b\u8a18\u306b\u30a2\u30af\u30bb\u30b9\u3059\u308c\u3070Spark UI\u3092\u307f\u308b\u3053\u3068\u304c\u3067\u304d\u307e\u3059\u3002\n```\nhttp://localhost:4040/\n```\n![SparkUI.png](https://qiita-image-store.s3.amazonaws.com/0/45959/c25f2146-7c58-7c1d-197e-585fd17516b3.png)\n\n\u3061\u306a\u307f\u306b\u3001spark-shell\u3092\u8d77\u52d5\u3057\u305f\u6642\u306e\u51fa\u529b\u7d50\u679c\u306f\u4e0b\u8a18\u306e\u901a\u308a\u3067\u3059\u3002  \nINFO\u306e\u30ed\u30b0\u304c\u305f\u304f\u3055\u3093\u3042\u3063\u305f\u306e\u3067\u3001\u30ed\u30b0\u30ec\u30d9\u30eb\u3092WARN\u306e\u307f\u306b\u3057\u3066\u8868\u793a\u3057\u3066\u3044\u307e\u3059\u3002\n\n```bash\nbash-3.2$ spark-shell\n15/08/09 12:17:58 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\nWelcome to\n      ____              __\n     / __/__  ___ _____/ /__\n    _\\ \\/ _ \\/ _ `/ __/  '_/\n   /___/ .__/\\_,_/_/ /_/\\_\\   version 1.4.0\n      /_/\n\nUsing Scala version 2.10.4 (Java HotSpot(TM) 64-Bit Server VM, Java 1.7.0_60)\nType in expressions to have them evaluated.\nType :help for more information.\nSpark context available as sc.\n15/08/09 12:18:05 WARN Connection: BoneCP specified but not present in CLASSPATH (or one of dependencies)\n15/08/09 12:18:05 WARN Connection: BoneCP specified but not present in CLASSPATH (or one of dependencies)\n15/08/09 12:18:09 WARN ObjectStore: Version information not found in metastore. hive.metastore.schema.verification is not enabled so recording the schema version 0.13.1aa\nSQL context available as sqlContext.\n```\n\u6c17\u306b\u306a\u3063\u305f\u3053\u3068\u3068\u3057\u3066\u3002\u3002\u3002\n\n* native-hadoop library\u304cload\u3067\u304d\u3066\u3044\u306a\u3044  \nhadoop\u81ea\u4f53\u306f\u30a4\u30f3\u30b9\u30c8\u30fc\u30eb\u3057\u3066\u3044\u305f\u3093\u3060\u3051\u308c\u3069\u3002\u3002\u3002  \n\u591a\u5206conf\u306e\u8a2d\u5b9a\u304b\u306a\u3002\n* Scala\u306e\u30d0\u30fc\u30b8\u30e7\u30f3\u306f2.10.4  \n2.11\u7cfb\u3067\u306f\u306a\u3044\u3088\u3046\u3067\u3059\u3002  \n\u6700\u65b0\u7248\u306e1.4.1\u306e\u30c9\u30ad\u30e5\u30e1\u30f3\u30c8\u3092\u898b\u308b\u3068\u3001\u4e0b\u8a18\u306e\u3088\u3046\u306b\u66f8\u3044\u3066\u3042\u308a\u3001\u30d3\u30eb\u30c9\u3059\u308c\u3070\u826f\u3044\u69d8\u5b50\u3002  \n[Building for Scala 2.11](http://spark.apache.org/docs/latest/building-spark.html#building-for-scala-211)  \n\u305f\u3060\u3057\u3001JDBC\u30b3\u30f3\u30dd\u30fc\u30cd\u30f3\u30c8\u304c2.11\u306b\u5bfe\u5fdc\u3057\u3066\u3044\u306a\u3044\u3089\u3057\u304f\u3001\u307e\u30602.10\u3092\u4f7f\u3046\u306e\u304c\u7121\u96e3\u306a\u3088\u3046\u3067\u3059\u3002\n* Spark context\u306a\u308b\u3082\u306e\u3092sc\u3068\u3057\u3066\u4f7f\u3048\u308b  \n\u3053\u308c\u306f\u8907\u6570\u306e\u8a08\u7b97\u30af\u30e9\u30b9\u30bf\u306b\u63a5\u7d9a\u3059\u308b\u305f\u3081\u306e\u30aa\u30d6\u30b8\u30a7\u30af\u30c8\u3002  \n\u30af\u30e9\u30b9\u30bf\u3078\u306e\u30a2\u30af\u30bb\u30b9\u306fRDDs\u3092\u4ecb\u3057\u3066\u884c\u3046\u306e\u3067\u62bd\u8c61\u5316\u3055\u308c\u3066\u3044\u308b\u3002\n* SQL context\u306a\u308b\u3082\u306e\u3092sqlContext\u3068\u3057\u3066\u4f7f\u3048\u308b  \n\u4f7f\u3044\u65b9\u306f\u672a\u8abf\u67fb\u3002\n\n\u305d\u308c\u3067\u306f\u5b9f\u969b\u306b\u3001spark-shell\u3092\u89e6\u3063\u3066\u307f\u307e\u3059\u3002  \nSpark\u306e[Quick Start](http://spark.apache.org/docs/latest/quick-start.html)\u3088\u308a\u3001README.md\u306e\u884c\u6570\u3092\u8abf\u3079\u3066\u307f\u307e\u3059\u3002\n\n```scala\nscala> val textFile = sc.textFile(\"/usr/local/Cellar/apache-spark/1.4.0/README.md\")\ntextFile: org.apache.spark.rdd.RDD[String] = MapPartitionsRDD[5] at textFile at <console>:21\n\nscala> textFile.count()\ntextFile.count()\nres3: Long = 98\n\nscala> textFile.first()\ntextFile.first()\nres4: String = # Apache Spark\n```\n\u3053\u3053\u3067\u3001\u3053\u306etextFile\u304cRDD\u3068\u547c\u3070\u308c\u308b\u30b3\u30ec\u30af\u30b7\u30e7\u30f3\u306b\u3042\u305f\u308a\u307e\u3059\u3002\n\nFilter\u3082\u4f7f\u3048\u307e\u3059\u3002Spark\u306eword\u304c\u542b\u307e\u308c\u308bline\u306e\u307f\u3092\u629c\u304d\u51fa\u3057\u3066count\u3092\u8868\u793a\u3055\u305b\u308b\u5834\u5408\u306f\u3001\n\n```scala\nscala> val linesWithSpark = textFile.filter(line => line.contains(\"Spark\"))\nval linesWithSpark = textFile.filter(line => line.contains(\"Spark\"))\nlinesWithSpark: org.apache.spark.rdd.RDD[String] = MapPartitionsRDD[6] at filter at <console>:23\n\nscala> linesWithSpark.count()\nlinesWithSpark.count()\nres6: Long = 19\n\nscala> textFile.filter(line => line.contains(\"Spark\")).count()\ntextFile.filter(line => line.contains(\"Spark\")).count()\nres7: Long = 19\n```\nFilter\u306e\u3088\u3046\u64cd\u4f5c\u3082\u30af\u30e9\u30b9\u30bf\u306b\u307e\u305f\u304c\u3063\u3066\u5b9f\u884c\u3055\u308c\u308b\u3088\u3046\u3067\u3059\u3002\n\u203bSpark\u306b\u306fAction\u3068Transition\u306e\u95a2\u6570\u304c\u3042\u308a\u3001Transition\u306f\u8907\u6570\u306e\u30ef\u30fc\u30ab\u30fc\u30ce\u30fc\u30c9\u306b\u307e\u305f\u304c\u3063\u3066\u5b9f\u884c\u3055\u308c\u308b(8/15\u8ffd\u8a18)\n\n\u3061\u306a\u307f\u306b\u3001Scala\u3067\u306f\u306a\u304fPython\u306espark-shell\u3082\u3042\u308a\u307e\u3059\u3002\u305d\u3061\u3089\u3092\u4f7f\u3044\u305f\u3044\u5834\u5408\u306f\u4e0b\u8a18\u3092\u5b9f\u884c\u3057\u307e\u3059\u3002\n\n```bash\n$ pyspark\n```\n\n## Standalone\u30a2\u30d7\u30ea\u30b1\u30fc\u30b7\u30e7\u30f3\u3068\u3057\u3066\u5b9f\u884c\u3057\u3066\u307f\u308b\n\n\u4eca\u5ea6\u306fspark-shell\u3067\u3084\u3063\u305f\u3053\u3068\u3092Standalone\u306a\u30d7\u30ed\u30b0\u30e9\u30e0\u3067\u5b9f\u884c\u3057\u3066\u307f\u307e\u3059\u3002  \n\u30b3\u30fc\u30c9\u306f https://github.com/khiraiwa/spark-learning \u306b\u3042\u308a\u307e\u3059\u3002  \nspark-standalone-sample\u3068\u3044\u3046\u30d7\u30ed\u30b8\u30a7\u30af\u30c8\u3067\u3059\u3002\n\n### \u30bd\u30fc\u30b9\u30b3\u30fc\u30c9\n\u4e0b\u8a18\u306e\u3088\u3046\u306b\u306a\u308a\u307e\u3059\u3002Document\u306eQuickStart\u3092\u5143\u306b\u3057\u3066\u3044\u307e\u3059\u3002\n\n```scala\npackage sample\n\nimport org.apache.spark.{SparkContext, SparkConf}\n\nobject SimpleApp {\n  val file = \"/usr/local/Cellar/apache-spark/1.4.0/README.md\"\n\n  def main(args: Array[String]) {\n\n    // SparkContext\u306e\u521d\u671f\u5316\n    // local\u3092\u6307\u5b9a\u3057\u3066\u3001\u30ed\u30fc\u30ab\u30eb\u30671 thead\u3067\u5b9f\u884c\n    // setMaster\u306f\u7701\u7565\u53ef\n    val conf = new SparkConf().setMaster(\"local\").setAppName(\"spark-standalone-sample\")\n    val sc = new SparkContext(conf)\n\n    // \u30d5\u30a1\u30a4\u30eb\u3092\u8aad\u307f\u8fbc\u307f\u307e\u3059\n    // \u7b2c\u4e8c\u5f15\u6570\u306f\u6700\u5c0f\u30d1\u30fc\u30c6\u30a3\u30b7\u30e7\u30f3(\u5165\u529b\u30c7\u30fc\u30bf\u5206\u5272)\u6570\u3068\u306e\u3053\u3068.\u7701\u7565\u53ef\u80fd.\n    // cache()\u3092\u547c\u3076\u3068\u30af\u30e9\u30b9\u30bf\u30fc\u9593\u3067in-memory\u30ad\u30e3\u30b7\u30e5\u3055\u308c\u307e\u3059\n    val fileData = sc.textFile(file, 2).cache()\n\n    // \u30ab\u30a6\u30f3\u30c8\u3057\u307e\u3059\n    val numAs = fileData.filter(line => line.contains(\"spark\")).count()\n    val numBs = fileData.filter(line => line.contains(\"scala\")).count()\n    println(\"Lines with a: %s, Lines with b: %s\".format(numAs, numBs))\n  }\n}\n```\n\u307b\u3068\u3093\u3069spark-shell\u3067\u3084\u3063\u3066\u3044\u305f\u3053\u3068\u3001\u305d\u306e\u307e\u307e\u3067\u3059\u3002\n\n### \u30d3\u30eb\u30c9\u3068\u5b9f\u884c\nQuickStart\u3067\u306fsbt\u3067\u3084\u3063\u3066\u3044\u307e\u3059\u304c\u3001\u3053\u3053\u3067\u306fGradle\u3067\u3084\u3063\u3066\u307f\u307e\u3057\u305f\u3002\n\n\u5b9f\u884c\u306b\u306fSpark Core\u306e\u30b3\u30f3\u30dd\u30fc\u30cd\u30f3\u30c8\u304c\u5fc5\u8981\u3067\u3059\u3002\n\n2.11\u7cfb\u306espark-core\u30e9\u30a4\u30d6\u30e9\u30ea\u304cMaven Central\u306b\u4e0a\u304c\u3063\u3066\u3044\u308b\u306e\u3067\u3001build.gradle\u306b\u4e0b\u8a18\u306e\u3088\u3046\u306b\u66f8\u304f\u3060\u3051\u30672.11\u7cfb\u5bfe\u5fdc\u306espark\u304c\u4f7f\u3048\u307e\u3059\u3002  \n\n\u307e\u305f\u3001manifest\u306eMain-Class\u3092\u6307\u5b9a\u3057\u3066\u304a\u304b\u306a\u3044\u3068\u3001\u5b9f\u884c\u6642\u306b--class\u30aa\u30d7\u30b7\u30e7\u30f3\u3067\u30af\u30e9\u30b9\u540d\u3092\u6e21\u3059\u5fc5\u8981\u304c\u51fa\u3066\u304d\u307e\u3059\u3002\n\n```groovy:spark-standalone-sample/build.gradle\ndependencies {\n  compile \"org.scala-lang:scala-compiler:2.11.7\"\n  compile \"org.scala-lang:scala-library:2.11.7\"\n  compile \"org.apache.spark:spark-core_2.11:1.4.1\"\n}\n\njar {\n  manifest {\n    attributes \"Main-Class\" : \"sample.SimpleApp\"\n  }\n  from configurations.compile.collect { it.isDirectory() ? it : zipTree(it) }\n}\n```\n\n\u5b9f\u884c\u306f\u3001\u4e0b\u8a18\u306e\u3088\u3046\u306b\u3001spark-submit\u30b3\u30de\u30f3\u30c9\u3092\u4f7f\u3044\u307e\u3059\u3002\n\n```bash\n$ git clone git@github.com:khiraiwa/spark-learning.git\n$ cd cd spark-learning/spark-standalone-sample/\n$ gradle shadowJar\n:compileJava UP-TO-DATE\n:compileScala\n:processResources UP-TO-DATE\n:classes\n:shadowJar\n\nBUILD SUCCESSFUL\n\nTotal time: 45.596 secs\n$ spark-submit build/libs/spark-standalone-sample-0.1-all.jar \n15/08/09 16:47:27 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\nLines with a: 11, Lines with b: 1\n```\n\u6b63\u3057\u304f\u7d50\u679c\u304c\u8868\u793a\u3055\u308c\u307e\u3057\u305f\u3002  \n\u3061\u306a\u307f\u306b\u30a2\u30d7\u30ea\u30b1\u30fc\u30b7\u30e7\u30f3\u5b9f\u884c\u4e2d\u3082\u3001\u4e0a\u8a18\u306eSpark UI\u306b\u30a2\u30af\u30bb\u30b9\u3057\u3066\u9032\u6357\u306a\u3069\u898b\u308c\u308b\u3088\u3046\u3067\u3059\u3002\n\n### \u88dc\u8db3\n\u666e\u901a\u306bgradle jar\u30b3\u30de\u30f3\u30c9\u7b49\u3067\u4f5c\u3063\u305fJAR\u30d5\u30a1\u30a4\u30eb\u3092\u5b9f\u884c\u3059\u308b\u3068\u4e0b\u8a18\u306eException\u304c\u51fa\u3066\u7d42\u4e86\u3057\u3066\u3057\u307e\u3044\u307e\u3059\u3002\n\n```bash\nbash-3.2$ spark-submit build/libs/spark-standalone-sample-0.1.jar \nspark-submit build/libs/spark-standalone-sample-0.1.jar \nException in thread \"main\" java.lang.SecurityException: Invalid signature file digest for Manifest main attributes\n```\n\u3069\u3046\u3084\u3089META-INF\u306e\u4e2d\u306esignature file\u306e\u554f\u984c\u306e\u3088\u3046\u3067\u3059\u3002  \n\u89e3\u6c7a\u65b9\u6cd5\u306fJAR\u30d5\u30a1\u30a4\u30eb\u306e\u4e2d\u306eMETA-INF/ECLIPSEF.RSA\u3092\u524a\u9664\u3057\u3066\u518d\u3073JAR\u306b\u623b\u305b\u3070\u826f\u3044\u306e\u3067\u4e0b\u8a18\u306e\u3088\u3046\u306b\u3059\u308c\u3070\u3088\u3044\u3067\u3059\u3002\n\n```\nzip -d spark-standalone-sample-0.1.jar META-INF/*.RSA META-INF/*.DSA\n```\n\n\u3057\u304b\u3057\u3001\u6bce\u56de\u4f5c\u308a\u306a\u304a\u3059\u306e\u306f\u9762\u5012\u3060\u3057\u3001\u4eca\u56de\u306fGradle\u3092\u4f7f\u3063\u3066\u3044\u308b\u306e\u3067\u3001Gradle Shadow\u30d7\u30e9\u30b0\u30a4\u30f3\u3092\u4f7f\u3063\u3066JAR\u30d5\u30a1\u30a4\u30eb\u4f5c\u6210\u6642\u306bExclude\u3059\u308b\u3088\u3046\u306b\u3057\u307e\u3057\u305f\u3002\n\n```groovy:spark-standalone-sample/build.gradle\nshadowJar {\n  mergeServiceFiles {\n    exclude 'META-INF/ECLIPSEF.RSA'\n  }\n}\n```\n\n\u4eca\u65e5\u306e\u3068\u3053\u308d\u306f\u3053\u3053\u307e\u3067\u3002\n\n# \u53c2\u8003\n* [Learning Spark](http://shop.oreilly.com/product/0636920028512.do)\n* [Spark\u306eDocument](http://spark.apache.org/docs/latest/)\n<script>\n  (function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){\n  (i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),\n  m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)\n  })(window,document,'script','//www.google-analytics.com/analytics.js','ga');\n\n  ga('create', 'UA-66125452-1', 'auto');\n  ga('send', 'pageview');\n\n</script>\n", "tags": ["Spark", "Scala", "gradle", "Apache", "Mac"]}