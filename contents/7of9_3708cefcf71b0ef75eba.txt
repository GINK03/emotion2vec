{"context": "\n\nTensorFlow\n\n\u52d5\u4f5c\u74b0\u5883\nGeForce GTX 1070 (8GB)\nASRock Z170M Pro4S [Intel Z170chipset]\nUbuntu 14.04 LTS desktop amd64\nTensorFlow v0.11\ncuDNN v5.1 for Linux\nCUDA v8.0\nPython 2.7.6\nIPython 5.1.0 -- An enhanced Interactive Python.\ngcc (Ubuntu 4.8.4-2ubuntu1~14.04.3) 4.8.4\n\n\nv0.1 http://qiita.com/7of9/items/8b43357bcaea1f1bce4b\nv0.5 http://qiita.com/7of9/items/e82451a71f017db03749\nTensorFlow\u3092\u4f7f\u3063\u3066\u3001input:100, output:100\u7a0b\u5ea6\u306e\u30cd\u30c3\u30c8\u30ef\u30fc\u30af\u306e\u5b66\u7fd2\u3092\u3057\u3088\u3046\u304b\u3068\u691c\u8a0e\u4e2d\u3002\n\nv0.6\n\n\u5909\u66f4\u7b87\u6240\nv0.5\u306b\u3066\u4f5c\u6210\u3057\u305f\u30d5\u30a1\u30a4\u30eb\u3092\u5143\u306bTensorFlow\u3092\u52d5\u304b\u305d\u3046\u3068\u3057\u3066\u3044\u305f\u304c\u3001\u30a8\u30e9\u30fc\u304c\u51fa\u3066\u3046\u307e\u304f\u52d5\u304b\u306a\u304b\u3063\u305f\u3002\n\u30a8\u30e9\u30fc\u3092\u8ffd\u8de1\u3057\u3088\u3046\u3068\u3057\u305f\u304c\u3001\u4e00\u3064\u306e\u30a8\u30e9\u30fc\u3092\u5bfe\u51e6\u3057\u305f\u3064\u3082\u308a\u304c\u3001\u5225\u306e\u30a8\u30e9\u30fc\u304c\u51fa\u308b\u3088\u3046\u306b\u306a\u3063\u3066\u3044\u305f\u3002\n\u8aad\u8fbc\u307f\u30d5\u30a1\u30a4\u30eb\u3092\u898b\u306a\u304a\u3057\u305f\u3068\u3053\u308d\u3001\",\"\u304c\u306a\u3044\u72b6\u614b\u3067\u4fdd\u5b58\u3057\u3066\u3044\u305f\u3002\ndef saveToCsvFile(data_1d, filename):\n    wrk_1d = data_1d.reshape(1, INDIM)\n    # np.savetxt(filename, wrk_1d, delimiter=',')\n    with open(filename, 'a') as fd:\n        np.savetxt(fd, wrk_1d)\n\n\u3092\u4ee5\u4e0b\u306e\u3088\u3046\u306b\u4fee\u6b63\u3057\u305f\u3002\ndef saveToCsvFile(data_1d, filename):\n    wrk_1d = data_1d.reshape(1, INDIM)\n    # np.savetxt(filename, wrk_1d, delimiter=',')\n    with open(filename, 'a') as fd:\n        np.savetxt(fd, wrk_1d, delimiter=',')\n\n\ncode\nJupyter\u30b3\u30fc\u30c9\n\nin100_out100.ipynb\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport matplotlib.cm as cm\nimport os\n\n'''\nv0.6 Feb. 14, 2017\n  - fix bug > savetxt() was without 'delimiter=','\nv0.5 Feb. 06, 2017\n  - add [FILENAME_*_CSV],[FILENAME_*_BAK]\n  - output to csv with append mode\nv0.4 Jan. 21, 2017\n  - set size of figures\nv0.3 Jan. 21, 2017\n  - show 2 images in one figure\nv0.2 Jan. 14, 2017\n  - calcOutput() return in numpy.array\n  - add saveToCsvFile()\nv0.1 Jan. 14, 2017\n  - add calcOutput()\n  - add showIn2D()\n  - show 1d in 2d format\n'''\n\n'''\ncodingrule:PEP8\n'''\n\nXDIM = 10\nYDIM = 10\nINDIM = XDIM * YDIM\n\nFILENAME_IN_CSV = 'test_in.csv'\nFILENAME_OUT_CSV = 'test_out.csv'\nFILENAME_IN_BAK = 'test_in.bak'\nFILENAME_OUT_BAK = 'test_out.bak'\n\n\ndef saveToCsvFile(data_1d, filename):\n    wrk_1d = data_1d.reshape(1, INDIM)\n    # np.savetxt(filename, wrk_1d, delimiter=',')\n    with open(filename, 'a') as fd:\n        np.savetxt(fd, wrk_1d, delimiter=',')\n\n\ndef calcOutput(in_1d):\n    len_1d = XDIM * YDIM\n    out_1d = [0.0] * len_1d\n    for idx in range(0, in_1d.size):\n        out_1d[idx] = in_1d[len_1d - idx - 1]\n    return np.array(out_1d)\n\n\ndef showIn2D(data_1d):\n    # print(data_1d)\n    data_2d = np.reshape(data_1d, (XDIM, YDIM))\n    plt.imshow(data_2d, extent=(0, XDIM, 0, YDIM), cmap=cm.gist_rainbow)\n    plt.show()\n\n\ndef showIn2D_2image_subplot_each(data1_1d, data2_1d):\n    data1_2d = np.reshape(data1_1d, (XDIM, YDIM))\n    data2_2d = np.reshape(data2_1d, (XDIM, YDIM))\n    fig1 = plt.figure(1)\n    fig1.set_size_inches(3.14, 3.14)\n    plt.subplot(121)\n    plt.title('input node')\n    plt.imshow(data1_2d, extent=(0, XDIM, 0, YDIM), cmap=cm.gist_rainbow)\n    plt.subplot(122)\n    plt.title('output node')\n    plt.imshow(data2_2d, extent=(0, XDIM, 0, YDIM), cmap=cm.gist_rainbow)\n    plt.show()\n\n\ndef showIn2D_2image_subplot_first(data1_1d, data2_1d):\n    data1_2d = np.reshape(data1_1d, (XDIM, YDIM))\n    data2_2d = np.reshape(data2_1d, (XDIM, YDIM))\n    fig, (axL, axR) = plt.subplots(ncols=2, figsize=(10, 4))\n    axL.imshow(data1_2d, extent=(0, XDIM, 0, YDIM), cmap=cm.gist_rainbow)\n    axL.grid(True)\n    axR.imshow(data2_2d, extent=(0, XDIM, 0, YDIM), cmap=cm.gist_rainbow)\n    axR.grid(True)\n    fig.show()\n\n\nif __name__ == '__main__':\n    # backup the original csv files\n    if os.path.exists(FILENAME_IN_CSV):\n        os.rename(FILENAME_IN_CSV, FILENAME_IN_BAK)\n    if os.path.exists(FILENAME_OUT_CSV):\n        os.rename(FILENAME_OUT_CSV, FILENAME_OUT_BAK)\n\n    # append csv\n    NUM_FILEOUT = 100\n    NUM_DISPLAY = 5\n    for loop in range(NUM_FILEOUT):\n        in_1d = np.random.rand(INDIM)\n        out_1d = calcOutput(in_1d)\n        saveToCsvFile(in_1d, FILENAME_IN_CSV)\n        saveToCsvFile(out_1d, FILENAME_OUT_CSV)\n        if loop < NUM_DISPLAY:\n            showIn2D_2image_subplot_each(in_1d, out_1d)\n            showIn2D_2image_subplot_first(in_1d, out_1d)\n\n\n\nTensorFlow\n\nlearn_in100out100.py\n#!/usr/bin/env python\n# -*- coding: utf-8 -*-\nimport sys\nimport tensorflow as tf\nimport tensorflow.contrib.slim as slim\nimport numpy as np\n\n'''\nv0.1 Feb. 06, 2017\n    - read [test_in.csv],[test_out.csv]\n'''\n\n'''\ncodingrule:PEP8\n'''\n\nfilename_inp = tf.train.string_input_producer([\"test_in.csv\"])\nfilename_out = tf.train.string_input_producer([\"test_out.csv\"])\nNUM_INP_NODE = 100\nNUM_OUT_NODE = 100\n\n# parse csv\n# a. input node\nreader = tf.TextLineReader()\nkey, value = reader.read(filename_inp)\ndeflist = [[0.] for idx in range(NUM_INP_NODE)]\ninput1 = tf.decode_csv(value, record_defaults=deflist)\n# b. output node\nkey, value = reader.read(filename_out)\ndeflist = [[0.] for idx in range(NUM_OUT_NODE)]\noutput1 = tf.decode_csv(value, record_defaults=deflist)\n# c. pack\ninputs = tf.pack([input1])\noutputs = tf.pack([output1])\n\nbatch_size = 1\ninputs_batch, output_batch = tf.train.shuffle_batch(\n    [inputs, outputs], batch_size, capacity=2, min_after_dequeue=batch_size)\n\ninput_ph = tf.placeholder(\"float\", [None, 1])\noutput_ph = tf.placeholder(\"float\", [None, 1])\n\n# network\nhiddens = slim.stack(input_ph, slim.fully_connected, [7, 7, 7],\n                     activation_fn=tf.nn.sigmoid, scope=\"hidden\")\nprediction = slim.fully_connected(\n    hiddens, 1, activation_fn=None, scope=\"output\")\nloss = tf.contrib.losses.mean_squared_error(prediction, output_ph)\n\ntrain_op = slim.learning.create_train_op(loss, tf.train.AdamOptimizer(0.001))\n\ninit_op = tf.initialize_all_variables()\n\nwith tf.Session() as sess:\n    coord = tf.train.Coordinator()\n    threads = tf.train.start_queue_runners(sess=sess, coord=coord)\n\n    try:\n#if 1\n        ipb = sess.run(inputs)\n        print(ipb)\n#endif\n\n        sess.run(init_op)\n        for idx in range(10):\n            inpbt, outbt = sess.run([inputs_batch, output_batch])\n            _, t_loss = sess.run(\n                [train_op, loss], feed_dict={input_ph: inpbt, output_ph: outbt})\n\n            if (idx+1) % 100 == 0:\n                print(\"%d,%f\" % (idx+1, t_loss))\n    finally:\n        coord.request_stop()\n\n\n\n\u7d50\u679c\n$ python learn_in100out100.py \nI tensorflow/stream_executor/dso_loader.cc:111] successfully opened CUDA library libcublas.so locally\nI tensorflow/stream_executor/dso_loader.cc:111] successfully opened CUDA library libcudnn.so locally\nI tensorflow/stream_executor/dso_loader.cc:111] successfully opened CUDA library libcufft.so locally\nI tensorflow/stream_executor/dso_loader.cc:111] successfully opened CUDA library libcuda.so.1 locally\nI tensorflow/stream_executor/dso_loader.cc:111] successfully opened CUDA library libcurand.so locally\nWARNING:tensorflow:sum_of_squares (from tensorflow.contrib.losses.python.losses.loss_ops) is deprecated and will be removed after 2016-10-01.\nInstructions for updating:\nUse mean_squared_error.\nI tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:925] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\nI tensorflow/core/common_runtime/gpu/gpu_device.cc:951] Found device 0 with properties: \nname: GeForce GTX 1070\nmajor: 6 minor: 1 memoryClockRate (GHz) 1.7715\npciBusID 0000:01:00.0\nTotal memory: 7.91GiB\nFree memory: 7.36GiB\nI tensorflow/core/common_runtime/gpu/gpu_device.cc:972] DMA: 0 \nI tensorflow/core/common_runtime/gpu/gpu_device.cc:982] 0:   Y \nI tensorflow/core/common_runtime/gpu/gpu_device.cc:1041] Creating TensorFlow device (/gpu:0) -> (device: 0, name: GeForce GTX 1070, pci bus id: 0000:01:00.0)\n[[ 0.99152142  0.66125107  0.547059    0.14975344  0.59668982  0.5901829\n   0.19366921  0.36180109  0.81899309  0.87902629  0.75462669  0.44262037\n   0.75782663  0.417696    0.93087715  0.52699465  0.2604886   0.56388456\n   0.05648197  0.71152961  0.65420961  0.70998633  0.41374552  0.8660866\n   0.2914612   0.46226504  0.21765819  0.48927236  0.08439976  0.79160899\n   0.82405055  0.81615603  0.30009007  0.93183696  0.04212759  0.40317428\n   0.46958077  0.62355512  0.63598049  0.65639907  0.35210919  0.95008641\n   0.82853442  0.66671896  0.04488055  0.16904673  0.38758042  0.33223122\n   0.20159586  0.63469607  0.72147346  0.42067477  0.67577803  0.66193497\n   0.9133414   0.87213254  0.76146173  0.83638555  0.76472205  0.63005483\n   0.5895927   0.99512172  0.20544738  0.87122935  0.06446151  0.46439987\n   0.50364745  0.1033207   0.9024967   0.96334237  0.86734897  0.68662459\n   0.85111129  0.81870919  0.92511994  0.12714404  0.66975749  0.39298803\n   0.91989315  0.80589581  0.1647516   0.73296088  0.97263211  0.09779057\n   0.34991187  0.74653304  0.42894962  0.25509003  0.36797443  0.33486256\n   0.33328396  0.91020757  0.26428241  0.85101151  0.26242641  0.27273661\n   0.74265695  0.81854439  0.58753532  0.09706611]]\nW tensorflow/core/kernels/queue_base.cc:294] _1_input_producer_1: Skipping cancelled enqueue attempt with queue not closed\nW tensorflow/core/kernels/queue_base.cc:294] _0_input_producer: Skipping cancelled enqueue attempt with queue not closed\nTraceback (most recent call last):\n  File \"learn_in100out100.py\", line 68, in <module>\n    [train_op, loss], feed_dict={input_ph: inpbt, output_ph: outbt})\n  File \"/home/yasokada/tensorflow-GPU/local/lib/python2.7/site-packages/tensorflow/python/client/session.py\", line 717, in run\n    run_metadata_ptr)\n  File \"/home/yasokada/tensorflow-GPU/local/lib/python2.7/site-packages/tensorflow/python/client/session.py\", line 894, in _run\n    % (np_val.shape, subfeed_t.name, str(subfeed_t.get_shape())))\nValueError: Cannot feed value of shape (1, 1, 100) for Tensor u'Placeholder:0', which has shape '(?, 1)'\n\n\n\u307e\u3060\u30a8\u30e9\u30fc\u304c\u51fa\u3066\u3044\u308b\u3002\ninput placeholder\u306e\u5b9a\u7fa9\u3068\u5b9f\u969b\u306b\u8aad\u307f\u8fbc\u3080\u30c7\u30fc\u30bf\u306e\u30c7\u30a3\u30e1\u30f3\u30b7\u30e7\u30f3\uff1f\u304c\u5408\u3063\u3066\u3044\u306a\u3044\u3002\n### TensorFlow\n\n```txt:\u52d5\u4f5c\u74b0\u5883\nGeForce GTX 1070 (8GB)\nASRock Z170M Pro4S [Intel Z170chipset]\nUbuntu 14.04 LTS desktop amd64\nTensorFlow v0.11\ncuDNN v5.1 for Linux\nCUDA v8.0\nPython 2.7.6\nIPython 5.1.0 -- An enhanced Interactive Python.\ngcc (Ubuntu 4.8.4-2ubuntu1~14.04.3) 4.8.4\n```\n\nv0.1 http://qiita.com/7of9/items/8b43357bcaea1f1bce4b\nv0.5 http://qiita.com/7of9/items/e82451a71f017db03749\n\nTensorFlow\u3092\u4f7f\u3063\u3066\u3001input:100, output:100\u7a0b\u5ea6\u306e\u30cd\u30c3\u30c8\u30ef\u30fc\u30af\u306e\u5b66\u7fd2\u3092\u3057\u3088\u3046\u304b\u3068\u691c\u8a0e\u4e2d\u3002\n\n## v0.6\n\n### \u5909\u66f4\u7b87\u6240\n\nv0.5\u306b\u3066\u4f5c\u6210\u3057\u305f\u30d5\u30a1\u30a4\u30eb\u3092\u5143\u306bTensorFlow\u3092\u52d5\u304b\u305d\u3046\u3068\u3057\u3066\u3044\u305f\u304c\u3001\u30a8\u30e9\u30fc\u304c\u51fa\u3066\u3046\u307e\u304f\u52d5\u304b\u306a\u304b\u3063\u305f\u3002\n\u30a8\u30e9\u30fc\u3092\u8ffd\u8de1\u3057\u3088\u3046\u3068\u3057\u305f\u304c\u3001\u4e00\u3064\u306e\u30a8\u30e9\u30fc\u3092\u5bfe\u51e6\u3057\u305f\u3064\u3082\u308a\u304c\u3001\u5225\u306e\u30a8\u30e9\u30fc\u304c\u51fa\u308b\u3088\u3046\u306b\u306a\u3063\u3066\u3044\u305f\u3002\n\n\u8aad\u8fbc\u307f\u30d5\u30a1\u30a4\u30eb\u3092\u898b\u306a\u304a\u3057\u305f\u3068\u3053\u308d\u3001\",\"\u304c\u306a\u3044\u72b6\u614b\u3067\u4fdd\u5b58\u3057\u3066\u3044\u305f\u3002\n\n```py\ndef saveToCsvFile(data_1d, filename):\n    wrk_1d = data_1d.reshape(1, INDIM)\n    # np.savetxt(filename, wrk_1d, delimiter=',')\n    with open(filename, 'a') as fd:\n        np.savetxt(fd, wrk_1d)\n```\n\n\u3092\u4ee5\u4e0b\u306e\u3088\u3046\u306b\u4fee\u6b63\u3057\u305f\u3002\n\n```py\ndef saveToCsvFile(data_1d, filename):\n    wrk_1d = data_1d.reshape(1, INDIM)\n    # np.savetxt(filename, wrk_1d, delimiter=',')\n    with open(filename, 'a') as fd:\n        np.savetxt(fd, wrk_1d, delimiter=',')\n```\n\n### code \n\nJupyter\u30b3\u30fc\u30c9\n\n```py:in100_out100.ipynb\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport matplotlib.cm as cm\nimport os\n\n'''\nv0.6 Feb. 14, 2017\n  - fix bug > savetxt() was without 'delimiter=','\nv0.5 Feb. 06, 2017\n  - add [FILENAME_*_CSV],[FILENAME_*_BAK]\n  - output to csv with append mode\nv0.4 Jan. 21, 2017\n  - set size of figures\nv0.3 Jan. 21, 2017\n  - show 2 images in one figure\nv0.2 Jan. 14, 2017\n  - calcOutput() return in numpy.array\n  - add saveToCsvFile()\nv0.1 Jan. 14, 2017\n  - add calcOutput()\n  - add showIn2D()\n  - show 1d in 2d format\n'''\n\n'''\ncodingrule:PEP8\n'''\n\nXDIM = 10\nYDIM = 10\nINDIM = XDIM * YDIM\n\nFILENAME_IN_CSV = 'test_in.csv'\nFILENAME_OUT_CSV = 'test_out.csv'\nFILENAME_IN_BAK = 'test_in.bak'\nFILENAME_OUT_BAK = 'test_out.bak'\n\n\ndef saveToCsvFile(data_1d, filename):\n    wrk_1d = data_1d.reshape(1, INDIM)\n    # np.savetxt(filename, wrk_1d, delimiter=',')\n    with open(filename, 'a') as fd:\n        np.savetxt(fd, wrk_1d, delimiter=',')\n\n\ndef calcOutput(in_1d):\n    len_1d = XDIM * YDIM\n    out_1d = [0.0] * len_1d\n    for idx in range(0, in_1d.size):\n        out_1d[idx] = in_1d[len_1d - idx - 1]\n    return np.array(out_1d)\n\n\ndef showIn2D(data_1d):\n    # print(data_1d)\n    data_2d = np.reshape(data_1d, (XDIM, YDIM))\n    plt.imshow(data_2d, extent=(0, XDIM, 0, YDIM), cmap=cm.gist_rainbow)\n    plt.show()\n\n\ndef showIn2D_2image_subplot_each(data1_1d, data2_1d):\n    data1_2d = np.reshape(data1_1d, (XDIM, YDIM))\n    data2_2d = np.reshape(data2_1d, (XDIM, YDIM))\n    fig1 = plt.figure(1)\n    fig1.set_size_inches(3.14, 3.14)\n    plt.subplot(121)\n    plt.title('input node')\n    plt.imshow(data1_2d, extent=(0, XDIM, 0, YDIM), cmap=cm.gist_rainbow)\n    plt.subplot(122)\n    plt.title('output node')\n    plt.imshow(data2_2d, extent=(0, XDIM, 0, YDIM), cmap=cm.gist_rainbow)\n    plt.show()\n\n\ndef showIn2D_2image_subplot_first(data1_1d, data2_1d):\n    data1_2d = np.reshape(data1_1d, (XDIM, YDIM))\n    data2_2d = np.reshape(data2_1d, (XDIM, YDIM))\n    fig, (axL, axR) = plt.subplots(ncols=2, figsize=(10, 4))\n    axL.imshow(data1_2d, extent=(0, XDIM, 0, YDIM), cmap=cm.gist_rainbow)\n    axL.grid(True)\n    axR.imshow(data2_2d, extent=(0, XDIM, 0, YDIM), cmap=cm.gist_rainbow)\n    axR.grid(True)\n    fig.show()\n\n\nif __name__ == '__main__':\n    # backup the original csv files\n    if os.path.exists(FILENAME_IN_CSV):\n        os.rename(FILENAME_IN_CSV, FILENAME_IN_BAK)\n    if os.path.exists(FILENAME_OUT_CSV):\n        os.rename(FILENAME_OUT_CSV, FILENAME_OUT_BAK)\n\n    # append csv\n    NUM_FILEOUT = 100\n    NUM_DISPLAY = 5\n    for loop in range(NUM_FILEOUT):\n        in_1d = np.random.rand(INDIM)\n        out_1d = calcOutput(in_1d)\n        saveToCsvFile(in_1d, FILENAME_IN_CSV)\n        saveToCsvFile(out_1d, FILENAME_OUT_CSV)\n        if loop < NUM_DISPLAY:\n            showIn2D_2image_subplot_each(in_1d, out_1d)\n            showIn2D_2image_subplot_first(in_1d, out_1d)\n```\n\n### TensorFlow\n\n```learn_in100out100.py\n#!/usr/bin/env python\n# -*- coding: utf-8 -*-\nimport sys\nimport tensorflow as tf\nimport tensorflow.contrib.slim as slim\nimport numpy as np\n\n'''\nv0.1 Feb. 06, 2017\n    - read [test_in.csv],[test_out.csv]\n'''\n\n'''\ncodingrule:PEP8\n'''\n\nfilename_inp = tf.train.string_input_producer([\"test_in.csv\"])\nfilename_out = tf.train.string_input_producer([\"test_out.csv\"])\nNUM_INP_NODE = 100\nNUM_OUT_NODE = 100\n\n# parse csv\n# a. input node\nreader = tf.TextLineReader()\nkey, value = reader.read(filename_inp)\ndeflist = [[0.] for idx in range(NUM_INP_NODE)]\ninput1 = tf.decode_csv(value, record_defaults=deflist)\n# b. output node\nkey, value = reader.read(filename_out)\ndeflist = [[0.] for idx in range(NUM_OUT_NODE)]\noutput1 = tf.decode_csv(value, record_defaults=deflist)\n# c. pack\ninputs = tf.pack([input1])\noutputs = tf.pack([output1])\n\nbatch_size = 1\ninputs_batch, output_batch = tf.train.shuffle_batch(\n    [inputs, outputs], batch_size, capacity=2, min_after_dequeue=batch_size)\n\ninput_ph = tf.placeholder(\"float\", [None, 1])\noutput_ph = tf.placeholder(\"float\", [None, 1])\n\n# network\nhiddens = slim.stack(input_ph, slim.fully_connected, [7, 7, 7],\n                     activation_fn=tf.nn.sigmoid, scope=\"hidden\")\nprediction = slim.fully_connected(\n    hiddens, 1, activation_fn=None, scope=\"output\")\nloss = tf.contrib.losses.mean_squared_error(prediction, output_ph)\n\ntrain_op = slim.learning.create_train_op(loss, tf.train.AdamOptimizer(0.001))\n\ninit_op = tf.initialize_all_variables()\n\nwith tf.Session() as sess:\n    coord = tf.train.Coordinator()\n    threads = tf.train.start_queue_runners(sess=sess, coord=coord)\n\n    try:\n#if 1\n        ipb = sess.run(inputs)\n        print(ipb)\n#endif\n\n        sess.run(init_op)\n        for idx in range(10):\n            inpbt, outbt = sess.run([inputs_batch, output_batch])\n            _, t_loss = sess.run(\n                [train_op, loss], feed_dict={input_ph: inpbt, output_ph: outbt})\n\n            if (idx+1) % 100 == 0:\n                print(\"%d,%f\" % (idx+1, t_loss))\n    finally:\n        coord.request_stop()\n```\n\n```txt:\u7d50\u679c\n$ python learn_in100out100.py \nI tensorflow/stream_executor/dso_loader.cc:111] successfully opened CUDA library libcublas.so locally\nI tensorflow/stream_executor/dso_loader.cc:111] successfully opened CUDA library libcudnn.so locally\nI tensorflow/stream_executor/dso_loader.cc:111] successfully opened CUDA library libcufft.so locally\nI tensorflow/stream_executor/dso_loader.cc:111] successfully opened CUDA library libcuda.so.1 locally\nI tensorflow/stream_executor/dso_loader.cc:111] successfully opened CUDA library libcurand.so locally\nWARNING:tensorflow:sum_of_squares (from tensorflow.contrib.losses.python.losses.loss_ops) is deprecated and will be removed after 2016-10-01.\nInstructions for updating:\nUse mean_squared_error.\nI tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:925] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\nI tensorflow/core/common_runtime/gpu/gpu_device.cc:951] Found device 0 with properties: \nname: GeForce GTX 1070\nmajor: 6 minor: 1 memoryClockRate (GHz) 1.7715\npciBusID 0000:01:00.0\nTotal memory: 7.91GiB\nFree memory: 7.36GiB\nI tensorflow/core/common_runtime/gpu/gpu_device.cc:972] DMA: 0 \nI tensorflow/core/common_runtime/gpu/gpu_device.cc:982] 0:   Y \nI tensorflow/core/common_runtime/gpu/gpu_device.cc:1041] Creating TensorFlow device (/gpu:0) -> (device: 0, name: GeForce GTX 1070, pci bus id: 0000:01:00.0)\n[[ 0.99152142  0.66125107  0.547059    0.14975344  0.59668982  0.5901829\n   0.19366921  0.36180109  0.81899309  0.87902629  0.75462669  0.44262037\n   0.75782663  0.417696    0.93087715  0.52699465  0.2604886   0.56388456\n   0.05648197  0.71152961  0.65420961  0.70998633  0.41374552  0.8660866\n   0.2914612   0.46226504  0.21765819  0.48927236  0.08439976  0.79160899\n   0.82405055  0.81615603  0.30009007  0.93183696  0.04212759  0.40317428\n   0.46958077  0.62355512  0.63598049  0.65639907  0.35210919  0.95008641\n   0.82853442  0.66671896  0.04488055  0.16904673  0.38758042  0.33223122\n   0.20159586  0.63469607  0.72147346  0.42067477  0.67577803  0.66193497\n   0.9133414   0.87213254  0.76146173  0.83638555  0.76472205  0.63005483\n   0.5895927   0.99512172  0.20544738  0.87122935  0.06446151  0.46439987\n   0.50364745  0.1033207   0.9024967   0.96334237  0.86734897  0.68662459\n   0.85111129  0.81870919  0.92511994  0.12714404  0.66975749  0.39298803\n   0.91989315  0.80589581  0.1647516   0.73296088  0.97263211  0.09779057\n   0.34991187  0.74653304  0.42894962  0.25509003  0.36797443  0.33486256\n   0.33328396  0.91020757  0.26428241  0.85101151  0.26242641  0.27273661\n   0.74265695  0.81854439  0.58753532  0.09706611]]\nW tensorflow/core/kernels/queue_base.cc:294] _1_input_producer_1: Skipping cancelled enqueue attempt with queue not closed\nW tensorflow/core/kernels/queue_base.cc:294] _0_input_producer: Skipping cancelled enqueue attempt with queue not closed\nTraceback (most recent call last):\n  File \"learn_in100out100.py\", line 68, in <module>\n    [train_op, loss], feed_dict={input_ph: inpbt, output_ph: outbt})\n  File \"/home/yasokada/tensorflow-GPU/local/lib/python2.7/site-packages/tensorflow/python/client/session.py\", line 717, in run\n    run_metadata_ptr)\n  File \"/home/yasokada/tensorflow-GPU/local/lib/python2.7/site-packages/tensorflow/python/client/session.py\", line 894, in _run\n    % (np_val.shape, subfeed_t.name, str(subfeed_t.get_shape())))\nValueError: Cannot feed value of shape (1, 1, 100) for Tensor u'Placeholder:0', which has shape '(?, 1)'\n```\n\n\u307e\u3060\u30a8\u30e9\u30fc\u304c\u51fa\u3066\u3044\u308b\u3002\ninput placeholder\u306e\u5b9a\u7fa9\u3068\u5b9f\u969b\u306b\u8aad\u307f\u8fbc\u3080\u30c7\u30fc\u30bf\u306e\u30c7\u30a3\u30e1\u30f3\u30b7\u30e7\u30f3\uff1f\u304c\u5408\u3063\u3066\u3044\u306a\u3044\u3002\n\n\n\n", "tags": ["borgWarp"]}