{"context": " More than 1 year has passed since last update.\u5099\u5fd8\u9332\u7684\u306a\u3082\u306e\u3067\u3059\nimport UIKit\nimport AVFoundation\n\nclass ViewController: UIViewController, AVCaptureVideoDataOutputSampleBufferDelegate {\n\n    var device: AVCaptureDevice!\n    var session: AVCaptureSession!\n    var adjustingExposure: Bool!\n\n    override func viewWillAppear(animated: Bool) {\n        self.initCamera()\n    }\n\n    override func viewDidDisappear(animated: Bool) {\n        self.session.stopRunning()\n        for output in self.session.outputs {\n            self.session.removeOutput(output as AVCaptureOutput)\n        }\n\n        for input in self.session.inputs {\n            self.session.removeInput(input as AVCaptureInput)\n        }\n        self.session = nil\n        self.device = nil\n    }\n\n    private func initCamera() {\n        for caputureDevice: AnyObject in AVCaptureDevice.devices() {\n            if caputureDevice.position == AVCaptureDevicePosition.Back {\n                self.device = caputureDevice as AVCaptureDevice\n            }\n        }\n\n        self.device.activeVideoMinFrameDuration = CMTimeMake(1, 30)\n\n        var input: AVCaptureDeviceInput = AVCaptureDeviceInput.deviceInputWithDevice(self.device, error: nil) as AVCaptureDeviceInput\n\n        let cameraQueue = dispatch_queue_create(\"cameraQueue\", nil)\n        var videoDataOutput: AVCaptureVideoDataOutput = AVCaptureVideoDataOutput()\n        videoDataOutput.videoSettings = [kCVPixelBufferPixelFormatTypeKey : kCVPixelFormatType_32BGRA]\n        videoDataOutput.setSampleBufferDelegate(self, queue: cameraQueue)\n        videoDataOutput.alwaysDiscardsLateVideoFrames = true\n\n        self.session = AVCaptureSession()\n\n        if(self.session.canAddInput(input)) {\n            self.session.addInput(input)\n        }\n\n        if(self.session.canAddOutput(videoDataOutput)) {\n            self.session.addOutput(videoDataOutput)\n        }\n\n        self.session.sessionPreset = AVCaptureSessionPreset1920x1080\n        self.session.startRunning()\n\n        self.adjustingExposure = false\n        self.device.addObserver(self, forKeyPath: \"adjustingExposure\", options: NSKeyValueObservingOptions.New, context: nil)\n    }\n\n    func captureOutput(captureOutput: AVCaptureOutput!, didOutputSampleBuffer sampleBuffer: CMSampleBuffer!, fromConnection connection: AVCaptureConnection!) {\n        let image = self.imageFromSampleBuffer(sampleBuffer)\n        dispatch_async(dispatch_get_main_queue()) {\n            self.preview.image = image\n        }\n    }\n\n    private func imageFromSampleBuffer(sampleBuffer :CMSampleBufferRef) -> UIImage {\n        let imageBuffer: CVImageBufferRef = CMSampleBufferGetImageBuffer(sampleBuffer)\n        CVPixelBufferLockBaseAddress(imageBuffer, 0)\n        let baseAddress: UnsafeMutablePointer<Void> = CVPixelBufferGetBaseAddressOfPlane(imageBuffer, UInt(0))\n\n        let bytesPerRow: UInt = CVPixelBufferGetBytesPerRow(imageBuffer)\n        let width: UInt = CVPixelBufferGetWidth(imageBuffer)\n        let height: UInt = CVPixelBufferGetHeight(imageBuffer)\n\n        let colorSpace: CGColorSpaceRef = CGColorSpaceCreateDeviceRGB()\n\n        let bitsPerCompornent: UInt = 8\n        var bitmapInfo = CGBitmapInfo((CGBitmapInfo.ByteOrder32Little.rawValue | CGImageAlphaInfo.PremultipliedFirst.rawValue) as UInt32)\n        let newContext: CGContextRef = CGBitmapContextCreate(baseAddress, width, height, bitsPerCompornent, bytesPerRow, colorSpace, bitmapInfo) as CGContextRef\n\n        let imageRef: CGImageRef = CGBitmapContextCreateImage(newContext)\n        let resultImage = UIImage(CGImage: imageRef, scale: 1.0, orientation: UIImageOrientation.Right)!\n\n        return resultImage\n    }\n\n     // \u4ee5\u4e0b\u306e\u30b3\u30e1\u30f3\u30c8\u306e\u5024\u3092\u5f15\u6570\u3067\u53d7\u3051\u53d6\u308b\u5024\u306e\u4f8b\n\u3000\u3000\u3000// let anyTouch = sender as UIGestureRecognizer\n     // let origin = anyTouch.locationInView(self.preview);\n     // let focusPoint = CGPointMake(origin.y / self.preview.bounds.size.height, 1 - origin.x / self.preview.bounds.size.width);\n    func setFocusAndrExposure(focusPoint: CGPoint) {\n        if self.device.lockForConfiguration(nil) {\n            self.device.focusPointOfInterest = focusPoint\n            self.device.focusMode = AVCaptureFocusMode.AutoFocus\n\n            if self.device.isExposureModeSupported(AVCaptureExposureMode.ContinuousAutoExposure) {\n                self.adjustingExposure = true\n                self.device.exposurePointOfInterest = focusPoint\n                self.device.exposureMode = AVCaptureExposureMode.AutoExpose\n            }\n            self.device.unlockForConfiguration()\n        }\n    }\n\n    override func observeValueForKeyPath(keyPath: String, ofObject object: AnyObject, change: [NSObject : AnyObject], context: UnsafeMutablePointer<Void>) {\n        if !self.adjustingExposure {\n            return\n        }\n\n        if keyPath == \"adjustingExposure\" {\n            let isNew = change[NSKeyValueChangeNewKey]! as Bool\n            if !isNew {\n                self.adjustingExposure = false\n\n                if self.device.lockForConfiguration(nil) {\n                    self.device.exposureMode = AVCaptureExposureMode.Locked\n                    self.device.unlockForConfiguration()\n                }\n            }\n        }\n    }\n\n\n\n\u53c2\u8003\nSwift\u3067\u30ab\u30e1\u30e9\u3092\u4f7f\u3046\nhttp://mslgt.hatenablog.com/entry/2014/09/24/233459\n\n\u5099\u5fd8\u9332\u7684\u306a\u3082\u306e\u3067\u3059\n\n```\nimport UIKit\nimport AVFoundation\n\nclass ViewController: UIViewController, AVCaptureVideoDataOutputSampleBufferDelegate {\n    \n    var device: AVCaptureDevice!\n    var session: AVCaptureSession!\n    var adjustingExposure: Bool!\n    \n    override func viewWillAppear(animated: Bool) {\n        self.initCamera()\n    }\n    \n    override func viewDidDisappear(animated: Bool) {\n        self.session.stopRunning()\n        for output in self.session.outputs {\n            self.session.removeOutput(output as AVCaptureOutput)\n        }\n        \n        for input in self.session.inputs {\n            self.session.removeInput(input as AVCaptureInput)\n        }\n        self.session = nil\n        self.device = nil\n    }\n    \n    private func initCamera() {\n        for caputureDevice: AnyObject in AVCaptureDevice.devices() {\n            if caputureDevice.position == AVCaptureDevicePosition.Back {\n                self.device = caputureDevice as AVCaptureDevice\n            }\n        }\n        \n        self.device.activeVideoMinFrameDuration = CMTimeMake(1, 30)\n        \n        var input: AVCaptureDeviceInput = AVCaptureDeviceInput.deviceInputWithDevice(self.device, error: nil) as AVCaptureDeviceInput\n        \n        let cameraQueue = dispatch_queue_create(\"cameraQueue\", nil)\n        var videoDataOutput: AVCaptureVideoDataOutput = AVCaptureVideoDataOutput()\n        videoDataOutput.videoSettings = [kCVPixelBufferPixelFormatTypeKey : kCVPixelFormatType_32BGRA]\n        videoDataOutput.setSampleBufferDelegate(self, queue: cameraQueue)\n        videoDataOutput.alwaysDiscardsLateVideoFrames = true\n        \n        self.session = AVCaptureSession()\n        \n        if(self.session.canAddInput(input)) {\n            self.session.addInput(input)\n        }\n        \n        if(self.session.canAddOutput(videoDataOutput)) {\n            self.session.addOutput(videoDataOutput)\n        }\n        \n        self.session.sessionPreset = AVCaptureSessionPreset1920x1080\n        self.session.startRunning()\n\n        self.adjustingExposure = false\n        self.device.addObserver(self, forKeyPath: \"adjustingExposure\", options: NSKeyValueObservingOptions.New, context: nil)\n    }\n    \n    func captureOutput(captureOutput: AVCaptureOutput!, didOutputSampleBuffer sampleBuffer: CMSampleBuffer!, fromConnection connection: AVCaptureConnection!) {\n        let image = self.imageFromSampleBuffer(sampleBuffer)\n        dispatch_async(dispatch_get_main_queue()) {\n            self.preview.image = image\n        }\n    }\n    \n    private func imageFromSampleBuffer(sampleBuffer :CMSampleBufferRef) -> UIImage {\n        let imageBuffer: CVImageBufferRef = CMSampleBufferGetImageBuffer(sampleBuffer)\n        CVPixelBufferLockBaseAddress(imageBuffer, 0)\n        let baseAddress: UnsafeMutablePointer<Void> = CVPixelBufferGetBaseAddressOfPlane(imageBuffer, UInt(0))\n        \n        let bytesPerRow: UInt = CVPixelBufferGetBytesPerRow(imageBuffer)\n        let width: UInt = CVPixelBufferGetWidth(imageBuffer)\n        let height: UInt = CVPixelBufferGetHeight(imageBuffer)\n        \n        let colorSpace: CGColorSpaceRef = CGColorSpaceCreateDeviceRGB()\n        \n        let bitsPerCompornent: UInt = 8\n        var bitmapInfo = CGBitmapInfo((CGBitmapInfo.ByteOrder32Little.rawValue | CGImageAlphaInfo.PremultipliedFirst.rawValue) as UInt32)\n        let newContext: CGContextRef = CGBitmapContextCreate(baseAddress, width, height, bitsPerCompornent, bytesPerRow, colorSpace, bitmapInfo) as CGContextRef\n        \n        let imageRef: CGImageRef = CGBitmapContextCreateImage(newContext)\n        let resultImage = UIImage(CGImage: imageRef, scale: 1.0, orientation: UIImageOrientation.Right)!\n        \n        return resultImage\n    }\n\n     // \u4ee5\u4e0b\u306e\u30b3\u30e1\u30f3\u30c8\u306e\u5024\u3092\u5f15\u6570\u3067\u53d7\u3051\u53d6\u308b\u5024\u306e\u4f8b\n\u3000\u3000\u3000// let anyTouch = sender as UIGestureRecognizer\n     // let origin = anyTouch.locationInView(self.preview);\n     // let focusPoint = CGPointMake(origin.y / self.preview.bounds.size.height, 1 - origin.x / self.preview.bounds.size.width);\n    func setFocusAndrExposure(focusPoint: CGPoint) {\n        if self.device.lockForConfiguration(nil) {\n            self.device.focusPointOfInterest = focusPoint\n            self.device.focusMode = AVCaptureFocusMode.AutoFocus\n            \n            if self.device.isExposureModeSupported(AVCaptureExposureMode.ContinuousAutoExposure) {\n                self.adjustingExposure = true\n                self.device.exposurePointOfInterest = focusPoint\n                self.device.exposureMode = AVCaptureExposureMode.AutoExpose\n            }\n            self.device.unlockForConfiguration()\n        }\n    }\n    \n    override func observeValueForKeyPath(keyPath: String, ofObject object: AnyObject, change: [NSObject : AnyObject], context: UnsafeMutablePointer<Void>) {\n        if !self.adjustingExposure {\n            return\n        }\n        \n        if keyPath == \"adjustingExposure\" {\n            let isNew = change[NSKeyValueChangeNewKey]! as Bool\n            if !isNew {\n                self.adjustingExposure = false\n                \n                if self.device.lockForConfiguration(nil) {\n                    self.device.exposureMode = AVCaptureExposureMode.Locked\n                    self.device.unlockForConfiguration()\n                }\n            }\n        }\n    }\n\n```\n\n## \u53c2\u8003\nSwift\u3067\u30ab\u30e1\u30e9\u3092\u4f7f\u3046\nhttp://mslgt.hatenablog.com/entry/2014/09/24/233459\n", "tags": ["\u30ab\u30e1\u30e9", "iOS", "Swift"]}