{"context": "\n\n\u6982\u8981\n\u524d\u56de\u9854\u3092\u691c\u51fa\u3057\u3066\u30a2\u30d5\u30a3\u30f3\u5909\u63db\u307e\u3067\u3057\u307e\u3057\u305f\u304c\u3001\u4eca\u56de\u306f\u5909\u63db\u5f8c\u306e\u5ea7\u6a19\u306b\u5225\u306e\u9854\u306e\u5ea7\u6a19\u306b\u30de\u30c3\u30d4\u30f3\u30b0\u3057\u3066\u307f\u307e\u3059\u3002\nSNOW\u3068\u3044\u3046\u30a2\u30d7\u30ea\u3067\u3082\u6709\u540d\u306a\u9854\u306e\u4ea4\u63db\u3067\u3059\u3002\n\u984c\u6750\u3068\u3057\u3066\u30d6\u30e9\u30d4\u3055\u3093\u3092\u4f7f\u308f\u305b\u3066\u3082\u3089\u3044\u307e\u3059\u3002\n\n\u7d50\u679c\n\n\u3042\u308b\u7a0b\u5ea6\u89d2\u5ea6\u306b\u3088\u308b\u5909\u5316\u306b\u5bfe\u5fdc\u51fa\u6765\u3066\u3044\u307e\u3059\u304c\u3001\u9055\u548c\u611f\u306f\u5426\u3081\u307e\u305b\u3093\u3002\u3002\n\n\u30bd\u30fc\u30b9\u30b3\u30fc\u30c9\n\n#include <dlib/opencv.h>\n#include <opencv2/highgui/highgui.hpp>\n#include <dlib/image_processing/frontal_face_detector.h>\n#include <dlib/image_processing/render_face_detections.h>\n#include <dlib/image_processing.h>\n#include <dlib/gui_widgets.h>\n#include <opencv2/imgproc.hpp>\n#include <dlib/image_io.h>\n\nusing namespace dlib;\nusing namespace std;\nconst int WIDTH = 320;\nconst int HEIGHT = 240;\n\ncv::Point2f get_dist_point(cv::Point2f srcPoint, std::map<int, cv::Point2f> srcMap, std::map<int, cv::Point2f> distMap) throw(int){\n    std::map<int, cv::Point2f>::iterator it = srcMap.begin();\n    while( it != srcMap.end() )\n    {\n        if((srcPoint.x == (*it).second.x) && (srcPoint.y == (*it).second.y)) {\n            if(distMap.count((*it).first) > 0) {\n                return distMap[(*it).first];\n            }\n        }\n        ++it;\n    }\n    throw 0;\n}\n\ncv::Mat get_affined_image(std::vector<cv::Vec6f> triangles, cv::Rect rect, cv::Mat srcImg, std::map<int, cv::Point2f> srcMap, std::map<int, cv::Point2f> distMap, cv::Mat distMat)\n{\n    for(auto it = triangles.begin(); it != triangles.end(); it++)\n    {\n        cv::Vec6f &vec = *it;\n\n        // \u753b\u9762\u5916\u306e\u70b9\u306f\u7121\u8996\u3059\u308b\uff08\u30c9\u30ed\u30cd\u30fc\u56f3\u3092\u63cf\u304f\u3068\u5fc5\u305a\u753b\u9762\u3092\u5185\u5305\u3059\u308b\u4e09\u89d2\u5f62\u304c\u4e00\u500b\u3060\u3051\u51fa\u6765\u3066\u3057\u307e\u3046\uff09\n        dlib::vector<long, 2> p1((long)vec[0], (long)vec[1]);\n        if(!rect.contains(cv::Point(p1.x(),p1.y()))) {\n            continue;\n        }\n        dlib::vector<long, 2> p2((long)vec[2], (long)vec[3]);\n        if(!rect.contains(cv::Point(p2.x(),p2.y()))) {\n            continue;\n        }\n        dlib::vector<long, 2> p3((long)vec[4], (long)vec[5]);\n        if(!rect.contains(cv::Point(p3.x(),p3.y()))) {\n            continue;\n        }\n\n        // Input triangle\n        cv::Point2f srcP1(vec[0],vec[1]);\n        cv::Point2f srcP2(vec[2],vec[3]);\n        cv::Point2f srcP3(vec[4],vec[5]);\n\n        cv::vector <cv::Point2f> triIn;\n        triIn.push_back(srcP1);\n        triIn.push_back(srcP2);\n        triIn.push_back(srcP3);\n\n        // Output triangle\n        cv::vector <cv::Point2f> triOut;\n        try {\n            triOut.push_back(get_dist_point(srcP1, srcMap, distMap));\n            triOut.push_back(get_dist_point(srcP2, srcMap, distMap));\n            triOut.push_back(get_dist_point(srcP3, srcMap, distMap));\n        } catch(int n) {\n            continue;\n        }\n\n        // \u4f59\u5206\u306a\u90e8\u5206\u306e\u8a08\u7b97\u3092\u3057\u306a\u3044\u3088\u3046\u306b\u3059\u308b\u305f\u3081\u4e09\u89d2\u5f62\u3092\u5185\u5305\u3059\u308b\u77e9\u5f62\u3092\u6c42\u3081\u3066\u304a\u304f\n        cv::Rect rectIn = boundingRect(triIn);\n        cv::Rect rectOut = boundingRect(triOut);\n\n        // \u5207\u308a\u53d6\u3089\u308c\u305f\u4e09\u89d2\u5f62\n        cv::vector<cv::Point2f> tri1Cropped, tri2Cropped;\n        cv::vector<cv::Point> tri2CroppedInt;\n\n        for(int i = 0; i < 3; i++)\n        {\n            tri1Cropped.push_back(cv::Point2f(triIn[i].x - rectIn.x, triIn[i].y -  rectIn.y));\n            tri2Cropped.push_back(cv::Point2f(triOut[i].x - rectOut.x, triOut[i].y - rectOut.y));\n\n            // fillConvexPoly needs a vector of Point and not Point2f\n            tri2CroppedInt.push_back(cv::Point((int)(triOut[i].x - rectOut.x), (int)(triOut[i].y - rectOut.y)));\n        }\n\n        // \u5143\u753b\u50cf\u304b\u3089\u6700\u5c0f\u77e9\u5f62\u3092\u5207\u308a\u53d6\u3063\u305f\u90e8\u5206\u3092\u30d1\u30c3\u30c1\u306b\u30b3\u30d4\u30fc\u3059\u308b\n        cv::Mat img1Cropped;\n        srcImg(rectIn).copyTo(img1Cropped);\n\n        // \u4e09\u89d2\u5f62\u306e\u30a2\u30d5\u30a3\u30f3\u884c\u5217\u3092\u6c42\u3081\u308b\n        cv::Mat warpMat = getAffineTransform(tri1Cropped, tri2Cropped);\n\n        // \u5143\u753b\u50cf\u304b\u3089\u30a2\u30d5\u30a3\u30f3\u884c\u5217\u3092\u5b9f\u65bd\u3059\u308b\n        cv::Mat img2Cropped = cv::Mat::zeros(rectOut.height, rectOut.width, img1Cropped.type());\n        warpAffine(img1Cropped, img2Cropped, warpMat, img2Cropped.size(), cv::INTER_LINEAR, cv::BORDER_REFLECT_101);\n\n        // \u30de\u30b9\u30af\u3092\u751f\u6210\n        cv::Mat mask = cv::Mat::zeros(rectOut.height, rectOut.width, img1Cropped.type());\n        fillConvexPoly(mask, tri2CroppedInt, cv::Scalar(1.0, 1.0, 1.0), 16, 0);\n\n        // \u30de\u30b9\u30af\u3092\u30d1\u30c3\u30c1\u306b\u9069\u7528\n        multiply(img2Cropped, mask, img2Cropped);\n\n        // \u30de\u30b9\u30af\u90e8\u5206\u3067\u3059\u3067\u306b\u5024\u304c\u5165\u3063\u3066\u3044\u308b\u5834\u5408\uff08\u5883\u754c\u7dda\u90e8\u5206\uff09\u306f\u4e00\u65e60\u306b\u3059\u308b\n        multiply(distMat(rectOut), cv::Scalar(1.0,1.0,1.0) - mask, distMat(rectOut));\n\n        // \u51fa\u529b\u753b\u50cf\u306b\u8ffd\u52a0\u3059\u308b\n        distMat(rectOut) = distMat(rectOut) + img2Cropped;\n    }\n    return distMat;\n}\n\nint main()\n{\n    try\n    {\n        array2d<bgr_pixel> bpImg;\n        dlib::load_image(bpImg, \"bp.png\");\n        cv::Mat bpMat = cv::Mat::zeros(HEIGHT, WIDTH, dlib::toMat(bpImg).type());\n        bpMat = dlib::toMat(bpImg);\n\n        cv::VideoCapture cap(0);\n        cap.set(CV_CAP_PROP_FRAME_WIDTH , WIDTH);\n        cap.set(CV_CAP_PROP_FRAME_HEIGHT , HEIGHT);\n        if (!cap.isOpened())\n        {\n            cerr << \"Unable to connect to camera\" << endl;\n            return 1;\n        }\n\n        image_window win1;\n        win1.set_size(WIDTH, HEIGHT+CV_CAP_PROP_FRAME_HEIGHT);\n        image_window win2;\n        win2.set_size(WIDTH, HEIGHT+CV_CAP_PROP_FRAME_HEIGHT);\n        image_window win3;\n\n        win3.set_image(bpImg);\n\n        // Load face detection and pose estimation models.\n        frontal_face_detector detector = get_frontal_face_detector();\n        shape_predictor pose_model;\n        deserialize(\"shape_predictor_68_face_landmarks.dat\") >> pose_model;\n        while(!win1.is_closed())\n        {\n            cv::Mat capMat;\n            cap >> capMat;\n            cv_image<bgr_pixel> targetImg(capMat);\n\n            // \u30ab\u30e1\u30e9\u753b\u50cf\u306e\u8868\u793a\n            win1.clear_overlay();\n            win1.set_image(targetImg);\n\n            // ###############\n            // \u30ab\u30e1\u30e9\u753b\u50cf\u306e\u51e6\u7406\n            // ###############\n\n            // Detect faces\n            std::vector<rectangle> targetFaces = detector(targetImg);\n\n            // Find the pose of each face.\n            std::vector<full_object_detection> targetShapes;\n            for (int i = 0; i < targetFaces.size(); ++i) {\n                targetShapes.push_back(pose_model(targetImg, targetFaces[i]));\n            }\n\n            // Subdiv2D\u521d\u671f\u5316\n            cv::Subdiv2D subdiv;\n            cv::Rect rect(0, 0, capMat.cols, capMat.rows);\n            subdiv.initDelaunay(rect);\n\n            // \u9854\u3092\u691c\u51fa\u3057\u3066\u3044\u306a\u3044\u5834\u5408\u306f\u4f55\u3082\u3057\u306a\u3044\n            if(targetShapes.empty()) {\n                continue;\n            }\n\n            // \u6700\u521d\u306b\u691c\u51fa\u3057\u305f\u9854\u306e\u70b9\u3092\u8ffd\u52a0\n            std::map<int, cv::Point2f> targetMap;\n            full_object_detection& d1 = targetShapes[0];\n            for (int i = 0; i < d1.num_parts(); ++i) {\n                if(!rect.contains(cv::Point(d1.part(i).x(),d1.part(i).y()))) {\n                    continue;\n                }\n                cv::Point2f point(d1.part(i).x(), d1.part(i).y());\n                subdiv.insert(point);\n                targetMap.insert(std::pair<int, cv::Point2f>(i, point));\n            }\n\n            // ###############\n            // \u91cd\u7573\u753b\u50cf\u306e\u51e6\u7406\n            // ###############\n\n            // Detect faces\n            std::vector<rectangle> bpFaces = detector(bpImg);\n\n            // Find the pose of each face.\n            std::vector<full_object_detection> bpShapes;\n            for (int i = 0; i < bpFaces.size(); ++i) {\n                bpShapes.push_back(pose_model(bpImg, bpFaces[i]));\n            }\n\n            // Subdiv2D\u521d\u671f\u5316\n            cv::Subdiv2D subdiv2;\n            cv::Rect rect2(0, 0, bpMat.cols, bpMat.rows);\n            subdiv2.initDelaunay(rect2);\n\n            // \u9854\u3092\u691c\u51fa\u3057\u3066\u3044\u306a\u3044\u5834\u5408\u306f\u4f55\u3082\u3057\u306a\u3044\n            if(bpShapes.empty()) {\n                continue;\n            }\n\n            // \u6700\u521d\u306b\u691c\u51fa\u3057\u305f\u9854\u306e\u70b9\u3092\u8ffd\u52a0\n            std::map<int, cv::Point2f> bpMap;\n            full_object_detection& d2 = bpShapes[0];\n            for (int i = 0; i < d2.num_parts(); ++i) {\n                if(!rect.contains(cv::Point(d2.part(i).x(),d2.part(i).y()))) {\n                    continue;\n                }\n                cv::Point2f point(d2.part(i).x(), d2.part(i).y());\n                subdiv2.insert(point);\n                bpMap.insert(std::pair<int, cv::Point2f>(i, point));\n            }\n\n            // \u30c9\u30ed\u30cd\u30fc\u4e09\u89d2\u5f62\u306e\u30ea\u30b9\u30c8\u3092\u53d6\u5f97\n            std::vector<cv::Vec6f> triangles;\n            subdiv2.getTriangleList(triangles);\n\n            // \u30c9\u30ed\u30cd\u30fc\u4e09\u89d2\u5f62\u3092\u30a2\u30d5\u30a3\u30f3\u5909\u63db\u3057\u305f\u753b\u50cf\u3092\u53d6\u5f97\n            cv_image<bgr_pixel> affinedImg(get_affined_image(triangles, rect, bpMat, bpMap, targetMap, capMat));\n\n            // \u753b\u50cf\u3092\u8868\u793a\n            win2.clear_overlay();\n            win2.set_image(affinedImg);\n        }\n    }\n    catch(serialization_error& e)\n    {\n        cout << \"You need dlib's default face landmarking model file to run this example.\" << endl;\n        cout << \"You can get it from the following URL: \" << endl;\n        cout << \"   http://dlib.net/files/shape_predictor_68_face_landmarks.dat.bz2\" << endl;\n        cout << endl << e.what() << endl;\n    }\n    catch(exception& e)\n    {\n        cout << e.what() << endl;\n    }\n}\n\n\n## \u6982\u8981\n[\u524d\u56de](http://qiita.com/chaoz/items/ab4abd84acf5a675f952)\u9854\u3092\u691c\u51fa\u3057\u3066\u30a2\u30d5\u30a3\u30f3\u5909\u63db\u307e\u3067\u3057\u307e\u3057\u305f\u304c\u3001\u4eca\u56de\u306f\u5909\u63db\u5f8c\u306e\u5ea7\u6a19\u306b\u5225\u306e\u9854\u306e\u5ea7\u6a19\u306b\u30de\u30c3\u30d4\u30f3\u30b0\u3057\u3066\u307f\u307e\u3059\u3002\nSNOW\u3068\u3044\u3046\u30a2\u30d7\u30ea\u3067\u3082\u6709\u540d\u306a\u9854\u306e\u4ea4\u63db\u3067\u3059\u3002\n\u984c\u6750\u3068\u3057\u3066\u30d6\u30e9\u30d4\u3055\u3093\u3092\u4f7f\u308f\u305b\u3066\u3082\u3089\u3044\u307e\u3059\u3002\n\n## \u7d50\u679c\n<img width=\"400\" alt=\"\u30b9\u30af\u30ea\u30fc\u30f3\u30b7\u30e7\u30c3\u30c8 2017-01-18 22.38.01.png\" src=\"https://qiita-image-store.s3.amazonaws.com/0/90377/1ca38a8a-3532-3ec7-16f8-ad72f09b77f5.png\">\n\n\u3042\u308b\u7a0b\u5ea6\u89d2\u5ea6\u306b\u3088\u308b\u5909\u5316\u306b\u5bfe\u5fdc\u51fa\u6765\u3066\u3044\u307e\u3059\u304c\u3001\u9055\u548c\u611f\u306f\u5426\u3081\u307e\u305b\u3093\u3002\u3002\n\n## \u30bd\u30fc\u30b9\u30b3\u30fc\u30c9\n\n\n```cpp\n\n#include <dlib/opencv.h>\n#include <opencv2/highgui/highgui.hpp>\n#include <dlib/image_processing/frontal_face_detector.h>\n#include <dlib/image_processing/render_face_detections.h>\n#include <dlib/image_processing.h>\n#include <dlib/gui_widgets.h>\n#include <opencv2/imgproc.hpp>\n#include <dlib/image_io.h>\n\nusing namespace dlib;\nusing namespace std;\nconst int WIDTH = 320;\nconst int HEIGHT = 240;\n\ncv::Point2f get_dist_point(cv::Point2f srcPoint, std::map<int, cv::Point2f> srcMap, std::map<int, cv::Point2f> distMap) throw(int){\n    std::map<int, cv::Point2f>::iterator it = srcMap.begin();\n    while( it != srcMap.end() )\n    {\n        if((srcPoint.x == (*it).second.x) && (srcPoint.y == (*it).second.y)) {\n            if(distMap.count((*it).first) > 0) {\n                return distMap[(*it).first];\n            }\n        }\n        ++it;\n    }\n    throw 0;\n}\n\ncv::Mat get_affined_image(std::vector<cv::Vec6f> triangles, cv::Rect rect, cv::Mat srcImg, std::map<int, cv::Point2f> srcMap, std::map<int, cv::Point2f> distMap, cv::Mat distMat)\n{\n    for(auto it = triangles.begin(); it != triangles.end(); it++)\n    {\n        cv::Vec6f &vec = *it;\n        \n        // \u753b\u9762\u5916\u306e\u70b9\u306f\u7121\u8996\u3059\u308b\uff08\u30c9\u30ed\u30cd\u30fc\u56f3\u3092\u63cf\u304f\u3068\u5fc5\u305a\u753b\u9762\u3092\u5185\u5305\u3059\u308b\u4e09\u89d2\u5f62\u304c\u4e00\u500b\u3060\u3051\u51fa\u6765\u3066\u3057\u307e\u3046\uff09\n        dlib::vector<long, 2> p1((long)vec[0], (long)vec[1]);\n        if(!rect.contains(cv::Point(p1.x(),p1.y()))) {\n            continue;\n        }\n        dlib::vector<long, 2> p2((long)vec[2], (long)vec[3]);\n        if(!rect.contains(cv::Point(p2.x(),p2.y()))) {\n            continue;\n        }\n        dlib::vector<long, 2> p3((long)vec[4], (long)vec[5]);\n        if(!rect.contains(cv::Point(p3.x(),p3.y()))) {\n            continue;\n        }\n        \n        // Input triangle\n        cv::Point2f srcP1(vec[0],vec[1]);\n        cv::Point2f srcP2(vec[2],vec[3]);\n        cv::Point2f srcP3(vec[4],vec[5]);\n        \n        cv::vector <cv::Point2f> triIn;\n        triIn.push_back(srcP1);\n        triIn.push_back(srcP2);\n        triIn.push_back(srcP3);\n        \n        // Output triangle\n        cv::vector <cv::Point2f> triOut;\n        try {\n            triOut.push_back(get_dist_point(srcP1, srcMap, distMap));\n            triOut.push_back(get_dist_point(srcP2, srcMap, distMap));\n            triOut.push_back(get_dist_point(srcP3, srcMap, distMap));\n        } catch(int n) {\n            continue;\n        }\n\n        // \u4f59\u5206\u306a\u90e8\u5206\u306e\u8a08\u7b97\u3092\u3057\u306a\u3044\u3088\u3046\u306b\u3059\u308b\u305f\u3081\u4e09\u89d2\u5f62\u3092\u5185\u5305\u3059\u308b\u77e9\u5f62\u3092\u6c42\u3081\u3066\u304a\u304f\n        cv::Rect rectIn = boundingRect(triIn);\n        cv::Rect rectOut = boundingRect(triOut);\n        \n        // \u5207\u308a\u53d6\u3089\u308c\u305f\u4e09\u89d2\u5f62\n        cv::vector<cv::Point2f> tri1Cropped, tri2Cropped;\n        cv::vector<cv::Point> tri2CroppedInt;\n        \n        for(int i = 0; i < 3; i++)\n        {\n            tri1Cropped.push_back(cv::Point2f(triIn[i].x - rectIn.x, triIn[i].y -  rectIn.y));\n            tri2Cropped.push_back(cv::Point2f(triOut[i].x - rectOut.x, triOut[i].y - rectOut.y));\n            \n            // fillConvexPoly needs a vector of Point and not Point2f\n            tri2CroppedInt.push_back(cv::Point((int)(triOut[i].x - rectOut.x), (int)(triOut[i].y - rectOut.y)));\n        }\n        \n        // \u5143\u753b\u50cf\u304b\u3089\u6700\u5c0f\u77e9\u5f62\u3092\u5207\u308a\u53d6\u3063\u305f\u90e8\u5206\u3092\u30d1\u30c3\u30c1\u306b\u30b3\u30d4\u30fc\u3059\u308b\n        cv::Mat img1Cropped;\n        srcImg(rectIn).copyTo(img1Cropped);\n        \n        // \u4e09\u89d2\u5f62\u306e\u30a2\u30d5\u30a3\u30f3\u884c\u5217\u3092\u6c42\u3081\u308b\n        cv::Mat warpMat = getAffineTransform(tri1Cropped, tri2Cropped);\n        \n        // \u5143\u753b\u50cf\u304b\u3089\u30a2\u30d5\u30a3\u30f3\u884c\u5217\u3092\u5b9f\u65bd\u3059\u308b\n        cv::Mat img2Cropped = cv::Mat::zeros(rectOut.height, rectOut.width, img1Cropped.type());\n        warpAffine(img1Cropped, img2Cropped, warpMat, img2Cropped.size(), cv::INTER_LINEAR, cv::BORDER_REFLECT_101);\n        \n        // \u30de\u30b9\u30af\u3092\u751f\u6210\n        cv::Mat mask = cv::Mat::zeros(rectOut.height, rectOut.width, img1Cropped.type());\n        fillConvexPoly(mask, tri2CroppedInt, cv::Scalar(1.0, 1.0, 1.0), 16, 0);\n        \n        // \u30de\u30b9\u30af\u3092\u30d1\u30c3\u30c1\u306b\u9069\u7528\n        multiply(img2Cropped, mask, img2Cropped);\n        \n        // \u30de\u30b9\u30af\u90e8\u5206\u3067\u3059\u3067\u306b\u5024\u304c\u5165\u3063\u3066\u3044\u308b\u5834\u5408\uff08\u5883\u754c\u7dda\u90e8\u5206\uff09\u306f\u4e00\u65e60\u306b\u3059\u308b\n        multiply(distMat(rectOut), cv::Scalar(1.0,1.0,1.0) - mask, distMat(rectOut));\n        \n        // \u51fa\u529b\u753b\u50cf\u306b\u8ffd\u52a0\u3059\u308b\n        distMat(rectOut) = distMat(rectOut) + img2Cropped;\n    }\n    return distMat;\n}\n\nint main()\n{\n    try\n    {\n        array2d<bgr_pixel> bpImg;\n        dlib::load_image(bpImg, \"bp.png\");\n        cv::Mat bpMat = cv::Mat::zeros(HEIGHT, WIDTH, dlib::toMat(bpImg).type());\n        bpMat = dlib::toMat(bpImg);\n        \n        cv::VideoCapture cap(0);\n        cap.set(CV_CAP_PROP_FRAME_WIDTH , WIDTH);\n        cap.set(CV_CAP_PROP_FRAME_HEIGHT , HEIGHT);\n        if (!cap.isOpened())\n        {\n            cerr << \"Unable to connect to camera\" << endl;\n            return 1;\n        }\n        \n        image_window win1;\n        win1.set_size(WIDTH, HEIGHT+CV_CAP_PROP_FRAME_HEIGHT);\n        image_window win2;\n        win2.set_size(WIDTH, HEIGHT+CV_CAP_PROP_FRAME_HEIGHT);\n        image_window win3;\n        \n        win3.set_image(bpImg);\n        \n        // Load face detection and pose estimation models.\n        frontal_face_detector detector = get_frontal_face_detector();\n        shape_predictor pose_model;\n        deserialize(\"shape_predictor_68_face_landmarks.dat\") >> pose_model;\n        while(!win1.is_closed())\n        {\n            cv::Mat capMat;\n            cap >> capMat;\n            cv_image<bgr_pixel> targetImg(capMat);\n            \n            // \u30ab\u30e1\u30e9\u753b\u50cf\u306e\u8868\u793a\n            win1.clear_overlay();\n            win1.set_image(targetImg);\n            \n            // ###############\n            // \u30ab\u30e1\u30e9\u753b\u50cf\u306e\u51e6\u7406\n            // ###############\n            \n            // Detect faces\n            std::vector<rectangle> targetFaces = detector(targetImg);\n            \n            // Find the pose of each face.\n            std::vector<full_object_detection> targetShapes;\n            for (int i = 0; i < targetFaces.size(); ++i) {\n                targetShapes.push_back(pose_model(targetImg, targetFaces[i]));\n            }\n            \n            // Subdiv2D\u521d\u671f\u5316\n            cv::Subdiv2D subdiv;\n            cv::Rect rect(0, 0, capMat.cols, capMat.rows);\n            subdiv.initDelaunay(rect);\n            \n            // \u9854\u3092\u691c\u51fa\u3057\u3066\u3044\u306a\u3044\u5834\u5408\u306f\u4f55\u3082\u3057\u306a\u3044\n            if(targetShapes.empty()) {\n                continue;\n            }\n            \n            // \u6700\u521d\u306b\u691c\u51fa\u3057\u305f\u9854\u306e\u70b9\u3092\u8ffd\u52a0\n            std::map<int, cv::Point2f> targetMap;\n            full_object_detection& d1 = targetShapes[0];\n            for (int i = 0; i < d1.num_parts(); ++i) {\n                if(!rect.contains(cv::Point(d1.part(i).x(),d1.part(i).y()))) {\n                    continue;\n                }\n                cv::Point2f point(d1.part(i).x(), d1.part(i).y());\n                subdiv.insert(point);\n                targetMap.insert(std::pair<int, cv::Point2f>(i, point));\n            }\n            \n            // ###############\n            // \u91cd\u7573\u753b\u50cf\u306e\u51e6\u7406\n            // ###############\n            \n            // Detect faces\n            std::vector<rectangle> bpFaces = detector(bpImg);\n            \n            // Find the pose of each face.\n            std::vector<full_object_detection> bpShapes;\n            for (int i = 0; i < bpFaces.size(); ++i) {\n                bpShapes.push_back(pose_model(bpImg, bpFaces[i]));\n            }\n\n            // Subdiv2D\u521d\u671f\u5316\n            cv::Subdiv2D subdiv2;\n            cv::Rect rect2(0, 0, bpMat.cols, bpMat.rows);\n            subdiv2.initDelaunay(rect2);\n            \n            // \u9854\u3092\u691c\u51fa\u3057\u3066\u3044\u306a\u3044\u5834\u5408\u306f\u4f55\u3082\u3057\u306a\u3044\n            if(bpShapes.empty()) {\n                continue;\n            }\n            \n            // \u6700\u521d\u306b\u691c\u51fa\u3057\u305f\u9854\u306e\u70b9\u3092\u8ffd\u52a0\n            std::map<int, cv::Point2f> bpMap;\n            full_object_detection& d2 = bpShapes[0];\n            for (int i = 0; i < d2.num_parts(); ++i) {\n                if(!rect.contains(cv::Point(d2.part(i).x(),d2.part(i).y()))) {\n                    continue;\n                }\n                cv::Point2f point(d2.part(i).x(), d2.part(i).y());\n                subdiv2.insert(point);\n                bpMap.insert(std::pair<int, cv::Point2f>(i, point));\n            }\n            \n            // \u30c9\u30ed\u30cd\u30fc\u4e09\u89d2\u5f62\u306e\u30ea\u30b9\u30c8\u3092\u53d6\u5f97\n            std::vector<cv::Vec6f> triangles;\n            subdiv2.getTriangleList(triangles);\n            \n            // \u30c9\u30ed\u30cd\u30fc\u4e09\u89d2\u5f62\u3092\u30a2\u30d5\u30a3\u30f3\u5909\u63db\u3057\u305f\u753b\u50cf\u3092\u53d6\u5f97\n            cv_image<bgr_pixel> affinedImg(get_affined_image(triangles, rect, bpMat, bpMap, targetMap, capMat));\n            \n            // \u753b\u50cf\u3092\u8868\u793a\n            win2.clear_overlay();\n            win2.set_image(affinedImg);\n        }\n    }\n    catch(serialization_error& e)\n    {\n        cout << \"You need dlib's default face landmarking model file to run this example.\" << endl;\n        cout << \"You can get it from the following URL: \" << endl;\n        cout << \"   http://dlib.net/files/shape_predictor_68_face_landmarks.dat.bz2\" << endl;\n        cout << endl << e.what() << endl;\n    }\n    catch(exception& e)\n    {\n        cout << e.what() << endl;\n    }\n}\n\n```\n\n\n", "tags": ["dlib", "OpenCV", "C++", "\u9854\u8a8d\u8b58", "\u753b\u50cf\u8a8d\u8b58"]}