{"context": " More than 1 year has passed since last update.\n\n\u306f\u3058\u3081\u306b\nCDH5\u3067hadoop\u306e\u30af\u30e9\u30b9\u30bf\u3092\u69cb\u7bc9\u3059\u308b\u65b9\u6cd5\u3092\u8a18\u8ff0\u3057\u307e\u3059\u3002\n\n\u74b0\u5883\n\nCentOS 6.5\nCDH5\njdk 1.7.0_55\n\n\n\u69cb\u6210\n\n\n\n\u30db\u30b9\u30c8\u540d\nIP\u30a2\u30c9\u30ec\u30b9\nResourceManager\nNamenode\nNodeManager\nDatanode\nJobHistoryServer\n\n\n\n\nhadoop-master\n192.168.122.101\n\u25cb\n\u25cb\n-\n-\n\u25cb\n\n\nhadoop-master2\n192.168.122.102\n\u25cb\n\u25cb\n-\n-\n-\n\n\nhadoop-slave\n192.168.122.111\n-\n-\n\u25cb\n\u25cb\n-\n\n\nhadoop-slave2\n192.168.122.112\n-\n-\n\u25cb\n\u25cb\n-\n\n\nhadoop-slave3\n192.168.122.113\n-\n-\n\u25cb\n\u25cb\n-\n\n\nhadoop-client\n192.168.122.201\n-\n-\n-\n-\n-\n\n\n\n\n\u30af\u30e9\u30b9\u30bf\u306e\u69cb\u7bc9\n\n\u4e8b\u524d\u6e96\u5099\n\njdk\u306e\u30a4\u30f3\u30b9\u30c8\u30fc\u30eb\n\n$ curl -LO -b \"oraclelicense=accept-securebackup-cookie\" \"http://download.oracle.com/otn-pub/java/jdk/7u55-b13/jdk-7u55-linux-x64.rpm\"\n$ sudo yum localinstall jdk-7u55-linux-x64.rpm\n$ java -version\njava version \"1.7.0_55\"\nJava(TM) SE Runtime Environment (build 1.7.0_55-b13)\nJava HotSpot(TM) 64-Bit Server VM (build 24.55-b03, mixed mode)\n\n\nCDH5\u306e\u30ea\u30dd\u30b8\u30c8\u30ea\u306e\u8ffd\u52a0\n\n$ curl -LO http://archive.cloudera.com/cdh5/one-click-install/redhat/6/x86_64/cloudera-cdh-5-0.x86_64.rpm\n$ sudo yum localinstall cloudera-cdh-5-0.x86_64.rpm\n$ sudo yum clean all\n$ yum repolist\nLoaded plugins: fastestmirror, presto\nLoading mirror speeds from cached hostfile\ncloudera-cdh5                                                                                                                                |  951 B     00:00\ncloudera-cdh5/primary                                                                                                                        |  41 kB     00:00\ncloudera-cdh5                                                                                                                                               141/141\nrepo id                                                        repo name                                                                                      status\nbase                                                           CentOS-6 - Base                                                                                6,367\ncloudera-cdh5                                                  Cloudera's Distribution for Hadoop, Version 5                                                    141\nextras                                                         CentOS-6 - Extras                                                                                 15\nupdates                                                        CentOS-6 - Updates                                                                             1,507\nrepolist: 8,030\n\n$ sudo rpm --import http://archive.cloudera.com/cdh5/redhat/5/x86_64/cdh/RPM-GPG-KEY-cloudera\n\n\n\u30d1\u30c3\u30b1\u30fc\u30b8\u306e\u30a4\u30f3\u30b9\u30c8\u30fc\u30eb\n\n\u30de\u30b9\u30bf\u30ce\u30fc\u30c9(hadoop-master,hadoop-master2)\n\n$ sudo yum install hadoop-yarn-resourcemanager hadoop-hdfs-namenode hadoop-mapreduce-historyserver hadoop-yarn-proxyserver\n\n\n\u30b9\u30ec\u30fc\u30d6\u30ce\u30fc\u30c9(hadoop-slave,hadoop-slave2)\n\n$ sudo yum install hadoop-yarn-nodemanager hadoop-hdfs-datanode hadoop-mapreduce\n\n\n\u30af\u30e9\u30a4\u30a2\u30f3\u30c8(hadoop-client)\n\n$ sudo yum install hadoop-client \n\n\n\u30cd\u30c3\u30c8\u30ef\u30fc\u30af\u8a2d\u5b9a\n\u5404\u30ce\u30fc\u30c9\u3067\u30db\u30b9\u30c8\u540d\u3092\u540d\u524d\u89e3\u6c7a\u3067\u304d\u308b\u3088\u3046\u306b\u8a2d\u5b9a\u3092\u8ffd\u52a0\u3057\u307e\u3059\u3002(\u30de\u30b9\u30bf\u30ce\u30fc\u30c9\u3001\u30b9\u30ec\u30fc\u30d6\u30ce\u30fc\u30c9\u304a\u3088\u3073\u30af\u30e9\u30a4\u30a2\u30f3\u30c8\u3059\u3079\u3066)\n\n/etc/hosts\n192.168.122.101 hadoop-master\n192.168.122.102 hadoop-master2\n192.168.122.111 hadoop-slave\n192.168.122.112 hadoop-slave2\n192.168.122.113 hadoop-slave3\n192.168.122.201 hadoop-client\n\n\n\nHDFS\u306e\u8a2d\u5b9a\n\n\u8a2d\u5b9a\u30d5\u30a1\u30a4\u30eb\u306e\u3072\u306a\u578b\u3092\u30b3\u30d4\u30fc\u3057\u307e\u3059\u3002(\u30de\u30b9\u30bf\u30ce\u30fc\u30c9\u3001\u30b9\u30ec\u30fc\u30d6\u30ce\u30fc\u30c9\u304a\u3088\u3073\u30af\u30e9\u30a4\u30a2\u30f3\u30c8\u3059\u3079\u3066)\n\n$ sudo cp -r /etc/hadoop/conf.empty /etc/hadoop/conf.cluster\n$ sudo alternatives --install /etc/hadoop/conf hadoop-conf /etc/hadoop/conf.cluster 50\n$ sudo alternatives --set hadoop-conf /etc/hadoop/conf.cluster\n\n$ sudo alternatives --display hadoop-conf\nhadoop-conf - status is manual.\n link currently points to /etc/hadoop/conf.cluster\n/etc/hadoop/conf.empty - priority 10\n/etc/hadoop/conf.impala - priority 5\n/etc/hadoop/conf.cluster - priority 50\nCurrent `best' version is /etc/hadoop/conf.cluster.\n\n\nHDFS\u306e\u8a2d\u5b9a\u3092\u884c\u3044\u307e\u3059\u3002(\u30de\u30b9\u30bf\u30ce\u30fc\u30c9\u3001\u30b9\u30ec\u30fc\u30d6\u30ce\u30fc\u30c9\u304a\u3088\u3073\u30af\u30e9\u30a4\u30a2\u30f3\u30c8\u3059\u3079\u3066)\n\n\n/etc/hadoop/conf/core-site.xml\n<configuration>\n  <property>\n    <name>fs.defaultFS</name>\n    <value>hdfs://hadoop-master:8020</value>\n  </property>\n</configuration>\n\n\n\n/etc/hadoop/conf/hdfs-site.xml\n<configuration>\n  <property>\n    <name>dfs.permissions.superusergroup</name>\n    <value>hadoop</value>\n  </property>\n  <property>\n    <name>dfs.namenode.name.dir</name>\n    <value>/var/lib/hadoop-hdfs/cache/dfs/name</value>\n  </property>\n  <property>\n    <name>dfs.datanode.name.dir</name>\n    <value>/var/lib/hadoop-hdfs/cache/dfs/data</value>\n  </property>\n</configuration>\n\n\n$ sudo mkdir -p /var/lib/hadoop-hdfs/cache/dfs/name\n$ sudo mkdir -p /var/lib/hadoop-hdfs/cache/dfs/data\n$ sudo chown hdfs:hadoop -R /var/lib/hadoop-hdfs/cache/dfs\n\n\n\u30cd\u30fc\u30e0\u30ce\u30fc\u30c9\u3092\u30d5\u30a9\u30fc\u30de\u30c3\u30c8\u3057\u307e\u3059\u3002(hadoop-master\u306e\u307f)\n\n$ sudo -u hdfs hdfs namenode -format\n14/09/20 03:59:16 INFO namenode.NameNode: STARTUP_MSG:\n/************************************************************\nSTARTUP_MSG: Starting NameNode\nSTARTUP_MSG:   host = localhost.localdomain/192.168.122.101\nSTARTUP_MSG:   args = [-format]\nSTARTUP_MSG:   version = 2.3.0-cdh5.1.2\nSTARTUP_MSG:   classpath = /etc/hadoop/conf:...(\u7701\u7565)...\nSTARTUP_MSG:   build = git://github.sf.cloudera.com/CDH/cdh.git -r 8e266e052e423af592871e2dfe09d54c03f6a0e8; compiled by 'jenkins' on 2014-08-26T01:36Z\nSTARTUP_MSG:   java = 1.7.0_55\n************************************************************/\n14/09/20 03:59:17 INFO namenode.NameNode: registered UNIX signal handlers for [TERM, HUP, INT]\n14/09/20 03:59:17 INFO namenode.NameNode: createNameNode [-format]\nFormatting using clusterid: CID-51ba5115-4500-4b1d-b26c-b8fb9f41e03d\n14/09/20 03:59:18 INFO namenode.FSNamesystem: fsLock is fair:true\n14/09/20 03:59:18 INFO blockmanagement.DatanodeManager: dfs.block.invalidate.limit=1000\n14/09/20 03:59:18 INFO blockmanagement.DatanodeManager: dfs.namenode.datanode.registration.ip-hostname-check=true\n14/09/20 03:59:18 INFO blockmanagement.BlockManager: dfs.namenode.startup.delay.block.deletion.ms is set to 0 ms.\n14/09/20 03:59:18 INFO blockmanagement.BlockManager: The block deletion will start around 2014 Sep 20 03:59:18\n14/09/20 03:59:18 INFO util.GSet: Computing capacity for map BlocksMap\n14/09/20 03:59:18 INFO util.GSet: VM type       = 64-bit\n14/09/20 03:59:18 INFO util.GSet: 2.0% max memory 889 MB = 17.8 MB\n14/09/20 03:59:18 INFO util.GSet: capacity      = 2^21 = 2097152 entries\n14/09/20 03:59:18 INFO blockmanagement.BlockManager: dfs.block.access.token.enable=false\n14/09/20 03:59:18 INFO blockmanagement.BlockManager: defaultReplication         = 3\n14/09/20 03:59:18 INFO blockmanagement.BlockManager: maxReplication             = 512\n14/09/20 03:59:18 INFO blockmanagement.BlockManager: minReplication             = 1\n14/09/20 03:59:18 INFO blockmanagement.BlockManager: maxReplicationStreams      = 2\n14/09/20 03:59:18 INFO blockmanagement.BlockManager: shouldCheckForEnoughRacks  = false\n14/09/20 03:59:18 INFO blockmanagement.BlockManager: replicationRecheckInterval = 3000\n14/09/20 03:59:18 INFO blockmanagement.BlockManager: encryptDataTransfer        = false\n14/09/20 03:59:18 INFO blockmanagement.BlockManager: maxNumBlocksToLog          = 1000\n14/09/20 03:59:18 INFO namenode.FSNamesystem: fsOwner             = hdfs (auth:SIMPLE)\n14/09/20 03:59:18 INFO namenode.FSNamesystem: supergroup          = hadoop\n14/09/20 03:59:18 INFO namenode.FSNamesystem: isPermissionEnabled = true\n14/09/20 03:59:18 INFO namenode.FSNamesystem: HA Enabled: false\n14/09/20 03:59:18 INFO namenode.FSNamesystem: Append Enabled: true\n14/09/20 03:59:18 INFO util.GSet: Computing capacity for map INodeMap\n14/09/20 03:59:18 INFO util.GSet: VM type       = 64-bit\n14/09/20 03:59:18 INFO util.GSet: 1.0% max memory 889 MB = 8.9 MB\n14/09/20 03:59:18 INFO util.GSet: capacity      = 2^20 = 1048576 entries\n14/09/20 03:59:18 INFO namenode.NameNode: Caching file names occuring more than 10 times\n14/09/20 03:59:18 INFO util.GSet: Computing capacity for map cachedBlocks\n14/09/20 03:59:18 INFO util.GSet: VM type       = 64-bit\n14/09/20 03:59:18 INFO util.GSet: 0.25% max memory 889 MB = 2.2 MB\n14/09/20 03:59:18 INFO util.GSet: capacity      = 2^18 = 262144 entries\n14/09/20 03:59:18 INFO namenode.FSNamesystem: dfs.namenode.safemode.threshold-pct = 0.9990000128746033\n14/09/20 03:59:18 INFO namenode.FSNamesystem: dfs.namenode.safemode.min.datanodes = 0\n14/09/20 03:59:18 INFO namenode.FSNamesystem: dfs.namenode.safemode.extension     = 30000\n14/09/20 03:59:18 INFO namenode.FSNamesystem: Retry cache on namenode is enabled\n14/09/20 03:59:18 INFO namenode.FSNamesystem: Retry cache will use 0.03 of total heap and retry cache entry expiry time is 600000 millis\n14/09/20 03:59:18 INFO util.GSet: Computing capacity for map NameNodeRetryCache\n14/09/20 03:59:18 INFO util.GSet: VM type       = 64-bit\n14/09/20 03:59:18 INFO util.GSet: 0.029999999329447746% max memory 889 MB = 273.1 KB\n14/09/20 03:59:18 INFO util.GSet: capacity      = 2^15 = 32768 entries\n14/09/20 03:59:18 INFO namenode.AclConfigFlag: ACLs enabled? false\n14/09/20 03:59:18 INFO namenode.FSImage: Allocated new BlockPoolId: BP-1157687996-10.250.0.101-1411185558593\n14/09/20 03:59:18 INFO common.Storage: Storage directory /var/lib/hadoop-hdfs/cache/dfs/name has been successfully formatted.\n14/09/20 03:59:19 INFO namenode.NNStorageRetentionManager: Going to retain 1 images with txid >= 0\n14/09/20 03:59:19 INFO util.ExitUtil: Exiting with status 0\n14/09/20 03:59:19 INFO namenode.NameNode: SHUTDOWN_MSG:\n/************************************************************\nSHUTDOWN_MSG: Shutting down NameNode at localhost.localdomain/192.168.122.101\n************************************************************/\n\n\nHDFS\u306e\u8d77\u52d5\n\n\u30cd\u30fc\u30e0\u30ce\u30fc\u30c9\u3092\u8d77\u52d5\u3057\u307e\u3059\u3002(\u30de\u30b9\u30bf\u30ce\u30fc\u30c9)\n$ sudo service hadoop-hdfs-namenode start\n\n\u30c7\u30fc\u30bf\u30ce\u30fc\u30c9\u3092\u8d77\u52d5\u3057\u307e\u3059\u3002(\u30b9\u30ec\u30fc\u30d6\u30ce\u30fc\u30c9)\n$ sudo service hadoop-hdfs-datanode start\n\n\nHDFS\u4e0a\u306btmp\u30c7\u30a3\u30ec\u30af\u30c8\u30ea\u3092\u4f5c\u6210\u3057\u307e\u3059\u3002(\u30af\u30e9\u30a4\u30a2\u30f3\u30c8\u30ce\u30fc\u30c9)\n\n$ sudo -u hdfs hadoop fs -mkdir /tmp\n$ sudo -u hdfs hadoop fs -chmod -R 1777 /tmp\n$ sudo -u hdfs hadoop fs -ls /\nFound 1 items\ndrwxrwxrwt   - hdfs hadoop          0 2014-09-20 04:30 /tmp\n\n\nMap Reduce v2(YARN)\u306e\u8a2d\u5b9a\n\nMap Reduce v2(YARN)\u306e\u8a2d\u5b9a\u3092\u884c\u3044\u307e\u3059\u3002(\u30de\u30b9\u30bf\u30ce\u30fc\u30c9\u3001\u30b9\u30ec\u30fc\u30d6\u30ce\u30fc\u30c9\u304a\u3088\u3073\u30af\u30e9\u30a4\u30a2\u30f3\u30c8\u3059\u3079\u3066)\n\n\n/etc/hadoop/conf/mapred-site.xml\n<configuration>\n  <property>\n    <name>yarn.nodemanager.local-dirs</name>\n    <value>file:///var/lib/hadoop-yarn/cache/local</value>\n  </property>\n  <property>\n    <name>yarn.nodemanager.log-dirs</name>\n    <value>file:///var/log/hadoop-yarn/containers</value>\n  </property>\n  <property>\n    <name>yarn.nodemanager.remote-app-log-dir</name>\n    <value>hdfs://hadoop-master:8020/var/log/hadoop-yarn/apps</value>\n  </property>\n  <property>\n    <name>mapreduce.jobhistory.address</name>\n    <value>hadoop-master:10020</value>\n  </property>\n  <property>\n    <name>mapreduce.jobhistory.webapp.address</name>\n    <value>hadoop-master:19888</value>\n  </property>\n  <property>\n    <name>hadoop.proxyuser.mapred.groups</name>\n    <value>*</value>\n  </property>\n  <property>\n    <name>hadoop.proxyuser.mapred.hosts</name>\n    <value>*</value>\n  </property>\n  <property>\n    <name>yarn.app.mapreduce.am.staging-dir</name>\n    <value>/user</value>\n  </property>\n</configuration>\n\n\n\n/etc/hadoop/conf/yarn-site.xml\n<configuration>\n  <property>\n    <name>yarn.nodemanager.aux-services</name>\n    <value>mapreduce_shuffle</value>\n  </property>\n  <property>\n    <name>yarn.nodemanager.aux-services.mapreduce_shuffle.class</name>\n    <value>org.apache.hadoop.mapred.ShuffleHandler</value>\n  </property>\n  <property>\n    <name>yarn.resourcemanager.hostname</name>\n    <value>hadoop-master</value>\n  </property>\n  <property>\n    <name>yarn.log-aggregation-enable</name>\n    <value>true</value>\n  </property>\n  <property>\n    <description>List of directories to store localized files in.</description>\n    <name>yarn.nodemanager.local-dirs</name>\n    <value>file:///var/lib/hadoop-yarn/cache/local</value>\n  </property>\n  <property>\n    <description>Where to store container logs.</description>\n    <name>yarn.nodemanager.log-dirs</name>\n    <value>file:///var/log/hadoop-yarn/containers</value>\n  </property>\n  <property>\n    <description>Where to aggregate logs to.</description>\n    <name>yarn.nodemanager.remote-app-log-dir</name>\n    <value>hdfs:///hadoop-master:8020/var/log/hadoop-yarn/apps</value>\n  </property>\n\n  <property>\n    <description>Classpath for typical applications.</description>\n     <name>yarn.application.classpath</name>\n     <value>\n        $HADOOP_CONF_DIR,\n        $HADOOP_COMMON_HOME/*,$HADOOP_COMMON_HOME/lib/*,\n        $HADOOP_HDFS_HOME/*,$HADOOP_HDFS_HOME/lib/*,\n        $HADOOP_MAPRED_HOME/*,$HADOOP_MAPRED_HOME/lib/*,\n        $HADOOP_YARN_HOME/*,$HADOOP_YARN_HOME/lib/*\n     </value>\n  </property>\n</configuration>\n\n\n\n\u5fc5\u8981\u306a\u30c7\u30a3\u30ec\u30af\u30c8\u3092\u4f5c\u6210\u3057\u307e\u3059\u3002(\u30de\u30b9\u30bf\u30ce\u30fc\u30c9\u3001\u30b9\u30ec\u30fc\u30d6\u30ce\u30fc\u30c9\u304a\u3088\u3073\u30af\u30e9\u30a4\u30a2\u30f3\u30c8)\n\n$ sudo mkdir -p /var/lib/hadoop-yarn/cache/local\n$ sudo chown yarn:hadoop /var/lib/hadoop-yarn/cache/local\n$ sudo mkdir -p /var/log/hadoop-yarn/containers\n$ sudo chown yarn:hadoop /var/log/hadoop-yarn/containers\n\n\n\u5fc5\u8981\u306a\u30c7\u30a3\u30ec\u30af\u30c8\u30ea\u3092HDFS\u4e0a\u306b\u4f5c\u6210\u3057\u307e\u3059\u3002(\u30af\u30e9\u30a4\u30a2\u30f3\u30c8\u3067\u5b9f\u884c)\n\n$ sudo -u hdfs hadoop fs -mkdir -p /user/history\n$ sudo -u hdfs hadoop fs -chmod -R 1777 /user/history\n$ sudo -u hdfs hadoop fs -chown mapred:hadoop /user/history\n$ sudo -u hdfs hadoop fs -mkdir -p /var/log/hadoop-yarn\n$ sudo -u hdfs hadoop fs -chown yarn:mapred /var/log/hadoop-yarn\n$ sudo -u hdfs hadoop fs -ls -R /\ndrwxrwxrwt   - hdfs hadoop          0 2014-09-20 04:30 /tmp\ndrwxr-xr-x   - hdfs hadoop          0 2014-09-20 05:08 /user\ndrwxrwxrwt   - mapred hadoop          0 2014-09-20 05:08 /user/history\ndrwxr-xr-x   - hdfs   hadoop          0 2014-09-20 05:08 /var\ndrwxr-xr-x   - hdfs   hadoop          0 2014-09-20 05:08 /var/log\ndrwxr-xr-x   - yarn   mapred          0 2014-09-20 05:08 /var/log/hadoop-yarn\n\n\n\u30ea\u30bd\u30fc\u30b9\u30de\u30cd\u30fc\u30b8\u30e3\u3092\u8d77\u52d5\u3057\u307e\u3059\u3002(\u30de\u30b9\u30bf\u30ce\u30fc\u30c9)\n\n$ sudo service hadoop-yarn-resourcemanager start\n\n\n\u30ce\u30fc\u30c9\u30de\u30cd\u30fc\u30b8\u30e3\u3092\u8d77\u52d5\u3057\u307e\u3059\u3002(\u30b9\u30ec\u30fc\u30d6\u30ce\u30fc\u30c9)\n\n$ sudo service hadoop-yarn-nodemanager start\n\n\n\u30d2\u30b9\u30c8\u30ea\u30b5\u30fc\u30d0\u3092\u8d77\u52d5\u3057\u307e\u3059\u3002(hadoop-master\u306e\u307f)\n\n$ sudo service hadoop-mapreduce-historyserver start\n\n\n\u52d5\u4f5c\u78ba\u8a8d\n\n\u30b5\u30f3\u30d7\u30eb\u30d7\u30ed\u30b0\u30e9\u30e0\u3092\u5b9f\u884c\u3057\u307e\u3059\u3002(\u30af\u30e9\u30a4\u30a2\u30f3\u30c8\u3067\u5b9f\u884c)\n\n$ sudo -u hdfs hadoop jar /usr/lib/hadoop-mapreduce/hadoop-mapreduce-examples-2.3.0-cdh5.1.2.jar pi 1 300\nNumber of Maps  = 1\nSamples per Map = 300\nWrote input for Map #0\nStarting Job\n14/09/20 06:33:37 INFO Configuration.deprecation: session.id is deprecated. Instead, use dfs.metrics.session-id\n14/09/20 06:33:37 INFO jvm.JvmMetrics: Initializing JVM Metrics with processName=JobTracker, sessionId=\n14/09/20 06:33:37 INFO input.FileInputFormat: Total input paths to process : 1\n14/09/20 06:33:37 INFO mapreduce.JobSubmitter: number of splits:1\n14/09/20 06:33:37 INFO mapreduce.JobSubmitter: Submitting tokens for job: job_local936971230_0001\n14/09/20 06:33:37 WARN conf.Configuration: file:/tmp/hadoop-hdfs/mapred/staging/hdfs936971230/.staging/job_local936971230_0001/job.xml:an attempt to override final parameter: mapreduce.job.end-notification.max.retry.interval;  Ignoring.\n14/09/20 06:33:37 WARN conf.Configuration: file:/tmp/hadoop-hdfs/mapred/staging/hdfs936971230/.staging/job_local936971230_0001/job.xml:an attempt to override final parameter: mapreduce.job.end-notification.max.attempts;  Ignoring.\n14/09/20 06:33:38 WARN conf.Configuration: file:/tmp/hadoop-hdfs/mapred/local/localRunner/hdfs/job_local936971230_0001/job_local936971230_0001.xml:an attempt to override final parameter: mapreduce.job.end-notification.max.retry.interval;  Ignoring.\n14/09/20 06:33:38 WARN conf.Configuration: file:/tmp/hadoop-hdfs/mapred/local/localRunner/hdfs/job_local936971230_0001/job_local936971230_0001.xml:an attempt to override final parameter: mapreduce.job.end-notification.max.attempts;  Ignoring.\n14/09/20 06:33:38 INFO mapreduce.Job: The url to track the job: http://localhost:8080/\n14/09/20 06:33:38 INFO mapreduce.Job: Running job: job_local936971230_0001\n14/09/20 06:33:38 INFO mapred.LocalJobRunner: OutputCommitter set in config null\n14/09/20 06:33:38 INFO mapred.LocalJobRunner: OutputCommitter is org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter\n14/09/20 06:33:38 INFO mapred.LocalJobRunner: Waiting for map tasks\n14/09/20 06:33:38 INFO mapred.LocalJobRunner: Starting task: attempt_local936971230_0001_m_000000_0\n14/09/20 06:33:38 INFO mapred.Task:  Using ResourceCalculatorProcessTree : [ ]\n14/09/20 06:33:38 INFO mapred.MapTask: Processing split: hdfs://hadoop-master:8020/user/hdfs/QuasiMonteCarlo_1411194815372_1775447123/in/part0:0+118\n14/09/20 06:33:38 INFO mapred.MapTask: Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer\n14/09/20 06:33:38 INFO mapred.MapTask: (EQUATOR) 0 kvi 26214396(104857584)\n14/09/20 06:33:38 INFO mapred.MapTask: mapreduce.task.io.sort.mb: 100\n14/09/20 06:33:38 INFO mapred.MapTask: soft limit at 83886080\n14/09/20 06:33:38 INFO mapred.MapTask: bufstart = 0; bufvoid = 104857600\n14/09/20 06:33:38 INFO mapred.MapTask: kvstart = 26214396; length = 6553600\n14/09/20 06:33:38 INFO mapred.LocalJobRunner:\n14/09/20 06:33:38 INFO mapred.MapTask: Starting flush of map output\n14/09/20 06:33:38 INFO mapred.MapTask: Spilling map output\n14/09/20 06:33:38 INFO mapred.MapTask: bufstart = 0; bufend = 18; bufvoid = 104857600\n14/09/20 06:33:38 INFO mapred.MapTask: kvstart = 26214396(104857584); kvend = 26214392(104857568); length = 5/6553600\n14/09/20 06:33:38 INFO mapred.MapTask: Finished spill 0\n14/09/20 06:33:38 INFO mapred.Task: Task:attempt_local936971230_0001_m_000000_0 is done. And is in the process of committing\n14/09/20 06:33:38 INFO mapred.LocalJobRunner: map\n14/09/20 06:33:38 INFO mapred.Task: Task 'attempt_local936971230_0001_m_000000_0' done.\n14/09/20 06:33:38 INFO mapred.LocalJobRunner: Finishing task: attempt_local936971230_0001_m_000000_0\n14/09/20 06:33:38 INFO mapred.LocalJobRunner: map task executor complete.\n14/09/20 06:33:38 INFO mapred.LocalJobRunner: Waiting for reduce tasks\n14/09/20 06:33:38 INFO mapred.LocalJobRunner: Starting task: attempt_local936971230_0001_r_000000_0\n14/09/20 06:33:38 INFO mapred.Task:  Using ResourceCalculatorProcessTree : [ ]\n14/09/20 06:33:38 INFO mapred.ReduceTask: Using ShuffleConsumerPlugin: org.apache.hadoop.mapreduce.task.reduce.Shuffle@73616964\n14/09/20 06:33:38 INFO reduce.MergeManagerImpl: MergerManager: memoryLimit=652528832, maxSingleShuffleLimit=163132208, mergeThreshold=430669056, ioSortFactor=10, memToMemMergeOutputsThreshold=10\n14/09/20 06:33:38 INFO reduce.EventFetcher: attempt_local936971230_0001_r_000000_0 Thread started: EventFetcher for fetching Map Completion Events\n14/09/20 06:33:38 INFO reduce.LocalFetcher: localfetcher#1 about to shuffle output of map attempt_local936971230_0001_m_000000_0 decomp: 24 len: 28 to MEMORY\n14/09/20 06:33:38 INFO reduce.InMemoryMapOutput: Read 24 bytes from map-output for attempt_local936971230_0001_m_000000_0\n14/09/20 06:33:38 INFO reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 24, inMemoryMapOutputs.size() -> 1, commitMemory -> 0, usedMemory ->24\n14/09/20 06:33:38 INFO reduce.EventFetcher: EventFetcher is interrupted.. Returning\n14/09/20 06:33:38 INFO mapred.LocalJobRunner: 1 / 1 copied.\n14/09/20 06:33:38 INFO reduce.MergeManagerImpl: finalMerge called with 1 in-memory map-outputs and 0 on-disk map-outputs\n14/09/20 06:33:38 INFO mapred.Merger: Merging 1 sorted segments\n14/09/20 06:33:38 INFO mapred.Merger: Down to the last merge-pass, with 1 segments left of total size: 21 bytes\n14/09/20 06:33:38 INFO reduce.MergeManagerImpl: Merged 1 segments, 24 bytes to disk to satisfy reduce memory limit\n14/09/20 06:33:38 INFO reduce.MergeManagerImpl: Merging 1 files, 28 bytes from disk\n14/09/20 06:33:38 INFO reduce.MergeManagerImpl: Merging 0 segments, 0 bytes from memory into reduce\n14/09/20 06:33:38 INFO mapred.Merger: Merging 1 sorted segments\n14/09/20 06:33:38 INFO mapred.Merger: Down to the last merge-pass, with 1 segments left of total size: 21 bytes\n14/09/20 06:33:38 INFO mapred.LocalJobRunner: 1 / 1 copied.\n14/09/20 06:33:38 INFO Configuration.deprecation: mapred.skip.on is deprecated. Instead, use mapreduce.job.skiprecords\n14/09/20 06:33:38 INFO mapred.Task: Task:attempt_local936971230_0001_r_000000_0 is done. And is in the process of committing\n14/09/20 06:33:38 INFO mapred.LocalJobRunner: 1 / 1 copied.\n14/09/20 06:33:38 INFO mapred.Task: Task attempt_local936971230_0001_r_000000_0 is allowed to commit now\n14/09/20 06:33:38 INFO output.FileOutputCommitter: Saved output of task 'attempt_local936971230_0001_r_000000_0' to hdfs://hadoop-master:8020/user/hdfs/QuasiMonteCarlo_1411194815372_1775447123/out/_temporary/0/task_local936971230_0001_r_000000\n14/09/20 06:33:38 INFO mapred.LocalJobRunner: reduce > reduce\n14/09/20 06:33:38 INFO mapred.Task: Task 'attempt_local936971230_0001_r_000000_0' done.\n14/09/20 06:33:38 INFO mapred.LocalJobRunner: Finishing task: attempt_local936971230_0001_r_000000_0\n14/09/20 06:33:38 INFO mapred.LocalJobRunner: reduce task executor complete.\n14/09/20 06:33:39 INFO mapreduce.Job: Job job_local936971230_0001 running in uber mode : false\n14/09/20 06:33:39 INFO mapreduce.Job:  map 100% reduce 100%\n14/09/20 06:33:39 INFO mapreduce.Job: Job job_local936971230_0001 completed successfully\n14/09/20 06:33:39 INFO mapreduce.Job: Counters: 38\n        File System Counters\n                FILE: Number of bytes read=552150\n                FILE: Number of bytes written=988114\n                FILE: Number of read operations=0\n                FILE: Number of large read operations=0\n                FILE: Number of write operations=0\n                HDFS: Number of bytes read=236\n                HDFS: Number of bytes written=451\n                HDFS: Number of read operations=19\n                HDFS: Number of large read operations=0\n                HDFS: Number of write operations=9\n        Map-Reduce Framework\n                Map input records=1\n                Map output records=2\n                Map output bytes=18\n                Map output materialized bytes=28\n                Input split bytes=150\n                Combine input records=0\n                Combine output records=0\n                Reduce input groups=2\n                Reduce shuffle bytes=28\n                Reduce input records=2\n                Reduce output records=0\n                Spilled Records=4\n                Shuffled Maps =1\n                Failed Shuffles=0\n                Merged Map outputs=1\n                GC time elapsed (ms)=0\n                CPU time spent (ms)=0\n                Physical memory (bytes) snapshot=0\n                Virtual memory (bytes) snapshot=0\n                Total committed heap usage (bytes)=634388480\n        Shuffle Errors\n                BAD_ID=0\n                CONNECTION=0\n                IO_ERROR=0\n                WRONG_LENGTH=0\n                WRONG_MAP=0\n                WRONG_REDUCE=0\n        File Input Format Counters\n                Bytes Read=118\n        File Output Format Counters\n                Bytes Written=97\nJob Finished in 2.024 seconds\nEstimated value of Pi is 3.16000000000000000000\n\n\n\u53c2\u8003\n\nCDH 5 Installation Guide\nSupported JDK Versions\nInstalling CDH 5\nDeploying HDFS on a Cluster\nDeploying MapReduce v2 (YARN) on a Cluster\n\n\n## \u306f\u3058\u3081\u306b\n\nCDH5\u3067hadoop\u306e\u30af\u30e9\u30b9\u30bf\u3092\u69cb\u7bc9\u3059\u308b\u65b9\u6cd5\u3092\u8a18\u8ff0\u3057\u307e\u3059\u3002\n\n## \u74b0\u5883\n\n* CentOS 6.5\n* CDH5\n* jdk 1.7.0_55\n\n## \u69cb\u6210\n\n|\u30db\u30b9\u30c8\u540d      |IP\u30a2\u30c9\u30ec\u30b9     |ResourceManager|Namenode|NodeManager|Datanode|JobHistoryServer|\n|:-------------|:--------------|:-------------:|:------:|:---------:|:------:|:--------------:|\n|hadoop-master |192.168.122.101|\u25cb             |\u25cb      |-          |-       |\u25cb              |\n|hadoop-master2|192.168.122.102|\u25cb             |\u25cb      |-          |-       |-               |\n|hadoop-slave  |192.168.122.111|-              |-       |\u25cb         |\u25cb      |-               |\n|hadoop-slave2 |192.168.122.112|-              |-       |\u25cb         |\u25cb      |-               |\n|hadoop-slave3 |192.168.122.113|-              |-       |\u25cb         |\u25cb      |-               |\n|hadoop-client |192.168.122.201|-              |-       |-          |-       |-               |\n\n## \u30af\u30e9\u30b9\u30bf\u306e\u69cb\u7bc9\n\n### \u4e8b\u524d\u6e96\u5099\n\n* jdk\u306e\u30a4\u30f3\u30b9\u30c8\u30fc\u30eb\n\n```shell\n$ curl -LO -b \"oraclelicense=accept-securebackup-cookie\" \"http://download.oracle.com/otn-pub/java/jdk/7u55-b13/jdk-7u55-linux-x64.rpm\"\n$ sudo yum localinstall jdk-7u55-linux-x64.rpm\n$ java -version\njava version \"1.7.0_55\"\nJava(TM) SE Runtime Environment (build 1.7.0_55-b13)\nJava HotSpot(TM) 64-Bit Server VM (build 24.55-b03, mixed mode)\n```\n* CDH5\u306e\u30ea\u30dd\u30b8\u30c8\u30ea\u306e\u8ffd\u52a0\n\n```shell\n$ curl -LO http://archive.cloudera.com/cdh5/one-click-install/redhat/6/x86_64/cloudera-cdh-5-0.x86_64.rpm\n$ sudo yum localinstall cloudera-cdh-5-0.x86_64.rpm\n$ sudo yum clean all\n$ yum repolist\nLoaded plugins: fastestmirror, presto\nLoading mirror speeds from cached hostfile\ncloudera-cdh5                                                                                                                                |  951 B     00:00\ncloudera-cdh5/primary                                                                                                                        |  41 kB     00:00\ncloudera-cdh5                                                                                                                                               141/141\nrepo id                                                        repo name                                                                                      status\nbase                                                           CentOS-6 - Base                                                                                6,367\ncloudera-cdh5                                                  Cloudera's Distribution for Hadoop, Version 5                                                    141\nextras                                                         CentOS-6 - Extras                                                                                 15\nupdates                                                        CentOS-6 - Updates                                                                             1,507\nrepolist: 8,030\n\n$ sudo rpm --import http://archive.cloudera.com/cdh5/redhat/5/x86_64/cdh/RPM-GPG-KEY-cloudera\n```\n\n### \u30d1\u30c3\u30b1\u30fc\u30b8\u306e\u30a4\u30f3\u30b9\u30c8\u30fc\u30eb\n\n* \u30de\u30b9\u30bf\u30ce\u30fc\u30c9(hadoop-master,hadoop-master2)\n\n```shell\n$ sudo yum install hadoop-yarn-resourcemanager hadoop-hdfs-namenode hadoop-mapreduce-historyserver hadoop-yarn-proxyserver\n```\n\n* \u30b9\u30ec\u30fc\u30d6\u30ce\u30fc\u30c9(hadoop-slave,hadoop-slave2)\n\n```shell\n$ sudo yum install hadoop-yarn-nodemanager hadoop-hdfs-datanode hadoop-mapreduce\n```\n\n* \u30af\u30e9\u30a4\u30a2\u30f3\u30c8(hadoop-client)\n\n```shell\n$ sudo yum install hadoop-client \n```\n\n### \u30cd\u30c3\u30c8\u30ef\u30fc\u30af\u8a2d\u5b9a\n\n\u5404\u30ce\u30fc\u30c9\u3067\u30db\u30b9\u30c8\u540d\u3092\u540d\u524d\u89e3\u6c7a\u3067\u304d\u308b\u3088\u3046\u306b\u8a2d\u5b9a\u3092\u8ffd\u52a0\u3057\u307e\u3059\u3002(\u30de\u30b9\u30bf\u30ce\u30fc\u30c9\u3001\u30b9\u30ec\u30fc\u30d6\u30ce\u30fc\u30c9\u304a\u3088\u3073\u30af\u30e9\u30a4\u30a2\u30f3\u30c8\u3059\u3079\u3066)\n\n```conf:/etc/hosts\n192.168.122.101 hadoop-master\n192.168.122.102 hadoop-master2\n192.168.122.111 hadoop-slave\n192.168.122.112 hadoop-slave2\n192.168.122.113 hadoop-slave3\n192.168.122.201 hadoop-client\n```\n\n### HDFS\u306e\u8a2d\u5b9a\n\n* \u8a2d\u5b9a\u30d5\u30a1\u30a4\u30eb\u306e\u3072\u306a\u578b\u3092\u30b3\u30d4\u30fc\u3057\u307e\u3059\u3002(\u30de\u30b9\u30bf\u30ce\u30fc\u30c9\u3001\u30b9\u30ec\u30fc\u30d6\u30ce\u30fc\u30c9\u304a\u3088\u3073\u30af\u30e9\u30a4\u30a2\u30f3\u30c8\u3059\u3079\u3066)\n\n```shell\n$ sudo cp -r /etc/hadoop/conf.empty /etc/hadoop/conf.cluster\n$ sudo alternatives --install /etc/hadoop/conf hadoop-conf /etc/hadoop/conf.cluster 50\n$ sudo alternatives --set hadoop-conf /etc/hadoop/conf.cluster\n\n$ sudo alternatives --display hadoop-conf\nhadoop-conf - status is manual.\n link currently points to /etc/hadoop/conf.cluster\n/etc/hadoop/conf.empty - priority 10\n/etc/hadoop/conf.impala - priority 5\n/etc/hadoop/conf.cluster - priority 50\nCurrent `best' version is /etc/hadoop/conf.cluster.\n```\n\n* HDFS\u306e\u8a2d\u5b9a\u3092\u884c\u3044\u307e\u3059\u3002(\u30de\u30b9\u30bf\u30ce\u30fc\u30c9\u3001\u30b9\u30ec\u30fc\u30d6\u30ce\u30fc\u30c9\u304a\u3088\u3073\u30af\u30e9\u30a4\u30a2\u30f3\u30c8\u3059\u3079\u3066)\n\n```xml:/etc/hadoop/conf/core-site.xml\n<configuration>\n  <property>\n    <name>fs.defaultFS</name>\n    <value>hdfs://hadoop-master:8020</value>\n  </property>\n</configuration>\n```\n\n```xml:/etc/hadoop/conf/hdfs-site.xml\n<configuration>\n  <property>\n    <name>dfs.permissions.superusergroup</name>\n    <value>hadoop</value>\n  </property>\n  <property>\n    <name>dfs.namenode.name.dir</name>\n    <value>/var/lib/hadoop-hdfs/cache/dfs/name</value>\n  </property>\n  <property>\n    <name>dfs.datanode.name.dir</name>\n    <value>/var/lib/hadoop-hdfs/cache/dfs/data</value>\n  </property>\n</configuration>\n```\n\n```shell\n$ sudo mkdir -p /var/lib/hadoop-hdfs/cache/dfs/name\n$ sudo mkdir -p /var/lib/hadoop-hdfs/cache/dfs/data\n$ sudo chown hdfs:hadoop -R /var/lib/hadoop-hdfs/cache/dfs\n```\n\n* \u30cd\u30fc\u30e0\u30ce\u30fc\u30c9\u3092\u30d5\u30a9\u30fc\u30de\u30c3\u30c8\u3057\u307e\u3059\u3002(hadoop-master\u306e\u307f)\n\n```shell\n$ sudo -u hdfs hdfs namenode -format\n14/09/20 03:59:16 INFO namenode.NameNode: STARTUP_MSG:\n/************************************************************\nSTARTUP_MSG: Starting NameNode\nSTARTUP_MSG:   host = localhost.localdomain/192.168.122.101\nSTARTUP_MSG:   args = [-format]\nSTARTUP_MSG:   version = 2.3.0-cdh5.1.2\nSTARTUP_MSG:   classpath = /etc/hadoop/conf:...(\u7701\u7565)...\nSTARTUP_MSG:   build = git://github.sf.cloudera.com/CDH/cdh.git -r 8e266e052e423af592871e2dfe09d54c03f6a0e8; compiled by 'jenkins' on 2014-08-26T01:36Z\nSTARTUP_MSG:   java = 1.7.0_55\n************************************************************/\n14/09/20 03:59:17 INFO namenode.NameNode: registered UNIX signal handlers for [TERM, HUP, INT]\n14/09/20 03:59:17 INFO namenode.NameNode: createNameNode [-format]\nFormatting using clusterid: CID-51ba5115-4500-4b1d-b26c-b8fb9f41e03d\n14/09/20 03:59:18 INFO namenode.FSNamesystem: fsLock is fair:true\n14/09/20 03:59:18 INFO blockmanagement.DatanodeManager: dfs.block.invalidate.limit=1000\n14/09/20 03:59:18 INFO blockmanagement.DatanodeManager: dfs.namenode.datanode.registration.ip-hostname-check=true\n14/09/20 03:59:18 INFO blockmanagement.BlockManager: dfs.namenode.startup.delay.block.deletion.ms is set to 0 ms.\n14/09/20 03:59:18 INFO blockmanagement.BlockManager: The block deletion will start around 2014 Sep 20 03:59:18\n14/09/20 03:59:18 INFO util.GSet: Computing capacity for map BlocksMap\n14/09/20 03:59:18 INFO util.GSet: VM type       = 64-bit\n14/09/20 03:59:18 INFO util.GSet: 2.0% max memory 889 MB = 17.8 MB\n14/09/20 03:59:18 INFO util.GSet: capacity      = 2^21 = 2097152 entries\n14/09/20 03:59:18 INFO blockmanagement.BlockManager: dfs.block.access.token.enable=false\n14/09/20 03:59:18 INFO blockmanagement.BlockManager: defaultReplication         = 3\n14/09/20 03:59:18 INFO blockmanagement.BlockManager: maxReplication             = 512\n14/09/20 03:59:18 INFO blockmanagement.BlockManager: minReplication             = 1\n14/09/20 03:59:18 INFO blockmanagement.BlockManager: maxReplicationStreams      = 2\n14/09/20 03:59:18 INFO blockmanagement.BlockManager: shouldCheckForEnoughRacks  = false\n14/09/20 03:59:18 INFO blockmanagement.BlockManager: replicationRecheckInterval = 3000\n14/09/20 03:59:18 INFO blockmanagement.BlockManager: encryptDataTransfer        = false\n14/09/20 03:59:18 INFO blockmanagement.BlockManager: maxNumBlocksToLog          = 1000\n14/09/20 03:59:18 INFO namenode.FSNamesystem: fsOwner             = hdfs (auth:SIMPLE)\n14/09/20 03:59:18 INFO namenode.FSNamesystem: supergroup          = hadoop\n14/09/20 03:59:18 INFO namenode.FSNamesystem: isPermissionEnabled = true\n14/09/20 03:59:18 INFO namenode.FSNamesystem: HA Enabled: false\n14/09/20 03:59:18 INFO namenode.FSNamesystem: Append Enabled: true\n14/09/20 03:59:18 INFO util.GSet: Computing capacity for map INodeMap\n14/09/20 03:59:18 INFO util.GSet: VM type       = 64-bit\n14/09/20 03:59:18 INFO util.GSet: 1.0% max memory 889 MB = 8.9 MB\n14/09/20 03:59:18 INFO util.GSet: capacity      = 2^20 = 1048576 entries\n14/09/20 03:59:18 INFO namenode.NameNode: Caching file names occuring more than 10 times\n14/09/20 03:59:18 INFO util.GSet: Computing capacity for map cachedBlocks\n14/09/20 03:59:18 INFO util.GSet: VM type       = 64-bit\n14/09/20 03:59:18 INFO util.GSet: 0.25% max memory 889 MB = 2.2 MB\n14/09/20 03:59:18 INFO util.GSet: capacity      = 2^18 = 262144 entries\n14/09/20 03:59:18 INFO namenode.FSNamesystem: dfs.namenode.safemode.threshold-pct = 0.9990000128746033\n14/09/20 03:59:18 INFO namenode.FSNamesystem: dfs.namenode.safemode.min.datanodes = 0\n14/09/20 03:59:18 INFO namenode.FSNamesystem: dfs.namenode.safemode.extension     = 30000\n14/09/20 03:59:18 INFO namenode.FSNamesystem: Retry cache on namenode is enabled\n14/09/20 03:59:18 INFO namenode.FSNamesystem: Retry cache will use 0.03 of total heap and retry cache entry expiry time is 600000 millis\n14/09/20 03:59:18 INFO util.GSet: Computing capacity for map NameNodeRetryCache\n14/09/20 03:59:18 INFO util.GSet: VM type       = 64-bit\n14/09/20 03:59:18 INFO util.GSet: 0.029999999329447746% max memory 889 MB = 273.1 KB\n14/09/20 03:59:18 INFO util.GSet: capacity      = 2^15 = 32768 entries\n14/09/20 03:59:18 INFO namenode.AclConfigFlag: ACLs enabled? false\n14/09/20 03:59:18 INFO namenode.FSImage: Allocated new BlockPoolId: BP-1157687996-10.250.0.101-1411185558593\n14/09/20 03:59:18 INFO common.Storage: Storage directory /var/lib/hadoop-hdfs/cache/dfs/name has been successfully formatted.\n14/09/20 03:59:19 INFO namenode.NNStorageRetentionManager: Going to retain 1 images with txid >= 0\n14/09/20 03:59:19 INFO util.ExitUtil: Exiting with status 0\n14/09/20 03:59:19 INFO namenode.NameNode: SHUTDOWN_MSG:\n/************************************************************\nSHUTDOWN_MSG: Shutting down NameNode at localhost.localdomain/192.168.122.101\n************************************************************/\n```\n\n* HDFS\u306e\u8d77\u52d5\n\n\u30cd\u30fc\u30e0\u30ce\u30fc\u30c9\u3092\u8d77\u52d5\u3057\u307e\u3059\u3002(\u30de\u30b9\u30bf\u30ce\u30fc\u30c9)\n\n```shell\n$ sudo service hadoop-hdfs-namenode start\n```\n\n\u30c7\u30fc\u30bf\u30ce\u30fc\u30c9\u3092\u8d77\u52d5\u3057\u307e\u3059\u3002(\u30b9\u30ec\u30fc\u30d6\u30ce\u30fc\u30c9)\n\n```shell\n$ sudo service hadoop-hdfs-datanode start\n```\n\n* HDFS\u4e0a\u306btmp\u30c7\u30a3\u30ec\u30af\u30c8\u30ea\u3092\u4f5c\u6210\u3057\u307e\u3059\u3002(\u30af\u30e9\u30a4\u30a2\u30f3\u30c8\u30ce\u30fc\u30c9)\n\n```shell\n$ sudo -u hdfs hadoop fs -mkdir /tmp\n$ sudo -u hdfs hadoop fs -chmod -R 1777 /tmp\n$ sudo -u hdfs hadoop fs -ls /\nFound 1 items\ndrwxrwxrwt   - hdfs hadoop          0 2014-09-20 04:30 /tmp\n```\n\n### Map Reduce v2(YARN)\u306e\u8a2d\u5b9a\n\n* Map Reduce v2(YARN)\u306e\u8a2d\u5b9a\u3092\u884c\u3044\u307e\u3059\u3002(\u30de\u30b9\u30bf\u30ce\u30fc\u30c9\u3001\u30b9\u30ec\u30fc\u30d6\u30ce\u30fc\u30c9\u304a\u3088\u3073\u30af\u30e9\u30a4\u30a2\u30f3\u30c8\u3059\u3079\u3066)\n\n```xml:/etc/hadoop/conf/mapred-site.xml\n<configuration>\n  <property>\n    <name>yarn.nodemanager.local-dirs</name>\n    <value>file:///var/lib/hadoop-yarn/cache/local</value>\n  </property>\n  <property>\n    <name>yarn.nodemanager.log-dirs</name>\n    <value>file:///var/log/hadoop-yarn/containers</value>\n  </property>\n  <property>\n    <name>yarn.nodemanager.remote-app-log-dir</name>\n    <value>hdfs://hadoop-master:8020/var/log/hadoop-yarn/apps</value>\n  </property>\n  <property>\n    <name>mapreduce.jobhistory.address</name>\n    <value>hadoop-master:10020</value>\n  </property>\n  <property>\n    <name>mapreduce.jobhistory.webapp.address</name>\n    <value>hadoop-master:19888</value>\n  </property>\n  <property>\n    <name>hadoop.proxyuser.mapred.groups</name>\n    <value>*</value>\n  </property>\n  <property>\n    <name>hadoop.proxyuser.mapred.hosts</name>\n    <value>*</value>\n  </property>\n  <property>\n    <name>yarn.app.mapreduce.am.staging-dir</name>\n    <value>/user</value>\n  </property>\n</configuration>\n```\n\n```xml:/etc/hadoop/conf/yarn-site.xml\n<configuration>\n  <property>\n    <name>yarn.nodemanager.aux-services</name>\n    <value>mapreduce_shuffle</value>\n  </property>\n  <property>\n    <name>yarn.nodemanager.aux-services.mapreduce_shuffle.class</name>\n    <value>org.apache.hadoop.mapred.ShuffleHandler</value>\n  </property>\n  <property>\n    <name>yarn.resourcemanager.hostname</name>\n    <value>hadoop-master</value>\n  </property>\n  <property>\n    <name>yarn.log-aggregation-enable</name>\n    <value>true</value>\n  </property>\n  <property>\n    <description>List of directories to store localized files in.</description>\n    <name>yarn.nodemanager.local-dirs</name>\n    <value>file:///var/lib/hadoop-yarn/cache/local</value>\n  </property>\n  <property>\n    <description>Where to store container logs.</description>\n    <name>yarn.nodemanager.log-dirs</name>\n    <value>file:///var/log/hadoop-yarn/containers</value>\n  </property>\n  <property>\n    <description>Where to aggregate logs to.</description>\n    <name>yarn.nodemanager.remote-app-log-dir</name>\n    <value>hdfs:///hadoop-master:8020/var/log/hadoop-yarn/apps</value>\n  </property>\n\n  <property>\n    <description>Classpath for typical applications.</description>\n     <name>yarn.application.classpath</name>\n     <value>\n        $HADOOP_CONF_DIR,\n        $HADOOP_COMMON_HOME/*,$HADOOP_COMMON_HOME/lib/*,\n        $HADOOP_HDFS_HOME/*,$HADOOP_HDFS_HOME/lib/*,\n        $HADOOP_MAPRED_HOME/*,$HADOOP_MAPRED_HOME/lib/*,\n        $HADOOP_YARN_HOME/*,$HADOOP_YARN_HOME/lib/*\n     </value>\n  </property>\n</configuration>\n```\n* \u5fc5\u8981\u306a\u30c7\u30a3\u30ec\u30af\u30c8\u3092\u4f5c\u6210\u3057\u307e\u3059\u3002(\u30de\u30b9\u30bf\u30ce\u30fc\u30c9\u3001\u30b9\u30ec\u30fc\u30d6\u30ce\u30fc\u30c9\u304a\u3088\u3073\u30af\u30e9\u30a4\u30a2\u30f3\u30c8)\n\n```shell\n$ sudo mkdir -p /var/lib/hadoop-yarn/cache/local\n$ sudo chown yarn:hadoop /var/lib/hadoop-yarn/cache/local\n$ sudo mkdir -p /var/log/hadoop-yarn/containers\n$ sudo chown yarn:hadoop /var/log/hadoop-yarn/containers\n```\n\n* \u5fc5\u8981\u306a\u30c7\u30a3\u30ec\u30af\u30c8\u30ea\u3092HDFS\u4e0a\u306b\u4f5c\u6210\u3057\u307e\u3059\u3002(\u30af\u30e9\u30a4\u30a2\u30f3\u30c8\u3067\u5b9f\u884c)\n\n```shell\n$ sudo -u hdfs hadoop fs -mkdir -p /user/history\n$ sudo -u hdfs hadoop fs -chmod -R 1777 /user/history\n$ sudo -u hdfs hadoop fs -chown mapred:hadoop /user/history\n$ sudo -u hdfs hadoop fs -mkdir -p /var/log/hadoop-yarn\n$ sudo -u hdfs hadoop fs -chown yarn:mapred /var/log/hadoop-yarn\n$ sudo -u hdfs hadoop fs -ls -R /\ndrwxrwxrwt   - hdfs hadoop          0 2014-09-20 04:30 /tmp\ndrwxr-xr-x   - hdfs hadoop          0 2014-09-20 05:08 /user\ndrwxrwxrwt   - mapred hadoop          0 2014-09-20 05:08 /user/history\ndrwxr-xr-x   - hdfs   hadoop          0 2014-09-20 05:08 /var\ndrwxr-xr-x   - hdfs   hadoop          0 2014-09-20 05:08 /var/log\ndrwxr-xr-x   - yarn   mapred          0 2014-09-20 05:08 /var/log/hadoop-yarn\n```\n\n* \u30ea\u30bd\u30fc\u30b9\u30de\u30cd\u30fc\u30b8\u30e3\u3092\u8d77\u52d5\u3057\u307e\u3059\u3002(\u30de\u30b9\u30bf\u30ce\u30fc\u30c9)\n\n```shell\n$ sudo service hadoop-yarn-resourcemanager start\n```\n\n* \u30ce\u30fc\u30c9\u30de\u30cd\u30fc\u30b8\u30e3\u3092\u8d77\u52d5\u3057\u307e\u3059\u3002(\u30b9\u30ec\u30fc\u30d6\u30ce\u30fc\u30c9)\n\n```shell\n$ sudo service hadoop-yarn-nodemanager start\n```\n\n* \u30d2\u30b9\u30c8\u30ea\u30b5\u30fc\u30d0\u3092\u8d77\u52d5\u3057\u307e\u3059\u3002(hadoop-master\u306e\u307f)\n\n```shell\n$ sudo service hadoop-mapreduce-historyserver start\n```\n\n## \u52d5\u4f5c\u78ba\u8a8d\n\n* \u30b5\u30f3\u30d7\u30eb\u30d7\u30ed\u30b0\u30e9\u30e0\u3092\u5b9f\u884c\u3057\u307e\u3059\u3002(\u30af\u30e9\u30a4\u30a2\u30f3\u30c8\u3067\u5b9f\u884c)\n\n```shell\n$ sudo -u hdfs hadoop jar /usr/lib/hadoop-mapreduce/hadoop-mapreduce-examples-2.3.0-cdh5.1.2.jar pi 1 300\nNumber of Maps  = 1\nSamples per Map = 300\nWrote input for Map #0\nStarting Job\n14/09/20 06:33:37 INFO Configuration.deprecation: session.id is deprecated. Instead, use dfs.metrics.session-id\n14/09/20 06:33:37 INFO jvm.JvmMetrics: Initializing JVM Metrics with processName=JobTracker, sessionId=\n14/09/20 06:33:37 INFO input.FileInputFormat: Total input paths to process : 1\n14/09/20 06:33:37 INFO mapreduce.JobSubmitter: number of splits:1\n14/09/20 06:33:37 INFO mapreduce.JobSubmitter: Submitting tokens for job: job_local936971230_0001\n14/09/20 06:33:37 WARN conf.Configuration: file:/tmp/hadoop-hdfs/mapred/staging/hdfs936971230/.staging/job_local936971230_0001/job.xml:an attempt to override final parameter: mapreduce.job.end-notification.max.retry.interval;  Ignoring.\n14/09/20 06:33:37 WARN conf.Configuration: file:/tmp/hadoop-hdfs/mapred/staging/hdfs936971230/.staging/job_local936971230_0001/job.xml:an attempt to override final parameter: mapreduce.job.end-notification.max.attempts;  Ignoring.\n14/09/20 06:33:38 WARN conf.Configuration: file:/tmp/hadoop-hdfs/mapred/local/localRunner/hdfs/job_local936971230_0001/job_local936971230_0001.xml:an attempt to override final parameter: mapreduce.job.end-notification.max.retry.interval;  Ignoring.\n14/09/20 06:33:38 WARN conf.Configuration: file:/tmp/hadoop-hdfs/mapred/local/localRunner/hdfs/job_local936971230_0001/job_local936971230_0001.xml:an attempt to override final parameter: mapreduce.job.end-notification.max.attempts;  Ignoring.\n14/09/20 06:33:38 INFO mapreduce.Job: The url to track the job: http://localhost:8080/\n14/09/20 06:33:38 INFO mapreduce.Job: Running job: job_local936971230_0001\n14/09/20 06:33:38 INFO mapred.LocalJobRunner: OutputCommitter set in config null\n14/09/20 06:33:38 INFO mapred.LocalJobRunner: OutputCommitter is org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter\n14/09/20 06:33:38 INFO mapred.LocalJobRunner: Waiting for map tasks\n14/09/20 06:33:38 INFO mapred.LocalJobRunner: Starting task: attempt_local936971230_0001_m_000000_0\n14/09/20 06:33:38 INFO mapred.Task:  Using ResourceCalculatorProcessTree : [ ]\n14/09/20 06:33:38 INFO mapred.MapTask: Processing split: hdfs://hadoop-master:8020/user/hdfs/QuasiMonteCarlo_1411194815372_1775447123/in/part0:0+118\n14/09/20 06:33:38 INFO mapred.MapTask: Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer\n14/09/20 06:33:38 INFO mapred.MapTask: (EQUATOR) 0 kvi 26214396(104857584)\n14/09/20 06:33:38 INFO mapred.MapTask: mapreduce.task.io.sort.mb: 100\n14/09/20 06:33:38 INFO mapred.MapTask: soft limit at 83886080\n14/09/20 06:33:38 INFO mapred.MapTask: bufstart = 0; bufvoid = 104857600\n14/09/20 06:33:38 INFO mapred.MapTask: kvstart = 26214396; length = 6553600\n14/09/20 06:33:38 INFO mapred.LocalJobRunner:\n14/09/20 06:33:38 INFO mapred.MapTask: Starting flush of map output\n14/09/20 06:33:38 INFO mapred.MapTask: Spilling map output\n14/09/20 06:33:38 INFO mapred.MapTask: bufstart = 0; bufend = 18; bufvoid = 104857600\n14/09/20 06:33:38 INFO mapred.MapTask: kvstart = 26214396(104857584); kvend = 26214392(104857568); length = 5/6553600\n14/09/20 06:33:38 INFO mapred.MapTask: Finished spill 0\n14/09/20 06:33:38 INFO mapred.Task: Task:attempt_local936971230_0001_m_000000_0 is done. And is in the process of committing\n14/09/20 06:33:38 INFO mapred.LocalJobRunner: map\n14/09/20 06:33:38 INFO mapred.Task: Task 'attempt_local936971230_0001_m_000000_0' done.\n14/09/20 06:33:38 INFO mapred.LocalJobRunner: Finishing task: attempt_local936971230_0001_m_000000_0\n14/09/20 06:33:38 INFO mapred.LocalJobRunner: map task executor complete.\n14/09/20 06:33:38 INFO mapred.LocalJobRunner: Waiting for reduce tasks\n14/09/20 06:33:38 INFO mapred.LocalJobRunner: Starting task: attempt_local936971230_0001_r_000000_0\n14/09/20 06:33:38 INFO mapred.Task:  Using ResourceCalculatorProcessTree : [ ]\n14/09/20 06:33:38 INFO mapred.ReduceTask: Using ShuffleConsumerPlugin: org.apache.hadoop.mapreduce.task.reduce.Shuffle@73616964\n14/09/20 06:33:38 INFO reduce.MergeManagerImpl: MergerManager: memoryLimit=652528832, maxSingleShuffleLimit=163132208, mergeThreshold=430669056, ioSortFactor=10, memToMemMergeOutputsThreshold=10\n14/09/20 06:33:38 INFO reduce.EventFetcher: attempt_local936971230_0001_r_000000_0 Thread started: EventFetcher for fetching Map Completion Events\n14/09/20 06:33:38 INFO reduce.LocalFetcher: localfetcher#1 about to shuffle output of map attempt_local936971230_0001_m_000000_0 decomp: 24 len: 28 to MEMORY\n14/09/20 06:33:38 INFO reduce.InMemoryMapOutput: Read 24 bytes from map-output for attempt_local936971230_0001_m_000000_0\n14/09/20 06:33:38 INFO reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 24, inMemoryMapOutputs.size() -> 1, commitMemory -> 0, usedMemory ->24\n14/09/20 06:33:38 INFO reduce.EventFetcher: EventFetcher is interrupted.. Returning\n14/09/20 06:33:38 INFO mapred.LocalJobRunner: 1 / 1 copied.\n14/09/20 06:33:38 INFO reduce.MergeManagerImpl: finalMerge called with 1 in-memory map-outputs and 0 on-disk map-outputs\n14/09/20 06:33:38 INFO mapred.Merger: Merging 1 sorted segments\n14/09/20 06:33:38 INFO mapred.Merger: Down to the last merge-pass, with 1 segments left of total size: 21 bytes\n14/09/20 06:33:38 INFO reduce.MergeManagerImpl: Merged 1 segments, 24 bytes to disk to satisfy reduce memory limit\n14/09/20 06:33:38 INFO reduce.MergeManagerImpl: Merging 1 files, 28 bytes from disk\n14/09/20 06:33:38 INFO reduce.MergeManagerImpl: Merging 0 segments, 0 bytes from memory into reduce\n14/09/20 06:33:38 INFO mapred.Merger: Merging 1 sorted segments\n14/09/20 06:33:38 INFO mapred.Merger: Down to the last merge-pass, with 1 segments left of total size: 21 bytes\n14/09/20 06:33:38 INFO mapred.LocalJobRunner: 1 / 1 copied.\n14/09/20 06:33:38 INFO Configuration.deprecation: mapred.skip.on is deprecated. Instead, use mapreduce.job.skiprecords\n14/09/20 06:33:38 INFO mapred.Task: Task:attempt_local936971230_0001_r_000000_0 is done. And is in the process of committing\n14/09/20 06:33:38 INFO mapred.LocalJobRunner: 1 / 1 copied.\n14/09/20 06:33:38 INFO mapred.Task: Task attempt_local936971230_0001_r_000000_0 is allowed to commit now\n14/09/20 06:33:38 INFO output.FileOutputCommitter: Saved output of task 'attempt_local936971230_0001_r_000000_0' to hdfs://hadoop-master:8020/user/hdfs/QuasiMonteCarlo_1411194815372_1775447123/out/_temporary/0/task_local936971230_0001_r_000000\n14/09/20 06:33:38 INFO mapred.LocalJobRunner: reduce > reduce\n14/09/20 06:33:38 INFO mapred.Task: Task 'attempt_local936971230_0001_r_000000_0' done.\n14/09/20 06:33:38 INFO mapred.LocalJobRunner: Finishing task: attempt_local936971230_0001_r_000000_0\n14/09/20 06:33:38 INFO mapred.LocalJobRunner: reduce task executor complete.\n14/09/20 06:33:39 INFO mapreduce.Job: Job job_local936971230_0001 running in uber mode : false\n14/09/20 06:33:39 INFO mapreduce.Job:  map 100% reduce 100%\n14/09/20 06:33:39 INFO mapreduce.Job: Job job_local936971230_0001 completed successfully\n14/09/20 06:33:39 INFO mapreduce.Job: Counters: 38\n        File System Counters\n                FILE: Number of bytes read=552150\n                FILE: Number of bytes written=988114\n                FILE: Number of read operations=0\n                FILE: Number of large read operations=0\n                FILE: Number of write operations=0\n                HDFS: Number of bytes read=236\n                HDFS: Number of bytes written=451\n                HDFS: Number of read operations=19\n                HDFS: Number of large read operations=0\n                HDFS: Number of write operations=9\n        Map-Reduce Framework\n                Map input records=1\n                Map output records=2\n                Map output bytes=18\n                Map output materialized bytes=28\n                Input split bytes=150\n                Combine input records=0\n                Combine output records=0\n                Reduce input groups=2\n                Reduce shuffle bytes=28\n                Reduce input records=2\n                Reduce output records=0\n                Spilled Records=4\n                Shuffled Maps =1\n                Failed Shuffles=0\n                Merged Map outputs=1\n                GC time elapsed (ms)=0\n                CPU time spent (ms)=0\n                Physical memory (bytes) snapshot=0\n                Virtual memory (bytes) snapshot=0\n                Total committed heap usage (bytes)=634388480\n        Shuffle Errors\n                BAD_ID=0\n                CONNECTION=0\n                IO_ERROR=0\n                WRONG_LENGTH=0\n                WRONG_MAP=0\n                WRONG_REDUCE=0\n        File Input Format Counters\n                Bytes Read=118\n        File Output Format Counters\n                Bytes Written=97\nJob Finished in 2.024 seconds\nEstimated value of Pi is 3.16000000000000000000\n```\n\n## \u53c2\u8003\n\n* [CDH 5 Installation Guide](http://www.cloudera.com/content/cloudera-content/cloudera-docs/CDH5/latest/CDH5-Installation-Guide/CDH5-Installation-Guide.html)\n* [Supported JDK Versions](http://www.cloudera.com/content/cloudera-content/cloudera-docs/CDH5/latest/CDH5-Requirements-and-Supported-Versions/cdhrsv_jdk.html)\n* [Installing CDH 5](http://www.cloudera.com/content/cloudera-content/cloudera-docs/CDH5/latest/CDH5-Installation-Guide/cdh5ig_cdh5_install.html)\n* [Deploying HDFS on a Cluster](http://www.cloudera.com/content/cloudera-content/cloudera-docs/CDH5/latest/CDH5-Installation-Guide/cdh5ig_hdfs_cluster_deploy.html)\n* [Deploying MapReduce v2 (YARN) on a Cluster](http://www.cloudera.com/content/cloudera-content/cloudera-docs/CDH5/latest/CDH5-Installation-Guide/cdh5ig_yarn_cluster_deploy.html)\n", "tags": ["hadoop", "CentOS6", "CDH5", "Java"]}