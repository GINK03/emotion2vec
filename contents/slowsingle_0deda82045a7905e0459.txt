{"tags": ["DeepLearning", "Keras", "\u6a5f\u68b0\u5b66\u7fd2"], "context": "\u6df1\u5c64\u5b66\u7fd2\u306e\u8868\u73fe\u529b\u306e\u9ad8\u3055\u306b\u306f\u3044\u3064\u3082\u9a5a\u304b\u3055\u308c\u307e\u3059\u3002\n\u753b\u50cf\u8a8d\u8b58\u7cfb\u306e\u30bf\u30b9\u30af\u3067\u3042\u308c\u3070\u5272\u3068\u4f55\u3067\u3082\u8b58\u5225\u3067\u304d\u308b\u30a4\u30e1\u30fc\u30b8\u3067\u3059\u3002\n\u4eca\u56de\u306fMNIST\u306e\u30c7\u30fc\u30bf\u30bb\u30c3\u30c8\u3092\u7528\u3044\u3066\u3001\u30e9\u30d9\u30eb\u3092\u30e9\u30f3\u30c0\u30e0\u306b\u632f\u308a\u5206\u3051\u306a\u304a\u3057\u3066\u304b\u3089\u5b66\u7fd2\u3055\u305b\u305f\u5834\u5408\u306b\u3001\u8a13\u7df4\u8aa4\u5dee\u304c\u6e1b\u5c11\u3059\u308b\u306e\u304b\u3092\u78ba\u304b\u3081\u3066\u307f\u307e\u3057\u305f\u3002\n\u3059\u306a\u308f\u3061\u4e38\u6697\u8a18\u304c\u3067\u304d\u308b\u304b\u3069\u3046\u304b\u306e\u8abf\u67fb\u3067\u3059\u3002\n\n\u30c6\u30b9\u30c8\u30d7\u30ed\u30b0\u30e9\u30e0\n\u4ee5\u4e0b\u306e\u30d7\u30ed\u30b0\u30e9\u30e0\u3092\u7528\u3044\u3066\u5b9f\u9a13\u3092\u3057\u307e\u3057\u305f\u3002\n\u30e9\u30d9\u30eb\u3092\u30e9\u30f3\u30c0\u30e0\u306b\u632f\u308a\u5206\u3051\u305f\u3042\u3068\u306b\u3001\u30c7\u30fc\u30bf\u306e\u6570\u30923000\u306b\u6e1b\u3089\u3057\u307e\u3059\u3002\ntensorflow\u3092\u30d0\u30c3\u30af\u30a8\u30f3\u30c9\u3068\u3057\u305fkeras\u3092\u7528\u3044\u3066\u3044\u307e\u3059\u3002\n\u30c7\u30fc\u30bf\u306e\u4e0e\u3048\u65b9\u306f(\u30c7\u30fc\u30bf\u6570\u3001\u30c1\u30e3\u30f3\u30cd\u30eb\u6570\u3001\u753b\u50cf\u306e\u9ad8\u3055\u3001\u753b\u50cf\u306e\u5e45)\u3067\u3059\u3002\n\nmnist_conv.py\n# -*- coding: utf-8 -*-\nfrom __future__ import print_function\n\nfrom keras.datasets import mnist\nfrom keras.models import Sequential\nfrom keras.layers.core import Dense, Dropout, Activation, Flatten\nfrom keras.layers.convolutional import Convolution2D, MaxPooling2D\nfrom keras.optimizers import Adam\nfrom keras.utils import np_utils\nfrom keras.callbacks import EarlyStopping\n\nimport sys\nimport numpy as np\n\nimport matplotlib.pyplot as plt\n\nbatch_size = 32\nnb_classes = 10\nnb_epoch = 1000\n\ndef main():\n    # load MNIST data\n    (X_train, y_train), (X_test, y_test) = mnist.load_data()\n\n    img_channels = 1\n    _, img_cols, img_rows = X_train.shape\n\n    X_train = X_train.reshape(60000, 1, 28, 28).astype('float32')[:3000]\n    X_test = X_test.reshape(10000, 1, 28, 28).astype('float32')\n    X_train /= 255.0\n    X_test /= 255.0\n    X_train -= 0.5\n    X_test -= 0.5\n\n    # \u5b66\u7fd2\u30c7\u30fc\u30bf\u306e\u30e9\u30d9\u30eb\u3092\u30e9\u30f3\u30c0\u30e0\u306b\u632f\u308a\u5206\u3051\u308b\n    y_train = y_train[np.random.permutation(y_train.shape[0])][:3000]\n\n    # convert class vectors to 1-of-K format\n    y_train = np_utils.to_categorical(y_train, nb_classes)\n    y_test = np_utils.to_categorical(y_test, nb_classes)\n\n    print('train samples: ', X_train.shape)\n    print('test samples: ', X_test.shape)\n\n    # building the model\n    print('building the model ...')\n\n    # build model\n    model = Sequential()\n\n    model.add(Convolution2D(32, 3, 3, border_mode='same',\n                            input_shape=(img_channels, img_rows, img_cols)))\n    model.add(Activation('relu'))\n\n    model.add(Convolution2D(32, 3, 3))\n    model.add(Activation('relu'))\n    model.add(MaxPooling2D(pool_size=(2, 2)))\n\n    model.add(Convolution2D(64, 3, 3, border_mode='same'))\n    model.add(Activation('relu'))\n\n    model.add(Convolution2D(64, 3, 3))\n    model.add(Activation('relu'))\n    model.add(MaxPooling2D(pool_size=(2, 2)))\n\n    model.add(Flatten())\n    model.add(Dense(512))\n    model.add(Activation('relu'))\n    model.add(Dense(nb_classes))\n    model.add(Activation('softmax'))\n\n    opt = Adam()\n    model.compile(loss='categorical_crossentropy',\n                  optimizer=opt,\n                  metrics=['accuracy'])\n\n    # training\n    hist = model.fit(X_train, y_train,\n                     batch_size=batch_size,\n                     verbose=1,\n                     nb_epoch=nb_epoch,\n                     validation_split=0.1)\n\n    # evaluate\n    score = model.evaluate(X_test, y_test, verbose=1)\n    print('Test loss:', score[0])\n    print('Test accuracy:', score[1])\n\n    # plot loss\n    loss = hist.history['loss']\n    val_loss = hist.history['val_loss']\n\n    nb_epoch = len(loss)\n    plt.plot(range(nb_epoch), loss, marker='.', label='loss')\n    plt.plot(range(nb_epoch), val_loss, marker='.', label='val_loss')\n    plt.legend(loc='best', fontsize=10)\n    plt.grid()\n    plt.xlabel('epoch')\n    plt.ylabel('loss')\n    plt.show()\n\n\nif __name__ == '__main__':\n    main()\n\n\n\n\u7d50\u679c\n\u4e38\u6697\u8a18\u5927\u6210\u529f\u3067\u3059\u3002\n\n\u9752\u3044\u7dda\u304c\u8a13\u7df4\u8aa4\u5dee\u3067\u3001\u7dd1\u306e\u7dda\u304c\u30d0\u30ea\u30c7\u30fc\u30b7\u30e7\u30f3\u8aa4\u5dee\uff08\u8a13\u7df4\u6642\u306b\u4f7f\u3063\u3066\u3044\u306a\u3044\u753b\u50cf\u306b\u3088\u308b\u63a8\u5b9a\u8aa4\u5dee\uff09\u306b\u306a\u308a\u307e\u3059\u3002\n\u8a13\u7df4\u8aa4\u5dee\u304c0\u306b\u53ce\u675f\u3057\u3001\u30d0\u30ea\u30c7\u30fc\u30b7\u30e7\u30f3\u8aa4\u5dee\u304c\u5897\u52a0\u3059\u308b\u3001\u706b\u3092\u898b\u308b\u3088\u308a\u660e\u3089\u304b\u306a\u7f8e\u3057\u3044\u904e\u5b66\u7fd2\u306e\u69d8\u76f8\u3092\u5448\u3057\u3066\u304a\u308a\u307e\u3059\u3002\n\u8a13\u7df4\u30c7\u30fc\u30bf\u306b\u5bfe\u3059\u308b\u6b63\u7b54\u7387\u306f99.7%\u3067\u3001\u30c6\u30b9\u30c8\u30c7\u30fc\u30bf\u306b\u5bfe\u3059\u308b\u6b63\u7b54\u7387\u306f8.67%\u3067\u3057\u305f\u3002\n\u30e9\u30f3\u30c0\u30e0\u306b\u7b54\u3048\u305f\u5834\u5408\u306e\u6b63\u7b54\u7387\u306e\u5e73\u5747\u306f10%\u306b\u306a\u308a\u307e\u3059\u304b\u3089\u3001\u30e9\u30f3\u30c0\u30e0\u3088\u308a\u3082\u96d1\u9b5a\u3044\u63a8\u5b9a\u5668\u306e\u5b8c\u6210\u3067\u3059\u3002\u5b9f\u7528\u6027\u7686\u7121\u3067\u3059\u3002\n\u3061\u306a\u307f\u306b\u3001\u8a13\u7df4\u30c7\u30fc\u30bf\u306e\u6570\u3092\u5897\u3084\u3059\u3068\u4e38\u6697\u8a18\u304c\u3067\u304d\u306a\u304f\u306a\u3063\u3066\u3044\u304d\u307e\u3059\u3002\n\u6df1\u5c64\u5b66\u7fd2\u306e\u7814\u7a76\u958b\u767a\u306f\u65e5\u9032\u6708\u6b69\u306a\u3089\u306c\u79d2\u9032\u65e5\u6b69\u3068\u3044\u3046\u611f\u3058\u3067\u3059\u3057\u3001\u8272\u3005\u306a\u30c6\u30af\u30cb\u30c3\u30af\u3092\u6d3b\u7528\u3059\u308c\u3070\u4f55\u3067\u3082\u304b\u3093\u3067\u3082\u4e38\u6697\u8a18\u304c\u3067\u304d\u305d\u3046\u306a\u611f\u3058\u304c\u3057\u307e\u3059\u3002\u305d\u308c\u304c\u5f79\u306b\u7acb\u3064\u306e\u304b\u3001\u305d\u308c\u3068\u3082\u3042\u307e\u308a\u826f\u3044\u6027\u8cea\u3067\u306f\u306a\u3044\u306e\u304b\u3001\u306f\u50d5\u81ea\u8eab\u307e\u3060\u308f\u304b\u3089\u306a\u3044\u306e\u3067\u3059\u304c\u3001CNN\u306e\u8868\u73fe\u529b\u306e\u9ad8\u3055\u3092\u6539\u3081\u3066\u601d\u3044\u77e5\u308b\u3053\u3068\u304c\u3067\u304d\u307e\u3057\u305f\u3002\n\u6df1\u5c64\u5b66\u7fd2\u306e\u8868\u73fe\u529b\u306e\u9ad8\u3055\u306b\u306f\u3044\u3064\u3082\u9a5a\u304b\u3055\u308c\u307e\u3059\u3002\n\u753b\u50cf\u8a8d\u8b58\u7cfb\u306e\u30bf\u30b9\u30af\u3067\u3042\u308c\u3070\u5272\u3068\u4f55\u3067\u3082\u8b58\u5225\u3067\u304d\u308b\u30a4\u30e1\u30fc\u30b8\u3067\u3059\u3002\n\n\u4eca\u56de\u306fMNIST\u306e\u30c7\u30fc\u30bf\u30bb\u30c3\u30c8\u3092\u7528\u3044\u3066\u3001\u30e9\u30d9\u30eb\u3092\u30e9\u30f3\u30c0\u30e0\u306b\u632f\u308a\u5206\u3051\u306a\u304a\u3057\u3066\u304b\u3089\u5b66\u7fd2\u3055\u305b\u305f\u5834\u5408\u306b\u3001\u8a13\u7df4\u8aa4\u5dee\u304c\u6e1b\u5c11\u3059\u308b\u306e\u304b\u3092\u78ba\u304b\u3081\u3066\u307f\u307e\u3057\u305f\u3002\n\u3059\u306a\u308f\u3061\u4e38\u6697\u8a18\u304c\u3067\u304d\u308b\u304b\u3069\u3046\u304b\u306e\u8abf\u67fb\u3067\u3059\u3002\n\n# \u30c6\u30b9\u30c8\u30d7\u30ed\u30b0\u30e9\u30e0\n\n\u4ee5\u4e0b\u306e\u30d7\u30ed\u30b0\u30e9\u30e0\u3092\u7528\u3044\u3066\u5b9f\u9a13\u3092\u3057\u307e\u3057\u305f\u3002\n\u30e9\u30d9\u30eb\u3092\u30e9\u30f3\u30c0\u30e0\u306b\u632f\u308a\u5206\u3051\u305f\u3042\u3068\u306b\u3001\u30c7\u30fc\u30bf\u306e\u6570\u30923000\u306b\u6e1b\u3089\u3057\u307e\u3059\u3002\n\ntensorflow\u3092\u30d0\u30c3\u30af\u30a8\u30f3\u30c9\u3068\u3057\u305fkeras\u3092\u7528\u3044\u3066\u3044\u307e\u3059\u3002\n\u30c7\u30fc\u30bf\u306e\u4e0e\u3048\u65b9\u306f(\u30c7\u30fc\u30bf\u6570\u3001\u30c1\u30e3\u30f3\u30cd\u30eb\u6570\u3001\u753b\u50cf\u306e\u9ad8\u3055\u3001\u753b\u50cf\u306e\u5e45)\u3067\u3059\u3002\n\n```python:mnist_conv.py\n# -*- coding: utf-8 -*-\nfrom __future__ import print_function\n\nfrom keras.datasets import mnist\nfrom keras.models import Sequential\nfrom keras.layers.core import Dense, Dropout, Activation, Flatten\nfrom keras.layers.convolutional import Convolution2D, MaxPooling2D\nfrom keras.optimizers import Adam\nfrom keras.utils import np_utils\nfrom keras.callbacks import EarlyStopping\n\nimport sys\nimport numpy as np\n\nimport matplotlib.pyplot as plt\n\nbatch_size = 32\nnb_classes = 10\nnb_epoch = 1000\n\ndef main():\n    # load MNIST data\n    (X_train, y_train), (X_test, y_test) = mnist.load_data()\n\n    img_channels = 1\n    _, img_cols, img_rows = X_train.shape\n\n    X_train = X_train.reshape(60000, 1, 28, 28).astype('float32')[:3000]\n    X_test = X_test.reshape(10000, 1, 28, 28).astype('float32')\n    X_train /= 255.0\n    X_test /= 255.0\n    X_train -= 0.5\n    X_test -= 0.5\n\n    # \u5b66\u7fd2\u30c7\u30fc\u30bf\u306e\u30e9\u30d9\u30eb\u3092\u30e9\u30f3\u30c0\u30e0\u306b\u632f\u308a\u5206\u3051\u308b\n    y_train = y_train[np.random.permutation(y_train.shape[0])][:3000]\n\n    # convert class vectors to 1-of-K format\n    y_train = np_utils.to_categorical(y_train, nb_classes)\n    y_test = np_utils.to_categorical(y_test, nb_classes)\n\n    print('train samples: ', X_train.shape)\n    print('test samples: ', X_test.shape)\n\n    # building the model\n    print('building the model ...')\n\n    # build model\n    model = Sequential()\n\n    model.add(Convolution2D(32, 3, 3, border_mode='same',\n                            input_shape=(img_channels, img_rows, img_cols)))\n    model.add(Activation('relu'))\n\n    model.add(Convolution2D(32, 3, 3))\n    model.add(Activation('relu'))\n    model.add(MaxPooling2D(pool_size=(2, 2)))\n\n    model.add(Convolution2D(64, 3, 3, border_mode='same'))\n    model.add(Activation('relu'))\n\n    model.add(Convolution2D(64, 3, 3))\n    model.add(Activation('relu'))\n    model.add(MaxPooling2D(pool_size=(2, 2)))\n\n    model.add(Flatten())\n    model.add(Dense(512))\n    model.add(Activation('relu'))\n    model.add(Dense(nb_classes))\n    model.add(Activation('softmax'))\n\n    opt = Adam()\n    model.compile(loss='categorical_crossentropy',\n                  optimizer=opt,\n                  metrics=['accuracy'])\n\n    # training\n    hist = model.fit(X_train, y_train,\n                     batch_size=batch_size,\n                     verbose=1,\n                     nb_epoch=nb_epoch,\n                     validation_split=0.1)\n\n    # evaluate\n    score = model.evaluate(X_test, y_test, verbose=1)\n    print('Test loss:', score[0])\n    print('Test accuracy:', score[1])\n\n    # plot loss\n    loss = hist.history['loss']\n    val_loss = hist.history['val_loss']\n\n    nb_epoch = len(loss)\n    plt.plot(range(nb_epoch), loss, marker='.', label='loss')\n    plt.plot(range(nb_epoch), val_loss, marker='.', label='val_loss')\n    plt.legend(loc='best', fontsize=10)\n    plt.grid()\n    plt.xlabel('epoch')\n    plt.ylabel('loss')\n    plt.show()\n\n\nif __name__ == '__main__':\n    main()\n```\n\n# \u7d50\u679c\n\n\u4e38\u6697\u8a18\u5927\u6210\u529f\u3067\u3059\u3002\n\n![loss_valLoss.png](https://qiita-image-store.s3.amazonaws.com/0/72509/f40ed946-43e3-abe7-a12b-d9f68ebc515e.png)\n\n\u9752\u3044\u7dda\u304c\u8a13\u7df4\u8aa4\u5dee\u3067\u3001\u7dd1\u306e\u7dda\u304c\u30d0\u30ea\u30c7\u30fc\u30b7\u30e7\u30f3\u8aa4\u5dee\uff08\u8a13\u7df4\u6642\u306b\u4f7f\u3063\u3066\u3044\u306a\u3044\u753b\u50cf\u306b\u3088\u308b\u63a8\u5b9a\u8aa4\u5dee\uff09\u306b\u306a\u308a\u307e\u3059\u3002\n\u8a13\u7df4\u8aa4\u5dee\u304c0\u306b\u53ce\u675f\u3057\u3001\u30d0\u30ea\u30c7\u30fc\u30b7\u30e7\u30f3\u8aa4\u5dee\u304c\u5897\u52a0\u3059\u308b\u3001\u706b\u3092\u898b\u308b\u3088\u308a\u660e\u3089\u304b\u306a\u7f8e\u3057\u3044\u904e\u5b66\u7fd2\u306e\u69d8\u76f8\u3092\u5448\u3057\u3066\u304a\u308a\u307e\u3059\u3002\n\n\u8a13\u7df4\u30c7\u30fc\u30bf\u306b\u5bfe\u3059\u308b\u6b63\u7b54\u7387\u306f99.7%\u3067\u3001\u30c6\u30b9\u30c8\u30c7\u30fc\u30bf\u306b\u5bfe\u3059\u308b\u6b63\u7b54\u7387\u306f8.67%\u3067\u3057\u305f\u3002\n\u30e9\u30f3\u30c0\u30e0\u306b\u7b54\u3048\u305f\u5834\u5408\u306e\u6b63\u7b54\u7387\u306e\u5e73\u5747\u306f10%\u306b\u306a\u308a\u307e\u3059\u304b\u3089\u3001\u30e9\u30f3\u30c0\u30e0\u3088\u308a\u3082\u96d1\u9b5a\u3044\u63a8\u5b9a\u5668\u306e\u5b8c\u6210\u3067\u3059\u3002\u5b9f\u7528\u6027\u7686\u7121\u3067\u3059\u3002\n\n\u3061\u306a\u307f\u306b\u3001\u8a13\u7df4\u30c7\u30fc\u30bf\u306e\u6570\u3092\u5897\u3084\u3059\u3068\u4e38\u6697\u8a18\u304c\u3067\u304d\u306a\u304f\u306a\u3063\u3066\u3044\u304d\u307e\u3059\u3002\n\n\u6df1\u5c64\u5b66\u7fd2\u306e\u7814\u7a76\u958b\u767a\u306f\u65e5\u9032\u6708\u6b69\u306a\u3089\u306c\u79d2\u9032\u65e5\u6b69\u3068\u3044\u3046\u611f\u3058\u3067\u3059\u3057\u3001\u8272\u3005\u306a\u30c6\u30af\u30cb\u30c3\u30af\u3092\u6d3b\u7528\u3059\u308c\u3070\u4f55\u3067\u3082\u304b\u3093\u3067\u3082\u4e38\u6697\u8a18\u304c\u3067\u304d\u305d\u3046\u306a\u611f\u3058\u304c\u3057\u307e\u3059\u3002\u305d\u308c\u304c\u5f79\u306b\u7acb\u3064\u306e\u304b\u3001\u305d\u308c\u3068\u3082\u3042\u307e\u308a\u826f\u3044\u6027\u8cea\u3067\u306f\u306a\u3044\u306e\u304b\u3001\u306f\u50d5\u81ea\u8eab\u307e\u3060\u308f\u304b\u3089\u306a\u3044\u306e\u3067\u3059\u304c\u3001CNN\u306e\u8868\u73fe\u529b\u306e\u9ad8\u3055\u3092\u6539\u3081\u3066\u601d\u3044\u77e5\u308b\u3053\u3068\u304c\u3067\u304d\u307e\u3057\u305f\u3002\n"}