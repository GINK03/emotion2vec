{"context": " More than 1 year has passed since last update.\n\n\u6982\u8981\nBeautifulSoup\u3092\u4f7f\u3063\u3066\u3001Ameba\u30d6\u30ed\u30b0\u3092\u30d1\u30fc\u30ba\u5f8cCSV\u30d5\u30a1\u30a4\u30eb\u3068\u3057\u3066\u4fdd\u5b58\u3057\u305f\u3002\n\n\u5229\u7528\u3057\u305f\u30c4\u30fc\u30eb\u3001\u30e9\u30a4\u30d6\u30e9\u30ea\u306a\u3069\npythonxy(2.7.6.1)\nBeautifulSoup\n\n\u6e96\u5099\uff1aBeautifulSoup\u306e\u30a4\u30f3\u30b9\u30c8\u30fc\u30eb\npip install BeautifulSoup\n\u3067\u30a4\u30f3\u30b9\u30c8\u30fc\u30eb\n\n\u5bfe\u8c61\u306e\u30c7\u30fc\u30bf\n\u4eca\u56de\u306f\n\u9053\u91cd\u3055\u3086\u307f\u30aa\u30d5\u30a3\u30b7\u30e3\u30eb\u30d6\u30ed\u30b0\u300c\u30b5\u30e6\u30df\u30f3\u30e9\u30f3\u30c9\u30fc\u30eb\u300dPowered by Ameba\n\u3092\u5bfe\u8c61\u306b\u3057\u305f\u3002\n\n\u30bd\u30fc\u30b9\u30b3\u30fc\u30c9\n\nbs_ameba.py\n# -*- coding: utf-8 -*-\n\nimport sys\nreload(sys)\nsys.setdefaultencoding('utf-8')\n\nimport csv\nfrom BeautifulSoup import *\n\nfrom fileutil import *\n\ndef extract_article(file):\n\n    f = open(file)\n    soup = BeautifulSoup(f)\n    f.close()\n\n    comments = soup.findAll(text=lambda text:isinstance(text, Comment))\n    [comment.extract() for comment in comments]\n\n    output_record = []\n\n    title_str = soup.find('a', {\"class\":\"skinArticleTitle\"})\n    output_record.append(str(title_str.text).rstrip())\n\n    theme_str = soup.find('span', {\"class\":\"articleTheme\"})\n    output_record.append(str(theme_str.text).rstrip())\n\n    date_time = soup.find('time',)\n    output_record.append(str(date_time.text).rstrip())\n\n    div = soup.find('div', {\"class\":\"articleText\"})\n    output_record.append(str(div.text).rstrip())\n\n    return output_record\n\nif __name__ == \"__main__\":\n\n    input_folder = './data/sayumimichishige-blog/'\n    output_file = './output/michishige_sayumi.csv'\n\n    w_f = open(output_file, 'w')    \n    writer = csv.writer(w_f, lineterminator='\\n')\n\n    output_record = ['title', 'theme', 'date_time', 'article']\n    writer.writerow(output_record)    \n\n    file_list = fild_all_files(input_folder)\n    for file in file_list:\n        if os.path.isdir(file):\n            continue\n        print file\n        output_record = extract_article(file)\n        writer.writerow(output_record)\n\n    w_f.close()\n\n\n\n\u7d50\u679c\n\n\u3053\u3093\u306a\u611f\u3058\u3067CSV\u5316\u306b\u6210\u529f\u3002\u5b9f\u969b\u306bHTML\u306e\u30bd\u30fc\u30b9\u30b3\u30fc\u30c9\u3092\u898b\u308b\u3068\u3001\u8907\u96d1\u306aHTML\u306a\u3093\u3067\u3059\u304c\u3001\u3053\u308c\u3060\u3051\u306e\u30b3\u30fc\u30c9\u91cf\u3067\u6574\u5f62\u5316\u3067\u304d\u308b\u306e\u306f\u826f\u3044\u3067\u3059\u3002\nBeautifulSoup\u306f\u524d\u304b\u3089\u6c17\u306b\u306a\u3063\u3066\u307e\u3057\u305f\u304c\u3001\u7d50\u69cb\u4f7f\u3048\u307e\u3059\u306d\u3002\n#\u6982\u8981\nBeautifulSoup\u3092\u4f7f\u3063\u3066\u3001Ameba\u30d6\u30ed\u30b0\u3092\u30d1\u30fc\u30ba\u5f8cCSV\u30d5\u30a1\u30a4\u30eb\u3068\u3057\u3066\u4fdd\u5b58\u3057\u305f\u3002\n\n#\u5229\u7528\u3057\u305f\u30c4\u30fc\u30eb\u3001\u30e9\u30a4\u30d6\u30e9\u30ea\u306a\u3069\n[pythonxy(2.7.6.1)](https://code.google.com/p/pythonxy/)\n[BeautifulSoup](http://www.crummy.com/software/BeautifulSoup/)\n\n##\u6e96\u5099\uff1aBeautifulSoup\u306e\u30a4\u30f3\u30b9\u30c8\u30fc\u30eb\n\n` pip install BeautifulSoup`\n\n\u3067\u30a4\u30f3\u30b9\u30c8\u30fc\u30eb\n\n#\u5bfe\u8c61\u306e\u30c7\u30fc\u30bf\n\u4eca\u56de\u306f\n\n[\u9053\u91cd\u3055\u3086\u307f\u30aa\u30d5\u30a3\u30b7\u30e3\u30eb\u30d6\u30ed\u30b0\u300c\u30b5\u30e6\u30df\u30f3\u30e9\u30f3\u30c9\u30fc\u30eb\u300dPowered by Ameba](http://ameblo.jp/sayumimichishige-blog/)\n\n\u3092\u5bfe\u8c61\u306b\u3057\u305f\u3002\n\n#\u30bd\u30fc\u30b9\u30b3\u30fc\u30c9\n```py:bs_ameba.py\n# -*- coding: utf-8 -*-\n\nimport sys\nreload(sys)\nsys.setdefaultencoding('utf-8')\n\nimport csv\nfrom BeautifulSoup import *\n\nfrom fileutil import *\n\ndef extract_article(file):\n    \n    f = open(file)\n    soup = BeautifulSoup(f)\n    f.close()\n\n    comments = soup.findAll(text=lambda text:isinstance(text, Comment))\n    [comment.extract() for comment in comments]\n\n    output_record = []\n\n    title_str = soup.find('a', {\"class\":\"skinArticleTitle\"})\n    output_record.append(str(title_str.text).rstrip())\n\n    theme_str = soup.find('span', {\"class\":\"articleTheme\"})\n    output_record.append(str(theme_str.text).rstrip())\n\n    date_time = soup.find('time',)\n    output_record.append(str(date_time.text).rstrip())\n \n    div = soup.find('div', {\"class\":\"articleText\"})\n    output_record.append(str(div.text).rstrip())\n    \n    return output_record\n    \nif __name__ == \"__main__\":\n    \n    input_folder = './data/sayumimichishige-blog/'\n    output_file = './output/michishige_sayumi.csv'\n    \n    w_f = open(output_file, 'w')    \n    writer = csv.writer(w_f, lineterminator='\\n')\n    \n    output_record = ['title', 'theme', 'date_time', 'article']\n    writer.writerow(output_record)    \n    \n    file_list = fild_all_files(input_folder)\n    for file in file_list:\n        if os.path.isdir(file):\n            continue\n        print file\n        output_record = extract_article(file)\n        writer.writerow(output_record)\n        \n    w_f.close()\n```\n#\u7d50\u679c\n![aaaa.jpg](https://qiita-image-store.s3.amazonaws.com/0/61199/91cf4f5b-7df1-3de2-ea78-37f2eea23bfa.jpeg)\n\n\u3053\u3093\u306a\u611f\u3058\u3067CSV\u5316\u306b\u6210\u529f\u3002\u5b9f\u969b\u306bHTML\u306e\u30bd\u30fc\u30b9\u30b3\u30fc\u30c9\u3092\u898b\u308b\u3068\u3001\u8907\u96d1\u306aHTML\u306a\u3093\u3067\u3059\u304c\u3001\u3053\u308c\u3060\u3051\u306e\u30b3\u30fc\u30c9\u91cf\u3067\u6574\u5f62\u5316\u3067\u304d\u308b\u306e\u306f\u826f\u3044\u3067\u3059\u3002\n\nBeautifulSoup\u306f\u524d\u304b\u3089\u6c17\u306b\u306a\u3063\u3066\u307e\u3057\u305f\u304c\u3001\u7d50\u69cb\u4f7f\u3048\u307e\u3059\u306d\u3002\n", "tags": ["BeautifulSoup"]}