{"context": "\n\n\u6982\u8981\nLSTM\u3092\u4f7f\u3063\u3066\u30ba\u30f3\u30c9\u30b3\u30ad\u30e8\u30b7\u3092\u5b66\u7fd2\u3057\u3066\u307f\u307e\u3057\u305f\u3002\nChainer\u3092\u4f7f\u3063\u3066\u5b9f\u88c5\u3057\u3066\u3044\u307e\u3059\u3002\n\u3061\u3087\u3063\u3068\u524d\u306b\u3042\u304b\u3089\u3055\u307e\u306b\u8aa4\u3063\u305f\u30b3\u30fc\u30c9\u3092\u6295\u7a3f\u3057\u3066\u3057\u307e\u3063\u305f\u306e\u3067\u3059\u304c\u3001\u4fee\u6b63\u3057\u3066\u518d\u6295\u7a3f\u3057\u307e\u3059\u3002\nLSTM\u306e\u8aac\u660e\u306f\u4ee5\u4e0b\u306e\u6295\u7a3f\u304c\u8a73\u3057\u3044\u3067\u3059\u3002\n\u308f\u304b\u308bLSTM \uff5e \u6700\u8fd1\u306e\u52d5\u5411\u3068\u5171\u306b\n\n\u30e2\u30c7\u30eb\n\u4ee5\u4e0b\u306e\u3088\u3046\u306a\u30e2\u30c7\u30eb\u3092\u69cb\u7bc9\u3057\u307e\u3059\n* \u5165\u529b\u3068\u3057\u3066\u300c\u30ba\u30f3\u300d\u307e\u305f\u306f\u300c\u30c9\u30b3\u300d\u3092\u53d7\u3051\u3064\u3051\u308b\n* \u51fa\u529b\u306fNone\u307e\u305f\u306f\u300c\uff3c\u30ad\u30fb\u30e8\u30fb\u30b7\uff01\uff0f\u300d\n* \u300c\u30ba\u30f3\u300d\u300c\u30ba\u30f3\u300d\u300c\u30ba\u30f3\u300d\u300c\u30ba\u30f3\u300d\u300c\u30c9\u30b3\u300d\u3092\u3053\u306e\u9806\u3067\u5165\u529b\u3057\u305f\u3089\u300c\uff3c\u30ad\u30fb\u30e8\u30fb\u30b7\uff01\uff0f\u300d\u3092\u51fa\u529b\u3001\u305d\u308c\u4ee5\u5916\u306e\u5834\u5408\u306fNone\u3092\u51fa\u529b\u3059\u308b\u3088\u3046\u306b\u5b66\u7fd2\u3059\u308b\n\n\u30b3\u30fc\u30c9\n\nzundoko.py\n#!/usr/bin/env python\n# -*- coding: utf-8 -*-\n\nimport numpy as np\nimport chainer\nfrom chainer import Variable, optimizers, functions as F, links as L\n\nnp.random.seed()\nzun = 0\ndoko = 1\ninput_num = 2\ninput_words = ['\u30ba\u30f3', '\u30c9\u30b3']\nnone = 0\nkiyoshi = 1\noutput_num = 2\noutput_words = [None, '\uff3c\u30ad\u30fb\u30e8\u30fb\u30b7\uff01\uff0f']\nhidden_num = 8\nupdate_iteration = 20\n\nclass Zundoko(chainer.Chain):\n    def __init__(self):\n        super(Zundoko, self).__init__(\n            word=L.EmbedID(input_num, hidden_num),\n            lstm=L.LSTM(hidden_num, hidden_num),\n            linear=L.Linear(hidden_num, hidden_num),\n            out=L.Linear(hidden_num, output_num),\n        )\n\n    def __call__(self, x, train=True):\n        h1 = self.word(x)\n        h2 = self.lstm(h1)\n        h3 = F.relu(self.linear(h2))\n        return self.out(h3)\n\n    def reset_state(self):\n        self.lstm.reset_state()\n\nkiyoshi_list = [zun, zun, zun, zun, doko]\nkiyoshi_pattern = 0\nkiyoshi_mask = (1 << len(kiyoshi_list)) - 1\nfor token in kiyoshi_list:\n    kiyoshi_pattern = (kiyoshi_pattern << 1) | token\n\nzundoko = Zundoko()\nfor param in zundoko.params():\n    data = param.data\n    data[:] = np.random.uniform(-1, 1, data.shape)\noptimizer = optimizers.Adam(alpha=0.01)\noptimizer.setup(zundoko)\n\ndef forward(train=True):\n    loss = 0\n    acc = 0\n    if train:\n        batch_size = 20\n    else:\n        batch_size = 1\n    recent_pattern = np.zeros((batch_size,), dtype=np.int32)\n    zundoko.reset_state()\n    for i in range(200):\n        x = np.random.randint(0, input_num, batch_size).astype(np.int32)\n        y_var = zundoko(Variable(x, volatile=not train), train=train)\n        recent_pattern = ((recent_pattern << 1) | x) & kiyoshi_mask\n        if i < len(kiyoshi_list):\n            t = np.full((batch_size,), none, dtype=np.int32)\n        else:\n            t = np.where(recent_pattern == kiyoshi_pattern, kiyoshi, none).astype(np.int32)\n        loss += F.softmax_cross_entropy(y_var, Variable(t, volatile=not train))\n        acc += float(F.accuracy(y_var, Variable(t, volatile=not train)).data)\n        if not train:\n            print input_words[x[0]]\n            y = np.argmax(y_var.data[0])\n            if output_words[y] != None:\n                print output_words[y]\n                break\n        if train and (i + 1) % update_iteration == 0:\n            optimizer.zero_grads()\n            loss.backward()\n            loss.unchain_backward()\n            optimizer.update()\n            print 'train loss: {} accuracy: {}'.format(loss.data, acc / update_iteration)\n            loss = 0\n            acc = 0\n\nfor iteration in range(20):\n    forward()\n\nforward(train=False)\n\n\n\n\u51fa\u529b\u4f8b\ntrain loss: 18.4753189087 accuracy: 0.020000000298\ntrain loss: 16.216506958 accuracy: 0.0325000006706\ntrain loss: 15.0742883682 accuracy: 0.0350000008941\ntrain loss: 13.9205350876 accuracy: 0.385000001639\ntrain loss: 12.5977449417 accuracy: 0.96249999404\n(\u4e2d\u7565)\ntrain loss: 0.00433994689956 accuracy: 1.0\ntrain loss: 0.00596862798557 accuracy: 1.0\ntrain loss: 0.0027643663343 accuracy: 1.0\ntrain loss: 0.011038181372 accuracy: 1.0\ntrain loss: 0.00512072304264 accuracy: 1.0\n\u30ba\u30f3\n\u30ba\u30f3\n\u30ba\u30f3\n\u30c9\u30b3\n\u30c9\u30b3\n\u30c9\u30b3\n\u30ba\u30f3\n\u30ba\u30f3\n\u30ba\u30f3\n\u30c9\u30b3\n\u30c9\u30b3\n\u30c9\u30b3\n\u30c9\u30b3\n\u30c9\u30b3\n\u30c9\u30b3\n\u30ba\u30f3\n\u30c9\u30b3\n\u30c9\u30b3\n\u30ba\u30f3\n\u30c9\u30b3\n\u30c9\u30b3\n\u30ba\u30f3\n\u30c9\u30b3\n\u30ba\u30f3\n\u30ba\u30f3\n\u30ba\u30f3\n\u30ba\u30f3\n\u30ba\u30f3\n\u30ba\u30f3\n\u30ba\u30f3\n\u30ba\u30f3\n\u30c9\u30b3\n\uff3c\u30ad\u30fb\u30e8\u30fb\u30b7\uff01\uff0f\n\n\n\u5c11\u3057\u306f\u307e\u3063\u305f\u3068\u3053\u308d\n\u6700\u521ddropout\u3092\u4f7f\u3063\u3066\u3044\u305f\u306e\u3067\u3059\u304c\u3001\u305d\u3046\u3059\u308b\u3068\u5b66\u7fd2\u304c\u3046\u307e\u304f\u3044\u304b\u305a\u51fa\u529b\u304c\u307b\u307cNone\u306e\u307f\u306b\u306a\u3063\u3066\u3057\u307e\u3044\u307e\u3057\u305f\u3002\n# \u6982\u8981\n\nLSTM\u3092\u4f7f\u3063\u3066\u30ba\u30f3\u30c9\u30b3\u30ad\u30e8\u30b7\u3092\u5b66\u7fd2\u3057\u3066\u307f\u307e\u3057\u305f\u3002\nChainer\u3092\u4f7f\u3063\u3066\u5b9f\u88c5\u3057\u3066\u3044\u307e\u3059\u3002\n\u3061\u3087\u3063\u3068\u524d\u306b\u3042\u304b\u3089\u3055\u307e\u306b\u8aa4\u3063\u305f\u30b3\u30fc\u30c9\u3092\u6295\u7a3f\u3057\u3066\u3057\u307e\u3063\u305f\u306e\u3067\u3059\u304c\u3001\u4fee\u6b63\u3057\u3066\u518d\u6295\u7a3f\u3057\u307e\u3059\u3002\n\nLSTM\u306e\u8aac\u660e\u306f\u4ee5\u4e0b\u306e\u6295\u7a3f\u304c\u8a73\u3057\u3044\u3067\u3059\u3002\n\n[\u308f\u304b\u308bLSTM \uff5e \u6700\u8fd1\u306e\u52d5\u5411\u3068\u5171\u306b](http://qiita.com/t_Signull/items/21b82be280b46f467d1b)\n\n# \u30e2\u30c7\u30eb\n\n\u4ee5\u4e0b\u306e\u3088\u3046\u306a\u30e2\u30c7\u30eb\u3092\u69cb\u7bc9\u3057\u307e\u3059\n* \u5165\u529b\u3068\u3057\u3066\u300c\u30ba\u30f3\u300d\u307e\u305f\u306f\u300c\u30c9\u30b3\u300d\u3092\u53d7\u3051\u3064\u3051\u308b\n* \u51fa\u529b\u306fNone\u307e\u305f\u306f\u300c\uff3c\u30ad\u30fb\u30e8\u30fb\u30b7\uff01\uff0f\u300d\n* \u300c\u30ba\u30f3\u300d\u300c\u30ba\u30f3\u300d\u300c\u30ba\u30f3\u300d\u300c\u30ba\u30f3\u300d\u300c\u30c9\u30b3\u300d\u3092\u3053\u306e\u9806\u3067\u5165\u529b\u3057\u305f\u3089\u300c\uff3c\u30ad\u30fb\u30e8\u30fb\u30b7\uff01\uff0f\u300d\u3092\u51fa\u529b\u3001\u305d\u308c\u4ee5\u5916\u306e\u5834\u5408\u306fNone\u3092\u51fa\u529b\u3059\u308b\u3088\u3046\u306b\u5b66\u7fd2\u3059\u308b\n\n#\u30b3\u30fc\u30c9\n\n```zundoko.py\n#!/usr/bin/env python\n# -*- coding: utf-8 -*-\n\nimport numpy as np\nimport chainer\nfrom chainer import Variable, optimizers, functions as F, links as L\n\nnp.random.seed()\nzun = 0\ndoko = 1\ninput_num = 2\ninput_words = ['\u30ba\u30f3', '\u30c9\u30b3']\nnone = 0\nkiyoshi = 1\noutput_num = 2\noutput_words = [None, '\uff3c\u30ad\u30fb\u30e8\u30fb\u30b7\uff01\uff0f']\nhidden_num = 8\nupdate_iteration = 20\n\nclass Zundoko(chainer.Chain):\n    def __init__(self):\n        super(Zundoko, self).__init__(\n            word=L.EmbedID(input_num, hidden_num),\n            lstm=L.LSTM(hidden_num, hidden_num),\n            linear=L.Linear(hidden_num, hidden_num),\n            out=L.Linear(hidden_num, output_num),\n        )\n\n    def __call__(self, x, train=True):\n        h1 = self.word(x)\n        h2 = self.lstm(h1)\n        h3 = F.relu(self.linear(h2))\n        return self.out(h3)\n\n    def reset_state(self):\n        self.lstm.reset_state()\n\nkiyoshi_list = [zun, zun, zun, zun, doko]\nkiyoshi_pattern = 0\nkiyoshi_mask = (1 << len(kiyoshi_list)) - 1\nfor token in kiyoshi_list:\n    kiyoshi_pattern = (kiyoshi_pattern << 1) | token\n\nzundoko = Zundoko()\nfor param in zundoko.params():\n    data = param.data\n    data[:] = np.random.uniform(-1, 1, data.shape)\noptimizer = optimizers.Adam(alpha=0.01)\noptimizer.setup(zundoko)\n\ndef forward(train=True):\n    loss = 0\n    acc = 0\n    if train:\n        batch_size = 20\n    else:\n        batch_size = 1\n    recent_pattern = np.zeros((batch_size,), dtype=np.int32)\n    zundoko.reset_state()\n    for i in range(200):\n        x = np.random.randint(0, input_num, batch_size).astype(np.int32)\n        y_var = zundoko(Variable(x, volatile=not train), train=train)\n        recent_pattern = ((recent_pattern << 1) | x) & kiyoshi_mask\n        if i < len(kiyoshi_list):\n            t = np.full((batch_size,), none, dtype=np.int32)\n        else:\n            t = np.where(recent_pattern == kiyoshi_pattern, kiyoshi, none).astype(np.int32)\n        loss += F.softmax_cross_entropy(y_var, Variable(t, volatile=not train))\n        acc += float(F.accuracy(y_var, Variable(t, volatile=not train)).data)\n        if not train:\n            print input_words[x[0]]\n            y = np.argmax(y_var.data[0])\n            if output_words[y] != None:\n                print output_words[y]\n                break\n        if train and (i + 1) % update_iteration == 0:\n            optimizer.zero_grads()\n            loss.backward()\n            loss.unchain_backward()\n            optimizer.update()\n            print 'train loss: {} accuracy: {}'.format(loss.data, acc / update_iteration)\n            loss = 0\n            acc = 0\n\nfor iteration in range(20):\n    forward()\n\nforward(train=False)\n```\n\n# \u51fa\u529b\u4f8b\n\n```\ntrain loss: 18.4753189087 accuracy: 0.020000000298\ntrain loss: 16.216506958 accuracy: 0.0325000006706\ntrain loss: 15.0742883682 accuracy: 0.0350000008941\ntrain loss: 13.9205350876 accuracy: 0.385000001639\ntrain loss: 12.5977449417 accuracy: 0.96249999404\n(\u4e2d\u7565)\ntrain loss: 0.00433994689956 accuracy: 1.0\ntrain loss: 0.00596862798557 accuracy: 1.0\ntrain loss: 0.0027643663343 accuracy: 1.0\ntrain loss: 0.011038181372 accuracy: 1.0\ntrain loss: 0.00512072304264 accuracy: 1.0\n\u30ba\u30f3\n\u30ba\u30f3\n\u30ba\u30f3\n\u30c9\u30b3\n\u30c9\u30b3\n\u30c9\u30b3\n\u30ba\u30f3\n\u30ba\u30f3\n\u30ba\u30f3\n\u30c9\u30b3\n\u30c9\u30b3\n\u30c9\u30b3\n\u30c9\u30b3\n\u30c9\u30b3\n\u30c9\u30b3\n\u30ba\u30f3\n\u30c9\u30b3\n\u30c9\u30b3\n\u30ba\u30f3\n\u30c9\u30b3\n\u30c9\u30b3\n\u30ba\u30f3\n\u30c9\u30b3\n\u30ba\u30f3\n\u30ba\u30f3\n\u30ba\u30f3\n\u30ba\u30f3\n\u30ba\u30f3\n\u30ba\u30f3\n\u30ba\u30f3\n\u30ba\u30f3\n\u30c9\u30b3\n\uff3c\u30ad\u30fb\u30e8\u30fb\u30b7\uff01\uff0f\n```\n\n# \u5c11\u3057\u306f\u307e\u3063\u305f\u3068\u3053\u308d\n\n\u6700\u521ddropout\u3092\u4f7f\u3063\u3066\u3044\u305f\u306e\u3067\u3059\u304c\u3001\u305d\u3046\u3059\u308b\u3068\u5b66\u7fd2\u304c\u3046\u307e\u304f\u3044\u304b\u305a\u51fa\u529b\u304c\u307b\u307cNone\u306e\u307f\u306b\u306a\u3063\u3066\u3057\u307e\u3044\u307e\u3057\u305f\u3002\n\n", "tags": ["\u30ba\u30f3\u30c9\u30b3\u30ad\u30e8\u30b7", "Python", "Chainer", "DeepLearning", "MachineLearning"]}