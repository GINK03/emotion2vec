{"context": "\n\n\u30cf\u30a4\u30d1\u30fc\u30d1\u30e9\u30e1\u30fc\u30bf\u30c1\u30e5\u30fc\u30cb\u30f3\u30b0\u3063\u3066\uff1f\n\u30e2\u30c7\u30eb\u306b\u3088\u3063\u3066\u3042\u3089\u304b\u3058\u3081\u6c7a\u3081\u306a\u304d\u3083\u3044\u3051\u306a\u3044\u30d1\u30e9\u30e1\u30fc\u30bf\u304c\u3042\u308a\u307e\u3059\u3002\n(\u4f8b\u3048\u3070k-means\u306e\u30af\u30e9\u30b9\u30bf\u6570\u3084\u3001SVC\u306e\u6b63\u5247\u5316\u9805\u306e\u5f37\u3055\u3001\u6c7a\u5b9a\u6728\u306e\u6df1\u3055\u306a\u3069)\n\u305d\u308c\u3092\u300e\u30cf\u30a4\u30d1\u30fc\u30d1\u30e9\u30e1\u30fc\u30bf\u300f\u3068\u3044\u3046\u306e\u3067\u3059\u304c\u3001\u56f0\u3063\u305f\u3053\u3068\u306b\u540c\u3058\u30e2\u30c7\u30eb\u3060\u3068\u3057\u3066\u3082\u30cf\u30a4\u30d1\u30fc\u30d1\u30e9\u30e1\u30fc\u30bf\u306e\u5024\u306b\u3088\u3063\u3066\u7cbe\u5ea6\u304c\u5927\u5e45\u306b\u5909\u308f\u308b\u3053\u3068\u3082\u3042\u308a\u307e\u3059\u3002\n\u305d\u308c\u3092\u3046\u307e\u304f\u3001\u5b66\u7fd2\u30c7\u30fc\u30bf\u3092\u7528\u3044\u3066\u6c7a\u3081\u3066\u3057\u307e\u304a\u3046\u3068\u3044\u3046\u306e\u304c\u3001\u30cf\u30a4\u30d1\u30fc\u30d1\u30e9\u30e1\u30fc\u30bf\u30c1\u30e5\u30fc\u30cb\u30f3\u30b0\u306a\u306e\u3067\u3059\uff01\uff01\n\n\u30b0\u30ea\u30c3\u30c9\u30b5\u30fc\u30c1\u3068\u30e9\u30f3\u30c0\u30e0\u30b5\u30fc\u30c1\n\u305d\u306e\u30c1\u30e5\u30fc\u30cb\u30f3\u30b0\u624b\u6cd5\u306e\u5185\u3001\u4eca\u56de\u6271\u3046\u306e\u306f\u3001\u30b0\u30ea\u30c3\u30c9\u30b5\u30fc\u30c1\u3068\u30e9\u30f3\u30c0\u30e0\u30b5\u30fc\u30c1\u306e2\u3064\u3067\u3059\u3002\n\u3056\u3063\u304f\u308a\u3044\u3044\u307e\u3059\u3068\u3001\u30cf\u30a4\u30d1\u30fc\u30d1\u30e9\u30e1\u30fc\u30bf\u03b1\u304c\u3042\u308b\u3068\u3059\u308b\u3068\u4ee5\u4e0b\u306e\u6d41\u308c\u3067\u5b9f\u884c\u3057\u307e\u3059\u3002\n\u30fb\u30b0\u30ea\u30c3\u30c9\u30b5\u30fc\u30c1\u306f\u3001\u3042\u3089\u304b\u3058\u3081\u03b1\u306e\u7bc4\u56f2(ex. 0,1,2,3,4,5\u306a\u3069)\u3092\u6307\u5b9a\u3057\u3066\u3001\u5b9f\u969b\u306b\u305d\u306e\u30d1\u30e9\u30e1\u30fc\u30bf\u3067\u30e2\u30c7\u30eb\u306e\u7cbe\u5ea6\u3092\u51fa\u3057\u3066\u307f\u3066\u3001\u4e00\u756a\u3044\u3044\u3084\u3064\u3092\u30d1\u30e9\u30e1\u30fc\u30bf\u306b\u3059\u308b\u3002\n\u30fb\u30e9\u30f3\u30c0\u30e0\u30b5\u30fc\u30c1\u306f\u3001\u3042\u3089\u304b\u3058\u3081\u03b1\u304c\u5f93\u3046\u5206\u5e03(ex. \u5e73\u57470, \u6a19\u6e96\u504f\u5dee1\u306e\u6b63\u898f\u5206\u5e03\u306a\u3069)\u3092\u6307\u5b9a\u3057\u3066\u3001\u305d\u3053\u304b\u3089\u30e9\u30f3\u30c0\u30e0\u306b\u53d6\u308a\u51fa\u3057\u3001\u5b9f\u969b\u306b\u305d\u306e\u30d1\u30e9\u30e1\u30fc\u30bf\u3067\u30e2\u30c7\u30eb\u306e\u7cbe\u5ea6\u3092\u51fa\u3057\u3066\u307f\u3066\u3001\u4e00\u756a\u3044\u3044\u3084\u3064\u3092\u30d1\u30e9\u30e1\u30fc\u30bf\u306b\u3059\u308b.\n\n\u4ee5\u4e0a\u306e\u3088\u3046\u306b\u3001\u4e21\u8005\u3068\u3082\u30cf\u30a4\u30d1\u30fc\u30d1\u30e9\u30e1\u30fc\u30bf\u03b1\u3092\u305d\u306e\u307e\u307e\u3042\u3066\u305a\u3063\u307d\u3046\u3067\u6c7a\u3081\u308b\u3068\u3044\u3046\u624b\u9806\u3067\u306f\u306a\u304f\u3001\n\u305d\u306e\u524d\u306b\u3001\u7bc4\u56f2\u3084\u5206\u5e03\u3092\u6c7a\u3081\u3001\u5b9f\u969b\u306e\u8a13\u7df4\u30c7\u30fc\u30bf\u3092\u4f7f\u3063\u3066\u6c7a\u3081\u308b\u3068\u3044\u3046\u624b\u9806\u3092\u3068\u3063\u3066\u3044\u308b\u3053\u3068\u304c\u308f\u304b\u308a\u307e\u3059\u3002(\u3088\u308a\u8a73\u7d30\u306b\u3064\u3044\u3066\u306f\u3001\u53c2\u8003\u6587\u732e\u3092\u3054\u89a7\u306b\u306a\u3063\u3066\u304f\u3060\u3055\u3044!)\n\nPython\u30b3\u30fc\u30c9\n\u4e0a\u8a18\u306e2\u3064\u304cscikit-learn\u3067\u306f\u6a19\u6e96\u88c5\u5099\u3055\u308c\u3066\u3044\u308b\u306e\u3067\u5229\u7528\u3057\u3066\u3044\u304d\u307e\u3059\uff01\npython3.5.1, scikit_learn-0.18.1\u3067\u306e\u30b3\u30fc\u30c9\u3067\u3059\u3002\n\u4eca\u56de\u306f\u3001UCI\u306eMachine Learning Repository\u304b\u3089\u30c7\u30fc\u30bf\u3092\u3068\u3063\u3066\u3001RandomForestClassifier\u306e2\u3064\u306e\u5206\u985e\u5668\u3092\u4f7f\u7528\u3057\u3066\u3001\u30d1\u30e9\u30e1\u30fc\u30bf\u30c1\u30e5\u30fc\u30cb\u30f3\u30b0\u3092\u3057\u3066\u3044\u307e\u3059\u3002\n\u30b3\u30fc\u30c9\u306e\u5168\u5bb9\u306fgithub\u306b\u30a2\u30c3\u30d7\u30ed\u30fc\u30c9\u3057\u3066\u3044\u307e\u3059.\n\nSTEP1 \u30c7\u30fc\u30bf\u3092UCI\u30ea\u30dd\u30b8\u30c8\u30ea\u304b\u3089\u30c0\u30a6\u30f3\u30ed\u30fc\u30c9\n\nGrid_and_Random_Search.ipynb\n df = pd.read_csv('https://archive.ics.uci.edu/ml/machine-learning-databases'\n                  '/breast-cancer-wisconsin/wdbc.data', header=None)\n\n\n\u5206\u304b\u308a\u3084\u3059\u304f\u3059\u308b\u305f\u3081\u306b\u3001\u4e88\u6e2c\u3057\u305f\u3044\u30ab\u30e9\u30e0\u3092Target\u306b\u3001\u305d\u306e\u4ed6\u3092a~\u306b\u3057\u307e\u3059\u3002\n\nGrid_and_Random_Search.ipynb\n columns_list = [] \n for i in range(df.shape[1]):\n     columns_list.append(\"a%d\"%i) \n columns_list[1] = \"Target\" \n df.columns = columns_list\n\n\n\nSTEP2 \u30c7\u30fc\u30bf\u3092\u5206\u5272\n\nGrid_and_Random_Search.ipynb\n y = df[\"Target\"].values\n X = df.drop([\"a0\",\"Target\"],axis=1)\n\n\ntrain\u30c7\u30fc\u30bf\u3068test\u30c7\u30fc\u30bf\u306b\u5206\u5272\n\nGrid_and_Random_Search.ipynb\n #split X,y to train,test(0.5:0.5)\n from sklearn.cross_validation import train_test_split\n\n X_train,X_test,y_train,y_test = train_test_split(X,y,test_size=0.5,random_state=2017)\n\n\n\nSTEP3 \u30c7\u30d5\u30a9\u30eb\u30c8\u306e\u72b6\u614b\u3067\u306e\u30e2\u30c7\u30eb\u306e\u7cbe\u5ea6\u3092\u691c\u67fb\u3057\u3066\u307f\u308b.\n\nGrid_and_Random_Search.ipynb\n from sklearn.metrics import classification_report\n\n def model_check(model):\n     model.fit(X_train,y_train)\n     y_train_pred = classification_report(y_train,model.predict(X_train))\n     y_test_pred  = classification_report(y_test,model.predict(X_test))\n\n     print(\"\"\"\u3010{model_name}\u3011\\n Train Accuracy: \\n{train}\n           \\n Test Accuracy:  \\n{test}\"\"\".format(model_name=model.__class__.__name__, train=y_train_pred, test=y_test_pred))\n\nprint(model_check(RandomForestClassifier()))\n\n\n\n\u51fa\u529b\u7d50\u679c1(\u30c7\u30d5\u30a9\u30eb\u30c8)\n    [RandomForestClassifier]\n     Train Accuracy: \n                 precision    recall  f1-score   support\n\n              B       1.00      1.00      1.00        67\n              M       1.00      1.00      1.00        75\n\n    avg / total       1.00      1.00      1.00       142\n\n\n     Test Accuracy:  \n                 precision    recall  f1-score   support\n\n              B       0.89      0.93      0.91        72\n              M       0.93      0.89      0.91        70\n\n    avg / total       0.91      0.91      0.91       142\n\n\nTrain\u30c7\u30fc\u30bf\u306e\u6b63\u7b54\u7387\u306f1.0\u3001Test\u30c7\u30fc\u30bf\u306e\u6b63\u7b54\u7387\u306f0.91\u3060\u3068\u3044\u3046\u3053\u3068\u304c\u308f\u304b\u308a\u307e\u3057\u305f\u3002\n\u3053\u3053\u304b\u3089\u30b0\u30ea\u30c3\u30c9\u30b5\u30fc\u30c1\u3068\u30e9\u30f3\u30c0\u30e0\u30b5\u30fc\u30c1\u3092\u5b9f\u88c5\u3057\u3066\u3044\u304d\u307e\u3059\u3002\n\u4ee5\u964d\u306f\u53c2\u8003\u6587\u732e3\u3092\u53c2\u8003\u306b\u3057\u3066\u3044\u307e\u3059\u3002\n\nSTEP4 \u30b0\u30ea\u30c3\u30c9\u30b5\u30fc\u30c1\n\nGrid_and_Random_Search.ipynb\n #Grid search\n\n from sklearn.grid_search import GridSearchCV\n\n # use a full grid over all parameters\n param_grid = {\"max_depth\": [2,3, None],\n              \"n_estimators\":[50,100,200,300,400,500],\n              \"max_features\": [1, 3, 10],\n              \"min_samples_split\": [2, 3, 10],\n              \"min_samples_leaf\": [1, 3, 10],\n              \"bootstrap\": [True, False],\n              \"criterion\": [\"gini\", \"entropy\"]}\n\n forest_grid = GridSearchCV(estimator=RandomForestClassifier(random_state=0),\n                 param_grid = param_grid,   \n                 scoring=\"accuracy\",  #metrics\n                 cv = 3,              #cross-validation\n                 n_jobs = 1)          #number of core\n\n forest_grid.fit(X_train,y_train) #fit\n\n forest_grid_best = forest_grid.best_estimator_ #best estimator\n print(\"Best Model Parameter: \",forest_grid.best_params_)\n\n\n\n\u51fa\u529b\u7d50\u679c2(\u30b0\u30ea\u30c3\u30c9\u30b5\u30fc\u30c1)\n    [RandomForestClassifier]\n     Train Accuracy: \n                 precision    recall  f1-score   support\n\n              B       0.99      0.99      0.99        67\n              M       0.99      0.99      0.99        75\n\n    avg / total       0.99      0.99      0.99       142\n\n\n     Test Accuracy:  \n                 precision    recall  f1-score   support\n\n              B       0.96      0.89      0.92        72\n              M       0.89      0.96      0.92        70\n\n    avg / total       0.92      0.92      0.92       142\n\n\n\u5408\u8a08\u306e\u6b63\u7b54\u7387\u3084\u3001f1-score\u306a\u3069\u5168\u3066\u306e\u7cbe\u5ea6\u304c\u4e0a\u6607\u3057\u3066\u3044\u307e\u3059\uff01\uff01\n\nSTEP5 \u30e9\u30f3\u30c0\u30e0\u30b5\u30fc\u30c1\n\u30e9\u30f3\u30c0\u30e0\u30b5\u30fc\u30c1\u3067\u306f\u3001scipy\u3092\u4f7f\u3063\u3066\u30d1\u30e9\u30e1\u30fc\u30bf\u306e\u5f93\u3046\u5206\u5e03\u3092\u8868\u73fe\u3059\u308b\u3002\n\u4eca\u56de\u306f\u3001\u30a4\u30c6\u30ec\u30fc\u30b7\u30e7\u30f3\u56de\u6570\u3092\u30b0\u30ea\u30c3\u30c9\u30b5\u30fc\u30c1\u3068\u540c\u69d8\u306b\u3057\u3066\u3044\u307e\u3059\u3002\n\nGrid_and_Random_Search.ipynb\n#Random search\nfrom sklearn.grid_search import RandomizedSearchCV\nfrom scipy.stats import randint as sp_randint\n\nparam_dist = {\"max_depth\": [3, None],                  #distribution\n              \"n_estimators\":[50,100,200,300,400,500],\n              \"max_features\": sp_randint(1, 11),\n              \"min_samples_split\": sp_randint(2, 11),\n              \"min_samples_leaf\": sp_randint(1, 11),\n              \"bootstrap\": [True, False],\n              \"criterion\": [\"gini\", \"entropy\"]}\n\nforest_random = RandomizedSearchCV( estimator=RandomForestClassifier( random_state=0 ),\n                                    param_distributions=param_dist,\n                                    cv=3,              #CV\n                                    n_iter=1944,          #interation num\n                                    scoring=\"accuracy\", #metrics\n                                    n_jobs=1,           #num of core\n                                    verbose=0,          \n                                    random_state=1)\n\nforest_random.fit(X,y)\nforest_random_best = forest_random.best_estimator_ #best estimator\nprint(\"Best Model Parameter: \",forest_random.best_params_)\n\n\n\n\u51fa\u529b\u7d50\u679c3(\u30e9\u30f3\u30c0\u30e0\u30b5\u30fc\u30c1)\n    [RandomForestClassifier]\n     Train Accuracy: \n                 precision    recall  f1-score   support\n\n              B       1.00      1.00      1.00        67\n              M       1.00      1.00      1.00        75\n\n    avg / total       1.00      1.00      1.00       142\n\n\n     Test Accuracy:  \n                 precision    recall  f1-score   support\n\n              B       0.94      0.92      0.93        72\n              M       0.92      0.94      0.93        70\n\n    avg / total       0.93      0.93      0.93       142\n\n\n\u30c7\u30d5\u30a9\u30eb\u30c8\u306e\u5834\u5408\u3068\u6bd4\u3079\u308b\u3068\u3001\u3069\u306e\u9805\u76ee\u30822%\u5897\u52a0\u3057\u3066\u3044\u308b\u3053\u3068\u304c\u308f\u304b\u308a\u307e\u3057\u305f\uff01\n\n\u307e\u3068\u3081\n\u30b0\u30ea\u30c3\u30c9\u30b5\u30fc\u30c1\u3001\u30e9\u30f3\u30c0\u30e0\u30b5\u30fc\u30c1\u3068\u3082\u306b\u7cbe\u5ea6\u304c\u826f\u304f\u306a\u308a\u307e\u3057\u305f\uff01\n\u305f\u3060\u3001\u304a\u305d\u3089\u304f\u4eca\u56de\u306f\u5143\u3005\u7cbe\u5ea6\u304c\u9ad8\u3044\u3088\u3046\u306a\u30c7\u30fc\u30bf\u3092\u9078\u3093\u3060\u305f\u3081\u3001\u52b9\u679c\u304c\u898b\u3048\u3065\u3089\u304f\u306a\u3063\u3066\u3057\u307e\u3063\u305f\u306e\u3067\u306f\u306a\u3044\u304b\u3068\u601d\u3044\u307e\u3059\u3002\n\u7cbe\u5ea6\u304c\u826f\u304f\u306a\u3044\u3088\u3046\u306a\u30c7\u30fc\u30bf\u306b\u8a66\u3057\u3066\u307f\u308b\u3068\u30c1\u30e5\u30fc\u30cb\u30f3\u30b0\u306e\u52b9\u679c\u304c\u5206\u304b\u308a\u3084\u3059\u3044\u304b\u3082\u3057\u308c\u307e\u305b\u3093\u3002\n\u30b3\u30fc\u30c9\u5168\u5bb9\u306f\u3001github\u306b\u30a2\u30c3\u30d7\u30ed\u30fc\u30c9\u3057\u3066\u3042\u308a\u307e\u3059\u3002\n\u53c2\u8003\u6587\u732e\n1. Bergstra, J., & Bengio, Y. (2012)\n2. http://qiita.com/SE96UoC5AfUt7uY/items/c81f7cea72a44a7bfd3a\n3. http://scikit-learn.org/stable/auto_examples/model_selection/randomized_search.html\n#\u30cf\u30a4\u30d1\u30fc\u30d1\u30e9\u30e1\u30fc\u30bf\u30c1\u30e5\u30fc\u30cb\u30f3\u30b0\u3063\u3066\uff1f\n\u30e2\u30c7\u30eb\u306b\u3088\u3063\u3066\u3042\u3089\u304b\u3058\u3081\u6c7a\u3081\u306a\u304d\u3083\u3044\u3051\u306a\u3044\u30d1\u30e9\u30e1\u30fc\u30bf\u304c\u3042\u308a\u307e\u3059\u3002\n(\u4f8b\u3048\u3070k-means\u306e\u30af\u30e9\u30b9\u30bf\u6570\u3084\u3001SVC\u306e\u6b63\u5247\u5316\u9805\u306e\u5f37\u3055\u3001\u6c7a\u5b9a\u6728\u306e\u6df1\u3055\u306a\u3069)\n\n\u305d\u308c\u3092\u300e\u30cf\u30a4\u30d1\u30fc\u30d1\u30e9\u30e1\u30fc\u30bf\u300f\u3068\u3044\u3046\u306e\u3067\u3059\u304c\u3001\u56f0\u3063\u305f\u3053\u3068\u306b\u540c\u3058\u30e2\u30c7\u30eb\u3060\u3068\u3057\u3066\u3082\u30cf\u30a4\u30d1\u30fc\u30d1\u30e9\u30e1\u30fc\u30bf\u306e\u5024\u306b\u3088\u3063\u3066\u7cbe\u5ea6\u304c**\u5927\u5e45\u306b**\u5909\u308f\u308b\u3053\u3068\u3082\u3042\u308a\u307e\u3059\u3002\n\n\u305d\u308c\u3092\u3046\u307e\u304f\u3001\u5b66\u7fd2\u30c7\u30fc\u30bf\u3092\u7528\u3044\u3066\u6c7a\u3081\u3066\u3057\u307e\u304a\u3046\u3068\u3044\u3046\u306e\u304c\u3001\u30cf\u30a4\u30d1\u30fc\u30d1\u30e9\u30e1\u30fc\u30bf\u30c1\u30e5\u30fc\u30cb\u30f3\u30b0\u306a\u306e\u3067\u3059\uff01\uff01\n\n#\u30b0\u30ea\u30c3\u30c9\u30b5\u30fc\u30c1\u3068\u30e9\u30f3\u30c0\u30e0\u30b5\u30fc\u30c1\n\u305d\u306e\u30c1\u30e5\u30fc\u30cb\u30f3\u30b0\u624b\u6cd5\u306e\u5185\u3001\u4eca\u56de\u6271\u3046\u306e\u306f\u3001\u30b0\u30ea\u30c3\u30c9\u30b5\u30fc\u30c1\u3068\u30e9\u30f3\u30c0\u30e0\u30b5\u30fc\u30c1\u306e2\u3064\u3067\u3059\u3002\n\u3056\u3063\u304f\u308a\u3044\u3044\u307e\u3059\u3068\u3001\u30cf\u30a4\u30d1\u30fc\u30d1\u30e9\u30e1\u30fc\u30bf\u03b1\u304c\u3042\u308b\u3068\u3059\u308b\u3068\u4ee5\u4e0b\u306e\u6d41\u308c\u3067\u5b9f\u884c\u3057\u307e\u3059\u3002\n\n\u30fb\u30b0\u30ea\u30c3\u30c9\u30b5\u30fc\u30c1\u306f\u3001\u3042\u3089\u304b\u3058\u3081\u03b1\u306e**\u7bc4\u56f2**(ex. 0,1,2,3,4,5\u306a\u3069)\u3092\u6307\u5b9a\u3057\u3066\u3001\u5b9f\u969b\u306b\u305d\u306e\u30d1\u30e9\u30e1\u30fc\u30bf\u3067\u30e2\u30c7\u30eb\u306e\u7cbe\u5ea6\u3092\u51fa\u3057\u3066\u307f\u3066\u3001\u4e00\u756a\u3044\u3044\u3084\u3064\u3092\u30d1\u30e9\u30e1\u30fc\u30bf\u306b\u3059\u308b\u3002\n\n\u30fb\u30e9\u30f3\u30c0\u30e0\u30b5\u30fc\u30c1\u306f\u3001\u3042\u3089\u304b\u3058\u3081\u03b1\u304c\u5f93\u3046**\u5206\u5e03**(ex. \u5e73\u57470, \u6a19\u6e96\u504f\u5dee1\u306e\u6b63\u898f\u5206\u5e03\u306a\u3069)\u3092\u6307\u5b9a\u3057\u3066\u3001\u305d\u3053\u304b\u3089\u30e9\u30f3\u30c0\u30e0\u306b\u53d6\u308a\u51fa\u3057\u3001\u5b9f\u969b\u306b\u305d\u306e\u30d1\u30e9\u30e1\u30fc\u30bf\u3067\u30e2\u30c7\u30eb\u306e\u7cbe\u5ea6\u3092\u51fa\u3057\u3066\u307f\u3066\u3001\u4e00\u756a\u3044\u3044\u3084\u3064\u3092\u30d1\u30e9\u30e1\u30fc\u30bf\u306b\u3059\u308b.\n\n![Screen Shot 2017-02-25 at 22.37.35.png](https://qiita-image-store.s3.amazonaws.com/0/167522/936568c9-87d0-7e7f-c5e3-24065387718c.png)\n\n\n\u4ee5\u4e0a\u306e\u3088\u3046\u306b\u3001\u4e21\u8005\u3068\u3082\u30cf\u30a4\u30d1\u30fc\u30d1\u30e9\u30e1\u30fc\u30bf\u03b1\u3092\u305d\u306e\u307e\u307e\u3042\u3066\u305a\u3063\u307d\u3046\u3067\u6c7a\u3081\u308b\u3068\u3044\u3046\u624b\u9806\u3067\u306f\u306a\u304f\u3001\n\u305d\u306e\u524d\u306b\u3001**\u7bc4\u56f2\u3084\u5206\u5e03**\u3092\u6c7a\u3081\u3001\u5b9f\u969b\u306e\u8a13\u7df4\u30c7\u30fc\u30bf\u3092\u4f7f\u3063\u3066\u6c7a\u3081\u308b\u3068\u3044\u3046\u624b\u9806\u3092\u3068\u3063\u3066\u3044\u308b\u3053\u3068\u304c\u308f\u304b\u308a\u307e\u3059\u3002(\u3088\u308a\u8a73\u7d30\u306b\u3064\u3044\u3066\u306f\u3001\u53c2\u8003\u6587\u732e\u3092\u3054\u89a7\u306b\u306a\u3063\u3066\u304f\u3060\u3055\u3044!)\n\n\n#Python\u30b3\u30fc\u30c9\n\n\u4e0a\u8a18\u306e2\u3064\u304cscikit-learn\u3067\u306f\u6a19\u6e96\u88c5\u5099\u3055\u308c\u3066\u3044\u308b\u306e\u3067\u5229\u7528\u3057\u3066\u3044\u304d\u307e\u3059\uff01\npython3.5.1, scikit_learn-0.18.1\u3067\u306e\u30b3\u30fc\u30c9\u3067\u3059\u3002\n\n\u4eca\u56de\u306f\u3001UCI\u306eMachine Learning Repository\u304b\u3089\u30c7\u30fc\u30bf\u3092\u3068\u3063\u3066\u3001RandomForestClassifier\u306e2\u3064\u306e\u5206\u985e\u5668\u3092\u4f7f\u7528\u3057\u3066\u3001\u30d1\u30e9\u30e1\u30fc\u30bf\u30c1\u30e5\u30fc\u30cb\u30f3\u30b0\u3092\u3057\u3066\u3044\u307e\u3059\u3002\n\u30b3\u30fc\u30c9\u306e\u5168\u5bb9\u306f[github](https://github.com/ragAgar/qiita/blob/master/Grid_and_Random_Search.ipynb)\u306b\u30a2\u30c3\u30d7\u30ed\u30fc\u30c9\u3057\u3066\u3044\u307e\u3059.\n\n\n### STEP1 \u30c7\u30fc\u30bf\u3092UCI\u30ea\u30dd\u30b8\u30c8\u30ea\u304b\u3089\u30c0\u30a6\u30f3\u30ed\u30fc\u30c9\n\n```python:Grid_and_Random_Search.ipynb\n df = pd.read_csv('https://archive.ics.uci.edu/ml/machine-learning-databases'\n                  '/breast-cancer-wisconsin/wdbc.data', header=None)\n```\n\u5206\u304b\u308a\u3084\u3059\u304f\u3059\u308b\u305f\u3081\u306b\u3001\u4e88\u6e2c\u3057\u305f\u3044\u30ab\u30e9\u30e0\u3092Target\u306b\u3001\u305d\u306e\u4ed6\u3092a~\u306b\u3057\u307e\u3059\u3002\n\n```python:Grid_and_Random_Search.ipynb\n columns_list = [] \n for i in range(df.shape[1]):\n     columns_list.append(\"a%d\"%i) \n columns_list[1] = \"Target\" \n df.columns = columns_list\n```\n\n### STEP2 \u30c7\u30fc\u30bf\u3092\u5206\u5272\n```python:Grid_and_Random_Search.ipynb\n y = df[\"Target\"].values\n X = df.drop([\"a0\",\"Target\"],axis=1)\n```\ntrain\u30c7\u30fc\u30bf\u3068test\u30c7\u30fc\u30bf\u306b\u5206\u5272\n\n```python:Grid_and_Random_Search.ipynb\n #split X,y to train,test(0.5:0.5)\n from sklearn.cross_validation import train_test_split\n\n X_train,X_test,y_train,y_test = train_test_split(X,y,test_size=0.5,random_state=2017)\n```\n\n\n### STEP3 \u30c7\u30d5\u30a9\u30eb\u30c8\u306e\u72b6\u614b\u3067\u306e\u30e2\u30c7\u30eb\u306e\u7cbe\u5ea6\u3092\u691c\u67fb\u3057\u3066\u307f\u308b.\n\n```python:Grid_and_Random_Search.ipynb\n from sklearn.metrics import classification_report\n\n def model_check(model):\n     model.fit(X_train,y_train)\n     y_train_pred = classification_report(y_train,model.predict(X_train))\n     y_test_pred  = classification_report(y_test,model.predict(X_test))\n        \n     print(\"\"\"\u3010{model_name}\u3011\\n Train Accuracy: \\n{train}\n           \\n Test Accuracy:  \\n{test}\"\"\".format(model_name=model.__class__.__name__, train=y_train_pred, test=y_test_pred))\n\nprint(model_check(RandomForestClassifier()))\n```\n```python:\u51fa\u529b\u7d50\u679c1(\u30c7\u30d5\u30a9\u30eb\u30c8)\n    [RandomForestClassifier]\n     Train Accuracy: \n                 precision    recall  f1-score   support\n\n              B       1.00      1.00      1.00        67\n              M       1.00      1.00      1.00        75\n\n    avg / total       1.00      1.00      1.00       142\n\n\n     Test Accuracy:  \n                 precision    recall  f1-score   support\n\n              B       0.89      0.93      0.91        72\n              M       0.93      0.89      0.91        70\n\n    avg / total       0.91      0.91      0.91       142\n```\nTrain\u30c7\u30fc\u30bf\u306e\u6b63\u7b54\u7387\u306f1.0\u3001Test\u30c7\u30fc\u30bf\u306e\u6b63\u7b54\u7387\u306f0.91\u3060\u3068\u3044\u3046\u3053\u3068\u304c\u308f\u304b\u308a\u307e\u3057\u305f\u3002\n\u3053\u3053\u304b\u3089\u30b0\u30ea\u30c3\u30c9\u30b5\u30fc\u30c1\u3068\u30e9\u30f3\u30c0\u30e0\u30b5\u30fc\u30c1\u3092\u5b9f\u88c5\u3057\u3066\u3044\u304d\u307e\u3059\u3002\n\u4ee5\u964d\u306f\u53c2\u8003\u6587\u732e3\u3092\u53c2\u8003\u306b\u3057\u3066\u3044\u307e\u3059\u3002\n\n### STEP4 \u30b0\u30ea\u30c3\u30c9\u30b5\u30fc\u30c1\n```python:Grid_and_Random_Search.ipynb\n #Grid search\n\n from sklearn.grid_search import GridSearchCV\n\n # use a full grid over all parameters\n param_grid = {\"max_depth\": [2,3, None],\n              \"n_estimators\":[50,100,200,300,400,500],\n              \"max_features\": [1, 3, 10],\n              \"min_samples_split\": [2, 3, 10],\n              \"min_samples_leaf\": [1, 3, 10],\n              \"bootstrap\": [True, False],\n              \"criterion\": [\"gini\", \"entropy\"]}\n\n forest_grid = GridSearchCV(estimator=RandomForestClassifier(random_state=0),\n                 param_grid = param_grid,   \n                 scoring=\"accuracy\",  #metrics\n                 cv = 3,              #cross-validation\n                 n_jobs = 1)          #number of core\n\n forest_grid.fit(X_train,y_train) #fit\n\n forest_grid_best = forest_grid.best_estimator_ #best estimator\n print(\"Best Model Parameter: \",forest_grid.best_params_)\n```\n\n```python:\u51fa\u529b\u7d50\u679c2(\u30b0\u30ea\u30c3\u30c9\u30b5\u30fc\u30c1)\n    [RandomForestClassifier]\n     Train Accuracy: \n                 precision    recall  f1-score   support\n\n              B       0.99      0.99      0.99        67\n              M       0.99      0.99      0.99        75\n\n    avg / total       0.99      0.99      0.99       142\n\n\n     Test Accuracy:  \n                 precision    recall  f1-score   support\n\n              B       0.96      0.89      0.92        72\n              M       0.89      0.96      0.92        70\n\n    avg / total       0.92      0.92      0.92       142\n```\n\u5408\u8a08\u306e\u6b63\u7b54\u7387\u3084\u3001f1-score\u306a\u3069\u5168\u3066\u306e\u7cbe\u5ea6\u304c\u4e0a\u6607\u3057\u3066\u3044\u307e\u3059\uff01\uff01\n\n### STEP5 \u30e9\u30f3\u30c0\u30e0\u30b5\u30fc\u30c1\n\u30e9\u30f3\u30c0\u30e0\u30b5\u30fc\u30c1\u3067\u306f\u3001scipy\u3092\u4f7f\u3063\u3066\u30d1\u30e9\u30e1\u30fc\u30bf\u306e\u5f93\u3046\u5206\u5e03\u3092\u8868\u73fe\u3059\u308b\u3002\n\u4eca\u56de\u306f\u3001\u30a4\u30c6\u30ec\u30fc\u30b7\u30e7\u30f3\u56de\u6570\u3092\u30b0\u30ea\u30c3\u30c9\u30b5\u30fc\u30c1\u3068\u540c\u69d8\u306b\u3057\u3066\u3044\u307e\u3059\u3002\n\n```python:Grid_and_Random_Search.ipynb\n#Random search\nfrom sklearn.grid_search import RandomizedSearchCV\nfrom scipy.stats import randint as sp_randint\n\nparam_dist = {\"max_depth\": [3, None],                  #distribution\n              \"n_estimators\":[50,100,200,300,400,500],\n              \"max_features\": sp_randint(1, 11),\n              \"min_samples_split\": sp_randint(2, 11),\n              \"min_samples_leaf\": sp_randint(1, 11),\n              \"bootstrap\": [True, False],\n              \"criterion\": [\"gini\", \"entropy\"]}\n\nforest_random = RandomizedSearchCV( estimator=RandomForestClassifier( random_state=0 ),\n                                    param_distributions=param_dist,\n                                    cv=3,              #CV\n                                    n_iter=1944,          #interation num\n                                    scoring=\"accuracy\", #metrics\n                                    n_jobs=1,           #num of core\n                                    verbose=0,          \n                                    random_state=1)\n\nforest_random.fit(X,y)\nforest_random_best = forest_random.best_estimator_ #best estimator\nprint(\"Best Model Parameter: \",forest_random.best_params_)\n```\n```python:\u51fa\u529b\u7d50\u679c3(\u30e9\u30f3\u30c0\u30e0\u30b5\u30fc\u30c1)\n    [RandomForestClassifier]\n     Train Accuracy: \n                 precision    recall  f1-score   support\n\n              B       1.00      1.00      1.00        67\n              M       1.00      1.00      1.00        75\n\n    avg / total       1.00      1.00      1.00       142\n\n\n     Test Accuracy:  \n                 precision    recall  f1-score   support\n\n              B       0.94      0.92      0.93        72\n              M       0.92      0.94      0.93        70\n\n    avg / total       0.93      0.93      0.93       142\n```\n\u30c7\u30d5\u30a9\u30eb\u30c8\u306e\u5834\u5408\u3068\u6bd4\u3079\u308b\u3068\u3001\u3069\u306e\u9805\u76ee\u30822%\u5897\u52a0\u3057\u3066\u3044\u308b\u3053\u3068\u304c\u308f\u304b\u308a\u307e\u3057\u305f\uff01\n\n# \u307e\u3068\u3081\n\u30b0\u30ea\u30c3\u30c9\u30b5\u30fc\u30c1\u3001\u30e9\u30f3\u30c0\u30e0\u30b5\u30fc\u30c1\u3068\u3082\u306b\u7cbe\u5ea6\u304c\u826f\u304f\u306a\u308a\u307e\u3057\u305f\uff01\n\u305f\u3060\u3001\u304a\u305d\u3089\u304f\u4eca\u56de\u306f\u5143\u3005\u7cbe\u5ea6\u304c\u9ad8\u3044\u3088\u3046\u306a\u30c7\u30fc\u30bf\u3092\u9078\u3093\u3060\u305f\u3081\u3001\u52b9\u679c\u304c\u898b\u3048\u3065\u3089\u304f\u306a\u3063\u3066\u3057\u307e\u3063\u305f\u306e\u3067\u306f\u306a\u3044\u304b\u3068\u601d\u3044\u307e\u3059\u3002\n\u7cbe\u5ea6\u304c\u826f\u304f\u306a\u3044\u3088\u3046\u306a\u30c7\u30fc\u30bf\u306b\u8a66\u3057\u3066\u307f\u308b\u3068\u30c1\u30e5\u30fc\u30cb\u30f3\u30b0\u306e\u52b9\u679c\u304c\u5206\u304b\u308a\u3084\u3059\u3044\u304b\u3082\u3057\u308c\u307e\u305b\u3093\u3002\n\n\u30b3\u30fc\u30c9\u5168\u5bb9\u306f\u3001[github](https://github.com/ragAgar/qiita/blob/master/Grid_and_Random_Search.ipynb)\u306b\u30a2\u30c3\u30d7\u30ed\u30fc\u30c9\u3057\u3066\u3042\u308a\u307e\u3059\u3002\n\n\n\u53c2\u8003\u6587\u732e\n1. [Bergstra, J., & Bengio, Y. (2012)](http://www.jmlr.org/papers/volume13/bergstra12a/bergstra12a)\n2. http://qiita.com/SE96UoC5AfUt7uY/items/c81f7cea72a44a7bfd3a\n3. http://scikit-learn.org/stable/auto_examples/model_selection/randomized_search.html\n", "tags": ["Python", "scikit-learn", "\u6a5f\u68b0\u5b66\u7fd2", "MachineLearning"]}