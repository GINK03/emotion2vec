{"context": "\u8a00\u8a9e\u51e6\u7406100\u672c\u30ce\u30c3\u30af 2015\u306e\u300c\u7b2c4\u7ae0 \u5f62\u614b\u7d20\u89e3\u6790 (30\u301c39)\u300d\u3092\u89e3\u3044\u305f\u8a18\u9332\u3067\u3059\u3002\n\n\u74b0\u5883\n\nOS X El Capitan Version 10.11.4 \nPython 3.5.1\n\n\n\u6e96\u5099\n\n\u4f7f\u7528\u3059\u308b\u30e9\u30a4\u30d6\u30e9\u30ea\nimport MeCab\nimport ngram\nimport numpy as np\nimport matplotlib.pyplot as plt\nfrom matplotlib.font_manager import FontProperties\n\n\n\u5f62\u614b\u7d20\u89e3\u6790\u6e08\u307f\u6587\u7ae0\u306e\u30d5\u30a1\u30a4\u30eb\u4fdd\u5b58\n\n\u590f\u76ee\u6f31\u77f3\u306e\u5c0f\u8aac\u300e\u543e\u8f29\u306f\u732b\u3067\u3042\u308b\u300f\u306e\u6587\u7ae0\uff08neko.txt\uff09\u3092MeCab\u3092\u4f7f\u3063\u3066\u5f62\u614b\u7d20\u89e3\u6790\u3057\uff0c\u305d\u306e\u7d50\u679c\u3092neko.txt.mecab\u3068\u3044\u3046\u30d5\u30a1\u30a4\u30eb\u306b\u4fdd\u5b58\u305b\u3088\uff0e\u3053\u306e\u30d5\u30a1\u30a4\u30eb\u3092\u7528\u3044\u3066\uff0c\u4ee5\u4e0b\u306e\u554f\u306b\u5bfe\u5fdc\u3059\u308b\u30d7\u30ed\u30b0\u30e9\u30e0\u3092\u5b9f\u88c5\u305b\u3088\uff0e\n\u306a\u304a\uff0c\u554f\u984c37, 38, 39\u306fmatplotlib\u3082\u3057\u304f\u306fGnuplot\u3092\u7528\u3044\u308b\u3068\u3088\u3044\uff0e\n\nmake_analyzed_file\u3068\u3044\u3046\u95a2\u6570\u3092\u4f5c\u3063\u3066\u5f62\u614b\u7d20\u89e3\u6790\u3092\u884c\u3044\u30d5\u30a1\u30a4\u30eb\u306b\u4fdd\u5b58\u3059\u308b\u3002\u306a\u304a\u3001neko.txt\u306f\u4e88\u3081\u30c0\u30a6\u30f3\u30ed\u30fc\u30c9\u3057\u3066\u3001\u5b9f\u884c\u30d5\u30a1\u30a4\u30eb\u3068\u540c\u4e00\u30d5\u30a9\u30eb\u30c0\u306b\u4fdd\u5b58\u3057\u3066\u3044\u308b\u3082\u306e\u3068\u3059\u308b\u3002\ndef make_analyzed_file(input_file_name: str, output_file_name: str) -> None:\n    \"\"\"\n    \u30d7\u30ec\u30fc\u30f3\u306a\u65e5\u672c\u8a9e\u306e\u6587\u7ae0\u30d5\u30a1\u30a4\u30eb\u3092\u5f62\u614b\u7d20\u89e3\u6790\u3057\u3066\u30d5\u30a1\u30a4\u30eb\u306b\u4fdd\u5b58\u3059\u308b.\n    :param input_file_name \u30d7\u30ec\u30fc\u30f3\u306a\u65e5\u672c\u8a9e\u306e\u6587\u7ae0\u30d5\u30a1\u30a4\u30eb\u540d\n    :param output_file_name \u5f62\u614b\u7d20\u89e3\u6790\u6e08\u307f\u306e\u6587\u7ae0\u30d5\u30a1\u30a4\u30eb\u540d\n    \"\"\"\n    _m = MeCab.Tagger(\"-Ochasen\")\n    with open(input_file_name, encoding='utf-8') as input_file:\n        with open(output_file_name, mode='w', encoding='utf-8') as output_file:\n            output_file.write(_m.parse(input_file.read()))\n\nmake_analyzed_file('neko.txt', 'neko.txt.mecab')\n\n\n30. \u5f62\u614b\u7d20\u89e3\u6790\u7d50\u679c\u306e\u8aad\u307f\u8fbc\u307f\n\n\u5f62\u614b\u7d20\u89e3\u6790\u7d50\u679c\uff08neko.txt.mecab\uff09\u3092\u8aad\u307f\u8fbc\u3080\u30d7\u30ed\u30b0\u30e9\u30e0\u3092\u5b9f\u88c5\u305b\u3088\uff0e\u305f\u3060\u3057\uff0c\u5404\u5f62\u614b\u7d20\u306f\u8868\u5c64\u5f62\uff08surface\uff09\uff0c\u57fa\u672c\u5f62\uff08base\uff09\uff0c\u54c1\u8a5e\uff08pos\uff09\uff0c\u54c1\u8a5e\u7d30\u5206\u985e1\uff08pos1\uff09\u3092\u30ad\u30fc\u3068\u3059\u308b\u30de\u30c3\u30d4\u30f3\u30b0\u578b\u306b\u683c\u7d0d\u3057\uff0c1\u6587\u3092\u5f62\u614b\u7d20\uff08\u30de\u30c3\u30d4\u30f3\u30b0\u578b\uff09\u306e\u30ea\u30b9\u30c8\u3068\u3057\u3066\u8868\u73fe\u305b\u3088\uff0e\u7b2c4\u7ae0\u306e\u6b8b\u308a\u306e\u554f\u984c\u3067\u306f\uff0c\u3053\u3053\u3067\u4f5c\u3063\u305f\u30d7\u30ed\u30b0\u30e9\u30e0\u3092\u6d3b\u7528\u305b\u3088\uff0e\n\n\u5358\u7d14\u306b\u5f62\u614b\u7d20\u89e3\u6790\u7d50\u679c\u3092\u30bf\u30d6\u533a\u5207\u308a\u6587\u5b57\u5217\u304b\u3089\u8f9e\u66f8\u578b\u306b\u5909\u63db\u3057\u305f\u3082\u306e\u3092morphemes\u306b\u30011\u6587\u6bce\u306b\u307e\u3068\u3081\u305f\u3082\u306e\u3092sentences\u306b\u4fdd\u5b58\u3059\u308b\u3002\ndef tabbed_str_to_dict(tabbed_str: str) -> dict:\n    \"\"\"\n    \u4f8b\u3048\u3070\u300c\u6b21\u7b2c\u306b   \u30b7\u30c0\u30a4\u30cb    \u6b21\u7b2c\u306b   \u526f\u8a5e-\u4e00\u822c   \u300d\u306e\u3088\u3046\u306a\u30bf\u30d6\u533a\u5207\u308a\u3067\u5f62\u614b\u7d20\u3092\u8868\u3059\u6587\u5b57\u5217\u3092Dict\u578b\u306b\u5909\u63db\u3059\u308b.\n    :param tabbed_str \u30bf\u30d6\u533a\u5207\u308a\u3067\u5f62\u614b\u7d20\u3092\u8868\u3059\u6587\u5b57\u5217\n    :return Dict\u578b\u3067\u8868\u3055\u308c\u305f\u5f62\u614b\u7d20\n    \"\"\"\n    elements = tabbed_str.split()\n    if 0 < len(elements) < 4:\n        return {'surface': elements[0], 'base': '', 'pos': '', 'pos1': ''}\n    else:\n        return {'surface': elements[0], 'base': elements[1], 'pos': elements[2], 'pos1': elements[3]}\n\n\ndef morphemes_to_sentence(morphemes: list) -> list:\n    \"\"\"\n    Dict\u578b\u3067\u8868\u3055\u308c\u305f\u5f62\u614b\u7d20\u306e\u30ea\u30b9\u30c8\u3092\u53e5\u70b9\u6bce\u306b\u30b0\u30eb\u30fc\u30d4\u30f3\u30b0\u3057\u3001\u30ea\u30b9\u30c8\u5316\u3059\u308b.\n    :param morphemes Dict\u578b\u3067\u8868\u3055\u308c\u305f\u5f62\u614b\u7d20\u306e\u30ea\u30b9\u30c8\n    :return \u6587\u7ae0\u306e\u30ea\u30b9\u30c8\n    \"\"\"\n    sentences = []\n    sentence = []\n\n    for morpheme in morphemes:\n        sentence.append(morpheme)\n        if morpheme['pos1'] == '\u8a18\u53f7-\u53e5\u70b9':\n            sentences.append(sentence)\n            sentence = []\n\n    return sentences\n\n\nwith open('neko.txt.mecab', encoding='utf-8') as file_wrapper:\n    morphemes = [tabbed_str_to_dict(line) for line in file_wrapper]\n\nsentences = morphemes_to_sentence(morphemes)\n\n# \u7d50\u679c\u306e\u78ba\u8a8d\nprint(morphemes[::100])\nprint(sentences[::100])\n\n\n31. \u52d5\u8a5e / 32. \u52d5\u8a5e\u306e\u539f\u5f62 / 33. \u30b5\u5909\u540d\u8a5e\n\n\u52d5\u8a5e\u306e\u8868\u5c64\u5f62\u3092\u3059\u3079\u3066\u62bd\u51fa\u305b\u3088\uff0e\n\u52d5\u8a5e\u306e\u539f\u5f62\u3092\u3059\u3079\u3066\u62bd\u51fa\u305b\u3088\uff0e\n\u30b5\u5909\u63a5\u7d9a\u306e\u540d\u8a5e\u3092\u3059\u3079\u3066\u62bd\u51fa\u305b\u3088\uff0e\n\n\u300c30. \u5f62\u614b\u7d20\u89e3\u6790\u7d50\u679c\u306e\u8aad\u307f\u8fbc\u307f\u300d\u3067\u4f5c\u3063\u305fmorphemes\u3092\u4f7f\u3048\u3070\u7c21\u5358\u3067\u3059\u3002\nverbs_surface = [morpheme['surface'] for morpheme in morphemes if morpheme['pos1'].find('\u52d5\u8a5e') == 0]\nverbs_base = [morpheme['base'] for morpheme in morphemes if morpheme['pos1'].find('\u52d5\u8a5e') == 0]\nnouns_suru = [morpheme['surface'] for morpheme in morphemes if morpheme['pos1'] == '\u540d\u8a5e-\u30b5\u5909\u63a5\u7d9a']\n\n# \u7d50\u679c\u306e\u78ba\u8a8d\nprint(verbs_surface[::100])\nprint(verbs_base[::100])\nprint(nouns_suru[::100])\n\n\n34. \u300cA\u306eB\u300d\n\n2\u3064\u306e\u540d\u8a5e\u304c\u300c\u306e\u300d\u3067\u9023\u7d50\u3055\u308c\u3066\u3044\u308b\u540d\u8a5e\u53e5\u3092\u62bd\u51fa\u305b\u3088\uff0e\n\ndef ngramed_list(lst: list, n: int = 3) -> list:\n    \"\"\"\n    list\u3092N\u30b0\u30e9\u30e0\u5316\u3059\u308b.\n    :param lst N\u30b0\u30e9\u30e0\u5316\u5bfe\u8c61\u306e\u30ea\u30b9\u30c8\n    :param n N (\u30c7\u30d5\u30a9\u30eb\u30c8\u306f N = 3)\n    :return N\u30b0\u30e9\u30e0\u5316\u6e08\u307f\u306e\u30ea\u30b9\u30c8\n    \"\"\"\n    index = ngram.NGram(N=n)\n    return [term for term in index.ngrams(lst)]\n\n\ndef is_noun_no_noun(words: list) -> bool:\n    \"\"\"\n    3\u3064\u306e\u5358\u8a9e\u304b\u3089\u6210\u308b\u30ea\u30b9\u30c8\u304c\u300c\u540d\u8a5e-\u306e-\u540d\u8a5e\u300d\u3068\u3044\u3046\u69cb\u6210\u306b\u306a\u3063\u3066\u3044\u308b\u304b\u3092\u5224\u5b9a\u3059\u308b.\n    :param words 3\u3064\u306e\u5358\u8a9e\u304b\u3089\u6210\u308b\u30ea\u30b9\u30c8\n    :return bool (True:\u300c\u540d\u8a5e-\u306e-\u540d\u8a5e\u300d\u3068\u3044\u3046\u69cb\u6210\u306b\u306a\u3063\u3066\u3044\u308b / False:\u300c\u540d\u8a5e-\u306e-\u540d\u8a5e\u300d\u3068\u3044\u3046\u69cb\u6210\u306b\u306a\u3063\u3066\u3044\u306a\u3044)\n    \"\"\"\n    return (type(words) == list) and (len(words) == 3) and \\\n           (words[0]['pos1'].find('\u540d\u8a5e') == 0) and \\\n           (words[1]['surface'] == '\u306e') and \\\n           (words[2]['pos1'].find('\u540d\u8a5e') == 0)\n\n\n# \u300c\u540d\u8a5e-\u306e-\u540d\u8a5e\u300d\u3092\u542b\u3080N\u30b0\u30e9\u30e0\u306e\u307f\u3092\u62bd\u51fa\nnoun_no_noun = [ngrams for ngrams in ngramed_list(morphemes) if is_noun_no_noun(ngrams)]\n\n# \u8868\u5c64\u3092\u53d6\u308a\u51fa\u3057\u3066\u7d50\u5408\u3059\u308b\nnoun_no_noun = [''.join([word['surface'] for word in ngram]) for ngram in noun_no_noun]\n\n# \u7d50\u679c\u306e\u78ba\u8a8d\nprint(noun_no_noun[::100])\n\n\n35. \u540d\u8a5e\u306e\u9023\u63a5\n\n\u540d\u8a5e\u306e\u9023\u63a5\uff08\u9023\u7d9a\u3057\u3066\u51fa\u73fe\u3059\u308b\u540d\u8a5e\uff09\u3092\u6700\u9577\u4e00\u81f4\u3067\u62bd\u51fa\u305b\u3088\uff0e\n\ndef morphemes_to_noun_array(morphemes: list) -> list:\n    \"\"\"\n    \u8f9e\u66f8\u578b\u3067\u8868\u3055\u308c\u305f\u5f62\u614b\u7d20\u306e\u30ea\u30b9\u30c8\u3092\u53e5\u70b9\u3082\u3057\u304f\u306f\u540d\u8a5e\u4ee5\u5916\u306e\u5f62\u614b\u7d20\u3067\u533a\u5207\u3063\u3066\u30b0\u30eb\u30fc\u30d4\u30f3\u30b0\u3057\u3001\u30ea\u30b9\u30c8\u5316\u3059\u308b.\n    :param morphemes \u8f9e\u66f8\u578b\u3067\u8868\u3055\u308c\u305f\u5f62\u614b\u7d20\u306e\u30ea\u30b9\u30c8\n    :return \u540d\u8a5e\u306e\u9023\u63a5\u306e\u30ea\u30b9\u30c8\n    \"\"\"\n    nouns_list = []\n    nouns = []\n\n    for morpheme in morphemes:\n        if morpheme['pos1'].find('\u540d\u8a5e') >= 0:\n            nouns.append(morpheme)\n        elif (morpheme['pos1'] == '\u8a18\u53f7-\u53e5\u70b9') | (morpheme['pos1'].find('\u540d\u8a5e') < 0):\n            nouns_list.append(nouns)\n            nouns = []\n\n    return [nouns for nouns in nouns_list if len(nouns) > 1]\n\n\nnoun_array = [''.join([noun['surface'] for noun in nouns]) for nouns in morphemes_to_noun_array(morphemes)]\n\n# \u7d50\u679c\u306e\u78ba\u8a8d\nprint(noun_array[::100])\n\n\n36. \u5358\u8a9e\u306e\u51fa\u73fe\u983b\u5ea6\n\n\u6587\u7ae0\u4e2d\u306b\u51fa\u73fe\u3059\u308b\u5358\u8a9e\u3068\u305d\u306e\u51fa\u73fe\u983b\u5ea6\u3092\u6c42\u3081\uff0c\u51fa\u73fe\u983b\u5ea6\u306e\u9ad8\u3044\u9806\u306b\u4e26\u3079\u3088\uff0e\n\ndef get_frequency(words: list) -> dict:\n    \"\"\"\n    \u5358\u8a9e\u306e\u30ea\u30b9\u30c8\u3092\u53d7\u3051\u53d6\u3063\u3066\u3001\u5358\u8a9e\u3092\u30ad\u30fc\u3068\u3057\u3066\u3001\u983b\u5ea6\u3092\u30d0\u30ea\u30e5\u30fc\u3068\u3059\u308b\u8f9e\u66f8\u3092\u8fd4\u3059.\n    :param words \u5358\u8a9e\u306e\u30ea\u30b9\u30c8\n    :return dict \u5358\u8a9e\u3092\u30ad\u30fc\u3068\u3057\u3066\u3001\u983b\u5ea6\u3092\u30d0\u30ea\u30e5\u30fc\u3068\u3059\u308b\u8f9e\u66f8\n    \"\"\"\n    frequency = {}\n    for word in words:\n        if frequency.get(word):\n            frequency[word] += 1\n        else:\n            frequency[word] = 1\n\n    return frequency\n\n\nfrequency = get_frequency([morpheme['surface'] for morpheme in morphemes])\n\n# \u30bd\u30fc\u30c8\nfrequency = [(k, v) for k, v in sorted(frequency.items(), key=lambda x: x[1], reverse=True)]\n\n# \u7d50\u679c\u306e\u78ba\u8a8d\nprint(frequency[0:20])\n\n\n37. \u983b\u5ea6\u4e0a\u4f4d10\u8a9e / 38. \u30d2\u30b9\u30c8\u30b0\u30e9\u30e0 / 39. Zipf\u306e\u6cd5\u5247\n\n\u51fa\u73fe\u983b\u5ea6\u304c\u9ad8\u304410\u8a9e\u3068\u305d\u306e\u51fa\u73fe\u983b\u5ea6\u3092\u30b0\u30e9\u30d5\uff08\u4f8b\u3048\u3070\u68d2\u30b0\u30e9\u30d5\u306a\u3069\uff09\u3067\u8868\u793a\u305b\u3088\uff0e\n\u5358\u8a9e\u306e\u51fa\u73fe\u983b\u5ea6\u306e\u30d2\u30b9\u30c8\u30b0\u30e9\u30e0\uff08\u6a2a\u8ef8\u306b\u51fa\u73fe\u983b\u5ea6\uff0c\u7e26\u8ef8\u306b\u51fa\u73fe\u983b\u5ea6\u3092\u3068\u308b\u5358\u8a9e\u306e\u7a2e\u985e\u6570\u3092\u68d2\u30b0\u30e9\u30d5\u3067\u8868\u3057\u305f\u3082\u306e\uff09\u3092\u63cf\u3051\uff0e\n\u5358\u8a9e\u306e\u51fa\u73fe\u983b\u5ea6\u9806\u4f4d\u3092\u6a2a\u8ef8\uff0c\u305d\u306e\u51fa\u73fe\u983b\u5ea6\u3092\u7e26\u8ef8\u3068\u3057\u3066\uff0c\u4e21\u5bfe\u6570\u30b0\u30e9\u30d5\u3092\u30d7\u30ed\u30c3\u30c8\u305b\u3088\uff0e\n\n\u30b0\u30e9\u30d5\u7cfb\u306f\u307e\u3068\u3081\u3066\u51fa\u3057\u3066\u3057\u307e\u3044\u307e\u3059\u3002\nfig = plt.figure(figsize=(20, 6))\n\n# 37. \u51fa\u73fe\u983b\u5ea6\u304c\u9ad8\u304410\u8a9e\u3068\u305d\u306e\u51fa\u73fe\u983b\u5ea6\u3092\u30b0\u30e9\u30d5\uff08\u4f8b\u3048\u3070\u68d2\u30b0\u30e9\u30d5\u306a\u3069\uff09\u3067\u8868\u793a\u305b\u3088\uff0e\nwords = [f[0] for f in frequency[0:10]]\nx_pos = np.arange(len(words))\nfp = FontProperties(fname=r'/Library/Fonts/\u30d2\u30e9\u30ae\u30ce\u4e38\u30b4 ProN W4.ttc', size=14)\n\nax1 = fig.add_subplot(131)\nax1.bar(x_pos, [f[1] for f in frequency[0:10]], align='center', alpha=0.4)\nax1.set_xticks(x_pos)\nax1.set_xticklabels(words, fontproperties=fp)\nax1.set_ylabel('Frequency')\nax1.set_title('Top 10 frequent words')\n\n# 38. \u5358\u8a9e\u306e\u51fa\u73fe\u983b\u5ea6\u306e\u30d2\u30b9\u30c8\u30b0\u30e9\u30e0\uff08\u6a2a\u8ef8\u306b\u51fa\u73fe\u983b\u5ea6\uff0c\u7e26\u8ef8\u306b\u51fa\u73fe\u983b\u5ea6\u3092\u3068\u308b\u5358\u8a9e\u306e\u7a2e\u985e\u6570\u3092\u68d2\u30b0\u30e9\u30d5\u3067\u8868\u3057\u305f\u3082\u306e\uff09\u3092\u63cf\u3051\uff0e\nfreq = list(dict(frequency).values())\nfreq.sort(reverse=True)\n\nax2 = fig.add_subplot(132)\nax2.hist(freq, bins=50, range=(0, 50))\nax2.set_title('Histogram of word count')\nax2.set_xlabel('Word count')\nax2.set_ylabel('Frequency')\n\n# 39. \u5358\u8a9e\u306e\u51fa\u73fe\u983b\u5ea6\u9806\u4f4d\u3092\u6a2a\u8ef8\uff0c\u305d\u306e\u51fa\u73fe\u983b\u5ea6\u3092\u7e26\u8ef8\u3068\u3057\u3066\uff0c\u4e21\u5bfe\u6570\u30b0\u30e9\u30d5\u3092\u30d7\u30ed\u30c3\u30c8\u305b\u3088\uff0e\nrank = list(range(1, len(freq) + 1))\n\nax3 = fig.add_subplot(133)\nax3.plot(freq, rank)\nax3.set_xlabel('Rank')\nax3.set_ylabel('Frequency')\nax3.set_title('Zipf low')\nax3.set_xscale('log')\nax3.set_yscale('log')\n\nfig.savefig('morphological_analysis.png')\n\n\n<a href=\"http://www.cl.ecei.tohoku.ac.jp/nlp100/\" target=\"_blank\">\u8a00\u8a9e\u51e6\u7406100\u672c\u30ce\u30c3\u30af 2015</a>\u306e\u300c\u7b2c4\u7ae0 \u5f62\u614b\u7d20\u89e3\u6790 (30\u301c39)\u300d\u3092\u89e3\u3044\u305f\u8a18\u9332\u3067\u3059\u3002\n\n### \u74b0\u5883\n\n- OS X El Capitan Version 10.11.4 \n- Python 3.5.1\n\n\n# \u6e96\u5099\n\n### \u4f7f\u7528\u3059\u308b\u30e9\u30a4\u30d6\u30e9\u30ea\n\n```py3\nimport MeCab\nimport ngram\nimport numpy as np\nimport matplotlib.pyplot as plt\nfrom matplotlib.font_manager import FontProperties\n```\n\n### \u5f62\u614b\u7d20\u89e3\u6790\u6e08\u307f\u6587\u7ae0\u306e\u30d5\u30a1\u30a4\u30eb\u4fdd\u5b58\n\n> \u590f\u76ee\u6f31\u77f3\u306e\u5c0f\u8aac\u300e\u543e\u8f29\u306f\u732b\u3067\u3042\u308b\u300f\u306e\u6587\u7ae0\uff08<a href=\"http://www.cl.ecei.tohoku.ac.jp/nlp100/data/neko.txt\" target=\"_blank\">neko.txt</a>\uff09\u3092MeCab\u3092\u4f7f\u3063\u3066\u5f62\u614b\u7d20\u89e3\u6790\u3057\uff0c\u305d\u306e\u7d50\u679c\u3092neko.txt.mecab\u3068\u3044\u3046\u30d5\u30a1\u30a4\u30eb\u306b\u4fdd\u5b58\u305b\u3088\uff0e\u3053\u306e\u30d5\u30a1\u30a4\u30eb\u3092\u7528\u3044\u3066\uff0c\u4ee5\u4e0b\u306e\u554f\u306b\u5bfe\u5fdc\u3059\u308b\u30d7\u30ed\u30b0\u30e9\u30e0\u3092\u5b9f\u88c5\u305b\u3088\uff0e\n\u306a\u304a\uff0c\u554f\u984c37, 38, 39\u306fmatplotlib\u3082\u3057\u304f\u306fGnuplot\u3092\u7528\u3044\u308b\u3068\u3088\u3044\uff0e\n\nmake_analyzed_file\u3068\u3044\u3046\u95a2\u6570\u3092\u4f5c\u3063\u3066\u5f62\u614b\u7d20\u89e3\u6790\u3092\u884c\u3044\u30d5\u30a1\u30a4\u30eb\u306b\u4fdd\u5b58\u3059\u308b\u3002\u306a\u304a\u3001neko.txt\u306f\u4e88\u3081\u30c0\u30a6\u30f3\u30ed\u30fc\u30c9\u3057\u3066\u3001\u5b9f\u884c\u30d5\u30a1\u30a4\u30eb\u3068\u540c\u4e00\u30d5\u30a9\u30eb\u30c0\u306b\u4fdd\u5b58\u3057\u3066\u3044\u308b\u3082\u306e\u3068\u3059\u308b\u3002\n\n```py3\ndef make_analyzed_file(input_file_name: str, output_file_name: str) -> None:\n    \"\"\"\n    \u30d7\u30ec\u30fc\u30f3\u306a\u65e5\u672c\u8a9e\u306e\u6587\u7ae0\u30d5\u30a1\u30a4\u30eb\u3092\u5f62\u614b\u7d20\u89e3\u6790\u3057\u3066\u30d5\u30a1\u30a4\u30eb\u306b\u4fdd\u5b58\u3059\u308b.\n    :param input_file_name \u30d7\u30ec\u30fc\u30f3\u306a\u65e5\u672c\u8a9e\u306e\u6587\u7ae0\u30d5\u30a1\u30a4\u30eb\u540d\n    :param output_file_name \u5f62\u614b\u7d20\u89e3\u6790\u6e08\u307f\u306e\u6587\u7ae0\u30d5\u30a1\u30a4\u30eb\u540d\n    \"\"\"\n    _m = MeCab.Tagger(\"-Ochasen\")\n    with open(input_file_name, encoding='utf-8') as input_file:\n        with open(output_file_name, mode='w', encoding='utf-8') as output_file:\n            output_file.write(_m.parse(input_file.read()))\n\nmake_analyzed_file('neko.txt', 'neko.txt.mecab')\n```\n\n# 30. \u5f62\u614b\u7d20\u89e3\u6790\u7d50\u679c\u306e\u8aad\u307f\u8fbc\u307f\n\n> \u5f62\u614b\u7d20\u89e3\u6790\u7d50\u679c\uff08neko.txt.mecab\uff09\u3092\u8aad\u307f\u8fbc\u3080\u30d7\u30ed\u30b0\u30e9\u30e0\u3092\u5b9f\u88c5\u305b\u3088\uff0e\u305f\u3060\u3057\uff0c\u5404\u5f62\u614b\u7d20\u306f\u8868\u5c64\u5f62\uff08surface\uff09\uff0c\u57fa\u672c\u5f62\uff08base\uff09\uff0c\u54c1\u8a5e\uff08pos\uff09\uff0c\u54c1\u8a5e\u7d30\u5206\u985e1\uff08pos1\uff09\u3092\u30ad\u30fc\u3068\u3059\u308b\u30de\u30c3\u30d4\u30f3\u30b0\u578b\u306b\u683c\u7d0d\u3057\uff0c1\u6587\u3092\u5f62\u614b\u7d20\uff08\u30de\u30c3\u30d4\u30f3\u30b0\u578b\uff09\u306e\u30ea\u30b9\u30c8\u3068\u3057\u3066\u8868\u73fe\u305b\u3088\uff0e\u7b2c4\u7ae0\u306e\u6b8b\u308a\u306e\u554f\u984c\u3067\u306f\uff0c\u3053\u3053\u3067\u4f5c\u3063\u305f\u30d7\u30ed\u30b0\u30e9\u30e0\u3092\u6d3b\u7528\u305b\u3088\uff0e\n\n\u5358\u7d14\u306b\u5f62\u614b\u7d20\u89e3\u6790\u7d50\u679c\u3092\u30bf\u30d6\u533a\u5207\u308a\u6587\u5b57\u5217\u304b\u3089\u8f9e\u66f8\u578b\u306b\u5909\u63db\u3057\u305f\u3082\u306e\u3092`morphemes`\u306b\u30011\u6587\u6bce\u306b\u307e\u3068\u3081\u305f\u3082\u306e\u3092`sentences`\u306b\u4fdd\u5b58\u3059\u308b\u3002\n\n```py3\ndef tabbed_str_to_dict(tabbed_str: str) -> dict:\n    \"\"\"\n    \u4f8b\u3048\u3070\u300c\u6b21\u7b2c\u306b\t\u30b7\u30c0\u30a4\u30cb\t\u6b21\u7b2c\u306b\t\u526f\u8a5e-\u4e00\u822c\t\u300d\u306e\u3088\u3046\u306a\u30bf\u30d6\u533a\u5207\u308a\u3067\u5f62\u614b\u7d20\u3092\u8868\u3059\u6587\u5b57\u5217\u3092Dict\u578b\u306b\u5909\u63db\u3059\u308b.\n    :param tabbed_str \u30bf\u30d6\u533a\u5207\u308a\u3067\u5f62\u614b\u7d20\u3092\u8868\u3059\u6587\u5b57\u5217\n    :return Dict\u578b\u3067\u8868\u3055\u308c\u305f\u5f62\u614b\u7d20\n    \"\"\"\n    elements = tabbed_str.split()\n    if 0 < len(elements) < 4:\n        return {'surface': elements[0], 'base': '', 'pos': '', 'pos1': ''}\n    else:\n        return {'surface': elements[0], 'base': elements[1], 'pos': elements[2], 'pos1': elements[3]}\n\n\ndef morphemes_to_sentence(morphemes: list) -> list:\n    \"\"\"\n    Dict\u578b\u3067\u8868\u3055\u308c\u305f\u5f62\u614b\u7d20\u306e\u30ea\u30b9\u30c8\u3092\u53e5\u70b9\u6bce\u306b\u30b0\u30eb\u30fc\u30d4\u30f3\u30b0\u3057\u3001\u30ea\u30b9\u30c8\u5316\u3059\u308b.\n    :param morphemes Dict\u578b\u3067\u8868\u3055\u308c\u305f\u5f62\u614b\u7d20\u306e\u30ea\u30b9\u30c8\n    :return \u6587\u7ae0\u306e\u30ea\u30b9\u30c8\n    \"\"\"\n    sentences = []\n    sentence = []\n\n    for morpheme in morphemes:\n        sentence.append(morpheme)\n        if morpheme['pos1'] == '\u8a18\u53f7-\u53e5\u70b9':\n            sentences.append(sentence)\n            sentence = []\n\n    return sentences\n\n\nwith open('neko.txt.mecab', encoding='utf-8') as file_wrapper:\n    morphemes = [tabbed_str_to_dict(line) for line in file_wrapper]\n\nsentences = morphemes_to_sentence(morphemes)\n\n# \u7d50\u679c\u306e\u78ba\u8a8d\nprint(morphemes[::100])\nprint(sentences[::100])\n```\n\n# 31. \u52d5\u8a5e / 32. \u52d5\u8a5e\u306e\u539f\u5f62 / 33. \u30b5\u5909\u540d\u8a5e\n\n> \u52d5\u8a5e\u306e\u8868\u5c64\u5f62\u3092\u3059\u3079\u3066\u62bd\u51fa\u305b\u3088\uff0e\n> \u52d5\u8a5e\u306e\u539f\u5f62\u3092\u3059\u3079\u3066\u62bd\u51fa\u305b\u3088\uff0e\n> \u30b5\u5909\u63a5\u7d9a\u306e\u540d\u8a5e\u3092\u3059\u3079\u3066\u62bd\u51fa\u305b\u3088\uff0e\n\n\u300c30. \u5f62\u614b\u7d20\u89e3\u6790\u7d50\u679c\u306e\u8aad\u307f\u8fbc\u307f\u300d\u3067\u4f5c\u3063\u305f`morphemes`\u3092\u4f7f\u3048\u3070\u7c21\u5358\u3067\u3059\u3002\n\n```py3\nverbs_surface = [morpheme['surface'] for morpheme in morphemes if morpheme['pos1'].find('\u52d5\u8a5e') == 0]\nverbs_base = [morpheme['base'] for morpheme in morphemes if morpheme['pos1'].find('\u52d5\u8a5e') == 0]\nnouns_suru = [morpheme['surface'] for morpheme in morphemes if morpheme['pos1'] == '\u540d\u8a5e-\u30b5\u5909\u63a5\u7d9a']\n\n# \u7d50\u679c\u306e\u78ba\u8a8d\nprint(verbs_surface[::100])\nprint(verbs_base[::100])\nprint(nouns_suru[::100])\n```\n\n# 34. \u300cA\u306eB\u300d\n\n>2\u3064\u306e\u540d\u8a5e\u304c\u300c\u306e\u300d\u3067\u9023\u7d50\u3055\u308c\u3066\u3044\u308b\u540d\u8a5e\u53e5\u3092\u62bd\u51fa\u305b\u3088\uff0e\n\n```py3\ndef ngramed_list(lst: list, n: int = 3) -> list:\n    \"\"\"\n    list\u3092N\u30b0\u30e9\u30e0\u5316\u3059\u308b.\n    :param lst N\u30b0\u30e9\u30e0\u5316\u5bfe\u8c61\u306e\u30ea\u30b9\u30c8\n    :param n N (\u30c7\u30d5\u30a9\u30eb\u30c8\u306f N = 3)\n    :return N\u30b0\u30e9\u30e0\u5316\u6e08\u307f\u306e\u30ea\u30b9\u30c8\n    \"\"\"\n    index = ngram.NGram(N=n)\n    return [term for term in index.ngrams(lst)]\n\n\ndef is_noun_no_noun(words: list) -> bool:\n    \"\"\"\n    3\u3064\u306e\u5358\u8a9e\u304b\u3089\u6210\u308b\u30ea\u30b9\u30c8\u304c\u300c\u540d\u8a5e-\u306e-\u540d\u8a5e\u300d\u3068\u3044\u3046\u69cb\u6210\u306b\u306a\u3063\u3066\u3044\u308b\u304b\u3092\u5224\u5b9a\u3059\u308b.\n    :param words 3\u3064\u306e\u5358\u8a9e\u304b\u3089\u6210\u308b\u30ea\u30b9\u30c8\n    :return bool (True:\u300c\u540d\u8a5e-\u306e-\u540d\u8a5e\u300d\u3068\u3044\u3046\u69cb\u6210\u306b\u306a\u3063\u3066\u3044\u308b / False:\u300c\u540d\u8a5e-\u306e-\u540d\u8a5e\u300d\u3068\u3044\u3046\u69cb\u6210\u306b\u306a\u3063\u3066\u3044\u306a\u3044)\n    \"\"\"\n    return (type(words) == list) and (len(words) == 3) and \\\n           (words[0]['pos1'].find('\u540d\u8a5e') == 0) and \\\n           (words[1]['surface'] == '\u306e') and \\\n           (words[2]['pos1'].find('\u540d\u8a5e') == 0)\n\n\n# \u300c\u540d\u8a5e-\u306e-\u540d\u8a5e\u300d\u3092\u542b\u3080N\u30b0\u30e9\u30e0\u306e\u307f\u3092\u62bd\u51fa\nnoun_no_noun = [ngrams for ngrams in ngramed_list(morphemes) if is_noun_no_noun(ngrams)]\n\n# \u8868\u5c64\u3092\u53d6\u308a\u51fa\u3057\u3066\u7d50\u5408\u3059\u308b\nnoun_no_noun = [''.join([word['surface'] for word in ngram]) for ngram in noun_no_noun]\n\n# \u7d50\u679c\u306e\u78ba\u8a8d\nprint(noun_no_noun[::100])\n```\n\n# 35. \u540d\u8a5e\u306e\u9023\u63a5\n\n> \u540d\u8a5e\u306e\u9023\u63a5\uff08\u9023\u7d9a\u3057\u3066\u51fa\u73fe\u3059\u308b\u540d\u8a5e\uff09\u3092\u6700\u9577\u4e00\u81f4\u3067\u62bd\u51fa\u305b\u3088\uff0e\n\n```py3\ndef morphemes_to_noun_array(morphemes: list) -> list:\n    \"\"\"\n    \u8f9e\u66f8\u578b\u3067\u8868\u3055\u308c\u305f\u5f62\u614b\u7d20\u306e\u30ea\u30b9\u30c8\u3092\u53e5\u70b9\u3082\u3057\u304f\u306f\u540d\u8a5e\u4ee5\u5916\u306e\u5f62\u614b\u7d20\u3067\u533a\u5207\u3063\u3066\u30b0\u30eb\u30fc\u30d4\u30f3\u30b0\u3057\u3001\u30ea\u30b9\u30c8\u5316\u3059\u308b.\n    :param morphemes \u8f9e\u66f8\u578b\u3067\u8868\u3055\u308c\u305f\u5f62\u614b\u7d20\u306e\u30ea\u30b9\u30c8\n    :return \u540d\u8a5e\u306e\u9023\u63a5\u306e\u30ea\u30b9\u30c8\n    \"\"\"\n    nouns_list = []\n    nouns = []\n\n    for morpheme in morphemes:\n        if morpheme['pos1'].find('\u540d\u8a5e') >= 0:\n            nouns.append(morpheme)\n        elif (morpheme['pos1'] == '\u8a18\u53f7-\u53e5\u70b9') | (morpheme['pos1'].find('\u540d\u8a5e') < 0):\n            nouns_list.append(nouns)\n            nouns = []\n\n    return [nouns for nouns in nouns_list if len(nouns) > 1]\n\n\nnoun_array = [''.join([noun['surface'] for noun in nouns]) for nouns in morphemes_to_noun_array(morphemes)]\n\n# \u7d50\u679c\u306e\u78ba\u8a8d\nprint(noun_array[::100])\n```\n\n# 36. \u5358\u8a9e\u306e\u51fa\u73fe\u983b\u5ea6\n\n> \u6587\u7ae0\u4e2d\u306b\u51fa\u73fe\u3059\u308b\u5358\u8a9e\u3068\u305d\u306e\u51fa\u73fe\u983b\u5ea6\u3092\u6c42\u3081\uff0c\u51fa\u73fe\u983b\u5ea6\u306e\u9ad8\u3044\u9806\u306b\u4e26\u3079\u3088\uff0e\n\n```py3\ndef get_frequency(words: list) -> dict:\n    \"\"\"\n    \u5358\u8a9e\u306e\u30ea\u30b9\u30c8\u3092\u53d7\u3051\u53d6\u3063\u3066\u3001\u5358\u8a9e\u3092\u30ad\u30fc\u3068\u3057\u3066\u3001\u983b\u5ea6\u3092\u30d0\u30ea\u30e5\u30fc\u3068\u3059\u308b\u8f9e\u66f8\u3092\u8fd4\u3059.\n    :param words \u5358\u8a9e\u306e\u30ea\u30b9\u30c8\n    :return dict \u5358\u8a9e\u3092\u30ad\u30fc\u3068\u3057\u3066\u3001\u983b\u5ea6\u3092\u30d0\u30ea\u30e5\u30fc\u3068\u3059\u308b\u8f9e\u66f8\n    \"\"\"\n    frequency = {}\n    for word in words:\n        if frequency.get(word):\n            frequency[word] += 1\n        else:\n            frequency[word] = 1\n\n    return frequency\n\n\nfrequency = get_frequency([morpheme['surface'] for morpheme in morphemes])\n\n# \u30bd\u30fc\u30c8\nfrequency = [(k, v) for k, v in sorted(frequency.items(), key=lambda x: x[1], reverse=True)]\n\n# \u7d50\u679c\u306e\u78ba\u8a8d\nprint(frequency[0:20])\n```\n\n# 37. \u983b\u5ea6\u4e0a\u4f4d10\u8a9e / 38. \u30d2\u30b9\u30c8\u30b0\u30e9\u30e0 / 39. Zipf\u306e\u6cd5\u5247\n\n> \u51fa\u73fe\u983b\u5ea6\u304c\u9ad8\u304410\u8a9e\u3068\u305d\u306e\u51fa\u73fe\u983b\u5ea6\u3092\u30b0\u30e9\u30d5\uff08\u4f8b\u3048\u3070\u68d2\u30b0\u30e9\u30d5\u306a\u3069\uff09\u3067\u8868\u793a\u305b\u3088\uff0e\n> \u5358\u8a9e\u306e\u51fa\u73fe\u983b\u5ea6\u306e\u30d2\u30b9\u30c8\u30b0\u30e9\u30e0\uff08\u6a2a\u8ef8\u306b\u51fa\u73fe\u983b\u5ea6\uff0c\u7e26\u8ef8\u306b\u51fa\u73fe\u983b\u5ea6\u3092\u3068\u308b\u5358\u8a9e\u306e\u7a2e\u985e\u6570\u3092\u68d2\u30b0\u30e9\u30d5\u3067\u8868\u3057\u305f\u3082\u306e\uff09\u3092\u63cf\u3051\uff0e\n> \u5358\u8a9e\u306e\u51fa\u73fe\u983b\u5ea6\u9806\u4f4d\u3092\u6a2a\u8ef8\uff0c\u305d\u306e\u51fa\u73fe\u983b\u5ea6\u3092\u7e26\u8ef8\u3068\u3057\u3066\uff0c\u4e21\u5bfe\u6570\u30b0\u30e9\u30d5\u3092\u30d7\u30ed\u30c3\u30c8\u305b\u3088\uff0e\n\n\u30b0\u30e9\u30d5\u7cfb\u306f\u307e\u3068\u3081\u3066\u51fa\u3057\u3066\u3057\u307e\u3044\u307e\u3059\u3002\n\n```py3\nfig = plt.figure(figsize=(20, 6))\n\n# 37. \u51fa\u73fe\u983b\u5ea6\u304c\u9ad8\u304410\u8a9e\u3068\u305d\u306e\u51fa\u73fe\u983b\u5ea6\u3092\u30b0\u30e9\u30d5\uff08\u4f8b\u3048\u3070\u68d2\u30b0\u30e9\u30d5\u306a\u3069\uff09\u3067\u8868\u793a\u305b\u3088\uff0e\nwords = [f[0] for f in frequency[0:10]]\nx_pos = np.arange(len(words))\nfp = FontProperties(fname=r'/Library/Fonts/\u30d2\u30e9\u30ae\u30ce\u4e38\u30b4 ProN W4.ttc', size=14)\n\nax1 = fig.add_subplot(131)\nax1.bar(x_pos, [f[1] for f in frequency[0:10]], align='center', alpha=0.4)\nax1.set_xticks(x_pos)\nax1.set_xticklabels(words, fontproperties=fp)\nax1.set_ylabel('Frequency')\nax1.set_title('Top 10 frequent words')\n\n# 38. \u5358\u8a9e\u306e\u51fa\u73fe\u983b\u5ea6\u306e\u30d2\u30b9\u30c8\u30b0\u30e9\u30e0\uff08\u6a2a\u8ef8\u306b\u51fa\u73fe\u983b\u5ea6\uff0c\u7e26\u8ef8\u306b\u51fa\u73fe\u983b\u5ea6\u3092\u3068\u308b\u5358\u8a9e\u306e\u7a2e\u985e\u6570\u3092\u68d2\u30b0\u30e9\u30d5\u3067\u8868\u3057\u305f\u3082\u306e\uff09\u3092\u63cf\u3051\uff0e\nfreq = list(dict(frequency).values())\nfreq.sort(reverse=True)\n\nax2 = fig.add_subplot(132)\nax2.hist(freq, bins=50, range=(0, 50))\nax2.set_title('Histogram of word count')\nax2.set_xlabel('Word count')\nax2.set_ylabel('Frequency')\n\n# 39. \u5358\u8a9e\u306e\u51fa\u73fe\u983b\u5ea6\u9806\u4f4d\u3092\u6a2a\u8ef8\uff0c\u305d\u306e\u51fa\u73fe\u983b\u5ea6\u3092\u7e26\u8ef8\u3068\u3057\u3066\uff0c\u4e21\u5bfe\u6570\u30b0\u30e9\u30d5\u3092\u30d7\u30ed\u30c3\u30c8\u305b\u3088\uff0e\nrank = list(range(1, len(freq) + 1))\n\nax3 = fig.add_subplot(133)\nax3.plot(freq, rank)\nax3.set_xlabel('Rank')\nax3.set_ylabel('Frequency')\nax3.set_title('Zipf low')\nax3.set_xscale('log')\nax3.set_yscale('log')\n\nfig.savefig('morphological_analysis.png')\n```\n\n![morphological_analysis.png](https://qiita-image-store.s3.amazonaws.com/0/36429/d2c6fb68-f864-92b6-4235-426a30a017f5.png)\n", "tags": ["Python3.5.1", "\u81ea\u7136\u8a00\u8a9e\u51e6\u7406", "NLP", "\u8a00\u8a9e\u51e6\u7406100\u672c\u30ce\u30c3\u30af"]}