{"context": "\n\n\u306f\u3058\u3081\u306b\n\u30af\u30e9\u30a6\u30c9\u7d71\u5408\u958b\u767a\u74b0\u5883Cloud9\u3067\u958b\u767a\u4f5c\u696d\u3092\u3057\u3066\u3044\u307e\u3059\u3002\u6a5f\u68b0\u5b66\u7fd2\u3092\u52c9\u5f37\u3057\u3066\u3044\u308b\u306e\u3067\u3001TensorFlow\u3092Cloud9\u4e0a\u3067\u52c9\u5f37\u3057\u305f\u304f\u74b0\u5883\u69cb\u7bc9\u3057\u307e\u3057\u305f\u3002\u305d\u306e\u30e1\u30e2\u3092\u6b8b\u3057\u307e\u3059\u3002\n\n\u74b0\u5883\nCloud9\nPython 2.7.6\nSample Codes : GitHub\n\n\u624b\u9806\nCloud9\u4e0a\u3067\u3001TensorFlow\u306eGet Started\u307e\u3067\u3092\u5b9f\u884c\u3067\u304d\u308b\u3088\u3046\u306b\u3059\u308b\u307e\u3067\u306e\u624b\u9806\u3067\u3059\u3002\n\n\nCloud9\u3067\u65b0\u3057\u3044\u30ef\u30fc\u30af\u30b9\u30da\u30fc\u30b9\u3092\u4f5c\u6210\u3059\u308b\u3002\u30c6\u30f3\u30d7\u30ec\u30fc\u30c8\u306fpython\u3092\u9078\u3076\u3002\nTerminal\u3067\u4ee5\u4e0b\u3092\u5b9f\u884c\u3059\u308b\u3002\nexport export TF_BINARY_URL=https://storage.googleapis.com/tensorflow/linux/cpu/tensorflow-0.11.0rc0-cp27-none-linux_x86_64.whl\nsudo pip install --upgrade $TF_BINARY_URL\nGet Started\u306e\u30b5\u30f3\u30d7\u30eb\u30d7\u30ed\u30b0\u30e9\u30e0\u3092\u4fdd\u5b58\u3057\u3066\u5b9f\u884c\u3059\u308b\u3002TensorFlow\u306eGET STARTED\u306b\u63b2\u8f09\u3055\u308c\u3066\u3044\u3082\u306e\u3068\u540c\u3058\u3067\u3059\u3002\n\n\ngetstarted.py\nimport tensorflow as tf\nimport numpy as np\n\n# Create 100 phony x, y data points in NumPy, y = x * 0.1 + 0.3\nx_data = np.random.rand(100).astype(np.float32)\ny_data = x_data * 0.1 + 0.3\n\n# Try to find values for W and b that compute y_data = W * x_data + b\n# (We know that W should be 0.1 and b 0.3, but TensorFlow will\n# figure that out for us.)\nW = tf.Variable(tf.random_uniform([1], -1.0, 1.0))\nb = tf.Variable(tf.zeros([1]))\ny = W * x_data + b\n\n# Minimize the mean squared errors.\nloss = tf.reduce_mean(tf.square(y - y_data))\noptimizer = tf.train.GradientDescentOptimizer(0.5)\ntrain = optimizer.minimize(loss)\n\n# Before starting, initialize the variables.  We will 'run' this first.\ninit = tf.initialize_all_variables()\n\n# Launch the graph.\nsess = tf.Session()\nsess.run(init)\n\n# Fit the line.\nfor step in range(201):\n    sess.run(train)\n    if step % 20 == 0:\n        print(step, sess.run(W), sess.run(b))\n\n# Learns best fit is W: [0.1], b: [0.3]\n\n\n\u5b9f\u884c\u7d50\u679c\u304c\u30010.1\u30680.3\u306b\u8fd1\u3051\u308c\u3070\u5b66\u7fd2\u306b\u3088\u3063\u3066\u3001\u76f4\u7dda\u306e\u4fc2\u6570\u3092\u4e88\u6e2c\u3067\u304d\u3066\u3044\u308b\u3068\u3044\u3046\u3053\u3068\u3067\u3057\u3087\u3046\u3002\n\u79c1\u304c\u5b9f\u884c\u3057\u305f\u7d50\u679c\u306f\u4ee5\u4e0b\u3067\u30010.1\u30680.3\u306b\u8fd1\u3044\u5024\u304c\u898b\u3048\u3066\u3044\u307e\u3059\u3002\n(0, array([ 0.45364389], dtype=float32), array([ 0.13226086], dtype=float32))\n(20, array([ 0.18247673], dtype=float32), array([ 0.25206894], dtype=float32))\n(40, array([ 0.12017135], dtype=float32), array([ 0.28827751], dtype=float32))\n(60, array([ 0.10493329], dtype=float32), array([ 0.29713303], dtype=float32))\n(80, array([ 0.10120656], dtype=float32), array([ 0.29929882], dtype=float32))\n(100, array([ 0.10029508], dtype=float32), array([ 0.29982853], dtype=float32))\n(120, array([ 0.10007217], dtype=float32), array([ 0.29995808], dtype=float32))\n(140, array([ 0.10001764], dtype=float32), array([ 0.29998976], dtype=float32))\n(160, array([ 0.10000434], dtype=float32), array([ 0.29999751], dtype=float32))\n(180, array([ 0.10000106], dtype=float32), array([ 0.29999939], dtype=float32))\n(200, array([ 0.10000025], dtype=float32), array([ 0.29999986], dtype=float32))\n\n\nMNIST\u306e\u5b9f\u884c\n\u624b\u66f8\u304d\u306e\u6570\u5b57\u306e\u753b\u50cf\u30c7\u30fc\u30bf\u304b\u3089\u6570\u5b57\u3092\u8a8d\u8b58\u3059\u308b\u30d7\u30ed\u30b0\u30e9\u30e0\u3082\u7121\u4e8b\u5b9f\u884c\u3067\u304d\u307e\u3057\u305f\u3002\nGitHub\u306econvolutional.py\u3092\u30c0\u30a6\u30f3\u30ed\u30fc\u30c9\u3057\u3066\u5b9f\u884c\u3059\u308b\u3060\u3051\u3067\u3059\u3002\uff08\u516c\u5f0f\u30b5\u30a4\u30c8\u306e\u30bd\u30fc\u30b9\u3068\u540c\u3058\u3082\u306e\u3067\u3059\u3002\uff09\nCloud9\u3067\u5b9f\u884c\u3059\u308b\u3068100 Step 2\u5206\u307b\u3069\u3067\u3001\u5168\u90e8\u30672\u6642\u9593\u307b\u3069\u304b\u304b\u3063\u305f\u3068\u601d\u3044\u307e\u3059\u3002\u30b9\u30da\u30c3\u30af\u8db3\u308a\u306a\u3044\u3067\u3059\u306d\u3002Cloud9\u306e\u30b9\u30da\u30c3\u30af\u306f1CPU, 512MB RAM\u3067\u3057\u305f\u3002\n\u5b9f\u884c\u7d50\u679c\u306f\u4ee5\u4e0b\u3067\u3059\u3002\uff08\u9577\u3044\u306e\u3067\u9014\u4e2d\u7701\u7565\u3057\u3066\u3044\u307e\u3059\u3002\uff09\npython convolutional.py \n\nSuccessfully downloaded train-images-idx3-ubyte.gz 9912422 bytes.\nSuccessfully downloaded train-labels-idx1-ubyte.gz 28881 bytes.\nSuccessfully downloaded t10k-images-idx3-ubyte.gz 1648877 bytes.\nSuccessfully downloaded t10k-labels-idx1-ubyte.gz 4542 bytes.\nExtracting data/train-images-idx3-ubyte.gz\nExtracting data/train-labels-idx1-ubyte.gz\nExtracting data/t10k-images-idx3-ubyte.gz\nExtracting data/t10k-labels-idx1-ubyte.gz\nInitialized!\nStep 0 (epoch 0.00), 7.7 ms\nMinibatch loss: 12.054, learning rate: 0.010000\nMinibatch error: 90.6%\nValidation error: 84.6%\nStep 100 (epoch 0.12), 706.3 ms\nMinibatch loss: 3.287, learning rate: 0.010000\nMinibatch error: 6.2%\nValidation error: 7.0%\nStep 200 (epoch 0.23), 713.8 ms\n...\n...\nStep 5300 (epoch 6.17), 1937.9 ms\nMinibatch loss: 1.980, learning rate: 0.007351\nMinibatch error: 0.0%\nValidation error: 0.9%\nStep 5400 (epoch 6.28), 2089.9 ms\n\n\u898b\u65b9\u306f\u5fae\u5999\u306b\u5206\u304b\u308a\u307e\u305b\u3093\u304c\u3001Minibatch error\u3084Validation error\u306e\u30d1\u30fc\u30bb\u30f3\u30c8\u304c\u5c0f\u3055\u304f\u306a\u3063\u3066\u3044\u308b\u306e\u3067\u8b58\u5225\u3067\u304d\u308b\u3088\u3046\u306b\u306a\u3063\u3066\u3044\u308b\u3068\u3044\u3046\u3053\u3068\u3067\u3057\u3087\u3046\u304b\u3002\n\u4eca\u56de\u306f\u3068\u308a\u3042\u3048\u305a\u5b9f\u884c\u3057\u305f\u3060\u3051\u3067\u3059\u304c\u3001\u4eca\u5f8c\u4e2d\u8eab\u3092\u7406\u89e3\u3057\u3066\u3044\u304d\u305f\u3044\u3067\u3059\u3002\n\n\u304a\u308f\u308a\u306b\nCloud9\u4e0a\u3067\u3001TensorFlow\u3092\u30a4\u30f3\u30b9\u30c8\u30fc\u30eb\u3067\u304d\u305f\u306e\u3067\u3001\u4eca\u5f8c\u4e2d\u8eab\u3092\u7406\u89e3\u3057\u3066\u3044\u304d\u305f\u3044\u3068\u601d\u3044\u307e\u3059\u3002\n\u3061\u306a\u307f\u306bTensorFlow\u306f\u3001CPU\u3092\u4f7f\u3046\u3082\u306e\u3068GPU\u3092\u4f7f\u3046\u3082\u306e\u304c\u3042\u308b\u3088\u3046\u3067\u3059\u304c\u3001GPU\u3092\u4f7f\u3046\u3082\u306e\u306f\u4f7f\u3048\u306a\u3044\u3088\u3046\u3067\u3059\u3002\u30a4\u30f3\u30b9\u30c8\u30fc\u30eb\u3057\u3066\u307f\u307e\u3057\u305f\u304c\u3001\u5b9f\u884c\u6642\u306b\u30a8\u30e9\u30fc\u304c\u767a\u751f\u3057\u3066\u3057\u307e\u3044\u307e\u3057\u305f\u3002Cloud9\u4e0a\u3067\u306f\u3001CPU\u3092\u4f7f\u3046\u3082\u306e\u3092\u5229\u7528\u3057\u307e\u3057\u3087\u3046\u3002\n\n\u66f4\u65b0\u5c65\u6b74\n\n2016/10/19\n\nMNIST\u306e\u30b5\u30f3\u30d7\u30eb\u30b3\u30fc\u30c9\u5b9f\u884c\u7d50\u679c\u8ffd\u8a18\n\u74b0\u5883\u306e\u8a18\u8f09\nGitHub\u306b\u5408\u308f\u305b\u3066\u30b5\u30f3\u30d7\u30eb\u30b3\u30fc\u30c9\u540d\u3092\u5909\u66f4\n\n# \u306f\u3058\u3081\u306b\n\u30af\u30e9\u30a6\u30c9\u7d71\u5408\u958b\u767a\u74b0\u5883Cloud9\u3067\u958b\u767a\u4f5c\u696d\u3092\u3057\u3066\u3044\u307e\u3059\u3002\u6a5f\u68b0\u5b66\u7fd2\u3092\u52c9\u5f37\u3057\u3066\u3044\u308b\u306e\u3067\u3001TensorFlow\u3092Cloud9\u4e0a\u3067\u52c9\u5f37\u3057\u305f\u304f\u74b0\u5883\u69cb\u7bc9\u3057\u307e\u3057\u305f\u3002\u305d\u306e\u30e1\u30e2\u3092\u6b8b\u3057\u307e\u3059\u3002\n\n# \u74b0\u5883\n[Cloud9](https://c9.io)\nPython 2.7.6\nSample Codes : [GitHub](https://github.com/takus69/learn_tf)\n\n# \u624b\u9806\nCloud9\u4e0a\u3067\u3001TensorFlow\u306e[Get Started](https://www.tensorflow.org/versions/r0.11/get_started/index.html#introduction)\u307e\u3067\u3092\u5b9f\u884c\u3067\u304d\u308b\u3088\u3046\u306b\u3059\u308b\u307e\u3067\u306e\u624b\u9806\u3067\u3059\u3002\n\n1. [Cloud9](https://c9.io)\u3067\u65b0\u3057\u3044\u30ef\u30fc\u30af\u30b9\u30da\u30fc\u30b9\u3092\u4f5c\u6210\u3059\u308b\u3002\u30c6\u30f3\u30d7\u30ec\u30fc\u30c8\u306fpython\u3092\u9078\u3076\u3002\n2. Terminal\u3067\u4ee5\u4e0b\u3092\u5b9f\u884c\u3059\u308b\u3002<br>\nexport export TF_BINARY_URL=https://storage.googleapis.com/tensorflow/linux/cpu/tensorflow-0.11.0rc0-cp27-none-linux_x86_64.whl<br>\nsudo pip install --upgrade $TF_BINARY_URL\n3. Get Started\u306e\u30b5\u30f3\u30d7\u30eb\u30d7\u30ed\u30b0\u30e9\u30e0\u3092\u4fdd\u5b58\u3057\u3066\u5b9f\u884c\u3059\u308b\u3002[TensorFlow\u306eGET STARTED](https://www.tensorflow.org/versions/r0.11/get_started/index.html)\u306b\u63b2\u8f09\u3055\u308c\u3066\u3044\u3082\u306e\u3068\u540c\u3058\u3067\u3059\u3002\n\n``` getstarted.py\nimport tensorflow as tf\nimport numpy as np\n\n# Create 100 phony x, y data points in NumPy, y = x * 0.1 + 0.3\nx_data = np.random.rand(100).astype(np.float32)\ny_data = x_data * 0.1 + 0.3\n\n# Try to find values for W and b that compute y_data = W * x_data + b\n# (We know that W should be 0.1 and b 0.3, but TensorFlow will\n# figure that out for us.)\nW = tf.Variable(tf.random_uniform([1], -1.0, 1.0))\nb = tf.Variable(tf.zeros([1]))\ny = W * x_data + b\n\n# Minimize the mean squared errors.\nloss = tf.reduce_mean(tf.square(y - y_data))\noptimizer = tf.train.GradientDescentOptimizer(0.5)\ntrain = optimizer.minimize(loss)\n\n# Before starting, initialize the variables.  We will 'run' this first.\ninit = tf.initialize_all_variables()\n\n# Launch the graph.\nsess = tf.Session()\nsess.run(init)\n\n# Fit the line.\nfor step in range(201):\n    sess.run(train)\n    if step % 20 == 0:\n        print(step, sess.run(W), sess.run(b))\n\n# Learns best fit is W: [0.1], b: [0.3]\n```\n\n\u5b9f\u884c\u7d50\u679c\u304c\u30010.1\u30680.3\u306b\u8fd1\u3051\u308c\u3070\u5b66\u7fd2\u306b\u3088\u3063\u3066\u3001\u76f4\u7dda\u306e\u4fc2\u6570\u3092\u4e88\u6e2c\u3067\u304d\u3066\u3044\u308b\u3068\u3044\u3046\u3053\u3068\u3067\u3057\u3087\u3046\u3002\n\u79c1\u304c\u5b9f\u884c\u3057\u305f\u7d50\u679c\u306f\u4ee5\u4e0b\u3067\u30010.1\u30680.3\u306b\u8fd1\u3044\u5024\u304c\u898b\u3048\u3066\u3044\u307e\u3059\u3002\n\n``` result\n(0, array([ 0.45364389], dtype=float32), array([ 0.13226086], dtype=float32))\n(20, array([ 0.18247673], dtype=float32), array([ 0.25206894], dtype=float32))\n(40, array([ 0.12017135], dtype=float32), array([ 0.28827751], dtype=float32))\n(60, array([ 0.10493329], dtype=float32), array([ 0.29713303], dtype=float32))\n(80, array([ 0.10120656], dtype=float32), array([ 0.29929882], dtype=float32))\n(100, array([ 0.10029508], dtype=float32), array([ 0.29982853], dtype=float32))\n(120, array([ 0.10007217], dtype=float32), array([ 0.29995808], dtype=float32))\n(140, array([ 0.10001764], dtype=float32), array([ 0.29998976], dtype=float32))\n(160, array([ 0.10000434], dtype=float32), array([ 0.29999751], dtype=float32))\n(180, array([ 0.10000106], dtype=float32), array([ 0.29999939], dtype=float32))\n(200, array([ 0.10000025], dtype=float32), array([ 0.29999986], dtype=float32))\n```\n\n# MNIST\u306e\u5b9f\u884c\n\u624b\u66f8\u304d\u306e\u6570\u5b57\u306e\u753b\u50cf\u30c7\u30fc\u30bf\u304b\u3089\u6570\u5b57\u3092\u8a8d\u8b58\u3059\u308b\u30d7\u30ed\u30b0\u30e9\u30e0\u3082\u7121\u4e8b\u5b9f\u884c\u3067\u304d\u307e\u3057\u305f\u3002\n[GitHub](https://github.com/takus69/learn_tf)\u306econvolutional.py\u3092\u30c0\u30a6\u30f3\u30ed\u30fc\u30c9\u3057\u3066\u5b9f\u884c\u3059\u308b\u3060\u3051\u3067\u3059\u3002\uff08\u516c\u5f0f\u30b5\u30a4\u30c8\u306e\u30bd\u30fc\u30b9\u3068\u540c\u3058\u3082\u306e\u3067\u3059\u3002\uff09\nCloud9\u3067\u5b9f\u884c\u3059\u308b\u3068100 Step 2\u5206\u307b\u3069\u3067\u3001\u5168\u90e8\u30672\u6642\u9593\u307b\u3069\u304b\u304b\u3063\u305f\u3068\u601d\u3044\u307e\u3059\u3002\u30b9\u30da\u30c3\u30af\u8db3\u308a\u306a\u3044\u3067\u3059\u306d\u3002Cloud9\u306e\u30b9\u30da\u30c3\u30af\u306f1CPU, 512MB RAM\u3067\u3057\u305f\u3002\n\u5b9f\u884c\u7d50\u679c\u306f\u4ee5\u4e0b\u3067\u3059\u3002\uff08\u9577\u3044\u306e\u3067\u9014\u4e2d\u7701\u7565\u3057\u3066\u3044\u307e\u3059\u3002\uff09\n\n```\npython convolutional.py \n\nSuccessfully downloaded train-images-idx3-ubyte.gz 9912422 bytes.\nSuccessfully downloaded train-labels-idx1-ubyte.gz 28881 bytes.\nSuccessfully downloaded t10k-images-idx3-ubyte.gz 1648877 bytes.\nSuccessfully downloaded t10k-labels-idx1-ubyte.gz 4542 bytes.\nExtracting data/train-images-idx3-ubyte.gz\nExtracting data/train-labels-idx1-ubyte.gz\nExtracting data/t10k-images-idx3-ubyte.gz\nExtracting data/t10k-labels-idx1-ubyte.gz\nInitialized!\nStep 0 (epoch 0.00), 7.7 ms\nMinibatch loss: 12.054, learning rate: 0.010000\nMinibatch error: 90.6%\nValidation error: 84.6%\nStep 100 (epoch 0.12), 706.3 ms\nMinibatch loss: 3.287, learning rate: 0.010000\nMinibatch error: 6.2%\nValidation error: 7.0%\nStep 200 (epoch 0.23), 713.8 ms\n...\n...\nStep 5300 (epoch 6.17), 1937.9 ms\nMinibatch loss: 1.980, learning rate: 0.007351\nMinibatch error: 0.0%\nValidation error: 0.9%\nStep 5400 (epoch 6.28), 2089.9 ms\n```\n\n\u898b\u65b9\u306f\u5fae\u5999\u306b\u5206\u304b\u308a\u307e\u305b\u3093\u304c\u3001Minibatch error\u3084Validation error\u306e\u30d1\u30fc\u30bb\u30f3\u30c8\u304c\u5c0f\u3055\u304f\u306a\u3063\u3066\u3044\u308b\u306e\u3067\u8b58\u5225\u3067\u304d\u308b\u3088\u3046\u306b\u306a\u3063\u3066\u3044\u308b\u3068\u3044\u3046\u3053\u3068\u3067\u3057\u3087\u3046\u304b\u3002\n\u4eca\u56de\u306f\u3068\u308a\u3042\u3048\u305a\u5b9f\u884c\u3057\u305f\u3060\u3051\u3067\u3059\u304c\u3001\u4eca\u5f8c\u4e2d\u8eab\u3092\u7406\u89e3\u3057\u3066\u3044\u304d\u305f\u3044\u3067\u3059\u3002\n\n# \u304a\u308f\u308a\u306b\nCloud9\u4e0a\u3067\u3001TensorFlow\u3092\u30a4\u30f3\u30b9\u30c8\u30fc\u30eb\u3067\u304d\u305f\u306e\u3067\u3001\u4eca\u5f8c\u4e2d\u8eab\u3092\u7406\u89e3\u3057\u3066\u3044\u304d\u305f\u3044\u3068\u601d\u3044\u307e\u3059\u3002\n\u3061\u306a\u307f\u306bTensorFlow\u306f\u3001CPU\u3092\u4f7f\u3046\u3082\u306e\u3068GPU\u3092\u4f7f\u3046\u3082\u306e\u304c\u3042\u308b\u3088\u3046\u3067\u3059\u304c\u3001GPU\u3092\u4f7f\u3046\u3082\u306e\u306f\u4f7f\u3048\u306a\u3044\u3088\u3046\u3067\u3059\u3002\u30a4\u30f3\u30b9\u30c8\u30fc\u30eb\u3057\u3066\u307f\u307e\u3057\u305f\u304c\u3001\u5b9f\u884c\u6642\u306b\u30a8\u30e9\u30fc\u304c\u767a\u751f\u3057\u3066\u3057\u307e\u3044\u307e\u3057\u305f\u3002Cloud9\u4e0a\u3067\u306f\u3001CPU\u3092\u4f7f\u3046\u3082\u306e\u3092\u5229\u7528\u3057\u307e\u3057\u3087\u3046\u3002\n\n## \u66f4\u65b0\u5c65\u6b74\n### 2016/10/19\n- MNIST\u306e\u30b5\u30f3\u30d7\u30eb\u30b3\u30fc\u30c9\u5b9f\u884c\u7d50\u679c\u8ffd\u8a18\n- \u74b0\u5883\u306e\u8a18\u8f09\n- GitHub\u306b\u5408\u308f\u305b\u3066\u30b5\u30f3\u30d7\u30eb\u30b3\u30fc\u30c9\u540d\u3092\u5909\u66f4\n", "tags": ["cloud9", "TensorFlow", "Python", "\u6a5f\u68b0\u5b66\u7fd2"]}