{"context": "\n\n\u6982\u8981\n\u4e00\u9031\u9593\u524d\u304f\u3089\u3044\u306bSpark2.0\u304c\u51fa\u307e\u3057\u305f\u3002\u305d\u3057\u3066\u3001\u4eca\u65e5\u78ba\u8a8d\u3057\u305f\u3089EMR5.0\u304c\u65e2\u306bSpark2.0\u5bfe\u5fdc\u3055\u308c\u3066\u3044\u307e\u3057\u305f\u3002\u3055\u3059\u304cAWS\u3055\u3093\u3067\u3059\uff01\n\u3068\u3044\u3046\u3053\u3068\u3067\u3001Spark2.0\u3067\u30a4\u30de\u30c9\u30ad\u306eSpark\u5b9f\u884c\u3092\u7c21\u5358\u306b\u30e1\u30e2\u3057\u3066\u304a\u304d\u307e\u3059\u3002\n\n\u30b4\u30fc\u30eb\n\nSpark2.0\u304c\u52d5\u304f\nScala2.11\u30d3\u30eb\u30c9\u3057\u305fjar\u304c\u52d5\u304f\nJava8\u3067\u52d5\u304f\nYARN\u5206\u6563\u74b0\u5883\u4e0a\u3067\u52d5\u304f\n\n\nEMR\u8a2d\u5b9a\nSoftware Configuration\u306b\u3066\u4ee5\u4e0b\u306e\u3088\u3046\u306b\u8a2d\u5b9a\n\nemr-5.0.0\nhadoop2.7.2\nSpark2.0.0\nconfiguration\u306b\u4ee5\u4e0b\u306ejson\u3092\u8ffd\u52a0\n\n\nJava8\u306e\u8a2d\u5b9a\u3068\u3001spark\u306b\u6700\u9069\u5316\u3059\u308b\u8a2d\u5b9a\u3092\u884c\u3063\u3066\u3044\u307e\u3059\u3002\n\n\n\n[\n  {\n    \"classification\": \"spark\",\n    \"properties\": {\n      \"maximizeResourceAllocation\": \"true\"\n    }\n  },\n  {\n    \"Classification\": \"hadoop-env\",\n    \"Configurations\": [\n      {\n        \"Classification\": \"export\",\n        \"Configurations\": [],\n        \"Properties\": {\n          \"JAVA_HOME\": \"/usr/lib/jvm/java-1.8.0\"\n        }\n      }\n    ],\n    \"Properties\": {}\n  },\n  {\n    \"Classification\": \"spark-env\",\n    \"Configurations\": [\n      {\n        \"Classification\": \"export\",\n        \"Configurations\": [],\n        \"Properties\": {\n          \"JAVA_HOME\": \"/usr/lib/jvm/java-1.8.0\"\n        }\n      }\n    ],\n    \"Properties\": {}\n  }\n]\n\n\nSpark\u30a2\u30d7\u30ea\n\nbuild.sbt\n//name\u3068\u304b\u306f\u7701\u7565\n//sbt-assembly\u304c\u5165\u3063\u3066\u308b\u524d\u63d0\n\nscalaVersion := \"2.11.8\"\n\nlibraryDependencies ++= Seq(\n  \"org.apache.spark\" %% \"spark-core\" % \"2.0.0\" % \"provided\"\n)\n\nassemblyOption in assembly := (assemblyOption in assembly).value.copy(includeScala = false)\n\n\n\nMain.scala\nimport org.apache.spark.{SparkConf, SparkContext}\n\nobject Main {\n  def main(args: Array[String]): Unit = {\n\n    val conf = new SparkConf().setAppName(\"Simple Application\")\n    val sc = new SparkContext(conf)\n    val rdd = sc.range(1, 100000, 1, 10)\n    println(\"----Start----\")\n\n    //check for using scala-library_2.11\n    //if using 2.10, this method cause Exception.\n    println(\"hello\" -> \"world\")\n\n    rdd.map(i => i*2)\n      .foreach(i => println(i))\n  }\n}\n\n\n\u3053\u3093\u306a\u611f\u3058\u3067\u66f8\u3044\u3066\u3001sbt assembly\u3059\u308c\u3070OK\n\nEMR\u304b\u3089\u30a2\u30d7\u30ea\u3092\u5b9f\u884c\nassembly\u3057\u305fjar\u3092S3\u306b\u30a2\u30c3\u30d7\u30ed\u30fc\u30c9\u3057\u307e\u3059\u3002\n\u5f8c\u306fEMR\u30af\u30e9\u30b9\u30bf\u3092\u69cb\u7bc9\u3057\u3066\u3001\u8d77\u52d5\u30aa\u30d7\u30b7\u30e7\u30f3\u3092\u4ee5\u4e0b\u306e\u3088\u3046\u306b\u8a2d\u5b9a\u3059\u308c\u3070OK\n# \u3053\u306e2\u3064\u306f\u3001MasterNode\u4e0a\u3067\u4efb\u610f\u306eshell\u30b3\u30de\u30f3\u30c9\u3092\u53e9\u304f\u3053\u3068\u3092\u793a\u3057\u3066\u3044\u307e\u3059\u3002\nJAR location: command-runner.jar\nMain class: None\n\n# spark-submit\u30b3\u30de\u30f3\u30c9\nArguments: spark-submit --deploy-mode cluster \n--class com.github.uryyyyyyy.Main \n--master yarn \n--num-executors 2 \n--driver-memory 1g \n--executor-memory 1g \n--executor-cores 1 \ns3://<your-s3-bucket>/jars/<your-assembly-0.1.0.jar> <\u8d77\u52d5\u30aa\u30d7\u30b7\u30e7\u30f3>\n\n# \u5b9f\u884c\u4e2d\u306b\u5931\u6557\u3057\u305f\u3089\u30af\u30e9\u30b9\u30bf\u3092\u3069\u3046\u3059\u308b\u304b\nAction on failure: Continue\n\n\u3053\u3093\u306a\u611f\u3058\u3067\u5b9f\u884c\u3067\u304d\u307e\u3059\u3002\n\u3082\u3057\u304f\u306f\u3001Master Node\u306bssh\u3067\u5165\u3063\u3066spark-submit ~~~ \u3092\u5b9f\u884c\u3057\u3066\u3082\u52d5\u304d\u307e\u3059\u3002\n\n\u307e\u3068\u3081\n\u3053\u308c\u3060\u3051\u3067\u4e0a\u8a18\u306e\u30b4\u30fc\u30eb\u304c\u9054\u6210\u3067\u304d\u307e\u3059\u3002\nSpark2\u7cfb\u306f\u30c7\u30d5\u30a9\u30eb\u30c8\u3067scala2.11\u30d3\u30eb\u30c9\u306a\u306e\u304c\u5b09\u3057\u3044\u3067\u3059\u306d\u3002\nhttps://aws.amazon.com/blogs/aws/amazon-emr-5-0-0-major-app-updates-ui-improvements-better-debugging-and-more/\n\nIt also updates Spark (an engine for large-scale data processing) from 1.6.2 to 2.0, with a similar move to Scala 2.11.\n\n## \u6982\u8981\n\n\u4e00\u9031\u9593\u524d\u304f\u3089\u3044\u306bSpark2.0\u304c\u51fa\u307e\u3057\u305f\u3002\u305d\u3057\u3066\u3001\u4eca\u65e5\u78ba\u8a8d\u3057\u305f\u3089EMR5.0\u304c\u65e2\u306bSpark2.0\u5bfe\u5fdc\u3055\u308c\u3066\u3044\u307e\u3057\u305f\u3002\u3055\u3059\u304cAWS\u3055\u3093\u3067\u3059\uff01\n\n\u3068\u3044\u3046\u3053\u3068\u3067\u3001Spark2.0\u3067\u30a4\u30de\u30c9\u30ad\u306eSpark\u5b9f\u884c\u3092\u7c21\u5358\u306b\u30e1\u30e2\u3057\u3066\u304a\u304d\u307e\u3059\u3002\n\n## \u30b4\u30fc\u30eb\n\n- Spark2.0\u304c\u52d5\u304f\n- Scala2.11\u30d3\u30eb\u30c9\u3057\u305fjar\u304c\u52d5\u304f\n- Java8\u3067\u52d5\u304f\n- YARN\u5206\u6563\u74b0\u5883\u4e0a\u3067\u52d5\u304f\n\n## EMR\u8a2d\u5b9a\n\nSoftware Configuration\u306b\u3066\u4ee5\u4e0b\u306e\u3088\u3046\u306b\u8a2d\u5b9a\n\n- emr-5.0.0\n- hadoop2.7.2\n- Spark2.0.0\n- configuration\u306b\u4ee5\u4e0b\u306ejson\u3092\u8ffd\u52a0\n  - Java8\u306e\u8a2d\u5b9a\u3068\u3001spark\u306b\u6700\u9069\u5316\u3059\u308b\u8a2d\u5b9a\u3092\u884c\u3063\u3066\u3044\u307e\u3059\u3002\n\n```json\n[\n  {\n    \"classification\": \"spark\",\n    \"properties\": {\n      \"maximizeResourceAllocation\": \"true\"\n    }\n  },\n  {\n    \"Classification\": \"hadoop-env\",\n    \"Configurations\": [\n      {\n        \"Classification\": \"export\",\n        \"Configurations\": [],\n        \"Properties\": {\n          \"JAVA_HOME\": \"/usr/lib/jvm/java-1.8.0\"\n        }\n      }\n    ],\n    \"Properties\": {}\n  },\n  {\n    \"Classification\": \"spark-env\",\n    \"Configurations\": [\n      {\n        \"Classification\": \"export\",\n        \"Configurations\": [],\n        \"Properties\": {\n          \"JAVA_HOME\": \"/usr/lib/jvm/java-1.8.0\"\n        }\n      }\n    ],\n    \"Properties\": {}\n  }\n]\n```\n\n## Spark\u30a2\u30d7\u30ea\n\n```scala:build.sbt\n//name\u3068\u304b\u306f\u7701\u7565\n//sbt-assembly\u304c\u5165\u3063\u3066\u308b\u524d\u63d0\n\nscalaVersion := \"2.11.8\"\n\nlibraryDependencies ++= Seq(\n  \"org.apache.spark\" %% \"spark-core\" % \"2.0.0\" % \"provided\"\n)\n\nassemblyOption in assembly := (assemblyOption in assembly).value.copy(includeScala = false)\n```\n\n```scala:Main.scala\nimport org.apache.spark.{SparkConf, SparkContext}\n\nobject Main {\n  def main(args: Array[String]): Unit = {\n\n    val conf = new SparkConf().setAppName(\"Simple Application\")\n    val sc = new SparkContext(conf)\n    val rdd = sc.range(1, 100000, 1, 10)\n    println(\"----Start----\")\n\n    //check for using scala-library_2.11\n    //if using 2.10, this method cause Exception.\n    println(\"hello\" -> \"world\")\n\n    rdd.map(i => i*2)\n      .foreach(i => println(i))\n  }\n}\n```\n\n\u3053\u3093\u306a\u611f\u3058\u3067\u66f8\u3044\u3066\u3001sbt assembly\u3059\u308c\u3070OK\n\n## EMR\u304b\u3089\u30a2\u30d7\u30ea\u3092\u5b9f\u884c\n\nassembly\u3057\u305fjar\u3092S3\u306b\u30a2\u30c3\u30d7\u30ed\u30fc\u30c9\u3057\u307e\u3059\u3002\n\n\u5f8c\u306fEMR\u30af\u30e9\u30b9\u30bf\u3092\u69cb\u7bc9\u3057\u3066\u3001\u8d77\u52d5\u30aa\u30d7\u30b7\u30e7\u30f3\u3092\u4ee5\u4e0b\u306e\u3088\u3046\u306b\u8a2d\u5b9a\u3059\u308c\u3070OK\n\n```\n# \u3053\u306e2\u3064\u306f\u3001MasterNode\u4e0a\u3067\u4efb\u610f\u306eshell\u30b3\u30de\u30f3\u30c9\u3092\u53e9\u304f\u3053\u3068\u3092\u793a\u3057\u3066\u3044\u307e\u3059\u3002\nJAR location: command-runner.jar\nMain class: None\n\n# spark-submit\u30b3\u30de\u30f3\u30c9\nArguments: spark-submit --deploy-mode cluster \n--class com.github.uryyyyyyy.Main \n--master yarn \n--num-executors 2 \n--driver-memory 1g \n--executor-memory 1g \n--executor-cores 1 \ns3://<your-s3-bucket>/jars/<your-assembly-0.1.0.jar> <\u8d77\u52d5\u30aa\u30d7\u30b7\u30e7\u30f3>\n\n# \u5b9f\u884c\u4e2d\u306b\u5931\u6557\u3057\u305f\u3089\u30af\u30e9\u30b9\u30bf\u3092\u3069\u3046\u3059\u308b\u304b\nAction on failure: Continue\n```\n\n\u3053\u3093\u306a\u611f\u3058\u3067\u5b9f\u884c\u3067\u304d\u307e\u3059\u3002\n\n\u3082\u3057\u304f\u306f\u3001Master Node\u306bssh\u3067\u5165\u3063\u3066`spark-submit ~~~` \u3092\u5b9f\u884c\u3057\u3066\u3082\u52d5\u304d\u307e\u3059\u3002\n\n## \u307e\u3068\u3081\n\n\u3053\u308c\u3060\u3051\u3067\u4e0a\u8a18\u306e\u30b4\u30fc\u30eb\u304c\u9054\u6210\u3067\u304d\u307e\u3059\u3002\nSpark2\u7cfb\u306f\u30c7\u30d5\u30a9\u30eb\u30c8\u3067scala2.11\u30d3\u30eb\u30c9\u306a\u306e\u304c\u5b09\u3057\u3044\u3067\u3059\u306d\u3002\n\nhttps://aws.amazon.com/blogs/aws/amazon-emr-5-0-0-major-app-updates-ui-improvements-better-debugging-and-more/\n\n> It also updates Spark (an engine for large-scale data processing) from 1.6.2 to 2.0, with a similar move to Scala 2.11.\n", "tags": ["Spark", "EMR"]}