{"context": "\n\n\u306f\u3058\u3081\u306b\npython\u3067\u30de\u30eb\u30c1\u30a8\u30fc\u30b8\u30a7\u30f3\u30c8\u8ffd\u8de1\u554f\u984c\u3092\u89e3\u3044\u3066\u307f\u307e\u3057\u305f\uff0e\n\u6559\u79d1\u66f8\u3068\u3057\u3066\u300e\u5b66\u7fd2\u3068\u305d\u306e\u30a2\u30eb\u30b4\u30ea\u30ba\u30e0\u300f\u3092\u4f7f\u3044\u307e\u3057\u305f\uff0e\n\u672c\u8a18\u4e8b\u306e\u69cb\u6210\n\n\u306f\u3058\u3081\u306b\n\u30de\u30eb\u30c1\u30a8\u30fc\u30b8\u30a7\u30f3\u30c8\u8ffd\u8de1\n\n\n\u30eb\u30fc\u30eb\nQ \u5024\u306e\u66f4\u65b0\n\n\n\u5b9f\u88c5\n\n\n\u30b3\u30fc\u30c9\n\u30dd\u30a4\u30f3\u30c8\n\n\n\u7d50\u679c\n\u304a\u308f\u308a\u306b\n\n\n\u30de\u30eb\u30c1\u30a8\u30fc\u30b8\u30a7\u30f3\u30c8\u8ffd\u8de1\n$2$ \u3064\u306e\u30a8\u30fc\u30b8\u30a7\u30f3\u30c8\u3067 $1$ \u3064\u306e\u30bf\u30fc\u30b2\u30c3\u30c8\u3092\u6355\u7372\u3059\u308b\u305f\u3081\u306e\u6700\u9069\u306a\u884c\u52d5\u3092\u5b66\u7fd2\u3057\u307e\u3059\uff0e\n\u30a8\u30fc\u30b8\u30a7\u30f3\u30c8\u304c\u30bf\u30fc\u30b2\u30c3\u30c8\u3092\u631f\u307f\u8fbc\u3093\u3060\u72b6\u614b\u3092\uff0c\u6355\u7372\u3057\u305f\u72b6\u614b\u3068\u5b9a\u7fa9\u3057\u307e\u3059\uff0e\n\u300c\u631f\u307f\u8fbc\u3080\u300d\u3068\u306f\uff0c\u30bf\u30fc\u30b2\u30c3\u30c8\u306e $4$ \u8fd1\u508d\u306e\u3046\u3061 $2$ \u7b87\u6240\u306b\u30a8\u30fc\u30b8\u30a7\u30f3\u30c8\u304c\u5b58\u5728\u3059\u308b\u72b6\u614b\u3092\u6307\u3057\u307e\u3059\uff0e\n\n\u30eb\u30fc\u30eb\n\u8a73\u7d30\u306a\u30eb\u30fc\u30eb\u3092\u4ee5\u4e0b\u306b\u793a\u3057\u307e\u3059\uff0e\u300e\u5b66\u7fd2\u3068\u305d\u306e\u30a2\u30eb\u30b4\u30ea\u30ba\u30e0\u300f\u306e\u30eb\u30fc\u30eb\u3092\u63a1\u7528\u3057\u3066\u3044\u307e\u3059\uff0e\n\n\u74b0\u5883\u3068\u3057\u3066 $20 \\times 20$ \u306e\u683c\u5b50\u72b6\u30c8\u30fc\u30e9\u30b9\u5e73\u9762\u3092\u8a2d\u3051\u308b\uff0e\n$2$ \u3064\u306e\u30a8\u30fc\u30b8\u30a7\u30f3\u30c8\u3068 $1$ \u3064\u306e\u30bf\u30fc\u30b2\u30c3\u30c8\u3092\u74b0\u5883\u4e2d\u306b\u30e9\u30f3\u30c0\u30e0\u306b\u914d\u7f6e\u3059\u308b\uff0e\n\u30a8\u30fc\u30b8\u30a7\u30f3\u30c8\u306f\u81ea\u5206\u3092\u4e2d\u5fc3\u3068\u3057\u305f $2$ \u683c\u5b50\u5206\u306e\u72b6\u614b\u3092\u89b3\u6e2c\u3059\u308b\u3053\u3068\u304c\u3067\u304d\u308b\uff0e\n\u3059\u306a\u308f\u3061\uff0c\u81ea\u5206\u306e\u3044\u308b\u683c\u5b50\u3092\u542b\u3081 $25$ \u683c\u5b50\u5206\u3092\u72b6\u614b\u3068\u3057\u3066\u8a8d\u8b58\u3059\u308b\uff0e\n\u305d\u308c\u305e\u308c\u306e\u30a8\u30fc\u30b8\u30a7\u30f3\u30c8\u306f\uff0c\u72ec\u7acb\u306b Q-learning \u3092\u9032\u3081\u308b\uff0e\n\u5b66\u7fd2\u7d50\u679c\u306b\u57fa\u3065\u3044\u3066\uff0c$1$ \u30b9\u30c6\u30c3\u30d7\u306b\u3064\u304d\u4e0a\u4e0b\u5de6\u53f3\u306e\u3044\u305a\u308c\u304b\u306b $1$ \u683c\u5b50\u79fb\u52d5\u3059\u308b\u884c\u52d5\u304c\u9078\u629e\u3055\u308c\u308b\uff0e\n\u5404\u884c\u52d5\u306b\u3064\u304d $-1$ \u306e\u5831\u916c\u304c\u3064\u306d\u306b\u4e0e\u3048\u3089\u308c\u308b\uff0e\n\u79fb\u52d5\u5148\u306b\u3059\u3067\u306b\u5225\u306e\u30a8\u30fc\u30b8\u30a7\u30f3\u30c8\u3042\u308b\u3044\u306f\u30bf\u30fc\u30b2\u30c3\u30c8\u304c\u5b58\u5728\u3059\u308b\u5834\u5408\u306f\u305d\u306e\u5834\u306b\u7559\u307e\u308b.\n\u30bf\u30fc\u30b2\u30c3\u30c8\u306f\uff0c$1$ \u30b9\u30c6\u30c3\u30d7\u306b\u3064\u304d\u4e0a\u4e0b\u5de6\u53f3\u306e\u3044\u305a\u308c\u304b\u306e\u65b9\u5411\u3078\u30e9\u30f3\u30c0\u30e0\u306b\u79fb\u52d5\u3059\u308b\uff0e\u79fb\u52d5\u5148\u306b\u30a8\u30fc\u30b8\u30a7\u30f3\u30c8\u304c\u5b58\u5728\u3059\u308b\u5834\u5408\u306f\uff0c\u5225\u306e\u30e9\u30f3\u30c0\u30e0\u306a\u884c\u52d5\u3092\u9078\u629e\u3059\u308b\uff0e\n$2$ \u3064\u306e\u30a8\u30fc\u30b8\u30a7\u30f3\u30c8\u304c\u30bf\u30fc\u30b2\u30c3\u30c8\u3092\u631f\u307f\u8fbc\u3093\u3060\u6642\u70b9\u3067 $2$ \u3064\u306e\u30a8\u30fc\u30b8\u30a7\u30f3\u30c8\u305d\u308c\u305e\u308c\u306b\u5831\u916c\u3092\u4e0e\u3048\uff0c$1$ \u56de\u306e\u8a66\u884c\u3092\u7d42\u4e86\u3059\u308b\uff0e\u305d\u306e\u5f8c\uff0c2. \u306b\u623b\u308a\u6b21\u306e\u8a66\u884c\u3092\u958b\u59cb\u3059\u308b\uff0e\n\n\nQ \u5024\u306e\u66f4\u65b0\n\u4ee5\u4e0b\u306e\u5f0f\u306b\u3088\u308a $Q$ \u5024\u3092\u66f4\u65b0\u3057\u307e\u3059\uff0e\nQ_{new}(s_t, a) = Q_{old}(s_t, a) + \\alpha\\bigl[r_{t+1} + \\gamma max_{a'}Q(s_{t+1}, a') - Q_{old}(s_t, a)\\bigr]\n\n$Q(s_t, a)$ \u306f\uff0c\u3042\u308b\u72b6\u614b $s_t$ \u3067\u306e\u884c\u52d5 $a$ \u306e\u4fa1\u5024\u3092\u8868\u3057\u307e\u3059\uff0e\u72b6\u614b $s_t$ \u3067\u306e\u884c\u52d5 $a$ \u306b\u3088\u308a\u5831\u916c $r_{t+1}$ \u304c\u5f97\u3089\u308c\u307e\u3059\uff0e\n$Q$ \u5024\u3092\u66f4\u65b0\u3059\u308b\u969b\uff0c\u76f4\u8fd1\u306e\u5831\u916c $r_{t+1}$ \u306b\uff0c\u305d\u306e\u6b21\u306e\u72b6\u614b $s_{t+1}$ \u306b\u304a\u3051\u308b\u884c\u52d5 $a'$ \u306b\u3088\u3063\u3066\u5f97\u3089\u308c\u308b\u4fa1\u5024\u306e\u6700\u5927\u5024\u306b $\\gamma$ \u3092\u4e57\u3058\u305f\u3082\u306e\u3092\u52a0\u3048\u307e\u3059\uff0e\n\u3053\u308c\u306f\uff0c\u3042\u308b\u72b6\u614b\u3067\u306e\u884c\u52d5\u3092\u76f4\u8fd1\u306e\u5831\u916c\u3060\u3051\u3067\u306a\u304f\uff0c\u305d\u306e\u5f8c\u306e\u72b6\u614b\u306b\u304a\u3051\u308b\u4fa1\u5024\u3092\u52a0\u5473\u3057\u3066\u884c\u52d5\u3092\u9078\u629e\u3059\u308b\u3053\u3068\u3092\u610f\u5473\u3057\u307e\u3059\uff0e\n$\\gamma$ \u3092\u5272\u5f15\u7387\uff0c$\\alpha$ \u3092\u5b66\u7fd2\u7387\u3068\u547c\u3073\u307e\u3059\uff0e\n\n\u5b9f\u88c5\n\u30b3\u30fc\u30c9\u3068\u30dd\u30a4\u30f3\u30c8\u306b\u5206\u3051\u3066\u8f09\u305b\u307e\u3059\uff0e\n\n\u30b3\u30fc\u30c9\n\u4ee5\u4e0b\u306e\u3088\u3046\u306b\u5b9f\u88c5\u3057\u307e\u3057\u305f\uff0e\n.\n\u251c\u2500\u2500 main.py\n\u251c\u2500\u2500 model\n\u2502\u00a0\u00a0 \u251c\u2500\u2500 agent.py\n\u2502\u00a0\u00a0 \u251c\u2500\u2500 area.py\n\u2502\u00a0\u00a0 \u251c\u2500\u2500 movingobject.py\n\u2502\u00a0\u00a0 \u251c\u2500\u2500 target.py\n\u2514\u2500\u2500 service\n \u00a0\u00a0 \u2514\u2500\u2500 gameservice.py\n\n\nmovingobject.py\nimport numpy\nimport random\nimport copy\n\nclass MovingObject:\n\n    def __init__(self, area):\n        self.state = self.__random_state(area)\n        self.actions = self.__create_actions(area.shape)\n        self.moves = self.__create_moves()\n\n\n# public method\n    def reset_state(self, area):\n        self.state = self.__random_state(area)\n\n\n    def get_act_index(self, epsilon):\n        return self.__select_action(epsilon)\n\n\n    def move_state(self, act_index):\n        return self.state + self.moves.get(act_index)\n\n\n# private method\n    def __random_state(self, area):\n        h, w = area.shape\n        mergin = area.mergin\n\n        while True:\n            y = numpy.random.randint(mergin, h - mergin)\n            x = numpy.random.randint(mergin, w - mergin)\n\n            if area.state[y, x] == 0:\n                break\n\n        return numpy.array([y, x])\n\n\n    def __create_actions(self, area_shape):\n        actions = []\n        h, w = area_shape\n\n        for j in range(h):\n            actions.append([])\n            for i in range(w):\n                action_org = [0, 1, 2, 3]\n                action = self.__remove_actions(action_org, h, w, j, i)\n                actions[j].append(action)\n\n        return numpy.array(actions)\n\n\n    def __remove_actions(self, action_org, h, w, j, i):\n        action = copy.deepcopy(action_org)\n        mergin = 2\n        if j == mergin:\n            action.remove(3)\n        if j == h - mergin - 1:\n            action.remove(1)\n        if i == mergin:\n            action.remove(0)\n        if i == w - mergin - 1:\n            action.remove(2)\n\n        return action\n\n\n    def __create_moves(self):\n        # 0->left, 1->down, 2-> right, 3->up\n        return {0: numpy.array([0, -1]), 1: numpy.array([1, 0]), 2: numpy.array([0, 1]), 3: numpy.array([-1, 0])}\n\n\n    def __select_action(self, epsilon):\n        y, x = self.state\n        action = self.actions[y, x]\n        if numpy.random.rand() > epsilon:\n            return self.__greedy_action(action)\n        else:\n            return self.__random_action(action)\n\n\n    def __greedy_action(self, action):\n        sy, sx = self.around\n        qmax = self.q[action, sy, sx].max()\n        indexes = list(numpy.argwhere(self.q[action, sy, sx] == qmax))\n        random.shuffle(indexes)\n\n        return action[indexes[0]]\n\n\n    def __random_action(self, action):\n        act_indexes = copy.deepcopy(action)\n        random.shuffle(act_indexes)\n\n        return act_indexes[0]\n\n\n\ntartget.py\nfrom movingobject import *\n\nclass Target(MovingObject):\n\n    def __init__(self, area):\n        MovingObject.__init__(self, area)\n        self.value = 127\n\n\n# public method\n    def act(self, area):\n        _y, _x = self.state\n        if self.__check_catched(area, _y, _x) == False:\n            area.state[_y, _x] = 0\n            while True:\n                act_index = MovingObject.get_act_index(self, 1.0)\n                y, x = MovingObject.move_state(self, act_index)\n                if area.state[y, x] == 0:\n                    self.state = numpy.array([y ,x])\n                    area.state[y, x] = self.value\n                    break\n\n\n# private method\n    def __check_catched(self, area, _y, _x):\n        check = self.__is_surrounded(area)\n        check *= self.__is_atcorners(area, _y, _x)\n\n        return check\n\n\n    def __is_surrounded(self, area):\n        t_state = numpy.argwhere(area.state == 127)\n        a_state = numpy.argwhere(area.state == 255)\n\n        return numpy.array_equal(numpy.abs((a_state - t_state).sum(axis = 1)), numpy.array([1, 1]))\n\n\n    def __is_atcorners(self, area, _y, _x):\n        h, w = area.shape\n        mergin = 2\n        c = _y == mergin or _y == h - mergin - 1\n        c *= _x == mergin or _x == w - mergin - 1\n\n        return c\n\n\n\nagent.py\nfrom movingobject import *\n\nclass Agent(MovingObject):\n\n    def __init__(self, area):\n        MovingObject.__init__(self, area)\n        self.value = 255\n        self.q = self.__creat_q_table()\n        self.around = numpy.zeros(2).astype('int')\n        self.act_index = -1\n        self.reward = 0\n\n\n# public method\n    def lookout(self, area):\n        y, x = self.state\n        self.around = self.__get_object_states(area, y, x)\n\n\n    def act(self, area, epsilon):\n        _y, _x = self.state\n        area.state[_y, _x] = 0\n        if self.__is_alone():\n            epsilon = 1.0\n        self.act_index = MovingObject.get_act_index(self, epsilon)\n        y, x = MovingObject.move_state(self, self.act_index)\n        if area.state[y, x] == 0:\n            self.state = numpy.array([y, x])\n            area.state[y, x] = self.value\n        else:\n            area.state[_y, _x] = self.value\n\n\n    def update_q(self, area, alpha, gamma):\n        sy, sx = self.around\n        self.reward = self.__get_reward(area)\n        act_index = self.act_index\n        q = self.q[act_index, sy, sx]\n        self.q[act_index, sy, sx] = q + alpha * (self.reward + gamma * self.__get_max_q() - q)\n\n\n    def save_q(self, fname):\n        numpy.save(fname, self.q)\n\n\n# private method\n    def __creat_q_table(self):\n        q = numpy.zeros((4, 26, 26))\n\n        return q\n\n    def __get_object_states(self, area, y, x):\n        mergin = area.mergin\n        around = area.state[y - mergin: y + mergin + 1, x - mergin: x + mergin + 1].reshape((1, -1))\n        t_state = numpy.argwhere(around == 127)[:, 1]\n        _a_state = numpy.argwhere(around == 255)[:, 1]\n        a_state = numpy.delete(_a_state, numpy.argwhere(_a_state == 12)[:, 0], axis = 0)\n        if numpy.array_equal(t_state, numpy.array([])):\n            t_state = numpy.array([25])\n        if numpy.array_equal(a_state, numpy.array([])):\n            a_state = numpy.array([25])\n\n        return numpy.r_[t_state, a_state]\n\n\n    def __is_alone(self):\n        return numpy.array_equal(self.around, numpy.array([25, 25]))\n\n\n    def __get_reward(self, area):\n        return 3 if self.__is_surrounding(area) else -1\n\n\n    def __is_surrounding(self, area):\n        t_state = numpy.argwhere(area.state == 127)\n        a_state = numpy.argwhere(area.state == 255)\n\n        check = numpy.array_equal(numpy.abs((a_state - t_state).sum(axis = 1)), numpy.array([1, 1]))\n        check += numpy.array_equal(a_state.mean(axis = 0), t_state)\n\n        return check\n\n\n    def __get_max_q(self):\n        y, x = self.state\n        actions = self.actions[y, x]\n        sy, sx = self.around\n        _sy, _sx = self.__next_around(sy, sx)\n        return self.q[actions, _sy, _sx].max()\n\n\n    def __next_around(self, sy, sx):\n        act_index = self.act_index\n        _sy = self.__next_state(act_index, sy)\n        _sx = self.__next_state(act_index, sx)\n\n        return numpy.array([_sy, _sx])\n\n\n    def __next_state(self, act_index, z):\n        if z != 25:\n            if act_index == 0 and (z + 1) % 5 != 0:\n                z += 1\n            elif act_index == 1 and z / 5 != 0:\n                z -= 5\n            elif act_index == 2 and z % 5 != 0:\n                z -= 1\n            elif act_index == 3 and z / 5 != 4:\n                z += 5\n            else:\n                z = 25\n\n        return z\n\n\n\narea.py\nimport numpy\n\nclass Area:\n\n    def __init__(self, shape, mergin):\n        self.shape = shape\n        self.mergin = mergin\n        self.state = self.__init_state()\n\n\n# public method\n    def update_state(self, mvobj):\n        y, x = mvobj.state\n        self.state[y, x] = mvobj.value\n\n\n    def reset_state(self):\n        self.state = self.__init_state()\n\n\n# private method\n    def __init_state(self):\n        return numpy.zeros(self.shape).astype('uint8')\n\n\n\ngameservice.py\nfrom model.area import Area\nfrom model.agent import Agent\nfrom model.target import Target\n\nclass GameService:\n\n    def __init__(self):\n        'SERVICE'\n\n    def construct(self, area_shape, mergin):\n        area = Area(area_shape, mergin)\n        agent1 = Agent(area)\n        area.update_state(agent1)\n        agent2 = Agent(area)\n        area.update_state(agent2)\n        target = Target(area)\n        area.update_state(target)\n\n        return (area, agent1, agent2, target)\n\n\n    def turn(self, area, agent1, agent2, target, epsilon):\n        agent1.lookout(area)\n        agent2.lookout(area)\n        agent1.act(area, epsilon)\n        agent2.act(area, epsilon)\n        target.act(area)\n\n\n    def reset(self, area, agent1, agent2, target):\n        area.reset_state()\n        agent1.reset_state(area)\n        area.update_state(agent1)\n        agent2.reset_state(area)\n        area.update_state(agent2)\n        target.reset_state(area)\n        area.update_state(target)\n\n\n\nmain.py\nfrom service.gameservice import GameService\nimport numpy\nimport cv2\nfrom matplotlib import pyplot\n\nif __name__ == '__main__':\n\n    # init\n    h = 24\n    w = 24\n    area_shape = (h, w)\n    mergin = 2\n    epsilon = 0.3\n    alpha = 0.3\n    gamma = 0.7\n    image_shape = (200, 200)\n\n    # count\n    total_plays = 300\n    total_steps = numpy.zeros(total_plays).astype('int')\n    play = 0\n    steps = 0\n\n    # construct\n    gameservice = GameService()\n    area, agent1, agent2, target = gameservice.construct(area_shape, mergin)\n\n    # video writer\n    writer = cv2.VideoWriter('q-learning.mv4', cv2.cv.FOURCC('m', 'p', '4', 'v'), 20, image_shape)\n\n    while True:\n        # disp\n        print u'play: %d, steps: %d' % (play, steps)\n\n        # act\n        gameservice.turn(area, agent1, agent2, target, epsilon)\n\n        # update area and agents' q talbe\n        agent1.update_q(area, alpha, gamma)\n        agent2.update_q(area, alpha, gamma)\n\n        # show image\n        image = cv2.resize(area.state[mergin:h - mergin, mergin:w - mergin], image_shape, interpolation = cv2.INTER_NEAREST)\n        writer.write(cv2.cvtColor(image, cv2.COLOR_GRAY2BGR))\n        cv2.imshow('', image)\n        if cv2.waitKey() == 27:\n            break\n\n        # refresh state if agents catch the taget\n        steps += 1\n        if agent1.reward == 3:\n            print '\\033[32m' + '!!!catch the target!!!' + '\\033[0m'\n            gameservice.reset(area, agent1, agent2, target)\n            agent1.save_q('q1.npy')\n            agent2.save_q('q2.npy')\n            total_steps[play] = steps\n            steps = 0\n            play += 1\n\n        # count\n        if play == total_plays:\n            break\n\n    pyplot.plot(numpy.arange(0, total_plays), total_steps)\n    pyplot.savefig('graph.png')\n    cv2.destroyAllWindows()\n    print '!!!finish!!!'\n\n\n\n\u30dd\u30a4\u30f3\u30c8\n\u305d\u308c\u305e\u308c\u306e\u30a8\u30fc\u30b8\u30a7\u30f3\u30c8\u306f\u72ec\u7acb\u3057\u305f $Q$ \u5024\u3092\u6301\u3061\u307e\u3059\uff0e\n\u72b6\u614b $s$ \u306f\u30a8\u30fc\u30b8\u30a7\u30f3\u30c8\u306e\u5ea7\u6a19\u3068\u30bf\u30fc\u30b2\u30c3\u30c8\u306e\u5ea7\u6a19\u3067\u8868\u73fe\u3057\u307e\u3059\uff0e\u5ea7\u6a19\u306f\u5de6\u4e0a\u304b\u3089\u9806\u306b\u6c7a\u5b9a\u3057\u3066\u3044\u307e\u3059\uff0e\n\u8a8d\u8b58\u9818\u57df\u5185\u306b\u30a8\u30fc\u30b8\u30a7\u30f3\u30c8\u3042\u308b\u3044\u306f\u30bf\u30fc\u30b2\u30c3\u30c8\u304c\u3044\u306a\u3044\u5834\u5408\u3092 $25$ \u3068\u3044\u3046\u6570\u5024\u3067\u8868\u3057\u307e\u3059\uff0e\n\u884c\u52d5\u306f\uff0c\u5de6\u4e0b\u53f3\u4e0a\u306e\u9806\u306b $0, 1, 2, 3$ \u306e\u6570\u5024\u3067\u8868\u73fe\u3057\u307e\u3059\uff0e\n\uff08\u884c\u52d5\u6570\uff09$\\times$\uff08\u30bf\u30fc\u30b2\u30c3\u30c8\u306e\u5ea7\u6a19\uff09$\\times$\uff08\u30a8\u30fc\u30b8\u30a7\u30f3\u30c8\u306e\u5ea7\u6a19\uff09\u3068\u306a\u308b\u306e\u3067\uff0c$Q$ \u5024\u306e\u30b5\u30a4\u30ba\u306f $4 \\times 26 \\times 26$ \u3068\u306a\u308a\u307e\u3059\uff0e \n$Q$ \u5024\u306e\u66f4\u65b0\u306e\u969b\uff0c\u30a8\u30fc\u30b8\u30a7\u30f3\u30c8\u3084\u30bf\u30fc\u30b2\u30c3\u30c8\u304c\u3069\u306e\u3088\u3046\u306b\u884c\u52d5\u3059\u308b\u304b\u3092\u77e5\u308b\u3053\u3068\u306f\u3067\u304d\u306a\u3044\u306e\u3067\uff0c\n\u79fb\u52d5\u5148\u3067\u306e\u5468\u56f2\u306e\u72b6\u614b\u306f\u81ea\u5206\u306e\u884c\u52d5\u306b\u306e\u307f\u4f9d\u5b58\u3057\uff0c\u305d\u306e\u884c\u52d5\u306e\u5206\u5909\u5316\u3059\u308b\u3082\u306e\u3068\u3057\u3066\u3044\u307e\u3059\uff0e\n\n\n\n\n\n\n\n\n\n\n\n\n0\n1\n2\n3\n4\n\n\n5\n6\n7\n8\n9\n\n\n10\n11\n12\n13\n14\n\n\n15\n16\n17\n18\n19\n\n\n20\n21\n22\n23\n24\n\n\n\n\u2191\u30a8\u30fc\u30b8\u30a7\u30f3\u30c8\u306e\u8a8d\u8b58\u3059\u308b\u7bc4\u56f2\u3068\u305d\u306e\u5ea7\u6a19\n\n\u7d50\u679c\n\n\u30b0\u30e9\u30d5\n\u30bf\u30fc\u30b2\u30c3\u30c8\u3092\u6355\u7372\u3059\u308b\u306e\u306b\u304b\u304b\u3063\u305f\u30b9\u30c6\u30c3\u30d7\u6570\u3092\u7e26\u8ef8\u306b\uff0c\u8a66\u884c\u56de\u6570\u3092\u6a2a\u8ef8\u306b\u3057\u305f\u30b0\u30e9\u30d5\u3092\u4ee5\u4e0b\u306b\u793a\u3057\u307e\u3059\uff0e\n\u72ec\u7acb\u3057\u305f $300$ \u56de\u306e\u8a66\u884c\u3092 $30$ \u56de\u884c\u3044\uff0c\u5404\u8a66\u884c\u306b\u304a\u3051\u308b\u30b9\u30c6\u30c3\u30d7\u6570\u306e\u5e73\u5747\u3092\u7e26\u8ef8\u306e\u5024\u3068\u3057\u3066\u3044\u307e\u3059\uff0e\n\u5b66\u7fd2\u304c\u9032\u3080\u306b\u3064\u308c\u3066\uff0c\u30bf\u30fc\u30b2\u30c3\u30c8\u3092\u6355\u7372\u3059\u308b\u306e\u306b\u304b\u304b\u308b\u30b9\u30c6\u30c3\u30d7\u6570\u304c\u6e1b\u5c11\u3057\u3066\u3044\u308b\u306e\u304c\u78ba\u8a8d\u3067\u304d\u307e\u3059\uff0e\n\n\n\u884c\u52d5\n\u5b66\u7fd2\u3055\u308c\u305f\u884c\u52d5\u306e\u4e00\u4f8b\u3092\u753b\u50cf\u306b\u3057\u307e\u3057\u305f\uff0e\u767d\u8272\u304c\u30a8\u30fc\u30b8\u30a7\u30f3\u30c8\uff0c\u7070\u8272\u304c\u30bf\u30fc\u30b2\u30c3\u30c8\u3067\u3059\uff0e\n\u30bf\u30fc\u30b2\u30c3\u30c8\u3092\u8ffd\u3044\u8a70\u3081\u308b\u3088\u3046\u306a\u884c\u52d5\u3092\u5b66\u7fd2\u3067\u304d\u3066\u3044\u307e\u3059\uff0e\n\u5b9f\u969b\u306f\u5b66\u7fd2\u304c\u3046\u307e\u304f\u3044\u3063\u3066\u3044\u306a\u3044\u753b\u50cf\u3082\u3042\u308a\u307e\u3059\u304c\uff0c\u8003\u5bdf\u3067\u304d\u3066\u3044\u306a\u3044\u306e\u3067\u5272\u611b\u3057\u307e\u3059\uff0e\n\n\n\u304a\u308f\u308a\u306b\npython\u3067\u30de\u30eb\u30c1\u30a8\u30fc\u30b8\u30a7\u30f3\u30c8\u8ffd\u8de1\u554f\u984c\u3092\u89e3\u3044\u3066\u307f\u307e\u3057\u305f\uff0e\n\u5b9f\u88c5\u304c\u3046\u307e\u304f\u3044\u3063\u3066\u3044\u306a\u3044\u70b9\u3082\u3042\u308b\u304b\u3082\u3057\u308c\u306a\u3044\u306e\u3067\uff0c\u6307\u6458\u3042\u308c\u3070\u304a\u9858\u3044\u3057\u307e\u3059\uff0e\n\u4eca\u56de\u30a8\u30fc\u30b8\u30a7\u30f3\u30c8\u3068\u30bf\u30fc\u30b2\u30c3\u30c8\u304c\u898b\u3048\u3066\u3044\u308b\u72b6\u614b\u3067\u306e\u5b66\u7fd2\u7d50\u679c\u3057\u304b\u78ba\u8a8d\u3057\u3066\u3044\u307e\u305b\u3093\u304c\uff0c\n\u3069\u3061\u3089\u304b\u4e00\u65b9\u3057\u304b\u898b\u3048\u306a\u3044\u72b6\u614b\u3067\u306e\u5b66\u7fd2\u7d50\u679c\u3082\u78ba\u8a8d\u3057\u3066\u307f\u3088\u3046\u3068\u601d\u3044\u307e\u3059\uff0e\n\u767a\u898b\u304c\u3042\u3063\u305f\u3089\u968f\u6642\u8ffd\u8a18\u3057\u3066\u3044\u304d\u307e\u3059\uff0e\n# \u306f\u3058\u3081\u306b\n\npython\u3067\u30de\u30eb\u30c1\u30a8\u30fc\u30b8\u30a7\u30f3\u30c8\u8ffd\u8de1\u554f\u984c\u3092\u89e3\u3044\u3066\u307f\u307e\u3057\u305f\uff0e\n\u6559\u79d1\u66f8\u3068\u3057\u3066[\u300e\u5b66\u7fd2\u3068\u305d\u306e\u30a2\u30eb\u30b4\u30ea\u30ba\u30e0\u300f](http://www.amazon.co.jp/\u5b66\u7fd2\u3068\u305d\u306e\u30a2\u30eb\u30b4\u30ea\u30ba\u30e0\u2015\u30cb\u30e5\u30fc\u30e9\u30eb\u30cd\u30c3\u30c8\u30ef\u30fc\u30af\u30fb\u907a\u4f1d\u30a2\u30eb\u30b4\u30ea\u30ba\u30e0\u30fb\u5f37\u5316\u5b66\u7fd2-\u96fb\u6c17\u5b66\u4f1aGA\u30cb\u30e5\u30fc\u30ed\u3092\u7528\u3044\u305f\u5b66\u7fd2\u6cd5\u3068\u305d\u306e\u5fdc\u7528\u8abf\u67fb\u5c02\u9580\u59d4\u54e1\u4f1a/dp/4627827512/ref=sr_1_2?s=books&ie=UTF8&qid=1464583596&sr=1-2&keywords=\u5b66\u7fd2\u3068\u305d\u306e\u30a2\u30eb\u30b4\u30ea\u30ba\u30e0)\u3092\u4f7f\u3044\u307e\u3057\u305f\uff0e\n\n\u672c\u8a18\u4e8b\u306e\u69cb\u6210\n\n* \u306f\u3058\u3081\u306b\n* \u30de\u30eb\u30c1\u30a8\u30fc\u30b8\u30a7\u30f3\u30c8\u8ffd\u8de1\n    * \u30eb\u30fc\u30eb\n    * Q \u5024\u306e\u66f4\u65b0\n* \u5b9f\u88c5\n    * \u30b3\u30fc\u30c9\n    * \u30dd\u30a4\u30f3\u30c8\n* \u7d50\u679c\n* \u304a\u308f\u308a\u306b\n\n\n# \u30de\u30eb\u30c1\u30a8\u30fc\u30b8\u30a7\u30f3\u30c8\u8ffd\u8de1\n\n$2$ \u3064\u306e\u30a8\u30fc\u30b8\u30a7\u30f3\u30c8\u3067 $1$ \u3064\u306e\u30bf\u30fc\u30b2\u30c3\u30c8\u3092\u6355\u7372\u3059\u308b\u305f\u3081\u306e\u6700\u9069\u306a\u884c\u52d5\u3092\u5b66\u7fd2\u3057\u307e\u3059\uff0e\n\u30a8\u30fc\u30b8\u30a7\u30f3\u30c8\u304c\u30bf\u30fc\u30b2\u30c3\u30c8\u3092\u631f\u307f\u8fbc\u3093\u3060\u72b6\u614b\u3092\uff0c\u6355\u7372\u3057\u305f\u72b6\u614b\u3068\u5b9a\u7fa9\u3057\u307e\u3059\uff0e\n\u300c\u631f\u307f\u8fbc\u3080\u300d\u3068\u306f\uff0c\u30bf\u30fc\u30b2\u30c3\u30c8\u306e $4$ \u8fd1\u508d\u306e\u3046\u3061 $2$ \u7b87\u6240\u306b\u30a8\u30fc\u30b8\u30a7\u30f3\u30c8\u304c\u5b58\u5728\u3059\u308b\u72b6\u614b\u3092\u6307\u3057\u307e\u3059\uff0e\n\n## \u30eb\u30fc\u30eb\n\n\u8a73\u7d30\u306a\u30eb\u30fc\u30eb\u3092\u4ee5\u4e0b\u306b\u793a\u3057\u307e\u3059\uff0e[\u300e\u5b66\u7fd2\u3068\u305d\u306e\u30a2\u30eb\u30b4\u30ea\u30ba\u30e0\u300f](http://www.amazon.co.jp/\u5b66\u7fd2\u3068\u305d\u306e\u30a2\u30eb\u30b4\u30ea\u30ba\u30e0\u2015\u30cb\u30e5\u30fc\u30e9\u30eb\u30cd\u30c3\u30c8\u30ef\u30fc\u30af\u30fb\u907a\u4f1d\u30a2\u30eb\u30b4\u30ea\u30ba\u30e0\u30fb\u5f37\u5316\u5b66\u7fd2-\u96fb\u6c17\u5b66\u4f1aGA\u30cb\u30e5\u30fc\u30ed\u3092\u7528\u3044\u305f\u5b66\u7fd2\u6cd5\u3068\u305d\u306e\u5fdc\u7528\u8abf\u67fb\u5c02\u9580\u59d4\u54e1\u4f1a/dp/4627827512/ref=sr_1_2?s=books&ie=UTF8&qid=1464583596&sr=1-2&keywords=\u5b66\u7fd2\u3068\u305d\u306e\u30a2\u30eb\u30b4\u30ea\u30ba\u30e0)\u306e\u30eb\u30fc\u30eb\u3092\u63a1\u7528\u3057\u3066\u3044\u307e\u3059\uff0e\n\n1. \u74b0\u5883\u3068\u3057\u3066 $20 \\times 20$ \u306e\u683c\u5b50\u72b6\u30c8\u30fc\u30e9\u30b9\u5e73\u9762\u3092\u8a2d\u3051\u308b\uff0e\n2. $2$ \u3064\u306e\u30a8\u30fc\u30b8\u30a7\u30f3\u30c8\u3068 $1$ \u3064\u306e\u30bf\u30fc\u30b2\u30c3\u30c8\u3092\u74b0\u5883\u4e2d\u306b\u30e9\u30f3\u30c0\u30e0\u306b\u914d\u7f6e\u3059\u308b\uff0e\n3. \u30a8\u30fc\u30b8\u30a7\u30f3\u30c8\u306f\u81ea\u5206\u3092\u4e2d\u5fc3\u3068\u3057\u305f $2$ \u683c\u5b50\u5206\u306e\u72b6\u614b\u3092\u89b3\u6e2c\u3059\u308b\u3053\u3068\u304c\u3067\u304d\u308b\uff0e  \n\u3059\u306a\u308f\u3061\uff0c\u81ea\u5206\u306e\u3044\u308b\u683c\u5b50\u3092\u542b\u3081 $25$ \u683c\u5b50\u5206\u3092\u72b6\u614b\u3068\u3057\u3066\u8a8d\u8b58\u3059\u308b\uff0e\n4. \u305d\u308c\u305e\u308c\u306e\u30a8\u30fc\u30b8\u30a7\u30f3\u30c8\u306f\uff0c\u72ec\u7acb\u306b Q-learning \u3092\u9032\u3081\u308b\uff0e  \n\u5b66\u7fd2\u7d50\u679c\u306b\u57fa\u3065\u3044\u3066\uff0c$1$ \u30b9\u30c6\u30c3\u30d7\u306b\u3064\u304d\u4e0a\u4e0b\u5de6\u53f3\u306e\u3044\u305a\u308c\u304b\u306b $1$ \u683c\u5b50\u79fb\u52d5\u3059\u308b\u884c\u52d5\u304c\u9078\u629e\u3055\u308c\u308b\uff0e  \n\u5404\u884c\u52d5\u306b\u3064\u304d $-1$ \u306e\u5831\u916c\u304c\u3064\u306d\u306b\u4e0e\u3048\u3089\u308c\u308b\uff0e  \n\u79fb\u52d5\u5148\u306b\u3059\u3067\u306b\u5225\u306e\u30a8\u30fc\u30b8\u30a7\u30f3\u30c8\u3042\u308b\u3044\u306f\u30bf\u30fc\u30b2\u30c3\u30c8\u304c\u5b58\u5728\u3059\u308b\u5834\u5408\u306f\u305d\u306e\u5834\u306b\u7559\u307e\u308b.\n5. \u30bf\u30fc\u30b2\u30c3\u30c8\u306f\uff0c$1$ \u30b9\u30c6\u30c3\u30d7\u306b\u3064\u304d\u4e0a\u4e0b\u5de6\u53f3\u306e\u3044\u305a\u308c\u304b\u306e\u65b9\u5411\u3078\u30e9\u30f3\u30c0\u30e0\u306b\u79fb\u52d5\u3059\u308b\uff0e\u79fb\u52d5\u5148\u306b\u30a8\u30fc\u30b8\u30a7\u30f3\u30c8\u304c\u5b58\u5728\u3059\u308b\u5834\u5408\u306f\uff0c\u5225\u306e\u30e9\u30f3\u30c0\u30e0\u306a\u884c\u52d5\u3092\u9078\u629e\u3059\u308b\uff0e\n6. $2$ \u3064\u306e\u30a8\u30fc\u30b8\u30a7\u30f3\u30c8\u304c\u30bf\u30fc\u30b2\u30c3\u30c8\u3092\u631f\u307f\u8fbc\u3093\u3060\u6642\u70b9\u3067 $2$ \u3064\u306e\u30a8\u30fc\u30b8\u30a7\u30f3\u30c8\u305d\u308c\u305e\u308c\u306b\u5831\u916c\u3092\u4e0e\u3048\uff0c$1$ \u56de\u306e\u8a66\u884c\u3092\u7d42\u4e86\u3059\u308b\uff0e\u305d\u306e\u5f8c\uff0c2. \u306b\u623b\u308a\u6b21\u306e\u8a66\u884c\u3092\u958b\u59cb\u3059\u308b\uff0e\n\n\n## Q \u5024\u306e\u66f4\u65b0\n\n\u4ee5\u4e0b\u306e\u5f0f\u306b\u3088\u308a $Q$ \u5024\u3092\u66f4\u65b0\u3057\u307e\u3059\uff0e\n\n```math\nQ_{new}(s_t, a) = Q_{old}(s_t, a) + \\alpha\\bigl[r_{t+1} + \\gamma max_{a'}Q(s_{t+1}, a') - Q_{old}(s_t, a)\\bigr]\n```\n\n$Q(s_t, a)$ \u306f\uff0c\u3042\u308b\u72b6\u614b $s_t$ \u3067\u306e\u884c\u52d5 $a$ \u306e\u4fa1\u5024\u3092\u8868\u3057\u307e\u3059\uff0e\u72b6\u614b $s_t$ \u3067\u306e\u884c\u52d5 $a$ \u306b\u3088\u308a\u5831\u916c $r_{t+1}$ \u304c\u5f97\u3089\u308c\u307e\u3059\uff0e\n$Q$ \u5024\u3092\u66f4\u65b0\u3059\u308b\u969b\uff0c\u76f4\u8fd1\u306e\u5831\u916c $r_{t+1}$ \u306b\uff0c\u305d\u306e\u6b21\u306e\u72b6\u614b $s_{t+1}$ \u306b\u304a\u3051\u308b\u884c\u52d5 $a'$ \u306b\u3088\u3063\u3066\u5f97\u3089\u308c\u308b\u4fa1\u5024\u306e\u6700\u5927\u5024\u306b $\\gamma$ \u3092\u4e57\u3058\u305f\u3082\u306e\u3092\u52a0\u3048\u307e\u3059\uff0e\n\u3053\u308c\u306f\uff0c\u3042\u308b\u72b6\u614b\u3067\u306e\u884c\u52d5\u3092\u76f4\u8fd1\u306e\u5831\u916c\u3060\u3051\u3067\u306a\u304f\uff0c\u305d\u306e\u5f8c\u306e\u72b6\u614b\u306b\u304a\u3051\u308b\u4fa1\u5024\u3092\u52a0\u5473\u3057\u3066\u884c\u52d5\u3092\u9078\u629e\u3059\u308b\u3053\u3068\u3092\u610f\u5473\u3057\u307e\u3059\uff0e\n$\\gamma$ \u3092\u5272\u5f15\u7387\uff0c$\\alpha$ \u3092\u5b66\u7fd2\u7387\u3068\u547c\u3073\u307e\u3059\uff0e\n\n\n# \u5b9f\u88c5\n\n\u30b3\u30fc\u30c9\u3068\u30dd\u30a4\u30f3\u30c8\u306b\u5206\u3051\u3066\u8f09\u305b\u307e\u3059\uff0e\n\n## \u30b3\u30fc\u30c9\n\n\u4ee5\u4e0b\u306e\u3088\u3046\u306b\u5b9f\u88c5\u3057\u307e\u3057\u305f\uff0e\n\n```\n.\n\u251c\u2500\u2500 main.py\n\u251c\u2500\u2500 model\n\u2502\u00a0\u00a0 \u251c\u2500\u2500 agent.py\n\u2502\u00a0\u00a0 \u251c\u2500\u2500 area.py\n\u2502\u00a0\u00a0 \u251c\u2500\u2500 movingobject.py\n\u2502\u00a0\u00a0 \u251c\u2500\u2500 target.py\n\u2514\u2500\u2500 service\n \u00a0\u00a0 \u2514\u2500\u2500 gameservice.py\n```\n\n```movingobject.py\nimport numpy\nimport random\nimport copy\n\nclass MovingObject:\n\n    def __init__(self, area):\n        self.state = self.__random_state(area)\n        self.actions = self.__create_actions(area.shape)\n        self.moves = self.__create_moves()\n\n\n# public method\n    def reset_state(self, area):\n        self.state = self.__random_state(area)\n\n\n    def get_act_index(self, epsilon):\n        return self.__select_action(epsilon)\n\n\n    def move_state(self, act_index):\n        return self.state + self.moves.get(act_index)\n\n\n# private method\n    def __random_state(self, area):\n        h, w = area.shape\n        mergin = area.mergin\n\n        while True:\n            y = numpy.random.randint(mergin, h - mergin)\n            x = numpy.random.randint(mergin, w - mergin)\n\n            if area.state[y, x] == 0:\n                break\n\n        return numpy.array([y, x])\n\n\n    def __create_actions(self, area_shape):\n        actions = []\n        h, w = area_shape\n\n        for j in range(h):\n            actions.append([])\n            for i in range(w):\n                action_org = [0, 1, 2, 3]\n                action = self.__remove_actions(action_org, h, w, j, i)\n                actions[j].append(action)\n\n        return numpy.array(actions)\n\n\n    def __remove_actions(self, action_org, h, w, j, i):\n        action = copy.deepcopy(action_org)\n        mergin = 2\n        if j == mergin:\n            action.remove(3)\n        if j == h - mergin - 1:\n            action.remove(1)\n        if i == mergin:\n\t\t\taction.remove(0)\n        if i == w - mergin - 1:\n\t\t\taction.remove(2)\n\n        return action\n\n\n    def __create_moves(self):\n        # 0->left, 1->down, 2-> right, 3->up\n        return {0: numpy.array([0, -1]), 1: numpy.array([1, 0]), 2: numpy.array([0, 1]), 3: numpy.array([-1, 0])}\n\n\n    def __select_action(self, epsilon):\n        y, x = self.state\n        action = self.actions[y, x]\n        if numpy.random.rand() > epsilon:\n            return self.__greedy_action(action)\n        else:\n            return self.__random_action(action)\n\n\n    def __greedy_action(self, action):\n        sy, sx = self.around\n        qmax = self.q[action, sy, sx].max()\n        indexes = list(numpy.argwhere(self.q[action, sy, sx] == qmax))\n        random.shuffle(indexes)\n\n        return action[indexes[0]]\n\n\n    def __random_action(self, action):\n        act_indexes = copy.deepcopy(action)\n        random.shuffle(act_indexes)\n\n        return act_indexes[0]\n```\n\n```tartget.py\nfrom movingobject import *\n\nclass Target(MovingObject):\n\n\tdef __init__(self, area):\n\t\tMovingObject.__init__(self, area)\n\t\tself.value = 127\n\n\n# public method\n\tdef act(self, area):\n\t\t_y, _x = self.state\n\t\tif self.__check_catched(area, _y, _x) == False:\n\t\t\tarea.state[_y, _x] = 0\n\t\t\twhile True:\n\t\t\t\tact_index = MovingObject.get_act_index(self, 1.0)\n\t\t\t\ty, x = MovingObject.move_state(self, act_index)\n\t\t\t\tif area.state[y, x] == 0:\n\t\t\t\t\tself.state = numpy.array([y ,x])\n\t\t\t\t\tarea.state[y, x] = self.value\n\t\t\t\t\tbreak\n\n\n# private method\n\tdef __check_catched(self, area, _y, _x):\n\t\tcheck = self.__is_surrounded(area)\n\t\tcheck *= self.__is_atcorners(area, _y, _x)\n\n\t\treturn check\n\n\n\tdef __is_surrounded(self, area):\n\t\tt_state = numpy.argwhere(area.state == 127)\n\t\ta_state = numpy.argwhere(area.state == 255)\n\n\t\treturn numpy.array_equal(numpy.abs((a_state - t_state).sum(axis = 1)), numpy.array([1, 1]))\n\n\n\tdef __is_atcorners(self, area, _y, _x):\n\t\th, w = area.shape\n\t\tmergin = 2\n\t\tc = _y == mergin or _y == h - mergin - 1\n\t\tc *= _x == mergin or _x == w - mergin - 1\n\n\t\treturn c\n```\n\n```agent.py\nfrom movingobject import *\n\nclass Agent(MovingObject):\n\n\tdef __init__(self, area):\n\t\tMovingObject.__init__(self, area)\n\t\tself.value = 255\n\t\tself.q = self.__creat_q_table()\n\t\tself.around = numpy.zeros(2).astype('int')\n\t\tself.act_index = -1\n\t\tself.reward = 0\n\n\n# public method\n\tdef lookout(self, area):\n\t\ty, x = self.state\n\t\tself.around = self.__get_object_states(area, y, x)\n\n\n\tdef act(self, area, epsilon):\n\t\t_y, _x = self.state\n\t\tarea.state[_y, _x] = 0\n\t\tif self.__is_alone():\n\t\t\tepsilon = 1.0\n\t\tself.act_index = MovingObject.get_act_index(self, epsilon)\n\t\ty, x = MovingObject.move_state(self, self.act_index)\n\t\tif area.state[y, x] == 0:\n\t\t\tself.state = numpy.array([y, x])\n\t\t\tarea.state[y, x] = self.value\n\t\telse:\n\t\t\tarea.state[_y, _x] = self.value\n\n\n\tdef update_q(self, area, alpha, gamma):\n\t\tsy, sx = self.around\n\t\tself.reward = self.__get_reward(area)\n\t\tact_index = self.act_index\n\t\tq = self.q[act_index, sy, sx]\n\t\tself.q[act_index, sy, sx] = q + alpha * (self.reward + gamma * self.__get_max_q() - q)\n\n\n\tdef save_q(self, fname):\n\t\tnumpy.save(fname, self.q)\n\n\n# private method\n\tdef __creat_q_table(self):\n\t\tq = numpy.zeros((4, 26, 26))\n\n\t\treturn q\n\n\tdef __get_object_states(self, area, y, x):\n\t\tmergin = area.mergin\n\t\taround = area.state[y - mergin: y + mergin + 1, x - mergin: x + mergin + 1].reshape((1, -1))\n\t\tt_state = numpy.argwhere(around == 127)[:, 1]\n\t\t_a_state = numpy.argwhere(around == 255)[:, 1]\n\t\ta_state = numpy.delete(_a_state, numpy.argwhere(_a_state == 12)[:, 0], axis = 0)\n\t\tif numpy.array_equal(t_state, numpy.array([])):\n\t\t\tt_state = numpy.array([25])\n\t\tif numpy.array_equal(a_state, numpy.array([])):\n\t\t\ta_state = numpy.array([25])\n\n\t\treturn numpy.r_[t_state, a_state]\n\n\n\tdef __is_alone(self):\n\t\treturn numpy.array_equal(self.around, numpy.array([25, 25]))\n\n\n\tdef __get_reward(self, area):\n\t\treturn 3 if self.__is_surrounding(area) else -1\n\n\n\tdef __is_surrounding(self, area):\n\t\tt_state = numpy.argwhere(area.state == 127)\n\t\ta_state = numpy.argwhere(area.state == 255)\n\n\t\tcheck = numpy.array_equal(numpy.abs((a_state - t_state).sum(axis = 1)), numpy.array([1, 1]))\n\t\tcheck += numpy.array_equal(a_state.mean(axis = 0), t_state)\n\n\t\treturn check\n\n\n\tdef __get_max_q(self):\n\t\ty, x = self.state\n\t\tactions = self.actions[y, x]\n\t\tsy, sx = self.around\n\t\t_sy, _sx = self.__next_around(sy, sx)\n\t\treturn self.q[actions, _sy, _sx].max()\n\n\n\tdef __next_around(self, sy, sx):\n\t\tact_index = self.act_index\n\t\t_sy = self.__next_state(act_index, sy)\n\t\t_sx = self.__next_state(act_index, sx)\n\n\t\treturn numpy.array([_sy, _sx])\n\n\n\tdef __next_state(self, act_index, z):\n\t\tif z != 25:\n\t\t\tif act_index == 0 and (z + 1) % 5 != 0:\n\t\t\t\tz += 1\n\t\t\telif act_index == 1 and z / 5 != 0:\n\t\t\t\tz -= 5\n\t\t\telif act_index == 2 and z % 5 != 0:\n\t\t\t\tz -= 1\n\t\t\telif act_index == 3 and z / 5 != 4:\n\t\t\t\tz += 5\n\t\t\telse:\n\t\t\t\tz = 25\n\n\t\treturn z\n```\n\n```area.py\nimport numpy\n\nclass Area:\n\n    def __init__(self, shape, mergin):\n        self.shape = shape\n        self.mergin = mergin\n        self.state = self.__init_state()\n\n\n# public method\n    def update_state(self, mvobj):\n        y, x = mvobj.state\n        self.state[y, x] = mvobj.value\n\n\n    def reset_state(self):\n        self.state = self.__init_state()\n\n\n# private method\n    def __init_state(self):\n        return numpy.zeros(self.shape).astype('uint8')\n```\n\n```gameservice.py\nfrom model.area import Area\nfrom model.agent import Agent\nfrom model.target import Target\n\nclass GameService:\n\n    def __init__(self):\n        'SERVICE'\n\n    def construct(self, area_shape, mergin):\n        area = Area(area_shape, mergin)\n    \tagent1 = Agent(area)\n        area.update_state(agent1)\n    \tagent2 = Agent(area)\n        area.update_state(agent2)\n    \ttarget = Target(area)\n        area.update_state(target)\n\n        return (area, agent1, agent2, target)\n\n\n    def turn(self, area, agent1, agent2, target, epsilon):\n        agent1.lookout(area)\n        agent2.lookout(area)\n        agent1.act(area, epsilon)\n        agent2.act(area, epsilon)\n        target.act(area)\n\n\n    def reset(self, area, agent1, agent2, target):\n        area.reset_state()\n        agent1.reset_state(area)\n        area.update_state(agent1)\n        agent2.reset_state(area)\n        area.update_state(agent2)\n        target.reset_state(area)\n        area.update_state(target)\n```\n\n```main.py\nfrom service.gameservice import GameService\nimport numpy\nimport cv2\nfrom matplotlib import pyplot\n\nif __name__ == '__main__':\n\n\t# init\n\th = 24\n\tw = 24\n\tarea_shape = (h, w)\n\tmergin = 2\n\tepsilon = 0.3\n\talpha = 0.3\n\tgamma = 0.7\n\timage_shape = (200, 200)\n\n\t# count\n\ttotal_plays = 300\n\ttotal_steps = numpy.zeros(total_plays).astype('int')\n\tplay = 0\n\tsteps = 0\n\n\t# construct\n\tgameservice = GameService()\n\tarea, agent1, agent2, target = gameservice.construct(area_shape, mergin)\n\n\t# video writer\n\twriter = cv2.VideoWriter('q-learning.mv4', cv2.cv.FOURCC('m', 'p', '4', 'v'), 20, image_shape)\n\n\twhile True:\n\t\t# disp\n\t\tprint u'play: %d, steps: %d' % (play, steps)\n\n\t\t# act\n\t\tgameservice.turn(area, agent1, agent2, target, epsilon)\n\n\t\t# update area and agents' q talbe\n\t\tagent1.update_q(area, alpha, gamma)\n\t\tagent2.update_q(area, alpha, gamma)\n\n\t\t# show image\n\t\timage = cv2.resize(area.state[mergin:h - mergin, mergin:w - mergin], image_shape, interpolation = cv2.INTER_NEAREST)\n\t\twriter.write(cv2.cvtColor(image, cv2.COLOR_GRAY2BGR))\n\t\tcv2.imshow('', image)\n\t\tif cv2.waitKey() == 27:\n\t\t \tbreak\n\n\t\t# refresh state if agents catch the taget\n\t\tsteps += 1\n\t\tif agent1.reward == 3:\n\t\t\tprint '\\033[32m' + '!!!catch the target!!!' + '\\033[0m'\n\t\t\tgameservice.reset(area, agent1, agent2, target)\n\t\t\tagent1.save_q('q1.npy')\n\t\t\tagent2.save_q('q2.npy')\n\t\t\ttotal_steps[play] = steps\n\t\t\tsteps = 0\n\t\t\tplay += 1\n\n\t\t# count\n\t\tif play == total_plays:\n\t\t\tbreak\n\n\tpyplot.plot(numpy.arange(0, total_plays), total_steps)\n\tpyplot.savefig('graph.png')\n\tcv2.destroyAllWindows()\n\tprint '!!!finish!!!'\n```\n\n## \u30dd\u30a4\u30f3\u30c8\n\n\u305d\u308c\u305e\u308c\u306e\u30a8\u30fc\u30b8\u30a7\u30f3\u30c8\u306f\u72ec\u7acb\u3057\u305f $Q$ \u5024\u3092\u6301\u3061\u307e\u3059\uff0e\n\u72b6\u614b $s$ \u306f\u30a8\u30fc\u30b8\u30a7\u30f3\u30c8\u306e\u5ea7\u6a19\u3068\u30bf\u30fc\u30b2\u30c3\u30c8\u306e\u5ea7\u6a19\u3067\u8868\u73fe\u3057\u307e\u3059\uff0e\u5ea7\u6a19\u306f\u5de6\u4e0a\u304b\u3089\u9806\u306b\u6c7a\u5b9a\u3057\u3066\u3044\u307e\u3059\uff0e\n\u8a8d\u8b58\u9818\u57df\u5185\u306b\u30a8\u30fc\u30b8\u30a7\u30f3\u30c8\u3042\u308b\u3044\u306f\u30bf\u30fc\u30b2\u30c3\u30c8\u304c\u3044\u306a\u3044\u5834\u5408\u3092 $25$ \u3068\u3044\u3046\u6570\u5024\u3067\u8868\u3057\u307e\u3059\uff0e\n\u884c\u52d5\u306f\uff0c\u5de6\u4e0b\u53f3\u4e0a\u306e\u9806\u306b $0, 1, 2, 3$ \u306e\u6570\u5024\u3067\u8868\u73fe\u3057\u307e\u3059\uff0e\n\uff08\u884c\u52d5\u6570\uff09$\\times$\uff08\u30bf\u30fc\u30b2\u30c3\u30c8\u306e\u5ea7\u6a19\uff09$\\times$\uff08\u30a8\u30fc\u30b8\u30a7\u30f3\u30c8\u306e\u5ea7\u6a19\uff09\u3068\u306a\u308b\u306e\u3067\uff0c$Q$ \u5024\u306e\u30b5\u30a4\u30ba\u306f $4 \\times 26 \\times 26$ \u3068\u306a\u308a\u307e\u3059\uff0e \n$Q$ \u5024\u306e\u66f4\u65b0\u306e\u969b\uff0c\u30a8\u30fc\u30b8\u30a7\u30f3\u30c8\u3084\u30bf\u30fc\u30b2\u30c3\u30c8\u304c\u3069\u306e\u3088\u3046\u306b\u884c\u52d5\u3059\u308b\u304b\u3092\u77e5\u308b\u3053\u3068\u306f\u3067\u304d\u306a\u3044\u306e\u3067\uff0c\n\u79fb\u52d5\u5148\u3067\u306e\u5468\u56f2\u306e\u72b6\u614b\u306f\u81ea\u5206\u306e\u884c\u52d5\u306b\u306e\u307f\u4f9d\u5b58\u3057\uff0c\u305d\u306e\u884c\u52d5\u306e\u5206\u5909\u5316\u3059\u308b\u3082\u306e\u3068\u3057\u3066\u3044\u307e\u3059\uff0e\n\n\n|   |   |   |   |   |\n|---|---|---|---|---|\n|0  |1  |2  |3  |4  |\n|5  |6  |7  |8  |9  |\n|10 |11 |12 |13 |14 |\n|15 |16 |17 |18 |19 |\n|20 |21 |22 |23 |24 |\n\n\u2191\u30a8\u30fc\u30b8\u30a7\u30f3\u30c8\u306e\u8a8d\u8b58\u3059\u308b\u7bc4\u56f2\u3068\u305d\u306e\u5ea7\u6a19\n\n\n# \u7d50\u679c\n\n## \u30b0\u30e9\u30d5\n\n\u30bf\u30fc\u30b2\u30c3\u30c8\u3092\u6355\u7372\u3059\u308b\u306e\u306b\u304b\u304b\u3063\u305f\u30b9\u30c6\u30c3\u30d7\u6570\u3092\u7e26\u8ef8\u306b\uff0c\u8a66\u884c\u56de\u6570\u3092\u6a2a\u8ef8\u306b\u3057\u305f\u30b0\u30e9\u30d5\u3092\u4ee5\u4e0b\u306b\u793a\u3057\u307e\u3059\uff0e\n\u72ec\u7acb\u3057\u305f $300$ \u56de\u306e\u8a66\u884c\u3092 $30$ \u56de\u884c\u3044\uff0c\u5404\u8a66\u884c\u306b\u304a\u3051\u308b\u30b9\u30c6\u30c3\u30d7\u6570\u306e\u5e73\u5747\u3092\u7e26\u8ef8\u306e\u5024\u3068\u3057\u3066\u3044\u307e\u3059\uff0e\n\u5b66\u7fd2\u304c\u9032\u3080\u306b\u3064\u308c\u3066\uff0c\u30bf\u30fc\u30b2\u30c3\u30c8\u3092\u6355\u7372\u3059\u308b\u306e\u306b\u304b\u304b\u308b\u30b9\u30c6\u30c3\u30d7\u6570\u304c\u6e1b\u5c11\u3057\u3066\u3044\u308b\u306e\u304c\u78ba\u8a8d\u3067\u304d\u307e\u3059\uff0e\n\n<img width = 600 src = \"https://qiita-image-store.s3.amazonaws.com/0/82527/8c08ecc3-8bf5-df56-afe6-d36815b9053b.png\">\n\n## \u884c\u52d5\n\n\u5b66\u7fd2\u3055\u308c\u305f\u884c\u52d5\u306e\u4e00\u4f8b\u3092\u753b\u50cf\u306b\u3057\u307e\u3057\u305f\uff0e\u767d\u8272\u304c\u30a8\u30fc\u30b8\u30a7\u30f3\u30c8\uff0c\u7070\u8272\u304c\u30bf\u30fc\u30b2\u30c3\u30c8\u3067\u3059\uff0e\n\u30bf\u30fc\u30b2\u30c3\u30c8\u3092\u8ffd\u3044\u8a70\u3081\u308b\u3088\u3046\u306a\u884c\u52d5\u3092\u5b66\u7fd2\u3067\u304d\u3066\u3044\u307e\u3059\uff0e\n\u5b9f\u969b\u306f\u5b66\u7fd2\u304c\u3046\u307e\u304f\u3044\u3063\u3066\u3044\u306a\u3044\u753b\u50cf\u3082\u3042\u308a\u307e\u3059\u304c\uff0c\u8003\u5bdf\u3067\u304d\u3066\u3044\u306a\u3044\u306e\u3067\u5272\u611b\u3057\u307e\u3059\uff0e\n\n<img width = 600 src = \"https://qiita-image-store.s3.amazonaws.com/0/82527/3859dbb6-2150-78fe-d431-0b7c71fe3eb8.png\">\n\n\n# \u304a\u308f\u308a\u306b\n\npython\u3067\u30de\u30eb\u30c1\u30a8\u30fc\u30b8\u30a7\u30f3\u30c8\u8ffd\u8de1\u554f\u984c\u3092\u89e3\u3044\u3066\u307f\u307e\u3057\u305f\uff0e\n\u5b9f\u88c5\u304c\u3046\u307e\u304f\u3044\u3063\u3066\u3044\u306a\u3044\u70b9\u3082\u3042\u308b\u304b\u3082\u3057\u308c\u306a\u3044\u306e\u3067\uff0c\u6307\u6458\u3042\u308c\u3070\u304a\u9858\u3044\u3057\u307e\u3059\uff0e\n\u4eca\u56de\u30a8\u30fc\u30b8\u30a7\u30f3\u30c8\u3068\u30bf\u30fc\u30b2\u30c3\u30c8\u304c\u898b\u3048\u3066\u3044\u308b\u72b6\u614b\u3067\u306e\u5b66\u7fd2\u7d50\u679c\u3057\u304b\u78ba\u8a8d\u3057\u3066\u3044\u307e\u305b\u3093\u304c\uff0c\n\u3069\u3061\u3089\u304b\u4e00\u65b9\u3057\u304b\u898b\u3048\u306a\u3044\u72b6\u614b\u3067\u306e\u5b66\u7fd2\u7d50\u679c\u3082\u78ba\u8a8d\u3057\u3066\u307f\u3088\u3046\u3068\u601d\u3044\u307e\u3059\uff0e\n\u767a\u898b\u304c\u3042\u3063\u305f\u3089\u968f\u6642\u8ffd\u8a18\u3057\u3066\u3044\u304d\u307e\u3059\uff0e\n", "tags": ["Python", "\u5f37\u5316\u5b66\u7fd2", "\u6a5f\u68b0\u5b66\u7fd2"]}