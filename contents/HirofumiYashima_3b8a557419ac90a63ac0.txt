{"context": " More than 1 year has passed since last update.\n\nVAR\u30e2\u30c7\u30eb\u306e\u300c\u30de\u30eb\u30b3\u30d5\u8ee2\u63db\u30e2\u30c7\u30eb\u300d\u7248\n\n\n\u30de\u30eb\u30b3\u30d5\u8ee2\u63db\u81ea\u5df1\u56de\u5e30\u30e2\u30c7\u30eb \u3092\u3001\u591a\u5909\u91cf\u30d9\u30af\u30c8\u30eb\u56de\u5e30\u30e2\u30c7\u30eb\u3000\uff08 VAR \u30e2\u30c7\u30eb\uff09\u306b\u62e1\u5f35\u3057\u305f\u3082\u306e\n\nR \u306b\u304a\u3051\u308b\u5b9f\u88c5\u30d1\u30c3\u30b1\u30fc\u30b8\n\n{MSBVAR} \u30d1\u30c3\u30b1\u30fc\u30b8\uff1a Markov-Switching, Bayesian, Vector Autoregression Models\n\n\n\u95a2\u6570\u306f\u3001 msbvar( ) : Bayesian VAR (MSBVAR)\n\n CRAN\u767b\u9332\u30d1\u30c3\u30b1\u30fc\u30b8\u30fb\u30de\u30cb\u30e5\u30a2\u30eb \n \u9280\u5ea7\u3067\u50cd\u304f\u30c7\u30fc\u30bf\u30b5\u30a4\u30a8\u30f3\u30c6\u30a3\u30b9\u30c8\u306e\u30d6\u30ed\u30b0 \uff08 2013-08-22 \uff09\u300cR\u3067\u8a08\u91cf\u6642\u7cfb\u5217\u5206\u6790\uff1a\u72b6\u614b\u5909\u5316\u3092\u4f34\u3046\u30e2\u30c7\u30eb\uff08\u95be\u5024\u30e2\u30c7\u30eb\u3001\u5e73\u6ed1\u63a8\u79fb\u30e2\u30c7\u30eb\u3001\u30de\u30eb\u30b3\u30d5\u8ee2\u63db\u30e2\u30c7\u30eb\uff09\u300d\n\n\n\u30b3\u30fc\u30c9\u5b9f\u884c\u4f8b\n\nexample( )\u30b3\u30de\u30f3\u30c9\u5b9f\u884c\u7d50\u679c\n\n\nR\ninstall.packages(\"MSBVAR\")\nrequire(MSBVAR)\n\nexample(msbvar)\n\n\nmsbvar> ## Not run: \nmsbvar> ##D # Simple replication of Hamilton (1989) as in\nmsbvar> ##D # Kim and Nelson (1999: 79, 220)\nmsbvar> ##D \nmsbvar> ##D data(HamiltonGDP)\nmsbvar> ##D set.seed(214)\nmsbvar> ##D \nmsbvar> ##D m2 <- msbvar(HamiltonGDP, p=1, h=2,\nmsbvar> ##D              lambda0=0.8, lambda1=0.15, lambda3=1, lambda4=0.25,\nmsbvar> ##D              lambda5=1, mu5=0, mu6=0, qm=12,\nmsbvar> ##D              alpha.prior=c(100, 30)*diag(2) +\nmsbvar> ##D              matrix(12, 2, 2), prior=0, max.iter=30,\nmsbvar> ##D              initialize.opt=NULL)\nmsbvar> ##D \nmsbvar> ##D # Now plot the filtered probabilities of a recession\nmsbvar> ##D # Compare to Kim and Nelson (1999: 79, 220)\nmsbvar> ##D \nmsbvar> ##D fp.rec <- ts(m2$fp[,1], start=tsp(HamiltonGDP)[1],\nmsbvar> ##D              freq=tsp(HamiltonGDP)[3])\nmsbvar> ##D plot(fp.rec)\nmsbvar> ##D \nmsbvar> ## End(Not run)\nmsbvar>  \nmsbvar> \nmsbvar> \n\n\nhelp(msbvar) \u3067\u8fd4\u3055\u308c\u308b Example \u3092\u884c\u3063\u305f\u7d50\u679c\n\nR\ndata(HamiltonGDP)\n\nprint(class(HamiltonGDP))\n\n\n[1] \"ts\"\n\n\nR\nprint(HamiltonGDP)\n\n\n            Qtr1        Qtr2        Qtr3        Qtr4\n1952                          0.60606548  2.18931351\n1953  1.76381955  0.47300980 -0.43745780 -0.99432651\n1954 -0.62424587 -0.14461465  1.15704818  1.22040008\n1955  2.56930842  0.91971604  1.10835652  0.87904451\n1956 -0.38537982  0.64147480  0.20551296  1.34481882\n1957  0.53508448 -0.08716363  0.88985407 -1.12448975\n1958 -2.23176830  0.79566695  2.00264557  2.14958029\n1959  1.26791279  1.69689557 -0.34640322  0.57324377\n1960  1.78630858 -0.26338835  0.10138390 -0.64044012\n1961  0.82773350  1.43598267  1.44513806  2.00897139\n1962  1.30614724  1.03558804  0.79189535 -0.11208306\n1963  1.42425233  1.30882787  1.71738447  0.75243123\n1964  2.47954250  0.81016624  1.17339691  0.27958242\n1965  1.93131814  1.34766614  1.73289042  2.31851987\n1966  2.06208914  0.17697875  0.94501690  0.54684001\n1967  0.63046253  0.44309520  1.13627003  0.57622504\n1968  1.35354710  1.61473340  0.70898801  0.17380167\n1969  1.50892356  0.11164439  0.58063724 -0.32640845\n1970 -0.25422879 -0.28984180  1.23383267 -0.75238990\n1971  2.29143219  0.14615828  0.61288934  0.50508558\n1972  1.99521130  1.71050041  1.16162830  1.57748342\n1973  2.42047806  0.43859196 -0.10104408  0.75686412\n1974 -0.90709014  0.25127010 -0.87602568 -0.39286093\n1975 -2.26954458  1.14747816  1.84779264  1.30229580\n1976  1.93111793  0.37169790  0.34962108  1.03865847\n1977  1.45584549  1.67638730  1.39168663 -0.20163419\n1978  0.68725226  3.15694410  0.76855502  1.17097354\n1979  0.03174306  0.09253018  0.61118637  0.18630298\n1980  0.42378359 -2.59686035  0.02410636  1.98892793\n1981  1.35612979 -0.41791902  0.52147890 -1.60157583\n1982 -1.24353382  0.39855509 -0.44383025  0.13841353\n1983  0.63369124  2.68595025  1.47878170  1.70179926\n1984  1.91078938  1.32387918  0.53908252  0.66503349\n\n\nR\nplot(HamiltonGDP)\n\n\n\n\nR\nset.seed(214)\n\nm2 <- msbvar(HamiltonGDP, p=1, h=2,\n             lambda0=0.8, lambda1=0.15, lambda3=1, lambda4=0.25,\n             lambda5=1, mu5=0, mu6=0, qm=12,\n             alpha.prior=c(100, 30)*diag(2) +\n             matrix(12, 2, 2), prior=0, max.iter=30,\n             initialize.opt=NULL)\n\n\n> m2 <- msbvar(HamiltonGDP, p=1, h=2,\n+              lambda0=0.8, lambda1=0.15, lambda3=1, lambda4=0.25,\n+              lambda5=1, mu5=0, mu6=0, qm=12,\n+              alpha.prior=c(100, 30)*diag(2) +\n+              matrix(12, 2, 2), prior=0, max.iter=30,\n+              initialize.opt=NULL)\nInitial Log Likelihood Value: -234.7732 \nStarting blockwise optimization over 30 block optimizations...\nCompleted iteration 1 of 30. Log Likelihood Value: -187.6087\nCompleted iteration 2 of 30. Log Likelihood Value: -179.8358\nCompleted iteration 3 of 30. Log Likelihood Value: -178.2616\nCompleted iteration 4 of 30. Log Likelihood Value: -177.6184\nCompleted iteration 5 of 30. Log Likelihood Value: -177.3516\nCompleted iteration 6 of 30. Log Likelihood Value: -177.0224\nCompleted iteration 7 of 30. Log Likelihood Value: -176.7122\nCompleted iteration 8 of 30. Log Likelihood Value: -176.6054\nCompleted iteration 9 of 30. Log Likelihood Value: -176.5618\nCompleted iteration 10 of 30. Log Likelihood Value: -176.5384\nCompleted iteration 11 of 30. Log Likelihood Value: -176.5246\nCompleted iteration 12 of 30. Log Likelihood Value: -176.5156\nCompleted iteration 13 of 30. Log Likelihood Value: -176.5096\nCompleted iteration 14 of 30. Log Likelihood Value: -176.5055\nCompleted iteration 15 of 30. Log Likelihood Value: -176.5026\nCompleted iteration 16 of 30. Log Likelihood Value: -176.5005\nCompleted iteration 17 of 30. Log Likelihood Value: -176.4989\nCompleted iteration 18 of 30. Log Likelihood Value: -176.4977\nCompleted iteration 19 of 30. Log Likelihood Value: -176.4968\nCompleted iteration 20 of 30. Log Likelihood Value: -176.4961\nCompleted iteration 21 of 30. Log Likelihood Value: -176.4956\nCompleted iteration 22 of 30. Log Likelihood Value: -176.4951\nCompleted iteration 23 of 30. Log Likelihood Value: -176.4948\nCompleted iteration 24 of 30. Log Likelihood Value: -176.4945\nCompleted iteration 25 of 30. Log Likelihood Value: -176.4943\nCompleted iteration 26 of 30. Log Likelihood Value: -176.4941\nCompleted iteration 27 of 30. Log Likelihood Value: -176.494\nCompleted iteration 28 of 30. Log Likelihood Value: -176.4939\nCompleted iteration 29 of 30. Log Likelihood Value: -176.4938\nCompleted iteration 30 of 30. Log Likelihood Value: -176.4937\n\n\nR\n# Now plot the filtered probabilities of a recession\n# Compare to Kim and Nelson (1999: 79, 220)\n\nfp.rec <- ts(m2$fp[,1], start=tsp(HamiltonGDP)[1],\n             freq=tsp(HamiltonGDP)[3])\nplot(fp.rec)\n\n\n\n\nR\nplot(HamiltonGDP, col=\"blue\")\npar(new=T)\nplot(fp.rec, col=\"red\")\n\n\n\n\n\u95a2\u6570\u306e\u4ed5\u69d8\n\nR\nhelp(msbvar)\n\n\nmsbvar {MSBVAR} R Documentation\nMarkov-switching Bayesian reduced form vector autoregression model setup and posterior mode estimation\n\nDescription\n\nSets up and estimates the posterior mode of a reduced form Markov-switching Bayesian vector autoregression model with a Sims-Zha prior. This is the setup and input function for the Gibbs sampler for this model.\n\nUsage\n\nmsbvar(Y, z=NULL, p, h, lambda0, lambda1, lambda3,\n       lambda4, lambda5, mu5, mu6, qm,\n       alpha.prior=100*diag(h) + matrix(2, h, h),\n       prior=0, max.iter=40, initialize.opt=NULL)\nArguments\n\nY   \nA T x m multiple time series object created with ts().\n\nz   \nNOT IMPLEMENTED AT PRESENT: THIS SHOULD BE A T x k matrix of exogenous variables. Can be z = NULL if there are none (the default).\n\np   \nLag length, aninteger\n\nh   \nNumber of regimes / states, an integer\n\nlambda0 \nValue in [0,1], Overall tightness of the prior (discounting of prior scale).\n\nlambda1 \nValue in [0,1], Standard deviation or tightness of the prior around the AR(1) parameters.\n\nlambda3 \nLag decay (>0, with 1=harmonic)\n\nlambda4 \nStandard deviation or tightness around the intercept >0\n\nlambda5 \nStandard deviation or tightness around the exogneous variable coefficients >0\n\nmu5 \nSum of coefficients prior weight \u22650. Larger values imply difference stationarity.\n\nmu6 \nDummy initial observations or drift prior \u22650. Larger values allow for common trends.\n\nqm  \nFrequency of the data for lag decay equivalence. Default is 4, and a value of 12 will match the lag decay of monthly to quarterly data. Other values have the same effect as \"4\"\n\nalpha.prior \nPrior for the Dirichlet process for the MS process. Default is 100 * diag(h) + matrix(2, h, h), but the model will be sensitive to this.\n\nprior   \nOne of three values: 0= Normal-Wishart prior, 1 = Normal-flat prior, 2 = flat-flat prior (i.e., akin to MLE). The conjugate prior is the first one, which is the default.\n\nmax.iter    \nMaximum number of iterations for the block EM algorithm used to fit an initial guess of the model posterior. Default value is 40 iterations. Larger problems will need more iterations.\n\ninitialize.opt  \nInitial values for the block optimization algorithm. If default=NULL initialize.msbvar is called to provide values. User can specify values as long as they conform to the structure produced by initialize.msbvar.\n\nDetails\n\nThis function estimates the posterior mode of a reduced form Bayesian Markov-switching VAR model. The MSBVAR mode is estimated using block EM algorithm where the blocks are 1) the BVAR regression coefficients for each regime (separating optimands for intercepts, AR coefficients, and error covariances) and 2) the transition matrix. Starting values are randomly drawn, so a random number seed should be set prior to calling the function in order to make the results replicable.\n\nThe steps of the blockwise optimization follow the suggestions of Sims, Waggoner, and Zha (2008). The joint optimization problem is partitioned into the following separate blocks. For each block, a separate call to optim is made, holding all of the other blocks constant:\n\nMaximize over the intercepts\n\nMaximize over the AR(p) coefficients\n\nMaximize over the error covariances Sigma\n\nMaximize over the transition matrix Q\n\nThese four blocks are iterated a total of max.iter times. Internal to each block, the state-space filtering algorithm for the regime classifications is computing using compiled Fortran code for speed. Despite the use of compiled code, this algorithm can take several minutes to compute.\n\nThe user should try multiple starting values and number of iterations to ensure convergence. The algorithm will improve with each step of the optimization, although sometimes this can be very incremental improvement.\n\nThe results for posterior sampling via gibbs.msbvar will be sensitive to the choice of alpha.prior. This is the prior for the independent Dirichlet process for the MS process. Note that the prior is roughly proportionate to the number of time periods spent in each regime, since the estimated MS probabilities map to the duration of the regime via 1/(1-p) where p is the probability of staying in the regime.\n\nThis function should NOT be used for inference, since it only finds the posterior mode of the model. This function is intended to generate starting values for the Gibbs sampling of the model. See gibbs.msbvar for further details of the Gibbs sampling.\n\nValue\n\nA list describing the posterior mode of the MSBVAR model and the inputs necessary for the subsequent Gibbs sampler.\n\ninit.model  \nAn object of the class BVAR that describes the setup of the model. See szbvar for details.\n\nhreg    \nA list containing the regime-specific moment matrices, VAR coefficients, and error covariances\n\nQ   \nThe h x h Markov transition matrix.\n\nfp  \nThe T x h matrix of the filtered regime probabilities. First column is the first regime, etc.\n\nm   \nInteger, the number of endogenous variables in the system.\n\np   \nInteger, the lag length of the VAR.\n\nh   \nInteger, the number of regimes in the MS process.\n\nalpha.prior \nThe h x h matrix for the prior for the Dirichlet density for the MS process.\n\nNote\n\nUsers should consult the reference papers and the (coming) package vignette to see how this function is used to setup an MSBVAR model. An example is currently in gibbs.msbvar.\n\nAuthor(s)\n\nPatrick T. Brandt\n\nReferences\n\nBrandt, Patrick T. 2009. \"Empirical, Regime-Specific Models of International, Inter-group Conflict, and Politics\"\n\nFruhwirth-Schnatter, Sylvia. 2001. \"Markov Chain Monte Carlo Estimation of Classical and Dynamic Switching and Mixture Models\". Journal of the American Statistical Association. 96(153):194\u2013209.\n\nFruhwirth-Schnatter, Sylvia. 2006. Finite Mixture and Markov Switching Models. Springer Series in Statistics New York: Springer.\n\nKim, Chang-Jin and Charles R. Nelson. 1999. State-Space Models with Regime Switching: Classical and Gibbs-Sampling Approaches with Applications. Cambridge: MIT Press.\n\nSims, Christopher A. and Daniel F. Waggoner and Tao Zha. 2008. \"Methods for inference in large multiple-equation Markov-switching models\" Journal of Econometrics 146(2):255\u2013274.\n\nSims, Christopher A. and Tao A. Zha. 1998. \"Bayesian Methods for Dynamic Multivariate Models\" International Economic Review 39(4):949-968.\n\nSims, Christopher A. and Tao A. Zha. 2006. \"Were There Regime Switches in U.S. Monetary Policy?\" American Economic Review. 96(1):54\u201381.\n\nSee Also\n\ngibbs.msbvar for the MCMC sampler after using this function, szbvar for a non-switching, Bayesian VAR and more details.\n\nExamples\n\n## Not run: \n# Simple replication of Hamilton (1989) as in\n# Kim and Nelson (1999: 79, 220)\n\ndata(HamiltonGDP)\nset.seed(214)\n\nm2 <- msbvar(HamiltonGDP, p=1, h=2,\n             lambda0=0.8, lambda1=0.15, lambda3=1, lambda4=0.25,\n             lambda5=1, mu5=0, mu6=0, qm=12,\n             alpha.prior=c(100, 30)*diag(2) +\n             matrix(12, 2, 2), prior=0, max.iter=30,\n             initialize.opt=NULL)\n\n# Now plot the filtered probabilities of a recession\n# Compare to Kim and Nelson (1999: 79, 220)\n\nfp.rec <- ts(m2$fp[,1], start=tsp(HamiltonGDP)[1],\n             freq=tsp(HamiltonGDP)[3])\nplot(fp.rec)\n\n\n## End(Not run)\n\n## **VAR\u30e2\u30c7\u30eb\u306e\u300c\u30de\u30eb\u30b3\u30d5\u8ee2\u63db\u30e2\u30c7\u30eb\u300d\u7248**\n\n##### **\u30de\u30eb\u30b3\u30d5\u8ee2\u63db\u81ea\u5df1\u56de\u5e30\u30e2\u30c7\u30eb** \u3092\u3001**\u591a\u5909\u91cf\u30d9\u30af\u30c8\u30eb\u56de\u5e30\u30e2\u30c7\u30eb**\u3000\uff08 _**VAR**_ \u30e2\u30c7\u30eb\uff09\u306b\u62e1\u5f35\u3057\u305f\u3082\u306e\n\n##  _R_ \u306b\u304a\u3051\u308b\u5b9f\u88c5\u30d1\u30c3\u30b1\u30fc\u30b8\n\n##### _**{MSBVAR}**_ \u30d1\u30c3\u30b1\u30fc\u30b8\uff1a _**Markov-Switching, Bayesian, Vector Autoregression Models**_\n\n##### \u95a2\u6570\u306f\u3001 _**msbvar( )**_ : _**Bayesian VAR (MSBVAR)**_\n\n\n[ CRAN\u767b\u9332\u30d1\u30c3\u30b1\u30fc\u30b8\u30fb\u30de\u30cb\u30e5\u30a2\u30eb ](http://cran.r-project.org/web/packages/MSBVAR/MSBVAR.pdf)\n\n[ \u9280\u5ea7\u3067\u50cd\u304f\u30c7\u30fc\u30bf\u30b5\u30a4\u30a8\u30f3\u30c6\u30a3\u30b9\u30c8\u306e\u30d6\u30ed\u30b0 \uff08 2013-08-22 \uff09\u300cR\u3067\u8a08\u91cf\u6642\u7cfb\u5217\u5206\u6790\uff1a\u72b6\u614b\u5909\u5316\u3092\u4f34\u3046\u30e2\u30c7\u30eb\uff08\u95be\u5024\u30e2\u30c7\u30eb\u3001\u5e73\u6ed1\u63a8\u79fb\u30e2\u30c7\u30eb\u3001\u30de\u30eb\u30b3\u30d5\u8ee2\u63db\u30e2\u30c7\u30eb\uff09\u300d](http://tjo.hatenablog.com/entry/2013/08/22/204451)\n![MSBVAR.png](https://qiita-image-store.s3.amazonaws.com/0/43487/db907e34-c2c4-9fa5-e0ef-e4994bcf1d5f.png)\n\n## \u30b3\u30fc\u30c9\u5b9f\u884c\u4f8b\n\n#### **example( )\u30b3\u30de\u30f3\u30c9\u5b9f\u884c\u7d50\u679c**\n\n```{r:R}\ninstall.packages(\"MSBVAR\")\nrequire(MSBVAR)\n\nexample(msbvar)\n```\n\n```\nmsbvar> ## Not run: \nmsbvar> ##D # Simple replication of Hamilton (1989) as in\nmsbvar> ##D # Kim and Nelson (1999: 79, 220)\nmsbvar> ##D \nmsbvar> ##D data(HamiltonGDP)\nmsbvar> ##D set.seed(214)\nmsbvar> ##D \nmsbvar> ##D m2 <- msbvar(HamiltonGDP, p=1, h=2,\nmsbvar> ##D              lambda0=0.8, lambda1=0.15, lambda3=1, lambda4=0.25,\nmsbvar> ##D              lambda5=1, mu5=0, mu6=0, qm=12,\nmsbvar> ##D              alpha.prior=c(100, 30)*diag(2) +\nmsbvar> ##D              matrix(12, 2, 2), prior=0, max.iter=30,\nmsbvar> ##D              initialize.opt=NULL)\nmsbvar> ##D \nmsbvar> ##D # Now plot the filtered probabilities of a recession\nmsbvar> ##D # Compare to Kim and Nelson (1999: 79, 220)\nmsbvar> ##D \nmsbvar> ##D fp.rec <- ts(m2$fp[,1], start=tsp(HamiltonGDP)[1],\nmsbvar> ##D              freq=tsp(HamiltonGDP)[3])\nmsbvar> ##D plot(fp.rec)\nmsbvar> ##D \nmsbvar> ## End(Not run)\nmsbvar>  \nmsbvar> \nmsbvar> \n```\n\n#### _**help(msbvar)**_ \u3067\u8fd4\u3055\u308c\u308b _**Example**_ \u3092\u884c\u3063\u305f\u7d50\u679c\n\n```{r:R}\ndata(HamiltonGDP)\n\nprint(class(HamiltonGDP))\n```\n\n```\n[1] \"ts\"\n```\n\n```{r:R}\nprint(HamiltonGDP)\n```\n\n```\n            Qtr1        Qtr2        Qtr3        Qtr4\n1952                          0.60606548  2.18931351\n1953  1.76381955  0.47300980 -0.43745780 -0.99432651\n1954 -0.62424587 -0.14461465  1.15704818  1.22040008\n1955  2.56930842  0.91971604  1.10835652  0.87904451\n1956 -0.38537982  0.64147480  0.20551296  1.34481882\n1957  0.53508448 -0.08716363  0.88985407 -1.12448975\n1958 -2.23176830  0.79566695  2.00264557  2.14958029\n1959  1.26791279  1.69689557 -0.34640322  0.57324377\n1960  1.78630858 -0.26338835  0.10138390 -0.64044012\n1961  0.82773350  1.43598267  1.44513806  2.00897139\n1962  1.30614724  1.03558804  0.79189535 -0.11208306\n1963  1.42425233  1.30882787  1.71738447  0.75243123\n1964  2.47954250  0.81016624  1.17339691  0.27958242\n1965  1.93131814  1.34766614  1.73289042  2.31851987\n1966  2.06208914  0.17697875  0.94501690  0.54684001\n1967  0.63046253  0.44309520  1.13627003  0.57622504\n1968  1.35354710  1.61473340  0.70898801  0.17380167\n1969  1.50892356  0.11164439  0.58063724 -0.32640845\n1970 -0.25422879 -0.28984180  1.23383267 -0.75238990\n1971  2.29143219  0.14615828  0.61288934  0.50508558\n1972  1.99521130  1.71050041  1.16162830  1.57748342\n1973  2.42047806  0.43859196 -0.10104408  0.75686412\n1974 -0.90709014  0.25127010 -0.87602568 -0.39286093\n1975 -2.26954458  1.14747816  1.84779264  1.30229580\n1976  1.93111793  0.37169790  0.34962108  1.03865847\n1977  1.45584549  1.67638730  1.39168663 -0.20163419\n1978  0.68725226  3.15694410  0.76855502  1.17097354\n1979  0.03174306  0.09253018  0.61118637  0.18630298\n1980  0.42378359 -2.59686035  0.02410636  1.98892793\n1981  1.35612979 -0.41791902  0.52147890 -1.60157583\n1982 -1.24353382  0.39855509 -0.44383025  0.13841353\n1983  0.63369124  2.68595025  1.47878170  1.70179926\n1984  1.91078938  1.32387918  0.53908252  0.66503349\n```\n\n```{r:R}\nplot(HamiltonGDP)\n```\n![plot(HamiltonGDP).png](https://qiita-image-store.s3.amazonaws.com/0/43487/0eccaf83-c744-c3be-6354-7250f8886406.png)\n\n\n```{r:R}\nset.seed(214)\n\nm2 <- msbvar(HamiltonGDP, p=1, h=2,\n             lambda0=0.8, lambda1=0.15, lambda3=1, lambda4=0.25,\n             lambda5=1, mu5=0, mu6=0, qm=12,\n             alpha.prior=c(100, 30)*diag(2) +\n             matrix(12, 2, 2), prior=0, max.iter=30,\n             initialize.opt=NULL)\n```\n\n```\n> m2 <- msbvar(HamiltonGDP, p=1, h=2,\n+              lambda0=0.8, lambda1=0.15, lambda3=1, lambda4=0.25,\n+              lambda5=1, mu5=0, mu6=0, qm=12,\n+              alpha.prior=c(100, 30)*diag(2) +\n+              matrix(12, 2, 2), prior=0, max.iter=30,\n+              initialize.opt=NULL)\nInitial Log Likelihood Value: -234.7732 \nStarting blockwise optimization over 30 block optimizations...\nCompleted iteration 1 of 30. Log Likelihood Value: -187.6087\nCompleted iteration 2 of 30. Log Likelihood Value: -179.8358\nCompleted iteration 3 of 30. Log Likelihood Value: -178.2616\nCompleted iteration 4 of 30. Log Likelihood Value: -177.6184\nCompleted iteration 5 of 30. Log Likelihood Value: -177.3516\nCompleted iteration 6 of 30. Log Likelihood Value: -177.0224\nCompleted iteration 7 of 30. Log Likelihood Value: -176.7122\nCompleted iteration 8 of 30. Log Likelihood Value: -176.6054\nCompleted iteration 9 of 30. Log Likelihood Value: -176.5618\nCompleted iteration 10 of 30. Log Likelihood Value: -176.5384\nCompleted iteration 11 of 30. Log Likelihood Value: -176.5246\nCompleted iteration 12 of 30. Log Likelihood Value: -176.5156\nCompleted iteration 13 of 30. Log Likelihood Value: -176.5096\nCompleted iteration 14 of 30. Log Likelihood Value: -176.5055\nCompleted iteration 15 of 30. Log Likelihood Value: -176.5026\nCompleted iteration 16 of 30. Log Likelihood Value: -176.5005\nCompleted iteration 17 of 30. Log Likelihood Value: -176.4989\nCompleted iteration 18 of 30. Log Likelihood Value: -176.4977\nCompleted iteration 19 of 30. Log Likelihood Value: -176.4968\nCompleted iteration 20 of 30. Log Likelihood Value: -176.4961\nCompleted iteration 21 of 30. Log Likelihood Value: -176.4956\nCompleted iteration 22 of 30. Log Likelihood Value: -176.4951\nCompleted iteration 23 of 30. Log Likelihood Value: -176.4948\nCompleted iteration 24 of 30. Log Likelihood Value: -176.4945\nCompleted iteration 25 of 30. Log Likelihood Value: -176.4943\nCompleted iteration 26 of 30. Log Likelihood Value: -176.4941\nCompleted iteration 27 of 30. Log Likelihood Value: -176.494\nCompleted iteration 28 of 30. Log Likelihood Value: -176.4939\nCompleted iteration 29 of 30. Log Likelihood Value: -176.4938\nCompleted iteration 30 of 30. Log Likelihood Value: -176.4937\n```\n\n```{r:R}\n# Now plot the filtered probabilities of a recession\n# Compare to Kim and Nelson (1999: 79, 220)\n\nfp.rec <- ts(m2$fp[,1], start=tsp(HamiltonGDP)[1],\n             freq=tsp(HamiltonGDP)[3])\nplot(fp.rec)\n```\n![msbvar.example.code.png](https://qiita-image-store.s3.amazonaws.com/0/43487/a7a24e9d-cdb9-b591-9f36-f4ecad00f764.png)\n\n\n```{r:R}\nplot(HamiltonGDP, col=\"blue\")\npar(new=T)\nplot(fp.rec, col=\"red\")\n```\n![dgraph.png](https://qiita-image-store.s3.amazonaws.com/0/43487/54270062-939d-07d5-ddf7-40bd31a8887a.png)\n\n\n## \u95a2\u6570\u306e\u4ed5\u69d8\n```{r:R}\nhelp(msbvar)\n```\n\n```\nmsbvar {MSBVAR}\tR Documentation\nMarkov-switching Bayesian reduced form vector autoregression model setup and posterior mode estimation\n\nDescription\n\nSets up and estimates the posterior mode of a reduced form Markov-switching Bayesian vector autoregression model with a Sims-Zha prior. This is the setup and input function for the Gibbs sampler for this model.\n\nUsage\n\nmsbvar(Y, z=NULL, p, h, lambda0, lambda1, lambda3,\n       lambda4, lambda5, mu5, mu6, qm,\n       alpha.prior=100*diag(h) + matrix(2, h, h),\n       prior=0, max.iter=40, initialize.opt=NULL)\nArguments\n\nY\t\nA T x m multiple time series object created with ts().\n\nz\t\nNOT IMPLEMENTED AT PRESENT: THIS SHOULD BE A T x k matrix of exogenous variables. Can be z = NULL if there are none (the default).\n\np\t\nLag length, aninteger\n\nh\t\nNumber of regimes / states, an integer\n\nlambda0\t\nValue in [0,1], Overall tightness of the prior (discounting of prior scale).\n\nlambda1\t\nValue in [0,1], Standard deviation or tightness of the prior around the AR(1) parameters.\n\nlambda3\t\nLag decay (>0, with 1=harmonic)\n\nlambda4\t\nStandard deviation or tightness around the intercept >0\n\nlambda5\t\nStandard deviation or tightness around the exogneous variable coefficients >0\n\nmu5\t\nSum of coefficients prior weight \u22650. Larger values imply difference stationarity.\n\nmu6\t\nDummy initial observations or drift prior \u22650. Larger values allow for common trends.\n\nqm\t\nFrequency of the data for lag decay equivalence. Default is 4, and a value of 12 will match the lag decay of monthly to quarterly data. Other values have the same effect as \"4\"\n\nalpha.prior\t\nPrior for the Dirichlet process for the MS process. Default is 100 * diag(h) + matrix(2, h, h), but the model will be sensitive to this.\n\nprior\t\nOne of three values: 0= Normal-Wishart prior, 1 = Normal-flat prior, 2 = flat-flat prior (i.e., akin to MLE). The conjugate prior is the first one, which is the default.\n\nmax.iter\t\nMaximum number of iterations for the block EM algorithm used to fit an initial guess of the model posterior. Default value is 40 iterations. Larger problems will need more iterations.\n\ninitialize.opt\t\nInitial values for the block optimization algorithm. If default=NULL initialize.msbvar is called to provide values. User can specify values as long as they conform to the structure produced by initialize.msbvar.\n\nDetails\n\nThis function estimates the posterior mode of a reduced form Bayesian Markov-switching VAR model. The MSBVAR mode is estimated using block EM algorithm where the blocks are 1) the BVAR regression coefficients for each regime (separating optimands for intercepts, AR coefficients, and error covariances) and 2) the transition matrix. Starting values are randomly drawn, so a random number seed should be set prior to calling the function in order to make the results replicable.\n\nThe steps of the blockwise optimization follow the suggestions of Sims, Waggoner, and Zha (2008). The joint optimization problem is partitioned into the following separate blocks. For each block, a separate call to optim is made, holding all of the other blocks constant:\n\nMaximize over the intercepts\n\nMaximize over the AR(p) coefficients\n\nMaximize over the error covariances Sigma\n\nMaximize over the transition matrix Q\n\nThese four blocks are iterated a total of max.iter times. Internal to each block, the state-space filtering algorithm for the regime classifications is computing using compiled Fortran code for speed. Despite the use of compiled code, this algorithm can take several minutes to compute.\n\nThe user should try multiple starting values and number of iterations to ensure convergence. The algorithm will improve with each step of the optimization, although sometimes this can be very incremental improvement.\n\nThe results for posterior sampling via gibbs.msbvar will be sensitive to the choice of alpha.prior. This is the prior for the independent Dirichlet process for the MS process. Note that the prior is roughly proportionate to the number of time periods spent in each regime, since the estimated MS probabilities map to the duration of the regime via 1/(1-p) where p is the probability of staying in the regime.\n\nThis function should NOT be used for inference, since it only finds the posterior mode of the model. This function is intended to generate starting values for the Gibbs sampling of the model. See gibbs.msbvar for further details of the Gibbs sampling.\n\nValue\n\nA list describing the posterior mode of the MSBVAR model and the inputs necessary for the subsequent Gibbs sampler.\n\ninit.model\t\nAn object of the class BVAR that describes the setup of the model. See szbvar for details.\n\nhreg\t\nA list containing the regime-specific moment matrices, VAR coefficients, and error covariances\n\nQ\t\nThe h x h Markov transition matrix.\n\nfp\t\nThe T x h matrix of the filtered regime probabilities. First column is the first regime, etc.\n\nm\t\nInteger, the number of endogenous variables in the system.\n\np\t\nInteger, the lag length of the VAR.\n\nh\t\nInteger, the number of regimes in the MS process.\n\nalpha.prior\t\nThe h x h matrix for the prior for the Dirichlet density for the MS process.\n\nNote\n\nUsers should consult the reference papers and the (coming) package vignette to see how this function is used to setup an MSBVAR model. An example is currently in gibbs.msbvar.\n\nAuthor(s)\n\nPatrick T. Brandt\n\nReferences\n\nBrandt, Patrick T. 2009. \"Empirical, Regime-Specific Models of International, Inter-group Conflict, and Politics\"\n\nFruhwirth-Schnatter, Sylvia. 2001. \"Markov Chain Monte Carlo Estimation of Classical and Dynamic Switching and Mixture Models\". Journal of the American Statistical Association. 96(153):194\u2013209.\n\nFruhwirth-Schnatter, Sylvia. 2006. Finite Mixture and Markov Switching Models. Springer Series in Statistics New York: Springer.\n\nKim, Chang-Jin and Charles R. Nelson. 1999. State-Space Models with Regime Switching: Classical and Gibbs-Sampling Approaches with Applications. Cambridge: MIT Press.\n\nSims, Christopher A. and Daniel F. Waggoner and Tao Zha. 2008. \"Methods for inference in large multiple-equation Markov-switching models\" Journal of Econometrics 146(2):255\u2013274.\n\nSims, Christopher A. and Tao A. Zha. 1998. \"Bayesian Methods for Dynamic Multivariate Models\" International Economic Review 39(4):949-968.\n\nSims, Christopher A. and Tao A. Zha. 2006. \"Were There Regime Switches in U.S. Monetary Policy?\" American Economic Review. 96(1):54\u201381.\n\nSee Also\n\ngibbs.msbvar for the MCMC sampler after using this function, szbvar for a non-switching, Bayesian VAR and more details.\n\nExamples\n\n## Not run: \n# Simple replication of Hamilton (1989) as in\n# Kim and Nelson (1999: 79, 220)\n\ndata(HamiltonGDP)\nset.seed(214)\n\nm2 <- msbvar(HamiltonGDP, p=1, h=2,\n             lambda0=0.8, lambda1=0.15, lambda3=1, lambda4=0.25,\n             lambda5=1, mu5=0, mu6=0, qm=12,\n             alpha.prior=c(100, 30)*diag(2) +\n             matrix(12, 2, 2), prior=0, max.iter=30,\n             initialize.opt=NULL)\n\n# Now plot the filtered probabilities of a recession\n# Compare to Kim and Nelson (1999: 79, 220)\n\nfp.rec <- ts(m2$fp[,1], start=tsp(HamiltonGDP)[1],\n             freq=tsp(HamiltonGDP)[3])\nplot(fp.rec)\n\n\n## End(Not run)\n```\n\n", "tags": ["R", "\u6642\u7cfb\u5217\u89e3\u6790", "MSBVAR", "VAR\u30e2\u30c7\u30eb", "\u30de\u30eb\u30b3\u30d5\u72b6\u614b\u8ee2\u63db\u30e2\u30c7\u30eb", "\u7d71\u8a08\u5b66"]}