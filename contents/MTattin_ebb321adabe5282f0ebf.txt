{"tags": ["swift3", "Xcode8", "avfoundation"], "context": "Apple\u306eAVFoundation\u306e\u30de\u30cb\u30e5\u30a2\u30eb\u307b\u307c\u305d\u306e\u307e\u307e\u3067\u3059\u304c\u3001Swift\uff13\u3067\u52d5\u4f5c\u78ba\u8a8d\u6e08\u307f\u3067\u3059\u3002\nAVFoundation\u30de\u30cb\u30e5\u30a2\u30eb\nhttps://developer.apple.com/jp/documentation/AVFoundationPG.pdf\n\u3053\u306e\u30a2\u30d7\u30ea\u306e\u3088\u3046\u306a\u3053\u3068\u304c\u53ef\u80fd\u3067\u3059\u3002\nhttps://itunes.apple.com/jp/app/id651397153\n\u540c\u3058\u3088\u3046\u306b\u52d5\u753b\u7de8\u96c6\u30a2\u30d7\u30ea\u3092\u4f5c\u308a\u305f\u3044\u65b9\u306f\u3054\u53c2\u8003\u307e\u3067\u306b\u3002\n\u97f3\u3082\u30aa\u30fc\u30c7\u30a3\u30aa\u7528\u306e\u30c8\u30e9\u30c3\u30af\u3092\u4f5c\u6210\u3059\u308c\u3070\u8ffd\u52a0\u53ef\u80fd\u3067\u3059\u3002\nimport UIKit\nimport AVFoundation\nimport Photos\n\n\n///\n/// \u30a2\u30eb\u30d0\u30e0\u4fdd\u5b58\u30b3\u30f3\u30c8\u30ed\u30fc\u30e9\u30fc\u30b5\u30f3\u30d7\u30eb\n///\nclass SaveAlbumSample: NSObject {\n\n\n    // MARK: ---------------------------------------- static\n    ///\n    /// \u51fa\u529b\u30d5\u30a1\u30a4\u30eb\u30d1\u30b9\uff08\u6587\u5b57\u5217\uff09\n    ///\n    static let ExportFileStr: String = NSHomeDirectory() + \"/Documents/sample.mov\"\n\n\n    // MARK: ---------------------------------------- func\n    ///\n    /// \u56fa\u5b9a\u51fa\u529b\u30b5\u30f3\u30d7\u30eb\n    ///\n    static func SaveStartSample2(a: AVURLAsset, b: AVURLAsset) {\n        do {\n            ///\n            /// \u30b3\u30f3\u30dd\u30b8\u30b7\u30e7\u30f3\u3092\u4f5c\u6210\u3059\u308b\n            ///\n            let mixCmp: AVMutableComposition = AVMutableComposition()\n            ///\n            /// \u30d3\u30c7\u30aa\u30c8\u30e9\u30c3\u30af\u8ffd\u52a0\uff21\n            ///\n            /// kCMPersistentTrackID_Invalid\u3067\u30c8\u30e9\u30c3\u30afID\u3092\u81ea\u52d5\u8a2d\u5b9a\n            ///\n            let cmpTrcA: AVMutableCompositionTrack = mixCmp.addMutableTrack(withMediaType: AVMediaTypeVideo, preferredTrackID: kCMPersistentTrackID_Invalid)\n            try cmpTrcA.insertTimeRange(CMTimeRangeMake(kCMTimeZero, a.duration), of: a.tracks(withMediaType: AVMediaTypeVideo)[0], at: kCMTimeZero)\n            ///\n            /// \u30d3\u30c7\u30aa\u30c8\u30e9\u30c3\u30af\u8ffd\u52a0\uff22\n            ///\n            /// kCMPersistentTrackID_Invalid\u3067\u30c8\u30e9\u30c3\u30afID\u3092\u81ea\u52d5\u8a2d\u5b9a\n            ///\n            let cmpTrcB: AVMutableCompositionTrack = mixCmp.addMutableTrack(withMediaType: AVMediaTypeVideo, preferredTrackID: kCMPersistentTrackID_Invalid)\n            try cmpTrcB.insertTimeRange(CMTimeRangeMake(kCMTimeZero, b.duration), of: b.tracks(withMediaType: AVMediaTypeVideo)[0], at: kCMTimeZero)\n            ///\n            /// \u30d3\u30c7\u30aa\u30b3\u30f3\u30dd\u30b8\u30b7\u30e7\u30f3\u547d\u4ee4\u4f5c\u6210\n            ///\n            /// You should add the length equal to the length of the longer asset in terms of duration.\n            ///\n            let mainIns: AVMutableVideoCompositionInstruction = AVMutableVideoCompositionInstruction.init()\n            mainIns.timeRange = CMTimeRangeMake(kCMTimeZero, CMTimeMaximum(a.duration, b.duration))\n            mainIns.backgroundColor = UIColor.darkGray.cgColor\n            ///\n            /// \u52a0\u5de5\u7528\u30ec\u30a4\u30e4\u30fc\u4f5c\u6210\uff21\n            ///\n            let lyrInsA: AVMutableVideoCompositionLayerInstruction = AVMutableVideoCompositionLayerInstruction.init(assetTrack: cmpTrcA)\n            let scaleA: CGAffineTransform = CGAffineTransform.init(scaleX: 1.5, y: 1.5)\n            let moveA: CGAffineTransform = CGAffineTransform.init(translationX: 100, y: 100)\n            lyrInsA.setOpacity(0.5, at: kCMTimeZero)\n            lyrInsA.setTransform(scaleA.concatenating(moveA), at: kCMTimeZero)\n            ///\n            /// \u52a0\u5de5\u7528\u30ec\u30a4\u30e4\u30fc\u4f5c\u6210\uff22\n            ///\n            let lyrInsB: AVMutableVideoCompositionLayerInstruction = AVMutableVideoCompositionLayerInstruction.init(assetTrack: cmpTrcB)\n            let scaleB: CGAffineTransform = CGAffineTransform.init(scaleX: 0.8, y: 0.8)\n            lyrInsB.setOpacity(0.5, at: kCMTimeZero)\n            lyrInsB.setTransform(scaleB, at: kCMTimeZero)\n            ///\n            /// \u30c6\u30ad\u30b9\u30c8\u30ec\u30a4\u30e4\u30fc\u4f5c\u6210\n            ///\n            let lyrText: CATextLayer = CATextLayer()\n            lyrText.string = \"TextLayer\"\n            lyrText.font = UIFont.systemFont(ofSize: 300) as CFTypeRef!\n            lyrText.foregroundColor = UIColor.yellow.cgColor\n            lyrText.opacity = 0.5\n            lyrText.shadowOpacity = 1\n            lyrText.alignmentMode = kCAAlignmentCenter\n            lyrText.frame = CGRect.init(x: 0, y: 0, width: UIScreen.main.bounds.size.width * 2, height: UIScreen.main.bounds.size.height * 2 * 0.5)\n            ///\n            /// \u89aa\u30ec\u30a4\u30e4\u30fc\u3068\u30d3\u30c7\u30aa\u30ec\u30a4\u30e4\u30fc\u4f5c\u6210\n            ///\n            let lyrParent: CALayer = CALayer()\n            lyrParent.backgroundColor = UIColor.clear.cgColor\n            lyrParent.frame = CGRect.Make(0, 0, UIScreen.main.bounds.size.width * 2, UIScreen.main.bounds.size.height * 2)\n            let lyrVideo: CALayer = CALayer()\n            lyrVideo.frame = CGRect.Make(0, 0, UIScreen.main.bounds.size.width * 2, UIScreen.main.bounds.size.height * 2)\n            lyrParent.addSublayer(lyrVideo)\n            lyrParent.addSublayer(lyrText)\n            ///\n            /// \u547d\u4ee4\u306b\u30bb\u30c3\u30c8\n            ///\n            mainIns.layerInstructions = [ lyrInsA, lyrInsB ]\n            ///\n            /// \u30d3\u30c7\u30aa\u30b3\u30f3\u30dd\u30b8\u30b7\u30e7\u30f3\u4f5c\u6210\n            ///\n            let mainCmp: AVMutableVideoComposition = AVMutableVideoComposition.init()\n            mainCmp.instructions = [ mainIns ]\n            mainCmp.frameDuration = CMTimeMake(1, 30)\n            mainCmp.renderSize = CGSize.init(width: UIScreen.main.bounds.size.width * 2, height: UIScreen.main.bounds.size.height * 2)\n            mainCmp.animationTool = AVVideoCompositionCoreAnimationTool.init(postProcessingAsVideoLayer: lyrVideo, in: lyrParent)\n            ///\n            /// \u51fa\u529b\u30d5\u30a1\u30a4\u30eb\u8a2d\u5b9a\n            ///\n            ///\n            /// \u30d5\u30a1\u30a4\u30eb\u304c\u5b58\u5728\u3057\u3066\u3044\u308b\u5834\u5408\u306f\u524a\u9664\n            ///\n            if FileManager.default.fileExists(atPath: SaveAlbumSample.ExportFileStr) == true {\n                try FileManager.default.removeItem(atPath: SaveAlbumSample.ExportFileStr)\n            }\n            ///\n            /// \u30a8\u30af\u30b9\u30dd\u30fc\u30c8\u30bb\u30c3\u30b7\u30e7\u30f3\u3092\u4f5c\u6210\u3057\u3066\u30ab\u30e1\u30e9\u30ed\u30fc\u30eb\u3078\u4fdd\u5b58\n            ///\n            /// ```\n            /// AVF_EXPORT NSString *const AVAssetExportPresetLowQuality     NS_AVAILABLE(10_11, 4_0)\n            /// AVF_EXPORT NSString *const AVAssetExportPresetMediumQuality  NS_AVAILABLE(10_11, 4_0)\n            /// AVF_EXPORT NSString *const AVAssetExportPresetHighestQuality NS_AVAILABLE(10_11, 4_0)\n            /// AVF_EXPORT NSString *const AVAssetExportPreset640x480        NS_AVAILABLE(10_7, 4_0)\n            /// AVF_EXPORT NSString *const AVAssetExportPreset960x540        NS_AVAILABLE(10_7, 4_0)\n            /// AVF_EXPORT NSString *const AVAssetExportPreset1280x720       NS_AVAILABLE(10_7, 4_0)\n            /// AVF_EXPORT NSString *const AVAssetExportPreset1920x1080      NS_AVAILABLE(10_7, 5_0)\n            /// AVF_EXPORT NSString *const AVAssetExportPreset3840x2160      NS_AVAILABLE(10_10, 9_0)\n            /// ```\n            ///\n            let exporter: AVAssetExportSession = AVAssetExportSession(asset: mixCmp, presetName: AVAssetExportPresetHighestQuality)!\n            exporter.outputURL = URL.init(fileURLWithPath: SaveAlbumSample.ExportFileStr)\n            exporter.videoComposition = mainCmp\n            exporter.outputFileType = AVFileTypeQuickTimeMovie\n            exporter.exportAsynchronously(completionHandler: {\n                ///\n                /// \u30e1\u30a4\u30f3\u30b9\u30ec\u30c3\u30c9\u3067\u51e6\u7406\n                ///\n                DispatchQueue.main.async(execute: {\n                    if exporter.status == AVAssetExportSessionStatus.completed {\n                        PHPhotoLibrary.shared().performChanges({\n                            PHAssetChangeRequest.creationRequestForAssetFromVideo(atFileURL: exporter.outputURL!)\n                        }, completionHandler: { (success, err) in\n                            if success == true {\n                                print(\"\u4fdd\u5b58\u6210\u529f\uff01\")\n                            } else {\n                                print(\"\u4fdd\u5b58\u5931\u6557\uff01 \\(err) \\(err?.localizedDescription)\")\n                            }\n                        })\n                    } else {\n                        print(\"\u5931\u6557 \\(exporter.status) \\(exporter.error)\")\n                    }\n                })\n            })\n        } catch let e as NSError {\n            print(\"\u4f8b\u5916\u767a\u751f \\(e) \\(e.localizedDescription)\")\n            return\n        }\n    }\n}\n\nApple\u306eAVFoundation\u306e\u30de\u30cb\u30e5\u30a2\u30eb\u307b\u307c\u305d\u306e\u307e\u307e\u3067\u3059\u304c\u3001Swift\uff13\u3067\u52d5\u4f5c\u78ba\u8a8d\u6e08\u307f\u3067\u3059\u3002\n\nAVFoundation\u30de\u30cb\u30e5\u30a2\u30eb\nhttps://developer.apple.com/jp/documentation/AVFoundationPG.pdf\n\n\u3053\u306e\u30a2\u30d7\u30ea\u306e\u3088\u3046\u306a\u3053\u3068\u304c\u53ef\u80fd\u3067\u3059\u3002\nhttps://itunes.apple.com/jp/app/id651397153\n\n\u540c\u3058\u3088\u3046\u306b\u52d5\u753b\u7de8\u96c6\u30a2\u30d7\u30ea\u3092\u4f5c\u308a\u305f\u3044\u65b9\u306f\u3054\u53c2\u8003\u307e\u3067\u306b\u3002\n\u97f3\u3082\u30aa\u30fc\u30c7\u30a3\u30aa\u7528\u306e\u30c8\u30e9\u30c3\u30af\u3092\u4f5c\u6210\u3059\u308c\u3070\u8ffd\u52a0\u53ef\u80fd\u3067\u3059\u3002\n\n```swift\nimport UIKit\nimport AVFoundation\nimport Photos\n\n\n///\n/// \u30a2\u30eb\u30d0\u30e0\u4fdd\u5b58\u30b3\u30f3\u30c8\u30ed\u30fc\u30e9\u30fc\u30b5\u30f3\u30d7\u30eb\n///\nclass SaveAlbumSample: NSObject {\n\n    \n    // MARK: ---------------------------------------- static\n    ///\n    /// \u51fa\u529b\u30d5\u30a1\u30a4\u30eb\u30d1\u30b9\uff08\u6587\u5b57\u5217\uff09\n    ///\n    static let ExportFileStr: String = NSHomeDirectory() + \"/Documents/sample.mov\"\n\n\n    // MARK: ---------------------------------------- func\n    ///\n    /// \u56fa\u5b9a\u51fa\u529b\u30b5\u30f3\u30d7\u30eb\n    ///\n    static func SaveStartSample2(a: AVURLAsset, b: AVURLAsset) {\n        do {\n            ///\n            /// \u30b3\u30f3\u30dd\u30b8\u30b7\u30e7\u30f3\u3092\u4f5c\u6210\u3059\u308b\n            ///\n            let mixCmp: AVMutableComposition = AVMutableComposition()\n            ///\n            /// \u30d3\u30c7\u30aa\u30c8\u30e9\u30c3\u30af\u8ffd\u52a0\uff21\n            ///\n            /// kCMPersistentTrackID_Invalid\u3067\u30c8\u30e9\u30c3\u30afID\u3092\u81ea\u52d5\u8a2d\u5b9a\n            ///\n            let cmpTrcA: AVMutableCompositionTrack = mixCmp.addMutableTrack(withMediaType: AVMediaTypeVideo, preferredTrackID: kCMPersistentTrackID_Invalid)\n            try cmpTrcA.insertTimeRange(CMTimeRangeMake(kCMTimeZero, a.duration), of: a.tracks(withMediaType: AVMediaTypeVideo)[0], at: kCMTimeZero)\n            ///\n            /// \u30d3\u30c7\u30aa\u30c8\u30e9\u30c3\u30af\u8ffd\u52a0\uff22\n            ///\n            /// kCMPersistentTrackID_Invalid\u3067\u30c8\u30e9\u30c3\u30afID\u3092\u81ea\u52d5\u8a2d\u5b9a\n            ///\n            let cmpTrcB: AVMutableCompositionTrack = mixCmp.addMutableTrack(withMediaType: AVMediaTypeVideo, preferredTrackID: kCMPersistentTrackID_Invalid)\n            try cmpTrcB.insertTimeRange(CMTimeRangeMake(kCMTimeZero, b.duration), of: b.tracks(withMediaType: AVMediaTypeVideo)[0], at: kCMTimeZero)\n            ///\n            /// \u30d3\u30c7\u30aa\u30b3\u30f3\u30dd\u30b8\u30b7\u30e7\u30f3\u547d\u4ee4\u4f5c\u6210\n            ///\n            /// You should add the length equal to the length of the longer asset in terms of duration.\n            ///\n            let mainIns: AVMutableVideoCompositionInstruction = AVMutableVideoCompositionInstruction.init()\n            mainIns.timeRange = CMTimeRangeMake(kCMTimeZero, CMTimeMaximum(a.duration, b.duration))\n            mainIns.backgroundColor = UIColor.darkGray.cgColor\n            ///\n            /// \u52a0\u5de5\u7528\u30ec\u30a4\u30e4\u30fc\u4f5c\u6210\uff21\n            ///\n            let lyrInsA: AVMutableVideoCompositionLayerInstruction = AVMutableVideoCompositionLayerInstruction.init(assetTrack: cmpTrcA)\n            let scaleA: CGAffineTransform = CGAffineTransform.init(scaleX: 1.5, y: 1.5)\n            let moveA: CGAffineTransform = CGAffineTransform.init(translationX: 100, y: 100)\n            lyrInsA.setOpacity(0.5, at: kCMTimeZero)\n            lyrInsA.setTransform(scaleA.concatenating(moveA), at: kCMTimeZero)\n            ///\n            /// \u52a0\u5de5\u7528\u30ec\u30a4\u30e4\u30fc\u4f5c\u6210\uff22\n            ///\n            let lyrInsB: AVMutableVideoCompositionLayerInstruction = AVMutableVideoCompositionLayerInstruction.init(assetTrack: cmpTrcB)\n            let scaleB: CGAffineTransform = CGAffineTransform.init(scaleX: 0.8, y: 0.8)\n            lyrInsB.setOpacity(0.5, at: kCMTimeZero)\n            lyrInsB.setTransform(scaleB, at: kCMTimeZero)\n            ///\n            /// \u30c6\u30ad\u30b9\u30c8\u30ec\u30a4\u30e4\u30fc\u4f5c\u6210\n            ///\n            let lyrText: CATextLayer = CATextLayer()\n            lyrText.string = \"TextLayer\"\n            lyrText.font = UIFont.systemFont(ofSize: 300) as CFTypeRef!\n            lyrText.foregroundColor = UIColor.yellow.cgColor\n            lyrText.opacity = 0.5\n            lyrText.shadowOpacity = 1\n            lyrText.alignmentMode = kCAAlignmentCenter\n            lyrText.frame = CGRect.init(x: 0, y: 0, width: UIScreen.main.bounds.size.width * 2, height: UIScreen.main.bounds.size.height * 2 * 0.5)\n            ///\n            /// \u89aa\u30ec\u30a4\u30e4\u30fc\u3068\u30d3\u30c7\u30aa\u30ec\u30a4\u30e4\u30fc\u4f5c\u6210\n            ///\n            let lyrParent: CALayer = CALayer()\n            lyrParent.backgroundColor = UIColor.clear.cgColor\n            lyrParent.frame = CGRect.Make(0, 0, UIScreen.main.bounds.size.width * 2, UIScreen.main.bounds.size.height * 2)\n            let lyrVideo: CALayer = CALayer()\n            lyrVideo.frame = CGRect.Make(0, 0, UIScreen.main.bounds.size.width * 2, UIScreen.main.bounds.size.height * 2)\n            lyrParent.addSublayer(lyrVideo)\n            lyrParent.addSublayer(lyrText)\n            ///\n            /// \u547d\u4ee4\u306b\u30bb\u30c3\u30c8\n            ///\n            mainIns.layerInstructions = [ lyrInsA, lyrInsB ]\n            ///\n            /// \u30d3\u30c7\u30aa\u30b3\u30f3\u30dd\u30b8\u30b7\u30e7\u30f3\u4f5c\u6210\n            ///\n            let mainCmp: AVMutableVideoComposition = AVMutableVideoComposition.init()\n            mainCmp.instructions = [ mainIns ]\n            mainCmp.frameDuration = CMTimeMake(1, 30)\n            mainCmp.renderSize = CGSize.init(width: UIScreen.main.bounds.size.width * 2, height: UIScreen.main.bounds.size.height * 2)\n            mainCmp.animationTool = AVVideoCompositionCoreAnimationTool.init(postProcessingAsVideoLayer: lyrVideo, in: lyrParent)\n            ///\n            /// \u51fa\u529b\u30d5\u30a1\u30a4\u30eb\u8a2d\u5b9a\n            ///\n            ///\n            /// \u30d5\u30a1\u30a4\u30eb\u304c\u5b58\u5728\u3057\u3066\u3044\u308b\u5834\u5408\u306f\u524a\u9664\n            ///\n            if FileManager.default.fileExists(atPath: SaveAlbumSample.ExportFileStr) == true {\n                try FileManager.default.removeItem(atPath: SaveAlbumSample.ExportFileStr)\n            }\n            ///\n            /// \u30a8\u30af\u30b9\u30dd\u30fc\u30c8\u30bb\u30c3\u30b7\u30e7\u30f3\u3092\u4f5c\u6210\u3057\u3066\u30ab\u30e1\u30e9\u30ed\u30fc\u30eb\u3078\u4fdd\u5b58\n            ///\n            /// ```\n            /// AVF_EXPORT NSString *const AVAssetExportPresetLowQuality     NS_AVAILABLE(10_11, 4_0)\n            /// AVF_EXPORT NSString *const AVAssetExportPresetMediumQuality  NS_AVAILABLE(10_11, 4_0)\n            /// AVF_EXPORT NSString *const AVAssetExportPresetHighestQuality NS_AVAILABLE(10_11, 4_0)\n            /// AVF_EXPORT NSString *const AVAssetExportPreset640x480        NS_AVAILABLE(10_7, 4_0)\n            /// AVF_EXPORT NSString *const AVAssetExportPreset960x540        NS_AVAILABLE(10_7, 4_0)\n            /// AVF_EXPORT NSString *const AVAssetExportPreset1280x720       NS_AVAILABLE(10_7, 4_0)\n            /// AVF_EXPORT NSString *const AVAssetExportPreset1920x1080      NS_AVAILABLE(10_7, 5_0)\n            /// AVF_EXPORT NSString *const AVAssetExportPreset3840x2160      NS_AVAILABLE(10_10, 9_0)\n            /// ```\n            ///\n            let exporter: AVAssetExportSession = AVAssetExportSession(asset: mixCmp, presetName: AVAssetExportPresetHighestQuality)!\n            exporter.outputURL = URL.init(fileURLWithPath: SaveAlbumSample.ExportFileStr)\n            exporter.videoComposition = mainCmp\n            exporter.outputFileType = AVFileTypeQuickTimeMovie\n            exporter.exportAsynchronously(completionHandler: {\n                ///\n                /// \u30e1\u30a4\u30f3\u30b9\u30ec\u30c3\u30c9\u3067\u51e6\u7406\n                ///\n                DispatchQueue.main.async(execute: {\n                    if exporter.status == AVAssetExportSessionStatus.completed {\n                        PHPhotoLibrary.shared().performChanges({\n                            PHAssetChangeRequest.creationRequestForAssetFromVideo(atFileURL: exporter.outputURL!)\n                        }, completionHandler: { (success, err) in\n                            if success == true {\n                                print(\"\u4fdd\u5b58\u6210\u529f\uff01\")\n                            } else {\n                                print(\"\u4fdd\u5b58\u5931\u6557\uff01 \\(err) \\(err?.localizedDescription)\")\n                            }\n                        })\n                    } else {\n                        print(\"\u5931\u6557 \\(exporter.status) \\(exporter.error)\")\n                    }\n                })\n            })\n        } catch let e as NSError {\n            print(\"\u4f8b\u5916\u767a\u751f \\(e) \\(e.localizedDescription)\")\n            return\n        }\n    }\n}\n```\n"}