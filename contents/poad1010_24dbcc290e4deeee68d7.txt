{"context": "\n\n\u3084\u308a\u305f\u3044\u3053\u3068\n\n\u958b\u767a\u74b0\u5883\u3092\u6c5a\u3055\u305a\u306bSpark\u306eHistory\u30b5\u30fc\u30d0\u30fc\u3092\u4f7f\u3044\u305f\u3044\uff01\nDocker\u4f7f\u3046\u5834\u5408\u3001\u4ed6\u306e\u30af\u30e9\u30b9\u30bf\u30fc\u3067\u5b9f\u884c\u3057\u305f\u7d50\u679c\u3092\u3001Spark\u306eHistory\u306b\u304a\u624b\u8efd\u306b\u98df\u308f\u305b\u3089\u308c\u308b\u3088\u3046\u306b\u3057\u305f\u3044\n\n\n\u8ab2\u984c\nDocker\u3092\u4f7f\u3063\u3066Spark\u3092\u5b9f\u884c\u3059\u308b\u305f\u3081\u306eDocker image\u306f\u591a\u3005\u3042\u308c\u3069\u3082\u3001History\u30b5\u30fc\u30d0\u30fc\u3082\u542b\u3081\u3066\u81ea\u52d5\u8d77\u52d5\u3057\u3066\u304f\u308c\u308bimage\u304c\u306a\u3044\uff01(\u3042\u3063\u3066\u3082\u898b\u3064\u304b\u3089\u306a\u3044)\n\n\u89e3\u6c7a\u65b9\u6cd5\n\u65e2\u5b58\u306eDocker image\u3092\u69cb\u7bc9\u3059\u308bDockerfile\u3092History\u30b5\u30fc\u30d0\u30fc\u3082\u8d77\u52d5\u3059\u308b\u3088\u3046\u306b\u5909\u66f4\u3059\u308b\n\n\u30d9\u30fc\u30b9\u3068\u3059\u308bDockerfile(\u30d3\u30eb\u30c9\u5bfe\u8c61\u30bd\u30fc\u30b9)\nhttps://github.com/poad/docker-spark/releases/tag/1.6.2\n\n\u30d0\u30fc\u30b8\u30e7\u30f3\n\u69cb\u7bc9\u3059\u308bDocker image\u306e\u5185\u5bb9\u306f\u4ee5\u4e0b\u306e\u901a\u308a\u3002\nJava\u3068Hadoop\u306e\u30d0\u30fc\u30b8\u30e7\u30f3\u306f\u3001\u4eca\u56de\u306f\u305f\u307e\u305f\u307e\u3053\u308c\u3068\u3044\u3046\u3060\u3051\u3067\u3001\u304a\u305d\u3089\u304f\u3001\u5225\u306e\u30d0\u30fc\u30b8\u30e7\u30f3\u3067\u3082\u540c\u3058\u5909\u66f4\u3067\u3044\u3051\u308b\u3068\u601d\u3046\uff08\u8a66\u3057\u3066\u306a\u3044\u3051\u3069\uff09\n\n\n\nOS/\u30df\u30c9\u30eb\u30a6\u30a7\u30a2\n\u30d0\u30fc\u30b8\u30e7\u30f3\n\u88dc\u8db3\n\n\n\n\nCentOS\n6.5\n7\u7cfb\u3060\u3068\u8272\u3005\u3068\u52d5\u304b\u306a\u3044\n\n\nJava\nOracle JDK7\nJava 8\u7248\u306eimage\u3082\u3042\u308b\u304c\u3001\u307e\u305a\u306f\u3053\u308c\n\n\nApache Hadoop\n2.7.2\n\n\n\nApache Spark\n1.6.2\n2.0.2\u30842.1.0\u306eimage\u3082\u3042\u308b\u304c\u3001\u307e\u305a\u306f\u3053\u308c\n\n\n\n\n\u624b\u9806\n\n\nbootstrap.sh \u306e $HADOOP_PREFIX/sbin/start-yarn.sh \u306e\u6b21\u306e\u884c\u306b\u4ee5\u4e0b\u306e1\u884c\u3092\u8ffd\u52a0\u3059\u308b\u3002\n\n${SPARK_HOME}/sbin/start-history-server.sh\n\n\n\n\nDockerfile \u306b\u4ee5\u4e0b\u306e2\u884c\u3092\u8ffd\u52a0\u3059\u308b\n\nRUN mkdir /tmp/spark-events\n\nEXPOSE 18080\n\n\n\ndocker run\u306e\u969b\u306b -p 18080:18080 \u3068-v /vagrant/logs/spark:/tmp/spark-events (/vagrant/logs/spark \u306f\u4ed6\u306e\u30af\u30e9\u30b9\u30bf\u30fc\u306eHistory\u3092\u683c\u7d0d\u3059\u308b\u30db\u30b9\u30c8\u5074\u306e\u30d1\u30b9)\u306e\u6307\u5b9a\u3092\u8ffd\u52a0\u3059\u308b\n\n\n\u7d50\u679c\n\nbootstrap.sh\n#!/bin/bash\n\n: ${HADOOP_PREFIX:=/usr/local/hadoop}\n\n$HADOOP_PREFIX/etc/hadoop/hadoop-env.sh\n\nrm /tmp/*.pid\n\n# installing libraries if any - (resource urls added comma separated to the ACP system variable)\ncd $HADOOP_PREFIX/share/hadoop/common ; for cp in ${ACP//,/ }; do  echo == $cp; curl -LO $cp ; done; cd -\n\n# altering the core-site configuration\nsed s/HOSTNAME/$HOSTNAME/ /usr/local/hadoop/etc/hadoop/core-site.xml.template > /usr/local/hadoop/etc/hadoop/core-site.xml\n\n# setting spark defaults\necho spark.yarn.jar hdfs:///spark/spark-assembly-1.6.2-hadoop2.6.0.jar > $SPARK_HOME/conf/spark-defaults.conf\ncp $SPARK_HOME/conf/metrics.properties.template $SPARK_HOME/conf/metrics.properties\n\nif [ -z \"${SPARK_HOME}\" ]; then\n  export SPARK_HOME=\"$(cd \"`dirname \"$0\"`\"/..; pwd)\"\nfi\n\nservice sshd start\n$HADOOP_PREFIX/sbin/start-dfs.sh\n$HADOOP_PREFIX/sbin/start-yarn.sh\n${SPARK_HOME}/sbin/start-history-server.sh\n\nCMD=${1:-\"exit 0\"}\nif [[ \"$CMD\" == \"-d\" ]];\nthen\n    service sshd stop\n    /usr/sbin/sshd -D -d\nelse\n    /bin/bash -c \"$*\"\nfi\n\n\n\nDockerfile\nFROM poad/docker-spark:1.6.2\n\nUSER root\n\nCOPY bootstrap.sh /etc/bootstrap.sh\nRUN chown root.root /etc/bootstrap.sh\nRUN chmod 700 /etc/bootstrap.sh\n\nRUN mkdir /tmp/spark-events\n\nEXPOSE 18080\n\nENTRYPOINT [\"/etc/bootstrap.sh\"]\n\n\n\n\n\u8d77\u52d5\u30b3\u30de\u30f3\u30c9\n docker run -d -h sandbox -p 18080:18080 -p 50010:50010 -p 50020:50020  -p 50070:50070 -p 50075:50075 -p 50090:50090 -p 8020:8020 -p 9000:9000 -p 19888:19888 -p 8030:8030 -p 8031:8031 -p 8032:8032 -p 8033:8033 -p 8040:8040 -p 8042:8042 -p 8088:8088 -p 49707:49707 -p 2122:2122 -v /vagrant/logs/spark:/tmp/spark-events --name spark poad/docker-spark:1.6.2-with-history-server -d\n\n\n\n\u6700\u5f8c\u306b\n\u3061\u306a\u307f\u306b\u3001History\u30b5\u30fc\u30d0\u30fc\u306e\u8d77\u52d5\u306f\u5c11\u3057\u6642\u9593\u304c\u304b\u304b\u308b(1\u5206\u304f\u3089\u3044\uff1f)\u305f\u3081\u3001\u305d\u308c\u307e\u3067\u306f\u6210\u529f\u3057\u3066\u3044\u308b\u306e\u304b\u308f\u304b\u3089\u306a\u3044\u72b6\u614b\u304c\u7d9a\u304d\u307e\u3059\n# \u3084\u308a\u305f\u3044\u3053\u3068\n - \u958b\u767a\u74b0\u5883\u3092\u6c5a\u3055\u305a\u306bSpark\u306eHistory\u30b5\u30fc\u30d0\u30fc\u3092\u4f7f\u3044\u305f\u3044\uff01\n - Docker\u4f7f\u3046\u5834\u5408\u3001\u4ed6\u306e\u30af\u30e9\u30b9\u30bf\u30fc\u3067\u5b9f\u884c\u3057\u305f\u7d50\u679c\u3092\u3001Spark\u306eHistory\u306b\u304a\u624b\u8efd\u306b\u98df\u308f\u305b\u3089\u308c\u308b\u3088\u3046\u306b\u3057\u305f\u3044\n\n# \u8ab2\u984c\nDocker\u3092\u4f7f\u3063\u3066Spark\u3092\u5b9f\u884c\u3059\u308b\u305f\u3081\u306eDocker image\u306f\u591a\u3005\u3042\u308c\u3069\u3082\u3001History\u30b5\u30fc\u30d0\u30fc\u3082\u542b\u3081\u3066\u81ea\u52d5\u8d77\u52d5\u3057\u3066\u304f\u308c\u308bimage\u304c\u306a\u3044\uff01(\u3042\u3063\u3066\u3082\u898b\u3064\u304b\u3089\u306a\u3044)\n\n# \u89e3\u6c7a\u65b9\u6cd5\n\u65e2\u5b58\u306eDocker image\u3092\u69cb\u7bc9\u3059\u308bDockerfile\u3092History\u30b5\u30fc\u30d0\u30fc\u3082\u8d77\u52d5\u3059\u308b\u3088\u3046\u306b\u5909\u66f4\u3059\u308b\n\n## \u30d9\u30fc\u30b9\u3068\u3059\u308bDockerfile(\u30d3\u30eb\u30c9\u5bfe\u8c61\u30bd\u30fc\u30b9)\nhttps://github.com/poad/docker-spark/releases/tag/1.6.2\n\n### \u30d0\u30fc\u30b8\u30e7\u30f3\n\u69cb\u7bc9\u3059\u308bDocker image\u306e\u5185\u5bb9\u306f\u4ee5\u4e0b\u306e\u901a\u308a\u3002\nJava\u3068Hadoop\u306e\u30d0\u30fc\u30b8\u30e7\u30f3\u306f\u3001\u4eca\u56de\u306f\u305f\u307e\u305f\u307e\u3053\u308c\u3068\u3044\u3046\u3060\u3051\u3067\u3001\u304a\u305d\u3089\u304f\u3001\u5225\u306e\u30d0\u30fc\u30b8\u30e7\u30f3\u3067\u3082\u540c\u3058\u5909\u66f4\u3067\u3044\u3051\u308b\u3068\u601d\u3046\uff08\u8a66\u3057\u3066\u306a\u3044\u3051\u3069\uff09\n\n| OS/\u30df\u30c9\u30eb\u30a6\u30a7\u30a2 | \u30d0\u30fc\u30b8\u30e7\u30f3    | \u88dc\u8db3                                 |\n|:-------------:|:-----------:|:-----------------------------------:|\n| CentOS        | 6.5         | 7\u7cfb\u3060\u3068\u8272\u3005\u3068\u52d5\u304b\u306a\u3044                   |\n| Java          | Oracle JDK7 | Java 8\u7248\u306eimage\u3082\u3042\u308b\u304c\u3001\u307e\u305a\u306f\u3053\u308c     |\n| Apache Hadoop | 2.7.2       |                                     |\n| Apache Spark  | 1.6.2       | 2.0.2\u30842.1.0\u306eimage\u3082\u3042\u308b\u304c\u3001\u307e\u305a\u306f\u3053\u308c |\n\n# \u624b\u9806\n1. `bootstrap.sh` \u306e `$HADOOP_PREFIX/sbin/start-yarn.sh` \u306e\u6b21\u306e\u884c\u306b\u4ee5\u4e0b\u306e1\u884c\u3092\u8ffd\u52a0\u3059\u308b\u3002\n> ```\n> ${SPARK_HOME}/sbin/start-history-server.sh\n> ```\n\n2. `Dockerfile` \u306b\u4ee5\u4e0b\u306e2\u884c\u3092\u8ffd\u52a0\u3059\u308b\n>```\n> RUN mkdir /tmp/spark-events\n> \n> EXPOSE 18080\n> ```\n\n3. docker run\u306e\u969b\u306b `-p 18080:18080` \u3068`-v /vagrant/logs/spark:/tmp/spark-events` (`/vagrant/logs/spark` \u306f\u4ed6\u306e\u30af\u30e9\u30b9\u30bf\u30fc\u306eHistory\u3092\u683c\u7d0d\u3059\u308b\u30db\u30b9\u30c8\u5074\u306e\u30d1\u30b9)\u306e\u6307\u5b9a\u3092\u8ffd\u52a0\u3059\u308b\n\n## \u7d50\u679c\n\n```:bootstrap.sh\n#!/bin/bash\n\n: ${HADOOP_PREFIX:=/usr/local/hadoop}\n\n$HADOOP_PREFIX/etc/hadoop/hadoop-env.sh\n\nrm /tmp/*.pid\n\n# installing libraries if any - (resource urls added comma separated to the ACP system variable)\ncd $HADOOP_PREFIX/share/hadoop/common ; for cp in ${ACP//,/ }; do  echo == $cp; curl -LO $cp ; done; cd -\n\n# altering the core-site configuration\nsed s/HOSTNAME/$HOSTNAME/ /usr/local/hadoop/etc/hadoop/core-site.xml.template > /usr/local/hadoop/etc/hadoop/core-site.xml\n\n# setting spark defaults\necho spark.yarn.jar hdfs:///spark/spark-assembly-1.6.2-hadoop2.6.0.jar > $SPARK_HOME/conf/spark-defaults.conf\ncp $SPARK_HOME/conf/metrics.properties.template $SPARK_HOME/conf/metrics.properties\n\nif [ -z \"${SPARK_HOME}\" ]; then\n  export SPARK_HOME=\"$(cd \"`dirname \"$0\"`\"/..; pwd)\"\nfi\n\nservice sshd start\n$HADOOP_PREFIX/sbin/start-dfs.sh\n$HADOOP_PREFIX/sbin/start-yarn.sh\n${SPARK_HOME}/sbin/start-history-server.sh\n\nCMD=${1:-\"exit 0\"}\nif [[ \"$CMD\" == \"-d\" ]];\nthen\n\tservice sshd stop\n\t/usr/sbin/sshd -D -d\nelse\n\t/bin/bash -c \"$*\"\nfi\n```\n\n```:Dockerfile\nFROM poad/docker-spark:1.6.2\n\nUSER root\n\nCOPY bootstrap.sh /etc/bootstrap.sh\nRUN chown root.root /etc/bootstrap.sh\nRUN chmod 700 /etc/bootstrap.sh\n\nRUN mkdir /tmp/spark-events\n\nEXPOSE 18080\n\nENTRYPOINT [\"/etc/bootstrap.sh\"]\n\n```\n\n```:\u8d77\u52d5\u30b3\u30de\u30f3\u30c9\n docker run -d -h sandbox -p 18080:18080 -p 50010:50010 -p 50020:50020 \t-p 50070:50070 -p 50075:50075 -p 50090:50090 -p 8020:8020 -p 9000:9000 -p 19888:19888 -p 8030:8030 -p 8031:8031 -p 8032:8032 -p 8033:8033 -p 8040:8040 -p 8042:8042 -p 8088:8088 -p 49707:49707 -p 2122:2122 -v /vagrant/logs/spark:/tmp/spark-events --name spark poad/docker-spark:1.6.2-with-history-server -d\n```\n\n# \u6700\u5f8c\u306b\n\u3061\u306a\u307f\u306b\u3001History\u30b5\u30fc\u30d0\u30fc\u306e\u8d77\u52d5\u306f\u5c11\u3057\u6642\u9593\u304c\u304b\u304b\u308b(1\u5206\u304f\u3089\u3044\uff1f)\u305f\u3081\u3001\u305d\u308c\u307e\u3067\u306f\u6210\u529f\u3057\u3066\u3044\u308b\u306e\u304b\u308f\u304b\u3089\u306a\u3044\u72b6\u614b\u304c\u7d9a\u304d\u307e\u3059\n", "tags": ["Spark1.6.2", "docker"]}