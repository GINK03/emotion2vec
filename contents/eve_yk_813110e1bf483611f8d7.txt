{"context": " More than 1 year has passed since last update.\u3053\u3093\u306b\u3061\u306f\uff01Liaro\u306e\u30a8\u30f3\u30b8\u30cb\u30a2\u306e@eve_yk\u3067\u3059\u3002\u4e8b\u306e\u767a\u7aef\u306b\u3064\u3044\u3066\u306f\u524d\u7de8\u3092\u898b\u3066\u4e0b\u3055\u3044(\u6ce3)\n\u524d\u56de\u306f\u8b58\u5225\u5668\u3092\u5b66\u7fd2\u3055\u305b\u308b\u305f\u3081\u306e\u30c7\u30fc\u30bf\u96c6\u3081\u30fb\u52a0\u5de5\u3092\u884c\u3044\u307e\u3057\u305f\u3002\n\u4eca\u56de\u306f\u8b58\u5225\u5668\u306e\u30e2\u30c7\u30eb\u3092\u8a18\u8ff0\u3057\u3001\u5b9f\u969b\u306b\u5b66\u7fd2\u30fb\u8a55\u4fa1(\u9854\u8b58\u5225)\u3092\u3057\u3066\u3044\u304d\u307e\u3059\uff01\n\n3. \u8b58\u5225\u5668\u306e\u30e2\u30c7\u30eb\u3092\u69cb\u7bc9\u3059\u308b\n\u6b21\u306f\u5b66\u7fd2\u3055\u305b\u308b\u9854\u753b\u50cf\u8b58\u5225\u5668\u306e\u30e2\u30c7\u30eb\u3092Chainer\u3067\u8a18\u8ff0\u3057\u307e\u3059\u3002\n(\u524d\u56de\u306e\u30c7\u30fc\u30bf\u30bb\u30c3\u30c8\u4f5c\u6210\u3082\u5408\u308f\u305b\u3066)\u4ee5\u4e0b\u306e\u30b3\u30fc\u30c9\u3092\u53c2\u8003\u306b\u3055\u305b\u3066\u3044\u305f\u3060\u304d\u307e\u3057\u305f\u3002\nhttps://github.com/mitmul/chainer-cifar10\n\nYTNet\nclass YTNet(chainer.Chain):\n\n    def __init__(self):\n        \"\"\"\n            \u30e2\u30c7\u30eb\u306e\u5b9a\u7fa9\n        \"\"\"\n        super(YTNet, self).__init__(\n            conv1=L.Convolution2D(3, 32, 5, stride=1, pad=2),\n            bn1  =L.BatchNormalization(32),\n            conv2=L.Convolution2D(32, 32, 5, stride=1, pad=2),\n            bn2  =L.BatchNormalization(32),\n            conv3=L.Convolution2D(32, 64, 5, stride=1, pad=2),\n            fc4=F.Linear(16384, 4096),\n            fc5=F.Linear(4096, 2),\n        )\n        self.train = True\n\n    def __call__(self, x, t):\n        \"\"\"\n            forword\u51e6\u7406\n        \"\"\"\n        h = F.max_pooling_2d(F.relu(self.conv1(x)), 3, stride=2)\n        h = F.max_pooling_2d(F.relu(self.conv2(h)), 3, stride=2)\n        h = F.relu(self.conv3(h))\n        h = F.dropout(F.relu(self.fc4(h)), ratio=0.5, train=self.train)\n        h = self.fc5(h)\n\n        self.loss = F.softmax_cross_entropy(h, t)\n        self.accuracy = F.accuracy(h, t)\n\n        if self.train:\n            return self.loss\n        else:\n            self.pred = F.softmax(h)\n            return self.pred\n\n\n\n4. \u30e2\u30c7\u30eb\u3092\u5b66\u7fd2\u3059\u308b\n3.\u306e\u30b3\u30fc\u30c9\u3092\u3082\u3068\u306b\u3001\u30e2\u30c7\u30eb\u3092\u5b66\u7fd2\u3055\u305b\u308b\u30b3\u30fc\u30c9\u3092\u66f8\u304d\u307e\u3059\u3002\n\u4eca\u56de\u306f\u6bd4\u8f03\u7684\u3059\u3050\u306b\u5b66\u7fd2\u304c\u7d42\u308f\u308a\u307e\u3059\u304c\u3001\u3082\u3063\u3068\u5927\u898f\u6a21\u306a\u30c7\u30fc\u30bf\u30bb\u30c3\u30c8\u3092\u6271\u304a\u3046\u3068\u3057\u305f\u6642\u306f\u3001\u5b66\u7fd2\u306e\u9032\u6357\u3092\u8868\u793a\u3059\u308b\u306e\u304c\u7cbe\u795e\u885b\u751f\u4e0a\u826f\u3044\u3067\u3059\u3002\n\ntrain.py\n# -*- coding: utf-8 -*-\n\nimport argparse\nimport os\nimport six\nimport chainer\nimport chainer.functions as F\nimport chainer.links as L\nimport numpy as np\nfrom chainer import optimizers\nfrom chainer import cuda\nfrom chainer import serializers\nfrom chainer import Variable\nfrom progressbar import ProgressBar\n\n\nclass YTNet(chainer.Chain):\n\n    def __init__(self):\n        \"\"\"\n            \u30e2\u30c7\u30eb\u306e\u5b9a\u7fa9\n        \"\"\"\n        super(YTNet, self).__init__(\n            conv1=L.Convolution2D(3, 32, 5, stride=1, pad=2),\n            bn1  =L.BatchNormalization(32),\n            conv2=L.Convolution2D(32, 32, 5, stride=1, pad=2),\n            bn2  =L.BatchNormalization(32),\n            conv3=L.Convolution2D(32, 64, 5, stride=1, pad=2),\n            fc4=F.Linear(16384, 4096),\n            fc5=F.Linear(4096, 2),\n        )\n        self.train = True\n\n    def __call__(self, x, t):\n        \"\"\"\n            forword\u51e6\u7406\n        \"\"\"\n        h = F.max_pooling_2d(F.relu(self.conv1(x)), 3, stride=2)\n        h = F.max_pooling_2d(F.relu(self.conv2(h)), 3, stride=2)\n        h = F.relu(self.conv3(h))\n        h = F.dropout(F.relu(self.fc4(h)), ratio=0.5, train=self.train)\n        h = self.fc5(h)\n\n        self.loss = F.softmax_cross_entropy(h, t)\n        self.accuracy = F.accuracy(h, t)\n\n        if self.train:\n            return self.loss\n        else:\n            self.pred = F.softmax(h)\n            return self.pred\n\ndef one_epoch(args, model, optimizer, data, label, epoch, train):\n    \"\"\"\n        1epoch\u306e\u30c8\u30ec\u30fc\u30cb\u30f3\u30b0\u3001\u3082\u3057\u304f\u306f\u8a55\u4fa1\u51e6\u7406\u3092\u884c\u3046\n    \"\"\"\n    model.train = train\n    xp = cuda.cupy if args.gpu >= 0 else np\n\n    sum_accuracy = 0\n    sum_loss = 0\n\n    p = ProgressBar(min_value=0, max_value=data.shape[0]) # \u9032\u6357\u78ba\u8a8d\u7528\n    perm = np.random.permutation(data.shape[0])\n    for i in xrange(0, data.shape[0], args.batchsize):\n        p.update(i)\n\n        # minibatch\u3092\u4f5c\u6210\n        target = perm[i:i + args.batchsize]\n        x = xp.array(data[target], dtype=xp.float32)\n        t = xp.array(label[target], dtype=xp.int32)\n\n        # Variable\u3092\u4f5c\u6210\n        volatile = 'off' if train else 'on'\n        x = Variable(x, volatile=volatile)\n        t = Variable(t, volatile=volatile)\n\n        # \u30d1\u30e9\u30e1\u30fc\u30bf\u66f4\u65b0\u3001\u3082\u3057\u304f\u306f\u30e9\u30d9\u30eb\u4e88\u6e2c\n        if train:\n            optimizer.update(model, x, t)\n        else:\n            pred = model(x, t).data\n\n        sum_loss += float(model.loss.data) * t.data.shape[0]\n        sum_accuracy += float(model.accuracy.data) * t.data.shape[0]\n\n        del x, t\n\n    print \"\" # \u6539\u884c\u7528\n    if train:\n        print \"train epoch \" + str(epoch)\n        print \"   train loss : \" + str(sum_loss / data.shape[0])\n        print \"   train acc  : \" + str(sum_accuracy / data.shape[0])\n    else:\n        print \"test epoch \" + str(epoch)\n        print \"   test loss : \" + str(sum_loss / data.shape[0])\n        print \"   test acc  : \" + str(sum_accuracy / data.shape[0])\n\ndef load_dataset(datadir):\n    \"\"\"\n        \u30c7\u30fc\u30bf\u30bb\u30c3\u30c8\u3092\u30ed\u30fc\u30c9\u3059\u308b\n    \"\"\"\n    train_data = np.load('%s/train_data.npy' % datadir)\n    train_labels = np.load('%s/train_label.npy' % datadir)\n    test_data = np.load('%s/test_data.npy' % datadir)\n    test_labels = np.load('%s/test_label.npy' % datadir)\n\n    return train_data, train_labels, test_data, test_labels\n\nif __name__ == '__main__':\n    parser = argparse.ArgumentParser()\n    parser.add_argument(\"--gpu\", type=int, default=-1)\n    parser.add_argument(\"--batchsize\", type=int, default=10)\n    parser.add_argument('--data_dir', type=str, default='dataset')\n    parser.add_argument('--output_dir', type=str, default='result')\n    args = parser.parse_args()\n\n    # model,optimizer\u4f5c\u6210\n    model = YTNet()\n    optimizer = optimizers.Adam(alpha=0.00005)\n    optimizer.setup(model)\n\n    # \u30c7\u30fc\u30bf\u30bb\u30c3\u30c8\u30ed\u30fc\u30c9\n    dataset = load_dataset(args.data_dir)\n    tr_data, tr_labels, te_data, te_labels = dataset\n\n    # \u30e1\u30a4\u30f3\u30eb\u30fc\u30d7\n    for epoch in range(1, 20):\n        # \u8a13\u7df4\n        one_epoch(args, model, optimizer, tr_data, tr_labels, epoch, True)\n        # \u8a55\u4fa1\n        one_epoch(args, model, optimizer, te_data, te_labels, epoch, False)\n\n    # \u30e2\u30c7\u30eb\u306e\u4fdd\u5b58\n    if not os.path.exists(args.output_dir):\n        os.makedirs(args.output_dir)\n    serializers.save_npz(args.output_dir + \"YTNet.chainermodel\", model)\n    serializers.save_npz(args.output_dir + \"YTNet.state\", optimizer)\n\n\n20epoch\u307b\u3069\u5b66\u7fd2\u3055\u305b\u308b\u3068\u8a13\u7df4\u30c7\u30fc\u30bf\u3067\u306eAccuracy\u304c99%\u3092\u8d85\u3048\u30b5\u30c1\u3063\u3066\u3044\u307e\u3057\u305f\u3002\n\n5. \u6027\u80fd\u3092\u8a55\u4fa1\u3059\u308b\n\u3044\u3088\u3044\u3088\u3001\u6027\u80fd\u306e\u8a55\u4fa1\u3092\u3057\u307e\u3059\u3002\n\u4ee5\u4e0b\u306e10\u679a\u306e\u753b\u50cf\u3092\u4f7f\u3063\u3066\u30c6\u30b9\u30c8\u3057\u307e\u3059\u3002\u3053\u306e\u4e2d\u306e5\u679a\u304c@eve_yk\u30675\u679a\u304c\u30b9\u30fc\u30d1\u30fc\u30de\u30e9\u30c9\u30fc\u30ca\u7530\u4e2d\u3055\u3093\u3067\u3059\u3002\n\u9854\u306e\u30b5\u30f3\u30d7\u30eb\u306f\u524d\u56de\u306e\u8a18\u4e8b\u306b\u3042\u308b\u306e\u3067\u3001\u5f53\u3066\u3089\u308c\u308b\u304b\u307f\u306a\u3055\u3093\u3082\u6311\u6226\u3057\u3066\u307f\u3066\u304f\u3060\u3055\u3044\u3002\n\n\u5c11\u3057\u60a9\u307f\u307e\u3059\u304c\u3001\u4eba\u306e\u76ee\u3067\u898b\u308c\u3070\u308f\u304b\u308a\u307e\u3059\u306d\u3002\u773c\u93e1\u306e\u8272\u3068\u304b\u9055\u3044\u307e\u3059\u3002\n\u6b63\u89e3\u306f\u30011,2,4,7,10\u304ceve_yk\u30013,5,6,8,9\u304c\u7530\u4e2d\u3055\u3093\u3067\u3059\u3002\n\u3055\u3066\u3001\u4eca\u56de\u5b66\u7fd2\u3057\u305fCNN\u3067\u306f\u3069\u3046\u3067\u3057\u3087\u3046\u304b\uff1f\n\u4ee5\u4e0b\u306e\u30b3\u30fc\u30c9\u3067\u30c6\u30b9\u30c8\u3057\u307e\u3059\u3002\n\ntest.py\n# coding:utf-8\n\nimport os\nimport sys\nimport argparse\nimport glob\nimport cv2\nimport numpy as np\nfrom chainer import Variable\nfrom chainer import serializers\nfrom train import YTNet\n\ndef transpose_opencv2chainer(x):\n    \"\"\"\n        opencv\u306enpy\u5f62\u5f0f\u304b\u3089chainer\u306enpy\u5f62\u5f0f\u306b\u5909\u63db\n        opencv  => (height, width, channel)\n        chainer => (channel, height, width)\n    \"\"\"\n    return x.transpose(2,0,1)\n\nfile2labels = {\"01.jpg\":\"eve_yk\", \"02.jpg\":\"eve_yk\", \"03.jpg\":\"tanaka\",\n               \"04.jpg\":\"eve_yk\", \"05.jpg\":\"tanaka\", \"06.jpg\":\"tanaka\",\n               \"07.jpg\":\"eve_yk\", \"08.jpg\":\"tanaka\", \"09.jpg\":\"tanaka\",\n               \"10.jpg\":\"eve_yk\"}\n\n\nif __name__ == \"__main__\":\n    parser = argparse.ArgumentParser(description='CNN\u7528\u30c7\u30fc\u30bf\u30bb\u30c3\u30c8\u4f5c\u6210')\n    parser.add_argument('--input_path',   required=True, type=str)\n    parser.add_argument('--model_path',  required=True, type=str)\n    args = parser.parse_args()\n\n    # jpg\u30d5\u30a1\u30a4\u30eb\u4e00\u89a7\u53d6\u5f97\n    test_files  = glob.glob(args.input_path+\"/*.jpg\")\n\n    # \u30e2\u30c7\u30eb\u306e\u30ed\u30fc\u30c9\n    model = YTNet()\n    model = serializers.load_npz(args.model_path, , model)\n\n    # \u4e00\u679a\u305a\u3064\u8a55\u4fa1\n    collect_count = 0.0\n        test_count = 0.0\n    for file_path in test_files:\n        image = cv2.imread(file_path)\n        if image is None:\n            # \u8aad\u307f\u8fbc\u307f\u5931\u6557\n            continue\n                test_count += 1.0\n\n        # \u30c7\u30a3\u30ec\u30af\u30c8\u30ea\u69cb\u9020\u304b\u3089\u30d5\u30a1\u30a4\u30eb\u540d\u3092\u53d6\u5f97\n        file_name = file_path.split(\"/\")[-1]\n                print file_name+\"(\"+file2labels[file_name]+\") :\",\n\n        # chainer\u7528\u5f62\u5f0f\u306b\u5909\u63db\n        image = transpose_opencv2chainer(image)\n        x = Variable(np.asarray([image], dtype=np.float32), volatile=\"on\")\n        t = Variable(np.asarray([[0]], dtype=np.int32), volatile=\"on\")\n\n        # \u8a55\u4fa1\n        pred = model(x, t).data\n        if int(pred) == 0: # tanaka\n            print u\"\u8b58\u5225\u7d50\u679c\u300ctanaka\u300d\"\n            if file2labels[file_name] == u\"tanaka\":\n                collect_count += 1.0\n        else: # eve_yk\n            print u\"\u8b58\u5225\u7d50\u679c\u300ceve_yk\u300d\"\n            if file2labels[file_name] == u\"eve_yk\":\n                collect_count += 1.0    \n\n    print u\"total:{}%\".format(collect_count/test_count*100)\n\n\n\u7d50\u679c\u306f\u3053\u306e\u901a\u308a\n\npython test.py --input_path test/ --model_path result/YTNet.chainermodel\n08.jpg(tanaka) : \u8b58\u5225\u7d50\u679c\u300ctanaka\u300d\n09.jpg(tanaka) : \u8b58\u5225\u7d50\u679c\u300ceve_yk\u300d\n07.jpg(eve_yk) : \u8b58\u5225\u7d50\u679c\u300ceve_yk\u300d\n01.jpg(eve_yk) : \u8b58\u5225\u7d50\u679c\u300ceve_yk\u300d\n03.jpg(tanaka) : \u8b58\u5225\u7d50\u679c\u300ctanaka\u300d\n06.jpg(tanaka) : \u8b58\u5225\u7d50\u679c\u300ceve_yk\u300d\n02.jpg(eve_yk) : \u8b58\u5225\u7d50\u679c\u300ceve_yk\u300d\n05.jpg(tanaka) : \u8b58\u5225\u7d50\u679c\u300ctanaka\u300d\n04.jpg(eve_yk) : \u8b58\u5225\u7d50\u679c\u300ceve_yk\u300d\n10.jpg(eve_yk) : \u8b58\u5225\u7d50\u679c\u300ceve_yk\u300d\ntotal:8.0/10\n\n6\u30689\u306e\u7530\u4e2d\u3055\u3093\u3092eve_yk\u3068\u9593\u9055\u3048\u3066\u3057\u307e\u3044\u307e\u3057\u305f\u3002\n\u8a13\u7df4\u30c7\u30fc\u30bf\u306e\u91cf\u306e\u9055\u3044\u304b\u3089\u3001\u504f\u3063\u305f\u4e88\u6e2c\u3092\u3057\u3066\u3057\u307e\u3046\u306e\u3067\u3057\u3087\u3046\u304b\u3002\n\u3057\u304b\u3057\u3001\u4eba\u306e\u76ee\u3067\u898b\u3066\u3082\u60a9\u3080\u753b\u50cf\u3092\u8aa4\u3063\u3066\u3044\u308b\u6c17\u304c\u3057\u307e\u3059\u3002\u3084\u306f\u308a\u3001\u4e2d\u9014\u534a\u7aef\u306a\u30b7\u30b9\u30c6\u30e0\u3067\u30c9\u30c3\u30da\u30eb\u30b2\u30f3\u30ac\u30fc\u3092\u898b\u5206\u3051\u308b\u306e\u306f\u96e3\u3057\u3044\u3088\u3046\u3067\u3059\u3002\n\n\u304a\u308f\u308a\u306b\n\u81ea\u5206\u306e\u305d\u3063\u304f\u308a\u3055\u3093\u3092\u8b58\u5225\u3059\u308b\u9854\u5206\u985e\u5668\u3092\u4f5c\u6210\u3057\u307e\u3057\u305f\u3002\n\u7cbe\u5ea6\u306f\u307e\u3041\u307e\u3041\u3068\u3044\u3063\u305f\u3068\u3053\u308d\u3002\u30c7\u30fc\u30bf\u6570\u3084\u524d\u51e6\u7406\u306a\u3069\u3001\u59a5\u5354\u3057\u305f\u3068\u3053\u308d\u304c\u591a\u304f\u3042\u3063\u305f\u4e2d\u3067\u306f\u826f\u304b\u3063\u305f\u65b9\u304b\u3068\u601d\u3044\u307e\u3059\u3002\n\u9811\u5f35\u3063\u3066\u30c7\u30fc\u30bf\u3092\u96c6\u3081\u3066\u3082\u3063\u3068\u591a\u4eba\u6570\u306e\u5206\u985e\u3092\u3057\u305f\u308a\u3001\u524d\u51e6\u7406\u306a\u3069\u3092\u9811\u5f35\u3063\u3066\u7cbe\u5ea6\u5411\u4e0a\u306b\u30c1\u30e3\u30ec\u30f3\u30b8\u3059\u308b\u3068\u9762\u767d\u305d\u3046\u3067\u3059\u306d\uff01\nLiaro\u3001eve_yk\u306f\u30b9\u30fc\u30d1\u30fc\u30de\u30e9\u30c9\u30fc\u30ca\u3092\u5fdc\u63f4\u3057\u3066\u3044\u307e\u3059\uff01\n\n\u53c2\u8003\nhttps://github.com/mitmul/chainer-cifar10\n\u5409\u672c\u8208\u696d\u682a\u5f0f\u4f1a\u793e \u82b8\u4eba\u30d7\u30ed\u30d5\u30a3\u30fc\u30eb | \u30b9\u30fc\u30d1\u30fc\u30de\u30e9\u30c9\u30fc\u30ca\n\u3053\u3093\u306b\u3061\u306f\uff01Liaro\u306e\u30a8\u30f3\u30b8\u30cb\u30a2\u306e@eve_yk\u3067\u3059\u3002\u4e8b\u306e\u767a\u7aef\u306b\u3064\u3044\u3066\u306f[\u524d\u7de8](http://qiita.com/eve_yk/items/e0ccd7917237fed1607f)\u3092\u898b\u3066\u4e0b\u3055\u3044(\u6ce3)\n\u524d\u56de\u306f\u8b58\u5225\u5668\u3092\u5b66\u7fd2\u3055\u305b\u308b\u305f\u3081\u306e\u30c7\u30fc\u30bf\u96c6\u3081\u30fb\u52a0\u5de5\u3092\u884c\u3044\u307e\u3057\u305f\u3002\n\u4eca\u56de\u306f\u8b58\u5225\u5668\u306e\u30e2\u30c7\u30eb\u3092\u8a18\u8ff0\u3057\u3001\u5b9f\u969b\u306b\u5b66\u7fd2\u30fb\u8a55\u4fa1(\u9854\u8b58\u5225)\u3092\u3057\u3066\u3044\u304d\u307e\u3059\uff01\n\n## 3. \u8b58\u5225\u5668\u306e\u30e2\u30c7\u30eb\u3092\u69cb\u7bc9\u3059\u308b\n\u6b21\u306f\u5b66\u7fd2\u3055\u305b\u308b\u9854\u753b\u50cf\u8b58\u5225\u5668\u306e\u30e2\u30c7\u30eb\u3092[Chainer](http://chainer.org/)\u3067\u8a18\u8ff0\u3057\u307e\u3059\u3002\n(\u524d\u56de\u306e\u30c7\u30fc\u30bf\u30bb\u30c3\u30c8\u4f5c\u6210\u3082\u5408\u308f\u305b\u3066)\u4ee5\u4e0b\u306e\u30b3\u30fc\u30c9\u3092\u53c2\u8003\u306b\u3055\u305b\u3066\u3044\u305f\u3060\u304d\u307e\u3057\u305f\u3002\n[https://github.com/mitmul/chainer-cifar10](https://github.com/mitmul/chainer-cifar10)\n\n\n\n```py:YTNet\nclass YTNet(chainer.Chain):\n\n    def __init__(self):\n        \"\"\"\n            \u30e2\u30c7\u30eb\u306e\u5b9a\u7fa9\n        \"\"\"\n        super(YTNet, self).__init__(\n            conv1=L.Convolution2D(3, 32, 5, stride=1, pad=2),\n            bn1  =L.BatchNormalization(32),\n            conv2=L.Convolution2D(32, 32, 5, stride=1, pad=2),\n            bn2  =L.BatchNormalization(32),\n            conv3=L.Convolution2D(32, 64, 5, stride=1, pad=2),\n            fc4=F.Linear(16384, 4096),\n            fc5=F.Linear(4096, 2),\n        )\n        self.train = True\n\n    def __call__(self, x, t):\n    \t\"\"\"\n    \t    forword\u51e6\u7406\n\t    \"\"\"\n        h = F.max_pooling_2d(F.relu(self.conv1(x)), 3, stride=2)\n        h = F.max_pooling_2d(F.relu(self.conv2(h)), 3, stride=2)\n        h = F.relu(self.conv3(h))\n        h = F.dropout(F.relu(self.fc4(h)), ratio=0.5, train=self.train)\n        h = self.fc5(h)\n\n        self.loss = F.softmax_cross_entropy(h, t)\n        self.accuracy = F.accuracy(h, t)\n\n        if self.train:\n            return self.loss\n        else:\n            self.pred = F.softmax(h)\n            return self.pred\n```\n\n\n## 4. \u30e2\u30c7\u30eb\u3092\u5b66\u7fd2\u3059\u308b\n3.\u306e\u30b3\u30fc\u30c9\u3092\u3082\u3068\u306b\u3001\u30e2\u30c7\u30eb\u3092\u5b66\u7fd2\u3055\u305b\u308b\u30b3\u30fc\u30c9\u3092\u66f8\u304d\u307e\u3059\u3002\n\u4eca\u56de\u306f\u6bd4\u8f03\u7684\u3059\u3050\u306b\u5b66\u7fd2\u304c\u7d42\u308f\u308a\u307e\u3059\u304c\u3001\u3082\u3063\u3068\u5927\u898f\u6a21\u306a\u30c7\u30fc\u30bf\u30bb\u30c3\u30c8\u3092\u6271\u304a\u3046\u3068\u3057\u305f\u6642\u306f\u3001\u5b66\u7fd2\u306e\u9032\u6357\u3092\u8868\u793a\u3059\u308b\u306e\u304c\u7cbe\u795e\u885b\u751f\u4e0a\u826f\u3044\u3067\u3059\u3002\n\n```py:train.py\n# -*- coding: utf-8 -*-\n\nimport argparse\nimport os\nimport six\nimport chainer\nimport chainer.functions as F\nimport chainer.links as L\nimport numpy as np\nfrom chainer import optimizers\nfrom chainer import cuda\nfrom chainer import serializers\nfrom chainer import Variable\nfrom progressbar import ProgressBar\n\n\nclass YTNet(chainer.Chain):\n\n    def __init__(self):\n        \"\"\"\n            \u30e2\u30c7\u30eb\u306e\u5b9a\u7fa9\n        \"\"\"\n        super(YTNet, self).__init__(\n            conv1=L.Convolution2D(3, 32, 5, stride=1, pad=2),\n            bn1  =L.BatchNormalization(32),\n            conv2=L.Convolution2D(32, 32, 5, stride=1, pad=2),\n            bn2  =L.BatchNormalization(32),\n            conv3=L.Convolution2D(32, 64, 5, stride=1, pad=2),\n            fc4=F.Linear(16384, 4096),\n            fc5=F.Linear(4096, 2),\n        )\n        self.train = True\n\n    def __call__(self, x, t):\n        \"\"\"\n            forword\u51e6\u7406\n        \"\"\"\n        h = F.max_pooling_2d(F.relu(self.conv1(x)), 3, stride=2)\n        h = F.max_pooling_2d(F.relu(self.conv2(h)), 3, stride=2)\n        h = F.relu(self.conv3(h))\n        h = F.dropout(F.relu(self.fc4(h)), ratio=0.5, train=self.train)\n        h = self.fc5(h)\n\n        self.loss = F.softmax_cross_entropy(h, t)\n        self.accuracy = F.accuracy(h, t)\n\n        if self.train:\n            return self.loss\n        else:\n            self.pred = F.softmax(h)\n            return self.pred\n\ndef one_epoch(args, model, optimizer, data, label, epoch, train):\n    \"\"\"\n        1epoch\u306e\u30c8\u30ec\u30fc\u30cb\u30f3\u30b0\u3001\u3082\u3057\u304f\u306f\u8a55\u4fa1\u51e6\u7406\u3092\u884c\u3046\n    \"\"\"\n    model.train = train\n    xp = cuda.cupy if args.gpu >= 0 else np\n\n    sum_accuracy = 0\n    sum_loss = 0\n\n    p = ProgressBar(min_value=0, max_value=data.shape[0]) # \u9032\u6357\u78ba\u8a8d\u7528\n    perm = np.random.permutation(data.shape[0])\n    for i in xrange(0, data.shape[0], args.batchsize):\n        p.update(i)\n        \n        # minibatch\u3092\u4f5c\u6210\n        target = perm[i:i + args.batchsize]\n        x = xp.array(data[target], dtype=xp.float32)\n        t = xp.array(label[target], dtype=xp.int32)\n\n        # Variable\u3092\u4f5c\u6210\n        volatile = 'off' if train else 'on'\n        x = Variable(x, volatile=volatile)\n        t = Variable(t, volatile=volatile)\n\n        # \u30d1\u30e9\u30e1\u30fc\u30bf\u66f4\u65b0\u3001\u3082\u3057\u304f\u306f\u30e9\u30d9\u30eb\u4e88\u6e2c\n        if train:\n            optimizer.update(model, x, t)\n        else:\n            pred = model(x, t).data\n        \n        sum_loss += float(model.loss.data) * t.data.shape[0]\n        sum_accuracy += float(model.accuracy.data) * t.data.shape[0]\n\n        del x, t\n\n    print \"\" # \u6539\u884c\u7528\n    if train:\n        print \"train epoch \" + str(epoch)\n        print \"   train loss : \" + str(sum_loss / data.shape[0])\n        print \"   train acc  : \" + str(sum_accuracy / data.shape[0])\n    else:\n        print \"test epoch \" + str(epoch)\n        print \"   test loss : \" + str(sum_loss / data.shape[0])\n        print \"   test acc  : \" + str(sum_accuracy / data.shape[0])\n\ndef load_dataset(datadir):\n    \"\"\"\n        \u30c7\u30fc\u30bf\u30bb\u30c3\u30c8\u3092\u30ed\u30fc\u30c9\u3059\u308b\n    \"\"\"\n    train_data = np.load('%s/train_data.npy' % datadir)\n    train_labels = np.load('%s/train_label.npy' % datadir)\n    test_data = np.load('%s/test_data.npy' % datadir)\n    test_labels = np.load('%s/test_label.npy' % datadir)\n\n    return train_data, train_labels, test_data, test_labels\n\nif __name__ == '__main__':\n    parser = argparse.ArgumentParser()\n    parser.add_argument(\"--gpu\", type=int, default=-1)\n    parser.add_argument(\"--batchsize\", type=int, default=10)\n    parser.add_argument('--data_dir', type=str, default='dataset')\n    parser.add_argument('--output_dir', type=str, default='result')\n    args = parser.parse_args()\n\n    # model,optimizer\u4f5c\u6210\n    model = YTNet()\n    optimizer = optimizers.Adam(alpha=0.00005)\n    optimizer.setup(model)\n\n    # \u30c7\u30fc\u30bf\u30bb\u30c3\u30c8\u30ed\u30fc\u30c9\n    dataset = load_dataset(args.data_dir)\n    tr_data, tr_labels, te_data, te_labels = dataset\n\n    # \u30e1\u30a4\u30f3\u30eb\u30fc\u30d7\n    for epoch in range(1, 20):\n        # \u8a13\u7df4\n        one_epoch(args, model, optimizer, tr_data, tr_labels, epoch, True)\n        # \u8a55\u4fa1\n        one_epoch(args, model, optimizer, te_data, te_labels, epoch, False)\n\n    # \u30e2\u30c7\u30eb\u306e\u4fdd\u5b58\n    if not os.path.exists(args.output_dir):\n        os.makedirs(args.output_dir)\n    serializers.save_npz(args.output_dir + \"YTNet.chainermodel\", model)\n    serializers.save_npz(args.output_dir + \"YTNet.state\", optimizer)\n```\n\n20epoch\u307b\u3069\u5b66\u7fd2\u3055\u305b\u308b\u3068\u8a13\u7df4\u30c7\u30fc\u30bf\u3067\u306eAccuracy\u304c99%\u3092\u8d85\u3048\u30b5\u30c1\u3063\u3066\u3044\u307e\u3057\u305f\u3002\n\n\n## 5. \u6027\u80fd\u3092\u8a55\u4fa1\u3059\u308b\n\u3044\u3088\u3044\u3088\u3001\u6027\u80fd\u306e\u8a55\u4fa1\u3092\u3057\u307e\u3059\u3002\n\u4ee5\u4e0b\u306e10\u679a\u306e\u753b\u50cf\u3092\u4f7f\u3063\u3066\u30c6\u30b9\u30c8\u3057\u307e\u3059\u3002\u3053\u306e\u4e2d\u306e5\u679a\u304c@eve_yk\u30675\u679a\u304c\u30b9\u30fc\u30d1\u30fc\u30de\u30e9\u30c9\u30fc\u30ca\u7530\u4e2d\u3055\u3093\u3067\u3059\u3002\n\u9854\u306e\u30b5\u30f3\u30d7\u30eb\u306f[\u524d\u56de\u306e\u8a18\u4e8b](http://qiita.com/eve_yk/items/e0ccd7917237fed1607f)\u306b\u3042\u308b\u306e\u3067\u3001\u5f53\u3066\u3089\u308c\u308b\u304b\u307f\u306a\u3055\u3093\u3082\u6311\u6226\u3057\u3066\u307f\u3066\u304f\u3060\u3055\u3044\u3002\n\n![test.JPG](https://qiita-image-store.s3.amazonaws.com/0/110468/73942355-6da2-abf7-8947-e8f099236f79.jpeg)\n\n\u5c11\u3057\u60a9\u307f\u307e\u3059\u304c\u3001\u4eba\u306e\u76ee\u3067\u898b\u308c\u3070\u308f\u304b\u308a\u307e\u3059\u306d\u3002\u773c\u93e1\u306e\u8272\u3068\u304b\u9055\u3044\u307e\u3059\u3002\n\u6b63\u89e3\u306f\u30011,2,4,7,10\u304ceve_yk\u30013,5,6,8,9\u304c\u7530\u4e2d\u3055\u3093\u3067\u3059\u3002\n\n\u3055\u3066\u3001\u4eca\u56de\u5b66\u7fd2\u3057\u305fCNN\u3067\u306f\u3069\u3046\u3067\u3057\u3087\u3046\u304b\uff1f\n\u4ee5\u4e0b\u306e\u30b3\u30fc\u30c9\u3067\u30c6\u30b9\u30c8\u3057\u307e\u3059\u3002\n\n```py:test.py\n# coding:utf-8\n\nimport os\nimport sys\nimport argparse\nimport glob\nimport cv2\nimport numpy as np\nfrom chainer import Variable\nfrom chainer import serializers\nfrom train import YTNet\n\ndef transpose_opencv2chainer(x):\n\t\"\"\"\n\t\topencv\u306enpy\u5f62\u5f0f\u304b\u3089chainer\u306enpy\u5f62\u5f0f\u306b\u5909\u63db\n\t\topencv  => (height, width, channel)\n\t\tchainer => (channel, height, width)\n\t\"\"\"\n\treturn x.transpose(2,0,1)\n\nfile2labels = {\"01.jpg\":\"eve_yk\", \"02.jpg\":\"eve_yk\", \"03.jpg\":\"tanaka\",\n\t\t\t   \"04.jpg\":\"eve_yk\", \"05.jpg\":\"tanaka\", \"06.jpg\":\"tanaka\",\n\t\t\t   \"07.jpg\":\"eve_yk\", \"08.jpg\":\"tanaka\", \"09.jpg\":\"tanaka\",\n\t\t\t   \"10.jpg\":\"eve_yk\"}\n\n\nif __name__ == \"__main__\":\n\tparser = argparse.ArgumentParser(description='CNN\u7528\u30c7\u30fc\u30bf\u30bb\u30c3\u30c8\u4f5c\u6210')\n\tparser.add_argument('--input_path',   required=True, type=str)\n\tparser.add_argument('--model_path',  required=True, type=str)\n\targs = parser.parse_args()\n\n\t# jpg\u30d5\u30a1\u30a4\u30eb\u4e00\u89a7\u53d6\u5f97\n\ttest_files  = glob.glob(args.input_path+\"/*.jpg\")\n\n\t# \u30e2\u30c7\u30eb\u306e\u30ed\u30fc\u30c9\n\tmodel = YTNet()\n\tmodel = serializers.load_npz(args.model_path, , model)\n\n\t# \u4e00\u679a\u305a\u3064\u8a55\u4fa1\n\tcollect_count = 0.0\n        test_count = 0.0\n\tfor file_path in test_files:\n\t\timage = cv2.imread(file_path)\n\t\tif image is None:\n\t\t\t# \u8aad\u307f\u8fbc\u307f\u5931\u6557\n\t\t\tcontinue\n                test_count += 1.0\n\n\t\t# \u30c7\u30a3\u30ec\u30af\u30c8\u30ea\u69cb\u9020\u304b\u3089\u30d5\u30a1\u30a4\u30eb\u540d\u3092\u53d6\u5f97\n\t\tfile_name = file_path.split(\"/\")[-1]\n                print file_name+\"(\"+file2labels[file_name]+\") :\",\n\n\t\t# chainer\u7528\u5f62\u5f0f\u306b\u5909\u63db\n\t\timage = transpose_opencv2chainer(image)\n\t\tx = Variable(np.asarray([image], dtype=np.float32), volatile=\"on\")\n\t\tt = Variable(np.asarray([[0]], dtype=np.int32), volatile=\"on\")\n\n\t\t# \u8a55\u4fa1\n\t\tpred = model(x, t).data\n\t\tif int(pred) == 0: # tanaka\n\t\t\tprint u\"\u8b58\u5225\u7d50\u679c\u300ctanaka\u300d\"\n\t\t\tif file2labels[file_name] == u\"tanaka\":\n\t\t\t\tcollect_count += 1.0\n\t\telse: # eve_yk\n\t\t\tprint u\"\u8b58\u5225\u7d50\u679c\u300ceve_yk\u300d\"\n\t\t\tif file2labels[file_name] == u\"eve_yk\":\n\t\t\t\tcollect_count += 1.0\t\n\n\tprint u\"total:{}%\".format(collect_count/test_count*100)\n```\n\n\n\n\u7d50\u679c\u306f\u3053\u306e\u901a\u308a\n```\npython test.py --input_path test/ --model_path result/YTNet.chainermodel\n08.jpg(tanaka) : \u8b58\u5225\u7d50\u679c\u300ctanaka\u300d\n09.jpg(tanaka) : \u8b58\u5225\u7d50\u679c\u300ceve_yk\u300d\n07.jpg(eve_yk) : \u8b58\u5225\u7d50\u679c\u300ceve_yk\u300d\n01.jpg(eve_yk) : \u8b58\u5225\u7d50\u679c\u300ceve_yk\u300d\n03.jpg(tanaka) : \u8b58\u5225\u7d50\u679c\u300ctanaka\u300d\n06.jpg(tanaka) : \u8b58\u5225\u7d50\u679c\u300ceve_yk\u300d\n02.jpg(eve_yk) : \u8b58\u5225\u7d50\u679c\u300ceve_yk\u300d\n05.jpg(tanaka) : \u8b58\u5225\u7d50\u679c\u300ctanaka\u300d\n04.jpg(eve_yk) : \u8b58\u5225\u7d50\u679c\u300ceve_yk\u300d\n10.jpg(eve_yk) : \u8b58\u5225\u7d50\u679c\u300ceve_yk\u300d\ntotal:8.0/10\n```\n\n6\u30689\u306e\u7530\u4e2d\u3055\u3093\u3092eve_yk\u3068\u9593\u9055\u3048\u3066\u3057\u307e\u3044\u307e\u3057\u305f\u3002\n\u8a13\u7df4\u30c7\u30fc\u30bf\u306e\u91cf\u306e\u9055\u3044\u304b\u3089\u3001\u504f\u3063\u305f\u4e88\u6e2c\u3092\u3057\u3066\u3057\u307e\u3046\u306e\u3067\u3057\u3087\u3046\u304b\u3002\n\u3057\u304b\u3057\u3001\u4eba\u306e\u76ee\u3067\u898b\u3066\u3082\u60a9\u3080\u753b\u50cf\u3092\u8aa4\u3063\u3066\u3044\u308b\u6c17\u304c\u3057\u307e\u3059\u3002\u3084\u306f\u308a\u3001\u4e2d\u9014\u534a\u7aef\u306a\u30b7\u30b9\u30c6\u30e0\u3067\u30c9\u30c3\u30da\u30eb\u30b2\u30f3\u30ac\u30fc\u3092\u898b\u5206\u3051\u308b\u306e\u306f\u96e3\u3057\u3044\u3088\u3046\u3067\u3059\u3002\n\n## \u304a\u308f\u308a\u306b\n\u81ea\u5206\u306e\u305d\u3063\u304f\u308a\u3055\u3093\u3092\u8b58\u5225\u3059\u308b\u9854\u5206\u985e\u5668\u3092\u4f5c\u6210\u3057\u307e\u3057\u305f\u3002\n\u7cbe\u5ea6\u306f\u307e\u3041\u307e\u3041\u3068\u3044\u3063\u305f\u3068\u3053\u308d\u3002\u30c7\u30fc\u30bf\u6570\u3084\u524d\u51e6\u7406\u306a\u3069\u3001\u59a5\u5354\u3057\u305f\u3068\u3053\u308d\u304c\u591a\u304f\u3042\u3063\u305f\u4e2d\u3067\u306f\u826f\u304b\u3063\u305f\u65b9\u304b\u3068\u601d\u3044\u307e\u3059\u3002\n\u9811\u5f35\u3063\u3066\u30c7\u30fc\u30bf\u3092\u96c6\u3081\u3066\u3082\u3063\u3068\u591a\u4eba\u6570\u306e\u5206\u985e\u3092\u3057\u305f\u308a\u3001\u524d\u51e6\u7406\u306a\u3069\u3092\u9811\u5f35\u3063\u3066\u7cbe\u5ea6\u5411\u4e0a\u306b\u30c1\u30e3\u30ec\u30f3\u30b8\u3059\u308b\u3068\u9762\u767d\u305d\u3046\u3067\u3059\u306d\uff01\n\nLiaro\u3001eve_yk\u306f\u30b9\u30fc\u30d1\u30fc\u30de\u30e9\u30c9\u30fc\u30ca\u3092\u5fdc\u63f4\u3057\u3066\u3044\u307e\u3059\uff01\n\n## \u53c2\u8003\n[https://github.com/mitmul/chainer-cifar10](https://github.com/mitmul/chainer-cifar10)\n\n[\u5409\u672c\u8208\u696d\u682a\u5f0f\u4f1a\u793e \u82b8\u4eba\u30d7\u30ed\u30d5\u30a3\u30fc\u30eb | \u30b9\u30fc\u30d1\u30fc\u30de\u30e9\u30c9\u30fc\u30ca](http://search.yoshimoto.co.jp/talent_prf/?id=387)\n", "tags": ["Python", "Chainer", "\u6a5f\u68b0\u5b66\u7fd2", "DeepLearning", "\u753b\u50cf\u8a8d\u8b58"]}