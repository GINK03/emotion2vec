{"context": " More than 1 year has passed since last update.CentOS\u3067Hadoop\u3068Hive\u3092\u8a66\u3057\u3066\u307f\u308b\u306e\u7d9a\u304d\u3002\n\u3088\u304f\u3001Spark\u304cHadoop\u306e\u6a5f\u80fd\u306e\uff11\u3064\u307f\u305f\u3044\u306b\u7d39\u4ecb\u3055\u308c\u3066\u3044\u308b\u304c\u3001\u5168\u304f\u9055\u3046\u3082\u306e\u3002\u3069\u3061\u3089\u304b\u3068\u3044\u3046\u3068scala\u306e\u62e1\u5f35\u6a5f\u80fd\u3068\u8003\u3048\u305f\u65b9\u304c\u8fd1\u3044\u304b\u3002\u3082\u3061\u308d\u3093\u3001Hadoop\u306e\u51e6\u7406\u7d50\u679c\u3092HDFS\u7d4c\u7531\u3067\u5229\u7528\u306f\u3067\u304d\u307e\u3059\u3002\n\n\u30a4\u30f3\u30b9\u30c8\u30fc\u30eb\n\nscala\n\u307e\u305a\u306fScala\u306e\u30a4\u30f3\u30b9\u30c8\u30fc\u30eb\u304b\u3089\u3002\nwget http://downloads.typesafe.com/scala/2.11.7/scala-2.11.7.tgz\ntar zxfv scala-2.11.7.tgz\nmv scala-2.11.7 /usr/\n\n\nspark\nwget http://ftp.riken.jp/net/apache/spark/spark-1.5.2/spark-1.5.2-bin-hadoop2.6.tgz\ntar zxfv spark-1.5.2\nmv spark-1.5.2 /usr/\n\n\nSCALA_HOME,SPARK_HOME,PATH\u306e\u8a2d\u5b9a\n.bashrc\u306b\u4e0b\u8a18\u3092\u66f8\u304f\u3002\nexport SCALA_HOME=/usr/scala-2.11.7\nexport SPARK_HOME=/usr/spark-1.5.2\nexport PATH=$SCALA_HOME/bin:$PATH\n\nspark\uff08\u30b3\u30f3\u30bd\u30fc\u30eb\uff09\u306e\u8d77\u52d5\ncd $SPARK_HOME\nbin/spark-shell\n.\n.\n.\nscala>\n\n\u3068\u306a\u308c\u3070\u3001\u4e00\u5fdc\u52d5\u3044\u3066\u3044\u308b\u3002\n\u30a4\u30f3\u30bf\u30e9\u30af\u30c6\u30a3\u30d6\u30b7\u30a7\u30eb\u3092\u629c\u3051\u308b\u306b\u306f\u3001\nscala> :q\n\n\u3068\u3059\u308b\u3002\n\nsacla> :quite\u3067\u3082\u3088\u3044\u3002\n\n\nHadoop\u3068\u306e\u9023\u643a\uff1f\n\u4f55\u3082Hadoop\u3068\u9023\u643a\u3057\u306a\u3051\u308c\u3070\u3044\u3051\u306a\u3044\u3082\u306e\u3067\u3082\u7121\u3044\u304c\u3001HDFS\u4e0a\u306e\u30d5\u30a1\u30a4\u30eb\u3092\u51e6\u7406\u3057\u3066\u307f\u308b\u3002\n\u30d5\u30a1\u30a4\u30eb\u3068\u3057\u3066\u306f\u3001\u524d\u306bHive\u3067\u751f\u6210\u3057\u305f\u30d5\u30a1\u30a4\u30eb\uff08/outpu/000000_0)\u3092\u5229\u7528\u3057\u3066\u307f\u308b\u3002\nscala> val hdfs_file = sc.textFile(\"hdfs://127.0.0.1:9000/output/000000_0\")\n\nscala> hdfs_file.count()\nres4: Long = 5\n\nscala> hdfs_file.filter(line => line.contains(\"\u65b0\")).foreach(println)\n\u65b0\u6a4b\u5e97100\n\u65b0\u5bbf\u5e97340\n\n\nSpark SQL\nSpark\u3067\u306f\u6a19\u6e96\uff1f\u3067SQL\u30a4\u30f3\u30bf\u30fc\u30d5\u30a7\u30fc\u30b9\u3092\u5229\u7528\u3059\u308b\u3053\u3068\u3082\u3067\u304d\u308b\u3002\n\u4ee5\u4e0b\u306e\u4f8b\u3067\u306f\u3001\n\u65b0\u6a4b\u5e97,100\n\u65b0\u5bbf\u5e97,340\n\u6c60\u888b\u5e97,874\n\u6e0b\u8c37\u5e97,400\n\n\u3068\u3044\u3046\u5185\u5bb9\u306e/root/data.csv\u30d5\u30a1\u30a4\u30eb\u304c\u3042\u308b\u3053\u3068\u3092\u524d\u63d0\u3068\u3057\u305f\u64cd\u4f5c\u3002\ncd $SPARK_HOME\nbin/spark-sql\n\nspark-sql>\nspark-sql> show databases;\nspark-sql> create database testdb;\n\ncreate table sales(shop string,sales int)\nrow format delimited fields terminated by ','\nstored as textfile;\n\nload data local inpath \"/root/data.csv\" into table sales;\n\nselect * from sales where shop like '\u65b0%';\n\n\u306a\u305c\u304b\u3001\u4e0a\u8a18data.csv\u30d5\u30a1\u30a4\u30eb\u3092HDFS\u30b3\u30d4\u30fc\u3057\u3066\u3001\nload data inpath \u201c/input/data.csv\" into table sales;\n\n\u3068\u3059\u308b\u3068\u3001\n15/11/17 04:01:37 INFO ParseDriver: Parsing command: load data inpath \u201c/input/data.csv\" into table sales\nMismatchedTokenException(15!=313)\n    at org.antlr.runtime.BaseRecognizer.recoverFromMismatchedToken(BaseRecognizer.java:617)\n.\n.\n\n\n\u3068\u3044\u3063\u305f\u30a8\u30e9\u30fc\u306b\u306a\u308b\u3002\u3053\u308c\u306b\u3064\u3044\u3066\u306f\u3001\u5f15\u304d\u7d9a\u304d\u8abf\u67fb\u3057\u307e\u3059\u3002\u305f\u3076\u3093\u521d\u6b69\u7684\u306a\u4f55\u304b\u3002\n\nCentOS\u3067Hadoop\u3068Hive\u3092\u8a66\u3057\u3066\u307f\u308b\u306e\u7d9a\u304d\u3002\n\u3088\u304f\u3001Spark\u304cHadoop\u306e\u6a5f\u80fd\u306e\uff11\u3064\u307f\u305f\u3044\u306b\u7d39\u4ecb\u3055\u308c\u3066\u3044\u308b\u304c\u3001\u5168\u304f\u9055\u3046\u3082\u306e\u3002\u3069\u3061\u3089\u304b\u3068\u3044\u3046\u3068scala\u306e\u62e1\u5f35\u6a5f\u80fd\u3068\u8003\u3048\u305f\u65b9\u304c\u8fd1\u3044\u304b\u3002\u3082\u3061\u308d\u3093\u3001Hadoop\u306e\u51e6\u7406\u7d50\u679c\u3092HDFS\u7d4c\u7531\u3067\u5229\u7528\u306f\u3067\u304d\u307e\u3059\u3002\n\n##\u30a4\u30f3\u30b9\u30c8\u30fc\u30eb\n\n###scala\n\n\u307e\u305a\u306fScala\u306e\u30a4\u30f3\u30b9\u30c8\u30fc\u30eb\u304b\u3089\u3002\n\n```bash\nwget http://downloads.typesafe.com/scala/2.11.7/scala-2.11.7.tgz\ntar zxfv scala-2.11.7.tgz\nmv scala-2.11.7 /usr/\n```\n\n###spark\n\n```bash\nwget http://ftp.riken.jp/net/apache/spark/spark-1.5.2/spark-1.5.2-bin-hadoop2.6.tgz\ntar zxfv spark-1.5.2\nmv spark-1.5.2 /usr/\n```\n\n###SCALA_HOME,SPARK_HOME,PATH\u306e\u8a2d\u5b9a\n\n.bashrc\u306b\u4e0b\u8a18\u3092\u66f8\u304f\u3002\n\n```bash\nexport SCALA_HOME=/usr/scala-2.11.7\nexport SPARK_HOME=/usr/spark-1.5.2\nexport PATH=$SCALA_HOME/bin:$PATH\n```\n\nspark\uff08\u30b3\u30f3\u30bd\u30fc\u30eb\uff09\u306e\u8d77\u52d5\n\n```bash\ncd $SPARK_HOME\nbin/spark-shell\n.\n.\n.\nscala>\n```\n\u3068\u306a\u308c\u3070\u3001\u4e00\u5fdc\u52d5\u3044\u3066\u3044\u308b\u3002\n\u30a4\u30f3\u30bf\u30e9\u30af\u30c6\u30a3\u30d6\u30b7\u30a7\u30eb\u3092\u629c\u3051\u308b\u306b\u306f\u3001\n\n```bash\nscala> :q\n```\n\u3068\u3059\u308b\u3002\n>sacla> :quite\u3067\u3082\u3088\u3044\u3002\n\n\n\n##Hadoop\u3068\u306e\u9023\u643a\uff1f\n\n\u4f55\u3082Hadoop\u3068\u9023\u643a\u3057\u306a\u3051\u308c\u3070\u3044\u3051\u306a\u3044\u3082\u306e\u3067\u3082\u7121\u3044\u304c\u3001HDFS\u4e0a\u306e\u30d5\u30a1\u30a4\u30eb\u3092\u51e6\u7406\u3057\u3066\u307f\u308b\u3002\n\u30d5\u30a1\u30a4\u30eb\u3068\u3057\u3066\u306f\u3001\u524d\u306bHive\u3067\u751f\u6210\u3057\u305f\u30d5\u30a1\u30a4\u30eb\uff08/outpu/000000_0)\u3092\u5229\u7528\u3057\u3066\u307f\u308b\u3002\n\n```bash\nscala> val hdfs_file = sc.textFile(\"hdfs://127.0.0.1:9000/output/000000_0\")\n\nscala> hdfs_file.count()\nres4: Long = 5\n\nscala> hdfs_file.filter(line => line.contains(\"\u65b0\")).foreach(println)\n\u65b0\u6a4b\u5e97100\n\u65b0\u5bbf\u5e97340\n```\n\n###Spark SQL\n\nSpark\u3067\u306f\u6a19\u6e96\uff1f\u3067SQL\u30a4\u30f3\u30bf\u30fc\u30d5\u30a7\u30fc\u30b9\u3092\u5229\u7528\u3059\u308b\u3053\u3068\u3082\u3067\u304d\u308b\u3002\n\u4ee5\u4e0b\u306e\u4f8b\u3067\u306f\u3001\n\n```text\n\u65b0\u6a4b\u5e97,100\n\u65b0\u5bbf\u5e97,340\n\u6c60\u888b\u5e97,874\n\u6e0b\u8c37\u5e97,400\n```\n\n\u3068\u3044\u3046\u5185\u5bb9\u306e/root/data.csv\u30d5\u30a1\u30a4\u30eb\u304c\u3042\u308b\u3053\u3068\u3092\u524d\u63d0\u3068\u3057\u305f\u64cd\u4f5c\u3002\n\n```bash\ncd $SPARK_HOME\nbin/spark-sql\n\nspark-sql>\nspark-sql> show databases;\nspark-sql> create database testdb;\n\ncreate table sales(shop string,sales int)\nrow format delimited fields terminated by ','\nstored as textfile;\n\nload data local inpath \"/root/data.csv\" into table sales;\n\nselect * from sales where shop like '\u65b0%';\n```\n\u306a\u305c\u304b\u3001\u4e0a\u8a18data.csv\u30d5\u30a1\u30a4\u30eb\u3092HDFS\u30b3\u30d4\u30fc\u3057\u3066\u3001\n\n```bash\nload data inpath \u201c/input/data.csv\" into table sales;\n```\n\u3068\u3059\u308b\u3068\u3001\n\n```bash\n15/11/17 04:01:37 INFO ParseDriver: Parsing command: load data inpath \u201c/input/data.csv\" into table sales\nMismatchedTokenException(15!=313)\n\tat org.antlr.runtime.BaseRecognizer.recoverFromMismatchedToken(BaseRecognizer.java:617)\n.\n.\n\n```\n\u3068\u3044\u3063\u305f\u30a8\u30e9\u30fc\u306b\u306a\u308b\u3002\u3053\u308c\u306b\u3064\u3044\u3066\u306f\u3001\u5f15\u304d\u7d9a\u304d\u8abf\u67fb\u3057\u307e\u3059\u3002\u305f\u3076\u3093\u521d\u6b69\u7684\u306a\u4f55\u304b\u3002\n", "tags": ["Spark"]}