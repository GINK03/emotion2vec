{"tags": ["Python", "pandas", "matplotlib"], "context": "\n\u74b0\u5883\n\n\nwin10 64bit\nPython 3.5.2 \nAnaconda 4.1.1 (64-bit)\n\n\n\u8457\u66f8\n\n\nPython for Data Analysis( by Wes McKinney )(Final Release Date: October 2012 )\n\n\n\u30c7\u30fc\u30bf\n\n\nhttps://github.com/wesm/pydata-book\n\n\n\n# %load ipython_log.py\n# IPython log file\nimport matplotlib.pyplot as plt\nimport numpy as np\nimport pandas as pd\n\n\n# __\u307e\u305a\u306f1\u30d5\u30a1\u30a4\u30eb\u3092\u30d5\u30ec\u30fc\u30e0\u306b\u53d6\u308a\u8fbc\u3093\u3067\u307f\u308b__________________________\nnames1880=pd.read_csv('yob1880.txt',names=['name', 'sex', 'births'])\nnames1880.groupby('sex').births.sum()\n\n\n# __\u3059\u3079\u3066\u306eyob\uff85\uff9d\uff84\uff76.txt\u30921\u3064\u306e\u30d5\u30ec\u30fc\u30e0\u306b\u53d6\u308a\u5165\u308c\u305f\u3044\u3068\u304d__________________________\npieces=[]\ncolumns=['name', 'sex', 'births']\nyears=range(1880,2011)\nfor year in years:\n    path='yob%d.txt' % year\n    frame=pd.read_csv(path,names=columns)\n    frame['year']=year\n    pieces.append(frame)\n    names=pd.concat(pieces,ignore_index=True)   #\u30a4\u30f3\u30c7\u30c3\u30af\u30b9\u3092\u7121\u8996\u3059\u308bTrue\u306b\u3059\u308b\u3068text\u5de6\u5217\u306e\u30a4\u30f3\u30c7\u30c3\u30af\u30b9\u3092\u9069\u5f53\u306b\u5909\u3048\u3066\u304f\u308c\u308b\n                     #1690783\u884c\u306e\u5de8\u5927\u306a\u30d5\u30ec\u30fc\u30e0\u304c\u51fa\u6765\u4e0a\u304c\u308b\u3002\u305d\u308c\u3067\u3082\u691c\u7d22\u306f\u9ad8\u901f\n\n\n# __\u51fa\u751f\u6570\u306e\u63a8\u79fb__________________________\ntotal_births=names.pivot_table(names, index='year', columns='sex', aggfunc=sum)\n'''\n\u672c\u3067\u306f\n total_births = names.pivot_table('births', rows='year',cols='sex', aggfunc=sum)\n \u306e\u3088\u3046\u306b\u3042\u308b\u304c\u3001\u3053\u308c\u306f\u53e4\u3044\n rows=>index\n cols=>columns\n \u306b\u5909\u66f4\u3055\u308c\u3001\n \u7b2c\u4e00\u5f15\u6570\u306b\u30c7\u30fc\u30bf\u30d5\u30ec\u30fc\u30e0\u5165\u308c\u306a\u3044\u3068\u3044\u3051\u306a\u3044\n (\u7b2c\u4e8c\u5f15\u6570\u306b'birth'\u5165\u308c\u306a\u304d\u3083\u3068\u601d\u3063\u305f\u3051\u3069\u306f\u3058\u304b\u308c\u305f\u30fb\u30fb\u30fb\uff1f)\n'''\ntotal_births.tail()\ntotal_births.plot(title='Total births by sex and year')\n'''prop \u306b\u3088\u3063\u3066\u5168\u51fa\u751f\u6570\u306b\u5bfe\u3059\u308b\u5404\u540d\u524d\u306e\u51fa\u751f\u6570\u3092\u306f\u3058\u304d\u51fa\u3057\u3066\u307f\u308b'''\n# data\u3092year,sex\u3067\u30b0\u30eb\u30fc\u30d7\u5316\u3057\u3001\u65b0\u3057\u3044\u5217\u306b\u5165\u308c\u308b\n\n\n\n\n\ndef add_prop(group):\n    '''\u5404\u540d\u524d\u306e\u51fa\u751f\u6570\u306e\u3001\u5168\u51fa\u751f\u6570\u306b\u5bfe\u3059\u308b\u5272\u5408\u3092\u51fa\u3057\u3066\u3001group\u306b\u5217\u3092\u8ffd\u52a0'''\n    births = group.births.astype(float)   # Integer division floors\n    group['prop'] = births / births.sum()   #prop\u3068\u3044\u3046column\u306b\u7d50\u679c\u3092\u8ffd\u52a0\n    return group\n\nnames = names.groupby(['year', 'sex']).apply(add_prop)\n\nnp.allclose(names.groupby(['year','sex']).prop.sum(),1)   # prop\u3092\u3059\u3079\u3066\u8db3\u3059\u30681(100%)\u306b\u306a\u308b\u3053\u3068\u3092\u78ba\u8a8d\n    # allclose \u306b\u3088\u3063\u3066\u30c1\u30a7\u30c3\u30af\u3059\u308b\u3000names.groupby(['year','sex']).prop.sum()\u30681\u304c\u7b49\u3057\u3044\u304b\u78ba\u8a8d\n\n\n\n\n\n\n\n\n\n\n#__Analyzing Naming Trends__________________________ \ndef get_top1000(group):\n    '''\n    top1000\u306e\u540d\u524d\u3092\u5404sex/year \u304b\u3089\u629c\u304d\u51fa\u3059\u3002\u5225\u306e\u30b0\u30eb\u30fc\u30d7\u4f5c\u308b\n    <\u65e7\u5f62\u5f0f>\n    return group.sort_index(by='births', ascending=False)[:1000]\n    '''\n    return group.sort_values(by='births', ascending=False)[:1000]\n\ngrouped=names.groupby(['year','sex'])\ntop1000=grouped.apply(get_top1000)\n'''\n__top1000 Another Way__________________________ \npieces = []\nfor year, group in names.groupby(['year', 'sex']):\n    pieces.append(group.sort_index(by='births', ascending=False)[:1000])\ntop1000 = pd.concat(pieces, ignore_index=True)\n'''\n\nboys=top1000[top1000.sex=='M']\ngirls=top1000[top1000.sex=='F']\n\ntotal_births=top1000.pivot_table('births',index='year',columns='name',aggfunc=sum)   #data munging(\u30c7\u30fc\u30bf\u5909\u63db)\u3092\u884c\u3046\u3079\u304fpivot table\u3067\u76f4\u3059\nsubset=total_births[['John', 'Harry', 'Mary', 'Marilyn']]\nsubset.plot(subplots=True, figsize=(12,10),grid=False, title=\"Number of births per year\")\n\n\n\n\n\n\n\n\n# __Measuring the increase in naming diversity__________________________\ntable=top1000.pivot_table('prop',index='year',columns='sex',aggfunc=sum)   # \u540d\u524d\u306e\u591a\u69d8\u6027\u3092\u8abf\u3079\u308b\u3079\u304f\u3001\u6bd4\u7387\u3092pivot_table\u306b\u3057\u3066\u307f\u308b\ntable.plot(title='Sum of table1000.prop by year and sex',yticks=np.linspace(0,1.2,13),xticks=range(1880,2020,10))\n\n# __2010\u5e74\u30c7\u30fc\u30bf\u306e\u6bd4\u7387\u3092\u30bd\u30fc\u30c8\u3059\u308b__________________________ \ndf=boys[boys.year==2010]\nprop_cumsum=df.sort_values(by='prop',ascending=False).prop.cumsum()   # \u7d2f\u7a4d\u548ccumulativesum`cumsum`\u4f7f\u3063\u3066\u6bd4\u7387prop=0.5\u306b\u5c4a\u304f\u540d\u524d\u3092\u5f97\u308b\nprop_cumsum[:10]\nprop_cumsum.searchsorted(0.5)   # \u305d\u306e\u969b\u306e\u30a4\u30f3\u30c7\u30c3\u30af\u30b9\u3092searchsorted\u95a2\u6570\u3092\u4f7f\u3063\u3066\u5f97\u3066\u3001\u30bd\u30fc\u30c8\u3055\u308c\u305f\u5217\u306b0.5\u306ecumsum\u3092insert\u3059\u308b\n\n# __1990\u306b\u3082\u540c\u69d8\u306b__________________________\ndf=boys[boys.year==1900]\nin1900=df.sort_values(by='prop',ascending=False).prop.cumsum()\nin1900.searchsorted(0.5)+1\nprop_cumsum[:10]\nprop_cumsum=df.sort_values(by='prop',ascending=False).prop.cumsum()\n\n# __1990, 2010\u5e74\u306b\u3084\u3063\u305f\u3053\u3068\u3092\u5168\u5e74\u6570\u306b\u5bfe\u3057\u3066\u5b9f\u884c__________________________\ndef get_quantile_count(group, q=0.5):\n    '''\n    prop\u30bd\u30fc\u30c8\u3057\u3066\u7d2f\u7a4d\u548c\u3057\u305f\u3082\u306e\u306e0.5\u306e\u30a4\u30f3\u30c7\u30c3\u30af\u30b9\u3092\u8fd4\u3059\n    <\u65e7\u5f62\u5f0f>\n        group = group.sort_index(by='prop', ascending=False)\n        return group.prop.cumsum().searchsorted(q) + 1\n    '''\n    group = group.sort_values(by='prop', ascending=False)\n    return group.prop.cumsum().values.searchsorted(q) + 1   #return group.prop.cumsum().values.searchsorted(q) + 1 \u306b\u66f8\u304d\u63db\u3048 values\u304f\u308f\u308f\u3063\u305f \u5024\u304c\u30a2\u30ec\u30a4\u8868\u793a\u306b\u306a\u3063\u3066\u3057\u307e\u3046\u306e\u3092\u9632\u3050\n\ndiversity=top1000.groupby(['year','sex']).apply(get_quantile_count)\ndiversity=diversity.unstack('sex')   #\u7537\u5973\u5225\n\ndiversity.head()\ndiversity.plot(title=\"Number of popular names in top 50%\")   # \u5973\u6027\u306e\u307b\u3046\u304c\u540d\u524d\u306e\u591a\u69d8\u6027\u304c\u3059\u3079\u3066\u306e\u5e74\u306b\u304a\u3044\u3066\u591a\u3044\u3053\u3068\u304c\u5206\u304b\u308b\n\n\n\n# __The \"Last letter\" Revolution__________________________ \nget_last_letter=lambda x:x[-1]   # name columns\u304b\u3089\u6700\u5f8c\u306e\u6587\u5b57\u5217\u3060\u3051\u629c\u304d\u51fa\u3057\nlast_letters=names.name.map(get_last_letter)   #names\u306e\u540d\u524d\u3059\u3079\u3066\u306b\u6700\u5f8c\u306e\u6587\u5b57\u5217\u629c\u51fa\u5f0f(get_last_letter)\u3092\u9069\u7528\nlast_letters.name='last_letter'\ntable=names.pivot_table('births',index=last_letters,columns=['sex','year'],aggfunc=sum)\n\nsubtable=table.reindex(columns=[1910,1960,2010],level='year')\nsubtable.head()\n\n\nsubtable.sum()   #\u5168\u51fa\u751f\u6570\nletter_prop=subtable/subtable.sum().astype(float)   # \u6587\u5b57\u5217\u6bd4\u7387\u3092\u53d6\u5f97\n\nfig,axes=plt.subplots(2,1,figsize=(10,8))   #2\u6bb5\u306e\u30b5\u30d6\u30d7\u30ed\u30c3\u30c8\u3067\u8868\u793a\nletter_prop['M'].plot(kind='bar',rot=0,ax=axes[0],title='Male')\nletter_prop['F'].plot(kind='bar',rot=0,ax=axes[1],title='Female',legend=False)\n\n#\u7537\u6027\u306e\u540d\u524d\u306e\u6700\u5f8c\u304cn\u3067\u7d42\u308f\u308b\u6bd4\u7387\u304c\u30c0\u30f3\u30c8\u30c4\u306b\u9ad8\u3044\n#\u4ee5\u4e0b\u3067\u5e74\u63a8\u79fbof last 'n' name\u3092\u898b\u3066\u3044\u304f\n\nletter_prop=table/table.sum().astype(float)   #last_letter\u5404\u3005\u306e\u5168\u4f53\u6570\u306b\u5bfe\u3059\u308b\u6bd4\u7387\ndny_ts=letter_prop.ix[['d','n','y'],'M'].T   #d,n,y\u3060\u3051\u30d7\u30ed\u30c3\u30c8\u3057\u3066\u307f\u308b\n                                                                                #'M'\u7537\u6027\u306b\u5bfe\u3057\u3066\u3060\u3051\u3000\n                                                                                # .T\u3067\u30c7\u30fc\u30bf\u30d5\u30ec\u30fc\u30e0\u306e\u8ee2\u7f6e\u884c\u5217\u4f5c\u308b\n# dny_ts.head()\n# dny_ts.plot()\n# plt.show()\n\n\n\n\n\n\n\n\n\n\n\n\n\n#__Boy names that became girl names (and vice versa)__________________________ \nall_names=top1000.name.unique()   #\u5168\u540d\u524d\u5217\u6319\nmask=np.array(['lesl' in x.lower() for x in all_names])   #lower() \u5c0f\u6587\u5b57\u5909\u63db\u30e1\u30bd\u30c3\u30c9\n                                                            #'lesl'\u3068\u3044\u3046\u6587\u5b57\u542b\u3093\u3067\u3044\u305f\u3089True\u8fd4\u3059\n#[In]# mask\n#[Out]# array([False, False, False, ..., False, False, False], dtype=bool)\n\n\n\n\nlesley_like=all_names[mask]   #all_names\u306e\u4e2d\u306e'lesl'\u542b\u3093\u3067\u3044\u308b\u3082\u306e\u3060\u3051lesley_like\u306b\u683c\u7d0d\n#[In]# lesley_like\n#[Out]# array(['Leslie', 'Lesley', 'Leslee', 'Lesli', 'Lesly'], dtype=object)\n\n\n\n\n\nfiltered=top1000[top1000.name.isin(lesley_like)]   #top1000\u306e\u4e2d\u304b\u3089lesley\u307d\u3044\u5974\u3060\u3051\u629c\u304d\u51fa\u3057\n#[In]# filtered\n#[Out]#                     name sex  births  year      prop\n#[Out]# year sex                                            \n#[Out]# 1880 F   654      Leslie   F       8  1880  0.000088\n#[Out]#      M   1108     Leslie   M      79  1880  0.000715\n#[Out]# 1881 F   2523     Leslie   F      11  1881  0.000120\n#[Out]#      M   3072     Leslie   M      92  1881  0.000913\n#[Out]# 1882 F   4593     Leslie   F       9  1882  0.000083\n#[Out]#      M   5081     Leslie   M     122  1882  0.001073\n#[Out]#          5865     Lesley   M       6  1882  0.000053\n#[Out]# 1883 F   6850     Leslie   F       7  1883  0.000062\n#[Out]#      M   7225     Leslie   M     120  1883  0.001147\n#[Out]#          8093     Lesley   M       5  1883  0.000048\n#[Out]# 1884 F   8697     Leslie   F      15  1884  0.000116\n#[Out]#      M   9432     Leslie   M     125  1884  0.001092\n#[Out]# 1885 F   11161    Leslie   F      10  1885  0.000075\n#[Out]#      M   11751    Leslie   M     122  1885  0.001132\n#[Out]# 1886 F   13601    Leslie   F       8  1886  0.000055\n#[Out]#      M   14132    Leslie   M     136  1886  0.001228\n#[Out]# 1887 F   15806    Leslie   F      12  1887  0.000082\n#[Out]#      M   16524    Leslie   M     166  1887  0.001637\n#[Out]# 1888 F   18030    Leslie   F      23  1888  0.000129\n#[Out]#      M   19074    Leslie   M     175  1888  0.001448\n#[Out]# 1889 F   20690    Leslie   F      23  1889  0.000129\n#[Out]#      M   21737    Leslie   M     155  1889  0.001402\n#[Out]# 1890 F   23332    Leslie   F      20  1890  0.000105\n#[Out]#      M   24372    Leslie   M     181  1890  0.001630\n#[Out]# 1891 F   25928    Leslie   F      28  1891  0.000151\n#[Out]#      M   27068    Leslie   M     164  1891  0.001621\n#[Out]# 1892 F   28704    Leslie   F      22  1892  0.000104\n#[Out]#      M   29851    Leslie   M     207  1892  0.001696\n#[Out]# 1893 F   31576    Leslie   F      26  1893  0.000122\n#[Out]#      M   32765    Leslie   M     185  1893  0.001647\n#[Out]# ...                  ...  ..     ...   ...       ...\n#[Out]# 2000 F   1332261  Leslie   F    3619  2000  0.001995\n#[Out]#          1332560   Lesly   F     742  2000  0.000409\n#[Out]#          1332601  Lesley   F     658  2000  0.000363\n#[Out]# 2001 F   1362012  Leslie   F    3610  2001  0.002007\n#[Out]#          1362300   Lesly   F     801  2001  0.000445\n#[Out]#          1362452  Lesley   F     509  2001  0.000283\n#[Out]# 2002 F   1392272  Leslie   F    3520  2002  0.001962\n#[Out]#          1392586   Lesly   F     717  2002  0.000400\n#[Out]#          1392743  Lesley   F     471  2002  0.000262\n#[Out]# 2003 F   1422818  Leslie   F    3635  2003  0.001992\n#[Out]#          1423091   Lesly   F     838  2003  0.000459\n#[Out]#          1423330  Lesley   F     451  2003  0.000247\n#[Out]# 2004 F   1453982  Leslie   F    3497  2004  0.001908\n#[Out]#          1454295   Lesly   F     747  2004  0.000408\n#[Out]#          1454500  Lesley   F     450  2004  0.000245\n#[Out]# 2005 F   1486010  Leslie   F    3120  2005  0.001692\n#[Out]#          1486308   Lesly   F     783  2005  0.000425\n#[Out]#          1486623  Lesley   F     381  2005  0.000207\n#[Out]# 2006 F   1518523  Leslie   F    3035  2006  0.001600\n#[Out]#          1518834   Lesly   F     761  2006  0.000401\n#[Out]#          1519161  Lesley   F     370  2006  0.000195\n#[Out]# 2007 F   1552581  Leslie   F    2689  2007  0.001403\n#[Out]#          1552882   Lesly   F     765  2007  0.000399\n#[Out]#          1553271  Lesley   F     351  2007  0.000183\n#[Out]# 2008 F   1587484  Leslie   F    2323  2008  0.001233\n#[Out]#          1587788   Lesly   F     699  2008  0.000371\n#[Out]# 2009 F   1622503  Leslie   F    1975  2009  0.001081\n#[Out]#          1622845   Lesly   F     598  2009  0.000327\n#[Out]# 2010 F   1657142  Leslie   F    1558  2010  0.000886\n#[Out]#          1657525   Lesly   F     502  2010  0.000285\n#[Out]# \n#[Out]# [400 rows x 5 columns]\n\n\n\n\n\n\n\n\n\n\n\nfiltered.groupby('name').births.sum()   #name\u3067\u30b0\u30eb\u30fc\u30d7\u5316\u3057\u3066\u305d\u306e\u51fa\u751f\u6570\u3092\u5408\u8a08\u3059\u308b\n#[Out]# name\n#[Out]# Leslee      1082\n#[Out]# Lesley     35022\n#[Out]# Lesli        929\n#[Out]# Leslie    370429\n#[Out]# Lesly      10067\n#[Out]# Name: births, dtype: int64\n\n\n\n\n\n\n\ntable=filtered.pivot_table('births',index='year',columns='sex',aggfunc=sum)   # sex, year\u3054\u3068\u306b\u96c6\u8a08\n#[Out]# sex        F      M\n#[Out]# year               \n#[Out]# 1880     8.0   79.0\n#[Out]# 1881    11.0   92.0\n#[Out]# 1882     9.0  128.0\n#[Out]# 1883     7.0  125.0\n#[Out]# 1884    15.0  125.0\n#[Out]# 1885    10.0  122.0\n#[Out]# 1886     8.0  136.0\n#[Out]# 1887    12.0  166.0\n#[Out]# 1888    23.0  175.0\n#[Out]# 1889    23.0  155.0\n#[Out]# 1890    20.0  181.0\n#[Out]# 1891    28.0  164.0\n#[Out]# 1892    22.0  207.0\n#[Out]# 1893    26.0  185.0\n#[Out]# 1894    36.0  223.0\n#[Out]# 1895    22.0  235.0\n#[Out]# 1896    27.0  237.0\n#[Out]# 1897    34.0  222.0\n#[Out]# 1898    24.0  236.0\n#[Out]# 1899    18.0  181.0\n#[Out]# 1900    30.0  285.0\n#[Out]# 1901    29.0  204.0\n#[Out]# 1902    37.0  251.0\n#[Out]# 1903    24.0  244.0\n#[Out]# 1904    30.0  243.0\n#[Out]# 1905    35.0  247.0\n#[Out]# 1906    29.0  263.0\n#[Out]# 1907    34.0  273.0\n#[Out]# 1908    41.0  290.0\n#[Out]# 1909    35.0  292.0\n#[Out]# ...      ...    ...\n#[Out]# 1981  5796.0  500.0\n#[Out]# 1982  5814.0  430.0\n#[Out]# 1983  4975.0  414.0\n#[Out]# 1984  4419.0  367.0\n#[Out]# 1985  4168.0  331.0\n#[Out]# 1986  3741.0  379.0\n#[Out]# 1987  3666.0  290.0\n#[Out]# 1988  3555.0  318.0\n#[Out]# 1989  3259.0  327.0\n#[Out]# 1990  3268.0  295.0\n#[Out]# 1991  2920.0  277.0\n#[Out]# 1992  2836.0  216.0\n#[Out]# 1993  2607.0  201.0\n#[Out]# 1994  2685.0  207.0\n#[Out]# 1995  2782.0  186.0\n#[Out]# 1996  3584.0  176.0\n#[Out]# 1997  3847.0  158.0\n#[Out]# 1998  4289.0    NaN\n#[Out]# 1999  4693.0    NaN\n#[Out]# 2000  5019.0    NaN\n#[Out]# 2001  4920.0    NaN\n#[Out]# 2002  4708.0    NaN\n#[Out]# 2003  4924.0    NaN\n#[Out]# 2004  4694.0    NaN\n#[Out]# 2005  4284.0    NaN\n#[Out]# 2006  4166.0    NaN\n#[Out]# 2007  3805.0    NaN\n#[Out]# 2008  3022.0    NaN\n#[Out]# 2009  2573.0    NaN\n#[Out]# 2010  2060.0    NaN\n#[Out]# \n#[Out]# [131 rows x 2 columns]\n\n\n\ntable=table.div(table.sum(1),axis=0)   #\u6b63\u898f\u5316\n# table.tail()\n#[Out]# sex     F   M\n#[Out]# year         \n#[Out]# 2006  1.0 NaN\n#[Out]# 2007  1.0 NaN\n#[Out]# 2008  1.0 NaN\n#[Out]# 2009  1.0 NaN\n#[Out]# 2010  1.0 NaN\n# table.head()\n#[Out]# sex          F         M\n#[Out]# year                    \n#[Out]# 1880  0.091954  0.908046\n#[Out]# 1881  0.106796  0.893204\n#[Out]# 1882  0.065693  0.934307\n#[Out]# 1883  0.053030  0.946970\n#[Out]# 1884  0.107143  0.892857\n\n\n\ntable.plot(style={'M':'k-','F':'k--'})\n#[Out]# <matplotlib.axes._subplots.AxesSubplot at 0x227b78e6400>\n\n\n* \u74b0\u5883\n\t* win10 64bit\n\t* Python 3.5.2 \n\t* Anaconda 4.1.1 (64-bit)\n* \u8457\u66f8\n\t* [Python for Data Analysis( by Wes McKinney )(Final Release Date: October 2012 )](http://www.cin.ufpe.br/~embat/Python%20for%20Data%20Analysis.pdf)\n* \u30c7\u30fc\u30bf\n\t* [https://github.com/wesm/pydata-book](https://github.com/wesm/pydata-book)\n\n\n\n```python\n# %load ipython_log.py\n# IPython log file\nimport matplotlib.pyplot as plt\nimport numpy as np\nimport pandas as pd\n\n\n# __\u307e\u305a\u306f1\u30d5\u30a1\u30a4\u30eb\u3092\u30d5\u30ec\u30fc\u30e0\u306b\u53d6\u308a\u8fbc\u3093\u3067\u307f\u308b__________________________\nnames1880=pd.read_csv('yob1880.txt',names=['name', 'sex', 'births'])\nnames1880.groupby('sex').births.sum()\n\n\n# __\u3059\u3079\u3066\u306eyob\uff85\uff9d\uff84\uff76.txt\u30921\u3064\u306e\u30d5\u30ec\u30fc\u30e0\u306b\u53d6\u308a\u5165\u308c\u305f\u3044\u3068\u304d__________________________\npieces=[]\ncolumns=['name', 'sex', 'births']\nyears=range(1880,2011)\nfor year in years:\n\tpath='yob%d.txt' % year\n\tframe=pd.read_csv(path,names=columns)\n\tframe['year']=year\n\tpieces.append(frame)\n\tnames=pd.concat(pieces,ignore_index=True)   #\u30a4\u30f3\u30c7\u30c3\u30af\u30b9\u3092\u7121\u8996\u3059\u308bTrue\u306b\u3059\u308b\u3068text\u5de6\u5217\u306e\u30a4\u30f3\u30c7\u30c3\u30af\u30b9\u3092\u9069\u5f53\u306b\u5909\u3048\u3066\u304f\u308c\u308b\n\t\t\t\t\t #1690783\u884c\u306e\u5de8\u5927\u306a\u30d5\u30ec\u30fc\u30e0\u304c\u51fa\u6765\u4e0a\u304c\u308b\u3002\u305d\u308c\u3067\u3082\u691c\u7d22\u306f\u9ad8\u901f\n\n\n# __\u51fa\u751f\u6570\u306e\u63a8\u79fb__________________________\ntotal_births=names.pivot_table(names, index='year', columns='sex', aggfunc=sum)\n'''\n\u672c\u3067\u306f\n total_births = names.pivot_table('births', rows='year',cols='sex', aggfunc=sum)\n \u306e\u3088\u3046\u306b\u3042\u308b\u304c\u3001\u3053\u308c\u306f\u53e4\u3044\n rows=>index\n cols=>columns\n \u306b\u5909\u66f4\u3055\u308c\u3001\n \u7b2c\u4e00\u5f15\u6570\u306b\u30c7\u30fc\u30bf\u30d5\u30ec\u30fc\u30e0\u5165\u308c\u306a\u3044\u3068\u3044\u3051\u306a\u3044\n (\u7b2c\u4e8c\u5f15\u6570\u306b'birth'\u5165\u308c\u306a\u304d\u3083\u3068\u601d\u3063\u305f\u3051\u3069\u306f\u3058\u304b\u308c\u305f\u30fb\u30fb\u30fb\uff1f)\n'''\ntotal_births.tail()\ntotal_births.plot(title='Total births by sex and year')\n'''prop \u306b\u3088\u3063\u3066\u5168\u51fa\u751f\u6570\u306b\u5bfe\u3059\u308b\u5404\u540d\u524d\u306e\u51fa\u751f\u6570\u3092\u306f\u3058\u304d\u51fa\u3057\u3066\u307f\u308b'''\n# data\u3092year,sex\u3067\u30b0\u30eb\u30fc\u30d7\u5316\u3057\u3001\u65b0\u3057\u3044\u5217\u306b\u5165\u308c\u308b\n\n\n\n\n\ndef add_prop(group):\n\t'''\u5404\u540d\u524d\u306e\u51fa\u751f\u6570\u306e\u3001\u5168\u51fa\u751f\u6570\u306b\u5bfe\u3059\u308b\u5272\u5408\u3092\u51fa\u3057\u3066\u3001group\u306b\u5217\u3092\u8ffd\u52a0'''\n\tbirths = group.births.astype(float)   # Integer division floors\n\tgroup['prop'] = births / births.sum()   #prop\u3068\u3044\u3046column\u306b\u7d50\u679c\u3092\u8ffd\u52a0\n\treturn group\n\nnames = names.groupby(['year', 'sex']).apply(add_prop)\n\nnp.allclose(names.groupby(['year','sex']).prop.sum(),1)   # prop\u3092\u3059\u3079\u3066\u8db3\u3059\u30681(100%)\u306b\u306a\u308b\u3053\u3068\u3092\u78ba\u8a8d\n\t# allclose \u306b\u3088\u3063\u3066\u30c1\u30a7\u30c3\u30af\u3059\u308b\u3000names.groupby(['year','sex']).prop.sum()\u30681\u304c\u7b49\u3057\u3044\u304b\u78ba\u8a8d\n\n\n\n\n\n\n\n\n\n\n#__Analyzing Naming Trends__________________________ \ndef get_top1000(group):\n\t'''\n\ttop1000\u306e\u540d\u524d\u3092\u5404sex/year \u304b\u3089\u629c\u304d\u51fa\u3059\u3002\u5225\u306e\u30b0\u30eb\u30fc\u30d7\u4f5c\u308b\n\t<\u65e7\u5f62\u5f0f>\n\treturn group.sort_index(by='births', ascending=False)[:1000]\n\t'''\n\treturn group.sort_values(by='births', ascending=False)[:1000]\n\ngrouped=names.groupby(['year','sex'])\ntop1000=grouped.apply(get_top1000)\n'''\n__top1000 Another Way__________________________ \npieces = []\nfor year, group in names.groupby(['year', 'sex']):\n\tpieces.append(group.sort_index(by='births', ascending=False)[:1000])\ntop1000 = pd.concat(pieces, ignore_index=True)\n'''\n\nboys=top1000[top1000.sex=='M']\ngirls=top1000[top1000.sex=='F']\n\ntotal_births=top1000.pivot_table('births',index='year',columns='name',aggfunc=sum)   #data munging(\u30c7\u30fc\u30bf\u5909\u63db)\u3092\u884c\u3046\u3079\u304fpivot table\u3067\u76f4\u3059\nsubset=total_births[['John', 'Harry', 'Mary', 'Marilyn']]\nsubset.plot(subplots=True, figsize=(12,10),grid=False, title=\"Number of births per year\")\n\n\n\n\n\n\n\n\n# __Measuring the increase in naming diversity__________________________\ntable=top1000.pivot_table('prop',index='year',columns='sex',aggfunc=sum)   # \u540d\u524d\u306e\u591a\u69d8\u6027\u3092\u8abf\u3079\u308b\u3079\u304f\u3001\u6bd4\u7387\u3092pivot_table\u306b\u3057\u3066\u307f\u308b\ntable.plot(title='Sum of table1000.prop by year and sex',yticks=np.linspace(0,1.2,13),xticks=range(1880,2020,10))\n\n# __2010\u5e74\u30c7\u30fc\u30bf\u306e\u6bd4\u7387\u3092\u30bd\u30fc\u30c8\u3059\u308b__________________________ \ndf=boys[boys.year==2010]\nprop_cumsum=df.sort_values(by='prop',ascending=False).prop.cumsum()   # \u7d2f\u7a4d\u548ccumulativesum`cumsum`\u4f7f\u3063\u3066\u6bd4\u7387prop=0.5\u306b\u5c4a\u304f\u540d\u524d\u3092\u5f97\u308b\nprop_cumsum[:10]\nprop_cumsum.searchsorted(0.5)   # \u305d\u306e\u969b\u306e\u30a4\u30f3\u30c7\u30c3\u30af\u30b9\u3092searchsorted\u95a2\u6570\u3092\u4f7f\u3063\u3066\u5f97\u3066\u3001\u30bd\u30fc\u30c8\u3055\u308c\u305f\u5217\u306b0.5\u306ecumsum\u3092insert\u3059\u308b\n\n# __1990\u306b\u3082\u540c\u69d8\u306b__________________________\ndf=boys[boys.year==1900]\nin1900=df.sort_values(by='prop',ascending=False).prop.cumsum()\nin1900.searchsorted(0.5)+1\nprop_cumsum[:10]\nprop_cumsum=df.sort_values(by='prop',ascending=False).prop.cumsum()\n\n# __1990, 2010\u5e74\u306b\u3084\u3063\u305f\u3053\u3068\u3092\u5168\u5e74\u6570\u306b\u5bfe\u3057\u3066\u5b9f\u884c__________________________\ndef get_quantile_count(group, q=0.5):\n\t'''\n\tprop\u30bd\u30fc\u30c8\u3057\u3066\u7d2f\u7a4d\u548c\u3057\u305f\u3082\u306e\u306e0.5\u306e\u30a4\u30f3\u30c7\u30c3\u30af\u30b9\u3092\u8fd4\u3059\n\t<\u65e7\u5f62\u5f0f>\n\t\tgroup = group.sort_index(by='prop', ascending=False)\n\t\treturn group.prop.cumsum().searchsorted(q) + 1\n\t'''\n\tgroup = group.sort_values(by='prop', ascending=False)\n\treturn group.prop.cumsum().values.searchsorted(q) + 1   #return group.prop.cumsum().values.searchsorted(q) + 1 \u306b\u66f8\u304d\u63db\u3048 values\u304f\u308f\u308f\u3063\u305f \u5024\u304c\u30a2\u30ec\u30a4\u8868\u793a\u306b\u306a\u3063\u3066\u3057\u307e\u3046\u306e\u3092\u9632\u3050\n\ndiversity=top1000.groupby(['year','sex']).apply(get_quantile_count)\ndiversity=diversity.unstack('sex')   #\u7537\u5973\u5225\n\ndiversity.head()\ndiversity.plot(title=\"Number of popular names in top 50%\")   # \u5973\u6027\u306e\u307b\u3046\u304c\u540d\u524d\u306e\u591a\u69d8\u6027\u304c\u3059\u3079\u3066\u306e\u5e74\u306b\u304a\u3044\u3066\u591a\u3044\u3053\u3068\u304c\u5206\u304b\u308b\n\n\n\n# __The \"Last letter\" Revolution__________________________ \nget_last_letter=lambda x:x[-1]   # name columns\u304b\u3089\u6700\u5f8c\u306e\u6587\u5b57\u5217\u3060\u3051\u629c\u304d\u51fa\u3057\nlast_letters=names.name.map(get_last_letter)   #names\u306e\u540d\u524d\u3059\u3079\u3066\u306b\u6700\u5f8c\u306e\u6587\u5b57\u5217\u629c\u51fa\u5f0f(get_last_letter)\u3092\u9069\u7528\nlast_letters.name='last_letter'\ntable=names.pivot_table('births',index=last_letters,columns=['sex','year'],aggfunc=sum)\n\nsubtable=table.reindex(columns=[1910,1960,2010],level='year')\nsubtable.head()\n\n\nsubtable.sum()   #\u5168\u51fa\u751f\u6570\nletter_prop=subtable/subtable.sum().astype(float)   # \u6587\u5b57\u5217\u6bd4\u7387\u3092\u53d6\u5f97\n\nfig,axes=plt.subplots(2,1,figsize=(10,8))   #2\u6bb5\u306e\u30b5\u30d6\u30d7\u30ed\u30c3\u30c8\u3067\u8868\u793a\nletter_prop['M'].plot(kind='bar',rot=0,ax=axes[0],title='Male')\nletter_prop['F'].plot(kind='bar',rot=0,ax=axes[1],title='Female',legend=False)\n\n#\u7537\u6027\u306e\u540d\u524d\u306e\u6700\u5f8c\u304cn\u3067\u7d42\u308f\u308b\u6bd4\u7387\u304c\u30c0\u30f3\u30c8\u30c4\u306b\u9ad8\u3044\n#\u4ee5\u4e0b\u3067\u5e74\u63a8\u79fbof last 'n' name\u3092\u898b\u3066\u3044\u304f\n\nletter_prop=table/table.sum().astype(float)   #last_letter\u5404\u3005\u306e\u5168\u4f53\u6570\u306b\u5bfe\u3059\u308b\u6bd4\u7387\ndny_ts=letter_prop.ix[['d','n','y'],'M'].T   #d,n,y\u3060\u3051\u30d7\u30ed\u30c3\u30c8\u3057\u3066\u307f\u308b\n\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t#'M'\u7537\u6027\u306b\u5bfe\u3057\u3066\u3060\u3051\u3000\n\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t# .T\u3067\u30c7\u30fc\u30bf\u30d5\u30ec\u30fc\u30e0\u306e\u8ee2\u7f6e\u884c\u5217\u4f5c\u308b\n# dny_ts.head()\n# dny_ts.plot()\n# plt.show()\n\n\n\n\n\n\n\n\n\n\n\n\n\n#__Boy names that became girl names (and vice versa)__________________________ \nall_names=top1000.name.unique()   #\u5168\u540d\u524d\u5217\u6319\nmask=np.array(['lesl' in x.lower() for x in all_names])   #lower() \u5c0f\u6587\u5b57\u5909\u63db\u30e1\u30bd\u30c3\u30c9\n\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t#'lesl'\u3068\u3044\u3046\u6587\u5b57\u542b\u3093\u3067\u3044\u305f\u3089True\u8fd4\u3059\n#[In]# mask\n#[Out]# array([False, False, False, ..., False, False, False], dtype=bool)\n\n\n\n\nlesley_like=all_names[mask]   #all_names\u306e\u4e2d\u306e'lesl'\u542b\u3093\u3067\u3044\u308b\u3082\u306e\u3060\u3051lesley_like\u306b\u683c\u7d0d\n#[In]# lesley_like\n#[Out]# array(['Leslie', 'Lesley', 'Leslee', 'Lesli', 'Lesly'], dtype=object)\n\n\n\n\n\nfiltered=top1000[top1000.name.isin(lesley_like)]   #top1000\u306e\u4e2d\u304b\u3089lesley\u307d\u3044\u5974\u3060\u3051\u629c\u304d\u51fa\u3057\n#[In]# filtered\n#[Out]#                     name sex  births  year      prop\n#[Out]# year sex                                            \n#[Out]# 1880 F   654      Leslie   F       8  1880  0.000088\n#[Out]#      M   1108     Leslie   M      79  1880  0.000715\n#[Out]# 1881 F   2523     Leslie   F      11  1881  0.000120\n#[Out]#      M   3072     Leslie   M      92  1881  0.000913\n#[Out]# 1882 F   4593     Leslie   F       9  1882  0.000083\n#[Out]#      M   5081     Leslie   M     122  1882  0.001073\n#[Out]#          5865     Lesley   M       6  1882  0.000053\n#[Out]# 1883 F   6850     Leslie   F       7  1883  0.000062\n#[Out]#      M   7225     Leslie   M     120  1883  0.001147\n#[Out]#          8093     Lesley   M       5  1883  0.000048\n#[Out]# 1884 F   8697     Leslie   F      15  1884  0.000116\n#[Out]#      M   9432     Leslie   M     125  1884  0.001092\n#[Out]# 1885 F   11161    Leslie   F      10  1885  0.000075\n#[Out]#      M   11751    Leslie   M     122  1885  0.001132\n#[Out]# 1886 F   13601    Leslie   F       8  1886  0.000055\n#[Out]#      M   14132    Leslie   M     136  1886  0.001228\n#[Out]# 1887 F   15806    Leslie   F      12  1887  0.000082\n#[Out]#      M   16524    Leslie   M     166  1887  0.001637\n#[Out]# 1888 F   18030    Leslie   F      23  1888  0.000129\n#[Out]#      M   19074    Leslie   M     175  1888  0.001448\n#[Out]# 1889 F   20690    Leslie   F      23  1889  0.000129\n#[Out]#      M   21737    Leslie   M     155  1889  0.001402\n#[Out]# 1890 F   23332    Leslie   F      20  1890  0.000105\n#[Out]#      M   24372    Leslie   M     181  1890  0.001630\n#[Out]# 1891 F   25928    Leslie   F      28  1891  0.000151\n#[Out]#      M   27068    Leslie   M     164  1891  0.001621\n#[Out]# 1892 F   28704    Leslie   F      22  1892  0.000104\n#[Out]#      M   29851    Leslie   M     207  1892  0.001696\n#[Out]# 1893 F   31576    Leslie   F      26  1893  0.000122\n#[Out]#      M   32765    Leslie   M     185  1893  0.001647\n#[Out]# ...                  ...  ..     ...   ...       ...\n#[Out]# 2000 F   1332261  Leslie   F    3619  2000  0.001995\n#[Out]#          1332560   Lesly   F     742  2000  0.000409\n#[Out]#          1332601  Lesley   F     658  2000  0.000363\n#[Out]# 2001 F   1362012  Leslie   F    3610  2001  0.002007\n#[Out]#          1362300   Lesly   F     801  2001  0.000445\n#[Out]#          1362452  Lesley   F     509  2001  0.000283\n#[Out]# 2002 F   1392272  Leslie   F    3520  2002  0.001962\n#[Out]#          1392586   Lesly   F     717  2002  0.000400\n#[Out]#          1392743  Lesley   F     471  2002  0.000262\n#[Out]# 2003 F   1422818  Leslie   F    3635  2003  0.001992\n#[Out]#          1423091   Lesly   F     838  2003  0.000459\n#[Out]#          1423330  Lesley   F     451  2003  0.000247\n#[Out]# 2004 F   1453982  Leslie   F    3497  2004  0.001908\n#[Out]#          1454295   Lesly   F     747  2004  0.000408\n#[Out]#          1454500  Lesley   F     450  2004  0.000245\n#[Out]# 2005 F   1486010  Leslie   F    3120  2005  0.001692\n#[Out]#          1486308   Lesly   F     783  2005  0.000425\n#[Out]#          1486623  Lesley   F     381  2005  0.000207\n#[Out]# 2006 F   1518523  Leslie   F    3035  2006  0.001600\n#[Out]#          1518834   Lesly   F     761  2006  0.000401\n#[Out]#          1519161  Lesley   F     370  2006  0.000195\n#[Out]# 2007 F   1552581  Leslie   F    2689  2007  0.001403\n#[Out]#          1552882   Lesly   F     765  2007  0.000399\n#[Out]#          1553271  Lesley   F     351  2007  0.000183\n#[Out]# 2008 F   1587484  Leslie   F    2323  2008  0.001233\n#[Out]#          1587788   Lesly   F     699  2008  0.000371\n#[Out]# 2009 F   1622503  Leslie   F    1975  2009  0.001081\n#[Out]#          1622845   Lesly   F     598  2009  0.000327\n#[Out]# 2010 F   1657142  Leslie   F    1558  2010  0.000886\n#[Out]#          1657525   Lesly   F     502  2010  0.000285\n#[Out]# \n#[Out]# [400 rows x 5 columns]\n\n\n\n\n\n\n\n\n\n\n\nfiltered.groupby('name').births.sum()   #name\u3067\u30b0\u30eb\u30fc\u30d7\u5316\u3057\u3066\u305d\u306e\u51fa\u751f\u6570\u3092\u5408\u8a08\u3059\u308b\n#[Out]# name\n#[Out]# Leslee      1082\n#[Out]# Lesley     35022\n#[Out]# Lesli        929\n#[Out]# Leslie    370429\n#[Out]# Lesly      10067\n#[Out]# Name: births, dtype: int64\n\n\n\n\n\n\n\ntable=filtered.pivot_table('births',index='year',columns='sex',aggfunc=sum)   # sex, year\u3054\u3068\u306b\u96c6\u8a08\n#[Out]# sex        F      M\n#[Out]# year               \n#[Out]# 1880     8.0   79.0\n#[Out]# 1881    11.0   92.0\n#[Out]# 1882     9.0  128.0\n#[Out]# 1883     7.0  125.0\n#[Out]# 1884    15.0  125.0\n#[Out]# 1885    10.0  122.0\n#[Out]# 1886     8.0  136.0\n#[Out]# 1887    12.0  166.0\n#[Out]# 1888    23.0  175.0\n#[Out]# 1889    23.0  155.0\n#[Out]# 1890    20.0  181.0\n#[Out]# 1891    28.0  164.0\n#[Out]# 1892    22.0  207.0\n#[Out]# 1893    26.0  185.0\n#[Out]# 1894    36.0  223.0\n#[Out]# 1895    22.0  235.0\n#[Out]# 1896    27.0  237.0\n#[Out]# 1897    34.0  222.0\n#[Out]# 1898    24.0  236.0\n#[Out]# 1899    18.0  181.0\n#[Out]# 1900    30.0  285.0\n#[Out]# 1901    29.0  204.0\n#[Out]# 1902    37.0  251.0\n#[Out]# 1903    24.0  244.0\n#[Out]# 1904    30.0  243.0\n#[Out]# 1905    35.0  247.0\n#[Out]# 1906    29.0  263.0\n#[Out]# 1907    34.0  273.0\n#[Out]# 1908    41.0  290.0\n#[Out]# 1909    35.0  292.0\n#[Out]# ...      ...    ...\n#[Out]# 1981  5796.0  500.0\n#[Out]# 1982  5814.0  430.0\n#[Out]# 1983  4975.0  414.0\n#[Out]# 1984  4419.0  367.0\n#[Out]# 1985  4168.0  331.0\n#[Out]# 1986  3741.0  379.0\n#[Out]# 1987  3666.0  290.0\n#[Out]# 1988  3555.0  318.0\n#[Out]# 1989  3259.0  327.0\n#[Out]# 1990  3268.0  295.0\n#[Out]# 1991  2920.0  277.0\n#[Out]# 1992  2836.0  216.0\n#[Out]# 1993  2607.0  201.0\n#[Out]# 1994  2685.0  207.0\n#[Out]# 1995  2782.0  186.0\n#[Out]# 1996  3584.0  176.0\n#[Out]# 1997  3847.0  158.0\n#[Out]# 1998  4289.0    NaN\n#[Out]# 1999  4693.0    NaN\n#[Out]# 2000  5019.0    NaN\n#[Out]# 2001  4920.0    NaN\n#[Out]# 2002  4708.0    NaN\n#[Out]# 2003  4924.0    NaN\n#[Out]# 2004  4694.0    NaN\n#[Out]# 2005  4284.0    NaN\n#[Out]# 2006  4166.0    NaN\n#[Out]# 2007  3805.0    NaN\n#[Out]# 2008  3022.0    NaN\n#[Out]# 2009  2573.0    NaN\n#[Out]# 2010  2060.0    NaN\n#[Out]# \n#[Out]# [131 rows x 2 columns]\n\n\n\ntable=table.div(table.sum(1),axis=0)   #\u6b63\u898f\u5316\n# table.tail()\n#[Out]# sex     F   M\n#[Out]# year         \n#[Out]# 2006  1.0 NaN\n#[Out]# 2007  1.0 NaN\n#[Out]# 2008  1.0 NaN\n#[Out]# 2009  1.0 NaN\n#[Out]# 2010  1.0 NaN\n# table.head()\n#[Out]# sex          F         M\n#[Out]# year                    \n#[Out]# 1880  0.091954  0.908046\n#[Out]# 1881  0.106796  0.893204\n#[Out]# 1882  0.065693  0.934307\n#[Out]# 1883  0.053030  0.946970\n#[Out]# 1884  0.107143  0.892857\n\n\n\ntable.plot(style={'M':'k-','F':'k--'})\n#[Out]# <matplotlib.axes._subplots.AxesSubplot at 0x227b78e6400>\n\n```\n"}