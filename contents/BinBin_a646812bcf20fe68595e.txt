{"context": "Spark2.0\u304b\u3089Dataset\u304c\u6b63\u5f0f\u306b\u30b5\u30dd\u30fc\u30c8\u3055\u308c\u305f\u3068\u3044\u3046\u3053\u3068\u3067\uff0c\u521d\u3081\u3066\u89e6\u3063\u3066\u307f\u308b\u3002\n\u3061\u306a\u307f\u306b\uff0cSpark1.X\u306eDataFrame\u306f\u591a\u5c11\u89e6\u3063\u305f\u3053\u3068\u306f\u3042\u308b\u3002\n\u5404\u6240\u3067\u516c\u958b\u3055\u308c\u3066\u3044\u308b\u30b5\u30f3\u30d7\u30eb\u306fScala\u304c\u591a\u3044\u304c\uff0c\u7b46\u8005\u304cScala\u3092\u4f7f\u3048\u306a\u3044\u306e\u3067\u4eca\u56de\u306fJava\u3092\u4f7f\u3063\u3066\u307f\u308b\u3002\n\n\u74b0\u5883\n[OS]\uff1aCentOS 7\n[Apache Spark]\uff1a2.1.0\n\nSpark\u306e\u30a4\u30f3\u30b9\u30c8\u30fc\u30eb\n\u8abf\u3079\u305f\u3089\u7d50\u69cb\u3067\u3066\u304f\u308b\u306e\u3067\uff0c\u3053\u3053\u3067\u306f\u7c21\u5358\u306b\u8a18\u8f09\u3059\u308b\u3002\n\nSpark\u306e\u30a4\u30f3\u30b9\u30c8\u30fc\u30eb\n#Java\u304c\u5165\u3063\u3066\u306a\u304b\u3063\u305f\u3089\u30a4\u30f3\u30b9\u30c8\u30fc\u30eb\nyum install java-1.8.0-openjdk\n\nwget http://d3kbcqa49mib13.cloudfront.net/spark-2.1.0-bin-hadoop2.7.tgz\ncd /opt\ntar xzvf /tmp/spark-2.1.0-bin-hadoop2.7.tgz\nmv spark-2.1.0-bin-hadoop2.7 spark\n\n#spark-submit\u306e\u30d1\u30b9\u3092\u901a\u3057\u3066\u304a\u304f\nexport PATH=$PATH:/opt/spark/bin\n\n\n\nDataset\u306e\u4f5c\u6210\n\u3068\u308a\u3042\u3048\u305aDataset\u3092\u4f5c\u6210\u3057\u3066\u307f\u308b\u3002\n\u4eca\u56de\u306fDataFrame\u304b\u3089Dataset\u306b\u5909\u63db\u3057\u3066\u4f5c\u6210\u3059\u308b\u3002\n\u30c6\u30b9\u30c8\u30c7\u30fc\u30bf\u306e\u8aad\u307f\u8fbc\u307f\u306b\u306f\u4fbf\u5229\u306aSpark-Csv\u30e2\u30b8\u30e5\u30fc\u30eb\u3092\u5229\u7528\u3059\u308b\u3002\nJava\u30d7\u30ed\u30b0\u30e9\u30e0\u3068\u30c6\u30b9\u30c8\u30c7\u30fc\u30bf\u3092\u4e8b\u524d\u306b\u4f5c\u6210\u3057\uff0cSpark\u30db\u30b9\u30c8\u306b\u8ee2\u9001\u3057\u3066\u4e0b\u8a18\u30b3\u30de\u30f3\u30c9\u3092\u5b9f\u884c\u3059\u308b\u3002\n\nspark-submit\u30b3\u30de\u30f3\u30c9\nspark-submit --master local --class com.binbin.spark.DatasetTest --jars spark-csv_2.10-1.5.0.jar spark-0.0.1-SNAPSHOT.jar\n\n\n\u4e0b\u8a18\u306bSpark\u3067\u52d5\u4f5c\u3055\u305b\u308bJava\u30d7\u30ed\u30b0\u30e9\u30e0\u3092\u8a18\u8f09\u3059\u308b\u3002\n\u30b3\u30e1\u30f3\u30c8(//)\u306b\u7c21\u5358\u306a\u8aac\u660e\u3082\u5165\u308c\u305f\u3002\n\nDatasetTest\u30af\u30e9\u30b9\npackage com.binbin.spark;\nimport org.apache.spark.sql.Dataset;\nimport org.apache.spark.sql.Encoders;\nimport org.apache.spark.sql.Row;\nimport org.apache.spark.sql.SQLContext;\nimport org.apache.spark.sql.SparkSession;\n\npublic class DatasetTest {\n    public static void main(String args[]){\n\n        // \u30a8\u30f3\u30c8\u30ea\u30fc\u30dd\u30a4\u30f3\u30c8\n        SparkSession ss = SparkSession.builder().master(\"local\").appName(\"DatasetTest\").getOrCreate();\n        SQLContext sqlc = new SQLContext(ss);\n\n        // Spark-Csv\u3092\u4f7f\u7528\u3057\u3066DataFrame\u3092\u4f5c\u6210\n        Dataset<Row> df =sqlc.read()\n        .format(\"com.databricks.spark.csv\")\n        .option(\"header\", \"true\")\n        .option(\"inferSchema\", \"true\")\n        .load(\"testdata1.csv\");\n\n        // df.show()\u306e\u7d50\u679c\n        // +------+---+------+-------+--------------------+\n        // |  name|age|gender|married|            birthday|\n        // +------+---+------+-------+--------------------+\n        // | Aaron| 22|  male|   true|1994-04-17 21:00:...|\n        // |   Ray| 51|  male|   true|1965-06-11 11:30:...|\n        // | Barry| 33|  male|  false|1983-02-17 11:00:...|\n        // | Paula| 19|female|  false|1997-08-17 09:30:...|\n        // |Melvin| 21|  male|  false|1995-04-02 13:15:...|\n        // +------+---+------+-------+--------------------+\n        df.show();\n\n        // df.printSchema()\u306e\u7d50\u679c\n        // root\n        //  |-- name: string (nullable = true)\n        //  |-- age: integer (nullable = true)\n        //  |-- gender: string (nullable = true)\n        //  |-- married: boolean (nullable = true)\n        //  |-- birthday: timestamp (nullable = true)\n        df.printSchema();\n\n        // DataFrame\u306e\u5834\u5408\uff0c\u4e0b\u8a18\u306e\u3088\u3046\u306bdf\u306b\u5b58\u5728\u3057\u306a\u3044\u30ab\u30e9\u30e0(salary)\u3092\u6307\u5b9a\u3057\u3066filter\u3057\u305f\u3068\u304d\u306b\uff0c\n        // \u30b3\u30f3\u30d1\u30a4\u30eb\u6642\u306b\u30a8\u30e9\u30fc\u3068\u306a\u3089\u305a\uff0c\u5b9f\u884c\u6642\u306b\u30a8\u30e9\u30fc\u3068\u306a\u308b\u3002\n        // \u300corg.apache.spark.sql.AnalysisException: cannot resolve '`salary`' given input columns \u2026\u300d\n        df.filter(\"salary > 10000\").show();\n\n        // Dataset\u306b\u5909\u63db!\n        Dataset<Person> ds =df.as(Encoders.bean(Person.class));\n\n        // DataFrame(df.show())\u306e\u7d50\u679c\u3068\u4e00\u7dd2\n        ds.show();\n        // DataFrame(df.printSchema())\u306e\u7d50\u679c\u3068\u4e00\u7dd2\n        ds.printSchema();\n\n        // Dataset\u306e\u5834\u5408\uff0c\u4e0b\u8a18\u306e\u3088\u3046\u306b\u3092\u6307\u5b9a\u3057\u3066filter\u3057\u305f\u3068\u304d\u306b\uff0c\n        // Person\u578b\u306e\u30b3\u30f3\u30d1\u30a4\u30eb\u6642\u306b\u30a8\u30e9\u30fc\u3068\u306a\u308b\u3002\n        // \u300c\u30e1\u30bd\u30c3\u30c9 getSalary() \u306f\u578b Person \u3067\u672a\u5b9a\u7fa9\u3067\u3059\u300d\n         ds.filter(p -> {\n            return p.getSalary() > 10000;\n         }).show();\n    }\n}\n\n\n\nPerson\u30af\u30e9\u30b9\npackage com.binbin.spark;\nimport java.io.Serializable;\nimport java.sql.Timestamp;\npublic class Person implements Serializable {\n    private String name;\n    private int age;\n    private String gender;\n    private boolean married;\n    private Timestamp birthday;\n\n    public String getName() {\n        return name;\n    }\n    public void setName(String name) {\n        this.name = name;\n    }\n    public int getAge() {\n        return age;\n    }\n    public void setAge(int age) {\n        this.age = age;\n    }\n    public String getGender() {\n        return gender;\n    }\n    public void setGender(String gender) {\n        this.gender = gender;\n    }\n    public boolean getMarried() {\n        return married;\n    }\n    public void setMarried(boolean married) {\n        this.married = married;\n    }\n    public Timestamp getBirthday() {\n        return birthday;\n    }\n    public void setBirthday(Timestamp birthday) {\n        this.birthday = birthday;\n    }\n}\n\n\nDataset\u306fDataFrame\u3068\u6bd4\u8f03\u3057\u3066\uff0c\u30b3\u30f3\u30d1\u30a4\u30eb\u6642\u306bAnalysis\u7cfb\u30a8\u30e9\u30fc\u304c\u691c\u51fa\u3057\u3084\u3059\u304f\u306a\u308a\u307e\u3059\u3002\n\u307e\u305f\uff0cSpark2.0\u304b\u3089DataFram\u578b\u304c\u306a\u304f\u306a\u3063\u3066\u304a\u308a\uff0c\nDataset<Row>\u578b\u304c\u5f93\u6765\u306eDataFrame\u578b\u306b\u8a72\u5f53\u3059\u308b\u3068\u8003\u3048\u3066\u3088\u3055\u305d\u3046\u3067\u3059\u3002\n\n\u4e0b\u8a18\u3067\u7c21\u5358\u306bDataset\u306e\u30c7\u30fc\u30bf\u64cd\u4f5c\u3057\u3066\u307f\u307e\u3057\u305f\u3002\nhttp://qiita.com/BinBin/items/9fc3db51106fb805a586\n\u307e\u305f\uff0cSparkSQL\u304c\u63d0\u4f9b\u3059\u308b\u95a2\u6570\u306b\u3064\u3044\u3066\u306f\u4e0b\u8a18\u30b5\u30a4\u30c8\u3092\u53c2\u8003\u306b\u3057\u3066\u3044\u307e\u3059\u3002\nhttp://x1.inkenkun.com/archives/category/spark\n\n\u307e\u3068\u3081\n\u30fbDataset\u306fDataFrame\u3068\u6bd4\u8f03\u3057\u3066\uff0c\u30b3\u30f3\u30d1\u30a4\u30eb\u6642\u306bAnalysis\u7cfb\u30a8\u30e9\u30fc\u304c\u691c\u51fa\u3057\u3084\u3059\u304f\u306a\u308b!\n\u30fbDataset\u306fDataFrame\u3068\u540c\u3058\u611f\u899a\u3067\u30c7\u30fc\u30bf\u64cd\u4f5c\u53ef\u80fd\uff01\n\u30fbSpaek2.0\u4ee5\u964d\u3067\u306f\uff0cDataset<Row>\u30af\u30e9\u30b9\u304c\u5f93\u6765\u306eDataFrame\u30af\u30e9\u30b9\u306b\u8a72\u5f53\u3057\u305d\u3046\uff01\n\u30fb\u30d1\u30d5\u30a9\u30fc\u30de\u30f3\u30b9\u306e\u6539\u5584\u306b\u3064\u3044\u3066\u306f\uff0c\u4eca\u56de\u6271\u3046\u30c7\u30fc\u30bf\u91cf\u304c\u5c0f\u3055\u3059\u304e\u3066\u308f\u304b\u3089\u305a\u3002\nSpark2.0\u304b\u3089Dataset\u304c\u6b63\u5f0f\u306b\u30b5\u30dd\u30fc\u30c8\u3055\u308c\u305f\u3068\u3044\u3046\u3053\u3068\u3067\uff0c\u521d\u3081\u3066\u89e6\u3063\u3066\u307f\u308b\u3002\n\u3061\u306a\u307f\u306b\uff0cSpark1.X\u306eDataFrame\u306f\u591a\u5c11\u89e6\u3063\u305f\u3053\u3068\u306f\u3042\u308b\u3002\n\u5404\u6240\u3067\u516c\u958b\u3055\u308c\u3066\u3044\u308b\u30b5\u30f3\u30d7\u30eb\u306fScala\u304c\u591a\u3044\u304c\uff0c~~\u7b46\u8005\u304cScala\u3092\u4f7f\u3048\u306a\u3044\u306e\u3067~~\u4eca\u56de\u306fJava\u3092\u4f7f\u3063\u3066\u307f\u308b\u3002\n\n#\u74b0\u5883\n**[OS]**\uff1aCentOS 7\n**[Apache Spark]**\uff1a2.1.0\n\n#Spark\u306e\u30a4\u30f3\u30b9\u30c8\u30fc\u30eb\n\u8abf\u3079\u305f\u3089\u7d50\u69cb\u3067\u3066\u304f\u308b\u306e\u3067\uff0c\u3053\u3053\u3067\u306f\u7c21\u5358\u306b\u8a18\u8f09\u3059\u308b\u3002\n\n```bash:Spark\u306e\u30a4\u30f3\u30b9\u30c8\u30fc\u30eb\n#Java\u304c\u5165\u3063\u3066\u306a\u304b\u3063\u305f\u3089\u30a4\u30f3\u30b9\u30c8\u30fc\u30eb\nyum install java-1.8.0-openjdk\n\nwget http://d3kbcqa49mib13.cloudfront.net/spark-2.1.0-bin-hadoop2.7.tgz\ncd /opt\ntar xzvf /tmp/spark-2.1.0-bin-hadoop2.7.tgz\nmv spark-2.1.0-bin-hadoop2.7 spark\n\n#spark-submit\u306e\u30d1\u30b9\u3092\u901a\u3057\u3066\u304a\u304f\nexport PATH=$PATH:/opt/spark/bin\n```\n\n#Dataset\u306e\u4f5c\u6210\n\u3068\u308a\u3042\u3048\u305aDataset\u3092\u4f5c\u6210\u3057\u3066\u307f\u308b\u3002\n\u4eca\u56de\u306fDataFrame\u304b\u3089Dataset\u306b\u5909\u63db\u3057\u3066\u4f5c\u6210\u3059\u308b\u3002\n\u30c6\u30b9\u30c8\u30c7\u30fc\u30bf\u306e\u8aad\u307f\u8fbc\u307f\u306b\u306f\u4fbf\u5229\u306aSpark-Csv\u30e2\u30b8\u30e5\u30fc\u30eb\u3092\u5229\u7528\u3059\u308b\u3002\nJava\u30d7\u30ed\u30b0\u30e9\u30e0\u3068\u30c6\u30b9\u30c8\u30c7\u30fc\u30bf\u3092\u4e8b\u524d\u306b\u4f5c\u6210\u3057\uff0cSpark\u30db\u30b9\u30c8\u306b\u8ee2\u9001\u3057\u3066\u4e0b\u8a18\u30b3\u30de\u30f3\u30c9\u3092\u5b9f\u884c\u3059\u308b\u3002\n\n```co:spark-submit\u30b3\u30de\u30f3\u30c9\nspark-submit --master local --class com.binbin.spark.DatasetTest --jars spark-csv_2.10-1.5.0.jar spark-0.0.1-SNAPSHOT.jar\n```\n\n\u4e0b\u8a18\u306bSpark\u3067\u52d5\u4f5c\u3055\u305b\u308bJava\u30d7\u30ed\u30b0\u30e9\u30e0\u3092\u8a18\u8f09\u3059\u308b\u3002\n\u30b3\u30e1\u30f3\u30c8(//)\u306b\u7c21\u5358\u306a\u8aac\u660e\u3082\u5165\u308c\u305f\u3002\n\n```java:DatasetTest\u30af\u30e9\u30b9\npackage com.binbin.spark;\nimport org.apache.spark.sql.Dataset;\nimport org.apache.spark.sql.Encoders;\nimport org.apache.spark.sql.Row;\nimport org.apache.spark.sql.SQLContext;\nimport org.apache.spark.sql.SparkSession;\n\npublic class DatasetTest {\n\tpublic static void main(String args[]){\n\n\t\t// \u30a8\u30f3\u30c8\u30ea\u30fc\u30dd\u30a4\u30f3\u30c8\n\t\tSparkSession ss = SparkSession.builder().master(\"local\").appName(\"DatasetTest\").getOrCreate();\n\t\tSQLContext sqlc = new SQLContext(ss);\n\n\t\t// Spark-Csv\u3092\u4f7f\u7528\u3057\u3066DataFrame\u3092\u4f5c\u6210\n\t\tDataset<Row> df =sqlc.read()\n\t    .format(\"com.databricks.spark.csv\")\n\t    .option(\"header\", \"true\")\n\t    .option(\"inferSchema\", \"true\")\n\t    .load(\"testdata1.csv\");\n\n\t\t// df.show()\u306e\u7d50\u679c\n\t\t// +------+---+------+-------+--------------------+\n\t\t// |  name|age|gender|married|            birthday|\n\t\t// +------+---+------+-------+--------------------+\n\t\t// | Aaron| 22|  male|   true|1994-04-17 21:00:...|\n\t\t// |   Ray| 51|  male|   true|1965-06-11 11:30:...|\n\t\t// | Barry| 33|  male|  false|1983-02-17 11:00:...|\n\t\t// | Paula| 19|female|  false|1997-08-17 09:30:...|\n\t\t// |Melvin| 21|  male|  false|1995-04-02 13:15:...|\n\t\t// +------+---+------+-------+--------------------+\n\t\tdf.show();\n\n\t\t// df.printSchema()\u306e\u7d50\u679c\n\t\t// root\n\t\t//  |-- name: string (nullable = true)\n\t\t//  |-- age: integer (nullable = true)\n\t\t//  |-- gender: string (nullable = true)\n\t\t//  |-- married: boolean (nullable = true)\n\t\t//  |-- birthday: timestamp (nullable = true)\n\t\tdf.printSchema();\n\n\t\t// DataFrame\u306e\u5834\u5408\uff0c\u4e0b\u8a18\u306e\u3088\u3046\u306bdf\u306b\u5b58\u5728\u3057\u306a\u3044\u30ab\u30e9\u30e0(salary)\u3092\u6307\u5b9a\u3057\u3066filter\u3057\u305f\u3068\u304d\u306b\uff0c\n\t\t// \u30b3\u30f3\u30d1\u30a4\u30eb\u6642\u306b\u30a8\u30e9\u30fc\u3068\u306a\u3089\u305a\uff0c\u5b9f\u884c\u6642\u306b\u30a8\u30e9\u30fc\u3068\u306a\u308b\u3002\n\t\t// \u300corg.apache.spark.sql.AnalysisException: cannot resolve '`salary`' given input columns \u2026\u300d\n\t\tdf.filter(\"salary > 10000\").show();\n\n\t\t// Dataset\u306b\u5909\u63db!\n\t\tDataset<Person> ds =df.as(Encoders.bean(Person.class));\n\n\t\t// DataFrame(df.show())\u306e\u7d50\u679c\u3068\u4e00\u7dd2\n\t\tds.show();\n\t\t// DataFrame(df.printSchema())\u306e\u7d50\u679c\u3068\u4e00\u7dd2\n\t\tds.printSchema();\n\n\t\t// Dataset\u306e\u5834\u5408\uff0c\u4e0b\u8a18\u306e\u3088\u3046\u306b\u3092\u6307\u5b9a\u3057\u3066filter\u3057\u305f\u3068\u304d\u306b\uff0c\n\t\t// Person\u578b\u306e\u30b3\u30f3\u30d1\u30a4\u30eb\u6642\u306b\u30a8\u30e9\u30fc\u3068\u306a\u308b\u3002\n\t\t// \u300c\u30e1\u30bd\u30c3\u30c9 getSalary() \u306f\u578b Person \u3067\u672a\u5b9a\u7fa9\u3067\u3059\u300d\n\t\t ds.filter(p -> {\n\t\t\treturn p.getSalary() > 10000;\n\t\t }).show();\n\t}\n}\n```\n\n```java:Person\u30af\u30e9\u30b9\npackage com.binbin.spark;\nimport java.io.Serializable;\nimport java.sql.Timestamp;\npublic class Person implements Serializable {\n\tprivate String name;\n\tprivate int age;\n\tprivate String gender;\n\tprivate boolean married;\n\tprivate Timestamp birthday;\n\n\tpublic String getName() {\n\t\treturn name;\n\t}\n\tpublic void setName(String name) {\n\t\tthis.name = name;\n\t}\n\tpublic int getAge() {\n\t\treturn age;\n\t}\n\tpublic void setAge(int age) {\n\t\tthis.age = age;\n\t}\n\tpublic String getGender() {\n\t\treturn gender;\n\t}\n\tpublic void setGender(String gender) {\n\t\tthis.gender = gender;\n\t}\n\tpublic boolean getMarried() {\n\t\treturn married;\n\t}\n\tpublic void setMarried(boolean married) {\n\t\tthis.married = married;\n\t}\n\tpublic Timestamp getBirthday() {\n\t\treturn birthday;\n\t}\n\tpublic void setBirthday(Timestamp birthday) {\n\t\tthis.birthday = birthday;\n\t}\n}\n```\n\nDataset\u306fDataFrame\u3068\u6bd4\u8f03\u3057\u3066\uff0c\u30b3\u30f3\u30d1\u30a4\u30eb\u6642\u306bAnalysis\u7cfb\u30a8\u30e9\u30fc\u304c\u691c\u51fa\u3057\u3084\u3059\u304f\u306a\u308a\u307e\u3059\u3002\n\u307e\u305f\uff0cSpark2.0\u304b\u3089DataFram\u578b\u304c\u306a\u304f\u306a\u3063\u3066\u304a\u308a\uff0c\nDataset\\<Row\\>\u578b\u304c\u5f93\u6765\u306eDataFrame\u578b\u306b\u8a72\u5f53\u3059\u308b\u3068\u8003\u3048\u3066\u3088\u3055\u305d\u3046\u3067\u3059\u3002\n\n![s_sql-vs-dataframes-vs-datasets-type-safety-spectrum.png](https://qiita-image-store.s3.amazonaws.com/0/157321/5fcbd35a-3dd4-a740-33a8-f0e9cd9f8638.png)\n\n\u4e0b\u8a18\u3067\u7c21\u5358\u306bDataset\u306e\u30c7\u30fc\u30bf\u64cd\u4f5c\u3057\u3066\u307f\u307e\u3057\u305f\u3002\nhttp://qiita.com/BinBin/items/9fc3db51106fb805a586\n\n\u307e\u305f\uff0cSparkSQL\u304c\u63d0\u4f9b\u3059\u308b\u95a2\u6570\u306b\u3064\u3044\u3066\u306f\u4e0b\u8a18\u30b5\u30a4\u30c8\u3092\u53c2\u8003\u306b\u3057\u3066\u3044\u307e\u3059\u3002\nhttp://x1.inkenkun.com/archives/category/spark\n\n#\u307e\u3068\u3081\n\u30fbDataset\u306fDataFrame\u3068\u6bd4\u8f03\u3057\u3066\uff0c\u30b3\u30f3\u30d1\u30a4\u30eb\u6642\u306bAnalysis\u7cfb\u30a8\u30e9\u30fc\u304c\u691c\u51fa\u3057\u3084\u3059\u304f\u306a\u308b!\n\u30fbDataset\u306fDataFrame\u3068\u540c\u3058\u611f\u899a\u3067\u30c7\u30fc\u30bf\u64cd\u4f5c\u53ef\u80fd\uff01\n\u30fbSpaek2.0\u4ee5\u964d\u3067\u306f\uff0cDataset\\<Row\\>\u30af\u30e9\u30b9\u304c\u5f93\u6765\u306eDataFrame\u30af\u30e9\u30b9\u306b\u8a72\u5f53\u3057\u305d\u3046\uff01\n\u30fb\u30d1\u30d5\u30a9\u30fc\u30de\u30f3\u30b9\u306e\u6539\u5584\u306b\u3064\u3044\u3066\u306f\uff0c\u4eca\u56de\u6271\u3046\u30c7\u30fc\u30bf\u91cf\u304c\u5c0f\u3055\u3059\u304e\u3066\u308f\u304b\u3089\u305a\u3002\n", "tags": ["Java", "Dataset", "ApacheSpark", "Spark"]}