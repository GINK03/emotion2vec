{"context": " More than 1 year has passed since last update.\n\nAmazon Kinesis\n\n\u516c\u5f0f\u30b5\u30a4\u30c8\n\n\u82f1\u8a9e http://aws.amazon.com/kinesis/\n\n\u65e5\u672c\u8a9e http://aws.amazon.com/jp/kinesis/\n\n\n\n\u6982\u8981\n\nAmazon Kinesis \u306f\u3001\u5927\u898f\u6a21\u306a\u30b9\u30c8\u30ea\u30fc\u30df\u30f3\u30b0\u30c7\u30fc\u30bf\u3092\u30ea\u30a2\u30eb\u30bf\u30a4\u30e0\u3067\u51e6\u7406\u3059\u308b\u5b8c\u5168\u30de\u30cd\u30fc\u30b8\u30c9\u578b\u30b5\u30fc\u30d3\u30b9\u3067\u3059\n\n\n\u5229\u7528\u53ef\u80fd\u306a\u30ea\u30fc\u30b8\u30e7\u30f3\u3068\u5229\u7528\u6599\u91d1\uff082014/06/08 \u73fe\u5728\uff09\n\n\u30ea\u30fc\u30b8\u30e7\u30f3\n** \u7c73\u56fd\u6771\u90e8\uff08\u30d0\u30fc\u30b8\u30cb\u30a2\u5317\u90e8\uff09\u306e\u307f\n\u5229\u7528\u6599\u91d1 \n** \u6642\u9593\u5358\u4f4d\u306e\u30b7\u30e3\u30fc\u30c9\u901f\u5ea6\uff08\u53d6\u5f97\u901f\u5ea6\u306f 1 MB/\u79d2\u3001\u9001\u4fe1\u901f\u5ea6\u306f 2 MB/\u79d2\uff09:  0.015 USD\n** PUT \u53d6\u5f15 1,000,000 \u500b\u3042\u305f\u308a:       0.028 USD\n\n\n\u7c21\u5358\u306a\u4f7f\u3044\u65b9\n\n\u30ec\u30b3\u30fc\u30c9\u3092\u767b\u9332\u3059\u308b (PutRecord http://docs.aws.amazon.com/kinesis/latest/APIReference/API_PutRecord.html)\n\u30ec\u30b3\u30fc\u30c9\u3092\u53d6\u5f97\u3059\u308b (GetRecord http://docs.aws.amazon.com/kinesis/latest/APIReference/API_GetRecords.html)\n\n\n\u30b3\u30fc\u30c9\u30b5\u30f3\u30d7\u30eb (Ruby)\n\n\u30ec\u30b3\u30fc\u30c9\u3092\u767b\u9332\u3059\u308b\n\n\nput.rb\nrequire 'aws-sdk'\n\nprint \"Enter target stream name: \"\nstream_name = gets.chomp\n\nbegin\n  client = AWS::Kinesis.new(\n    access_key_id: ENV['AWS_ACCESS_KEY_ID'],\n    secret_access_key: ENV['AWS_SECRET_ACCESS_KEY']).client\n\n  categories = %w{Foods Books Toys Electronics Sports Clothing Shoes Music Movies Games}\n  loop do\n    now = Time.now.to_s\n    partition_key = categories.sample\n    response = client.put_record(\n      stream_name: stream_name,\n      data: now,\n      partition_key: partition_key)\n    puts \"Data : #{now}, Partition Key : #{partition_key}, Shard Id : #{response.shard_id}, Sequence Number : #{response.sequence_number}\"\n    sleep(1)\n  end\nrescue => e\n  puts \"Error: #{e.message}\"\n  abort\nend\n\n\n\n\u30ec\u30b3\u30fc\u30c9\u3092\u53d6\u5f97\u3059\u308b\n\n\nget.rb\nrequire 'aws-sdk'\nrequire 'parallel'\n\nprint \"Enter target stream name: \"\nstream_name = gets.chomp\n\nif stream_name.empty?\n  puts \"target stream name is required\"\n  abort\nend\n\nbegin\n  client = AWS::Kinesis.new(\n    access_key_id: ENV['AWS_ACCESS_KEY_ID'],\n    secret_access_key: ENV['AWS_SECRET_ACCESS_KEY']).client\n\n  shards = client.describe_stream(stream_name: stream_name).stream_description.shards\n  shard_ids = shards.map(&:shard_id)\n\n  Parallel.each(shard_ids, in_threads: shard_ids.count) do |shard_id|\n    shard_iterator_info = client.get_shard_iterator(\n      stream_name: stream_name,\n      shard_id: shard_id,\n      shard_iterator_type: 'TRIM_HORIZON')\n\n    shard_iterator = shard_iterator_info.shard_iterator\n    loop do\n      records_info = client.get_records(\n        shard_iterator: shard_iterator,\n        limit: 100)\n\n      records_info.records.each do |record|\n        puts \"Data : #{record.data}, Partition Key : #{record.partition_key}, Shard Id : #{shard_id}, Sequence Number : #{record.sequence_number}\"\n      end\n\n      shard_iterator = records_info.next_shard_iterator\n      sleep(1)\n    end\n  end\nrescue => e\n  puts \"Error: #{e.message}\"\n  abort\nend\n\n\n\n\u305d\u306e\u4ed6\n\nfluentd \u3068\u7528\u9014\u304c\u8fd1\u3044\u3051\u308c\u3069\u3001Amazon Kinesis \u3067\u306f ThroughPut \u3092\u5411\u4e0a\u3055\u305b\u305f\u3044\u5834\u5408\u306f\u3001Shared \u306e\u6570\u3092\u5897\u52a0\u3055\u305b\u308b\u3060\u3051\u3067\u3088\u3044\nMultiStep Processing \u3082\u53ef\u80fd\nShared \u4e0a\u9650\u30c7\u30d5\u30a9\u30eb\u30c8\u6570\u304c 10\n\n\n\u53c2\u8003\u8cc7\u6599\n\nAPI \u30ea\u30d5\u30a1\u30ec\u30f3\u30b9 http://docs.aws.amazon.com/kinesis/latest/APIReference/Welcome.html\n\nAmazon Kinesis \u3053\u3068\u306f\u3058\u3081 http://www.slideshare.net/iktakahiro/amazon-kinesis-32428443\n\nRuby \u304b\u3089 Amazon Kinesis \u3092\u64cd\u4f5c\u3059\u308b http://tech-sketch.jp/2014/04/aws-kinesis-ruby.html\n\n[aws]\u30b9\u30c8\u30ea\u30fc\u30e0\u30c7\u30fc\u30bf\u51e6\u7406\u30b5\u30fc\u30d3\u30b9Amazon Kinesis\u306b\u3064\u3044\u3066\u8abf\u3079\u305f\u7d50\u679c  http://d.hatena.ne.jp/kimutansk/20131225/1387925700\n\nKinesis Wordcount \u30b5\u30f3\u30d7\u30eb https://github.com/kimutansk/storm-example-wordcount\n\nAmazon Kinesis: Real-time Streaming Big data Processing Applications (BDT311) | AWS re:Invent 2013 http://www.slideshare.net/AmazonWebServices/amazon-kinesis-realtime-streaming-big-data-processing-applications-bdt311-aws-reinvent-2013\n\n\n\nApache Kafka\n\n\u516c\u5f0f\u30b5\u30a4\u30c8 http://kafka.apache.org/\n\n\n\n\u6982\u8981\n\npublish-subscribe \u578b\u306e\u30e1\u30c3\u30bb\u30fc\u30b8\u30f3\u30b0\u30b7\u30b9\u30c6\u30e0\n\u7528\u9014\u3068\u3057\u3066\u306f\u3001\u30aa\u30d5\u30e9\u30a4\u30f3\u30fb\u30aa\u30f3\u30e9\u30a4\u30f3\u4e21\u65b9\u306e\u30e1\u30c3\u30bb\u30fc\u30b8\u53d6\u5f97\u306b\u9069\u3057\u3066\u3044\u308b\n\u5f53\u521d\u306f LinkedIn \u3067\u958b\u767a\u3055\u308c\u305f \u30e1\u30c3\u30bb\u30fc\u30b8\u30f3\u30b0\u30b7\u30b9\u30c6\u30e0\u3067\u3060\u3063\u305f\u304c\u3001Apache \u30d7\u30ed\u30b8\u30a7\u30af\u30c8\u306e\u30c8\u30c3\u30d7\u30ec\u30d9\u30eb\u30d7\u30ed\u30b8\u30a7\u30af\u30c8\u306b\u306a\u3063\u3066\u3044\u308b\n\u6700\u8fd1\u306f Tumblr\u3001DataSift \u3068\u3044\u3063\u305f\u4f01\u696d\u3067\u3082\u4f7f\u7528\u3055\u308c\u3066\u3044\u308b\u3068\u306e\u3053\u3068\n\n\n\u30b7\u30b9\u30c6\u30e0\u6982\u5ff5\u30a4\u30e1\u30fc\u30b8\n\n\u203b http://fuji-151a.hatenablog.com/entry/2014/02/23/231639 \u3088\u308a\n\n\u30af\u30e9\u30a4\u30a2\u30f3\u30c8\n\nJava, Ruby \u306a\u3069\u591a\u6570\u3042\u308a https://cwiki.apache.org/confluence/display/KAFKA/Clients\n\n\n\n\u30a4\u30f3\u30b9\u30c8\u30fc\u30eb\u65b9\u6cd5\n\nquick start \u30ac\u30a4\u30c9 http://kafka.apache.org/documentation.html#quickstart\n\n\n\n\u30b3\u30f3\u30dd\u30fc\u30cd\u30f3\u30c8\n\nmessage \u6d41\u3059\u30c7\u30fc\u30bf\ntopic message\u306e\u30ab\u30c6\u30b4\u30ea\u306e\u3053\u3068\u3001topic\u306f\u81ea\u5206\u3067\u540d\u524d\u3092\u6c7a\u3081\u308c\u308b\nbroker Kafka\u306b\u304a\u3044\u3066message\u3092\u8caf\u3081\u308b\u3068\u3053\u308d\nproducer broker\u306bmessage\u3092\u9001\u4fe1\u3059\u308bcomponent\nconsumer broker\u304b\u3089message\u3092\u8aad\u3080component\nconsumer group \u8a00\u8449\u901a\u308a\uff0cconsumer\u3092\u30b0\u30eb\u30fc\u30d4\u30f3\u30b0\u3057\u305f\u3082\u306e\uff0e\noffset consumer\u3068\u5bc6\u63a5\u306b\u95a2\u308f\u3063\u3066\u304f\u308b\u5358\u8a9e\n\u305d\u306e\u60c5\u5831\u3092\u7ba1\u7406\u3057\u3066\u3044\u308b\u306e\u306fZookeeper\u3068\u3044\u3046\u307e\u305f\u5225\u306eOSS\u3067\u3042\u308b\uff0e\n\n\n\u53c2\u8003\u8cc7\u6599\n\nApache Kafka, \u4ed6\u3068\u306f\u7570\u306a\u308b\u30e1\u30c3\u30bb\u30fc\u30b8\u30f3\u30b0\u30b7\u30b9\u30c6\u30e0 http://www.infoq.com/jp/news/2014/01/apache-afka-messaging-system\n\nApache Kafka \u5165\u9580 (kindle) http://www.amazon.co.jp/exec/obidos/ASIN/B00JU43ONW/\n\nKafka\u306b\u3088\u308b\u30ea\u30a2\u30eb\u30bf\u30a4\u30e0\u51e6\u7406 http://www.slideshare.net/yanaoki/kafka-10346557\n\nApache Kafka\u3063\u3066\u305d\u3082\u305d\u3082\u4f55\u304b\u78ba\u8a8d\u3057\u3066\u307f\u307e\u3059 http://d.hatena.ne.jp/kimutansk/20120411/1334070679\n\nApache Kafka \u3067\u4f55\u3092\u3059\u308b\u304b\u4ed6 http://open-groove.net/tag/kafka/\n\nApache Kafka \u306b\u3064\u3044\u3066 http://fuji-151a.hatenablog.com/entry/2014/02/23/231639\n\nApache Kafka RPM Spec \u30d5\u30a1\u30a4\u30eb https://github.com/kimutansk/kafka-installer\n\n\n\nStorm\n\n\u516c\u5f0f\u30b5\u30a4\u30c8 http://storm.incubator.apache.org/\n\n\n\n\u6982\u8981\n\nApache Storm is a free and open source distributed realtime computation system.\n\n\n\u30ea\u30a2\u30eb\u30bf\u30a4\u30e0\u3067\u306e\u5206\u6563\u51e6\u7406\u306e\u5b9f\u884c\u306e\u307f\u306b\u7279\u5316\n\u57fa\u672c\u7684\u306a\u30e6\u30fc\u30b9\u30b1\u30fc\u30b9\u3068\u3057\u3066\u306f\u3001\u30b9\u30c8\u30ea\u30fc\u30e0\u51e6\u7406\u3001\u7d99\u7d9a\u7684\u306a\u8a08\u7b97\u3001\u5206\u6563 RPC\n\n\n\u30b3\u30f3\u30dd\u30fc\u30cd\u30f3\u30c8\n\nTuple Storm \u3067\u51e6\u7406\u3055\u308c\u308b\u30e1\u30c3\u30bb\u30fc\u30b8\u3092\u4fdd\u6301\u3059\u308b\u30c7\u30fc\u30bf\nStream \u9014\u5207\u308c\u305a\u306b\u9023\u7d9a\u3059\u308b Tuple\nSpout Storm \u306e\u30b9\u30c8\u30ea\u30fc\u30e0\u51e6\u7406\u306e\u8d77\u70b9\u3068\u306a\u308b\nBolt Stream \u306e\u5909\u63db\u51e6\u7406\u3092\u884c\u3046\nTopology  Spult, Bolt \u304b\u3089\u306a\u308b\u30cd\u30c3\u30c8\u30ef\u30fc\u30af\u69cb\u9020\u306e\u3053\u3068\n\n\n\u53c2\u8003\u8cc7\u6599\n\nTwitter\u306e\u30ea\u30a2\u30eb\u30bf\u30a4\u30e0\u5206\u6563\u51e6\u7406\u30b7\u30b9\u30c6\u30e0\u300cStorm\u300d\u5165\u9580 http://www.slideshare.net/AdvancedTechNight/twitterstorm\n\n\u8a18\u8005\u306e\u773c - \u6fc0\u901f\u30a4\u30f3\u30d5\u30e9\u4f5c\u308b\u30cd\u30c3\u30c8\u4f01\u696d\u306e\u79d8\u5bc6\u57fa\u5730\u306b\u6f5c\u5165\uff1aITpro http://itpro.nikkeibp.co.jp/article/Watcher/20140403/548350/\n** \u30de\u30a4\u30af\u30ed\u30a2\u30c9\u3067 Storm \u304c\u5c0e\u5165\u3055\u308c\u3066\u3044\u308b\u3068\u306e\u3053\u3068\n\n\n\u305d\u306e\u4ed6\n\nApache Samza\n\nApache Samza is a distributed stream processing framework. It uses Apache Kafka for messaging, and Apache Hadoop YARN to provide fault tolerance, processor isolation, security, and resource management.\nhttp://samza.incubator.apache.org/\n\n\n\u305d\u306e\u4ed6\u306e\u30e1\u30e2\n\n\u30ed\u30b0\u53ce\u96c6\u306b\u3064\u3044\u3066\uff08kibana\u3001elasticsearch\u3001logstash\u3001Fluentd\u3001Apache Flume\u3001Splunk\uff09 - \u307a\u30fc\u307a\u30fcSE\u306e\u65e5\u8a18 http://d.hatena.ne.jp/tanakakns/20140306/1394099168\n\n\n# Amazon Kinesis\n\n## \u516c\u5f0f\u30b5\u30a4\u30c8\n* \u82f1\u8a9e http://aws.amazon.com/kinesis/\n* \u65e5\u672c\u8a9e http://aws.amazon.com/jp/kinesis/\n\n## \u6982\u8981\n* Amazon Kinesis \u306f\u3001\u5927\u898f\u6a21\u306a\u30b9\u30c8\u30ea\u30fc\u30df\u30f3\u30b0\u30c7\u30fc\u30bf\u3092\u30ea\u30a2\u30eb\u30bf\u30a4\u30e0\u3067\u51e6\u7406\u3059\u308b\u5b8c\u5168\u30de\u30cd\u30fc\u30b8\u30c9\u578b\u30b5\u30fc\u30d3\u30b9\u3067\u3059\n\n## \u5229\u7528\u53ef\u80fd\u306a\u30ea\u30fc\u30b8\u30e7\u30f3\u3068\u5229\u7528\u6599\u91d1\uff082014/06/08 \u73fe\u5728\uff09\n* \u30ea\u30fc\u30b8\u30e7\u30f3\n** \u7c73\u56fd\u6771\u90e8\uff08\u30d0\u30fc\u30b8\u30cb\u30a2\u5317\u90e8\uff09\u306e\u307f\n* \u5229\u7528\u6599\u91d1 \n** \u6642\u9593\u5358\u4f4d\u306e\u30b7\u30e3\u30fc\u30c9\u901f\u5ea6\uff08\u53d6\u5f97\u901f\u5ea6\u306f 1 MB/\u79d2\u3001\u9001\u4fe1\u901f\u5ea6\u306f 2 MB/\u79d2\uff09:\t0.015 USD\n** PUT \u53d6\u5f15 1,000,000 \u500b\u3042\u305f\u308a:\t \t0.028 USD\n\n## \u7c21\u5358\u306a\u4f7f\u3044\u65b9\n1. \u30ec\u30b3\u30fc\u30c9\u3092\u767b\u9332\u3059\u308b (PutRecord http://docs.aws.amazon.com/kinesis/latest/APIReference/API_PutRecord.html)\n2. \u30ec\u30b3\u30fc\u30c9\u3092\u53d6\u5f97\u3059\u308b (GetRecord http://docs.aws.amazon.com/kinesis/latest/APIReference/API_GetRecords.html)\n\n### \u30b3\u30fc\u30c9\u30b5\u30f3\u30d7\u30eb (Ruby)\n\n* \u30ec\u30b3\u30fc\u30c9\u3092\u767b\u9332\u3059\u308b\n\n```rb:put.rb\nrequire 'aws-sdk'\n\nprint \"Enter target stream name: \"\nstream_name = gets.chomp\n\nbegin\n  client = AWS::Kinesis.new(\n    access_key_id: ENV['AWS_ACCESS_KEY_ID'],\n    secret_access_key: ENV['AWS_SECRET_ACCESS_KEY']).client\n\n  categories = %w{Foods Books Toys Electronics Sports Clothing Shoes Music Movies Games}\n  loop do\n    now = Time.now.to_s\n    partition_key = categories.sample\n    response = client.put_record(\n      stream_name: stream_name,\n      data: now,\n      partition_key: partition_key)\n    puts \"Data : #{now}, Partition Key : #{partition_key}, Shard Id : #{response.shard_id}, Sequence Number : #{response.sequence_number}\"\n    sleep(1)\n  end\nrescue => e\n  puts \"Error: #{e.message}\"\n  abort\nend\n```\n\n* \u30ec\u30b3\u30fc\u30c9\u3092\u53d6\u5f97\u3059\u308b\n\n```rb:get.rb\nrequire 'aws-sdk'\nrequire 'parallel'\n \nprint \"Enter target stream name: \"\nstream_name = gets.chomp\n \nif stream_name.empty?\n  puts \"target stream name is required\"\n  abort\nend\n \nbegin\n  client = AWS::Kinesis.new(\n    access_key_id: ENV['AWS_ACCESS_KEY_ID'],\n    secret_access_key: ENV['AWS_SECRET_ACCESS_KEY']).client\n \n  shards = client.describe_stream(stream_name: stream_name).stream_description.shards\n  shard_ids = shards.map(&:shard_id)\n \n  Parallel.each(shard_ids, in_threads: shard_ids.count) do |shard_id|\n    shard_iterator_info = client.get_shard_iterator(\n      stream_name: stream_name,\n      shard_id: shard_id,\n      shard_iterator_type: 'TRIM_HORIZON')\n \n    shard_iterator = shard_iterator_info.shard_iterator\n    loop do\n      records_info = client.get_records(\n        shard_iterator: shard_iterator,\n        limit: 100)\n \n      records_info.records.each do |record|\n        puts \"Data : #{record.data}, Partition Key : #{record.partition_key}, Shard Id : #{shard_id}, Sequence Number : #{record.sequence_number}\"\n      end\n \n      shard_iterator = records_info.next_shard_iterator\n      sleep(1)\n    end\n  end\nrescue => e\n  puts \"Error: #{e.message}\"\n  abort\nend\n```\n\n## \u305d\u306e\u4ed6\n* fluentd \u3068\u7528\u9014\u304c\u8fd1\u3044\u3051\u308c\u3069\u3001Amazon Kinesis \u3067\u306f ThroughPut \u3092\u5411\u4e0a\u3055\u305b\u305f\u3044\u5834\u5408\u306f\u3001Shared \u306e\u6570\u3092\u5897\u52a0\u3055\u305b\u308b\u3060\u3051\u3067\u3088\u3044\n* MultiStep Processing \u3082\u53ef\u80fd\n* Shared \u4e0a\u9650\u30c7\u30d5\u30a9\u30eb\u30c8\u6570\u304c 10\n\n## \u53c2\u8003\u8cc7\u6599\n* API \u30ea\u30d5\u30a1\u30ec\u30f3\u30b9 http://docs.aws.amazon.com/kinesis/latest/APIReference/Welcome.html\n* Amazon Kinesis \u3053\u3068\u306f\u3058\u3081 http://www.slideshare.net/iktakahiro/amazon-kinesis-32428443\n* Ruby \u304b\u3089 Amazon Kinesis \u3092\u64cd\u4f5c\u3059\u308b http://tech-sketch.jp/2014/04/aws-kinesis-ruby.html\n* [aws]\u30b9\u30c8\u30ea\u30fc\u30e0\u30c7\u30fc\u30bf\u51e6\u7406\u30b5\u30fc\u30d3\u30b9Amazon Kinesis\u306b\u3064\u3044\u3066\u8abf\u3079\u305f\u7d50\u679c  http://d.hatena.ne.jp/kimutansk/20131225/1387925700\n* Kinesis Wordcount \u30b5\u30f3\u30d7\u30eb https://github.com/kimutansk/storm-example-wordcount\n* Amazon Kinesis: Real-time Streaming Big data Processing Applications (BDT311) | AWS re:Invent 2013 http://www.slideshare.net/AmazonWebServices/amazon-kinesis-realtime-streaming-big-data-processing-applications-bdt311-aws-reinvent-2013\n\n\n\n# Apache Kafka\n* \u516c\u5f0f\u30b5\u30a4\u30c8 http://kafka.apache.org/\n\n## \u6982\u8981\n* publish-subscribe \u578b\u306e\u30e1\u30c3\u30bb\u30fc\u30b8\u30f3\u30b0\u30b7\u30b9\u30c6\u30e0\n* \u7528\u9014\u3068\u3057\u3066\u306f\u3001\u30aa\u30d5\u30e9\u30a4\u30f3\u30fb\u30aa\u30f3\u30e9\u30a4\u30f3\u4e21\u65b9\u306e\u30e1\u30c3\u30bb\u30fc\u30b8\u53d6\u5f97\u306b\u9069\u3057\u3066\u3044\u308b\n* \u5f53\u521d\u306f LinkedIn \u3067\u958b\u767a\u3055\u308c\u305f \u30e1\u30c3\u30bb\u30fc\u30b8\u30f3\u30b0\u30b7\u30b9\u30c6\u30e0\u3067\u3060\u3063\u305f\u304c\u3001Apache \u30d7\u30ed\u30b8\u30a7\u30af\u30c8\u306e\u30c8\u30c3\u30d7\u30ec\u30d9\u30eb\u30d7\u30ed\u30b8\u30a7\u30af\u30c8\u306b\u306a\u3063\u3066\u3044\u308b\n* \u6700\u8fd1\u306f Tumblr\u3001DataSift \u3068\u3044\u3063\u305f\u4f01\u696d\u3067\u3082\u4f7f\u7528\u3055\u308c\u3066\u3044\u308b\u3068\u306e\u3053\u3068\n\n\n## \u30b7\u30b9\u30c6\u30e0\u6982\u5ff5\u30a4\u30e1\u30fc\u30b8\n![20140223221420.png](https://qiita-image-store.s3.amazonaws.com/0/37318/2ba53fd8-3179-992f-5781-9c43745404e2.png)\n\u203b http://fuji-151a.hatenablog.com/entry/2014/02/23/231639 \u3088\u308a\n\n## \u30af\u30e9\u30a4\u30a2\u30f3\u30c8\n* Java, Ruby \u306a\u3069\u591a\u6570\u3042\u308a https://cwiki.apache.org/confluence/display/KAFKA/Clients\n\n## \u30a4\u30f3\u30b9\u30c8\u30fc\u30eb\u65b9\u6cd5\n* quick start \u30ac\u30a4\u30c9 http://kafka.apache.org/documentation.html#quickstart\n\n## \u30b3\u30f3\u30dd\u30fc\u30cd\u30f3\u30c8\n* message \u6d41\u3059\u30c7\u30fc\u30bf\n* topic message\u306e\u30ab\u30c6\u30b4\u30ea\u306e\u3053\u3068\u3001topic\u306f\u81ea\u5206\u3067\u540d\u524d\u3092\u6c7a\u3081\u308c\u308b\n* broker Kafka\u306b\u304a\u3044\u3066message\u3092\u8caf\u3081\u308b\u3068\u3053\u308d\n* producer broker\u306bmessage\u3092\u9001\u4fe1\u3059\u308bcomponent\n* consumer broker\u304b\u3089message\u3092\u8aad\u3080component\n* consumer group \u8a00\u8449\u901a\u308a\uff0cconsumer\u3092\u30b0\u30eb\u30fc\u30d4\u30f3\u30b0\u3057\u305f\u3082\u306e\uff0e\n* offset consumer\u3068\u5bc6\u63a5\u306b\u95a2\u308f\u3063\u3066\u304f\u308b\u5358\u8a9e\n\u305d\u306e\u60c5\u5831\u3092\u7ba1\u7406\u3057\u3066\u3044\u308b\u306e\u306fZookeeper\u3068\u3044\u3046\u307e\u305f\u5225\u306eOSS\u3067\u3042\u308b\uff0e\n\n## \u53c2\u8003\u8cc7\u6599\n* Apache Kafka, \u4ed6\u3068\u306f\u7570\u306a\u308b\u30e1\u30c3\u30bb\u30fc\u30b8\u30f3\u30b0\u30b7\u30b9\u30c6\u30e0 http://www.infoq.com/jp/news/2014/01/apache-afka-messaging-system\n* Apache Kafka \u5165\u9580 (kindle) http://www.amazon.co.jp/exec/obidos/ASIN/B00JU43ONW/\n* Kafka\u306b\u3088\u308b\u30ea\u30a2\u30eb\u30bf\u30a4\u30e0\u51e6\u7406 http://www.slideshare.net/yanaoki/kafka-10346557\n* Apache Kafka\u3063\u3066\u305d\u3082\u305d\u3082\u4f55\u304b\u78ba\u8a8d\u3057\u3066\u307f\u307e\u3059 http://d.hatena.ne.jp/kimutansk/20120411/1334070679\n* Apache Kafka \u3067\u4f55\u3092\u3059\u308b\u304b\u4ed6 http://open-groove.net/tag/kafka/\n* Apache Kafka \u306b\u3064\u3044\u3066 http://fuji-151a.hatenablog.com/entry/2014/02/23/231639\n* Apache Kafka RPM Spec \u30d5\u30a1\u30a4\u30eb https://github.com/kimutansk/kafka-installer\n\n\n# Storm\n* \u516c\u5f0f\u30b5\u30a4\u30c8 http://storm.incubator.apache.org/\n\n## \u6982\u8981\n* Apache Storm is a free and open source distributed realtime computation system.\n![topology.png](https://qiita-image-store.s3.amazonaws.com/0/37318/b3133e66-a9d5-98ed-6a55-af1a38642cbe.png)\n* \u30ea\u30a2\u30eb\u30bf\u30a4\u30e0\u3067\u306e\u5206\u6563\u51e6\u7406\u306e\u5b9f\u884c\u306e\u307f\u306b\u7279\u5316\n* \u57fa\u672c\u7684\u306a\u30e6\u30fc\u30b9\u30b1\u30fc\u30b9\u3068\u3057\u3066\u306f\u3001\u30b9\u30c8\u30ea\u30fc\u30e0\u51e6\u7406\u3001\u7d99\u7d9a\u7684\u306a\u8a08\u7b97\u3001\u5206\u6563 RPC\n\n## \u30b3\u30f3\u30dd\u30fc\u30cd\u30f3\u30c8\n* Tuple Storm \u3067\u51e6\u7406\u3055\u308c\u308b\u30e1\u30c3\u30bb\u30fc\u30b8\u3092\u4fdd\u6301\u3059\u308b\u30c7\u30fc\u30bf\n* Stream \u9014\u5207\u308c\u305a\u306b\u9023\u7d9a\u3059\u308b Tuple\n* Spout Storm \u306e\u30b9\u30c8\u30ea\u30fc\u30e0\u51e6\u7406\u306e\u8d77\u70b9\u3068\u306a\u308b\n* Bolt Stream \u306e\u5909\u63db\u51e6\u7406\u3092\u884c\u3046\n* Topology  Spult, Bolt \u304b\u3089\u306a\u308b\u30cd\u30c3\u30c8\u30ef\u30fc\u30af\u69cb\u9020\u306e\u3053\u3068\n \n\n## \u53c2\u8003\u8cc7\u6599\n* Twitter\u306e\u30ea\u30a2\u30eb\u30bf\u30a4\u30e0\u5206\u6563\u51e6\u7406\u30b7\u30b9\u30c6\u30e0\u300cStorm\u300d\u5165\u9580 http://www.slideshare.net/AdvancedTechNight/twitterstorm\n* \u8a18\u8005\u306e\u773c - \u6fc0\u901f\u30a4\u30f3\u30d5\u30e9\u4f5c\u308b\u30cd\u30c3\u30c8\u4f01\u696d\u306e\u79d8\u5bc6\u57fa\u5730\u306b\u6f5c\u5165\uff1aITpro http://itpro.nikkeibp.co.jp/article/Watcher/20140403/548350/\n** \u30de\u30a4\u30af\u30ed\u30a2\u30c9\u3067 Storm \u304c\u5c0e\u5165\u3055\u308c\u3066\u3044\u308b\u3068\u306e\u3053\u3068\n\n\n# \u305d\u306e\u4ed6\n\n## Apache Samza\n* Apache Samza is a distributed stream processing framework. It uses Apache Kafka for messaging, and Apache Hadoop YARN to provide fault tolerance, processor isolation, security, and resource management.\n* http://samza.incubator.apache.org/\n\n## \u305d\u306e\u4ed6\u306e\u30e1\u30e2\n* \u30ed\u30b0\u53ce\u96c6\u306b\u3064\u3044\u3066\uff08kibana\u3001elasticsearch\u3001logstash\u3001Fluentd\u3001Apache Flume\u3001Splunk\uff09 - \u307a\u30fc\u307a\u30fcSE\u306e\u65e5\u8a18 http://d.hatena.ne.jp/tanakakns/20140306/1394099168\n", "tags": ["Kinesis", "Kafka", "storm"]}