{"context": "\n\n\u6ce8\u610f\n\n\u4e00\u6642\u7684\u306a\u691c\u8a3c\u76ee\u7684\u306a\u306e\u3067\u30bb\u30ad\u30e5\u30ea\u30c6\u30a3\u306a\u3069\u8003\u616e\u3057\u306a\u3044\u8a2d\u5b9a\u306b\u306a\u3063\u3066\u3044\u308b\u90e8\u5206\u304c\u3042\u308b\u306e\u3067\u3054\u6ce8\u610f\u3092\u3002\n\n\n\u74b0\u5883\u6982\u8981\n\nEMR\n\nm3.xlarge * 3(master 1, slave 2)\n\n\nAuroraDB\n\ndb.r3.large\n\u30c6\u30b9\u30c8\u30c6\u30fc\u30d6\u30eb\n\n CREATE DATABASE sqoop_test;\n\n GRANT ALL PRIVILEGES ON sqoop_test.* TO sqoopuser IDENTIFIED BY 'sqoopuser999' WITH GRANT OPTION;\n FLUSH PRIVILEGES;\n\n CREATE TABLE `sqoop_test_utf8` (\n   `key1` char(4) NOT NULL DEFAULT '',\n   `code1` varchar(10) DEFAULT NULL,   \n   `item1` varchar(10) DEFAULT NULL,   \n   PRIMARY KEY (`key1`) ) ENGINE=InnoDB  DEFAULT CHARSET=utf8;\n\n insert into sqoop_test_utf8 values('A001', 'shibuya_001', 'book');\n  insert into sqoop_test_utf8 values('A002', 'shibuya_002', 'DVD');\n  insert into sqoop_test_utf8 values('B003', 'shinagawa_001', 'stationery');\n  insert into sqoop_test_utf8 values('C004', 'ebisu_001', 'dictionary');\n  insert into sqoop_test_utf8 values('D005', 'meguro_001', 'book');\n\n\n\u901a\u4fe1\u8a2d\u5b9a\n\nAurora <- EMR(3\u53f0\u3068\u3082):3306\n\n\nSqoop\u3059\u308b\u6e96\u5099(EMR\u306eMaster\u30ce\u30fc\u30c9\u3067\u5b9f\u65bd)\n\nSqoop\u306e\u30a4\u30f3\u30b9\u30c8\u30fc\u30eb\n$ cd /tmp\n$ curl -OL http://ftp.tsukuba.wide.ad.jp/software/apache/sqoop/1.4.6/sqoop-1.4.6.bin__hadoop-2.0.4-alpha.tar.gz\n$ tar zxvf sqoop-1.4.6.bin__hadoop-2.0.4-alpha.tar.gz\n\n\nmariadb jdbc\u306e\u914d\u7f6e\n$ cd /tmp\n$ curl -OL https://downloads.mariadb.com/enterprise/rs6a-06j2/connectors/java/connector-java-1.3.6/mariadb-java-client-1.3.6.jar\n$ cp mariadb-java-client-1.3.6.jar /tmp/sqoop-1.4.6.bin__hadoop-2.0.4-alpha/lib/\n\n\nmysql jdbc\u306e\u914d\u7f6e\n$ cd /tmp\n$ curl -LO http://dev.mysql.com/get/Downloads/Connector-J/mysql-connector-java-5.1.38.tar.gz\n$ tar zxvf mysql-connector-java-5.1.38.tar.gz\n$ cd mysql-connector-java-5.1.38\n$ cp mysql-connector-java-5.1.38-bin.jar /tmp/sqoop-1.4.6.bin__hadoop-2.0.4-alpha/lib/\n\n\nSqoop\u5b9f\u884c\n\nUsing mysql driver\n$ ./sqoop import --connect jdbc:mysql://<Aurora\u306e\u30af\u30e9\u30b9\u30bf\u30fc\u30a8\u30f3\u30c9\u30dd\u30a4\u30f3\u30c8>/sqoop_test --username sqoopuser --password sqoopuser999 --table sqoop_test_utf8\n\n\nUsing mariadb driver\n$ ./sqoop import --connect jdbc:mysql://<Aurora\u306e\u30af\u30e9\u30b9\u30bf\u30fc\u30a8\u30f3\u30c9\u30dd\u30a4\u30f3\u30c8>/sqoop_test --username sqoopuser --password sqoopuser999 --table sqoop_test_utf8 --driver org.mariadb.jdbc.Driver\n\n\nhive import\n$ ./sqoop import --connect jdbc:mysql://test-cluster.cluster-cxkmqunzhbcv.us-east-1.rds.amazonaws.com/sqoop_test --username sqoopuser --password sqoopuser999 --table sqoop_test_utf8 --driver org.mariadb.jdbc.Driver --hive-import --hive-table sqoop_test\n\n\n\u30c7\u30fc\u30bf\u78ba\u8a8d\n\n hive> select * from sqoop_test;\nOK\nA001    shibuya_00  book\nA002    shibuya_00  DVD\nB003    shinagawa_  stationery\nC004    ebisu_001   dictionary\nD005    meguro_001  book\nTime taken: 0.786 seconds, Fetched: 5 row(s)\n\n\n\u305d\u306e\u4ed6\n\n\u30c6\u30fc\u30d6\u30eb\u306e\u6587\u5b57\u30b3\u30fc\u30c9\u3068sqoop\u5074\u306e\u6587\u5b57\u30b3\u30fc\u30c9\u306e\u9055\u3044\u3067\u30a8\u30e9\u30fc\uff1f\n\n\u30c6\u30fc\u30d6\u30eb\u306e\u6587\u5b57\u30b3\u30fc\u30c9\u3092latin1\u306b\u3057\u3066\u3044\u308b\u3068\u4ee5\u4e0b\u306e\u30a8\u30e9\u30fc\u304c\u51fa\u3066\u30b8\u30e7\u30d6\u304c\u5931\u6557\u3057\u305f\u3002\u306a\u306e\u3067\u3001\u4e0a\u8a18\u3067\u300cutf-8\u300d\u306b\u3057\u3066\u3044\u308b\u3002\n\u3084\u3063\u3066\u306f\u3044\u306a\u3044\u304c\u3001Sqoop\u5074\u3067\u5bfe\u5fdc\u3059\u308b\u5834\u5408\u3001\u300c--connection-param-file\u300d\u3092\u4f7f\u3063\u3066\u300ccharacterEncoding\u300d\u3067\u6307\u5b9a\u3057\u3066\u3084\u308c\u3070\u884c\u3051\u308b\u306e\u304b\u306a\u3002\n\u30a8\u30e9\u30fc\u30ed\u30b0\n\n 16/03/09 06:41:21 INFO mapreduce.Job: Task Id : attempt_1457497192768_0001_m_000000_2, Status : FAILED\nError: java.io.IOException: SQLException in nextKeyValue\n    at org.apache.sqoop.mapreduce.db.DBRecordReader.nextKeyValue(DBRecordReader.java:277)\n    at org.apache.hadoop.mapred.MapTask$NewTrackingRecordReader.nextKeyValue(MapTask.java:565)\n    at org.apache.hadoop.mapreduce.task.MapContextImpl.nextKeyValue(MapContextImpl.java:80)\n    at org.apache.hadoop.mapreduce.lib.map.WrappedMapper$Context.nextKeyValue(WrappedMapper.java:91)\n    at org.apache.hadoop.mapreduce.Mapper.run(Mapper.java:152)\n    at org.apache.sqoop.mapreduce.AutoProgressMapper.run(AutoProgressMapper.java:64)\n    at org.apache.hadoop.mapred.MapTask.runNewMapper(MapTask.java:796)\n    at org.apache.hadoop.mapred.MapTask.run(MapTask.java:342)\n    at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:172)\n    at java.security.AccessController.doPrivileged(Native Method)\n    at javax.security.auth.Subject.doAs(Subject.java:415)\n    at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1657)\n    at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:166)\nCaused by: java.sql.SQLException: Illegal mix of collations (latin1_swedish_ci,IMPLICIT) and (utf8_general_ci,COERCIBLE) for operation '<'\n    at org.mariadb.jdbc.internal.SQLExceptionMapper.get(SQLExceptionMapper.java:149)\n    at org.mariadb.jdbc.internal.SQLExceptionMapper.throwException(SQLExceptionMapper.java:106)\n    at org.mariadb.jdbc.MySQLStatement.executeQueryEpilog(MySQLStatement.java:252)\n    at org.mariadb.jdbc.MySQLStatement.execute(MySQLStatement.java:278)\n    at org.mariadb.jdbc.MySQLStatement.executeQuery(MySQLStatement.java:333)\n    at org.mariadb.jdbc.MySQLPreparedStatement.executeQuery(MySQLPreparedStatement.java:99)\n    at org.apache.sqoop.mapreduce.db.DBRecordReader.executeQuery(DBRecordReader.java:111)\n    at org.apache.sqoop.mapreduce.db.DBRecordReader.nextKeyValue(DBRecordReader.java:235)\n    ... 12 more\n\n\n\u53c2\u8003\uff1a\u5b9f\u884c\u7d50\u679c\n\nmysql driver\n\n Warning: /mnt/tmp/sqoop-1.4.6.bin__hadoop-2.0.4-alpha/bin/../../hcatalog does not exist! HCatalog jobs will fail.\nPlease set $HCAT_HOME to the root of your HCatalog installation.\nWarning: /mnt/tmp/sqoop-1.4.6.bin__hadoop-2.0.4-alpha/bin/../../accumulo does not exist! Accumulo imports will fail.\nPlease set $ACCUMULO_HOME to the root of your Accumulo installation.\n16/03/09 06:53:02 INFO sqoop.Sqoop: Running Sqoop version: 1.4.6\n16/03/09 06:53:02 WARN tool.BaseSqoopTool: Setting your password on the command-line is insecure. Consider using -P instead.\n16/03/09 06:53:02 INFO manager.MySQLManager: Preparing to use a MySQL streaming resultset.\n16/03/09 06:53:02 INFO tool.CodeGenTool: Beginning code generation\n16/03/09 06:53:02 INFO manager.SqlManager: Executing SQL statement: SELECT t.* FROM `sqoop_test_utf8` AS t LIMIT 1\n16/03/09 06:53:02 INFO manager.SqlManager: Executing SQL statement: SELECT t.* FROM `sqoop_test_utf8` AS t LIMIT 1\n16/03/09 06:53:02 INFO orm.CompilationManager: HADOOP_MAPRED_HOME is /usr/lib/hadoop-mapreduce\n\u6ce8\u610f:/tmp/sqoop-hadoop/compile/f5749f4d128f954b02ac58ff6e31a933/sqoop_test_utf8.java\u306f\u975e\u63a8\u5968\u306eAPI\u3092\u4f7f\u7528\u307e\u305f\u306f\u30aa\u30fc\u30d0\u30fc\u30e9\u30a4\u30c9\u3057\u3066\u3044\u307e\u3059\u3002\n\u6ce8\u610f:\u8a73\u7d30\u306f\u3001-Xlint:deprecation\u30aa\u30d7\u30b7\u30e7\u30f3\u3092\u6307\u5b9a\u3057\u3066\u518d\u30b3\u30f3\u30d1\u30a4\u30eb\u3057\u3066\u304f\u3060\u3055\u3044\u3002\n16/03/09 06:53:04 INFO orm.CompilationManager: Writing jar file: /tmp/sqoop-hadoop/compile/f5749f4d128f954b02ac58ff6e31a933/sqoop_test_utf8.jar\n16/03/09 06:53:04 WARN manager.MySQLManager: It looks like you are importing from mysql.\n16/03/09 06:53:04 WARN manager.MySQLManager: This transfer can be faster! Use the --direct\n16/03/09 06:53:04 WARN manager.MySQLManager: option to exercise a MySQL-specific fast path.\n16/03/09 06:53:04 INFO manager.MySQLManager: Setting zero DATETIME behavior to convertToNull (mysql)\n16/03/09 06:53:04 INFO mapreduce.ImportJobBase: Beginning import of sqoop_test_utf8\n16/03/09 06:53:05 INFO Configuration.deprecation: mapred.jar is deprecated. Instead, use mapreduce.job.jar\n16/03/09 06:53:05 INFO Configuration.deprecation: mapred.map.tasks is deprecated. Instead, use mapreduce.job.maps\n16/03/09 06:53:05 INFO client.RMProxy: Connecting to ResourceManager at ip-172-31-55-2.ec2.internal/172.31.55.2:8032\n16/03/09 06:53:06 INFO metrics.MetricsSaver: MetricsConfigRecord disabledInCluster: false instanceEngineCycleSec: 60 clusterEngineCycleSec: 60 disableClusterEngine: false maxMemoryMb: 3072 maxInstanceCount: 500 lastModified: 1457497199168\n16/03/09 06:53:06 INFO metrics.MetricsSaver: Created MetricsSaver j-3UO8LO9Y9U00I:i-81fac878:Sqoop:05010 period:60 /mnt/var/em/raw/i-81fac878_20160309_Sqoop_05010_raw.bin\n16/03/09 06:53:07 INFO db.DBInputFormat: Using read commited transaction isolation\n16/03/09 06:53:07 INFO db.DataDrivenDBInputFormat: BoundingValsQuery: SELECT MIN(`key1`), MAX(`key1`) FROM `sqoop_test_utf8`\n16/03/09 06:53:07 WARN db.TextSplitter: Generating splits for a textual index column.\n16/03/09 06:53:07 WARN db.TextSplitter: If your database sorts in a case-insensitive order, this may result in a partial import or duplicate records.\n16/03/09 06:53:07 WARN db.TextSplitter: You are strongly encouraged to choose an integral split column.\n16/03/09 06:53:07 INFO mapreduce.JobSubmitter: number of splits:4\n16/03/09 06:53:07 INFO mapreduce.JobSubmitter: Submitting tokens for job: job_1457497192768_0002\n16/03/09 06:53:08 INFO impl.YarnClientImpl: Submitted application application_1457497192768_0002\n16/03/09 06:53:08 INFO mapreduce.Job: The url to track the job: http://ip-172-31-55-2.ec2.internal:20888/proxy/application_1457497192768_0002/\n16/03/09 06:53:08 INFO mapreduce.Job: Running job: job_1457497192768_0002\n16/03/09 06:53:15 INFO mapreduce.Job: Job job_1457497192768_0002 running in uber mode : false\n16/03/09 06:53:15 INFO mapreduce.Job:  map 0% reduce 0%\n16/03/09 06:53:23 INFO mapreduce.Job:  map 50% reduce 0%\n16/03/09 06:53:24 INFO mapreduce.Job:  map 100% reduce 0%\n16/03/09 06:53:24 INFO mapreduce.Job: Job job_1457497192768_0002 completed successfully\n16/03/09 06:53:24 INFO mapreduce.Job: Counters: 30\n    File System Counters\n        FILE: Number of bytes read=0\n        FILE: Number of bytes written=565716\n        FILE: Number of read operations=0\n        FILE: Number of large read operations=0\n        FILE: Number of write operations=0\n        HDFS: Number of bytes read=461\n        HDFS: Number of bytes written=115\n        HDFS: Number of read operations=16\n        HDFS: Number of large read operations=0\n        HDFS: Number of write operations=8\n    Job Counters\n        Launched map tasks=4\n        Other local map tasks=4\n        Total time spent by all maps in occupied slots (ms)=1013580\n        Total time spent by all reduces in occupied slots (ms)=0\n        Total time spent by all map tasks (ms)=22524\n        Total vcore-seconds taken by all map tasks=22524\n        Total megabyte-seconds taken by all map tasks=32434560\n    Map-Reduce Framework\n        Map input records=5\n        Map output records=5\n        Input split bytes=461\n        Spilled Records=0\n        Failed Shuffles=0\n        Merged Map outputs=0\n        GC time elapsed (ms)=286\n        CPU time spent (ms)=4590\n        Physical memory (bytes) snapshot=869433344\n        Virtual memory (bytes) snapshot=8212455424\n        Total committed heap usage (bytes)=1195376640\n    File Input Format Counters\n        Bytes Read=0\n    File Output Format Counters\n        Bytes Written=115\n16/03/09 06:53:24 INFO mapreduce.ImportJobBase: Transferred 115 bytes in 18.7289 seconds (6.1403 bytes/sec)\n16/03/09 06:53:24 INFO mapreduce.ImportJobBase: Retrieved 5 records.\n\n\nmariadb driver\n\n Warning: /mnt/tmp/sqoop-1.4.6.bin__hadoop-2.0.4-alpha/bin/../../hcatalog does not exist! HCatalog jobs will fail.\nPlease set $HCAT_HOME to the root of your HCatalog installation.\nWarning: /mnt/tmp/sqoop-1.4.6.bin__hadoop-2.0.4-alpha/bin/../../accumulo does not exist! Accumulo imports will fail.\nPlease set $ACCUMULO_HOME to the root of your Accumulo installation.\n16/03/09 06:58:22 INFO sqoop.Sqoop: Running Sqoop version: 1.4.6\n16/03/09 06:58:22 WARN tool.BaseSqoopTool: Setting your password on the command-line is insecure. Consider using -P instead.\n16/03/09 06:58:22 WARN sqoop.ConnFactory: Parameter --driver is set to an explicit driver however appropriate connection manager is not being set (via --connection-manager). Sqoop is going to fall back to org.apache.sqoop.manager.GenericJdbcManager. Please specify explicitly which connection manager should be used next time.\n16/03/09 06:58:22 INFO manager.SqlManager: Using default fetchSize of 1000\n16/03/09 06:58:22 INFO tool.CodeGenTool: Beginning code generation\n16/03/09 06:58:22 INFO manager.SqlManager: Executing SQL statement: SELECT t.* FROM sqoop_test_utf8 AS t WHERE 1=0\n16/03/09 06:58:22 INFO manager.SqlManager: Executing SQL statement: SELECT t.* FROM sqoop_test_utf8 AS t WHERE 1=0\n16/03/09 06:58:22 INFO orm.CompilationManager: HADOOP_MAPRED_HOME is /usr/lib/hadoop-mapreduce\n\u6ce8\u610f:/tmp/sqoop-hadoop/compile/131e4ef66f3fe8206ed85367ddc6aa87/sqoop_test_utf8.java\u306f\u975e\u63a8\u5968\u306eAPI\u3092\u4f7f\u7528\u307e\u305f\u306f\u30aa\u30fc\u30d0\u30fc\u30e9\u30a4\u30c9\u3057\u3066\u3044\u307e\u3059\u3002\n\u6ce8\u610f:\u8a73\u7d30\u306f\u3001-Xlint:deprecation\u30aa\u30d7\u30b7\u30e7\u30f3\u3092\u6307\u5b9a\u3057\u3066\u518d\u30b3\u30f3\u30d1\u30a4\u30eb\u3057\u3066\u304f\u3060\u3055\u3044\u3002\n16/03/09 06:58:24 INFO orm.CompilationManager: Writing jar file: /tmp/sqoop-hadoop/compile/131e4ef66f3fe8206ed85367ddc6aa87/sqoop_test_utf8.jar\n16/03/09 06:58:24 INFO mapreduce.ImportJobBase: Beginning import of sqoop_test_utf8\n16/03/09 06:58:25 INFO Configuration.deprecation: mapred.jar is deprecated. Instead, use mapreduce.job.jar\n16/03/09 06:58:25 INFO manager.SqlManager: Executing SQL statement: SELECT t.* FROM sqoop_test_utf8 AS t WHERE 1=0\n16/03/09 06:58:25 INFO Configuration.deprecation: mapred.map.tasks is deprecated. Instead, use mapreduce.job.maps\n16/03/09 06:58:26 INFO client.RMProxy: Connecting to ResourceManager at ip-172-31-55-2.ec2.internal/172.31.55.2:8032\n16/03/09 06:58:26 INFO metrics.MetricsSaver: MetricsConfigRecord disabledInCluster: false instanceEngineCycleSec: 60 clusterEngineCycleSec: 60 disableClusterEngine: false maxMemoryMb: 3072 maxInstanceCount: 500 lastModified: 1457497199168\n16/03/09 06:58:26 INFO metrics.MetricsSaver: Created MetricsSaver j-3UO8LO9Y9U00I:i-81fac878:Sqoop:07626 period:60 /mnt/var/em/raw/i-81fac878_20160309_Sqoop_07626_raw.bin\n16/03/09 06:58:27 INFO db.DBInputFormat: Using read commited transaction isolation\n16/03/09 06:58:27 INFO db.DataDrivenDBInputFormat: BoundingValsQuery: SELECT MIN(key1), MAX(key1) FROM sqoop_test_utf8\n16/03/09 06:58:27 WARN db.TextSplitter: Generating splits for a textual index column.\n16/03/09 06:58:27 WARN db.TextSplitter: If your database sorts in a case-insensitive order, this may result in a partial import or duplicate records.\n16/03/09 06:58:27 WARN db.TextSplitter: You are strongly encouraged to choose an integral split column.\n16/03/09 06:58:27 INFO mapreduce.JobSubmitter: number of splits:4\n16/03/09 06:58:28 INFO metrics.MetricsSaver: 1 aggregated HDFSWriteDelay 306 raw values into 2 aggregated values, total 2\n16/03/09 06:58:28 INFO mapreduce.JobSubmitter: Submitting tokens for job: job_1457497192768_0003\n16/03/09 06:58:28 INFO impl.YarnClientImpl: Submitted application application_1457497192768_0003\n16/03/09 06:58:28 INFO mapreduce.Job: The url to track the job: http://ip-172-31-55-2.ec2.internal:20888/proxy/application_1457497192768_0003/\n16/03/09 06:58:28 INFO mapreduce.Job: Running job: job_1457497192768_0003\n16/03/09 06:58:35 INFO mapreduce.Job: Job job_1457497192768_0003 running in uber mode : false\n16/03/09 06:58:35 INFO mapreduce.Job:  map 0% reduce 0%\n16/03/09 06:58:43 INFO mapreduce.Job:  map 25% reduce 0%\n16/03/09 06:58:44 INFO mapreduce.Job:  map 75% reduce 0%\n16/03/09 06:58:45 INFO mapreduce.Job:  map 100% reduce 0%\n16/03/09 06:58:45 INFO mapreduce.Job: Job job_1457497192768_0003 completed successfully\n16/03/09 06:58:45 INFO mapreduce.Job: Counters: 30\n    File System Counters\n        FILE: Number of bytes read=0\n        FILE: Number of bytes written=565504\n        FILE: Number of read operations=0\n        FILE: Number of large read operations=0\n        FILE: Number of write operations=0\n        HDFS: Number of bytes read=445\n        HDFS: Number of bytes written=115\n        HDFS: Number of read operations=16\n        HDFS: Number of large read operations=0\n        HDFS: Number of write operations=8\n    Job Counters\n        Launched map tasks=4\n        Other local map tasks=4\n        Total time spent by all maps in occupied slots (ms)=1054530\n        Total time spent by all reduces in occupied slots (ms)=0\n        Total time spent by all map tasks (ms)=23434\n        Total vcore-seconds taken by all map tasks=23434\n        Total megabyte-seconds taken by all map tasks=33744960\n    Map-Reduce Framework\n        Map input records=5\n        Map output records=5\n        Input split bytes=445\n        Spilled Records=0\n        Failed Shuffles=0\n        Merged Map outputs=0\n        GC time elapsed (ms)=292\n        CPU time spent (ms)=5630\n        Physical memory (bytes) snapshot=992595968\n        Virtual memory (bytes) snapshot=8235737088\n        Total committed heap usage (bytes)=1195376640\n    File Input Format Counters\n        Bytes Read=0\n    File Output Format Counters\n        Bytes Written=115\n16/03/09 06:58:45 INFO mapreduce.ImportJobBase: Transferred 115 bytes in 19.782 seconds (5.8134 bytes/sec)\n16/03/09 06:58:45 INFO mapreduce.ImportJobBase: Retrieved 5 records.\n\n\n## \u6ce8\u610f\n* \u4e00\u6642\u7684\u306a\u691c\u8a3c\u76ee\u7684\u306a\u306e\u3067\u30bb\u30ad\u30e5\u30ea\u30c6\u30a3\u306a\u3069\u8003\u616e\u3057\u306a\u3044\u8a2d\u5b9a\u306b\u306a\u3063\u3066\u3044\u308b\u90e8\u5206\u304c\u3042\u308b\u306e\u3067\u3054\u6ce8\u610f\u3092\u3002\n\n## \u74b0\u5883\u6982\u8981\n### EMR\n* m3.xlarge * 3(master 1, slave 2)\n\n### AuroraDB\n* db.r3.large\n* \u30c6\u30b9\u30c8\u30c6\u30fc\u30d6\u30eb\n\n ```\n CREATE DATABASE sqoop_test;\n \n GRANT ALL PRIVILEGES ON sqoop_test.* TO sqoopuser IDENTIFIED BY 'sqoopuser999' WITH GRANT OPTION;\n FLUSH PRIVILEGES;\n \n CREATE TABLE `sqoop_test_utf8` (\n   `key1` char(4) NOT NULL DEFAULT '',\n   `code1` varchar(10) DEFAULT NULL,   \n   `item1` varchar(10) DEFAULT NULL,   \n   PRIMARY KEY (`key1`) ) ENGINE=InnoDB  DEFAULT CHARSET=utf8;\n   \n insert into sqoop_test_utf8 values('A001', 'shibuya_001', 'book');\n  insert into sqoop_test_utf8 values('A002', 'shibuya_002', 'DVD');\n  insert into sqoop_test_utf8 values('B003', 'shinagawa_001', 'stationery');\n  insert into sqoop_test_utf8 values('C004', 'ebisu_001', 'dictionary');\n  insert into sqoop_test_utf8 values('D005', 'meguro_001', 'book');\n ```\n\n### \u901a\u4fe1\u8a2d\u5b9a\n* Aurora <- EMR(3\u53f0\u3068\u3082):3306\n\n## Sqoop\u3059\u308b\u6e96\u5099(EMR\u306eMaster\u30ce\u30fc\u30c9\u3067\u5b9f\u65bd)\n### Sqoop\u306e\u30a4\u30f3\u30b9\u30c8\u30fc\u30eb\n\n```\n$ cd /tmp\n$ curl -OL http://ftp.tsukuba.wide.ad.jp/software/apache/sqoop/1.4.6/sqoop-1.4.6.bin__hadoop-2.0.4-alpha.tar.gz\n$ tar zxvf sqoop-1.4.6.bin__hadoop-2.0.4-alpha.tar.gz\n```\n\n### mariadb jdbc\u306e\u914d\u7f6e\n\n```\n$ cd /tmp\n$ curl -OL https://downloads.mariadb.com/enterprise/rs6a-06j2/connectors/java/connector-java-1.3.6/mariadb-java-client-1.3.6.jar\n$ cp mariadb-java-client-1.3.6.jar /tmp/sqoop-1.4.6.bin__hadoop-2.0.4-alpha/lib/\n``` \n\n\n### mysql jdbc\u306e\u914d\u7f6e\n\n```\n$ cd /tmp\n$ curl -LO http://dev.mysql.com/get/Downloads/Connector-J/mysql-connector-java-5.1.38.tar.gz\n$ tar zxvf mysql-connector-java-5.1.38.tar.gz\n$ cd mysql-connector-java-5.1.38\n$ cp mysql-connector-java-5.1.38-bin.jar /tmp/sqoop-1.4.6.bin__hadoop-2.0.4-alpha/lib/\n```\n\n## Sqoop\u5b9f\u884c\n### Using mysql driver\n\n```\n$ ./sqoop import --connect jdbc:mysql://<Aurora\u306e\u30af\u30e9\u30b9\u30bf\u30fc\u30a8\u30f3\u30c9\u30dd\u30a4\u30f3\u30c8>/sqoop_test --username sqoopuser --password sqoopuser999 --table sqoop_test_utf8\n```\n\n### Using mariadb driver\n\n```\n$ ./sqoop import --connect jdbc:mysql://<Aurora\u306e\u30af\u30e9\u30b9\u30bf\u30fc\u30a8\u30f3\u30c9\u30dd\u30a4\u30f3\u30c8>/sqoop_test --username sqoopuser --password sqoopuser999 --table sqoop_test_utf8 --driver org.mariadb.jdbc.Driver\n```\n\n### hive import\n\n```\n$ ./sqoop import --connect jdbc:mysql://test-cluster.cluster-cxkmqunzhbcv.us-east-1.rds.amazonaws.com/sqoop_test --username sqoopuser --password sqoopuser999 --table sqoop_test_utf8 --driver org.mariadb.jdbc.Driver --hive-import --hive-table sqoop_test\n```\n\n* \u30c7\u30fc\u30bf\u78ba\u8a8d\n\n ```\n hive> select * from sqoop_test;\nOK\nA001\tshibuya_00\tbook\nA002\tshibuya_00\tDVD\nB003\tshinagawa_\tstationery\nC004\tebisu_001\tdictionary\nD005\tmeguro_001\tbook\nTime taken: 0.786 seconds, Fetched: 5 row(s)\n ```\n\n\n## \u305d\u306e\u4ed6\n### \u30c6\u30fc\u30d6\u30eb\u306e\u6587\u5b57\u30b3\u30fc\u30c9\u3068sqoop\u5074\u306e\u6587\u5b57\u30b3\u30fc\u30c9\u306e\u9055\u3044\u3067\u30a8\u30e9\u30fc\uff1f\n* \u30c6\u30fc\u30d6\u30eb\u306e\u6587\u5b57\u30b3\u30fc\u30c9\u3092latin1\u306b\u3057\u3066\u3044\u308b\u3068\u4ee5\u4e0b\u306e\u30a8\u30e9\u30fc\u304c\u51fa\u3066\u30b8\u30e7\u30d6\u304c\u5931\u6557\u3057\u305f\u3002\u306a\u306e\u3067\u3001\u4e0a\u8a18\u3067\u300cutf-8\u300d\u306b\u3057\u3066\u3044\u308b\u3002\n* \u3084\u3063\u3066\u306f\u3044\u306a\u3044\u304c\u3001Sqoop\u5074\u3067\u5bfe\u5fdc\u3059\u308b\u5834\u5408\u3001\u300c--connection-param-file\u300d\u3092\u4f7f\u3063\u3066\u300ccharacterEncoding\u300d\u3067\u6307\u5b9a\u3057\u3066\u3084\u308c\u3070\u884c\u3051\u308b\u306e\u304b\u306a\u3002\n\n* \u30a8\u30e9\u30fc\u30ed\u30b0\n\n ```\n 16/03/09 06:41:21 INFO mapreduce.Job: Task Id : attempt_1457497192768_0001_m_000000_2, Status : FAILED\nError: java.io.IOException: SQLException in nextKeyValue\n\tat org.apache.sqoop.mapreduce.db.DBRecordReader.nextKeyValue(DBRecordReader.java:277)\n\tat org.apache.hadoop.mapred.MapTask$NewTrackingRecordReader.nextKeyValue(MapTask.java:565)\n\tat org.apache.hadoop.mapreduce.task.MapContextImpl.nextKeyValue(MapContextImpl.java:80)\n\tat org.apache.hadoop.mapreduce.lib.map.WrappedMapper$Context.nextKeyValue(WrappedMapper.java:91)\n\tat org.apache.hadoop.mapreduce.Mapper.run(Mapper.java:152)\n\tat org.apache.sqoop.mapreduce.AutoProgressMapper.run(AutoProgressMapper.java:64)\n\tat org.apache.hadoop.mapred.MapTask.runNewMapper(MapTask.java:796)\n\tat org.apache.hadoop.mapred.MapTask.run(MapTask.java:342)\n\tat org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:172)\n\tat java.security.AccessController.doPrivileged(Native Method)\n\tat javax.security.auth.Subject.doAs(Subject.java:415)\n\tat org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1657)\n\tat org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:166)\nCaused by: java.sql.SQLException: Illegal mix of collations (latin1_swedish_ci,IMPLICIT) and (utf8_general_ci,COERCIBLE) for operation '<'\n\tat org.mariadb.jdbc.internal.SQLExceptionMapper.get(SQLExceptionMapper.java:149)\n\tat org.mariadb.jdbc.internal.SQLExceptionMapper.throwException(SQLExceptionMapper.java:106)\n\tat org.mariadb.jdbc.MySQLStatement.executeQueryEpilog(MySQLStatement.java:252)\n\tat org.mariadb.jdbc.MySQLStatement.execute(MySQLStatement.java:278)\n\tat org.mariadb.jdbc.MySQLStatement.executeQuery(MySQLStatement.java:333)\n\tat org.mariadb.jdbc.MySQLPreparedStatement.executeQuery(MySQLPreparedStatement.java:99)\n\tat org.apache.sqoop.mapreduce.db.DBRecordReader.executeQuery(DBRecordReader.java:111)\n\tat org.apache.sqoop.mapreduce.db.DBRecordReader.nextKeyValue(DBRecordReader.java:235)\n\t... 12 more\n ```\n \n \n## \u53c2\u8003\uff1a\u5b9f\u884c\u7d50\u679c\n* mysql driver\n\n ```\n Warning: /mnt/tmp/sqoop-1.4.6.bin__hadoop-2.0.4-alpha/bin/../../hcatalog does not exist! HCatalog jobs will fail.\nPlease set $HCAT_HOME to the root of your HCatalog installation.\nWarning: /mnt/tmp/sqoop-1.4.6.bin__hadoop-2.0.4-alpha/bin/../../accumulo does not exist! Accumulo imports will fail.\nPlease set $ACCUMULO_HOME to the root of your Accumulo installation.\n16/03/09 06:53:02 INFO sqoop.Sqoop: Running Sqoop version: 1.4.6\n16/03/09 06:53:02 WARN tool.BaseSqoopTool: Setting your password on the command-line is insecure. Consider using -P instead.\n16/03/09 06:53:02 INFO manager.MySQLManager: Preparing to use a MySQL streaming resultset.\n16/03/09 06:53:02 INFO tool.CodeGenTool: Beginning code generation\n16/03/09 06:53:02 INFO manager.SqlManager: Executing SQL statement: SELECT t.* FROM `sqoop_test_utf8` AS t LIMIT 1\n16/03/09 06:53:02 INFO manager.SqlManager: Executing SQL statement: SELECT t.* FROM `sqoop_test_utf8` AS t LIMIT 1\n16/03/09 06:53:02 INFO orm.CompilationManager: HADOOP_MAPRED_HOME is /usr/lib/hadoop-mapreduce\n\u6ce8\u610f:/tmp/sqoop-hadoop/compile/f5749f4d128f954b02ac58ff6e31a933/sqoop_test_utf8.java\u306f\u975e\u63a8\u5968\u306eAPI\u3092\u4f7f\u7528\u307e\u305f\u306f\u30aa\u30fc\u30d0\u30fc\u30e9\u30a4\u30c9\u3057\u3066\u3044\u307e\u3059\u3002\n\u6ce8\u610f:\u8a73\u7d30\u306f\u3001-Xlint:deprecation\u30aa\u30d7\u30b7\u30e7\u30f3\u3092\u6307\u5b9a\u3057\u3066\u518d\u30b3\u30f3\u30d1\u30a4\u30eb\u3057\u3066\u304f\u3060\u3055\u3044\u3002\n16/03/09 06:53:04 INFO orm.CompilationManager: Writing jar file: /tmp/sqoop-hadoop/compile/f5749f4d128f954b02ac58ff6e31a933/sqoop_test_utf8.jar\n16/03/09 06:53:04 WARN manager.MySQLManager: It looks like you are importing from mysql.\n16/03/09 06:53:04 WARN manager.MySQLManager: This transfer can be faster! Use the --direct\n16/03/09 06:53:04 WARN manager.MySQLManager: option to exercise a MySQL-specific fast path.\n16/03/09 06:53:04 INFO manager.MySQLManager: Setting zero DATETIME behavior to convertToNull (mysql)\n16/03/09 06:53:04 INFO mapreduce.ImportJobBase: Beginning import of sqoop_test_utf8\n16/03/09 06:53:05 INFO Configuration.deprecation: mapred.jar is deprecated. Instead, use mapreduce.job.jar\n16/03/09 06:53:05 INFO Configuration.deprecation: mapred.map.tasks is deprecated. Instead, use mapreduce.job.maps\n16/03/09 06:53:05 INFO client.RMProxy: Connecting to ResourceManager at ip-172-31-55-2.ec2.internal/172.31.55.2:8032\n16/03/09 06:53:06 INFO metrics.MetricsSaver: MetricsConfigRecord disabledInCluster: false instanceEngineCycleSec: 60 clusterEngineCycleSec: 60 disableClusterEngine: false maxMemoryMb: 3072 maxInstanceCount: 500 lastModified: 1457497199168\n16/03/09 06:53:06 INFO metrics.MetricsSaver: Created MetricsSaver j-3UO8LO9Y9U00I:i-81fac878:Sqoop:05010 period:60 /mnt/var/em/raw/i-81fac878_20160309_Sqoop_05010_raw.bin\n16/03/09 06:53:07 INFO db.DBInputFormat: Using read commited transaction isolation\n16/03/09 06:53:07 INFO db.DataDrivenDBInputFormat: BoundingValsQuery: SELECT MIN(`key1`), MAX(`key1`) FROM `sqoop_test_utf8`\n16/03/09 06:53:07 WARN db.TextSplitter: Generating splits for a textual index column.\n16/03/09 06:53:07 WARN db.TextSplitter: If your database sorts in a case-insensitive order, this may result in a partial import or duplicate records.\n16/03/09 06:53:07 WARN db.TextSplitter: You are strongly encouraged to choose an integral split column.\n16/03/09 06:53:07 INFO mapreduce.JobSubmitter: number of splits:4\n16/03/09 06:53:07 INFO mapreduce.JobSubmitter: Submitting tokens for job: job_1457497192768_0002\n16/03/09 06:53:08 INFO impl.YarnClientImpl: Submitted application application_1457497192768_0002\n16/03/09 06:53:08 INFO mapreduce.Job: The url to track the job: http://ip-172-31-55-2.ec2.internal:20888/proxy/application_1457497192768_0002/\n16/03/09 06:53:08 INFO mapreduce.Job: Running job: job_1457497192768_0002\n16/03/09 06:53:15 INFO mapreduce.Job: Job job_1457497192768_0002 running in uber mode : false\n16/03/09 06:53:15 INFO mapreduce.Job:  map 0% reduce 0%\n16/03/09 06:53:23 INFO mapreduce.Job:  map 50% reduce 0%\n16/03/09 06:53:24 INFO mapreduce.Job:  map 100% reduce 0%\n16/03/09 06:53:24 INFO mapreduce.Job: Job job_1457497192768_0002 completed successfully\n16/03/09 06:53:24 INFO mapreduce.Job: Counters: 30\n\tFile System Counters\n\t\tFILE: Number of bytes read=0\n\t\tFILE: Number of bytes written=565716\n\t\tFILE: Number of read operations=0\n\t\tFILE: Number of large read operations=0\n\t\tFILE: Number of write operations=0\n\t\tHDFS: Number of bytes read=461\n\t\tHDFS: Number of bytes written=115\n\t\tHDFS: Number of read operations=16\n\t\tHDFS: Number of large read operations=0\n\t\tHDFS: Number of write operations=8\n\tJob Counters\n\t\tLaunched map tasks=4\n\t\tOther local map tasks=4\n\t\tTotal time spent by all maps in occupied slots (ms)=1013580\n\t\tTotal time spent by all reduces in occupied slots (ms)=0\n\t\tTotal time spent by all map tasks (ms)=22524\n\t\tTotal vcore-seconds taken by all map tasks=22524\n\t\tTotal megabyte-seconds taken by all map tasks=32434560\n\tMap-Reduce Framework\n\t\tMap input records=5\n\t\tMap output records=5\n\t\tInput split bytes=461\n\t\tSpilled Records=0\n\t\tFailed Shuffles=0\n\t\tMerged Map outputs=0\n\t\tGC time elapsed (ms)=286\n\t\tCPU time spent (ms)=4590\n\t\tPhysical memory (bytes) snapshot=869433344\n\t\tVirtual memory (bytes) snapshot=8212455424\n\t\tTotal committed heap usage (bytes)=1195376640\n\tFile Input Format Counters\n\t\tBytes Read=0\n\tFile Output Format Counters\n\t\tBytes Written=115\n16/03/09 06:53:24 INFO mapreduce.ImportJobBase: Transferred 115 bytes in 18.7289 seconds (6.1403 bytes/sec)\n16/03/09 06:53:24 INFO mapreduce.ImportJobBase: Retrieved 5 records.\n ```\n \n* mariadb driver\n\n ```\n Warning: /mnt/tmp/sqoop-1.4.6.bin__hadoop-2.0.4-alpha/bin/../../hcatalog does not exist! HCatalog jobs will fail.\nPlease set $HCAT_HOME to the root of your HCatalog installation.\nWarning: /mnt/tmp/sqoop-1.4.6.bin__hadoop-2.0.4-alpha/bin/../../accumulo does not exist! Accumulo imports will fail.\nPlease set $ACCUMULO_HOME to the root of your Accumulo installation.\n16/03/09 06:58:22 INFO sqoop.Sqoop: Running Sqoop version: 1.4.6\n16/03/09 06:58:22 WARN tool.BaseSqoopTool: Setting your password on the command-line is insecure. Consider using -P instead.\n16/03/09 06:58:22 WARN sqoop.ConnFactory: Parameter --driver is set to an explicit driver however appropriate connection manager is not being set (via --connection-manager). Sqoop is going to fall back to org.apache.sqoop.manager.GenericJdbcManager. Please specify explicitly which connection manager should be used next time.\n16/03/09 06:58:22 INFO manager.SqlManager: Using default fetchSize of 1000\n16/03/09 06:58:22 INFO tool.CodeGenTool: Beginning code generation\n16/03/09 06:58:22 INFO manager.SqlManager: Executing SQL statement: SELECT t.* FROM sqoop_test_utf8 AS t WHERE 1=0\n16/03/09 06:58:22 INFO manager.SqlManager: Executing SQL statement: SELECT t.* FROM sqoop_test_utf8 AS t WHERE 1=0\n16/03/09 06:58:22 INFO orm.CompilationManager: HADOOP_MAPRED_HOME is /usr/lib/hadoop-mapreduce\n\u6ce8\u610f:/tmp/sqoop-hadoop/compile/131e4ef66f3fe8206ed85367ddc6aa87/sqoop_test_utf8.java\u306f\u975e\u63a8\u5968\u306eAPI\u3092\u4f7f\u7528\u307e\u305f\u306f\u30aa\u30fc\u30d0\u30fc\u30e9\u30a4\u30c9\u3057\u3066\u3044\u307e\u3059\u3002\n\u6ce8\u610f:\u8a73\u7d30\u306f\u3001-Xlint:deprecation\u30aa\u30d7\u30b7\u30e7\u30f3\u3092\u6307\u5b9a\u3057\u3066\u518d\u30b3\u30f3\u30d1\u30a4\u30eb\u3057\u3066\u304f\u3060\u3055\u3044\u3002\n16/03/09 06:58:24 INFO orm.CompilationManager: Writing jar file: /tmp/sqoop-hadoop/compile/131e4ef66f3fe8206ed85367ddc6aa87/sqoop_test_utf8.jar\n16/03/09 06:58:24 INFO mapreduce.ImportJobBase: Beginning import of sqoop_test_utf8\n16/03/09 06:58:25 INFO Configuration.deprecation: mapred.jar is deprecated. Instead, use mapreduce.job.jar\n16/03/09 06:58:25 INFO manager.SqlManager: Executing SQL statement: SELECT t.* FROM sqoop_test_utf8 AS t WHERE 1=0\n16/03/09 06:58:25 INFO Configuration.deprecation: mapred.map.tasks is deprecated. Instead, use mapreduce.job.maps\n16/03/09 06:58:26 INFO client.RMProxy: Connecting to ResourceManager at ip-172-31-55-2.ec2.internal/172.31.55.2:8032\n16/03/09 06:58:26 INFO metrics.MetricsSaver: MetricsConfigRecord disabledInCluster: false instanceEngineCycleSec: 60 clusterEngineCycleSec: 60 disableClusterEngine: false maxMemoryMb: 3072 maxInstanceCount: 500 lastModified: 1457497199168\n16/03/09 06:58:26 INFO metrics.MetricsSaver: Created MetricsSaver j-3UO8LO9Y9U00I:i-81fac878:Sqoop:07626 period:60 /mnt/var/em/raw/i-81fac878_20160309_Sqoop_07626_raw.bin\n16/03/09 06:58:27 INFO db.DBInputFormat: Using read commited transaction isolation\n16/03/09 06:58:27 INFO db.DataDrivenDBInputFormat: BoundingValsQuery: SELECT MIN(key1), MAX(key1) FROM sqoop_test_utf8\n16/03/09 06:58:27 WARN db.TextSplitter: Generating splits for a textual index column.\n16/03/09 06:58:27 WARN db.TextSplitter: If your database sorts in a case-insensitive order, this may result in a partial import or duplicate records.\n16/03/09 06:58:27 WARN db.TextSplitter: You are strongly encouraged to choose an integral split column.\n16/03/09 06:58:27 INFO mapreduce.JobSubmitter: number of splits:4\n16/03/09 06:58:28 INFO metrics.MetricsSaver: 1 aggregated HDFSWriteDelay 306 raw values into 2 aggregated values, total 2\n16/03/09 06:58:28 INFO mapreduce.JobSubmitter: Submitting tokens for job: job_1457497192768_0003\n16/03/09 06:58:28 INFO impl.YarnClientImpl: Submitted application application_1457497192768_0003\n16/03/09 06:58:28 INFO mapreduce.Job: The url to track the job: http://ip-172-31-55-2.ec2.internal:20888/proxy/application_1457497192768_0003/\n16/03/09 06:58:28 INFO mapreduce.Job: Running job: job_1457497192768_0003\n16/03/09 06:58:35 INFO mapreduce.Job: Job job_1457497192768_0003 running in uber mode : false\n16/03/09 06:58:35 INFO mapreduce.Job:  map 0% reduce 0%\n16/03/09 06:58:43 INFO mapreduce.Job:  map 25% reduce 0%\n16/03/09 06:58:44 INFO mapreduce.Job:  map 75% reduce 0%\n16/03/09 06:58:45 INFO mapreduce.Job:  map 100% reduce 0%\n16/03/09 06:58:45 INFO mapreduce.Job: Job job_1457497192768_0003 completed successfully\n16/03/09 06:58:45 INFO mapreduce.Job: Counters: 30\n\tFile System Counters\n\t\tFILE: Number of bytes read=0\n\t\tFILE: Number of bytes written=565504\n\t\tFILE: Number of read operations=0\n\t\tFILE: Number of large read operations=0\n\t\tFILE: Number of write operations=0\n\t\tHDFS: Number of bytes read=445\n\t\tHDFS: Number of bytes written=115\n\t\tHDFS: Number of read operations=16\n\t\tHDFS: Number of large read operations=0\n\t\tHDFS: Number of write operations=8\n\tJob Counters\n\t\tLaunched map tasks=4\n\t\tOther local map tasks=4\n\t\tTotal time spent by all maps in occupied slots (ms)=1054530\n\t\tTotal time spent by all reduces in occupied slots (ms)=0\n\t\tTotal time spent by all map tasks (ms)=23434\n\t\tTotal vcore-seconds taken by all map tasks=23434\n\t\tTotal megabyte-seconds taken by all map tasks=33744960\n\tMap-Reduce Framework\n\t\tMap input records=5\n\t\tMap output records=5\n\t\tInput split bytes=445\n\t\tSpilled Records=0\n\t\tFailed Shuffles=0\n\t\tMerged Map outputs=0\n\t\tGC time elapsed (ms)=292\n\t\tCPU time spent (ms)=5630\n\t\tPhysical memory (bytes) snapshot=992595968\n\t\tVirtual memory (bytes) snapshot=8235737088\n\t\tTotal committed heap usage (bytes)=1195376640\n\tFile Input Format Counters\n\t\tBytes Read=0\n\tFile Output Format Counters\n\t\tBytes Written=115\n16/03/09 06:58:45 INFO mapreduce.ImportJobBase: Transferred 115 bytes in 19.782 seconds (5.8134 bytes/sec)\n16/03/09 06:58:45 INFO mapreduce.ImportJobBase: Retrieved 5 records.\n ```\n \n", "tags": ["hive", "Sqoop", "hadoop", "Aurora", "EMR"]}