{"context": "\u3053\u306e\u8a18\u4e8b\u306f Retty Advent Calendar 20\u65e5\u76ee\u3067\u3059\u3002\n\u6628\u65e5\u306f@takumi-suzuki\u306eDNS\u3067\u30d0\u30e9\u30f3\u30b7\u30f3\u30b0\u3057\u3066\u3044\u305f\u3089\u8f9b\u304f\u306a\u3063\u305f\u8a71\u3067\u3057\u305f\u3002\n\n\u30ac\u30b8\u30a7\u30c3\u30c8\u624b\u5f53\n\u307f\u306a\u3055\u3093\u3001\u3044\u304d\u306a\u308a\u3067\u3059\u304c\u30b9\u30d1\u30b3\u30f3\u3092\u6301\u3063\u3066\u307e\u3059\u304b\uff1f\n\u50d5\u306f\u6301\u3063\u3066\u3044\u307e\u3059\u3002\nRetty\u3068\u3044\u3046\u4f1a\u793e\u306f\u3001\u30a8\u30f3\u30b8\u30cb\u30a2\u306b\u306f\u901a\u671f\u3067\u4e00\u56de\u300c\u30ac\u30b8\u30a7\u30c3\u30c8\u624b\u5f53\u300d\u3068\u3044\u3046\u5236\u5ea6\u304c\u3042\u308a\u307e\u3059\u3002\nIT\u6a5f\u5668\u306a\u3069\u3092\u500b\u4eba\u7684\u306b\u8cfc\u5165\u3059\u308b\u5834\u5408\u306b\u3001\u696d\u52d9\u3068\u304b\u7528\u9014\u95a2\u4fc2\u306a\u304f\u63f4\u52a9\u3057\u3066\u304f\u308c\u308b\u5236\u5ea6\u3067\u3059\u3002\n\u3060\u304b\u3089\u3068\u3044\u3046\u308f\u3051\u3067\u306f\u3042\u308a\u307e\u305b\u3093\u304c\u3001Retty\u3067\u3082\u30b9\u30d1\u30b3\u30f3\u3092\u8cb7\u3063\u3066\u307f\u308b\u3053\u3068\u306b\u3057\u307e\u3057\u305f\u3002\n\n\u30b9\u30d1\u30b3\u30f3\u8cb7\u3063\u3066\u307f\u3088\u3046\uff01\n\u7686\u3055\u3093\u304c\u60f3\u50cf\u3055\u308c\u308b\u30b9\u30d1\u30b3\u30f3\u3068\u3044\u3046\u306e\u306f\u3053\u3046\u3044\u3046\u306e\u3092\u30a4\u30e1\u30fc\u30b8\u3055\u308c\u308b\u3068\u601d\u3044\u307e\u3059\u304c\u3001\nBy 0-0t - 0-0t, GFDL-no-disclaimers, Link\n\u3084\u3063\u3071\u8cb7\u3046\u306a\u3089\u3053\u3046\u3044\u3046\u306e\u304c\u6b32\u3057\u3044\u306a\u3068\u601d\u3063\u305f\u308a\u3059\u308b\u306e\u3067\u3059\u304c\u3001\u6b8b\u5ff5\u306a\u304c\u3089\u307e\u3060\u307e\u3060\u30d9\u30f3\u30c1\u30e3\u30fc\u306eRetty\u306b\u306f\u3053\u3093\u306a\u5e83\u3044\u30b9\u30da\u30fc\u30b9\u306f\u78ba\u4fdd\u3067\u304d\u307e\u305b\u3093\u3002\n\u50d5\u306e\u500b\u4eba\u7684\u306a\u8da3\u5473\u3067\u3001\u307f\u3093\u306a\u306e\u5feb\u9069\u306a\u30aa\u30d5\u30a3\u30b9\u3092\u5360\u6709\u3059\u308b\u306e\u306f\u5c11\u3005\u5fc3\u304c\u75db\u307f\u307e\u3059\u3002\n\u5b9f\u306f\u3053\u306e\u4e16\u754c\u306e\u9032\u6b69\u306f\u3082\u306e\u3059\u3054\u304f\u65e9\u304f\u3066\u3001\u6700\u8fd1\u3067\u306f\u682a\u5f0f\u4f1a\u793ePEZY Computing\u3068\u3044\u3046\u4f1a\u793e\u306f\u3001\uff12\uff10\uff12\uff10\u5e74\u307e\u3067\u306b\u4eac\u306e\uff12\u53f0\u5206\u306e\u6f14\u7b97\u80fd\u529b\u3092\u6301\u3063\u305f\u30b9\u30d1\u30b3\u30f3\u3092\u30b3\u30d4\u30fc\u6a5f\u30b5\u30a4\u30ba\u306b\u3057\u3066\u3001\u30aa\u30d5\u30a3\u30b9\u3067\u4e00\u4eba\u4e00\u53f0\u304c\u4f7f\u3048\u308b\u3088\u3046\u306b\u3059\u308b\u3068\u3044\u3046\u3053\u3068\u3092\u8868\u660e\u3057\u3066\u3044\u3066\u8a71\u984c\u306b\u306a\u3063\u305f\u308a\u3057\u3066\u3044\u307e\u3059\u3002\n\u3068\u306f\u3044\u3048\u3001\u6708\u984d\u306e\u96fb\u6c17\u4ee3\u304c\uff11\uff15\u4e07\u3082\u3059\u308b\u30b3\u30d4\u30fc\u6a5f\u306f\u3001\u6bce\u6708\u306eAWS\u306e\u8acb\u6c42\u306b\u30c9\u30ad\u30c9\u30ad\u3057\u3066\u3044\u308b\u3088\u3046\u306a\u79c1\u306b\u306f\u3069\u3046\u8003\u3048\u3066\u3082\u6271\u3048\u305d\u3046\u306b\u3042\u308a\u307e\u305b\u3093\u3002\u3002\u3002\n\u305d\u3082\u305d\u3082\u30b9\u30fc\u30d1\u30fc\u30b3\u30f3\u30d4\u30e5\u30fc\u30bf\u30fc\u3063\u3066\u4f55\u3063\u3066\u8003\u3048\u305f\u3068\u3053\u308d\n\n\u4e00\u822c\u7684\u306b\u4f7f\u7528\u3055\u308c\u308b\u30b5\u30fc\u30d0\u6a5f\u3088\u308a\u3082\u6d6e\u52d5\u5c0f\u6570\u70b9\u6f14\u7b97\u304c1,000\u500d\u4ee5\u4e0a\u306e\u901f\u3055\u306e\u30b3\u30f3\u30d4\u30e5\u30fc\u30bf\u3092\u300c\u30b9\u30fc\u30d1\u30fc\u30b3\u30f3\u30d4\u30e5\u30fc\u30bf\u300d\u3068\u547c\u3076\u3053\u3068\u304c\u591a\u3044\u3002\n\n\u3089\u3057\u3044\u3067\u3059\u3002\n\u6d6e\u52d5\u5c0f\u6570\u70b9\u6f14\u7b97\u3068\u3044\u3048\u3070\u3001CUDA\u306b\u4ee3\u8868\u3055\u308c\u308bGPGPU\u304c\u6709\u540d\u3067\u3059\u306d\u3002\n\u3068\u8a00\u3046\u306e\u3067\u3001NVIDIA\u306e\u30b5\u30a4\u30c8\u3092\u898b\u3066\u3044\u305f\u3089\u3053\u3093\u306a\u3082\u306e\u3092\u898b\u3064\u3051\u307e\u3057\u305f\u3002\n\nNVIDIA Jetson TK1\nNVIDIA Jetson TK1\n\u3061\u3063\u3061\u3083\u3044\u3067\u3059\u306d\uff01\n\n\n\u4e16\u754c\u4e2d\u306e\u30b9\u30fc\u30d1\u30fc\u30b3\u30f3\u30d4\u30e5\u30fc\u30bf\u306b\u7d44\u307f\u8fbc\u307e\u308c\u3066\u3044\u308b\u306e\u3068\u540c\u3058 NVIDIA Kepler\u2122 \u30a2\u30fc\u30ad\u30c6\u30af\u30c1\u30e3\u306e\u30b3\u30f3\u30d4\u30e5\u30fc\u30c6\u30a3\u30f3\u30b0\u30b3\u30a2\u3092\u4f7f\u7528\u3057\u3066\u3044\u307e\u3059\u3002\n\n\u3082\u3068\u3082\u3068\u7d44\u307f\u8fbc\u307f\u306e\u6a5f\u68b0\u5b66\u7fd2\u30b7\u30b9\u30c6\u30e0\u958b\u767a\u306e\u691c\u8a3c\u7528\u30dc\u30fc\u30c9\u307f\u305f\u3044\u306a\u3093\u3067\u3059\u304c\u3001\u3053\u308c\u306a\u3089\u307f\u3093\u306a\u306b\u8ff7\u60d1\u3092\u304b\u3051\u305a\u306b\u61a7\u308c\u306e\u30b9\u30d1\u30b3\u30f3\u30aa\u30fc\u30ca\u30fc\u306b\u306a\u308c\u305d\u3046\u3067\u3059\u3002\n\nCUDA\u74b0\u5883\u306e\u30bb\u30c3\u30c8\u30a2\u30c3\u30d7\n\u8af8\u3005\u306e\u624b\u9806\u3092\u304b\u306a\u308a\u7aef\u6298\u308a\u307e\u3059\u304c\u3001Jetson\u306bJetPack L4T\u304b\u3089CUDA\u74b0\u5883\u3092\u30bb\u30c3\u30c8\u30a2\u30c3\u30d7\u3057\u307e\u3059\u3002\n\n\u304a\u304a\u3001CUDA\u30c9\u30e9\u30a4\u30d0\u30fc\u304c\u30a4\u30f3\u30b9\u30c8\u30fc\u30eb\u3055\u308c\u3066\u3044\u307e\u3059\u3002\n\nubuntu@tegra-ubuntu:~$ nvcc -V\nnvcc: NVIDIA (R) Cuda compiler driver\nCopyright (c) 2005-2014 NVIDIA Corporation\nBuilt on Tue_Feb_17_22:53:16_CST_2015\nCuda compilation tools, release 6.5, V6.5.45\n\n\n\u3068\u308a\u3042\u3048\u305a\u6a5f\u68b0\u5b66\u7fd2\u3067\u3082\u3084\u3063\u3066\u307f\u308b\u304b\u30fb\u30fb\u30fb\n\u5df7\u3067\u306f\u6700\u8fd1\u3001\u6a5f\u68b0\u5b66\u7fd2\u3084\u3089AI\u3084\u3089\u304c\u6d41\u884c\u308a\u3089\u3057\u3044\u3067\u3059\u304c\u3001Retty\u3067\u306f\u666e\u901a\u306b\u3044\u308d\u3093\u306a\u3068\u3053\u308d\u3067\u6a5f\u68b0\u5b66\u7fd2\u3067\u5f97\u3089\u308c\u305f\u30e2\u30c7\u30eb\u3092\u30b5\u30fc\u30d3\u30b9\u306b\u6d3b\u7528\u3057\u3066\u3044\u307e\u3059\u3002\n\u5f53\u793e\u306e\u6a5f\u68b0\u5b66\u7fd2\u30a8\u30f3\u30b8\u30cb\u30a2\u306b\u805e\u304f\u3068\u3001\u6700\u8fd1\u306fKeras\u3068\u3044\u3046\u306e\u304c\u6d41\u884c\u3063\u3066\u3044\u308b\u3089\u3057\u3044\u306e\u3067\u305d\u308c\u3092\u8a66\u3057\u3066\u898b\u307e\u3059\u3002\n\nTensorflow\u306e\u30bb\u30c3\u30c8\u30a2\u30c3\u30d7\nCUDA\u304c\u5229\u7528\u53ef\u80fd\u306a\u306e\u3067\u3001\u30bd\u30fc\u30b9\u30b3\u30fc\u30c9\u304b\u3089\u30d3\u30eb\u30c9\u3057\u307e\u3059\u3002\n\u57fa\u672c\u306f\u3053\u3053\u306b\u66f8\u3044\u3066\u3042\u308b\u3068\u3046\u308a\u3067\u3059\u304c\u3001\u4eca\u56de\u306fVirtualenv\u3067\u30a4\u30f3\u30b9\u30c8\u30fc\u30eb\u3057\u307e\u3059\u3002\n$ sudo apt-get install python-pip python-dev python-virtualenv python-gtk2-dev gfortran swig liblapack-dev\n\nvirtualenv\u306e\u74b0\u5883\u3092\u4f5c\u3063\u3066\u3001\u30a2\u30af\u30c6\u30a3\u30d9\u30fc\u30c8\u3002\n$ virtualenv --system-site-packages ~/tensorflow\n$ source ~/tensorflow/bin/activate\n\n\u4eca\u56de\u306fCUDA\u304c\u5229\u7528\u53ef\u80fd\u306a\u306e\u3067\u3059\u304c\u3001\u6700\u65b0\u306e\u30d0\u30a4\u30ca\u30ea\u306fCUDA-8.0\u3001CuDNN-v5\u304c\u5fc5\u8981\u3067\u3059\u3002\n# Ubuntu/Linux 64-bit, GPU enabled, Python 2.7\n# Requires CUDA toolkit 8.0 and CuDNN v5. For other versions, see \"Installing from sources\" below.\n\nTK1\u306eCUDA toolkit\u306f6.5\u3001CuDNN\u306fv2\u306b\u306a\u3063\u3066\u3044\u308b\u306e\u3068CPU\u304cARM\u30b3\u30a2\u306a\u306e\u3067\u3001\u30bd\u30fc\u30b9\u30b3\u30fc\u30c9\u304b\u3089\u30b3\u30f3\u30d1\u30a4\u30eb\u3057\u307e\u3059\u3002\n\u305d\u306e\u524d\u306bbazel\u306e\u30a4\u30f3\u30b9\u30c8\u30fc\u30eb\u3092\u3057\u3066\u304a\u304d\u307e\u3059\u3002\n$ git clone --recurse-submodules https://github.com/tensorflow/tensorflow\n$ cd tensorflow/tensorflow\n$ ./configure\nDo you wish to bulid TensorFlow with GPU support? [y/n] y\nGPU support will be enabled for TensorFlow\n\nPlease specify the location where CUDA 6.5 toolkit is installed. Refer to\nREADME.md for more details. [default is: /usr/local/cuda]: /usr/local/cuda-6.5\n\nPlease specify the location where CUDNN 6.5 V2 library is installed. Refer to\nREADME.md for more details. [default is: /usr/local/cuda]: /usr/local/cuda-6.5\n\nSetting up Cuda include\nSetting up Cuda lib64\nSetting up Cuda bin\nSetting up Cuda nvvm\nConfiguration finished\n\n\nkeras\u306e\u30bb\u30c3\u30c8\u30a2\u30c3\u30d7\nKeras: Deep Learning library for Theano and TensorFlow\n$ sudo pip install keras\n\n\u3053\u308c\u3060\u3051\u3067\u3059\u3002\n\nMNIST\u3067\u52d5\u4f5c\u78ba\u8a8d\nKeras\u306e\u958b\u767a\u8005Fran\u00e7ois Chollet\u3055\u3093\u306eGithub\u304b\u3089\u30b5\u30f3\u30d7\u30eb\u30b3\u30fc\u30c9\u3092\u30c0\u30a6\u30f3\u30ed\u30fc\u30c9\u3057\u3066\u5b9f\u884c\u3057\u3066\u898b\u307e\u3059\u3002\n\nmnist_cnn.py\n'''Trains a simple convnet on the MNIST dataset.\nGets to 99.25% test accuracy after 12 epochs\n(there is still a lot of margin for parameter tuning).\n16 seconds per epoch on a GRID K520 GPU.\n'''\n\nfrom __future__ import print_function\nimport numpy as np\nnp.random.seed(1337)  # for reproducibility\n\nfrom keras.datasets import mnist\nfrom keras.models import Sequential\nfrom keras.layers import Dense, Dropout, Activation, Flatten\nfrom keras.layers import Convolution2D, MaxPooling2D\nfrom keras.utils import np_utils\nfrom keras import backend as K\n\nbatch_size = 128\nnb_classes = 10\nnb_epoch = 12\n\n# input image dimensions\nimg_rows, img_cols = 28, 28\n# number of convolutional filters to use\nnb_filters = 32\n# size of pooling area for max pooling\npool_size = (2, 2)\n# convolution kernel size\nkernel_size = (3, 3)\n\n# the data, shuffled and split between train and test sets\n(X_train, y_train), (X_test, y_test) = mnist.load_data()\n\nif K.image_dim_ordering() == 'th':\n    X_train = X_train.reshape(X_train.shape[0], 1, img_rows, img_cols)\n    X_test = X_test.reshape(X_test.shape[0], 1, img_rows, img_cols)\n    input_shape = (1, img_rows, img_cols)\nelse:\n    X_train = X_train.reshape(X_train.shape[0], img_rows, img_cols, 1)\n    X_test = X_test.reshape(X_test.shape[0], img_rows, img_cols, 1)\n    input_shape = (img_rows, img_cols, 1)\n\nX_train = X_train.astype('float32')\nX_test = X_test.astype('float32')\nX_train /= 255\nX_test /= 255\nprint('X_train shape:', X_train.shape)\nprint(X_train.shape[0], 'train samples')\nprint(X_test.shape[0], 'test samples')\n\n# convert class vectors to binary class matrices\nY_train = np_utils.to_categorical(y_train, nb_classes)\nY_test = np_utils.to_categorical(y_test, nb_classes)\n\nmodel = Sequential()\n\nmodel.add(Convolution2D(nb_filters, kernel_size[0], kernel_size[1],\n                        border_mode='valid',\n                        input_shape=input_shape))\nmodel.add(Activation('relu'))\nmodel.add(Convolution2D(nb_filters, kernel_size[0], kernel_size[1]))\nmodel.add(Activation('relu'))\nmodel.add(MaxPooling2D(pool_size=pool_size))\nmodel.add(Dropout(0.25))\n\nmodel.add(Flatten())\nmodel.add(Dense(128))\nmodel.add(Activation('relu'))\nmodel.add(Dropout(0.5))\nmodel.add(Dense(nb_classes))\nmodel.add(Activation('softmax'))\n\nmodel.compile(loss='categorical_crossentropy',\n              optimizer='adadelta',\n              metrics=['accuracy'])\n\nmodel.fit(X_train, Y_train, batch_size=batch_size, nb_epoch=nb_epoch,\n          verbose=1, validation_data=(X_test, Y_test))\nscore = model.evaluate(X_test, Y_test, verbose=0)\nprint('Test score:', score[0])\nprint('Test accuracy:', score[1])\n\n\n\u304a\u304a\u52d5\u3044\u305f\uff01\n\u3061\u3087\u3063\u3068\u9045\u3044\u3051\u3069\u30fb\u30fb\u30fb\n$ python minst_cnn.py \nUsing TensorFlow backend.\nX_train shape: (60000, 28, 28, 1)\n60000 train samples\n10000 test samples\nTrain on 60000 samples, validate on 10000 samples\nEpoch 1/12\n60000/60000 [==============================] - 147s - loss: 0.3819 - acc: 0.8820 - val_loss: 0.0856 - val_acc: 0.9740\nEpoch 2/12\n60000/60000 [==============================] - 154s - loss: 0.1335 - acc: 0.9605 - val_loss: 0.0617 - val_acc: 0.9794\nEpoch 3/12\n60000/60000 [==============================] - 150s - loss: 0.1042 - acc: 0.9689 - val_loss: 0.0529 - val_acc: 0.9833\nEpoch 4/12\n60000/60000 [==============================] - 149s - loss: 0.0863 - acc: 0.9737 - val_loss: 0.0446 - val_acc: 0.9852\nEpoch 5/12\n60000/60000 [==============================] - 147s - loss: 0.0785 - acc: 0.9768 - val_loss: 0.0402 - val_acc: 0.9864\nEpoch 6/12\n60000/60000 [==============================] - 155s - loss: 0.0703 - acc: 0.9790 - val_loss: 0.0387 - val_acc: 0.9871\nEpoch 7/12\n60000/60000 [==============================] - 157s - loss: 0.0627 - acc: 0.9817 - val_loss: 0.0371 - val_acc: 0.9875\nEpoch 8/12\n60000/60000 [==============================] - 157s - loss: 0.0602 - acc: 0.9820 - val_loss: 0.0353 - val_acc: 0.9885\nEpoch 9/12\n60000/60000 [==============================] - 156s - loss: 0.0557 - acc: 0.9833 - val_loss: 0.0341 - val_acc: 0.9886\nEpoch 10/12\n60000/60000 [==============================] - 155s - loss: 0.0539 - acc: 0.9838 - val_loss: 0.0320 - val_acc: 0.9892\nEpoch 11/12\n60000/60000 [==============================] - 145s - loss: 0.0510 - acc: 0.9850 - val_loss: 0.0307 - val_acc: 0.9898\nEpoch 12/12\n60000/60000 [==============================] - 165s - loss: 0.0459 - acc: 0.9862 - val_loss: 0.0318 - val_acc: 0.9897\nTest score: 0.0317565297928\nTest accuracy: 0.9897  \n\n\n\u4eca\u56de\u306fCUDA\u7121\u3057\u306e\u74b0\u5883\u3067\u30c6\u30b9\u30c8\u3057\u3066\u3044\u306a\u3044\u3067\u3059\u304c\u3001\u5e74\u672b\u306b\u3067\u3082\u6d88\u8cbb\u96fb\u529b\u3084\u51e6\u7406\u6642\u9593\u306a\u3069\u30d9\u30f3\u30c1\u30de\u30fc\u30af\u3092\u53d6\u3063\u3066\u307f\u305f\u3044\u3068\u601d\u3044\u307e\u3059\u3002\n\u307e\u305f\u3001Jetson TK1\u306e\u5f8c\u7d99\u6a5f\u3067\u30d7\u30ed\u30c0\u30af\u30b7\u30e7\u30f3\u30e2\u30c7\u30eb\u306eJetson TX1\u3068\u3044\u3046\u306e\u304c\u3059\u3067\u306b\u88fd\u54c1\u5316\u3055\u308c\u3066\u3044\u3066\u3001\u5b9f\u969b\u306b\u81ea\u52d5\u904b\u8ee2\u8eca\u3084\u30c9\u30ed\u30fc\u30f3\u306a\u3069\u306b\u4f7f\u308f\u308c\u3066\u3044\u308b\u3088\u3046\u3067\u3059\u3002\n\u6b21\u56de\u306e\u300c\u30ac\u30b8\u30a7\u30c3\u30c8\u624b\u5f53\u300d\u304c\u697d\u3057\u307f\u3067\u3059\u3002\n\n\u7d42\u308f\u308a\u306b\n\u3061\u306a\u307f\u306b\u3001Retty\u3067\u306fAKIBA\u3068\u3044\u3046\u6a5f\u68b0\u5b66\u7fd2\u306e\u70ba\u306eCUDA\u74b0\u5883\u3092\u81ea\u524d\u3067\u7528\u610f\u3057\u3066\u3044\u3066\u3001\u30a8\u30f3\u30b8\u30cb\u30a2\u306b\u9650\u3089\u305a\u8ab0\u3082\u304c\u5229\u7528\u3059\u308b\u3053\u3068\u304c\u3067\u304d\u307e\u3059\u3002\n\u307e\u305f\u3001\u30a8\u30f3\u30b8\u30cb\u30a2\u306e\u53ef\u80fd\u6027\u3092\u7121\u9650\u5927\u306b\u4f38\u3070\u3059\u70ba\u306b\u3001\u65b0\u3057\u3044\u50cd\u304d\u65b9\u3084\u4fa1\u5024\u89b3\u3092\u652f\u63f4\u3059\u308b\u69d8\u3005\u306a\u5236\u5ea6\u3092\u6e96\u5099\u3057\u3066\u3044\u307e\u3059\u3002\n\u3082\u3057\u8208\u5473\u304c\u3042\u308c\u3070\u904a\u3073\u306b\u6765\u3066\u304f\u3060\u3055\u3044\uff01\n\n\u3053\u306e\u8a18\u4e8b\u306f Retty Advent Calendar 20\u65e5\u76ee\u3067\u3059\u3002\n\u6628\u65e5\u306f[@takumi-suzuki](http://qiita.com/takumi-suzuki)\u306e[DNS\u3067\u30d0\u30e9\u30f3\u30b7\u30f3\u30b0\u3057\u3066\u3044\u305f\u3089\u8f9b\u304f\u306a\u3063\u305f\u8a71](http://qiita.com/takumi-suzuki/items/9d004ab863972f52a929)\u3067\u3057\u305f\u3002\n\n#\u30ac\u30b8\u30a7\u30c3\u30c8\u624b\u5f53\n\u307f\u306a\u3055\u3093\u3001\u3044\u304d\u306a\u308a\u3067\u3059\u304c\u30b9\u30d1\u30b3\u30f3\u3092\u6301\u3063\u3066\u307e\u3059\u304b\uff1f\n\u50d5\u306f\u6301\u3063\u3066\u3044\u307e\u3059\u3002\n\nRetty\u3068\u3044\u3046\u4f1a\u793e\u306f\u3001\u30a8\u30f3\u30b8\u30cb\u30a2\u306b\u306f\u901a\u671f\u3067\u4e00\u56de\u300c\u30ac\u30b8\u30a7\u30c3\u30c8\u624b\u5f53\u300d\u3068\u3044\u3046\u5236\u5ea6\u304c\u3042\u308a\u307e\u3059\u3002\nIT\u6a5f\u5668\u306a\u3069\u3092\u500b\u4eba\u7684\u306b\u8cfc\u5165\u3059\u308b\u5834\u5408\u306b\u3001\u696d\u52d9\u3068\u304b\u7528\u9014\u95a2\u4fc2\u306a\u304f\u63f4\u52a9\u3057\u3066\u304f\u308c\u308b\u5236\u5ea6\u3067\u3059\u3002\n\n\u3060\u304b\u3089\u3068\u3044\u3046\u308f\u3051\u3067\u306f\u3042\u308a\u307e\u305b\u3093\u304c\u3001Retty\u3067\u3082\u30b9\u30d1\u30b3\u30f3\u3092\u8cb7\u3063\u3066\u307f\u308b\u3053\u3068\u306b\u3057\u307e\u3057\u305f\u3002\n\n\n#\u30b9\u30d1\u30b3\u30f3\u8cb7\u3063\u3066\u307f\u3088\u3046\uff01\n\n\u7686\u3055\u3093\u304c\u60f3\u50cf\u3055\u308c\u308b\u30b9\u30d1\u30b3\u30f3\u3068\u3044\u3046\u306e\u306f\u3053\u3046\u3044\u3046\u306e\u3092\u30a4\u30e1\u30fc\u30b8\u3055\u308c\u308b\u3068\u601d\u3044\u307e\u3059\u304c\u3001\n<p><a href=\"https://ja.wikipedia.org/wiki/%E3%83%95%E3%82%A1%E3%82%A4%E3%83%AB:K_computer_S0071267.JPG#/media/File:K_computer_S0071267.JPG\"><img src=\"https://upload.wikimedia.org/wikipedia/ja/thumb/8/82/K_computer_S0071267.JPG/1200px-K_computer_S0071267.JPG\" alt=\"K computer S0071267.JPG\"></a><br>By 0-0t - 0-0t, <a href=\"//ja.wikipedia.org/wiki/Wikipedia:Text_of_GNU_Free_Documentation_License\" title=\"GNU Free Documentation License with no disclaimers\">GFDL-no-disclaimers</a>, <a href=\"https://ja.wikipedia.org/w/index.php?curid=2876061\">Link</a></p>\n\n\u3084\u3063\u3071\u8cb7\u3046\u306a\u3089\u3053\u3046\u3044\u3046\u306e\u304c\u6b32\u3057\u3044\u306a\u3068\u601d\u3063\u305f\u308a\u3059\u308b\u306e\u3067\u3059\u304c\u3001\u6b8b\u5ff5\u306a\u304c\u3089\u307e\u3060\u307e\u3060\u30d9\u30f3\u30c1\u30e3\u30fc\u306eRetty\u306b\u306f\u3053\u3093\u306a\u5e83\u3044\u30b9\u30da\u30fc\u30b9\u306f\u78ba\u4fdd\u3067\u304d\u307e\u305b\u3093\u3002\n\u50d5\u306e\u500b\u4eba\u7684\u306a\u8da3\u5473\u3067\u3001\u307f\u3093\u306a\u306e\u5feb\u9069\u306a\u30aa\u30d5\u30a3\u30b9\u3092\u5360\u6709\u3059\u308b\u306e\u306f\u5c11\u3005\u5fc3\u304c\u75db\u307f\u307e\u3059\u3002\n\n\u5b9f\u306f\u3053\u306e\u4e16\u754c\u306e\u9032\u6b69\u306f\u3082\u306e\u3059\u3054\u304f\u65e9\u304f\u3066\u3001\u6700\u8fd1\u3067\u306f[\u682a\u5f0f\u4f1a\u793ePEZY Computing](http://www.pezy.co.jp/)\u3068\u3044\u3046\u4f1a\u793e\u306f\u3001\uff12\uff10\uff12\uff10\u5e74\u307e\u3067\u306b\u4eac\u306e\uff12\u53f0\u5206\u306e\u6f14\u7b97\u80fd\u529b\u3092\u6301\u3063\u305f\u30b9\u30d1\u30b3\u30f3\u3092\u30b3\u30d4\u30fc\u6a5f\u30b5\u30a4\u30ba\u306b\u3057\u3066\u3001\u30aa\u30d5\u30a3\u30b9\u3067\u4e00\u4eba\u4e00\u53f0\u304c\u4f7f\u3048\u308b\u3088\u3046\u306b\u3059\u308b\u3068\u3044\u3046\u3053\u3068\u3092\u8868\u660e\u3057\u3066\u3044\u3066\u8a71\u984c\u306b\u306a\u3063\u305f\u308a\u3057\u3066\u3044\u307e\u3059\u3002\n\n\u3068\u306f\u3044\u3048\u3001\u6708\u984d\u306e\u96fb\u6c17\u4ee3\u304c\uff11\uff15\u4e07\u3082\u3059\u308b\u30b3\u30d4\u30fc\u6a5f\u306f\u3001\u6bce\u6708\u306eAWS\u306e\u8acb\u6c42\u306b\u30c9\u30ad\u30c9\u30ad\u3057\u3066\u3044\u308b\u3088\u3046\u306a\u79c1\u306b\u306f\u3069\u3046\u8003\u3048\u3066\u3082\u6271\u3048\u305d\u3046\u306b\u3042\u308a\u307e\u305b\u3093\u3002\u3002\u3002\n\n\u305d\u3082\u305d\u3082[\u30b9\u30fc\u30d1\u30fc\u30b3\u30f3\u30d4\u30e5\u30fc\u30bf\u30fc](https://ja.wikipedia.org/wiki/%E3%82%B9%E3%83%BC%E3%83%91%E3%83%BC%E3%82%B3%E3%83%B3%E3%83%94%E3%83%A5%E3%83%BC%E3%82%BF)\u3063\u3066\u4f55\u3063\u3066\u8003\u3048\u305f\u3068\u3053\u308d\n\n>\u4e00\u822c\u7684\u306b\u4f7f\u7528\u3055\u308c\u308b\u30b5\u30fc\u30d0\u6a5f\u3088\u308a\u3082\u6d6e\u52d5\u5c0f\u6570\u70b9\u6f14\u7b97\u304c1,000\u500d\u4ee5\u4e0a\u306e\u901f\u3055\u306e\u30b3\u30f3\u30d4\u30e5\u30fc\u30bf\u3092\u300c\u30b9\u30fc\u30d1\u30fc\u30b3\u30f3\u30d4\u30e5\u30fc\u30bf\u300d\u3068\u547c\u3076\u3053\u3068\u304c\u591a\u3044\u3002\n\n\u3089\u3057\u3044\u3067\u3059\u3002\n\u6d6e\u52d5\u5c0f\u6570\u70b9\u6f14\u7b97\u3068\u3044\u3048\u3070\u3001[CUDA](http://www.nvidia.co.jp/object/cuda-parallel-computing-platform-jp.html)\u306b\u4ee3\u8868\u3055\u308c\u308bGPGPU\u304c\u6709\u540d\u3067\u3059\u306d\u3002\n\u3068\u8a00\u3046\u306e\u3067\u3001NVIDIA\u306e\u30b5\u30a4\u30c8\u3092\u898b\u3066\u3044\u305f\u3089\u3053\u3093\u306a\u3082\u306e\u3092\u898b\u3064\u3051\u307e\u3057\u305f\u3002\n\n# NVIDIA Jetson TK1\n\n[NVIDIA Jetson TK1](http://www.nvidia.co.jp/object/jetson-tk1-embedded-dev-kit-jp.html)\n\u3061\u3063\u3061\u3083\u3044\u3067\u3059\u306d\uff01\n![IMG_7668.jpg](https://3.bp.blogspot.com/-uWmuajdyVnc/WFesnMmob1I/AAAAAAAAEQI/BPez9C9MsdgIEhsk54yzjHORFcNntQRrgCLcB/s1600/IMG_7668.jpg)\n>\u4e16\u754c\u4e2d\u306e\u30b9\u30fc\u30d1\u30fc\u30b3\u30f3\u30d4\u30e5\u30fc\u30bf\u306b\u7d44\u307f\u8fbc\u307e\u308c\u3066\u3044\u308b\u306e\u3068\u540c\u3058 NVIDIA Kepler\u2122 \u30a2\u30fc\u30ad\u30c6\u30af\u30c1\u30e3\u306e\u30b3\u30f3\u30d4\u30e5\u30fc\u30c6\u30a3\u30f3\u30b0\u30b3\u30a2\u3092\u4f7f\u7528\u3057\u3066\u3044\u307e\u3059\u3002\n\n\u3082\u3068\u3082\u3068\u7d44\u307f\u8fbc\u307f\u306e\u6a5f\u68b0\u5b66\u7fd2\u30b7\u30b9\u30c6\u30e0\u958b\u767a\u306e\u691c\u8a3c\u7528\u30dc\u30fc\u30c9\u307f\u305f\u3044\u306a\u3093\u3067\u3059\u304c\u3001\u3053\u308c\u306a\u3089\u307f\u3093\u306a\u306b\u8ff7\u60d1\u3092\u304b\u3051\u305a\u306b\u61a7\u308c\u306e\u30b9\u30d1\u30b3\u30f3\u30aa\u30fc\u30ca\u30fc\u306b\u306a\u308c\u305d\u3046\u3067\u3059\u3002\n\n# CUDA\u74b0\u5883\u306e\u30bb\u30c3\u30c8\u30a2\u30c3\u30d7\n\n\u8af8\u3005\u306e\u624b\u9806\u3092\u304b\u306a\u308a\u7aef\u6298\u308a\u307e\u3059\u304c\u3001Jetson\u306b[JetPack L4T](http://docs.nvidia.com/jetpack-l4t/index.html#developertools/mobile/jetpack/l4t/2.3/jetpack_l4t_install.htm)\u304b\u3089CUDA\u74b0\u5883\u3092\u30bb\u30c3\u30c8\u30a2\u30c3\u30d7\u3057\u307e\u3059\u3002\n![Installing JetPack L4T](https://4.bp.blogspot.com/-0eAVhG1yAd0/WFesnJ9NQ0I/AAAAAAAAEQM/9244q6irkeAvACArBBTTMkfQV4bboTJTgCLcB/s1600/IMG_7669.jpg)\n\n\n\u304a\u304a\u3001CUDA\u30c9\u30e9\u30a4\u30d0\u30fc\u304c\u30a4\u30f3\u30b9\u30c8\u30fc\u30eb\u3055\u308c\u3066\u3044\u307e\u3059\u3002\n\n```bash\n\nubuntu@tegra-ubuntu:~$ nvcc -V\nnvcc: NVIDIA (R) Cuda compiler driver\nCopyright (c) 2005-2014 NVIDIA Corporation\nBuilt on Tue_Feb_17_22:53:16_CST_2015\nCuda compilation tools, release 6.5, V6.5.45\n```\n\n##\u3068\u308a\u3042\u3048\u305a\u6a5f\u68b0\u5b66\u7fd2\u3067\u3082\u3084\u3063\u3066\u307f\u308b\u304b\u30fb\u30fb\u30fb\n\u5df7\u3067\u306f\u6700\u8fd1\u3001\u6a5f\u68b0\u5b66\u7fd2\u3084\u3089AI\u3084\u3089\u304c\u6d41\u884c\u308a\u3089\u3057\u3044\u3067\u3059\u304c\u3001Retty\u3067\u306f\u666e\u901a\u306b\u3044\u308d\u3093\u306a\u3068\u3053\u308d\u3067\u6a5f\u68b0\u5b66\u7fd2\u3067\u5f97\u3089\u308c\u305f\u30e2\u30c7\u30eb\u3092\u30b5\u30fc\u30d3\u30b9\u306b\u6d3b\u7528\u3057\u3066\u3044\u307e\u3059\u3002\n\u5f53\u793e\u306e\u6a5f\u68b0\u5b66\u7fd2\u30a8\u30f3\u30b8\u30cb\u30a2\u306b\u805e\u304f\u3068\u3001\u6700\u8fd1\u306f[Keras](https://keras.io/)\u3068\u3044\u3046\u306e\u304c\u6d41\u884c\u3063\u3066\u3044\u308b\u3089\u3057\u3044\u306e\u3067\u305d\u308c\u3092\u8a66\u3057\u3066\u898b\u307e\u3059\u3002\n\n###Tensorflow\u306e\u30bb\u30c3\u30c8\u30a2\u30c3\u30d7\nCUDA\u304c\u5229\u7528\u53ef\u80fd\u306a\u306e\u3067\u3001\u30bd\u30fc\u30b9\u30b3\u30fc\u30c9\u304b\u3089\u30d3\u30eb\u30c9\u3057\u307e\u3059\u3002\n\u57fa\u672c\u306f[\u3053\u3053](https://www.tensorflow.org/get_started/os_setup#virtualenv_installation)\u306b\u66f8\u3044\u3066\u3042\u308b\u3068\u3046\u308a\u3067\u3059\u304c\u3001\u4eca\u56de\u306fVirtualenv\u3067\u30a4\u30f3\u30b9\u30c8\u30fc\u30eb\u3057\u307e\u3059\u3002\n\n```\n$ sudo apt-get install python-pip python-dev python-virtualenv python-gtk2-dev gfortran swig liblapack-dev\n```\n\nvirtualenv\u306e\u74b0\u5883\u3092\u4f5c\u3063\u3066\u3001\u30a2\u30af\u30c6\u30a3\u30d9\u30fc\u30c8\u3002\n\n```\n$ virtualenv --system-site-packages ~/tensorflow\n$ source ~/tensorflow/bin/activate\n```\n\n\u4eca\u56de\u306fCUDA\u304c\u5229\u7528\u53ef\u80fd\u306a\u306e\u3067\u3059\u304c\u3001\u6700\u65b0\u306e\u30d0\u30a4\u30ca\u30ea\u306fCUDA-8.0\u3001CuDNN-v5\u304c\u5fc5\u8981\u3067\u3059\u3002\n\n```\n# Ubuntu/Linux 64-bit, GPU enabled, Python 2.7\n# Requires CUDA toolkit 8.0 and CuDNN v5. For other versions, see \"Installing from sources\" below.\n```\n\nTK1\u306eCUDA toolkit\u306f6.5\u3001CuDNN\u306fv2\u306b\u306a\u3063\u3066\u3044\u308b\u306e\u3068CPU\u304cARM\u30b3\u30a2\u306a\u306e\u3067\u3001\u30bd\u30fc\u30b9\u30b3\u30fc\u30c9\u304b\u3089\u30b3\u30f3\u30d1\u30a4\u30eb\u3057\u307e\u3059\u3002\n\u305d\u306e\u524d\u306b[bazel](https://bazel.build/versions/master/docs/install.html#ubuntu)\u306e\u30a4\u30f3\u30b9\u30c8\u30fc\u30eb\u3092\u3057\u3066\u304a\u304d\u307e\u3059\u3002\u001c\n\n```\n$ git clone --recurse-submodules https://github.com/tensorflow/tensorflow\n$ cd tensorflow/tensorflow\n$ ./configure\nDo you wish to bulid TensorFlow with GPU support? [y/n] y\nGPU support will be enabled for TensorFlow\n\nPlease specify the location where CUDA 6.5 toolkit is installed. Refer to\nREADME.md for more details. [default is: /usr/local/cuda]: /usr/local/cuda-6.5\n\nPlease specify the location where CUDNN 6.5 V2 library is installed. Refer to\nREADME.md for more details. [default is: /usr/local/cuda]: /usr/local/cuda-6.5\n\nSetting up Cuda include\nSetting up Cuda lib64\nSetting up Cuda bin\nSetting up Cuda nvvm\nConfiguration finished\n```\n\n\n###keras\u306e\u30bb\u30c3\u30c8\u30a2\u30c3\u30d7\n[Keras: Deep Learning library for Theano and TensorFlow](https://keras.io/)\n\n```\n$ sudo pip install keras\n```\n\u3053\u308c\u3060\u3051\u3067\u3059\u3002\n\n\n###MNIST\u3067\u52d5\u4f5c\u78ba\u8a8d\n\nKeras\u306e\u958b\u767a\u8005Fran\u00e7ois Chollet\u3055\u3093\u306e[Github](https://github.com/fchollet)\u304b\u3089\u30b5\u30f3\u30d7\u30eb\u30b3\u30fc\u30c9\u3092\u30c0\u30a6\u30f3\u30ed\u30fc\u30c9\u3057\u3066\u5b9f\u884c\u3057\u3066\u898b\u307e\u3059\u3002\n\n```mnist_cnn.py\n'''Trains a simple convnet on the MNIST dataset.\nGets to 99.25% test accuracy after 12 epochs\n(there is still a lot of margin for parameter tuning).\n16 seconds per epoch on a GRID K520 GPU.\n'''\n\nfrom __future__ import print_function\nimport numpy as np\nnp.random.seed(1337)  # for reproducibility\n\nfrom keras.datasets import mnist\nfrom keras.models import Sequential\nfrom keras.layers import Dense, Dropout, Activation, Flatten\nfrom keras.layers import Convolution2D, MaxPooling2D\nfrom keras.utils import np_utils\nfrom keras import backend as K\n\nbatch_size = 128\nnb_classes = 10\nnb_epoch = 12\n\n# input image dimensions\nimg_rows, img_cols = 28, 28\n# number of convolutional filters to use\nnb_filters = 32\n# size of pooling area for max pooling\npool_size = (2, 2)\n# convolution kernel size\nkernel_size = (3, 3)\n\n# the data, shuffled and split between train and test sets\n(X_train, y_train), (X_test, y_test) = mnist.load_data()\n\nif K.image_dim_ordering() == 'th':\n    X_train = X_train.reshape(X_train.shape[0], 1, img_rows, img_cols)\n    X_test = X_test.reshape(X_test.shape[0], 1, img_rows, img_cols)\n    input_shape = (1, img_rows, img_cols)\nelse:\n    X_train = X_train.reshape(X_train.shape[0], img_rows, img_cols, 1)\n    X_test = X_test.reshape(X_test.shape[0], img_rows, img_cols, 1)\n    input_shape = (img_rows, img_cols, 1)\n\nX_train = X_train.astype('float32')\nX_test = X_test.astype('float32')\nX_train /= 255\nX_test /= 255\nprint('X_train shape:', X_train.shape)\nprint(X_train.shape[0], 'train samples')\nprint(X_test.shape[0], 'test samples')\n\n# convert class vectors to binary class matrices\nY_train = np_utils.to_categorical(y_train, nb_classes)\nY_test = np_utils.to_categorical(y_test, nb_classes)\n\nmodel = Sequential()\n\nmodel.add(Convolution2D(nb_filters, kernel_size[0], kernel_size[1],\n                        border_mode='valid',\n                        input_shape=input_shape))\nmodel.add(Activation('relu'))\nmodel.add(Convolution2D(nb_filters, kernel_size[0], kernel_size[1]))\nmodel.add(Activation('relu'))\nmodel.add(MaxPooling2D(pool_size=pool_size))\nmodel.add(Dropout(0.25))\n\nmodel.add(Flatten())\nmodel.add(Dense(128))\nmodel.add(Activation('relu'))\nmodel.add(Dropout(0.5))\nmodel.add(Dense(nb_classes))\nmodel.add(Activation('softmax'))\n\nmodel.compile(loss='categorical_crossentropy',\n              optimizer='adadelta',\n              metrics=['accuracy'])\n\nmodel.fit(X_train, Y_train, batch_size=batch_size, nb_epoch=nb_epoch,\n          verbose=1, validation_data=(X_test, Y_test))\nscore = model.evaluate(X_test, Y_test, verbose=0)\nprint('Test score:', score[0])\nprint('Test accuracy:', score[1])\n```\n\n\u304a\u304a\u52d5\u3044\u305f\uff01\n\u3061\u3087\u3063\u3068\u9045\u3044\u3051\u3069\u30fb\u30fb\u30fb\n\n```\n$ python minst_cnn.py \nUsing TensorFlow backend.\nX_train shape: (60000, 28, 28, 1)\n60000 train samples\n10000 test samples\nTrain on 60000 samples, validate on 10000 samples\nEpoch 1/12\n60000/60000 [==============================] - 147s - loss: 0.3819 - acc: 0.8820 - val_loss: 0.0856 - val_acc: 0.9740\nEpoch 2/12\n60000/60000 [==============================] - 154s - loss: 0.1335 - acc: 0.9605 - val_loss: 0.0617 - val_acc: 0.9794\nEpoch 3/12\n60000/60000 [==============================] - 150s - loss: 0.1042 - acc: 0.9689 - val_loss: 0.0529 - val_acc: 0.9833\nEpoch 4/12\n60000/60000 [==============================] - 149s - loss: 0.0863 - acc: 0.9737 - val_loss: 0.0446 - val_acc: 0.9852\nEpoch 5/12\n60000/60000 [==============================] - 147s - loss: 0.0785 - acc: 0.9768 - val_loss: 0.0402 - val_acc: 0.9864\nEpoch 6/12\n60000/60000 [==============================] - 155s - loss: 0.0703 - acc: 0.9790 - val_loss: 0.0387 - val_acc: 0.9871\nEpoch 7/12\n60000/60000 [==============================] - 157s - loss: 0.0627 - acc: 0.9817 - val_loss: 0.0371 - val_acc: 0.9875\nEpoch 8/12\n60000/60000 [==============================] - 157s - loss: 0.0602 - acc: 0.9820 - val_loss: 0.0353 - val_acc: 0.9885\nEpoch 9/12\n60000/60000 [==============================] - 156s - loss: 0.0557 - acc: 0.9833 - val_loss: 0.0341 - val_acc: 0.9886\nEpoch 10/12\n60000/60000 [==============================] - 155s - loss: 0.0539 - acc: 0.9838 - val_loss: 0.0320 - val_acc: 0.9892\nEpoch 11/12\n60000/60000 [==============================] - 145s - loss: 0.0510 - acc: 0.9850 - val_loss: 0.0307 - val_acc: 0.9898\nEpoch 12/12\n60000/60000 [==============================] - 165s - loss: 0.0459 - acc: 0.9862 - val_loss: 0.0318 - val_acc: 0.9897\nTest score: 0.0317565297928\nTest accuracy: 0.9897  \n\n```\n\n\u4eca\u56de\u306fCUDA\u7121\u3057\u306e\u74b0\u5883\u3067\u30c6\u30b9\u30c8\u3057\u3066\u3044\u306a\u3044\u3067\u3059\u304c\u3001\u5e74\u672b\u306b\u3067\u3082\u6d88\u8cbb\u96fb\u529b\u3084\u51e6\u7406\u6642\u9593\u306a\u3069\u30d9\u30f3\u30c1\u30de\u30fc\u30af\u3092\u53d6\u3063\u3066\u307f\u305f\u3044\u3068\u601d\u3044\u307e\u3059\u3002\n\u307e\u305f\u3001Jetson TK1\u306e\u5f8c\u7d99\u6a5f\u3067\u30d7\u30ed\u30c0\u30af\u30b7\u30e7\u30f3\u30e2\u30c7\u30eb\u306e[Jetson TX1](http://www.nvidia.co.jp/object/jetson-tx1-module-jp.html)\u3068\u3044\u3046\u306e\u304c\u3059\u3067\u306b\u88fd\u54c1\u5316\u3055\u308c\u3066\u3044\u3066\u3001\u5b9f\u969b\u306b\u81ea\u52d5\u904b\u8ee2\u8eca\u3084\u30c9\u30ed\u30fc\u30f3\u306a\u3069\u306b\u4f7f\u308f\u308c\u3066\u3044\u308b\u3088\u3046\u3067\u3059\u3002\n\u6b21\u56de\u306e\u300c\u30ac\u30b8\u30a7\u30c3\u30c8\u624b\u5f53\u300d\u304c\u697d\u3057\u307f\u3067\u3059\u3002\n\n##\u7d42\u308f\u308a\u306b\n\u3061\u306a\u307f\u306b\u3001Retty\u3067\u306f**AKIBA**\u3068\u3044\u3046\u6a5f\u68b0\u5b66\u7fd2\u306e\u70ba\u306eCUDA\u74b0\u5883\u3092\u81ea\u524d\u3067\u7528\u610f\u3057\u3066\u3044\u3066\u3001\u30a8\u30f3\u30b8\u30cb\u30a2\u306b\u9650\u3089\u305a\u8ab0\u3082\u304c\u5229\u7528\u3059\u308b\u3053\u3068\u304c\u3067\u304d\u307e\u3059\u3002\n\u307e\u305f\u3001\u30a8\u30f3\u30b8\u30cb\u30a2\u306e\u53ef\u80fd\u6027\u3092\u7121\u9650\u5927\u306b\u4f38\u3070\u3059\u70ba\u306b\u3001\u65b0\u3057\u3044\u50cd\u304d\u65b9\u3084\u4fa1\u5024\u89b3\u3092\u652f\u63f4\u3059\u308b\u69d8\u3005\u306a\u5236\u5ea6\u3092\u6e96\u5099\u3057\u3066\u3044\u307e\u3059\u3002\n\u3082\u3057\u8208\u5473\u304c\u3042\u308c\u3070\u904a\u3073\u306b\u6765\u3066\u304f\u3060\u3055\u3044\uff01\n![AKIBA](https://1.bp.blogspot.com/-QjFsPxrZVlY/WFesnYOqpdI/AAAAAAAAEQQ/jVGoxwSezAMa2iAI6Gemu96zeeZd3NWBQCLcB/s1600/IMG_3751.JPG)\n\n\n\n", "tags": ["CUDA", "JetsonTK1", "TensorFlow", "Keras"]}