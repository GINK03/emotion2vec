{"context": " More than 1 year has passed since last update.\u307e\u3060\u5341\u5206\u306b\u691c\u8a3c\u51fa\u6765\u3066\u306a\u3044\u3051\u3069UIImage\u3067\u30e1\u30e2\u30ea\u304c\u89e3\u653e\u51fa\u6765\u306a\u304f\u3066\u82e6\u6226\u3057\u305f\u3002\n\u203b\u30b3\u30fc\u30c9\u306e\u5143\u30cd\u30bf\u306fOpenCV\u306e\u30c1\u30e5\u30fc\u30c8\u30ea\u304b\u3089\nhttp://docs.opencv.org/doc/tutorials/ios/image_manipulation/image_manipulation.html\n+ (UIImage *)imageFromCVMat:(cv::Mat&)cvMat\n{\n    NSData *nsData = [NSData dataWithBytes:cvMat.data length:cvMat.elemSize()*cvMat.total()];\n    CGColorSpaceRef colorSpace;\n\n    if (cvMat.elemSize() == 1) {\n        colorSpace = CGColorSpaceCreateDeviceGray();\n    } else {\n        colorSpace = CGColorSpaceCreateDeviceRGB();\n    }\n\n    CFDataRef cfData = (__bridge CFDataRef)nsData;\n    nsData = nil;\n\n    CGDataProviderRef provider = CGDataProviderCreateWithCFData(cfData);\n\n    // Creating CGImage from cv::Mat\n    CGImageRef imageRef = CGImageCreate(cvMat.cols,                                 //width\n                                        cvMat.rows,                                 //height\n                                        8,                                          //bits per component\n                                        8 * cvMat.elemSize(),                       //bits per pixel\n                                        cvMat.step[0],                              //bytesPerRow\n                                        colorSpace,                                 //colorspace\n                                        kCGImageAlphaNone|kCGBitmapByteOrderDefault,// bitmap info\n                                        provider,                                   //CGDataProviderRef\n                                        NULL,                                       //decode\n                                        false,                                      //should interpolate\n                                        kCGRenderingIntentDefault                   //intent\n                                        );\n\n    // Getting UIImage from CGImage\n    UIImage *finalImage = [UIImage imageWithCGImage:imageRef scale:1.0 orientation:UIImageOrientationRight];\n    CGImageRelease(imageRef);\n    CGDataProviderRelease(provider);\n    CGColorSpaceRelease(colorSpace);\n    CFRelease(cfData);\n\n    return finalImage;\n}\n\n\u3053\u3046\u3084\u3063\u3066\u4f5c\u3063\u305fUIImage\u304c\u6b21\u306e\u3088\u3046\u306a\u30b1\u30fc\u30b9\u3067\u89e3\u653e\u3055\u308c\u306a\u3044\u3002\n// AVCaptureVideoDataOutputSampleBufferDelegate\u30d7\u30ed\u30c8\u30b3\u30eb\n- (void)captureOutput:(AVCaptureOutput *)captureOutput\ndidOutputSampleBuffer:(CMSampleBufferRef)sampleBuffer\n       fromConnection:(AVCaptureConnection *)connection\n{\n    // OpenCV\u3067\u3054\u306b\u3087\u3054\u306b\u3087\n    // \u5185\u90e8\u3067\u306fsampleBuffer->cv::Mat->UIImage\u5909\u63db\u3092\u884c\u3063\u3066\u3044\u308b\n    // processingImage\u306fcv::Mat->UIImage\u3057\u305fUIImage\n    UIImage *processingImage = [self.imageProcessingFromBuffer:sampleBuffer];\n\n    // \u753b\u50cf\u3092\u753b\u9762\u306b\u8868\u793a\n    dispatch_async(dispatch_get_main_queue(), ^{\n        self.previewImageView.image = processingImage;\n    });\n}\n\n\u539f\u56e0\u306f\u3088\u304f\u308f\u304b\u3089\u306a\u304b\u3063\u305f\u3051\u3069\u3001\u4e0b\u8a18\u306e\u65b9\u6cd5\u3067\u89e3\u6c7a\u3057\u305f\u3002\n\u30e1\u30e2\u30ea\u306e\u5b9f\u4f53\u306fcv::Mat\u304c\u6301\u3063\u3066\u308b\u306e\u3067delegate\u30e1\u30bd\u30c3\u30c9\u5185\u3067cvMat\u3092\u751f\u6210\u3057\u3066\u3001\u30d6\u30ed\u30c3\u30af\u306e\u4e2d\u3067delete\u3059\u308b\u3053\u3068\u3067\u30e1\u30e2\u30ea\u30ea\u30fc\u30af\u304c\u7121\u304f\u306a\u3063\u305f\u3002\n\u591a\u5206cv::Mat\u306e\u30b3\u30d4\u30fc\u304c\u7406\u89e3\u3067\u304d\u3066\u306a\u3044\u3093\u3060\u3068\u601d\u3046(:D)TL\n// AVCaptureVideoDataOutputSampleBufferDelegate\u30d7\u30ed\u30c8\u30b3\u30eb\n- (void)captureOutput:(AVCaptureOutput *)captureOutput\ndidOutputSampleBuffer:(CMSampleBufferRef)sampleBuffer\n       fromConnection:(AVCaptureConnection *)connection\n{\n    // OpenCV\u3067\u3054\u306b\u3087\u3054\u306b\u3087\n    // \u5185\u90e8\u3067\u306fsampleBuffer->cv::Mat\u5909\u63db\u3092\u884c\u3063\u3066\u3044\u308b\n    // processingImage\u306fcv::Mat\u5f62\u5f0f\n    cv::Mat processingImage = new cv::Mat();\n    processingImage = [self imageProcessingFromBuffer:sampleBuffer];\n\n    // \u753b\u50cf\u3092\u753b\u9762\u306b\u8868\u793a\n    dispatch_async(dispatch_get_main_queue(), ^{\n        // \u5185\u90e8\u3067cv::Mat -> UIImage\u5909\u63db\n        self.previewImageView.image = [self imageFromCVMat:processingImage];\n\u3000\u3000\u3000\u3000\u3000// \u6e21\u3057\u305f\u3089delete\u3059\u308b\n         delete processingImage;\n    });\n}\n\n\u3068\u308a\u3042\u3048\u305a\u3053\u3093\u306a\u3068\u3053\u308d\u3067\u3002\n\n\u307e\u3060\u5341\u5206\u306b\u691c\u8a3c\u51fa\u6765\u3066\u306a\u3044\u3051\u3069UIImage\u3067\u30e1\u30e2\u30ea\u304c\u89e3\u653e\u51fa\u6765\u306a\u304f\u3066\u82e6\u6226\u3057\u305f\u3002\n\n\u203b\u30b3\u30fc\u30c9\u306e\u5143\u30cd\u30bf\u306fOpenCV\u306e\u30c1\u30e5\u30fc\u30c8\u30ea\u304b\u3089\nhttp://docs.opencv.org/doc/tutorials/ios/image_manipulation/image_manipulation.html\n\n```\n+ (UIImage *)imageFromCVMat:(cv::Mat&)cvMat\n{\n    NSData *nsData = [NSData dataWithBytes:cvMat.data length:cvMat.elemSize()*cvMat.total()];\n    CGColorSpaceRef colorSpace;\n    \n    if (cvMat.elemSize() == 1) {\n        colorSpace = CGColorSpaceCreateDeviceGray();\n    } else {\n        colorSpace = CGColorSpaceCreateDeviceRGB();\n    }\n    \n    CFDataRef cfData = (__bridge CFDataRef)nsData;\n    nsData = nil;\n    \n    CGDataProviderRef provider = CGDataProviderCreateWithCFData(cfData);\n    \n    // Creating CGImage from cv::Mat\n    CGImageRef imageRef = CGImageCreate(cvMat.cols,                                 //width\n                                        cvMat.rows,                                 //height\n                                        8,                                          //bits per component\n                                        8 * cvMat.elemSize(),                       //bits per pixel\n                                        cvMat.step[0],                              //bytesPerRow\n                                        colorSpace,                                 //colorspace\n                                        kCGImageAlphaNone|kCGBitmapByteOrderDefault,// bitmap info\n                                        provider,                                   //CGDataProviderRef\n                                        NULL,                                       //decode\n                                        false,                                      //should interpolate\n                                        kCGRenderingIntentDefault                   //intent\n                                        );\n    \n    // Getting UIImage from CGImage\n    UIImage *finalImage = [UIImage imageWithCGImage:imageRef scale:1.0 orientation:UIImageOrientationRight];\n    CGImageRelease(imageRef);\n    CGDataProviderRelease(provider);\n    CGColorSpaceRelease(colorSpace);\n    CFRelease(cfData);\n    \n    return finalImage;\n}\n```\n\n\u3053\u3046\u3084\u3063\u3066\u4f5c\u3063\u305fUIImage\u304c\u6b21\u306e\u3088\u3046\u306a\u30b1\u30fc\u30b9\u3067\u89e3\u653e\u3055\u308c\u306a\u3044\u3002\n\n```\n// AVCaptureVideoDataOutputSampleBufferDelegate\u30d7\u30ed\u30c8\u30b3\u30eb\n- (void)captureOutput:(AVCaptureOutput *)captureOutput\ndidOutputSampleBuffer:(CMSampleBufferRef)sampleBuffer\n       fromConnection:(AVCaptureConnection *)connection\n{\n    // OpenCV\u3067\u3054\u306b\u3087\u3054\u306b\u3087\n    // \u5185\u90e8\u3067\u306fsampleBuffer->cv::Mat->UIImage\u5909\u63db\u3092\u884c\u3063\u3066\u3044\u308b\n    // processingImage\u306fcv::Mat->UIImage\u3057\u305fUIImage\n    UIImage *processingImage = [self.imageProcessingFromBuffer:sampleBuffer];\n    \n    // \u753b\u50cf\u3092\u753b\u9762\u306b\u8868\u793a\n    dispatch_async(dispatch_get_main_queue(), ^{\n        self.previewImageView.image = processingImage;\n    });\n}\n```\n\n\u539f\u56e0\u306f\u3088\u304f\u308f\u304b\u3089\u306a\u304b\u3063\u305f\u3051\u3069\u3001\u4e0b\u8a18\u306e\u65b9\u6cd5\u3067\u89e3\u6c7a\u3057\u305f\u3002\n\u30e1\u30e2\u30ea\u306e\u5b9f\u4f53\u306fcv::Mat\u304c\u6301\u3063\u3066\u308b\u306e\u3067delegate\u30e1\u30bd\u30c3\u30c9\u5185\u3067cvMat\u3092\u751f\u6210\u3057\u3066\u3001\u30d6\u30ed\u30c3\u30af\u306e\u4e2d\u3067delete\u3059\u308b\u3053\u3068\u3067\u30e1\u30e2\u30ea\u30ea\u30fc\u30af\u304c\u7121\u304f\u306a\u3063\u305f\u3002\n\u591a\u5206cv::Mat\u306e\u30b3\u30d4\u30fc\u304c\u7406\u89e3\u3067\u304d\u3066\u306a\u3044\u3093\u3060\u3068\u601d\u3046(:D)TL\n\n```\n// AVCaptureVideoDataOutputSampleBufferDelegate\u30d7\u30ed\u30c8\u30b3\u30eb\n- (void)captureOutput:(AVCaptureOutput *)captureOutput\ndidOutputSampleBuffer:(CMSampleBufferRef)sampleBuffer\n       fromConnection:(AVCaptureConnection *)connection\n{\n    // OpenCV\u3067\u3054\u306b\u3087\u3054\u306b\u3087\n    // \u5185\u90e8\u3067\u306fsampleBuffer->cv::Mat\u5909\u63db\u3092\u884c\u3063\u3066\u3044\u308b\n    // processingImage\u306fcv::Mat\u5f62\u5f0f\n    cv::Mat processingImage = new cv::Mat();\n\tprocessingImage = [self imageProcessingFromBuffer:sampleBuffer];\n    \n    // \u753b\u50cf\u3092\u753b\u9762\u306b\u8868\u793a\n    dispatch_async(dispatch_get_main_queue(), ^{\n\t\t// \u5185\u90e8\u3067cv::Mat -> UIImage\u5909\u63db\n        self.previewImageView.image = [self imageFromCVMat:processingImage];\n\u3000\u3000\u3000\u3000\u3000// \u6e21\u3057\u305f\u3089delete\u3059\u308b\n\t     delete processingImage;\n    });\n}\n```\n\n\u3068\u308a\u3042\u3048\u305a\u3053\u3093\u306a\u3068\u3053\u308d\u3067\u3002\n", "tags": ["OpenCV", "Objective-C", "iOS"]}