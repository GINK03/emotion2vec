{"tags": ["Spark1.1.1"], "context": " More than 1 year has passed since last update.\u3053\u306e\u8a18\u4e8b\u306f\uff0c Spark, SQL on Hadoop etc. Advent Calendar 2014 - Qiita \u306e 12 \u6708\uff16\u65e5\u306e\u305f\u3081\u306e\u8a18\u4e8b\u3067\u3059\uff0e\n\u4eca\u56de\u306e\u8a18\u4e8b\u3067\u306f\uff0c\u6700\u8fd1\u8a71\u984c\u306b\u306a\u3063\u3066\u3044\u308b word2vec \u306e Apache Spark \u5b9f\u88c5\u3092 EC2 \u4e0a\u3067\u52d5\u304b\u3059\u65b9\u6cd5\u306b\u3064\u3044\u3066\u89e3\u8aac\u3057\u307e\u3059\uff0e\n\nword2vec \u3068\u306f\uff1f\n\u81ea\u7136\u8a00\u8a9e\u51e6\u7406\u306b\u65b0\u98a8\u3092\u5dfb\u304d\u8d77\u3053\u3057\u305fWord2Vec\u3068\u306f\u4f55\u304b - \u65e5\u7d4cBigData \u306e\u8aac\u660e\u3092\u62dd\u501f\u3059\u308b\u3068\uff0cword2vec \u3068\u306f\u3064\u304e\u306e\u3088\u3046\u306a\u8aac\u660e\u306b\u306a\u308a\u307e\u3059\n\nWord2Vec\u306f\u3001\u305d\u306e\u540d\u524d\u306e\u8868\u3059\u901a\u308a\u3001\u5358\u8a9e\u3092\u30d9\u30af\u30c8\u30eb\u5316\u3057\u3066\u8868\u73fe\u3059\u308b\u3059\u308b\u5b9a\u91cf\u5316\u624b\u6cd5\u3067\u3042\u308b\u3002\u4f8b\u3048\u3070\u65e5\u672c\u4eba\u304c\u65e5\u5e38\u7684\u306b\u4f7f\u3046\u8a9e\u5f59\u6570\u306f\u6570\u4e07\u304b\u3089\u6570\u5341\u4e07\u3068\u3044\u308f\u308c\u308b\u304c\u3001Word2Vec\u3067\u306f\u5404\u5358\u8a9e\u3092200\u6b21\u5143\u304f\u3089\u3044\u306e\u7a7a\u9593\u5185\u306b\u304a\u3051\u308b\u30d9\u30af\u30c8\u30eb\u3068\u3057\u3066\u8868\u73fe\u3059\u308b\u3002\n\u305d\u308c\u305e\u308c\u306e\u5358\u8a9e\u3092200\u500b\u306e\u8981\u7d20\u306e\u7d44\u307f\u5408\u308f\u305b\u3068\u3057\u3066\u8868\u73fe\u3059\u308b\u305f\u3081\u3001\u3053\u306e\u3088\u3046\u306a\u624b\u6cd5\u306f\u300c\u5206\u6563\u8868\u73fe\u300d\u3068\u3082\u547c\u3070\u308c\u3066\u3044\u308b\u3002\u5358\u8a9e\u304b\u3089\u30d9\u30af\u30c8\u30eb\u8868\u73fe\u3092\u4f5c\u308a\u51fa\u3059\u7814\u7a76\u306f\u4ee5\u524d\u306b\u3082\u3042\u3063\u305f\u304c\u3001\u305d\u308c\u3089\u3068\u306e\u9055\u3044\u306f\u3001\u305d\u306e\u30d9\u30af\u30c8\u30eb\u304c\u305f\u3060\u306e\u6570\u5b66\u7684\u306a\u5b58\u5728\u3068\u3057\u3066\u4ee5\u4e0a\u306b\u3001\u8907\u96d1\u306a\u30b3\u30f3\u30bb\u30d7\u30c8\u3092\u8868\u73fe\u3057\u3066\u3044\u308b\u3053\u3068\u306b\u3042\u308b\u3002\u5b9f\u4f8b\u3092\u898b\u3066\u307f\u308b\u3068\u305d\u306e\u53ef\u80fd\u6027\u304c\u5b9f\u611f\u3067\u304d\u308b\u3060\u308d\u3046\u3002\n\nApache Spark \u306b\u5b9f\u88c5\u3055\u308c\u3066\u3044\u308b word2vec \u306f\uff0cDaabricks \u793e\u306e Xiangrui Meng \u3068 Pivotal \u793e\u306e Liquan Pei \u306b\u3088\u3063\u3066\u5b9f\u88c5\u3055\u308c\u307e\u3057\u305f\uff0e\nGoogle \u672c\u5bb6\u306e word2vec - Tool for computing continuous distributed representations of words. - Google Project Hosting \u306b\u5bfe\u3057\u3066\u63d0\u4f9b\u3055\u308c\u3066\u3044\u308b Public API \u306f\u307e\u3060\u307e\u3060\u8db3\u308a\u306a\u304f\u3066\uff0c\u5bfe\u8c61\u306e\u5358\u8a9e\u3068 Cosine \u8ddd\u96e2\u304c\u8fd1\u3044\u5358\u8a9e\u3092\u8fd4\u3059\u306a\u3069\u304c\u3067\u304d\u307e\u305b\u3093\uff0e\n\u3057\u304b\u3057\u5927\u898f\u6a21\u30c7\u30fc\u30bf\u306b\u5bfe\u3057\u3066\u5272\u3068\u9ad8\u901f\u306b\u5b9f\u884c\u3067\u304d\u308b\u306e\u3067\uff0c\u304a\u8a66\u3057\u306b\u5b9f\u884c\u3057\u3066\u307f\u308b\u3068\u306a\u304b\u306a\u304b\u304a\u3082\u3057\u308d\u3044\u3067\u3059\uff0e\n\n\u74b0\u5883\u69cb\u7bc9\nAmazon EC2 \u4e0a\u3067 Apache Spark \u306e\u30af\u30e9\u30b9\u30bf\u3092\u69cb\u7bc9\u3059\u308b\u305f\u3081\u306e\u30b9\u30af\u30ea\u30d7\u30c8\u306f\uff0cSpark \u306e\u30bd\u30fc\u30b9\u30b3\u30fc\u30c9\u306b\u542b\u307e\u308c\u3066\u3044\u307e\u3059\uff0e\n\u3053\u3061\u3089\u306e\u30b9\u30af\u30ea\u30d7\u30c8\u3067\uff11\u30b3\u30de\u30f3\u30c9\u3067\u7c21\u5358\u306b\u69cb\u7bc9\u3059\u308b\u3053\u3068\u304c\u3067\u304d\u307e\u3059\uff0e\n\u4eca\u56de\u306f\uff0c\u3064\u304e\u306e\u3088\u3046\u306a\u69cb\u6210\u3067\u30af\u30e9\u30b9\u30bf\u3092\u7acb\u3061\u4e0a\u3052\u307e\u3059\uff0e\n\nSpark version: 1.1.1\nMaster Instance Type: r3.large\nSlave Instance Type: r3.8xlarge\n# Slave Instances: 5\n\n\nTotal CPU Cores: 160\nTotal Memory: 1195.0 GB\n\n\n\n# clone spark\ngit clone https://github.com/apache/spark.git \ncd spark\n\n# launch a spark cluster\n_REGION='ap-northeast1'\n_ZONE='ap-northeast-1b'\n_VERSION='1.1.1'\n_MASTER_INSTANCE_TYPE='r3.large'\n_SLAVE_INSTANCE_TYPE='r3.8xlarge'\n_SLAVES=5\n_PRICE=1.0\n_CLUSTER_NAME=\"spark-cluster-v${_VERSION}-${_SLAVE_INSTANCE_TYPE}x${_SLAVES}\"\n./ec2/spark-ec2 -k \"YOUR_KEY_NAME\" -i \"YOUR_SSH_KEY\" -s $_SLAVES --master-instance-type=\"$_MASTER_INSTANCE_TYPE\" --instance-type=\"$_SLAVE_INSTANCE_TYPE\" --region=\"$_REGION\" --zone=\"$_ZONE\" --spot-price=$_PRICE --spark-version=\"${_VERSION}\" --hadoop-major-version=2 launch \"$_CLUSTER_NAME\"\n\n\n\u5b9f\u969b\u306b word2vec \u3092\u52d5\u304b\u3057\u3066\u307f\u308b\uff0e\n\n\u30c7\u30fc\u30bf\u306e\u6e96\u5099\n\u4eca\u56de\u5229\u7528\u3057\u305f\u30c7\u30fc\u30bf\u306f\uff0c Wikipedia \u306e\u82f1\u8a9e\u7248\u306e\u30c7\u30fc\u30bf \u306b\u306a\u308a\u307e\u3059\uff0e\nWikipedia \u306e\u30c7\u30fc\u30bf\u3092\u6271\u3044\u3084\u3059\u304f\u3059\u308b\u305f\u3081\u306e\u8a18\u4e8b\u306f\uff0cWikipedia\u30c7\u30fc\u30bf\u3092xml2sql\u3092\u5229\u7528\u3057MySQL\u306b\u3076\u3063\u3053\u3080 - Miningoo \u304c\u53c2\u8003\u306b\u306a\u308a\u307e\u3059\uff0e\n\u62bd\u51fa\u3057\u305f\u5143\u306e\u30c6\u30ad\u30b9\u30c8\u30c7\u30fc\u30bf\u306f\uff0c\u7d04 38 GB \u306b\u306a\u308a\u307e\u3057\u305f\uff0e\n\nword2vec \u306e\u30e2\u30c7\u30eb\u69cb\u7bc9\nWikipedia \u306e\u30c0\u30f3\u30d7\u30c7\u30fc\u30bf\u304b\u3089 Wikimarkup \u306e\u30c6\u30ad\u30b9\u30c8\u90e8\u5206\u3092\u629c\u304d\u53d6\u308a\uff0cWord2Vec \u3067\u30e2\u30c7\u30eb\u3092\u69cb\u7bc9\u3059\u308b\u305f\u3081\u306e\u30b3\u30fc\u30c9\u306f\u3064\u304e\u306e\u3088\u3046\u306b\u306a\u308a\u307e\u3059\uff0e\n// Imports the dependent libraries\nimport org.apache.spark.mllib.feature.Word2Vec\nimport org.apache.spark.mllib.linalg.Vectors\nimport org.apache.spark.mllib.linalg.Vector\nimport org.apache.spark.rdd.RDD\nimport org.apache.spark.SparkContext\nimport org.apache.spark.SparkContext._\nimport org.apache.spark.SparkFiles\n\n// Loads the input file.\nval path = \"s3n://xxxxxxx/wikipedia/en/text-en.txt\"\nval source: RDD[String] = sc.textFile(path)\n\n// Formats the input file.\nval lines = source.map(line => line.replaceAll(\"\"\"^[0-9]*\\s*\"\"\", \"\"))\nval input = lines.map(content => content.split(\" \").map(_.replaceAll(\"\"\"(\\n|\\[|\\s|\\]|'|\\|\\|)\"\"\", \"\")).toSeq).cache\ninput.count\n\n// Trains a Word2Vec model.\nval model = new Word2Vec().setVectorSize(10).setNumPartitions(10).fit(input)\n\n\n\u69cb\u7bc9\u3057\u305f\u30e2\u30c7\u30eb\u306b\u304a\u3051\u308b\u95a2\u9023\u5358\u8a9e\u306e\u62bd\u51fa\n\u69cb\u7bc9\u3057\u305f\u30e2\u30c7\u30eb\u3092\u7528\u3044\u3066\u985e\u4f3c\u8a9e\u3092\u62bd\u51fa\u3059\u308b\u305f\u3081\u306e\u51e6\u7406\u306f\u3064\u304e\u306b\u306a\u308a\u307e\u3059\uff0e\nmodel.findSynonyms(\"America\", 5).foreach(println)\nmodel.findSynonyms(\"Japan\", 5).foreach(println)\n\n\nApache Spark \u3067 Word2Vec \u3092\u4f7f\u3046\u4e0a\u3067\u306e\u8ab2\u984c\nApache Spark \u306e Mllib \u3067\u5b9f\u88c5\u3055\u308c\u3066\u3044\u308b Word2Vec \u306f\uff0c\u73fe\u72b6\u5927\u898f\u6a21\u30c7\u30fc\u30bf\u306b\u5bfe\u3057\u3066\u9069\u5fdc\u3059\u308b\u306b\u306f\uff12\u3064\u306e\u70b9\u3067\u96e3\u3057\u3044\u3067\u3059\uff0e\n\uff11\u3064\u306f\uff0c\u7cbe\u5ea6\u3092\u3042\u3052\u3088\u3046\u3068\u601d\u3046\u3068 MapReduce \u30a2\u30eb\u30b4\u30ea\u30ba\u30e0\u306e Reduce \u90e8\u5206\u3092\u5c11\u306a\u304f\u8a2d\u5b9a\u3057\u306a\u3051\u308c\u3070\u306a\u3089\u306a\u3044\u306e\u3067\uff0c\u5927\u898f\u6a21\u306a\u30c7\u30fc\u30bf\u306b\u9069\u5fdc\u3059\u308b\u3068\u591a\u304f\u306e\u5834\u5408\u8db3\u308a\u306a\u304f\u306a\u308a\u307e\u3059\uff0e\n\u307e\u305f\u540c\u69d8\u306e\u7406\u7531\u3067\uff0c\u51e6\u7406\u901f\u5ea6\u304c\u843d\u3061\u3066\u3057\u307e\u3046\u306e\u3082\u6b20\u70b9\u3067\u3059\uff0e\n\uff12\u3064\u3081\u306f\uff0c\u69cb\u7bc9\u3055\u308c\u305f\u30e2\u30c7\u30eb\u306f\u5404\u5358\u8a9e\u3068\u305d\u306e\u30d9\u30af\u30c8\u30eb\u3092\u901a\u5e38\u306e Scala \u306e Map[String, Array[Float]] \u3068\u3057\u3066\u8868\u73fe\u3055\u308c\u3066\u3044\u307e\u3059\uff0e\n\u305d\u306e\u305f\u3081\u3042\u307e\u308a\u306b\u3082\u305f\u304f\u3055\u3093\u306e\u5358\u8a9e\u304c\u3042\u308b\u3068\u304d\u306f\uff0cMap \u3068\u3057\u3066\u4fdd\u6301\u3067\u304d\u306a\u304f\u306a\u3063\u3066\u3057\u307e\u3044\u307e\u3059\uff0e\n\n\u3053\u306e\u8a18\u4e8b\u306f\uff0c [Spark, SQL on Hadoop etc. Advent Calendar 2014 - Qiita](http://qiita.com/advent-calendar/2014/distributedcomputing) \u306e 12 \u6708\uff16\u65e5\u306e\u305f\u3081\u306e\u8a18\u4e8b\u3067\u3059\uff0e\n\n\u4eca\u56de\u306e\u8a18\u4e8b\u3067\u306f\uff0c\u6700\u8fd1\u8a71\u984c\u306b\u306a\u3063\u3066\u3044\u308b word2vec \u306e Apache Spark \u5b9f\u88c5\u3092 EC2 \u4e0a\u3067\u52d5\u304b\u3059\u65b9\u6cd5\u306b\u3064\u3044\u3066\u89e3\u8aac\u3057\u307e\u3059\uff0e\n\n## word2vec \u3068\u306f\uff1f\n\n[\u81ea\u7136\u8a00\u8a9e\u51e6\u7406\u306b\u65b0\u98a8\u3092\u5dfb\u304d\u8d77\u3053\u3057\u305fWord2Vec\u3068\u306f\u4f55\u304b - \u65e5\u7d4cBigData](http://business.nikkeibp.co.jp/article/bigdata/20141110/273649/) \u306e\u8aac\u660e\u3092\u62dd\u501f\u3059\u308b\u3068\uff0cword2vec \u3068\u306f\u3064\u304e\u306e\u3088\u3046\u306a\u8aac\u660e\u306b\u306a\u308a\u307e\u3059\n\n>Word2Vec\u306f\u3001\u305d\u306e\u540d\u524d\u306e\u8868\u3059\u901a\u308a\u3001\u5358\u8a9e\u3092\u30d9\u30af\u30c8\u30eb\u5316\u3057\u3066\u8868\u73fe\u3059\u308b\u3059\u308b\u5b9a\u91cf\u5316\u624b\u6cd5\u3067\u3042\u308b\u3002\u4f8b\u3048\u3070\u65e5\u672c\u4eba\u304c\u65e5\u5e38\u7684\u306b\u4f7f\u3046\u8a9e\u5f59\u6570\u306f\u6570\u4e07\u304b\u3089\u6570\u5341\u4e07\u3068\u3044\u308f\u308c\u308b\u304c\u3001Word2Vec\u3067\u306f\u5404\u5358\u8a9e\u3092200\u6b21\u5143\u304f\u3089\u3044\u306e\u7a7a\u9593\u5185\u306b\u304a\u3051\u308b\u30d9\u30af\u30c8\u30eb\u3068\u3057\u3066\u8868\u73fe\u3059\u308b\u3002\n>\u305d\u308c\u305e\u308c\u306e\u5358\u8a9e\u3092200\u500b\u306e\u8981\u7d20\u306e\u7d44\u307f\u5408\u308f\u305b\u3068\u3057\u3066\u8868\u73fe\u3059\u308b\u305f\u3081\u3001\u3053\u306e\u3088\u3046\u306a\u624b\u6cd5\u306f\u300c\u5206\u6563\u8868\u73fe\u300d\u3068\u3082\u547c\u3070\u308c\u3066\u3044\u308b\u3002\u5358\u8a9e\u304b\u3089\u30d9\u30af\u30c8\u30eb\u8868\u73fe\u3092\u4f5c\u308a\u51fa\u3059\u7814\u7a76\u306f\u4ee5\u524d\u306b\u3082\u3042\u3063\u305f\u304c\u3001\u305d\u308c\u3089\u3068\u306e\u9055\u3044\u306f\u3001\u305d\u306e\u30d9\u30af\u30c8\u30eb\u304c\u305f\u3060\u306e\u6570\u5b66\u7684\u306a\u5b58\u5728\u3068\u3057\u3066\u4ee5\u4e0a\u306b\u3001\u8907\u96d1\u306a\u30b3\u30f3\u30bb\u30d7\u30c8\u3092\u8868\u73fe\u3057\u3066\u3044\u308b\u3053\u3068\u306b\u3042\u308b\u3002\u5b9f\u4f8b\u3092\u898b\u3066\u307f\u308b\u3068\u305d\u306e\u53ef\u80fd\u6027\u304c\u5b9f\u611f\u3067\u304d\u308b\u3060\u308d\u3046\u3002\n\nApache Spark \u306b\u5b9f\u88c5\u3055\u308c\u3066\u3044\u308b word2vec \u306f\uff0cDaabricks \u793e\u306e Xiangrui Meng \u3068 Pivotal \u793e\u306e Liquan Pei \u306b\u3088\u3063\u3066\u5b9f\u88c5\u3055\u308c\u307e\u3057\u305f\uff0e\nGoogle \u672c\u5bb6\u306e [word2vec - Tool for computing continuous distributed representations of words. - Google Project Hosting](https://code.google.com/p/word2vec/) \u306b\u5bfe\u3057\u3066\u63d0\u4f9b\u3055\u308c\u3066\u3044\u308b Public API \u306f\u307e\u3060\u307e\u3060\u8db3\u308a\u306a\u304f\u3066\uff0c\u5bfe\u8c61\u306e\u5358\u8a9e\u3068 Cosine \u8ddd\u96e2\u304c\u8fd1\u3044\u5358\u8a9e\u3092\u8fd4\u3059\u306a\u3069\u304c\u3067\u304d\u307e\u305b\u3093\uff0e\n\u3057\u304b\u3057\u5927\u898f\u6a21\u30c7\u30fc\u30bf\u306b\u5bfe\u3057\u3066\u5272\u3068\u9ad8\u901f\u306b\u5b9f\u884c\u3067\u304d\u308b\u306e\u3067\uff0c\u304a\u8a66\u3057\u306b\u5b9f\u884c\u3057\u3066\u307f\u308b\u3068\u306a\u304b\u306a\u304b\u304a\u3082\u3057\u308d\u3044\u3067\u3059\uff0e\n\n## \u74b0\u5883\u69cb\u7bc9\n\nAmazon EC2 \u4e0a\u3067 Apache Spark \u306e\u30af\u30e9\u30b9\u30bf\u3092\u69cb\u7bc9\u3059\u308b\u305f\u3081\u306e\u30b9\u30af\u30ea\u30d7\u30c8\u306f\uff0cSpark \u306e\u30bd\u30fc\u30b9\u30b3\u30fc\u30c9\u306b\u542b\u307e\u308c\u3066\u3044\u307e\u3059\uff0e\n\u3053\u3061\u3089\u306e\u30b9\u30af\u30ea\u30d7\u30c8\u3067\uff11\u30b3\u30de\u30f3\u30c9\u3067\u7c21\u5358\u306b\u69cb\u7bc9\u3059\u308b\u3053\u3068\u304c\u3067\u304d\u307e\u3059\uff0e\n\n\u4eca\u56de\u306f\uff0c\u3064\u304e\u306e\u3088\u3046\u306a\u69cb\u6210\u3067\u30af\u30e9\u30b9\u30bf\u3092\u7acb\u3061\u4e0a\u3052\u307e\u3059\uff0e\n\n- Spark version: 1.1.1\n- Master Instance Type: r3.large\n- Slave Instance Type: r3.8xlarge\n- # Slave Instances: 5\n    - Total CPU Cores: 160\n    - Total Memory: 1195.0 GB\n\n\n```\n# clone spark\ngit clone https://github.com/apache/spark.git \ncd spark\n\n# launch a spark cluster\n_REGION='ap-northeast1'\n_ZONE='ap-northeast-1b'\n_VERSION='1.1.1'\n_MASTER_INSTANCE_TYPE='r3.large'\n_SLAVE_INSTANCE_TYPE='r3.8xlarge'\n_SLAVES=5\n_PRICE=1.0\n_CLUSTER_NAME=\"spark-cluster-v${_VERSION}-${_SLAVE_INSTANCE_TYPE}x${_SLAVES}\"\n./ec2/spark-ec2 -k \"YOUR_KEY_NAME\" -i \"YOUR_SSH_KEY\" -s $_SLAVES --master-instance-type=\"$_MASTER_INSTANCE_TYPE\" --instance-type=\"$_SLAVE_INSTANCE_TYPE\" --region=\"$_REGION\" --zone=\"$_ZONE\" --spot-price=$_PRICE --spark-version=\"${_VERSION}\" --hadoop-major-version=2 launch \"$_CLUSTER_NAME\"\n```\n\n## \u5b9f\u969b\u306b word2vec \u3092\u52d5\u304b\u3057\u3066\u307f\u308b\uff0e\n\n### \u30c7\u30fc\u30bf\u306e\u6e96\u5099\n\n\u4eca\u56de\u5229\u7528\u3057\u305f\u30c7\u30fc\u30bf\u306f\uff0c [Wikipedia \u306e\u82f1\u8a9e\u7248\u306e\u30c7\u30fc\u30bf](http://en.wikipedia.org/wiki/Wikipedia:Database_download) \u306b\u306a\u308a\u307e\u3059\uff0e\nWikipedia \u306e\u30c7\u30fc\u30bf\u3092\u6271\u3044\u3084\u3059\u304f\u3059\u308b\u305f\u3081\u306e\u8a18\u4e8b\u306f\uff0c[Wikipedia\u30c7\u30fc\u30bf\u3092xml2sql\u3092\u5229\u7528\u3057MySQL\u306b\u3076\u3063\u3053\u3080 - Miningoo](http://miningoo.hatenablog.com/entry/2014/10/30/Wikipedia%E3%83%87%E3%83%BC%E3%82%BF%E3%82%92xml2sql%E3%82%92%E5%88%A9%E7%94%A8%E3%81%97MySQL%E3%81%AB%E3%81%B6%E3%81%A3%E3%81%93%E3%82%80) \u304c\u53c2\u8003\u306b\u306a\u308a\u307e\u3059\uff0e\n\u62bd\u51fa\u3057\u305f\u5143\u306e\u30c6\u30ad\u30b9\u30c8\u30c7\u30fc\u30bf\u306f\uff0c\u7d04 38 GB \u306b\u306a\u308a\u307e\u3057\u305f\uff0e\n\n### word2vec \u306e\u30e2\u30c7\u30eb\u69cb\u7bc9\n\nWikipedia \u306e\u30c0\u30f3\u30d7\u30c7\u30fc\u30bf\u304b\u3089 Wikimarkup \u306e\u30c6\u30ad\u30b9\u30c8\u90e8\u5206\u3092\u629c\u304d\u53d6\u308a\uff0cWord2Vec \u3067\u30e2\u30c7\u30eb\u3092\u69cb\u7bc9\u3059\u308b\u305f\u3081\u306e\u30b3\u30fc\u30c9\u306f\u3064\u304e\u306e\u3088\u3046\u306b\u306a\u308a\u307e\u3059\uff0e\n\n```\n// Imports the dependent libraries\nimport org.apache.spark.mllib.feature.Word2Vec\nimport org.apache.spark.mllib.linalg.Vectors\nimport org.apache.spark.mllib.linalg.Vector\nimport org.apache.spark.rdd.RDD\nimport org.apache.spark.SparkContext\nimport org.apache.spark.SparkContext._\nimport org.apache.spark.SparkFiles\n\n// Loads the input file.\nval path = \"s3n://xxxxxxx/wikipedia/en/text-en.txt\"\nval source: RDD[String] = sc.textFile(path)\n\n// Formats the input file.\nval lines = source.map(line => line.replaceAll(\"\"\"^[0-9]*\\s*\"\"\", \"\"))\nval input = lines.map(content => content.split(\" \").map(_.replaceAll(\"\"\"(\\n|\\[|\\s|\\]|'|\\|\\|)\"\"\", \"\")).toSeq).cache\ninput.count\n\n// Trains a Word2Vec model.\nval model = new Word2Vec().setVectorSize(10).setNumPartitions(10).fit(input)\n```\n\n### \u69cb\u7bc9\u3057\u305f\u30e2\u30c7\u30eb\u306b\u304a\u3051\u308b\u95a2\u9023\u5358\u8a9e\u306e\u62bd\u51fa\n\n\u69cb\u7bc9\u3057\u305f\u30e2\u30c7\u30eb\u3092\u7528\u3044\u3066\u985e\u4f3c\u8a9e\u3092\u62bd\u51fa\u3059\u308b\u305f\u3081\u306e\u51e6\u7406\u306f\u3064\u304e\u306b\u306a\u308a\u307e\u3059\uff0e\n\n```\nmodel.findSynonyms(\"America\", 5).foreach(println)\nmodel.findSynonyms(\"Japan\", 5).foreach(println)\n```\n\n## Apache Spark \u3067 Word2Vec \u3092\u4f7f\u3046\u4e0a\u3067\u306e\u8ab2\u984c\n\nApache Spark \u306e Mllib \u3067\u5b9f\u88c5\u3055\u308c\u3066\u3044\u308b `Word2Vec` \u306f\uff0c\u73fe\u72b6\u5927\u898f\u6a21\u30c7\u30fc\u30bf\u306b\u5bfe\u3057\u3066\u9069\u5fdc\u3059\u308b\u306b\u306f\uff12\u3064\u306e\u70b9\u3067\u96e3\u3057\u3044\u3067\u3059\uff0e\n\uff11\u3064\u306f\uff0c\u7cbe\u5ea6\u3092\u3042\u3052\u3088\u3046\u3068\u601d\u3046\u3068 MapReduce \u30a2\u30eb\u30b4\u30ea\u30ba\u30e0\u306e Reduce \u90e8\u5206\u3092\u5c11\u306a\u304f\u8a2d\u5b9a\u3057\u306a\u3051\u308c\u3070\u306a\u3089\u306a\u3044\u306e\u3067\uff0c\u5927\u898f\u6a21\u306a\u30c7\u30fc\u30bf\u306b\u9069\u5fdc\u3059\u308b\u3068\u591a\u304f\u306e\u5834\u5408\u8db3\u308a\u306a\u304f\u306a\u308a\u307e\u3059\uff0e\n\u307e\u305f\u540c\u69d8\u306e\u7406\u7531\u3067\uff0c\u51e6\u7406\u901f\u5ea6\u304c\u843d\u3061\u3066\u3057\u307e\u3046\u306e\u3082\u6b20\u70b9\u3067\u3059\uff0e\n\uff12\u3064\u3081\u306f\uff0c\u69cb\u7bc9\u3055\u308c\u305f\u30e2\u30c7\u30eb\u306f\u5404\u5358\u8a9e\u3068\u305d\u306e\u30d9\u30af\u30c8\u30eb\u3092\u901a\u5e38\u306e Scala \u306e `Map[String, Array[Float]]` \u3068\u3057\u3066\u8868\u73fe\u3055\u308c\u3066\u3044\u307e\u3059\uff0e\n\u305d\u306e\u305f\u3081\u3042\u307e\u308a\u306b\u3082\u305f\u304f\u3055\u3093\u306e\u5358\u8a9e\u304c\u3042\u308b\u3068\u304d\u306f\uff0c`Map` \u3068\u3057\u3066\u4fdd\u6301\u3067\u304d\u306a\u304f\u306a\u3063\u3066\u3057\u307e\u3044\u307e\u3059\uff0e\n"}