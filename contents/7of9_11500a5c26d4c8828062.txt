{"context": "http://qiita.com/7of9/items/d4fc540c1dc92f2f0c85\n\u306b\u304a\u3044\u3066\u6c17\u306b\u306a\u3063\u305f\u56de\u5e30\u306eDeep Learning\u3002\n\u300csine TensorFlow regression\u300d\u3067\u691c\u7d22\u3057\u3066\u4ee5\u4e0b\u3092\u898b\u3064\u3051\u305f\u3002\nhttps://github.com/mouradmourafiq/tensorflow-lstm-regression\n\nThis is an example of a regressor based on recurrent networks:\nThe objective is to predict continuous values, sin and cos functions in this example, based on previous observations using the LSTM architecture.\n\nLSTM\u3092\u4f7f\u3063\u3066\u306e\u5b66\u7fd2\u306e\u3088\u3046\u3060\u3002\nlstm_sin.ipynb\u306a\u3069\u306eJupyter\u7528\u306e\u30d5\u30a1\u30a4\u30eb\u304c\u3042\u308b\u3002\n\u8a66\u305d\u3046\u3068\u3057\u305f\u304c\u3001\u4ee5\u4e0b\u306e\u30d1\u30c3\u30b1\u30fc\u30b8\u304c\u5fc5\u8981\u306b\u306a\u308b\n\nmatplotlib\npandas\ncython\ngfortran\nscipy\nscikit-learn\n\n\nlstm_sin.ipynb\u3092\u8a66\u3057\u3066\u307f\u305f\n\n\u52d5\u4f5c\u74b0\u5883\nUbuntu 14.04 LTS desktop amd64\nGeForce GTX 750 Ti\nASRock Z170M Pro4S [Intel Z170chipset]\nTensorFlow v0.11\ncuDNN v5.1 for Linux\nCUDA v7.5\nPython 2.7.6\nIPython 5.1.0 -- An enhanced Interactive Python.\nscipy 0.13.3-1build1\npython-matplotlib 1.3.1-1ubuntu5\ngfortran 4.8.4-2ubuntu1\n\n\n\n\u5b9f\u884c\u7d50\u679c\n\u4e0a\u8a18\u306e\u30bb\u30c3\u30c8\u30a2\u30c3\u30d7\u3092\u6e08\u307e\u305b\u3066lstm_sin.ipynb\u3092\u5b9f\u884c\u3057\u3066\u307f\u305f\u3002\nIn[4]\u306e\u5b9f\u884c\u306b\u306f\u3053\u3061\u3089\u306e\u74b0\u5883(GTX 750 Ti, 2GB)\u306730\u79d2\u304b\u304b\u3063\u305f\u3002\n\n\u4e0a\u8a18\u306e\u30b0\u30e9\u30d5\u306b\u304a\u3044\u3066\u3001\u4ee5\u4e0b\u306e\u70b9\u304c\u672a\u6d88\u5316\n\nsin(0)\u304c0.0\u3067\u306f\u306a\u3044\n\u6a2a\u8ef8\u306e\u5024\u304c\u4e0d\u660e\n\n\u8aa4\u5dee\u306f\u4ee5\u4e0b\u3060\u3063\u305f\u3002\nMSE: 0.000156\n\u30b3\u30fc\u30c9\u306e\u4e2d\u8eab\u306f\u307e\u3060\u672a\u6d88\u5316\u3002\n\u56de\u5e30\u306e\u5b66\u7fd2\u306b\u304a\u3044\u3066ConvNet\u3068RNN\u306e\u4f7f\u3044\u308f\u3051\u3082\u672a\u6d88\u5316\u3002\n\ncode\n%matplotlib inline\nimport numpy as np\nimport pandas as pd\nimport tensorflow as tf\nfrom matplotlib import pyplot as plt\n\nfrom tensorflow.contrib import learn\nfrom sklearn.metrics import mean_squared_error\n\nfrom lstm import generate_data, lstm_model\n\nLOG_DIR = './ops_logs/sin'\nTIMESTEPS = 3\nRNN_LAYERS = [{'num_units': 5}]\nDENSE_LAYERS = None\nTRAINING_STEPS = 10000\nPRINT_STEPS = TRAINING_STEPS / 10\nBATCH_SIZE = 100\n\nregressor = learn.Estimator(model_fn=lstm_model(TIMESTEPS, RNN_LAYERS, DENSE_LAYERS),\n                            model_dir=LOG_DIR)\n\nRNN_LAYERS\u3092\u4e0e\u3048\u3066regressor\u3068\u3044\u3046\u3082\u306e\u3092\u4f5c\u3063\u3066\u3044\u308b\u3002\nX, y = generate_data(np.sin, np.linspace(0, 100, 10000, dtype=np.float32), TIMESTEPS, seperate=False)\n\n# create a lstm instance and validation monitor\nvalidation_monitor = learn.monitors.ValidationMonitor(X['val'], y['val'],\n                                                     every_n_steps=PRINT_STEPS,\n                                                     early_stopping_rounds=1000)\n# print(X['train'])\n# print(y['train'])\n\nregressor.fit(X['train'], y['train'], \n              monitors=[validation_monitor], \n              batch_size=BATCH_SIZE,\n              steps=TRAINING_STEPS)\n\ngenerate_data()\u3092\u7528\u3044\u3066train\u30c7\u30fc\u30bf\u3092\u4f5c\u6210\u3057\u3066\u3044\u308b\u3002\nregressor.fit()\u306b\u3088\u308a\u5b66\u7fd2\u3092\u3057\u3066\u3044\u308b\u3068\u7406\u89e3\u3057\u305f\u3002\npredicted = regressor.predict(X['test'])\nrmse = np.sqrt(((predicted - y['test']) ** 2).mean(axis=0))\nscore = mean_squared_error(predicted, y['test'])\nprint (\"MSE: %f\" % score)\n\n\u8aa4\u5dee\u8a08\u7b97\u3002\nplot_predicted, = plt.plot(predicted, label='predicted')\nplot_test, = plt.plot(y['test'], label='test')\nplt.legend(handles=[plot_predicted, plot_test])\n\n\u30b0\u30e9\u30d5\u63cf\u753b\u3002\n\ncosine\u306b\u3057\u3066\u307f\u305f\n\ncosine curve\u3068\u3057\u3066\u3082\u4f4d\u76f8\u304c0\u304b\u3089\u3067\u306a\u3044\u3088\u3046\u3060\u304c\u672a\u6d88\u5316\u3060\u3063\u305f\u3002\n\nX\u306e\u5024\nX\u306b\u306ftrain\u3068test\u304c\u3042\u308b\u3088\u3046\u3060\u3002\nX['train']\n\narray([[[ 1.        ],\n        [ 0.99994999],\n        [ 0.99979997]],\n\n       [[ 0.99994999],\n        [ 0.99979997],\n        [ 0.99954993]],\n...\n\ntest\u306e\u65b9\u306f\u5024\u57df\u304c-0.45610371\u304b\u3089\u59cb\u307e\u3063\u3066\u3044\u308b\u3088\u3046\u3060\u3002\nX['test']\n\narray([[[-0.45610371],\n        [-0.46498191],\n        [-0.47380689]],\n\n       [[-0.46498191],\n        [-0.47380689],\n        [-0.48259121]],\n\n       [[-0.47380689],\n        [-0.48259121],\n        [-0.49132726]],\n\n       ..., \n       [[ 0.83593178],\n        [ 0.8413794 ],\n        [ 0.84673876]],\n\n       [[ 0.8413794 ],\n        [ 0.84673876],\n        [ 0.85201752]],\n\n       [[ 0.84673876],\n        [ 0.85201752],\n        [ 0.85721111]]], dtype=float32)\n\nX.keys\n\n['test', 'train', 'val']\n\nlen(X['train'])\n\n8097\n\nlen(X['test'])\n\n997\n\nlen(X['val'])\n\n897\n\n\u3053\u306e\uff13\u3064\u306e\u5024\u3092\u3069\u3053\u3067\u8a2d\u5b9a\u3057\u3066\u3044\u308b\u304b\u306f\u672a\u6d88\u5316\u3060\u3063\u305f\u3002\n8097 + 997 + 897 = 9991.\n\u30ea\u30f3\u30af\u8a18\u4e8b\u3067\u3060\u3044\u305f\u3044\u89e3\u6c7a\u3057\u305f\u3002\nhttp://qiita.com/7of9/items/d970baf3322b93efb02b\nhttp://qiita.com/7of9/items/d4fc540c1dc92f2f0c85\n\u306b\u304a\u3044\u3066\u6c17\u306b\u306a\u3063\u305f\u56de\u5e30\u306eDeep Learning\u3002\n\n\u300csine TensorFlow regression\u300d\u3067\u691c\u7d22\u3057\u3066\u4ee5\u4e0b\u3092\u898b\u3064\u3051\u305f\u3002\n\nhttps://github.com/mouradmourafiq/tensorflow-lstm-regression\n\n> This is an example of a regressor based on recurrent networks:\n\n> The objective is to predict continuous values, sin and cos functions in this example, based on previous observations using the LSTM architecture.\n\nLSTM\u3092\u4f7f\u3063\u3066\u306e\u5b66\u7fd2\u306e\u3088\u3046\u3060\u3002\n\nlstm_sin.ipynb\u306a\u3069\u306eJupyter\u7528\u306e\u30d5\u30a1\u30a4\u30eb\u304c\u3042\u308b\u3002\n\n\u8a66\u305d\u3046\u3068\u3057\u305f\u304c\u3001\u4ee5\u4e0b\u306e\u30d1\u30c3\u30b1\u30fc\u30b8\u304c\u5fc5\u8981\u306b\u306a\u308b\n\n- matplotlib\n- pandas\n- cython\n- gfortran\n- scipy\n- scikit-learn\n\n## lstm_sin.ipynb\u3092\u8a66\u3057\u3066\u307f\u305f\n\n```txt:\u52d5\u4f5c\u74b0\u5883\nUbuntu 14.04 LTS desktop amd64\nGeForce GTX 750 Ti\nASRock Z170M Pro4S [Intel Z170chipset]\nTensorFlow v0.11\ncuDNN v5.1 for Linux\nCUDA v7.5\nPython 2.7.6\nIPython 5.1.0 -- An enhanced Interactive Python.\nscipy 0.13.3-1build1\npython-matplotlib 1.3.1-1ubuntu5\ngfortran 4.8.4-2ubuntu1\n```\n\n### \u5b9f\u884c\u7d50\u679c\n\n\u4e0a\u8a18\u306e\u30bb\u30c3\u30c8\u30a2\u30c3\u30d7\u3092\u6e08\u307e\u305b\u3066lstm_sin.ipynb\u3092\u5b9f\u884c\u3057\u3066\u307f\u305f\u3002\n\n`In[4]`\u306e\u5b9f\u884c\u306b\u306f\u3053\u3061\u3089\u306e\u74b0\u5883(GTX 750 Ti, 2GB)\u306730\u79d2\u304b\u304b\u3063\u305f\u3002\n\n![qiita.png](https://qiita-image-store.s3.amazonaws.com/0/32870/88f49cf7-81ba-836f-d411-97cbd751b91f.png)\n\n\u4e0a\u8a18\u306e\u30b0\u30e9\u30d5\u306b\u304a\u3044\u3066\u3001\u4ee5\u4e0b\u306e\u70b9\u304c\u672a\u6d88\u5316\n\n- sin(0)\u304c0.0\u3067\u306f\u306a\u3044\n- \u6a2a\u8ef8\u306e\u5024\u304c\u4e0d\u660e\n\n\u8aa4\u5dee\u306f\u4ee5\u4e0b\u3060\u3063\u305f\u3002\n\n`MSE: 0.000156`\n\n\u30b3\u30fc\u30c9\u306e\u4e2d\u8eab\u306f\u307e\u3060\u672a\u6d88\u5316\u3002\n\u56de\u5e30\u306e\u5b66\u7fd2\u306b\u304a\u3044\u3066ConvNet\u3068RNN\u306e\u4f7f\u3044\u308f\u3051\u3082\u672a\u6d88\u5316\u3002\n\n### code\n\n```py\n%matplotlib inline\nimport numpy as np\nimport pandas as pd\nimport tensorflow as tf\nfrom matplotlib import pyplot as plt\n\nfrom tensorflow.contrib import learn\nfrom sklearn.metrics import mean_squared_error\n\nfrom lstm import generate_data, lstm_model\n```\n\n```py\nLOG_DIR = './ops_logs/sin'\nTIMESTEPS = 3\nRNN_LAYERS = [{'num_units': 5}]\nDENSE_LAYERS = None\nTRAINING_STEPS = 10000\nPRINT_STEPS = TRAINING_STEPS / 10\nBATCH_SIZE = 100\n```\n\n```py\nregressor = learn.Estimator(model_fn=lstm_model(TIMESTEPS, RNN_LAYERS, DENSE_LAYERS),\n                            model_dir=LOG_DIR)\n```\n\nRNN_LAYERS\u3092\u4e0e\u3048\u3066regressor\u3068\u3044\u3046\u3082\u306e\u3092\u4f5c\u3063\u3066\u3044\u308b\u3002\n\n```py\nX, y = generate_data(np.sin, np.linspace(0, 100, 10000, dtype=np.float32), TIMESTEPS, seperate=False)\n\n# create a lstm instance and validation monitor\nvalidation_monitor = learn.monitors.ValidationMonitor(X['val'], y['val'],\n                                                     every_n_steps=PRINT_STEPS,\n                                                     early_stopping_rounds=1000)\n# print(X['train'])\n# print(y['train'])\n\nregressor.fit(X['train'], y['train'], \n              monitors=[validation_monitor], \n              batch_size=BATCH_SIZE,\n              steps=TRAINING_STEPS)\n```\n\ngenerate_data()\u3092\u7528\u3044\u3066train\u30c7\u30fc\u30bf\u3092\u4f5c\u6210\u3057\u3066\u3044\u308b\u3002\nregressor.fit()\u306b\u3088\u308a\u5b66\u7fd2\u3092\u3057\u3066\u3044\u308b\u3068\u7406\u89e3\u3057\u305f\u3002\n\n\n```py\npredicted = regressor.predict(X['test'])\nrmse = np.sqrt(((predicted - y['test']) ** 2).mean(axis=0))\nscore = mean_squared_error(predicted, y['test'])\nprint (\"MSE: %f\" % score)\n```\n\n\u8aa4\u5dee\u8a08\u7b97\u3002\n\n```py\nplot_predicted, = plt.plot(predicted, label='predicted')\nplot_test, = plt.plot(y['test'], label='test')\nplt.legend(handles=[plot_predicted, plot_test])\n```\n\n\u30b0\u30e9\u30d5\u63cf\u753b\u3002\n\n### cosine\u306b\u3057\u3066\u307f\u305f\n\n![qiita.png](https://qiita-image-store.s3.amazonaws.com/0/32870/05f4e732-385b-e145-ed93-15e389a4315e.png)\n\ncosine curve\u3068\u3057\u3066\u3082\u4f4d\u76f8\u304c0\u304b\u3089\u3067\u306a\u3044\u3088\u3046\u3060\u304c\u672a\u6d88\u5316\u3060\u3063\u305f\u3002\n\n### X\u306e\u5024\n\nX\u306b\u306ftrain\u3068test\u304c\u3042\u308b\u3088\u3046\u3060\u3002\n\n```\nX['train']\n```\n\n```\narray([[[ 1.        ],\n        [ 0.99994999],\n        [ 0.99979997]],\n\n       [[ 0.99994999],\n        [ 0.99979997],\n        [ 0.99954993]],\n...\n```\n\ntest\u306e\u65b9\u306f\u5024\u57df\u304c-0.45610371\u304b\u3089\u59cb\u307e\u3063\u3066\u3044\u308b\u3088\u3046\u3060\u3002\n\n```\nX['test']\n```\n\n```\narray([[[-0.45610371],\n        [-0.46498191],\n        [-0.47380689]],\n\n       [[-0.46498191],\n        [-0.47380689],\n        [-0.48259121]],\n\n       [[-0.47380689],\n        [-0.48259121],\n        [-0.49132726]],\n\n       ..., \n       [[ 0.83593178],\n        [ 0.8413794 ],\n        [ 0.84673876]],\n\n       [[ 0.8413794 ],\n        [ 0.84673876],\n        [ 0.85201752]],\n\n       [[ 0.84673876],\n        [ 0.85201752],\n        [ 0.85721111]]], dtype=float32)\n```\n\n```\nX.keys\n```\n\n```\n['test', 'train', 'val']\n```\n\n```\nlen(X['train'])\n```\n\n```\n8097\n```\n\n```\nlen(X['test'])\n```\n\n```\n997\n```\n\n```\nlen(X['val'])\n```\n\n```\n897\n```\n\n\n\u3053\u306e\uff13\u3064\u306e\u5024\u3092\u3069\u3053\u3067\u8a2d\u5b9a\u3057\u3066\u3044\u308b\u304b\u306f\u672a\u6d88\u5316\u3060\u3063\u305f\u3002\n8097 + 997 + 897 = 9991.\n\n\u30ea\u30f3\u30af\u8a18\u4e8b\u3067\u3060\u3044\u305f\u3044\u89e3\u6c7a\u3057\u305f\u3002\nhttp://qiita.com/7of9/items/d970baf3322b93efb02b\n", "tags": ["borgWarp", "link", "TensorFlow", "RNN"]}