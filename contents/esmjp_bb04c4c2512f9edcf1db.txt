{"context": " More than 1 year has passed since last update.\u30fbhadoop\u30921\u304b\u3089\u52c9\u5f37\u3059\u308b\u70ba\u306b\u3001\u3068\u308a\u3042\u3048\u305a\u30b3\u30f3\u30c6\u30ca\u4e0a\u306b\u74b0\u5883\u69cb\u7bc9\n\u30fb\u624b\u9593\u3092\u7701\u304f\u305f\u3081sequenceiq/hadoop-docker\u3092\u5229\u7528\u3059\u308b\n\u30fb\u4e0b\u8a18\u69cb\u6210\u3067\u69cb\u7bc9\n\n\n\nnode name\n\u5f79\u5272\n\n\n\n\nhadoop1\nNamenode/ResourceManager/datanode/NodeManager\n\n\nhadoop2\ndatanode/NodeManager\n\n\nhadoop3\ndatanode/NodeManager\n\n\n\n\n\u30b3\u30f3\u30c6\u30ca\u30a4\u30e1\u30fc\u30b8\u3092\u5165\u624b\ndocker pull sequenceiq/hadoop-docker\n\n\n1\u30ce\u30fc\u30c9\u76ee\u8d77\u52d5\ndocker run -it --name hadoop1 -h hadoop1 -p 50070:50070 -p 8088:8088 sequenceiq/hadoop-docker /etc/bootstrap.sh -bash\n/\nStarting sshd:                                             [  OK  ]\nStarting namenodes on [hadoop1]\nhadoop1: starting namenode, logging to /usr/local/hadoop/logs/hadoop-root-namenode-hadoop1.out\nlocalhost: starting datanode, logging to /usr/local/hadoop/logs/hadoop-root-datanode-hadoop1.out\nStarting secondary namenodes [0.0.0.0]\n0.0.0.0: starting secondarynamenode, logging to /usr/local/hadoop/logs/hadoop-root-secondarynamenode-hadoop1.out\nstarting yarn daemons\nstarting resourcemanager, logging to /usr/local/hadoop/logs/yarn--resourcemanager-hadoop1.out\nlocalhost: starting nodemanager, logging to /usr/local/hadoop/logs/yarn-root-nodemanager-hadoop1.out\nbash-4.1# \n\n\n\n2\u30ce\u30fc\u30c9\u76ee\u8d77\u52d5\ndocker run -it --name hadoop2 -h hadoop2 sequenceiq/hadoop-docker /etc/bootstrap.sh -bash\n\n\n3\u30ce\u30fc\u30c9\u76ee\u8d77\u52d5\ndocker run -it --name hadoop3 -h hadoop3 sequenceiq/hadoop-docker /etc/bootstrap.sh -bash\n\n\u7ba1\u7406\u753b\u9762\u898b\u308b\u3068\u81ea\u52d5\u3067\u306f\u30af\u30e9\u30b9\u30bf\u306b\u306f\u306a\u3089\u306a\u3044\u3002\u3002\u3002\n\n\u505c\u6b62\nbootstrap\u3067\u5358\u4f53\u8d77\u52d5\u3057\u3066\u308b\u306e\u3067\u3001\u3068\u308a\u3042\u3048\u305a\u305d\u308c\u305e\u308c\u843d\u3068\u3059\n$HADOOP_PREFIX/sbin/stop-all.sh\n\n\nhosts\u8a2d\u5b9a\n\u305d\u308c\u305e\u308c\u306e\u30b3\u30f3\u30c6\u30ca\u3067\u5404\u30b3\u30f3\u30c6\u30ca\u306eIP\u3092\u8a18\u8ff0\nvi /etc/hosts\n172.17.0.2  hadoop1\n172.17.0.3  hadoop2\n172.17.0.4  hadoop3\n\n\nHDFS\u8a2d\u5b9a\n\u4ee5\u4e0b\u3001master\u3068\u306a\u308b1\u53f7\u6a5f\u3067\u5b9f\u65bd\n\n\u30c7\u30fc\u30bf\u30c7\u30a3\u30ec\u30af\u30c8\u30ea\u4f5c\u6210\nmkdir -p /hdfs/data1\n\n\ncore-site.xml\u4fee\u6b63\n\u4f5c\u6210\u3057\u305f\u30c7\u30a3\u30ec\u30af\u30c8\u30ea\u306e\u8a18\u8ff0\u3092\u8ffd\u8a18\nvi /usr/local/hadoop/etc/hadoop/core-site.xml \n<configuration>\n   <property>\n      <name>fs.defaultFS</name>\n      <value>hdfs://hadoop1:9000</value>\n   </property>\n   <property>\n      <name>hadoop.tmp.dir</name>\n      <value>/hdfs/data1</value>\n   </property>\n</configuration>\n\n\nmapred-site.xml\u4fee\u6b63\n\u4e0b\u8a18\u3092\u8ffd\u8a18\nvi mapred-site.xml\n    <name>mapred.job.tracker</name>\n    <value>hadoop1:8021</value>\n    <final>true</final>\n  </property>\n\n\nyarn-site.xml\u4fee\u6b63\n\u4e0b\u8a18\u3092\u8ffd\u8a18\nvi yarn-site.xml \n  <property>\n   <name>yarn.resourcemanager.resource-tracker.address</name>\n   <value>hadoop1:8031</value>\n  </property>\n\n\nslave\u4fee\u6b63\nvi slaves\nhadoop1\nhadoop2\nhadoop3\n\n\n2\u301c3\u30ce\u30fc\u30c9\u76ee\u306b\u30b3\u30d4\u30fc\nrsync\u3067\u30b3\u30d4\u30fc\nrsync -av /usr/local/hadoop/etc/hadoop/ hadoop2:/usr/local/hadoop/etc/hadoop/\n\nrsync -av /usr/local/hadoop/etc/hadoop/ hadoop3:/usr/local/hadoop/etc/hadoop/\n\n\n\u521d\u671f\u5316\n$HADOOP_PREFIX/bin/hadoop namenode -format\n\n\n\u8d77\u52d5\n1\u53f7\u6a5f\u3067\u8d77\u52d5\n$HADOOP_PREFIX/sbin/start-all.sh\n\n\n\u8d77\u52d5\u78ba\u8a8d\njps\u30b3\u30de\u30f3\u30c9\u3067\u78ba\u8a8d\nnode1\njps\n218 NameNode\n769 NodeManager\n349 DataNode\n663 ResourceManager\n481 SecondaryNameNode\n1089 Jps\n\nnode2\u301c3\njps\n260 Jps\n162 NodeManager\n61 DataNode\n\n\n\u8d77\u52d5\u78ba\u8a8d\uff20WebUI\n\u3068\u308a\u3042\u3048\u305a\u30013\u53f0\u30af\u30e9\u30b9\u30bf\u69cb\u6210\u3067\u8d77\u52d5\u3057\u305f\nhttp://192.168.99.100:8088/cluster/nodes\n\nhttp://192.168.99.100:50070/\n\n\n\u30b3\u30f3\u30c6\u30ca\u518d\u8d77\u52d5\u5bfe\u5fdc\n\nbootstrap\u30b3\u30e1\u30f3\u30c8\u30a2\u30a6\u30c8\n\u30b3\u30f3\u30c6\u30ca\u518d\u8d77\u52d5\u3067\u30b3\u30f3\u30d5\u30a3\u30b0\u521d\u671f\u5316\uff06\u7121\u99c4\u306b\u8d77\u52d5\u3059\u308b\u306e\u3067\u52d5\u304b\u306a\u3044\u3088\u3046\u306b\u3059\u308b\u3002\nvi /etc/bootstrap.sh\n#!/bin/bash\n\n: ${HADOOP_PREFIX:=/usr/local/hadoop}\n\n$HADOOP_PREFIX/etc/hadoop/hadoop-env.sh\n\nrm /tmp/*.pid\n\n# installing libraries if any - (resource urls added comma separated to the ACP system variable)\ncd $HADOOP_PREFIX/share/hadoop/common ; for cp in ${ACP//,/ }; do  echo == $cp; curl -LO $cp ; done; cd -\n\n# altering the core-site configuration\n#sed s/HOSTNAME/$HOSTNAME/ /usr/local/hadoop/etc/hadoop/core-site.xml.template > /usr/local/hadoop/etc/hadoop/core-site.xml\n\n\nservice sshd start\n#$HADOOP_PREFIX/sbin/start-dfs.sh\n#$HADOOP_PREFIX/sbin/start-yarn.sh\n\nif [[ $1 == \"-d\" ]]; then\n  while true; do sleep 1000; done\nfi\n\nif [[ $1 == \"-bash\" ]]; then\n  /bin/bash\nfi\n\n\u3042\u3068\u306fhosts\u304c\u6bce\u56de\u521d\u671f\u5316\u3055\u308c\u308b&IP\u5909\u308f\u308b\u304b\u3089\u3069\u30fc\u3057\u3088\u3002\u3002\n\u4e00\u5fdc\u30b3\u30f3\u30c6\u30ca\u518d\u8d77\u52d5\u5f8c\u3001hosts\u66f8\u304d\u63db\u3048\u3066node1\u3067start-all.sh \u53e9\u3051\u3070\u30af\u30e9\u30b9\u30bf\u72b6\u614b\u3067\u8d77\u52d5\u3059\u308b\u3002\n\n\u30fbhadoop\u30921\u304b\u3089\u52c9\u5f37\u3059\u308b\u70ba\u306b\u3001\u3068\u308a\u3042\u3048\u305a\u30b3\u30f3\u30c6\u30ca\u4e0a\u306b\u74b0\u5883\u69cb\u7bc9\n\u30fb\u624b\u9593\u3092\u7701\u304f\u305f\u3081sequenceiq/hadoop-docker\u3092\u5229\u7528\u3059\u308b\n\u30fb\u4e0b\u8a18\u69cb\u6210\u3067\u69cb\u7bc9\n\n| node name | \u5f79\u5272 |\n|:---------:|:---------:|\n| hadoop1   |Namenode/ResourceManager/datanode/NodeManager |\n| hadoop2   |datanode/NodeManager|\n| hadoop3   |datanode/NodeManager|\n\n\n\n## \u30b3\u30f3\u30c6\u30ca\u30a4\u30e1\u30fc\u30b8\u3092\u5165\u624b\n\n```\ndocker pull sequenceiq/hadoop-docker\n```\n\n## 1\u30ce\u30fc\u30c9\u76ee\u8d77\u52d5\n\n```\ndocker run -it --name hadoop1 -h hadoop1 -p 50070:50070 -p 8088:8088 sequenceiq/hadoop-docker /etc/bootstrap.sh -bash\n/\nStarting sshd:                                             [  OK  ]\nStarting namenodes on [hadoop1]\nhadoop1: starting namenode, logging to /usr/local/hadoop/logs/hadoop-root-namenode-hadoop1.out\nlocalhost: starting datanode, logging to /usr/local/hadoop/logs/hadoop-root-datanode-hadoop1.out\nStarting secondary namenodes [0.0.0.0]\n0.0.0.0: starting secondarynamenode, logging to /usr/local/hadoop/logs/hadoop-root-secondarynamenode-hadoop1.out\nstarting yarn daemons\nstarting resourcemanager, logging to /usr/local/hadoop/logs/yarn--resourcemanager-hadoop1.out\nlocalhost: starting nodemanager, logging to /usr/local/hadoop/logs/yarn-root-nodemanager-hadoop1.out\nbash-4.1# \n\n```\n\n## 2\u30ce\u30fc\u30c9\u76ee\u8d77\u52d5\n\n```\ndocker run -it --name hadoop2 -h hadoop2 sequenceiq/hadoop-docker /etc/bootstrap.sh -bash\n```\n\n## 3\u30ce\u30fc\u30c9\u76ee\u8d77\u52d5\n\n```\ndocker run -it --name hadoop3 -h hadoop3 sequenceiq/hadoop-docker /etc/bootstrap.sh -bash\n```\n\n\n\u7ba1\u7406\u753b\u9762\u898b\u308b\u3068\u81ea\u52d5\u3067\u306f\u30af\u30e9\u30b9\u30bf\u306b\u306f\u306a\u3089\u306a\u3044\u3002\u3002\u3002\n\n## \u505c\u6b62\nbootstrap\u3067\u5358\u4f53\u8d77\u52d5\u3057\u3066\u308b\u306e\u3067\u3001\u3068\u308a\u3042\u3048\u305a\u305d\u308c\u305e\u308c\u843d\u3068\u3059\n\n```\n$HADOOP_PREFIX/sbin/stop-all.sh\n```\n\n\n## hosts\u8a2d\u5b9a\n\u305d\u308c\u305e\u308c\u306e\u30b3\u30f3\u30c6\u30ca\u3067\u5404\u30b3\u30f3\u30c6\u30ca\u306eIP\u3092\u8a18\u8ff0\n\n```\nvi /etc/hosts\n172.17.0.2\thadoop1\n172.17.0.3\thadoop2\n172.17.0.4\thadoop3\n```\n\n## HDFS\u8a2d\u5b9a\n\u4ee5\u4e0b\u3001master\u3068\u306a\u308b1\u53f7\u6a5f\u3067\u5b9f\u65bd\n\n### \u30c7\u30fc\u30bf\u30c7\u30a3\u30ec\u30af\u30c8\u30ea\u4f5c\u6210\n\n```\nmkdir -p /hdfs/data1\n```\n\n### core-site.xml\u4fee\u6b63\n\u4f5c\u6210\u3057\u305f\u30c7\u30a3\u30ec\u30af\u30c8\u30ea\u306e\u8a18\u8ff0\u3092\u8ffd\u8a18\n\n```\nvi /usr/local/hadoop/etc/hadoop/core-site.xml \n<configuration>\n   <property>\n      <name>fs.defaultFS</name>\n      <value>hdfs://hadoop1:9000</value>\n   </property>\n   <property>\n      <name>hadoop.tmp.dir</name>\n      <value>/hdfs/data1</value>\n   </property>\n</configuration>\n```\n\n### mapred-site.xml\u4fee\u6b63\n\u4e0b\u8a18\u3092\u8ffd\u8a18\n\n```\nvi mapred-site.xml\n    <name>mapred.job.tracker</name>\n    <value>hadoop1:8021</value>\n    <final>true</final>\n  </property>\n```\n\n\n### yarn-site.xml\u4fee\u6b63\n\u4e0b\u8a18\u3092\u8ffd\u8a18\n\n```\nvi yarn-site.xml \n  <property>\n   <name>yarn.resourcemanager.resource-tracker.address</name>\n   <value>hadoop1:8031</value>\n  </property>\n```\n\n### slave\u4fee\u6b63\n\n```\nvi slaves\nhadoop1\nhadoop2\nhadoop3\n```\n\n### 2\u301c3\u30ce\u30fc\u30c9\u76ee\u306b\u30b3\u30d4\u30fc\nrsync\u3067\u30b3\u30d4\u30fc\n\n```\nrsync -av /usr/local/hadoop/etc/hadoop/ hadoop2:/usr/local/hadoop/etc/hadoop/\n\nrsync -av /usr/local/hadoop/etc/hadoop/ hadoop3:/usr/local/hadoop/etc/hadoop/\n```\n\n### \u521d\u671f\u5316\n\n```\n$HADOOP_PREFIX/bin/hadoop namenode -format\n```\n\n## \u8d77\u52d5\n1\u53f7\u6a5f\u3067\u8d77\u52d5\n\n```\n$HADOOP_PREFIX/sbin/start-all.sh\n```\n\n## \u8d77\u52d5\u78ba\u8a8d\njps\u30b3\u30de\u30f3\u30c9\u3067\u78ba\u8a8d\n\nnode1\n\n```\njps\n218 NameNode\n769 NodeManager\n349 DataNode\n663 ResourceManager\n481 SecondaryNameNode\n1089 Jps\n```\n\nnode2\u301c3\n\n```\njps\n260 Jps\n162 NodeManager\n61 DataNode\n```\n\n## \u8d77\u52d5\u78ba\u8a8d\uff20WebUI\n\u3068\u308a\u3042\u3048\u305a\u30013\u53f0\u30af\u30e9\u30b9\u30bf\u69cb\u6210\u3067\u8d77\u52d5\u3057\u305f\n\nhttp://192.168.99.100:8088/cluster/nodes\n![hadoop1.png](https://qiita-image-store.s3.amazonaws.com/0/59856/c9ce426d-9949-26ac-537b-7d9733196192.png \"hadoop1.png\")\n\n\nhttp://192.168.99.100:50070/\n![hadoop2.png](https://qiita-image-store.s3.amazonaws.com/0/59856/03ed9170-af6b-8795-538b-736e3c708c06.png \"hadoop2.png\")\n\n\n\n## \u30b3\u30f3\u30c6\u30ca\u518d\u8d77\u52d5\u5bfe\u5fdc\n\n### bootstrap\u30b3\u30e1\u30f3\u30c8\u30a2\u30a6\u30c8\n\u30b3\u30f3\u30c6\u30ca\u518d\u8d77\u52d5\u3067\u30b3\u30f3\u30d5\u30a3\u30b0\u521d\u671f\u5316\uff06\u7121\u99c4\u306b\u8d77\u52d5\u3059\u308b\u306e\u3067\u52d5\u304b\u306a\u3044\u3088\u3046\u306b\u3059\u308b\u3002\n\n```\nvi /etc/bootstrap.sh\n#!/bin/bash\n\n: ${HADOOP_PREFIX:=/usr/local/hadoop}\n\n$HADOOP_PREFIX/etc/hadoop/hadoop-env.sh\n\nrm /tmp/*.pid\n\n# installing libraries if any - (resource urls added comma separated to the ACP system variable)\ncd $HADOOP_PREFIX/share/hadoop/common ; for cp in ${ACP//,/ }; do  echo == $cp; curl -LO $cp ; done; cd -\n\n# altering the core-site configuration\n#sed s/HOSTNAME/$HOSTNAME/ /usr/local/hadoop/etc/hadoop/core-site.xml.template > /usr/local/hadoop/etc/hadoop/core-site.xml\n\n\nservice sshd start\n#$HADOOP_PREFIX/sbin/start-dfs.sh\n#$HADOOP_PREFIX/sbin/start-yarn.sh\n\nif [[ $1 == \"-d\" ]]; then\n  while true; do sleep 1000; done\nfi\n\nif [[ $1 == \"-bash\" ]]; then\n  /bin/bash\nfi\n```\n\n\u3042\u3068\u306fhosts\u304c\u6bce\u56de\u521d\u671f\u5316\u3055\u308c\u308b&IP\u5909\u308f\u308b\u304b\u3089\u3069\u30fc\u3057\u3088\u3002\u3002\n\u4e00\u5fdc\u30b3\u30f3\u30c6\u30ca\u518d\u8d77\u52d5\u5f8c\u3001hosts\u66f8\u304d\u63db\u3048\u3066node1\u3067start-all.sh \u53e9\u3051\u3070\u30af\u30e9\u30b9\u30bf\u72b6\u614b\u3067\u8d77\u52d5\u3059\u308b\u3002\n\n\n\n\n", "tags": ["Hdfs", "hadoop"]}