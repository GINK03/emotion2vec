{"context": " More than 1 year has passed since last update.Apache Spark\u30d7\u30ed\u30b8\u30a7\u30af\u30c8\u306e\u4ee5\u4e0b\u306e\u30c7\u30d7\u30ed\u30a4\u30e1\u30f3\u30c8\u30aa\u30fc\u30d0\u30fc\u30d3\u30e5\u30fc\u306e\u65e5\u672c\u8a9e\u8a33\u3067\u3059\u3002\nhttp://spark.apache.org/docs/latest/cluster-overview.html\n\u7ffb\u8a33\u306b\u304a\u304b\u3057\u305f\u3068\u3053\u308d\u304c\u3042\u308a\u307e\u3057\u305f\u3089\u30b3\u30e1\u30f3\u30c8\u306b\u3066\u3054\u6307\u6458\u304f\u3060\u3055\u3044\u3002\nQuick Start\u3068EC2\u5c0e\u5165\u306e\u548c\u8a33\u3082\u4e0b\u8a18\u3067\u6295\u7a3f\u3057\u3066\u3044\u308b\u306e\u3067\u4f1a\u308f\u305b\u3066\u3054\u89a7\u304f\u3060\u3055\u3044\u3002\n\nQuick Start\nhttp://qiita.com/mychaelstyle/items/46440cd27ef641892a58\n\nSpark on AWS EC2\nhttp://qiita.com/mychaelstyle/items/b752087a0bee6e41c182\n\n\n\nCluster Mode Overview (\u30af\u30e9\u30b9\u30bf\u30e2\u30fc\u30c9 \u30aa\u30fc\u30d0\u30fc\u30d3\u30e5\u30fc)\n\nThis document gives a short overview of how Spark runs on clusters, to make it easier to understand the components involved. Read through the application submission guide to submit applications to a cluster.\n\n\u3053\u306e\u30c9\u30ad\u30e5\u30e1\u30f3\u30c8\u306fSpark\u304c\u30af\u30e9\u30b9\u30bf\u4e0a\u3067\u3069\u306e\u3088\u3046\u306b\u52d5\u4f5c\u3059\u308b\u304b\u3001\u8907\u96d1\u306a\u30b3\u30f3\u30dd\u30fc\u30cd\u30f3\u30c8\u3092\u7c21\u5358\u306b\u7406\u89e3\u3059\u308b\u305f\u3081\u306e\u7c21\u5358\u306a\u30aa\u30fc\u30d0\u30fc\u30d3\u30e5\u30fc\u3067\u3059\u3002\n\u30a2\u30d7\u30ea\u30b1\u30fc\u30b7\u30e7\u30f3\u3092\u30af\u30e9\u30b9\u30bf\u306b\u3069\u306e\u3088\u3046\u306b\u914d\u5099\u3059\u308b\u304b\u3092\u30a2\u30d7\u30ea\u30b1\u30fc\u30b7\u30e7\u30f3\u30b5\u30d6\u30df\u30c3\u30b7\u30e7\u30f3\u30ac\u30a4\u30c9\u306b\u76ee\u3092\u901a\u3057\u3066\u304f\u3060\u3055\u3044\u3002\nhttp://spark.apache.org/docs/latest/submitting-applications.html\n\nComponents (\u30b3\u30f3\u30dd\u30fc\u30cd\u30f3\u30c8)\n\nSpark applications run as independent sets of processes on a cluster, coordinated by the SparkContext object in your main program (called the driver program).\n\nSpark\u30a2\u30d7\u30ea\u30b1\u30fc\u30b7\u30e7\u30f3\u306f\u3001\u3042\u306a\u305f\u306e\u30a2\u30d7\u30ea\u30b1\u30fc\u30b7\u30e7\u30f3\u30e1\u30a4\u30f3\u30d7\u30ed\u30b0\u30e9\u30e0\uff08\u30c9\u30e9\u30a4\u30d0\u30fc\u30d7\u30ed\u30b0\u30e9\u30e0\u3068\u3044\u3044\u307e\u3059\uff09\u306eSparkContext\u30aa\u30d6\u30b8\u30a7\u30af\u30c8\u306b\u3088\u3063\u3066\u5354\u8abf\u3057\u3066\u4e00\u3064\u306e\u30af\u30e9\u30b9\u30bf\u4e0a\u3067\u72ec\u7acb\u3057\u305f\u30d7\u30ed\u30bb\u30b9\u306e\u30bb\u30c3\u30c8\u3068\u3057\u3066\u52d5\u4f5c\u3057\u307e\u3059\u3002\n\nSpecifically, to run on a cluster, the SparkContext can connect to several types of cluster managers (either Spark\u2019s own standalone cluster manager or Mesos/YARN), which allocate resources across applications.\n\n\u7279\u306b\u3001\u4e00\u3064\u306e\u30af\u30e9\u30b9\u30bf\u3067\u52d5\u4f5c\u3055\u305b\u308b\u305f\u3081\u306bSparkContext\u306f\u3044\u304f\u3064\u304b\u306e\u30bf\u30a4\u30d7\u306e\u30af\u30e9\u30b9\u30bf\u30de\u30cd\u30fc\u30b8\u30e3\u30fc\uff08Spark\u306e\u72ec\u81ea\u30b9\u30bf\u30f3\u30c9\u30a2\u30ed\u30f3\u30af\u30e9\u30b9\u30bf\u30de\u30cd\u30fc\u30b8\u30e3\u30fc\u3084Mesos/YARN)\u306b\u63a5\u7d9a\u3057\u3001\u30a2\u30d7\u30ea\u30b1\u30fc\u30b7\u30e7\u30f3\u306b\u307e\u305f\u304c\u3063\u3066\u30ea\u30bd\u30fc\u30b9\u3092\u5272\u308a\u5f53\u3066\u307e\u3059\u3002\n\nOnce connected, Spark acquires executors on nodes in the cluster, which are processes that run computations and store data for your application. Next, it sends your application code (defined by JAR or Python files passed to SparkContext) to the executors. Finally, SparkContext sends tasks for the executors to run.\n\n\u4e00\u5ea6\u63a5\u7d9a\u3055\u308c\u308b\u3068Spark\u306fexecuteros\u3092\u30af\u30e9\u30b9\u30bf\u306e\u30ce\u30fc\u30c9\u7fa4\u4e0a\u306b\u53d6\u5f97\u3057\u3001\u305d\u308c\u3089\u304c\u3042\u306a\u305f\u306e\u30a2\u30d7\u30ea\u30b1\u30fc\u30b7\u30e7\u30f3\u306e\u70ba\u306b\u8a08\u7b97\u3092\u5b9f\u884c\u3057\u3001\u30c7\u30fc\u30bf\u3092\u30b9\u30c8\u30a2\u3057\u307e\u3059\u3002\n\u6b21\u306b\u3042\u306a\u305f\u306e\u30a2\u30d7\u30ea\u30b1\u30fc\u30b7\u30e7\u30f3\u30b3\u30fc\u30c9\uff08SparkContext\u306b\u6e21\u3055\u308c\u305fJAR\u3084Python\u30d5\u30a1\u30a4\u30eb\uff09\u304cexecutors\u306b\u9001\u3089\u308c\u307e\u3059\u3002\n\u3055\u3044\u3054\u306bSparkContext\u306fexecutors\u306e\u5b9f\u884c\u30bf\u30b9\u30af\u3092\u9001\u4fe1\u3057\u307e\u3059\u3002\n\n\nThere are several useful things to note about this architecture:\n\n\u30a2\u30fc\u30ad\u30c6\u30af\u30c1\u30e3\u306b\u3064\u3044\u3066\u3044\u304f\u3064\u304b\u306e\u6709\u7528\u306a\u3053\u3068\u304c\u3042\u308a\u307e\u3059\u3002\n\n\nEach application gets its own executor processes, which stay up for the duration of the whole application and run tasks in multiple threads. This has the benefit of isolating applications from each other, on both the scheduling side (each driver schedules its own tasks) and executor side (tasks from different applications run in different JVMs). However, it also means that data cannot be shared across different Spark applications (instances of SparkContext) without writing it to an external storage system.\n\n\n\u305d\u308c\u305e\u308c\u306e\u30a2\u30d7\u30ea\u30b1\u30fc\u30b7\u30e7\u30f3\u306f\u3001\u5168\u3066\u306e\u30a2\u30d7\u30ea\u30b1\u30fc\u30b7\u30e7\u30f3\u304c\u30bf\u30b9\u30af\u3092\u5b9f\u884c\u3059\u308b\u5168\u3066\u306e\u30b9\u30ec\u30c3\u30c9\u304c\u5b9f\u884c\u3055\u308c\u308b\u9593\u3001\u72ec\u81ea\u306eexecutor\u30d7\u30ed\u30bb\u30b9\u7fa4\u3092\u53d6\u5f97\u3057\u307e\u3059\u3002\n\u3053\u308c\u306f\u30a2\u30d7\u30ea\u30b1\u30fc\u30b7\u30e7\u30f3\u3092\u305d\u308c\u305e\u308c\u500b\u5225\u306b\u5206\u96e2\u3059\u308b\u4e0a\u3067\u3001\u30b9\u30b1\u30b8\u30e5\u30fc\u30ea\u30f3\u30b0\u9762\uff08\u305d\u308c\u305e\u308c\u306e\u30c9\u30e9\u30a4\u30d0\u30fc\u306f\u72ec\u81ea\u306b\u30bf\u30b9\u30af\u3092\u30b9\u30b1\u30b8\u30e5\u30fc\u30eb\u3057\u307e\u3059\uff09\u3001executor\u9762\uff08\u9055\u3046\u30a2\u30d7\u30ea\u30b1\u30fc\u30b7\u30e7\u30f3\u304b\u3089\u306e\u30bf\u30b9\u30af\u306f\u9055\u3046JVM\u4e0a\u3067\u5b9f\u884c\uff09\u3068\u3082\u306b\u975e\u5e38\u306b\u6709\u76ca\u3067\u3059\u3002\n\u3057\u304b\u3057\u3001\u3053\u308c\u306f\u30c7\u30fc\u30bf\u3092\u5916\u90e8\u30b9\u30c8\u30ec\u30fc\u30b8\u30b7\u30b9\u30c6\u30e0\u3092\u5229\u7528\u3057\u306a\u3051\u308c\u3070\u3001\u7570\u306a\u308bSpark\u30a2\u30d7\u30ea\u30b1\u30fc\u30b7\u30e7\u30f3\uff08SparkContext\u30a4\u30f3\u30b9\u30bf\u30f3\u30b9\uff09\u3067\u30b7\u30a7\u30a2\u3067\u304d\u306a\u3044\u3053\u3068\u3092\u610f\u5473\u3057\u307e\u3059\u3002\n\n\nSpark is agnostic to the underlying cluster manager. As long as it can acquire executor processes, and these communicate with each other, it is relatively easy to run it even on a cluster manager that also supports other applications (e.g. Mesos/YARN).\n\n\nSpark\u306f\u30af\u30e9\u30b9\u30bf\u30de\u30cd\u30fc\u30b8\u30e3\u30fc\u306b\u5f37\u304f\u95a2\u4fc2\u3057\u307e\u305b\u3093\u3002executor\u30d7\u30ed\u30bb\u30b9\u7fa4\u3092\u8981\u6c42\u3057\u3001\u76f8\u4e92\u306b\u901a\u4fe1\u3059\u308b\u9593\u305a\u3063\u3068\u3001Spark\u306f\u6bd4\u8f03\u7684\u7c21\u5358\u306b\u5b9f\u4ed6\u306e\u30a2\u30d7\u30ea\u30b1\u30fc\u30b7\u30e7\u30f3\u3092\u30b5\u30dd\u30fc\u30c8\u3057\u3066\u3044\u308b\u30af\u30e9\u30b9\u30bf\u30de\u30cd\u30fc\u30b8\u30e3\u4e0a\u3067\u52d5\u4f5c\u3057\u307e\u3059\u3002\n\n\nBecause the driver schedules tasks on the cluster, it should be run close to the worker nodes, preferably on the same local area network. If you\u2019d like to send requests to the cluster remotely, it\u2019s better to open an RPC to the driver and have it submit operations from nearby than to run a driver far away from the worker nodes.\n\n\n\u30c9\u30e9\u30a4\u30d0\u306f\u30af\u30e9\u30b9\u30bf\u4e0a\u3067\u30bf\u30b9\u30af\u3092\u30b9\u30b1\u30b8\u30e5\u30fc\u30eb\u3059\u308b\u306e\u3067\u3001\u30ef\u30fc\u30ab\u30fc\u30ce\u30fc\u30c9\u7fa4\u306e\u8fd1\u304f\u3067\u5b9f\u884c\u3059\u308b\u3079\u304d\u3067\u3059, \u3080\u3057\u308d\u540c\u3058\u30ed\u30fc\u30ab\u30eb\u30a8\u30ea\u30a2\u30cd\u30c3\u30c8\u30ef\u30fc\u30af\u5185\u3067\u3002\n\u3082\u3057\u3042\u306a\u305f\u304c\u30ea\u30e2\u30fc\u30c8\u3067\u30ea\u30af\u30a8\u30b9\u30c8\u3092\u9001\u4fe1\u3057\u305f\u3044\u306a\u3089\u3001RPC\u3092\u5229\u7528\u3057\u3066\u30a2\u30d7\u30ea\u30b1\u30fc\u30b7\u30e7\u30f3\u306e\u30b5\u30d6\u30df\u30c3\u30c8\u30aa\u30da\u30ec\u30fc\u30b7\u30e7\u30f3\u3092\u304a\u3053\u306a\u3063\u3066\u8fd1\u304f\u3067\u5b9f\u884c\u3059\u308b\u65b9\u304c\u3001\u30ef\u30fc\u30ab\u30fc\u30ce\u30fc\u30c9\u7fa4\u306e\u9060\u304f\u304b\u3089\u5b9f\u884c\u3059\u308b\u3088\u308a\u826f\u3044\u3067\u3057\u3087\u3046\u3002\nApache Spark\u30d7\u30ed\u30b8\u30a7\u30af\u30c8\u306e\u4ee5\u4e0b\u306e\u30c7\u30d7\u30ed\u30a4\u30e1\u30f3\u30c8\u30aa\u30fc\u30d0\u30fc\u30d3\u30e5\u30fc\u306e\u65e5\u672c\u8a9e\u8a33\u3067\u3059\u3002\nhttp://spark.apache.org/docs/latest/cluster-overview.html\n\n\u7ffb\u8a33\u306b\u304a\u304b\u3057\u305f\u3068\u3053\u308d\u304c\u3042\u308a\u307e\u3057\u305f\u3089\u30b3\u30e1\u30f3\u30c8\u306b\u3066\u3054\u6307\u6458\u304f\u3060\u3055\u3044\u3002\n\nQuick Start\u3068EC2\u5c0e\u5165\u306e\u548c\u8a33\u3082\u4e0b\u8a18\u3067\u6295\u7a3f\u3057\u3066\u3044\u308b\u306e\u3067\u4f1a\u308f\u305b\u3066\u3054\u89a7\u304f\u3060\u3055\u3044\u3002\n\n* Quick Start<br>\nhttp://qiita.com/mychaelstyle/items/46440cd27ef641892a58\n* Spark on AWS EC2<br>\nhttp://qiita.com/mychaelstyle/items/b752087a0bee6e41c182\n\n# Cluster Mode Overview (\u30af\u30e9\u30b9\u30bf\u30e2\u30fc\u30c9 \u30aa\u30fc\u30d0\u30fc\u30d3\u30e5\u30fc)\n\n> This document gives a short overview of how Spark runs on clusters, to make it easier to understand the components involved. Read through the application submission guide to submit applications to a cluster.\n\n\u3053\u306e\u30c9\u30ad\u30e5\u30e1\u30f3\u30c8\u306fSpark\u304c\u30af\u30e9\u30b9\u30bf\u4e0a\u3067\u3069\u306e\u3088\u3046\u306b\u52d5\u4f5c\u3059\u308b\u304b\u3001\u8907\u96d1\u306a\u30b3\u30f3\u30dd\u30fc\u30cd\u30f3\u30c8\u3092\u7c21\u5358\u306b\u7406\u89e3\u3059\u308b\u305f\u3081\u306e\u7c21\u5358\u306a\u30aa\u30fc\u30d0\u30fc\u30d3\u30e5\u30fc\u3067\u3059\u3002\n\u30a2\u30d7\u30ea\u30b1\u30fc\u30b7\u30e7\u30f3\u3092\u30af\u30e9\u30b9\u30bf\u306b\u3069\u306e\u3088\u3046\u306b\u914d\u5099\u3059\u308b\u304b\u3092\u30a2\u30d7\u30ea\u30b1\u30fc\u30b7\u30e7\u30f3\u30b5\u30d6\u30df\u30c3\u30b7\u30e7\u30f3\u30ac\u30a4\u30c9\u306b\u76ee\u3092\u901a\u3057\u3066\u304f\u3060\u3055\u3044\u3002\n\nhttp://spark.apache.org/docs/latest/submitting-applications.html\n\n## Components (\u30b3\u30f3\u30dd\u30fc\u30cd\u30f3\u30c8)\n\n> Spark applications run as independent sets of processes on a cluster, coordinated by the SparkContext object in your main program (called the driver program).\n\nSpark\u30a2\u30d7\u30ea\u30b1\u30fc\u30b7\u30e7\u30f3\u306f\u3001\u3042\u306a\u305f\u306e\u30a2\u30d7\u30ea\u30b1\u30fc\u30b7\u30e7\u30f3\u30e1\u30a4\u30f3\u30d7\u30ed\u30b0\u30e9\u30e0\uff08\u30c9\u30e9\u30a4\u30d0\u30fc\u30d7\u30ed\u30b0\u30e9\u30e0\u3068\u3044\u3044\u307e\u3059\uff09\u306eSparkContext\u30aa\u30d6\u30b8\u30a7\u30af\u30c8\u306b\u3088\u3063\u3066\u5354\u8abf\u3057\u3066\u4e00\u3064\u306e\u30af\u30e9\u30b9\u30bf\u4e0a\u3067\u72ec\u7acb\u3057\u305f\u30d7\u30ed\u30bb\u30b9\u306e\u30bb\u30c3\u30c8\u3068\u3057\u3066\u52d5\u4f5c\u3057\u307e\u3059\u3002\n\n> Specifically, to run on a cluster, the SparkContext can connect to several types of cluster managers (either Spark\u2019s own standalone cluster manager or Mesos/YARN), which allocate resources across applications.\n\n\u7279\u306b\u3001\u4e00\u3064\u306e\u30af\u30e9\u30b9\u30bf\u3067\u52d5\u4f5c\u3055\u305b\u308b\u305f\u3081\u306bSparkContext\u306f\u3044\u304f\u3064\u304b\u306e\u30bf\u30a4\u30d7\u306e\u30af\u30e9\u30b9\u30bf\u30de\u30cd\u30fc\u30b8\u30e3\u30fc\uff08Spark\u306e\u72ec\u81ea\u30b9\u30bf\u30f3\u30c9\u30a2\u30ed\u30f3\u30af\u30e9\u30b9\u30bf\u30de\u30cd\u30fc\u30b8\u30e3\u30fc\u3084Mesos/YARN)\u306b\u63a5\u7d9a\u3057\u3001\u30a2\u30d7\u30ea\u30b1\u30fc\u30b7\u30e7\u30f3\u306b\u307e\u305f\u304c\u3063\u3066\u30ea\u30bd\u30fc\u30b9\u3092\u5272\u308a\u5f53\u3066\u307e\u3059\u3002\n\n> Once connected, Spark acquires executors on nodes in the cluster, which are processes that run computations and store data for your application. Next, it sends your application code (defined by JAR or Python files passed to SparkContext) to the executors. Finally, SparkContext sends tasks for the executors to run.\n\n\u4e00\u5ea6\u63a5\u7d9a\u3055\u308c\u308b\u3068Spark\u306fexecuteros\u3092\u30af\u30e9\u30b9\u30bf\u306e\u30ce\u30fc\u30c9\u7fa4\u4e0a\u306b\u53d6\u5f97\u3057\u3001\u305d\u308c\u3089\u304c\u3042\u306a\u305f\u306e\u30a2\u30d7\u30ea\u30b1\u30fc\u30b7\u30e7\u30f3\u306e\u70ba\u306b\u8a08\u7b97\u3092\u5b9f\u884c\u3057\u3001\u30c7\u30fc\u30bf\u3092\u30b9\u30c8\u30a2\u3057\u307e\u3059\u3002\n\u6b21\u306b\u3042\u306a\u305f\u306e\u30a2\u30d7\u30ea\u30b1\u30fc\u30b7\u30e7\u30f3\u30b3\u30fc\u30c9\uff08SparkContext\u306b\u6e21\u3055\u308c\u305fJAR\u3084Python\u30d5\u30a1\u30a4\u30eb\uff09\u304cexecutors\u306b\u9001\u3089\u308c\u307e\u3059\u3002\n\u3055\u3044\u3054\u306bSparkContext\u306fexecutors\u306e\u5b9f\u884c\u30bf\u30b9\u30af\u3092\u9001\u4fe1\u3057\u307e\u3059\u3002\n\n<img src=\"http://spark.apache.org/docs/latest/img/cluster-overview.png\">\n\n> There are several useful things to note about this architecture:\n\n\u30a2\u30fc\u30ad\u30c6\u30af\u30c1\u30e3\u306b\u3064\u3044\u3066\u3044\u304f\u3064\u304b\u306e\u6709\u7528\u306a\u3053\u3068\u304c\u3042\u308a\u307e\u3059\u3002\n\n> 1. Each application gets its own executor processes, which stay up for the duration of the whole application and run tasks in multiple threads. This has the benefit of isolating applications from each other, on both the scheduling side (each driver schedules its own tasks) and executor side (tasks from different applications run in different JVMs). However, it also means that data cannot be shared across different Spark applications (instances of SparkContext) without writing it to an external storage system.\n\n\u305d\u308c\u305e\u308c\u306e\u30a2\u30d7\u30ea\u30b1\u30fc\u30b7\u30e7\u30f3\u306f\u3001\u5168\u3066\u306e\u30a2\u30d7\u30ea\u30b1\u30fc\u30b7\u30e7\u30f3\u304c\u30bf\u30b9\u30af\u3092\u5b9f\u884c\u3059\u308b\u5168\u3066\u306e\u30b9\u30ec\u30c3\u30c9\u304c\u5b9f\u884c\u3055\u308c\u308b\u9593\u3001\u72ec\u81ea\u306eexecutor\u30d7\u30ed\u30bb\u30b9\u7fa4\u3092\u53d6\u5f97\u3057\u307e\u3059\u3002\n\u3053\u308c\u306f\u30a2\u30d7\u30ea\u30b1\u30fc\u30b7\u30e7\u30f3\u3092\u305d\u308c\u305e\u308c\u500b\u5225\u306b\u5206\u96e2\u3059\u308b\u4e0a\u3067\u3001\u30b9\u30b1\u30b8\u30e5\u30fc\u30ea\u30f3\u30b0\u9762\uff08\u305d\u308c\u305e\u308c\u306e\u30c9\u30e9\u30a4\u30d0\u30fc\u306f\u72ec\u81ea\u306b\u30bf\u30b9\u30af\u3092\u30b9\u30b1\u30b8\u30e5\u30fc\u30eb\u3057\u307e\u3059\uff09\u3001executor\u9762\uff08\u9055\u3046\u30a2\u30d7\u30ea\u30b1\u30fc\u30b7\u30e7\u30f3\u304b\u3089\u306e\u30bf\u30b9\u30af\u306f\u9055\u3046JVM\u4e0a\u3067\u5b9f\u884c\uff09\u3068\u3082\u306b\u975e\u5e38\u306b\u6709\u76ca\u3067\u3059\u3002\n\u3057\u304b\u3057\u3001\u3053\u308c\u306f\u30c7\u30fc\u30bf\u3092\u5916\u90e8\u30b9\u30c8\u30ec\u30fc\u30b8\u30b7\u30b9\u30c6\u30e0\u3092\u5229\u7528\u3057\u306a\u3051\u308c\u3070\u3001\u7570\u306a\u308bSpark\u30a2\u30d7\u30ea\u30b1\u30fc\u30b7\u30e7\u30f3\uff08SparkContext\u30a4\u30f3\u30b9\u30bf\u30f3\u30b9\uff09\u3067\u30b7\u30a7\u30a2\u3067\u304d\u306a\u3044\u3053\u3068\u3092\u610f\u5473\u3057\u307e\u3059\u3002\n\n> 2. Spark is agnostic to the underlying cluster manager. As long as it can acquire executor processes, and these communicate with each other, it is relatively easy to run it even on a cluster manager that also supports other applications (e.g. Mesos/YARN).\n\nSpark\u306f\u30af\u30e9\u30b9\u30bf\u30de\u30cd\u30fc\u30b8\u30e3\u30fc\u306b\u5f37\u304f\u95a2\u4fc2\u3057\u307e\u305b\u3093\u3002executor\u30d7\u30ed\u30bb\u30b9\u7fa4\u3092\u8981\u6c42\u3057\u3001\u76f8\u4e92\u306b\u901a\u4fe1\u3059\u308b\u9593\u305a\u3063\u3068\u3001Spark\u306f\u6bd4\u8f03\u7684\u7c21\u5358\u306b\u5b9f\u4ed6\u306e\u30a2\u30d7\u30ea\u30b1\u30fc\u30b7\u30e7\u30f3\u3092\u30b5\u30dd\u30fc\u30c8\u3057\u3066\u3044\u308b\u30af\u30e9\u30b9\u30bf\u30de\u30cd\u30fc\u30b8\u30e3\u4e0a\u3067\u52d5\u4f5c\u3057\u307e\u3059\u3002\n\n> 3. Because the driver schedules tasks on the cluster, it should be run close to the worker nodes, preferably on the same local area network. If you\u2019d like to send requests to the cluster remotely, it\u2019s better to open an RPC to the driver and have it submit operations from nearby than to run a driver far away from the worker nodes.\n\n\u30c9\u30e9\u30a4\u30d0\u306f\u30af\u30e9\u30b9\u30bf\u4e0a\u3067\u30bf\u30b9\u30af\u3092\u30b9\u30b1\u30b8\u30e5\u30fc\u30eb\u3059\u308b\u306e\u3067\u3001\u30ef\u30fc\u30ab\u30fc\u30ce\u30fc\u30c9\u7fa4\u306e\u8fd1\u304f\u3067\u5b9f\u884c\u3059\u308b\u3079\u304d\u3067\u3059, \u3080\u3057\u308d\u540c\u3058\u30ed\u30fc\u30ab\u30eb\u30a8\u30ea\u30a2\u30cd\u30c3\u30c8\u30ef\u30fc\u30af\u5185\u3067\u3002\n\u3082\u3057\u3042\u306a\u305f\u304c\u30ea\u30e2\u30fc\u30c8\u3067\u30ea\u30af\u30a8\u30b9\u30c8\u3092\u9001\u4fe1\u3057\u305f\u3044\u306a\u3089\u3001RPC\u3092\u5229\u7528\u3057\u3066\u30a2\u30d7\u30ea\u30b1\u30fc\u30b7\u30e7\u30f3\u306e\u30b5\u30d6\u30df\u30c3\u30c8\u30aa\u30da\u30ec\u30fc\u30b7\u30e7\u30f3\u3092\u304a\u3053\u306a\u3063\u3066\u8fd1\u304f\u3067\u5b9f\u884c\u3059\u308b\u65b9\u304c\u3001\u30ef\u30fc\u30ab\u30fc\u30ce\u30fc\u30c9\u7fa4\u306e\u9060\u304f\u304b\u3089\u5b9f\u884c\u3059\u308b\u3088\u308a\u826f\u3044\u3067\u3057\u3087\u3046\u3002\n\n\n", "tags": ["Spark", "Scala", "Java", "Python", "ApacheSpark"]}