{"context": "KDD CUP 2015\u306b\u53c2\u52a0\u3057\u3066\u3044\u308b\u308f\u3051\u3067\u3059\u304c\u3001\u30c7\u30a3\u30fc\u30d7\u30e9\u30fc\u30cb\u30f3\u30b0\u3068\u304b\u4f7f\u3063\u3066\u307f\u3088!\n\u3068\u601d\u3063\u305f\u6642\u306b\u53c2\u8003\u306b\u306a\u308b\u30b3\u30fc\u30c9\u304c\u898b\u3064\u304b\u3089\u306a\u304b\u3063\u305f\u306e\u3067\u7f6e\u3044\u3066\u304a\u304d\u307e\u3059\u3002\n\u3000\n\u30e9\u30d9\u30eb\u306f0\u30681\u3067\u3001\u3069\u3061\u3089\u304b\u3092\u63a8\u5b9a\u3057\u307e\u3059\u3002\n\u5fc5\u8981\u306a\u30e9\u30a4\u30d6\u30e9\u30ea\u306fKeras\u3001sklearn\u3001pandas\u3042\u305f\u308a\u3067\u3059\u3002\npip\u3067\u4f9d\u5b58\u95a2\u4fc2\u3088\u308d\u3057\u304f\u5165\u3063\u305f\u6c17\u304c\u3057\u307e\u3059\u304c\u8a18\u61b6\u304c\u5b9a\u304b\u3067\u306f\u3042\u308a\u307e\u305b\u3093\u3002\nChainer\u3082\u30c8\u30e9\u30a4\u3057\u307e\u3057\u305f\u304c\u3001\u7d50\u5c40\u50d5\u306e\u77e5\u8b58\u3067\u306f\u6271\u3044\u304d\u308c\u307e\u305b\u3093\u3067\u3057\u305f....\n\u3000\n\u53c2\u8003\u306b\u3057\u305f\u30b3\u30fc\u30c9\u306f\u3053\u3061\u3089\u3002\nkaggle otto\u3068\u3044\u3046\u30b3\u30f3\u30da\u306e\u554f\u984c\u3092\u89e3\u304f\u30b3\u30fc\u30c9\u3067\u3001\u591a\u30af\u30e9\u30b9\u5206\u985e\u306e\u30b3\u30fc\u30c9\u3067\u3059\u3002\n@yag_ays\u306b\u6559\u3048\u3066\u3082\u3089\u3044\u307e\u3057\u305f\u3002\u3042\u308a\u304c\u3068\u3046\u3054\u3056\u3044\u307e\u3059\u3002\nhttps://github.com/fchollet/keras/blob/master/examples/kaggle_otto_nn.py\nKeras\u306b\u3064\u3044\u3066\u306f\u3053\u3061\u3089\u306e\u8a18\u4e8b\u3067\u3082\u8a73\u3057\u304f\u89e3\u8aac\u3055\u308c\u3066\u307e\u3059\u3002\n\"\u30c7\u30a3\u30fc\u30d7\u30e9\u30fc\u30cb\u30f3\u30b0\u3092Keras\u3068\u3044\u3046\u30d5\u30ec\u30fc\u30e0\u30ef\u30fc\u30af\u4e0a\u3067\u884c\u3046\"\nhttp://sharply.hatenablog.com/entry/2016/05/03/202806#\n\u3000\n\u3000\n\u3067\u3001\u4eca\u56de\u306e\u30b3\u30fc\u30c9\u306e\u4f8b\u304c\u4ee5\u4e0b\u3002\u3000\n\nkeras_deep_nn_example.py\n#!/usr/bin/python\n\nfrom __future__ import absolute_import\n\nimport numpy as np\nimport pandas as pd\n\nfrom keras.models import Sequential\nfrom keras.layers.core import Dense, Dropout, Activation\nfrom keras.layers.normalization import BatchNormalization\nfrom keras.layers.advanced_activations import PReLU\nfrom keras.utils import np_utils, generic_utils\n\nfrom sklearn.preprocessing import LabelEncoder\nfrom sklearn.preprocessing import StandardScaler\n\ndef preprocess_data(X, scaler=None):\n    if not scaler:\n        scaler = StandardScaler()\n        scaler.fit(X)\n    X = scaler.transform(X)\n    return X, scaler\n\ndef preprocess_labels(labels, encoder=None, categorical=True):\n    if not encoder:\n        encoder = LabelEncoder()\n        encoder.fit(labels)\n    y = encoder.transform(labels).astype(np.int32)\n    if categorical:\n        y = np_utils.to_categorical(y)\n    return y, encoder\n\nX_list = []\nlabels_list = []\n# setup training data\nfor i in xrange(20000):\n    # [1,2] => [0]\n    X_list.append([1,2])\n    labels_list.append(0)\n    # [2,1] => [1]\n    X_list.append([2,1])\n    labels_list.append(1)\n\nprint(\"Loading data...\")\nX = np.array(X_list)\nlabels = np.array(labels_list)\nX, scaler = preprocess_data(X)\nY, encoder = preprocess_labels(labels)\n\nnp.random.seed(1337) # for reproducibility\n\n# input for predection\nX_test_list = [[1,2],[2,1]]\nX_test = np.array(X_test_list)\nX_test, _ = preprocess_data(X_test_list, scaler)\n\nnb_classes = Y.shape[1]\nprint(nb_classes, 'classes')\n\ndims = X.shape[1]\nprint(dims, 'dims')\n\nprint(\"Building model...\")\n\nneuro_num = 16\n\n# setup deep NN\nmodel = Sequential()\nmodel.add(Dense(dims, neuro_num, init='glorot_uniform'))\nmodel.add(PReLU((neuro_num,)))\nmodel.add(BatchNormalization((neuro_num,)))\nmodel.add(Dropout(0.5))\n\nmodel.add(Dense(neuro_num, neuro_num, init='glorot_uniform'))\nmodel.add(PReLU((neuro_num,)))\nmodel.add(BatchNormalization((neuro_num,)))\nmodel.add(Dropout(0.5))\n\nmodel.add(Dense(neuro_num, neuro_num, init='glorot_uniform'))\nmodel.add(PReLU((neuro_num,)))\nmodel.add(BatchNormalization((neuro_num,)))\nmodel.add(Dropout(0.5))\n\nmodel.add(Dense(neuro_num, nb_classes, init='glorot_uniform'))\nmodel.add(Activation('sigmoid'))\n\nmodel.compile(loss='binary_crossentropy', optimizer=\"adam\")\n\nprint(\"Training model...\")\nmodel.fit(X, Y, nb_epoch=20, batch_size=128, validation_split=0.15)\n\nprint(\"Prediction...\")\nproba = model.predict_proba(X_test)\n\n# predicted result\nprint(\"probability of [label=0 label=1]\")\nprint(\"  input: [1,2] => \" + str(proba[0]))\nprint(\"  input: [2,1] => \" + str(proba[1]))\n\n\nhttps://github.com/ryogrid/kddcup2015/blob/master/train/keras_deep_nn_example.py\n\u266f16/07/15 Keras\u306e\u30d0\u30fc\u30b8\u30e7\u30f3\u304c\u6700\u65b0\u3060\u3068\u3001\u3053\u308c\u3060\u3068\u52d5\u304b\u306a\u3044\u3088\u3046\u3067\u3059\u3002\u2193\u306e\u30b3\u30fc\u30c9\u3092\u53c2\u8003\u306b\u30cd\u30c3\u30c8\u30ef\u30fc\u30af\u306e\u3068\u3053\u308d\u3060\u3051\u4fee\u6b63\u3057\u3066\u307f\u3066\u4e0b\u3055\u3044\n\u266fhttps://github.com/ryogrid/fx_systrade/blob/e93103c804e992bc21b7afc8a0f707ec4ce37029/keras_trade.py\n\u3010\u5b9f\u884c\u7d50\u679c\u3011\n\n(Keras\u306e\u51fa\u529b\u306f\u7701\u7565)\nprobability of [label=0 label=1]\n\u3000input: [1,2] => [  9.99876779e-01   2.05630928e-04]\n\u3000input: [2,1] => [  1.21604726e-04   9.99792734e-01]\n\n\u3000\n\u3084\u3063\u3066\u308b\u3053\u3068\u306f\u30b3\u30fc\u30c9\u3092\u898b\u3066\u3082\u3089\u3048\u3070\u5927\u4f53\u5206\u304b\u308b\u304b\u3068\u601d\u3044\u307e\u3059\u3002\n\u666e\u901a\u306f\u3001\u3082\u3063\u3068\u305f\u304f\u3055\u3093\u306e\u30d1\u30bf\u30fc\u30f3\u3067\u5b66\u7fd2\u3055\u305b\u308b\u3057\u3001\u4e88\u6e2c\u3059\u308b\u6642\u3082\u5b66\u7fd2\u3055\u305b\u305f\u6642\u306e\u30d1\u30bf\u30fc\u30f3\u305d\u306e\u307e\u307e\u3068\u304b\u306f\u3042\u308a\u5f97\u306a\u3044\u3068\u601d\u3044\u307e\u3059\u304c\u3001\u307e\u3042\u305d\u3053\u306f\u3054\u611b\u5b0c\u3068\u3044\u3046\u3053\u3068\u3067\u3002\n\u3082\u3057\u3001\u3053\u308c\u306f\u30c7\u30a3\u30fc\u30d7\u30e9\u30fc\u30cb\u30f3\u30b0\u3058\u3083\u306a\u3044\u3001\u3068\u3044\u3046\u3053\u3068\u3067\u3042\u308c\u3070\u30b3\u30e1\u30f3\u30c8\u6b04\u3067\u30c4\u30c3\u30b3\u30df\u304a\u9858\u3044\u3057\u307e\u3059\u3002\n\u266f \u78ba\u304b\u306b CNN, RBN, Auto Encoder(&Decoder) \u3068\u304b\u4f7f\u3063\u3066\u306a\u3044\u3057\u306a\u3042...\n\u3042\u3068\u3001R\u304b\u3089H2O\u3092\u53e9\u3044\u3066\u3082\u7c21\u5358\u306b\u3067\u304d\u308b\u307f\u305f\u3044\u3067\u3059\u3002\n\u300cR\u3067\u4e00\u884c\u3067\u30c7\u30a3\u30fc\u30d7\u30e9\u30fc\u30cb\u30f3\u30b0\u300d\nhttp://d.hatena.ne.jp/dichika/20140503/p1\n\u3051\u3069\u3001\u8a66\u3057\u3066\u307f\u305f\u3089R\u5468\u308a\u3067\u30c8\u30e9\u30d6\u3063\u305f\u308a\u3057\u305f\u306e\u3067\u3001H2O\u306e\u30a6\u30a7\u30d6\u30a4\u30f3\u30bf\u30d5\u30a7\u30fc\u30b9 (Flow\u3068\u547c\u3076\u3089\u3057\u3044) \u3067\u9811\u5f35\u3063\u305f\u307b\u3046\u304c\u65e9\u3044\u304b\u3082\u3067\u3059\u3002\n\n\u3082\u3063\u3068\u7c21\u5358\u306a\u65b9\u6cd5\u3082\u3042\u308b\u3088\u3046\u3067\u3059(11/8 \u8ffd\u8a18)\nhttp://qiita.com/rindai87/items/546991f5ecae0ef7cde3\nKDD CUP 2015\u306b\u53c2\u52a0\u3057\u3066\u3044\u308b\u308f\u3051\u3067\u3059\u304c\u3001\u30c7\u30a3\u30fc\u30d7\u30e9\u30fc\u30cb\u30f3\u30b0\u3068\u304b\u4f7f\u3063\u3066\u307f\u3088!\n\u3068\u601d\u3063\u305f\u6642\u306b\u53c2\u8003\u306b\u306a\u308b\u30b3\u30fc\u30c9\u304c\u898b\u3064\u304b\u3089\u306a\u304b\u3063\u305f\u306e\u3067\u7f6e\u3044\u3066\u304a\u304d\u307e\u3059\u3002\n\u3000\n\n\u30e9\u30d9\u30eb\u306f0\u30681\u3067\u3001\u3069\u3061\u3089\u304b\u3092\u63a8\u5b9a\u3057\u307e\u3059\u3002\n\u5fc5\u8981\u306a\u30e9\u30a4\u30d6\u30e9\u30ea\u306fKeras\u3001sklearn\u3001pandas\u3042\u305f\u308a\u3067\u3059\u3002\npip\u3067\u4f9d\u5b58\u95a2\u4fc2\u3088\u308d\u3057\u304f\u5165\u3063\u305f\u6c17\u304c\u3057\u307e\u3059\u304c\u8a18\u61b6\u304c\u5b9a\u304b\u3067\u306f\u3042\u308a\u307e\u305b\u3093\u3002\nChainer\u3082\u30c8\u30e9\u30a4\u3057\u307e\u3057\u305f\u304c\u3001\u7d50\u5c40\u50d5\u306e\u77e5\u8b58\u3067\u306f\u6271\u3044\u304d\u308c\u307e\u305b\u3093\u3067\u3057\u305f....\n\u3000\n\n\u53c2\u8003\u306b\u3057\u305f\u30b3\u30fc\u30c9\u306f\u3053\u3061\u3089\u3002\nkaggle otto\u3068\u3044\u3046\u30b3\u30f3\u30da\u306e\u554f\u984c\u3092\u89e3\u304f\u30b3\u30fc\u30c9\u3067\u3001\u591a\u30af\u30e9\u30b9\u5206\u985e\u306e\u30b3\u30fc\u30c9\u3067\u3059\u3002\n@yag_ays\u306b\u6559\u3048\u3066\u3082\u3089\u3044\u307e\u3057\u305f\u3002\u3042\u308a\u304c\u3068\u3046\u3054\u3056\u3044\u307e\u3059\u3002\nhttps://github.com/fchollet/keras/blob/master/examples/kaggle_otto_nn.py\n\n\nKeras\u306b\u3064\u3044\u3066\u306f\u3053\u3061\u3089\u306e\u8a18\u4e8b\u3067\u3082\u8a73\u3057\u304f\u89e3\u8aac\u3055\u308c\u3066\u307e\u3059\u3002\n\n\n\"\u30c7\u30a3\u30fc\u30d7\u30e9\u30fc\u30cb\u30f3\u30b0\u3092Keras\u3068\u3044\u3046\u30d5\u30ec\u30fc\u30e0\u30ef\u30fc\u30af\u4e0a\u3067\u884c\u3046\"\nhttp://sharply.hatenablog.com/entry/2016/05/03/202806#\n\u3000\n\u3000\n\u3067\u3001\u4eca\u56de\u306e\u30b3\u30fc\u30c9\u306e\u4f8b\u304c\u4ee5\u4e0b\u3002\u3000\n\n```keras_deep_nn_example.py\n#!/usr/bin/python\n\nfrom __future__ import absolute_import\n\nimport numpy as np\nimport pandas as pd\n\nfrom keras.models import Sequential\nfrom keras.layers.core import Dense, Dropout, Activation\nfrom keras.layers.normalization import BatchNormalization\nfrom keras.layers.advanced_activations import PReLU\nfrom keras.utils import np_utils, generic_utils\n\nfrom sklearn.preprocessing import LabelEncoder\nfrom sklearn.preprocessing import StandardScaler\n\ndef preprocess_data(X, scaler=None):\n    if not scaler:\n        scaler = StandardScaler()\n        scaler.fit(X)\n    X = scaler.transform(X)\n    return X, scaler\n    \ndef preprocess_labels(labels, encoder=None, categorical=True):\n    if not encoder:\n        encoder = LabelEncoder()\n        encoder.fit(labels)\n    y = encoder.transform(labels).astype(np.int32)\n    if categorical:\n        y = np_utils.to_categorical(y)\n    return y, encoder\n\nX_list = []\nlabels_list = []\n# setup training data\nfor i in xrange(20000):\n    # [1,2] => [0]\n    X_list.append([1,2])\n    labels_list.append(0)\n    # [2,1] => [1]\n    X_list.append([2,1])\n    labels_list.append(1)\n\nprint(\"Loading data...\")\nX = np.array(X_list)\nlabels = np.array(labels_list)\nX, scaler = preprocess_data(X)\nY, encoder = preprocess_labels(labels)\n\nnp.random.seed(1337) # for reproducibility\n\n# input for predection\nX_test_list = [[1,2],[2,1]]\nX_test = np.array(X_test_list)\nX_test, _ = preprocess_data(X_test_list, scaler)\n\nnb_classes = Y.shape[1]\nprint(nb_classes, 'classes')\n\ndims = X.shape[1]\nprint(dims, 'dims')\n\nprint(\"Building model...\")\n\nneuro_num = 16\n\n# setup deep NN\nmodel = Sequential()\nmodel.add(Dense(dims, neuro_num, init='glorot_uniform'))\nmodel.add(PReLU((neuro_num,)))\nmodel.add(BatchNormalization((neuro_num,)))\nmodel.add(Dropout(0.5))\n\nmodel.add(Dense(neuro_num, neuro_num, init='glorot_uniform'))\nmodel.add(PReLU((neuro_num,)))\nmodel.add(BatchNormalization((neuro_num,)))\nmodel.add(Dropout(0.5))\n\nmodel.add(Dense(neuro_num, neuro_num, init='glorot_uniform'))\nmodel.add(PReLU((neuro_num,)))\nmodel.add(BatchNormalization((neuro_num,)))\nmodel.add(Dropout(0.5))\n\nmodel.add(Dense(neuro_num, nb_classes, init='glorot_uniform'))\nmodel.add(Activation('sigmoid'))\n\nmodel.compile(loss='binary_crossentropy', optimizer=\"adam\")\n\nprint(\"Training model...\")\nmodel.fit(X, Y, nb_epoch=20, batch_size=128, validation_split=0.15)\n\nprint(\"Prediction...\")\nproba = model.predict_proba(X_test)\n\n# predicted result\nprint(\"probability of [label=0 label=1]\")\nprint(\"  input: [1,2] => \" + str(proba[0]))\nprint(\"  input: [2,1] => \" + str(proba[1]))\n```\n\nhttps://github.com/ryogrid/kddcup2015/blob/master/train/keras_deep_nn_example.py\n\u266f16/07/15 Keras\u306e\u30d0\u30fc\u30b8\u30e7\u30f3\u304c\u6700\u65b0\u3060\u3068\u3001\u3053\u308c\u3060\u3068\u52d5\u304b\u306a\u3044\u3088\u3046\u3067\u3059\u3002\u2193\u306e\u30b3\u30fc\u30c9\u3092\u53c2\u8003\u306b\u30cd\u30c3\u30c8\u30ef\u30fc\u30af\u306e\u3068\u3053\u308d\u3060\u3051\u4fee\u6b63\u3057\u3066\u307f\u3066\u4e0b\u3055\u3044\n\u266fhttps://github.com/ryogrid/fx_systrade/blob/e93103c804e992bc21b7afc8a0f707ec4ce37029/keras_trade.py\n\n\u3010\u5b9f\u884c\u7d50\u679c\u3011\n>(Keras\u306e\u51fa\u529b\u306f\u7701\u7565)\nprobability of [label=0 label=1]\n\u3000input: [1,2] => [  9.99876779e-01   2.05630928e-04]\n\u3000input: [2,1] => [  1.21604726e-04   9.99792734e-01]\n\n\u3000\n\u3084\u3063\u3066\u308b\u3053\u3068\u306f\u30b3\u30fc\u30c9\u3092\u898b\u3066\u3082\u3089\u3048\u3070\u5927\u4f53\u5206\u304b\u308b\u304b\u3068\u601d\u3044\u307e\u3059\u3002\n\u666e\u901a\u306f\u3001\u3082\u3063\u3068\u305f\u304f\u3055\u3093\u306e\u30d1\u30bf\u30fc\u30f3\u3067\u5b66\u7fd2\u3055\u305b\u308b\u3057\u3001\u4e88\u6e2c\u3059\u308b\u6642\u3082\u5b66\u7fd2\u3055\u305b\u305f\u6642\u306e\u30d1\u30bf\u30fc\u30f3\u305d\u306e\u307e\u307e\u3068\u304b\u306f\u3042\u308a\u5f97\u306a\u3044\u3068\u601d\u3044\u307e\u3059\u304c\u3001\u307e\u3042\u305d\u3053\u306f\u3054\u611b\u5b0c\u3068\u3044\u3046\u3053\u3068\u3067\u3002\n\u3082\u3057\u3001\u3053\u308c\u306f\u30c7\u30a3\u30fc\u30d7\u30e9\u30fc\u30cb\u30f3\u30b0\u3058\u3083\u306a\u3044\u3001\u3068\u3044\u3046\u3053\u3068\u3067\u3042\u308c\u3070\u30b3\u30e1\u30f3\u30c8\u6b04\u3067\u30c4\u30c3\u30b3\u30df\u304a\u9858\u3044\u3057\u307e\u3059\u3002\n\u266f \u78ba\u304b\u306b CNN, RBN, Auto Encoder(&Decoder) \u3068\u304b\u4f7f\u3063\u3066\u306a\u3044\u3057\u306a\u3042...\n\n\n\u3042\u3068\u3001R\u304b\u3089H2O\u3092\u53e9\u3044\u3066\u3082\u7c21\u5358\u306b\u3067\u304d\u308b\u307f\u305f\u3044\u3067\u3059\u3002\n\u300cR\u3067\u4e00\u884c\u3067\u30c7\u30a3\u30fc\u30d7\u30e9\u30fc\u30cb\u30f3\u30b0\u300d\nhttp://d.hatena.ne.jp/dichika/20140503/p1\n\u3051\u3069\u3001\u8a66\u3057\u3066\u307f\u305f\u3089R\u5468\u308a\u3067\u30c8\u30e9\u30d6\u3063\u305f\u308a\u3057\u305f\u306e\u3067\u3001H2O\u306e\u30a6\u30a7\u30d6\u30a4\u30f3\u30bf\u30d5\u30a7\u30fc\u30b9 (Flow\u3068\u547c\u3076\u3089\u3057\u3044) \u3067\u9811\u5f35\u3063\u305f\u307b\u3046\u304c\u65e9\u3044\u304b\u3082\u3067\u3059\u3002\n\n#\u3082\u3063\u3068\u7c21\u5358\u306a\u65b9\u6cd5\u3082\u3042\u308b\u3088\u3046\u3067\u3059(11/8 \u8ffd\u8a18)\nhttp://qiita.com/rindai87/items/546991f5ecae0ef7cde3\n", "tags": ["Keras", "\u5165\u9580", "DeepLearning"]}