{"context": " More than 1 year has passed since last update.PRML5\u7ae0\u304b\u3089\u56f35.3\u3092\u518d\u73fe\u3059\u308b\u305f\u3081\u306b\u3001\u30cb\u30e5\u30fc\u30e9\u30eb\u30cd\u30c3\u30c8\u30ef\u30fc\u30af\u3092\u5b9f\u88c5\u3057\u3066\u307f\u307e\u3059\u3002\n\u5148\u306b\u7533\u3057\u4e0a\u3052\u3066\u304a\u304d\u307e\u3059\u3068\u3001\u5049\u305d\u3046\u306b\u5b9f\u88c5\u3068\u304b\u8a00\u3063\u3066\u308b\u3082\u306e\u306e\u3001\u30b3\u30fc\u30c9\u304b\u3089\u518d\u73fe\u3057\u305f\u56f3\u306f\u6b6f\u5207\u308c\u306e\u60aa\u3044\u3082\u306e\u3068\u306a\u3063\u3066\u304a\u308a\u307e\u3059\u3002\u3002\u3002\u4e0d\u5b8c\u5168\u306a\u3082\u306e\u3092\u4e0a\u3052\u308b\u306a\u3068\u6012\u3089\u308c\u305d\u3046\u306a\u6c17\u3082\u3057\u307e\u3059\u304c\u3001\u3054\u53c2\u8003\u306b\u4e0b\u3055\u3044\u3002\n\u307e\u305a\u3001\u56f35.3(b),(c),(d)\u306b\u95a2\u3057\u3066\u306fPRML\u306e\u4e2d\u306e\u56f3\u306b\u6bd4\u3079\u3066\u4e88\u6e2c\u7cbe\u5ea6\u304c\u3044\u307e\u3044\u3061\u826f\u304f\u306a\u3044\u5370\u8c61\u3002\u3055\u3089\u306b\u3001\u56f35.3(a)\u306b\u95a2\u3057\u3066\u306f\u5168\u304f\u898b\u5f53\u306f\u305a\u308c\u306a\u4e88\u6e2c\u304c\u8fd4\u3063\u3066\u304f\u308b\u3068\u3044\u3046\u72b6\u6cc1\u3002\u8a66\u884c\u932f\u8aa4\u3057\u307e\u3057\u305f\u304c\u3001\u529b\u4e0d\u8db3\u3067\u3057\u3066\u3001\u3069\u306a\u305f\u304b\u9593\u9055\u3044\u6c17\u3065\u304b\u308c\u307e\u3057\u305f\u3089\u3054\u6307\u6458\u4e0b\u3055\u3044\u3002\n\u30cb\u30e5\u30fc\u30e9\u30eb\u30cd\u30c3\u30c8\u30ef\u30fc\u30af\u3084\u3001\u8aa4\u5dee\u4f1d\u64ad\u6cd5(Backpropagation)\u305d\u306e\u3082\u306e\u306e\u89e3\u8aac\u306fPRML\u3084\u306f\u3058\u30d1\u30bf\u306a\u3069\u306b\u4efb\u305b\u308b\u3068\u3057\u3066\u3001\u5b9f\u88c5\u306b\u5fc5\u8981\u306a\u90e8\u5206\u3060\u3051\u3056\u3063\u3068\u78ba\u8a8d\u3057\u305f\u3044\u3068\u601d\u3044\u307e\u3059\u3002\n\n\u5b9f\u88c5\u306e\u5927\u307e\u304b\u306a\u6d41\u308c\n\u2460\u30cb\u30e5\u30fc\u30e9\u30eb\u30cd\u30c3\u30c8\u3092\u7d4c\u305f\u30a2\u30a6\u30c8\u30d7\u30c3\u30c8\u306f(5.9)\u3067\u8868\u3055\u308c\u308b\u3002PRML\u6587\u4e2d\u306e\u5f0f\u306f\u6d3b\u6027\u5316\u95a2\u6570$h()$\u306b\u30b7\u30b0\u30e2\u30a4\u30c9\u95a2\u6570\u3092\u60f3\u5b9a\u3057\u3066\u3044\u308b\u304c\u3001\u56f35.3\u3067\u306ftanh()\u304c\u6307\u5b9a\u3055\u308c\u3066\u3044\u308b\u70b9\u306b\u6ce8\u610f\u3002\n y_k({\\bf x}, {\\bf w}) = \\sigma(\\sum_{j=0}^M, w^{(2)}_{kj} h(\\sum_{i=0}^D w^{(1)}_{ji} x_i)) (5.9)\n\n\u2461\u30ce\u30fc\u30c9\u9593\u306e\u91cd\u307f${\\bf w}$\u3092\u5b66\u7fd2\u3059\u308b\u306b\u3042\u305f\u308a\u3001\u5404\u30ce\u30fc\u30c9\u3067\u306e\u30a2\u30a6\u30c8\u30d7\u30c3\u30c8\u3068\u5b9f\u6e2c\u5024\u3068\u306e\u5dee\u3092\u6c42\u3081\u308b\u3002\u307e\u305a\u306f\u96a0\u308c\u30e6\u30cb\u30c3\u30c8\u306e\u51fa\u529b\u306f(5.63)\u3001\u51fa\u529b\u30e6\u30cb\u30c3\u30c8\u306e\u51fa\u529b\u306f(5.64)\u3002\n z_j = {\\rm tanh} (\\sigma(\\sum_{i=0}^D, w^{(1)}_{ji} x_i)) (5.63)\n\n y_k = \\sum_{j=0}^M, w^{(2)}_{kj} z_i (5.64)\n\n\u2462\u6b21\u306b\u51fa\u529b\u5c64\u3067\u306e\u8aa4\u5dee$\\delta_k$\u3092\u6c42\u3081\u308b\u3002\n\\delta_k = y_k - t_k (5.65)\n\n\u2463\u6b21\u306b\u96a0\u308c\u5c64\u3067\u306e\u8aa4\u5dee$\\delta_j$\u3092\u6c42\u3081\u308b\u3002\n\\delta_j = (1-{z_j}^2) \\sum_{k=1}^K w_{kj} \\delta_k (5.65)\n\n\u2464(5.43)\u3001(5.67)\u3092\u7528\u3044\u3066\u30ce\u30fc\u30c9\u9593\u306e\u91cd\u307f\u3092\u66f4\u65b0\u3059\u308b\u3002\n{\\bf w}^{\\rm \\tau+1} = {\\bf w}^{\\rm \\tau} - \\mu \\nabla  E({\\bf{w}})(5.43)\n\n\n\u30b3\u30fc\u30c9\nimport matplotlib.pyplot as plt\nfrom pylab import *\nimport numpy as np\nimport random\n\ndef heaviside(x):\n    return 0.5 * (np.sign(x) + 1)\n\ndef NN(x_train, t, n_imput, n_hidden, n_output, eta, W1, W2, n_loop):\n    for n in xrange(n_loop):\n        for n in range(len(x_train)):\n            x = np.array([x_train[n]])\n\n            #feedforward\n            X = np.insert(x, 0, 1) #Insert fixed term\n\n            A = np.dot(W1, X) #(5.62)\n            Z = np.tanh(A)  #(5.63)\n            Z[0] = 1.0\n            Y = np.dot(W2, Z) #(5.64)\n\n\n            #Backprobagation\n            D2 = Y - t[n]#(5.65)\n            D1 = (1-Z**2)*W2*D2 #(5.66)\n\n            W1 = W1- eta*D1.T*X #(5.67), (5.43)\n            W2 = W2- eta*D2.T*Z #(5.67), (5.43)\n    return  W1, W2\n\ndef output(x, W1, W2):\n    X = np.insert(x, 0, 1) #Insert fixed term\n\n    A = np.dot(W1, X) #(5.62)\n    Z = np.tanh(A)  #(5.63)\n    Z[0] = 1.0 #Insert fixed term\n    Y = np.dot(W2, Z) #(5.64)\n    return Y, Z\n\nif __name__ == \"__main__\":\n    #Set form of nueral network \n    n_imput = 2\n    n_hidden = 4\n    n_output = 1\n    eta = 0.1\n    W1 = np.random.random((n_hidden, n_imput))\n    W2 = np.random.random((n_output, n_hidden))\n    n_loop = 1000\n\n\n    #Set train data\n    x_train = np.linspace(-4, 4, 300).reshape(300, 1)\n    y_train_1 = x_train * x_train\n    y_train_2 = np.sin(x_train)\n    y_train_3 = np.abs(x_train)\n    y_train_4 = heaviside(x_train)\n\n    W1_1, W2_1= NN(x_train, y_train_1, n_imput, n_hidden, n_output, eta, W1, W2, n_loop) \n    W1_2, W2_2= NN(x_train, y_train_2, n_imput, n_hidden, n_output, eta, W1, W2, n_loop)\n    W1_3, W2_3= NN(x_train, y_train_3, n_imput, n_hidden, n_output, eta, W1, W2, n_loop)\n    W1_4, W2_4= NN(x_train, y_train_4, n_imput, n_hidden, n_output, eta, W1, W2, n_loop)\n\n    Y_1 = np.zeros((len(x_train), n_output))\n    Z_1 = np.zeros((len(x_train), n_hidden))\n\n    Y_2 = np.zeros((len(x_train), n_output))\n    Z_2 = np.zeros((len(x_train), n_hidden))\n\n    Y_3 = np.zeros((len(x_train), n_output))\n    Z_3 = np.zeros((len(x_train), n_hidden))\n\n    Y_4 = np.zeros((len(x_train), n_output))\n    Z_4 = np.zeros((len(x_train), n_hidden))\n\n    for n in range(len(x_train)):\n        Y_1[n], Z_1[n] =output(x_train[n], W1_1, W2_1)\n        Y_2[n], Z_2[n] =output(x_train[n], W1_2, W2_2)\n        Y_3[n], Z_3[n] =output(x_train[n], W1_3, W2_3)\n        Y_4[n], Z_4[n] =output(x_train[n], W1_4, W2_4)\n\n\n    plt.plot(x_train, Y_1, \"r-\")\n    plt.plot(x_train, y_train_1, \"bo\", markersize=3)\n    for i in range(n_hidden):\n        plt.plot(x_train, Z_1[:,i], 'm--')\n    xlim([-1,1])\n    ylim([0, 1])\n    title(\"Figure 5.3(a)\")\n    show()\n\n    plt.plot(x_train, Y_2, \"r-\")\n    plt.plot(x_train, y_train_2, \"bo\", markersize=2)\n    for i in range(n_hidden):\n        plt.plot(x_train, Z_2[:,i], 'm--')\n    xlim([-3.14,3.14])\n    ylim([-1, 1])\n    title(\"Figure 5.3(b)\")\n    show()\n\n\n    plt.plot(x_train, Y_3, \"r-\")\n    plt.plot(x_train, y_train_3, \"bo\", markersize=4)\n    for i in range(n_hidden):\n        plt.plot(x_train, Z_3[:,i], 'm--')\n    xlim([-1,1])\n    ylim([0, 1])\n    title(\"Figure 5.3(c)\")\n    show()\n\n\n    plt.plot(x_train, Y_4, \"r-\")\n    plt.plot(x_train, y_train_4, \"bo\" ,markersize=2)\n    for i in range(n_hidden):\n        plt.plot(x_train, Z_4[:,i], 'm--')\n    xlim([-2,2])\n    ylim([-0.05, 1.05])\n    title(\"Figure 5.3(d)\")\n    show()\n\n\n\u7d50\u679c\n\n\n\n\nPRML5\u7ae0\u304b\u3089\u56f35.3\u3092\u518d\u73fe\u3059\u308b\u305f\u3081\u306b\u3001\u30cb\u30e5\u30fc\u30e9\u30eb\u30cd\u30c3\u30c8\u30ef\u30fc\u30af\u3092\u5b9f\u88c5\u3057\u3066\u307f\u307e\u3059\u3002\n\u5148\u306b\u7533\u3057\u4e0a\u3052\u3066\u304a\u304d\u307e\u3059\u3068\u3001\u5049\u305d\u3046\u306b\u5b9f\u88c5\u3068\u304b\u8a00\u3063\u3066\u308b\u3082\u306e\u306e\u3001\u30b3\u30fc\u30c9\u304b\u3089\u518d\u73fe\u3057\u305f\u56f3\u306f\u6b6f\u5207\u308c\u306e\u60aa\u3044\u3082\u306e\u3068\u306a\u3063\u3066\u304a\u308a\u307e\u3059\u3002\u3002\u3002\u4e0d\u5b8c\u5168\u306a\u3082\u306e\u3092\u4e0a\u3052\u308b\u306a\u3068\u6012\u3089\u308c\u305d\u3046\u306a\u6c17\u3082\u3057\u307e\u3059\u304c\u3001\u3054\u53c2\u8003\u306b\u4e0b\u3055\u3044\u3002\n\n\n\u307e\u305a\u3001\u56f35.3(b),(c),(d)\u306b\u95a2\u3057\u3066\u306fPRML\u306e\u4e2d\u306e\u56f3\u306b\u6bd4\u3079\u3066\u4e88\u6e2c\u7cbe\u5ea6\u304c\u3044\u307e\u3044\u3061\u826f\u304f\u306a\u3044\u5370\u8c61\u3002\u3055\u3089\u306b\u3001\u56f35.3(a)\u306b\u95a2\u3057\u3066\u306f\u5168\u304f\u898b\u5f53\u306f\u305a\u308c\u306a\u4e88\u6e2c\u304c\u8fd4\u3063\u3066\u304f\u308b\u3068\u3044\u3046\u72b6\u6cc1\u3002\u8a66\u884c\u932f\u8aa4\u3057\u307e\u3057\u305f\u304c\u3001\u529b\u4e0d\u8db3\u3067\u3057\u3066\u3001\u3069\u306a\u305f\u304b\u9593\u9055\u3044\u6c17\u3065\u304b\u308c\u307e\u3057\u305f\u3089\u3054\u6307\u6458\u4e0b\u3055\u3044\u3002\n\n\u30cb\u30e5\u30fc\u30e9\u30eb\u30cd\u30c3\u30c8\u30ef\u30fc\u30af\u3084\u3001\u8aa4\u5dee\u4f1d\u64ad\u6cd5(Backpropagation)\u305d\u306e\u3082\u306e\u306e\u89e3\u8aac\u306fPRML\u3084\u306f\u3058\u30d1\u30bf\u306a\u3069\u306b\u4efb\u305b\u308b\u3068\u3057\u3066\u3001\u5b9f\u88c5\u306b\u5fc5\u8981\u306a\u90e8\u5206\u3060\u3051\u3056\u3063\u3068\u78ba\u8a8d\u3057\u305f\u3044\u3068\u601d\u3044\u307e\u3059\u3002\n\n##\u5b9f\u88c5\u306e\u5927\u307e\u304b\u306a\u6d41\u308c\n\u2460\u30cb\u30e5\u30fc\u30e9\u30eb\u30cd\u30c3\u30c8\u3092\u7d4c\u305f\u30a2\u30a6\u30c8\u30d7\u30c3\u30c8\u306f(5.9)\u3067\u8868\u3055\u308c\u308b\u3002PRML\u6587\u4e2d\u306e\u5f0f\u306f\u6d3b\u6027\u5316\u95a2\u6570$h()$\u306b\u30b7\u30b0\u30e2\u30a4\u30c9\u95a2\u6570\u3092\u60f3\u5b9a\u3057\u3066\u3044\u308b\u304c\u3001\u56f35.3\u3067\u306ftanh()\u304c\u6307\u5b9a\u3055\u308c\u3066\u3044\u308b\u70b9\u306b\u6ce8\u610f\u3002\n\n```math\n y_k({\\bf x}, {\\bf w}) = \\sigma(\\sum_{j=0}^M, w^{(2)}_{kj} h(\\sum_{i=0}^D w^{(1)}_{ji} x_i)) (5.9)\n```\n\n\u2461\u30ce\u30fc\u30c9\u9593\u306e\u91cd\u307f${\\bf w}$\u3092\u5b66\u7fd2\u3059\u308b\u306b\u3042\u305f\u308a\u3001\u5404\u30ce\u30fc\u30c9\u3067\u306e\u30a2\u30a6\u30c8\u30d7\u30c3\u30c8\u3068\u5b9f\u6e2c\u5024\u3068\u306e\u5dee\u3092\u6c42\u3081\u308b\u3002\u307e\u305a\u306f\u96a0\u308c\u30e6\u30cb\u30c3\u30c8\u306e\u51fa\u529b\u306f(5.63)\u3001\u51fa\u529b\u30e6\u30cb\u30c3\u30c8\u306e\u51fa\u529b\u306f(5.64)\u3002\n\n```math\n z_j = {\\rm tanh} (\\sigma(\\sum_{i=0}^D, w^{(1)}_{ji} x_i)) (5.63)\n```\n\n```math\n y_k = \\sum_{j=0}^M, w^{(2)}_{kj} z_i (5.64)\n```\n\n\n\u2462\u6b21\u306b\u51fa\u529b\u5c64\u3067\u306e\u8aa4\u5dee$\\delta_k$\u3092\u6c42\u3081\u308b\u3002\n\n```math\n\\delta_k = y_k - t_k (5.65)\n```\n\n\u2463\u6b21\u306b\u96a0\u308c\u5c64\u3067\u306e\u8aa4\u5dee$\\delta_j$\u3092\u6c42\u3081\u308b\u3002\n\n```math\n\\delta_j = (1-{z_j}^2) \\sum_{k=1}^K w_{kj} \\delta_k (5.65)\n```\n\n\u2464(5.43)\u3001(5.67)\u3092\u7528\u3044\u3066\u30ce\u30fc\u30c9\u9593\u306e\u91cd\u307f\u3092\u66f4\u65b0\u3059\u308b\u3002\n\n\n```math\n{\\bf w}^{\\rm \\tau+1} = {\\bf w}^{\\rm \\tau} - \\mu \\nabla  E({\\bf{w}})(5.43)\n```\n\n## \u30b3\u30fc\u30c9\n\n```python\nimport matplotlib.pyplot as plt\nfrom pylab import *\nimport numpy as np\nimport random\n\ndef heaviside(x):\n    return 0.5 * (np.sign(x) + 1)\n\ndef NN(x_train, t, n_imput, n_hidden, n_output, eta, W1, W2, n_loop):\n    for n in xrange(n_loop):\n        for n in range(len(x_train)):\n            x = np.array([x_train[n]])\n            \n            #feedforward\n            X = np.insert(x, 0, 1) #Insert fixed term\n\n            A = np.dot(W1, X) #(5.62)\n            Z = np.tanh(A)  #(5.63)\n            Z[0] = 1.0\n            Y = np.dot(W2, Z) #(5.64)\n\n   \n            #Backprobagation\n            D2 = Y - t[n]#(5.65)\n            D1 = (1-Z**2)*W2*D2 #(5.66)\n    \n            W1 = W1- eta*D1.T*X #(5.67), (5.43)\n            W2 = W2- eta*D2.T*Z #(5.67), (5.43)\n    return  W1, W2\n\ndef output(x, W1, W2):\n    X = np.insert(x, 0, 1) #Insert fixed term\n            \n    A = np.dot(W1, X) #(5.62)\n    Z = np.tanh(A)  #(5.63)\n    Z[0] = 1.0 #Insert fixed term\n    Y = np.dot(W2, Z) #(5.64)\n    return Y, Z\n\nif __name__ == \"__main__\":\n    #Set form of nueral network \n    n_imput = 2\n    n_hidden = 4\n    n_output = 1\n    eta = 0.1\n    W1 = np.random.random((n_hidden, n_imput))\n    W2 = np.random.random((n_output, n_hidden))\n    n_loop = 1000\n    \n    \n    #Set train data\n    x_train = np.linspace(-4, 4, 300).reshape(300, 1)\n    y_train_1 = x_train * x_train\n    y_train_2 = np.sin(x_train)\n    y_train_3 = np.abs(x_train)\n    y_train_4 = heaviside(x_train)\n    \n    W1_1, W2_1= NN(x_train, y_train_1, n_imput, n_hidden, n_output, eta, W1, W2, n_loop) \n    W1_2, W2_2= NN(x_train, y_train_2, n_imput, n_hidden, n_output, eta, W1, W2, n_loop)\n    W1_3, W2_3= NN(x_train, y_train_3, n_imput, n_hidden, n_output, eta, W1, W2, n_loop)\n    W1_4, W2_4= NN(x_train, y_train_4, n_imput, n_hidden, n_output, eta, W1, W2, n_loop)\n\n    Y_1 = np.zeros((len(x_train), n_output))\n    Z_1 = np.zeros((len(x_train), n_hidden))\n\n    Y_2 = np.zeros((len(x_train), n_output))\n    Z_2 = np.zeros((len(x_train), n_hidden))\n\n    Y_3 = np.zeros((len(x_train), n_output))\n    Z_3 = np.zeros((len(x_train), n_hidden))\n\n    Y_4 = np.zeros((len(x_train), n_output))\n    Z_4 = np.zeros((len(x_train), n_hidden))\n\n    for n in range(len(x_train)):\n        Y_1[n], Z_1[n] =output(x_train[n], W1_1, W2_1)\n        Y_2[n], Z_2[n] =output(x_train[n], W1_2, W2_2)\n        Y_3[n], Z_3[n] =output(x_train[n], W1_3, W2_3)\n        Y_4[n], Z_4[n] =output(x_train[n], W1_4, W2_4)\n    \n    \n    plt.plot(x_train, Y_1, \"r-\")\n    plt.plot(x_train, y_train_1, \"bo\", markersize=3)\n    for i in range(n_hidden):\n        plt.plot(x_train, Z_1[:,i], 'm--')\n    xlim([-1,1])\n    ylim([0, 1])\n    title(\"Figure 5.3(a)\")\n    show()\n    \n    plt.plot(x_train, Y_2, \"r-\")\n    plt.plot(x_train, y_train_2, \"bo\", markersize=2)\n    for i in range(n_hidden):\n        plt.plot(x_train, Z_2[:,i], 'm--')\n    xlim([-3.14,3.14])\n    ylim([-1, 1])\n    title(\"Figure 5.3(b)\")\n    show()\n    \n    \n    plt.plot(x_train, Y_3, \"r-\")\n    plt.plot(x_train, y_train_3, \"bo\", markersize=4)\n    for i in range(n_hidden):\n        plt.plot(x_train, Z_3[:,i], 'm--')\n    xlim([-1,1])\n    ylim([0, 1])\n    title(\"Figure 5.3(c)\")\n    show()\n    \n    \n    plt.plot(x_train, Y_4, \"r-\")\n    plt.plot(x_train, y_train_4, \"bo\" ,markersize=2)\n    for i in range(n_hidden):\n        plt.plot(x_train, Z_4[:,i], 'm--')\n    xlim([-2,2])\n    ylim([-0.05, 1.05])\n    title(\"Figure 5.3(d)\")\n    show()\n```\n\n##\u7d50\u679c\n![Screen Shot 2015-09-26 at 03.19.37.png](https://qiita-image-store.s3.amazonaws.com/0/62779/47fe4e1f-6586-6ff0-12fa-bc663ad22082.png)\n\n![Screen Shot 2015-09-26 at 03.19.59.png](https://qiita-image-store.s3.amazonaws.com/0/62779/5bfc28d5-f652-39e9-99a9-5a979b5c27a4.png)\n\n![Screen Shot 2015-09-26 at 03.20.17.png](https://qiita-image-store.s3.amazonaws.com/0/62779/2501bf69-c5a1-4229-09fb-7c7922f5f09f.png)\n\n![Screen Shot 2015-09-26 at 03.20.35.png](https://qiita-image-store.s3.amazonaws.com/0/62779/d0e2c3f2-e258-f75b-23bd-6c70c70804b7.png)\n\n\n\n", "tags": ["Python", "\u6a5f\u68b0\u5b66\u7fd2", "PRML"]}