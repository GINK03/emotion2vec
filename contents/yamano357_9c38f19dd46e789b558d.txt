{"context": "\n\n\u6982\u8981\n\u3000\u5c11\u3057\u524d\u306b{sparklyr}\u3068\u3044\u3046R\u304b\u3089Spark\u3092\u4f7f\u3046\u30d1\u30c3\u30b1\u30fc\u30b8\u304cRStudio\u793e\u304b\u3089\u516c\u958b\u3055\u308c\u307e\u3057\u305f\u3002\u3053\u306e{sparklyr}\u306b\u306fS3\u4e0a\u306e\u30d5\u30a1\u30a4\u30eb\u3082\u8aad\u307f\u8fbc\u3081\u308bspark_read_csv\u3068\u3044\u3046\u95a2\u6570\u304c\u63d0\u4f9b\u3055\u308c\u3066\u304a\u308a\u3001Amazon Athena\u304c\u6771\u4eac\u30ea\u30fc\u30b8\u30e7\u30f3\u306b\u6765\u308b\u307e\u3067\u4ee3\u308f\u308a\u306b\u4f7f\u3048\u306a\u3044\u304b\u3068\u8a66\u3057\u3066\u307f\u307e\u3057\u305f\u3002\n\u3000\u4eca\u56de\u306fAWS Public Datasets\u306b\u3042\u308b\u30c7\u30fc\u30bf\u30bb\u30c3\u30c8\u3092\u8aad\u307f\u8fbc\u3093\u3067\u307f\u307e\u3057\u305f\u304c\u3001\u5165\u529b\u5bfe\u8c61\u306eS3\u30d0\u30b1\u30c3\u30c8\u306b\u6a29\u9650\u304c\u3042\u308c\u3070\u540c\u3058\u3088\u3046\u306b\u6271\u3048\u308b\u3068\u601d\u3044\u307e\u3059\u3002\n\nsparklyr: R interface for Apache Spark\n\n\n\u4e8b\u524d\u6e96\u5099\n\u3000{sparklyr}\u306e\u6d3b\u7528\u306b\u3042\u305f\u3063\u3066\u5bfe\u8c61\u30d1\u30c3\u30b1\u30fc\u30b8\u306e\u30a4\u30f3\u30b9\u30c8\u30fc\u30eb\u3068\u3001Spark\u74b0\u5883\u306e\u8a2d\u5b9a\u304c\u5fc5\u8981\u306b\u306a\u308a\u307e\u3059\u3002\u5f8c\u8005\u306b\u3064\u3044\u3066\u306f{sparklyr}\u306b\u95a2\u6570\u304c\u7528\u610f\u3055\u308c\u3066\u3044\u308b\u306e\u3067\u3001\u4eca\u56de\u306f\u305d\u308c\u3092\u4f7f\u7528\u3057\u3066\u30ed\u30fc\u30ab\u30eb\u306b\u74b0\u5883\u69cb\u7bc9\u3057\u307e\u3059\u3002\n\u3000\u4eca\u56de\u306f\u8a66\u3057\u307e\u305b\u3093\u304c\u3001\u30ed\u30fc\u30ab\u30eb\u3067\u306f\u306a\u304fAWS\u4e0a\u306a\u3069\u306b\u5225\u69cb\u7bc9\u3057\u305fSpark\u74b0\u5883\u3082\u5229\u7528\u3067\u304d\u307e\u3059\u3002\u3053\u306e\u5834\u5408\u3001\u30bf\u30b9\u30af\u30ce\u30fc\u30c9\u3092\u30b9\u30dd\u30c3\u30c8\u30a4\u30f3\u30b9\u30bf\u30f3\u30b9\u3067\u69cb\u6210\u3059\u308b\u306a\u3069\u3067\u6bd4\u8f03\u7684\u5b89\u4fa1\u306b\u5927\u898f\u6a21\u30c7\u30fc\u30bf\u51e6\u7406\u74b0\u5883\u306e\u7528\u610f\u304c\u53ef\u80fd\u306b\u306a\u308a\u307e\u3059\u3002\n\u3000\u307e\u305f\u3001AWS CLI(\u30b3\u30de\u30f3\u30c9\u30e9\u30a4\u30f3\u30a4\u30f3\u30bf\u30fc\u30d5\u30a7\u30a4\u30b9)\u3092\u7528\u3044\u305f\u30d1\u30c3\u30b1\u30fc\u30b8\u3067S3\u306b\u30a2\u30af\u30bb\u30b9\u3057\u305f\u308a\u3057\u307e\u3059\u306e\u3067\u3001\u4e00\u7dd2\u306b\u30a4\u30f3\u30b9\u30c8\u30fc\u30eb\u3057\u307e\u3059\u3002\n\nAWS Documentation \u00bb Amazon Elastic MapReduce Documentation \u00bb \u30ea\u30ea\u30fc\u30b9\u30ac\u30a4\u30c9 \u00bb Apache Spark\nCluster Deployment\n\n\nSpark\u74b0\u5883\u8a2d\u5b9a\n\u3000\u524d\u8ff0\u306e\u901a\u308a\u3001{sparklyr}\u306e\u95a2\u6570\u3067\u30ed\u30fc\u30ab\u30eb\u306bSpark/Hadoop\u306e\u74b0\u5883\u3092\u69cb\u7bc9\u3057\u307e\u3059\u3002\u305f\u3060\u3057\u3001{sparklyr}\u306e\u30d0\u30fc\u30b8\u30e7\u30f3\u6b21\u7b2c\u3067\u5bfe\u5fdc\u3057\u3066\u3044\u306a\u3044Spark/Hadoop\u306e\u30d0\u30fc\u30b8\u30e7\u30f3\u304c\u3042\u308a\u307e\u3059\u306e\u3067\u3054\u6ce8\u610f\u304f\u3060\u3055\u3044\u3002\n\nSpark\u74b0\u5883\u8a2d\u5b9a\n# {sparklyr}\u306e\u30a4\u30f3\u30b9\u30c8\u30fc\u30eb\n# \u518d\u73fe\u3067\u304d\u308b\u3088\u3046\u306brepos\u5f15\u6570\u306bMicrosoft R Open\u306e\u30b9\u30ca\u30c3\u30d7\u30b7\u30e7\u30c3\u30c8\u30ea\u30dd\u30b8\u30c8\u30ea\u3092\u6307\u5b9a\n# \u7279\u306b\u652f\u969c\u304c\u306a\u304f\u30a4\u30f3\u30b9\u30c8\u30fc\u30eb\u3055\u308c\u308b\u306f\u305a\u306a\u306e\u3067\u3001\u5b9f\u884c\u5c65\u6b74\u306f\u7701\u7565\ninstall.packages(pkgs = \"sparklyr\", repos = \"https://mran.microsoft.com/snapshot/2017-01-11/\")\n\n\n# \u30a4\u30f3\u30b9\u30c8\u30fc\u30eb\u3067\u304d\u305f\u3089\u30d1\u30c3\u30b1\u30fc\u30b8\u8aad\u307f\u8fbc\u307f\nlibrary(sparklyr)\nlibrary(tidyverse)\n\n# \u30ed\u30fc\u30ab\u30eb\u4e0a\u306bSpark\u3068Hadoop\u74b0\u5883\u304c\u3042\u308b\u304b\u78ba\u8a8d\n# \u307e\u3060\u69cb\u7bc9\u3057\u3066\u3044\u306a\u3044\u306e\u3067\u3001\u7a7a\u306e\u30c7\u30fc\u30bf\u30d5\u30ec\u30fc\u30e0\u304c\u8fd4\u3063\u3066\u304f\u308b\n> sparklyr::spark_installed_versions()\n[1] spark  hadoop dir   \n<0 \u884c> (\u307e\u305f\u306f\u9577\u3055 0 \u306e row.names) \n\n# {sparklyr}\u3067\u7528\u610f\u3055\u308c\u3066\u3044\u308b\u95a2\u6570\u3067\u30a4\u30f3\u30b9\u30c8\u30fc\u30eb\u3067\u304d\u308b\u30d0\u30fc\u30b8\u30e7\u30f3\u306e\u5019\u88dc\u3092\u8868\u793a\n# \u305f\u3060\u3057\u3001\u30a4\u30f3\u30b9\u30c8\u30fc\u30eb\u3067\u304d\u308b\u30d0\u30fc\u30b8\u30e7\u30f3\u3067\u3082{sparklyr}\u3067\u306f\u5229\u7528\u3067\u304d\u306a\u3044\u30d0\u30fc\u30b8\u30e7\u30f3\u3082\u8868\u793a\u3055\u308c\u308b\n> sparklyr::spark_available_versions()\nspark hadoop                                                   install\n5  1.6.2    2.6  spark_install(version = \"1.6.2\", hadoop_version = \"2.6\")\n6  1.6.2    2.4  spark_install(version = \"1.6.2\", hadoop_version = \"2.4\")\n7  1.6.2    2.3  spark_install(version = \"1.6.2\", hadoop_version = \"2.3\")\n8  1.6.2   cdh4 spark_install(version = \"1.6.2\", hadoop_version = \"cdh4\")\n9  1.6.1    2.6  spark_install(version = \"1.6.1\", hadoop_version = \"2.6\")\n10 1.6.1    2.4  spark_install(version = \"1.6.1\", hadoop_version = \"2.4\")\n11 1.6.1    2.3  spark_install(version = \"1.6.1\", hadoop_version = \"2.3\")\n12 1.6.1   cdh4 spark_install(version = \"1.6.1\", hadoop_version = \"cdh4\")\n13 1.6.0    2.6  spark_install(version = \"1.6.0\", hadoop_version = \"2.6\")\n14 1.6.0    2.4  spark_install(version = \"1.6.0\", hadoop_version = \"2.4\")\n15 1.6.0    2.3  spark_install(version = \"1.6.0\", hadoop_version = \"2.3\")\n16 1.6.0   cdh4 spark_install(version = \"1.6.0\", hadoop_version = \"cdh4\")\n17 2.0.0    2.7  spark_install(version = \"2.0.0\", hadoop_version = \"2.7\")\n18 2.0.0    2.6  spark_install(version = \"2.0.0\", hadoop_version = \"2.6\")\n19 2.0.0    2.4  spark_install(version = \"2.0.0\", hadoop_version = \"2.4\")\n20 2.0.0    2.3  spark_install(version = \"2.0.0\", hadoop_version = \"2.3\")\n21 2.0.1    2.7  spark_install(version = \"2.0.1\", hadoop_version = \"2.7\")\n22 2.0.1    2.6  spark_install(version = \"2.0.1\", hadoop_version = \"2.6\")\n23 2.0.1    2.4  spark_install(version = \"2.0.1\", hadoop_version = \"2.4\")\n24 2.0.1    2.3  spark_install(version = \"2.0.1\", hadoop_version = \"2.3\")\n25 2.0.2    2.7  spark_install(version = \"2.0.2\", hadoop_version = \"2.7\")\n26 2.0.2    2.6  spark_install(version = \"2.0.2\", hadoop_version = \"2.6\")\n27 2.0.2    2.4  spark_install(version = \"2.0.2\", hadoop_version = \"2.4\")\n28 2.0.2    2.3  spark_install(version = \"2.0.2\", hadoop_version = \"2.3\")\n29 2.1.0    2.7  spark_install(version = \"2.1.0\", hadoop_version = \"2.7\")\n30 2.1.0    2.6  spark_install(version = \"2.1.0\", hadoop_version = \"2.6\")\n31 2.1.0    2.4  spark_install(version = \"2.1.0\", hadoop_version = \"2.4\")\n32 2.1.0    2.3  spark_install(version = \"2.1.0\", hadoop_version = \"2.3\")\n\n# \u4e0a\u8a18\u306e\u5019\u88dc\u306e\u3046\u3061\u3001\u300cversion = \"2.1.0\", hadoop_version = \"2.7\"\u300d\u3092\u6307\u5b9a\u3057\u3066\u30a4\u30f3\u30b9\u30c8\u30fc\u30eb\n> sparklyr::spark_install(version = \"2.1.0\", hadoop_version = \"2.7\")\nInstalling Spark 2.1.0 for Hadoop 2.7 or later.\nDownloading from:\n  - 'https://d3kbcqa49mib13.cloudfront.net/spark-2.1.0-bin-hadoop2.7.tgz'\nInstalling to:\n  - '~/Library/Caches/spark/spark-2.1.0-bin-hadoop2.7'\nURL 'https://d3kbcqa49mib13.cloudfront.net/spark-2.1.0-bin-hadoop2.7.tgz' \u3092\u8a66\u3057\u3066\u3044\u307e\u3059 \nContent type 'application/x-tar' length 195636829 bytes (186.6 MB)\n==================================================\n  downloaded 186.6 MB\n\nInstallation complete.\n\n\n# \u30ed\u30fc\u30ab\u30eb\u4e0a\u306bSpark\u3068Hadoop\u74b0\u5883\u304c\u3042\u308b\u304b\u3001\u518d\u5ea6\u78ba\u8a8d\n# \u30a4\u30f3\u30b9\u30c8\u30fc\u30eb\u3055\u308c\u305f\u30d0\u30fc\u30b8\u30e7\u30f3\u304b\u3089\u306a\u308b\u30c7\u30fc\u30bf\u30d5\u30ec\u30fc\u30e0\u304c\u8fd4\u3063\u3066\u304f\u308b\n> sparklyr::spark_installed_versions()\nspark hadoop                       dir\n1 2.1.0    2.7 spark-2.1.0-bin-hadoop2.7\n\n# \u8a66\u3057\u306b\u63a5\u7d9a\u3059\u308b\u3068\u73fe\u30d0\u30fc\u30b8\u30e7\u30f3(0.5.1)\u3067\u306fSpark 2.1.0\u306b\u306f\u5bfe\u5fdc\u3057\u3066\u3044\u306a\u3044\n> sc <- sparklyr::spark_connect(master = \"local\")\nsparklyr does not currently support Spark version: 2.1.0\n\n# \u30a4\u30f3\u30b9\u30c8\u30fc\u30eb\u3057\u305f\u30d0\u30fc\u30b8\u30e7\u30f3\u3092\u524a\u9664\n> sparklyr::spark_uninstall(version = \"2.1.0\", hadoop_version = \"2.7\")\nspark-2.1.0-bin-hadoop2.7 successfully uninstalled.\n\n# \u6539\u3081\u3066\u300cversion = \"2.1.0\", hadoop_version = \"2.7\"\u300d\u3092\u6307\u5b9a\u3057\u3066\u30a4\u30f3\u30b9\u30c8\u30fc\u30eb\n> sparklyr::spark_install(version = \"2.0.2\", hadoop_version = \"2.7\")\nInstalling Spark 2.0.2 for Hadoop 2.7 or later.\nDownloading from:\n  - 'https://d3kbcqa49mib13.cloudfront.net/spark-2.0.2-bin-hadoop2.7.tgz'\nInstalling to:\n  - '~/Library/Caches/spark/spark-2.0.2-bin-hadoop2.7'\nURL 'https://d3kbcqa49mib13.cloudfront.net/spark-2.0.2-bin-hadoop2.7.tgz' \u3092\u8a66\u3057\u3066\u3044\u307e\u3059 \nContent type 'application/x-tar' length 187426587 bytes (178.7 MB)\n==================================================\n  downloaded 178.7 MB\n\nInstallation complete.\n\n\n# \u78ba\u8a8d\n> sparklyr::spark_installed_versions()\nspark hadoop                       dir\n1 2.0.2    2.7 spark-2.0.2-bin-hadoop2.7\n\n# \u63a5\u7d9a\u3067\u304d\u3066\u3082\u4f55\u3082\u8fd4\u3055\u306a\u3044\uff081\u7cfb\u4ee5\u964d\u306eRStudio\u3067\u306f\u53f3\u4e0a\u306eSpark\u30d1\u30cd\u30eb\u304c\u5207\u308a\u66ff\u308f\u308b\uff09\nsc <- sparklyr::spark_connect(master = \"local\")\n# \u63a5\u7d9a\u3055\u308c\u3066\u3044\u308b\u304b\u78ba\u8a8d\n> sparklyr::spark_connection_is_open(sc = sc)\n[1] TRUE\n\n# \u63a5\u7d9a\u3092\u5207\u3063\u3066\u518d\u78ba\u8a8d\nsparklyr::spark_disconnect(sc = sc)\n> sparklyr::spark_connection_is_open(sc = sc)\n[1] FALSE\n\n\n\nAWS CLI\u306e\u30a4\u30f3\u30b9\u30c8\u30fc\u30eb\n\u3000EC2\u3067\u3042\u308c\u3070AWS CLI\u304c\u4e8b\u524d\u306b\u30a4\u30f3\u30b9\u30c8\u30fc\u30eb\u3055\u308c\u3066\u3044\u307e\u3059\u304c\u3001\u81ea\u5206\u306eMac\u74b0\u5883\u3067\u306f\u7528\u610f\u3055\u308c\u3066\u3044\u306a\u3044\u306e\u3067\u5225\u9014\u30a4\u30f3\u30b9\u30c8\u30fc\u30eb\u3057\u307e\u3059\u3002\u8abf\u3079\u3066\u307f\u308b\u3068Homebrew\u3067\u30a4\u30f3\u30b9\u30c8\u30fc\u30eb\u3067\u304d\u308b\u3088\u3046\u306a\u306e\u3067\u3001\u4eca\u56de\u306f\u305d\u3061\u3089\u3067\u6e96\u5099\u3057\u307e\u3057\u305f\u3002\n\nAWS_CLI\n# \u4e00\u90e8\u306e\u307f\u8868\u793a\n$ brew info awscli\nawscli: stable 1.11.36 (bottled), HEAD\nOfficial Amazon AWS command-line interface\nhttps://aws.amazon.com/cli/\n\n# \u30a4\u30f3\u30b9\u30c8\u30fc\u30eb\uff08\u5c65\u6b74\u306f\u7701\u7565\uff09\n$ brew install awscli\n\n# \u30a4\u30f3\u30b9\u30c8\u30fc\u30eb\u5f8c\u306baws configure\u3067\u30a2\u30af\u30bb\u30b9\u30ad\u30fc\u3001\u30b7\u30fc\u30af\u30ec\u30c3\u30c8\u30a2\u30af\u30bb\u30b9\u30ad\u30fc\u3001\u30c7\u30d5\u30a9\u30eb\u30c8\u30ea\u30fc\u30b8\u30e7\u30f3\u3092\u81ea\u524d\u306e\u3082\u306e\u3092\u8a2d\u5b9a\n# aws_pdataset\u3068\u3044\u3046\u540d\u524d\u306eprofile\u3092\u4f5c\u3063\u3066\u53c2\u7167\u3067\u304d\u308b\u3088\u3046\u306b\u3057\u3066\u304a\u304f\n$ aws configure --profile aws_pdataset\n\n\n\nAWS Public Datasets\u306e\u30d0\u30b1\u30c3\u30c8\u69cb\u9020\u3092\u78ba\u8a8d\n\u3000AWS Public Datasets\u306b\u3042\u308b\u30c7\u30fc\u30bf\u30bb\u30c3\u30c8\u306e\u30d0\u30b1\u30c3\u30c8\u69cb\u9020\u3092\u8abf\u3079\u308b\u305f\u3081\u3001\u4e0b\u8a18\u306e\u30d1\u30c3\u30b1\u30fc\u30b8\u3092\u5229\u7528\u3057\u3066S3\u306b\u30a2\u30af\u30bb\u30b9\u3057\u3066\u78ba\u8a8d\u3057\u307e\u3057\u305f\u3002\u524d\u8ff0\u306e\u3068\u304a\u308a\u3001\u3053\u3061\u3089\u306e\u30d1\u30c3\u30b1\u30fc\u30b8\u3067\u306fAWS CLI\u3092\u5229\u7528\u3057\u3066\u3044\u307e\u3059\u3002\n\u3000\n- Amazon Simple Storage Service (S3) API Client\n\nS3\u30d0\u30b1\u30c3\u30c8\u78ba\u8a8d\nlibrary(aws.signature)\nlibrary(aws.s3)\n\n# aws configure\u3067\u30a2\u30af\u30bb\u30b9\u30ad\u30fc\u306a\u3069\u3092\u8a2d\u5b9a\u3057\u3066\u3044\u306a\u3044\u5834\u5408\u306f\u4e0b\u8a18\u306e\u3088\u3046\u306b\u74b0\u5883\u5909\u6570\u3092\u30bb\u30c3\u30c8\u3059\u308b\u5fc5\u8981\u304c\u3042\u308b\n# \u30bb\u30ad\u30e5\u30ea\u30c6\u30a3\u89b3\u70b9\u304b\u3089\u5b9f\u30ad\u30fc\u306f\u4f0f\u305b\u3066\u3044\u307e\u3059\nSys.setenv(AWS_ACCESS_KEY_ID = \"***************\")\nSys.setenv(AWS_SECRET_ACCESS_KEY = \"***************\")\nSys.setenv(AWS_DEFAULT_REGION = \"us-east-1\")\n\n# profile\u540d\u3092\u6307\u5b9a\u3057\u3066\u3001aws configure\u3067\u8a2d\u5b9a\u3057\u305f\u30a2\u30af\u30bb\u30b9\u30ad\u30fc\u3084\u30b7\u30fc\u30af\u30ec\u30c3\u30c8\u30a2\u30af\u30bb\u30b9\u30ad\u30fc\u306a\u3069\u3092\u8aad\u307f\u8fbc\u307f\naws.signature::use_credentials(profile = \"aws_pdataset\")\n\n# \"1000genomes\"\u306e\u30c7\u30fc\u30bf\u30bb\u30c3\u30c8\u306e\u30d0\u30b1\u30c3\u30c8\u69cb\u9020\u3092\u95b2\u89a7\n# \u3053\u3053\u3067\u306f\"alignment_indices/2012\"\u304c\u4ed8\u304f\u3082\u306e\u309215\u500b\u8868\u793a\n> genomes <- aws.s3::get_bucket(bucket = \"1000genomes\", prefix = \"alignment_indices/2012\", max = 15, parse_response = TRUE)\nBucket: 1000genomes \n\n$Contents\nKey:            alignment_indices/20120522.alignment.chr20_cram.index \nLastModified:   2013-05-29T17:35:36.000Z \nETag:           \"ea7863d5db6acc3b6ca997bfa6d2c6c9\" \nSize (B):       270984 \nOwner:          1000genomes \nStorage class:  STANDARD \n\n$Contents\nKey:            alignment_indices/20120522.alignment.chr20_lossy_cram.index \nLastModified:   2013-05-27T16:33:30.000Z \nETag:           \"aeae5be28807b89f67ebdfe85e2fd676\" \nSize (B):       284256 \nOwner:          1000genomes \nStorage class:  STANDARD \n\n$Contents\nKey:            alignment_indices/20120522.alignment.index \nLastModified:   2013-06-03T18:15:51.000Z \nETag:           \"82d9523c2a48d18185f6ba905c306d7e\" \nSize (B):       1561723 \nOwner:          1000genomes \nStorage class:  STANDARD \n\n$Contents\nKey:            alignment_indices/20120522.alignment.index.bas.gz \nLastModified:   2013-06-03T18:14:53.000Z \nETag:           \"275801bf228b1ff33664dc0d538e320f\" \nSize (B):       1233947 \nOwner:          1000genomes \nStorage class:  STANDARD \n\n$Contents\nKey:            alignment_indices/20120522.alignment.mapped.binned_csra.index \nLastModified:   2014-09-02T22:15:39.000Z \nETag:           \"ab60350c0873f9527ce1347541027a8e\" \nSize (B):       131623 \nOwner:          1000genomes \nStorage class:  STANDARD \n\n$Contents\nKey:            alignment_indices/20120522.exome.alignment.chr20_cram.index \nLastModified:   2013-05-29T08:43:56.000Z \nETag:           \"7cf05ef22b7d2c9b5e64bf5cb9f03916\" \nSize (B):       215312 \nOwner:          1000genomes \nStorage class:  STANDARD \n\n$Contents\nKey:            alignment_indices/20120522.exome.alignment.chr20_lossy_cram.index \nLastModified:   2014-09-03T04:15:33.000Z \nETag:           \"fce87b37792304ab79e9584e224bf1b8\" \nSize (B):       225944 \nOwner:          1000genomes \nStorage class:  STANDARD \n\n$Contents\nKey:            alignment_indices/20120522.exome.alignment.index \nLastModified:   2013-06-03T18:14:54.000Z \nETag:           \"83ff92283546ad85101b80cf9e04e10b\" \nSize (B):       1240451 \nOwner:          1000genomes \nStorage class:  STANDARD \n\n$Contents\nKey:            alignment_indices/20120522.exome.alignment.index.HsMetrics.gz \nLastModified:   2014-09-03T03:54:02.000Z \nETag:           \"6742b3655a3cd388cc1ec3406b61f835\" \nSize (B):       118484 \nOwner:          1000genomes \nStorage class:  STANDARD \n\n$Contents\nKey:            alignment_indices/20120522.exome.alignment.index.HsMetrics.stats \nLastModified:   2013-05-28T11:39:20.000Z \nETag:           \"6757ae9b582c46174b764f4efe9097a6\" \nSize (B):       376 \nOwner:          1000genomes \nStorage class:  STANDARD \n\n$Contents\nKey:            alignment_indices/20120522.exome.alignment.index.bas.gz \nLastModified:   2013-06-03T18:15:57.000Z \nETag:           \"a7e71fab455a9f9634e0b4ec2c208658\" \nSize (B):       1617379 \nOwner:          1000genomes \nStorage class:  STANDARD \n\n$Contents\nKey:            alignment_indices/20120522.exome.alignment.mapped.binned_csra.index \nLastModified:   2014-09-02T12:22:40.000Z \nETag:           \"3b77f700a59c1f27b0f04a05bda4fc63\" \nSize (B):       104557 \nOwner:          1000genomes \nStorage class:  STANDARD \n\n$Contents\nKey:            alignment_indices/20120522_20111114.alignment_stats.exome.csv \nLastModified:   2013-06-03T18:08:02.000Z \nETag:           \"e4149d8e97a324892571fad80e0c6a6e\" \nSize (B):       1344 \nOwner:          1000genomes \nStorage class:  STANDARD \n\n$Contents\nKey:            alignment_indices/20120522_20111114.alignment_stats.low_coverage.csv \nLastModified:   2013-06-03T18:08:02.000Z \nETag:           \"b99c5dc76cd28a83cee962ecb33e6235\" \nSize (B):       1500 \nOwner:          1000genomes \nStorage class:  STANDARD \n\n$Contents\nKey:            alignment_indices/20121211.alignment.index \nLastModified:   2014-09-02T08:48:22.000Z \nETag:           \"9668dcf90d6d149ae612581cf404d7a1\" \nSize (B):       2332675 \nOwner:          1000genomes \nStorage class:  STANDARD \n\n\n\u3000\u3053\u3053\u3067\u306f\u6b21\u306e\u3075\u305f\u3064\u306e\u30d5\u30a1\u30a4\u30eb\u3092\u8aad\u307f\u8fbc\u3093\u3067\u307f\u307e\u3059\u3002\n\nalignment_indices/20120522.alignment.index\n\nalignment_indices/20120522.alignment.index.bas.gz\n\n\u3000\u30c7\u30fc\u30bf\u30d5\u30a9\u30fc\u30de\u30c3\u30c8\u306f\u4e0b\u8a18\u3092\u53c2\u8003\u307e\u3067\u306b\u3002\n- IGSR: The International Genome Sample Resource - Data file formats\n\nAWS Public Datasets\u306b\u3042\u308b\u30d5\u30a1\u30a4\u30eb\u3092\u8aad\u307f\u8fbc\u3080\n\u3000{sparklyr}\u3067\u306fS3\u306b\u3042\u308b\u30d5\u30a1\u30a4\u30eb\u3092\u8aad\u307f\u8fbc\u3081\u308b\u95a2\u6570\u304c\u5b9a\u7fa9\u3055\u308c\u3066\u3044\u307e\u3059\u304c\u3001\u30c7\u30d5\u30a9\u30eb\u30c8\u306e\u8a2d\u5b9a\u306e\u307e\u307e\u3067\u306f\u30ed\u30fc\u30ab\u30eb\u307e\u305f\u306fEC2\u304b\u3089\u306f\u8aad\u307f\u8fbc\u3081\u307e\u305b\u3093\uff08EMR\u304b\u3089\u3060\u3068\u53ef\u80fd\uff1f\uff09\u3002\n\u3000\u3053\u306e\u4ef6\u306b\u3064\u3044\u3066\u306f\u3001\u4e0b\u8a18\u306e\u901a\u308a\u30d8\u30eb\u30d7\u30c9\u30ad\u30e5\u30e1\u30f3\u30c8\u306b\u306f\u8a18\u8ff0\u304c\u3042\u308a\u307e\u305b\u3093\u3002\n\u3000\u300espark_read_csv {sparklyr} - R Documentation\u300f\u3088\u308a\n\nYou can read data from HDFS (hdfs://), S3 (s3n://), as well as the local file system (file://).\n\n\n\u30c7\u30d5\u30a9\u30eb\u30c8\u8a2d\u5b9a\u306e\u307e\u307e\nsc <- sparklyr::spark_connect(master = \"local\")\n> genome_alignment_indices <- sparklyr::spark_read_csv(\n+     sc = sc, name = \"alignment_indices\",\n+     path = \"s3a://1000genomes/20120522.alignment.index\",\n+     infer_schema = TRUE, header = TRUE, delimiter = \"\\t\"\n+ )\n \u30a8\u30e9\u30fc: java.lang.RuntimeException: java.lang.ClassNotFoundException: Class org.apache.hadoop.fs.s3a.S3AFileSystem not found\n    at org.apache.hadoop.conf.Configuration.getClass(Configuration.java:2195)\n    at org.apache.hadoop.fs.FileSystem.getFileSystemClass(FileSystem.java:2654)\n    at org.apache.hadoop.fs.FileSystem.createFileSystem(FileSystem.java:2667)\n    at org.apache.hadoop.fs.FileSystem.access$200(FileSystem.java:94)\n    at org.apache.hadoop.fs.FileSystem$Cache.getInternal(FileSystem.java:2703)\n    at org.apache.hadoop.fs.FileSystem$Cache.get(FileSystem.java:2685)\n    at org.apache.hadoop.fs.FileSystem.get(FileSystem.java:373)\n    at org.apache.hadoop.fs.Path.getFileSystem(Path.java:295)\n    at org.apache.spark.sql.execution.datasources.DataSource$$anonfun$12.apply(DataSource.scala:381)\n    at org.apache.spark.sql.execution.datasources.DataSource$$anonfun$12.apply(DataSource.scala:379)\n    at scala.collection.TraversableLike$$anonfun$flatMap$1.apply(TraversableLike.scala:241)\n    at scala.collection.TraversableLike$$anonfun$flatMap$1.apply(TraversableLike.scala:241)\n    at scala.collection.immutable.List.foreach(List.scala:381)\n    at scala.collection.TraversableLike$class.flatMap(TraversableLike.scala:241)\n    at scala.collection.immutable.List.flatMap(List.scala:344)\n    at org.apache.spark.sql.execution.datasources.DataSource.resolveRelation(DataSource.scala:379)\n    at org.apache.spark.sql.DataFrameReader.load(DataFrameReader.scala:149)\n    at org.apache.spark.sql.DataFrameReader.csv(DataFrameReader.scala:413)\n    at org.apache.spark.sql.DataFrameReader.csv(DataFrameReader.scala:349)\n    at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n    at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\n    at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n    at java.lang.reflect.Method.invoke(Method.java:497)\n    at sparklyr.Invoke$.invoke(invoke.scala:94)\n    at sparklyr.StreamHandler$.handleMethodCall(stream.scala:89)\n    at sparklyr.StreamHandler$.read(stream.scala:55)\n    at sparklyr.BackendHandler.channelRead0(handler.scala:49)\n    at sparklyr.BackendHandler.channelRead0(handler.scala:14)\n    at io.netty.channel.SimpleChannelInboundHandler.channelRead(SimpleChannelInboundHandler.java:105)\n    at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:308)\n    at io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:294)\n    at io.netty.handler.codec.MessageToMessageDecoder.channelRead(MessageToMessageDecoder.java:103)\n    at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:308)\n    at io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:294)\n    at io.netty.handler.codec.ByteToMessageDecoder.channelRead(ByteToMessageDecoder.java:244)\n    at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:308)\n    at io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:294)\n    at io.netty.channel.DefaultChannelPipeline.fireChannelRead(DefaultChannelPipeline.java:846)\n    at io.netty.channel.nio.AbstractNioByteChannel$NioByteUnsafe.read(AbstractNioByteChannel.java:131)\n    at io.netty.channel.nio.NioEventLoop.processSelectedKey(NioEventLoop.java:511)\n    at io.netty.channel.nio.NioEventLoop.processSelectedKeysOptimized(NioEventLoop.java:468)\n    at io.netty.channel.nio.NioEventLoop.processSelectedKeys(NioEventLoop.java:382)\n    at io.netty.channel.nio.NioEventLoop.run(NioEventLoop.java:354)\n    at io.netty.util.concurrent.SingleThreadEventExecutor$2.run(SingleThreadEventExecutor.java:111)\n    at io.netty.util.concurrent.DefaultThreadFactory$DefaultRunnableDecorator.run(DefaultThreadFactory.java:137)\n    at java.lang.Thread.run(Thread.java:745)\nCaused by: java.lang.ClassNotFoundException: Class org.apache.hadoop.fs.s3a.S3AFileSystem not found\n    at org.apache.hadoop.conf.Configuration.getClassByName(Configuration.java:2101)\n    at org.apache.hadoop.conf.Configuration.getClass(Configuration.java:2193)\n    ... 45 more\n\n\n# \u63a5\u7d9a\u3092\u5207\u308b\nsparklyr::spark_disconnect(sc = sc)\n\n\n\u3000\u3053\u308c\u306b\u5bfe\u5fdc\u3059\u308b\u306b\u306f\u3001\u63a5\u7d9a\u6642\u306e\u8a2d\u5b9a\u306bhadoop-aws\u3092\u30c7\u30d5\u30a9\u30eb\u30c8\u30d1\u30c3\u30b1\u30fc\u30b8\u3068\u3057\u3066\u8ffd\u52a0\u3057\u3066\u304a\u304f\u5fc5\u8981\u304c\u3042\u308a\u307e\u3059\u3002\u3053\u308c\u3092R\u4e0a\u3067\u3059\u308b\u306b\u306fspark_config\u3092\u4f7f\u3044\u307e\u3059\u3002\n\nHadoop-AWS module: Integration with Amazon Web Services\n\u30ed\u30fc\u30ab\u30eb\u306eSpark\u3067S3\u306e\u30d5\u30a1\u30a4\u30eb\u3092\u6271\u3046\n\n\n\u8a2d\u5b9a\u8ffd\u52a0\n# sparklyr::spark_config\u3067\u30c7\u30d5\u30a9\u30eb\u30c8\u8a2d\u5b9a\u30d5\u30a1\u30a4\u30eb\u3092\u8aad\u307f\u8fbc\u307f\nspark_config <- sparklyr::spark_config()\n\n# \u30c7\u30d5\u30a9\u30eb\u30c8\u30d1\u30c3\u30b1\u30fc\u30b8\u306bhadoop-aws\u3092\u8ffd\u52a0\nspark_config$sparklyr.defaultPackages <- append(\n  x = spark_config$sparklyr.defaultPackages, \"org.apache.hadoop:hadoop-aws:2.7.3\"\n)\n# \u30a4\u30f3\u30b9\u30c8\u30fc\u30eb\u72b6\u6cc1\u306b\u3088\u3063\u3066\u30d0\u30fc\u30b8\u30e7\u30f3\u306f\u7570\u306a\u308a\u305d\u3046\n> list.files(path = \"~/.ivy2/cache/org.apache.hadoop/hadoop-aws/jars/\")\n[1] \"hadoop-aws-2.7.2.jar\" \"hadoop-aws-2.7.3.jar\"\n\n\n# config\u5f15\u6570\u306b\u30bb\u30c3\u30c8\u3057\u305f\u8a2d\u5b9a\u3092\u6e21\u3057\u3066\u518d\u5ea6\u63a5\u7d9a\nsc <- sparklyr::spark_connect(master = \"local\", config = spark_config)\n> spark_connection_is_open(sc = sc)\n[1] TRUE\n\n# \u30a8\u30e9\u30fc\u304c\u306a\u304f\u7d50\u679c\u304c\u5f97\u3089\u308c\u308b\n# infer_schema\u5f15\u6570\u3092TRUE\u306b\u3057\u3066\u304a\u304f\u3068\u5404\u30ab\u30e9\u30e0\u306e\u578b\u3092\u63a8\u5b9a\u3057\u3066\u304f\u308c\u308b\ngenome_alignment_indices <- sparklyr::spark_read_csv(\n  sc = sc, name = \"alignment_indices\", path = \"s3a://1000genomes/alignment_indices/20100517.alignment.index\",\n  infer_schema = TRUE, header = TRUE, delimiter = \",\"\n)\n> genome_alignment_indices\nSource:   query [4,424 x 6]\nDatabase: spark connection master=local[4] app=sparklyr local=TRUE\n\n                                                                             BAM_FILE                          BAM_MD5\n                                                                                <chr>                            <chr>\n1   data/HG00096/alignment/HG00096.chrom11.ILLUMINA.bwa.GBR.low_coverage.20120522.bam e2425c6f57b2aa4ddb08f472d98221d0\n2   data/HG00096/alignment/HG00096.chrom20.ILLUMINA.bwa.GBR.low_coverage.20120522.bam c5cb5c7b356e95df899f7e780fa22e2b\n3    data/HG00096/alignment/HG00096.mapped.ILLUMINA.bwa.GBR.low_coverage.20120522.bam 336ea55913bc261b72875bd259753046\n4  data/HG00096/alignment/HG00096.unmapped.ILLUMINA.bwa.GBR.low_coverage.20120522.bam 21f4323f02d6d2a888a02bdfb24dc143\n5   data/HG00103/alignment/HG00103.chrom11.ILLUMINA.bwa.GBR.low_coverage.20120522.bam 09f5199ca81b87fba667a1d60d166474\n6   data/HG00103/alignment/HG00103.chrom20.ILLUMINA.bwa.GBR.low_coverage.20120522.bam 34f0cfc7d3584a64e104a1ebbc9209ab\n7    data/HG00103/alignment/HG00103.mapped.ILLUMINA.bwa.GBR.low_coverage.20120522.bam a09f7acc6a736daae40f689b8c9e40c2\n8  data/HG00103/alignment/HG00103.unmapped.ILLUMINA.bwa.GBR.low_coverage.20120522.bam 2d355139e1c8fe220efbf47f0e050bcf\n9   data/HG00106/alignment/HG00106.chrom11.ILLUMINA.bwa.GBR.low_coverage.20120522.bam cef7bda3308f06dcb9fe494c7addbd76\n10  data/HG00106/alignment/HG00106.chrom20.ILLUMINA.bwa.GBR.low_coverage.20120522.bam 81b3973ae3fa78083a9737f3bf800182\n# ... with 4,414 more rows, and 4 more variables: BAI_FILE <chr>, BAI_MD5 <chr>, BAS_FILE <chr>, BAS_MD5 <chr>\n\n\n# .gz\u30d5\u30a1\u30a4\u30eb\u3082\u5bfe\u5fdc\n# infer_schema\u5f15\u6570\u3092FALSE\u306b\u3059\u308b\u3068\u5404\u30ab\u30e9\u30e0\u306e\u578b\u304c\u6587\u5b57\u5217\u3068\u3057\u3066\u8aad\u307f\u8fbc\u307e\u308c\u308b\ngenome_alignment_indices_bas <- sparklyr::spark_read_csv(\n  sc = sc, name = \"alignment_indices_bas\", path = \"s3a://1000genomes/alignment_indices/20120522.alignment.index.bas.gz\",\n  infer_schema = FALSE, header = TRUE, delimiter = \"\\t\"\n)\n> genome_alignment_indices_bas\nSource:   query [2.78e+04 x 21]\nDatabase: spark connection master=local[4] app=sparklyr local=TRUE\n\n                                              bam_filename                              md5     study  sample platform\n                                                     <chr>                            <chr>     <chr>   <chr>    <chr>\n1   HG00096.chrom11.ILLUMINA.bwa.GBR.low_coverage.20120522 e2425c6f57b2aa4ddb08f472d98221d0 SRP001294 HG00096 ILLUMINA\n2   HG00096.chrom11.ILLUMINA.bwa.GBR.low_coverage.20120522 e2425c6f57b2aa4ddb08f472d98221d0 SRP001294 HG00096 ILLUMINA\n3   HG00096.chrom11.ILLUMINA.bwa.GBR.low_coverage.20120522 e2425c6f57b2aa4ddb08f472d98221d0 SRP001294 HG00096 ILLUMINA\n4   HG00096.chrom20.ILLUMINA.bwa.GBR.low_coverage.20120522 c5cb5c7b356e95df899f7e780fa22e2b SRP001294 HG00096 ILLUMINA\n5   HG00096.chrom20.ILLUMINA.bwa.GBR.low_coverage.20120522 c5cb5c7b356e95df899f7e780fa22e2b SRP001294 HG00096 ILLUMINA\n6   HG00096.chrom20.ILLUMINA.bwa.GBR.low_coverage.20120522 c5cb5c7b356e95df899f7e780fa22e2b SRP001294 HG00096 ILLUMINA\n7    HG00096.mapped.ILLUMINA.bwa.GBR.low_coverage.20120522 336ea55913bc261b72875bd259753046 SRP001294 HG00096 ILLUMINA\n8    HG00096.mapped.ILLUMINA.bwa.GBR.low_coverage.20120522 336ea55913bc261b72875bd259753046 SRP001294 HG00096 ILLUMINA\n9    HG00096.mapped.ILLUMINA.bwa.GBR.low_coverage.20120522 336ea55913bc261b72875bd259753046 SRP001294 HG00096 ILLUMINA\n10 HG00096.unmapped.ILLUMINA.bwa.GBR.low_coverage.20120522 21f4323f02d6d2a888a02bdfb24dc143 SRP001294 HG00096 ILLUMINA\n# ... with 2.779e+04 more rows, and 16 more variables: library <chr>, readgroup <chr>, `_total_bases` <chr>,\n#   `_mapped_bases` <chr>, `_total_reads` <chr>, `_mapped_reads` <chr>, `_mapped_reads_paired_in_sequencing` <chr>,\n#   `_mapped_reads_properly_paired` <chr>, `_of_mismatched_bases` <chr>, average_quality_of_mapped_bases <chr>,\n#   mean_insert_size <chr>, insert_size_sd <chr>, median_insert_size <chr>, insert_size_median_absolute_deviation <chr>,\n#   `_duplicate_reads` <chr>, `_duplicate_bases` <chr>\n\n\n# columns\u5f15\u6570\u306b\u540d\u524d\u4ed8\u304d\u30d9\u30af\u30c8\u30eb\u3092\u4e0e\u3048\u308b\u3053\u3068\u3067\u5404\u30ab\u30e9\u30e0\u306e\u578b\u3068\u540d\u524d\u3092\u6307\u5b9a\u3067\u304d\u308b\n# R\u3068Spark\u9593\u306e\u578b\u306e\u9055\u3044\u306f\u4e0b\u8a18\u306e\u30c9\u30ad\u30e5\u30e1\u30f3\u30c8\u3092\n# http://spark.apache.org/docs/latest/sparkr.html#data-type-mapping-between-r-and-spark\ncols <- c(\n  rep(x = \"string\", length = 7), rep(x = \"double\", length = 7), rep(x = \"float\", length = 5), \n  \"integer\", \"string\"\n)\nnames(x = cols) <- colnames(x = genome_alignment_indices_bas)\n\n# \u8b66\u544a\u30e1\u30c3\u30bb\u30fc\u30b8\u306b\u3064\u3044\u3066\u306f\u672a\u8abf\u67fb\ngenome_alignment_indices_bas_cols <- sparklyr::spark_read_csv(\n  sc = sc, name = \"alignment_indices_bas_cols\", path = \"s3a://1000genomes/alignment_indices/20120522.alignment.index.bas.gz\",\n  infer_schema = FALSE, header = TRUE, delimiter = \"\\t\",\n  columns = cols\n)\n \u8b66\u544a\u30e1\u30c3\u30bb\u30fc\u30b8: \n spark_csv_read(sc, spark_normalize_path(path), options, columns) \u3067: \n  Dataset has 1 columns but 'columns' has length 21\n\n> genome_alignment_indices_bas_cols\nSource:   query [2.78e+04 x 21]\nDatabase: spark connection master=local[4] app=sparklyr local=TRUE\n\n                                              bam_filename                              md5     study  sample platform    library readgroup\n                                                     <chr>                            <chr>     <chr>   <chr>    <chr>      <chr>     <chr>\n1   HG00096.chrom11.ILLUMINA.bwa.GBR.low_coverage.20120522 e2425c6f57b2aa4ddb08f472d98221d0 SRP001294 HG00096 ILLUMINA 2845856850 SRR062634\n2   HG00096.chrom11.ILLUMINA.bwa.GBR.low_coverage.20120522 e2425c6f57b2aa4ddb08f472d98221d0 SRP001294 HG00096 ILLUMINA 2845856850 SRR062635\n3   HG00096.chrom11.ILLUMINA.bwa.GBR.low_coverage.20120522 e2425c6f57b2aa4ddb08f472d98221d0 SRP001294 HG00096 ILLUMINA 2845856850 SRR062641\n4   HG00096.chrom20.ILLUMINA.bwa.GBR.low_coverage.20120522 c5cb5c7b356e95df899f7e780fa22e2b SRP001294 HG00096 ILLUMINA 2845856850 SRR062634\n5   HG00096.chrom20.ILLUMINA.bwa.GBR.low_coverage.20120522 c5cb5c7b356e95df899f7e780fa22e2b SRP001294 HG00096 ILLUMINA 2845856850 SRR062635\n6   HG00096.chrom20.ILLUMINA.bwa.GBR.low_coverage.20120522 c5cb5c7b356e95df899f7e780fa22e2b SRP001294 HG00096 ILLUMINA 2845856850 SRR062641\n7    HG00096.mapped.ILLUMINA.bwa.GBR.low_coverage.20120522 336ea55913bc261b72875bd259753046 SRP001294 HG00096 ILLUMINA 2845856850 SRR062634\n8    HG00096.mapped.ILLUMINA.bwa.GBR.low_coverage.20120522 336ea55913bc261b72875bd259753046 SRP001294 HG00096 ILLUMINA 2845856850 SRR062635\n9    HG00096.mapped.ILLUMINA.bwa.GBR.low_coverage.20120522 336ea55913bc261b72875bd259753046 SRP001294 HG00096 ILLUMINA 2845856850 SRR062641\n10 HG00096.unmapped.ILLUMINA.bwa.GBR.low_coverage.20120522 21f4323f02d6d2a888a02bdfb24dc143 SRP001294 HG00096 ILLUMINA 2845856850 SRR062634\n# ... with 2.779e+04 more rows, and 14 more variables: `_total_bases` <dbl>, `_mapped_bases` <dbl>, `_total_reads` <dbl>, `_mapped_reads` <dbl>,\n#   `_mapped_reads_paired_in_sequencing` <dbl>, `_mapped_reads_properly_paired` <dbl>, `_of_mismatched_bases` <dbl>,\n#   average_quality_of_mapped_bases <dbl>, mean_insert_size <dbl>, insert_size_sd <dbl>, median_insert_size <dbl>,\n#   insert_size_median_absolute_deviation <dbl>, `_duplicate_reads` <int>, `_duplicate_bases` <chr>\n\n\n# `$`\u306b\u3088\u308b\u53c2\u7167\u306f\u3067\u304d\u306a\u3044\u306e\u3067\u6ce8\u610f\n> genome_alignment_indices_bas_cols$bam_filename\nNULL\n\n# select\u3067\u53c2\u7167\n> genome_alignment_indices_bas_cols %>% \n+   dplyr::select(bam_filename) %>% \n+   head(n = 10)\nSource:   query [10 x 1]\nDatabase: spark connection master=local[4] app=sparklyr local=TRUE\n\n                                              bam_filename\n                                                     <chr>\n1   HG00096.chrom11.ILLUMINA.bwa.GBR.low_coverage.20120522\n2   HG00096.chrom11.ILLUMINA.bwa.GBR.low_coverage.20120522\n3   HG00096.chrom11.ILLUMINA.bwa.GBR.low_coverage.20120522\n4   HG00096.chrom20.ILLUMINA.bwa.GBR.low_coverage.20120522\n5   HG00096.chrom20.ILLUMINA.bwa.GBR.low_coverage.20120522\n6   HG00096.chrom20.ILLUMINA.bwa.GBR.low_coverage.20120522\n7    HG00096.mapped.ILLUMINA.bwa.GBR.low_coverage.20120522\n8    HG00096.mapped.ILLUMINA.bwa.GBR.low_coverage.20120522\n9    HG00096.mapped.ILLUMINA.bwa.GBR.low_coverage.20120522\n10 HG00096.unmapped.ILLUMINA.bwa.GBR.low_coverage.20120522\n\n\n# \u3068\u308a\u3042\u3048\u305a\u96c6\u8a08\u3057\u3066\u307f\u308b\n> genome_summarize <- genome_alignment_indices_bas_cols %>% \n  dplyr::group_by(readgroup) %>% \n  dplyr::summarize(\n    total_bases = sum(`_total_bases`),\n    mapped_bases = sum(`_mapped_bases`),\n    total_reads = sum(`_total_reads`),\n    mapped_reads = sum(`_mapped_reads`)\n  ) %>% \n  print\nSource:   query [6,949 x 5]\nDatabase: spark connection master=local[4] app=sparklyr local=TRUE\n\n   readgroup total_bases mapped_bases total_reads mapped_reads\n       <chr>       <dbl>        <dbl>       <dbl>        <dbl>\n1  ERR015528  6983935452   5952262482    64666069     62451949\n2  ERR020229 19111863316  16893939598   210020476    199362355\n3  ERR013151  4090595256   3654598436    37875882     36786031\n4  ERR015759  1341103068   1249066562    12417621     11811715\n5  ERR019905  2264878476   2181465658    20971097     20421069\n6  ERR013138  6858917784   6220244192    63508498     60258668\n7  SRR037779  2251299740   1995203950    29622365     27061710\n8  SRR037781  2203411836   1942146896    28992261     26343528\n9  SRR043409  4294927960   3987005465    59268712     57122507\n10 SRR044230  5247820064   4803974017    69050264     66265436\n# ... with 6,939 more rows\n\n# \u3068\u308a\u3042\u3048\u305aPCA\n> genome_summarize %>% \n+   sparklyr::ml_pca(features = c(\"total_bases\", \"mapped_bases\", \"total_reads\", \"mapped_reads\"))\n* No rows dropped by 'na.omit' call\nExplained variance:\n\n         PC1          PC2          PC3          PC4 \n9.977596e-01 2.239423e-03 9.743283e-07 1.377467e-08 \n\nRotation:\n                      PC1          PC2           PC3          PC4\ntotal_bases  -0.732068499  0.681081744  0.0140674519  0.002340459\nmapped_bases -0.681151089 -0.732137051  0.0001951216 -0.002914359\ntotal_reads  -0.007463459  0.009455473 -0.7330409740 -0.680077805\nmapped_reads -0.007294029  0.003686524 -0.6800389689  0.733130416\n\n# \u3068\u308a\u3042\u3048\u305a\u3001K-means\n> genome_cls <- genome_summarize %>% \n+   sparklyr::ml_kmeans(centers = 4, features = c(\"total_bases\", \"mapped_bases\", \"total_reads\", \"mapped_reads\"))\n* No rows dropped by 'na.omit' call\n> table(fitted(object = genome_cls))\n\n   0    1    2    3 \n4801   72 1815  261 \n\n\n\u3000\u30b2\u30ce\u30e0\u306e\u77e5\u8b58\u3082\u30c7\u30fc\u30bf\u30bd\u30fc\u30b9\u306e\u7d20\u6027\u3082\u3088\u304f\u308f\u304b\u3089\u306a\u3044\u306e\u3067\u3001\u5206\u6790\u306f\u5148\u9001\u308a\u3002\n\n\u307e\u3068\u3081\n\u3000{sparklyr}\u306espark_read_csv\u3092\u7528\u3044\u308b\u3053\u3068\u3067\u3001S3\u30d0\u30b1\u30c3\u30c8\u4e0a\u306b\u3042\u308b\u30c7\u30fc\u30bf\u3092\u8aad\u307f\u8fbc\u3081\u307e\u3057\u305f\u3002\u3053\u308c\u306b\u3088\u308a\u3001S3\u30d0\u30b1\u30c3\u30c8\u306b\u3042\u308b\u30d5\u30a1\u30a4\u30eb\u3092\u304a\u624b\u8efd\u306b\u5206\u6790\u3067\u304d\u308b\u3088\u3046\u306b\u306a\u308a\u307e\u3059\u3057\u3001\u30c7\u30fc\u30bf\u691c\u8a3c\u306e\u305f\u3081\u306bRedshift\u306b\u30b3\u30d4\u30fc\u3068\u304b\u30c0\u30a6\u30f3\u30ed\u30fc\u30c9\u3057\u3066\u30d5\u30a1\u30a4\u30eb\u3092\u958b\u304f\u3068\u304b\u4e0d\u8981\u306b\u306a\u308a\u307e\u3059\u3002\n\u3000Amazon Athena\u304c\u3069\u308c\u304f\u3089\u3044\u4fbf\u5229\u304b\u5224\u65ad\u3057\u304b\u306d\u307e\u3059\u304c\u3001RStudio\u4e0a\u3067\u51e6\u7406\u3067\u304d\u307e\u3059\u306e\u3067R\u304a\u3058\u3055\u3093\u306f\u307e\u3059\u307e\u3059\u6357\u308a\u307e\u3059\u306d\u3002\n\u3000\u3061\u306a\u307f\u306b\u4eca\u56de\u3068\u540c\u3058\u3053\u3068\u306f{sparkr}\u306eread.df\u3067\u3082\u53ef\u80fd\u3067\u3059\u3002\u3069\u3061\u3089\u306e\u30d1\u30c3\u30b1\u30fc\u30b8\u304c\u3044\u3044\u304b\u60a9\u3080\u304b\u3082\u3057\u308c\u307e\u305b\u3093\u304c\u3001\u304a\u597d\u307f\u3067\u3068\u3057\u304b\u8a00\u3048\u307e\u305b\u3093\u3002\n\nSparkR (R on Spark)\nSparkR vs sparklyr\n\n\u3000\u307e\u305f\u3001Java\u95a2\u4fc2\u306e\u30e9\u30a4\u30d6\u30e9\u30ea\u3092R\u3067\u6271\u3046\u5834\u5408\u306b\u3088\u304f\u3042\u308b\u8a71\u3067\u3059\u304c\u3001\u4f7f\u3048\u308b\u30e1\u30e2\u30ea\u30b5\u30a4\u30ba\u306f\u3042\u3089\u304b\u3058\u3081\u8a2d\u5b9a\u3057\u3066\u304a\u304d\u307e\u3057\u3087\u3046\u3002\n\nsparklyr - Configuration - Package Options\nSpark Configuration - Available Properties\n\n\nSpark\u30e1\u30e2\u30ea\u5468\u308a\u306e\u8a2d\u5b9a\n# SPARK_MEM\u306f\u8a2d\u5b9a\u3057\u306a\u304f\u3066\u3082\u3044\u3044\uff1f\n# Sys.setenv(\"SPARK_MEM\" = \"64g\")\nspark_conf <- sparklyr::spark_config()\nspark_conf$spark.executor.cores <- 2\nspark_conf$spark.executor.memory <- \"4G\"\nspark_conf$spark.driver.memory <- \"12G\"\n\n\n\n\u53c2\u8003\n\nData Science in Spark with sparklyr Cheat Sheet\nTutorial: Scalable R on Spark with SparkR, sparklyr and RevoScaleR\nRunning sparklyr \u2013 RStudio\u2019s R Interface to Spark on Amazon EMR\nAWS EMR bootstrap to install RStudio Server along with sparklyr\n\n\n\u5b9f\u884c\u74b0\u5883\n\n\u5b9f\u884c\u74b0\u5883\n> devtools::session_info()\nSession info -----------------------------------------------------------------------------------------------------------------\n setting  value                       \n version  R version 3.3.2 (2016-10-31)\n system   x86_64, darwin15.6.0        \n ui       RStudio (1.0.136)           \n language (EN)                        \n collate  ja_JP.UTF-8                 \n tz       Asia/Tokyo                  \n date     2017-01-19                  \n\nPackages ---------------------------------------------------------------------------------------------------------------------\n package       * version    date       source                            \n assertthat      0.1        2013-12-06 CRAN (R 3.3.2)                    \n aws.s3        * 0.1.34     2017-01-11 local                             \n aws.signature * 0.2.6      2017-01-11 local                             \n backports       1.0.4      2016-10-24 CRAN (R 3.3.2)                    \n base64enc       0.1-3      2015-07-28 CRAN (R 3.3.2)                    \n colorspace      1.3-2      2016-12-14 CRAN (R 3.3.2)                    \n config          0.2        2016-08-02 cran (@0.2)                       \n curl            2.3        2016-11-24 cran (@2.3)                       \n DBI             0.5-1      2016-09-10 CRAN (R 3.3.2)                    \n devtools        1.12.0     2016-12-05 CRAN (R 3.3.2)                    \n digest          0.6.10     2016-08-02 CRAN (R 3.3.2)                    \n dplyr         * 0.5.0      2016-06-24 CRAN (R 3.3.2)                    \n ggfortify       0.3.0.9000 2016-12-31 Github (sinhrks/ggfortify@907a044)\n ggplot2       * 2.2.0      2016-11-11 CRAN (R 3.3.2)                    \n gridExtra       2.2.1      2016-02-29 CRAN (R 3.3.2)                    \n gtable          0.2.0      2016-02-26 CRAN (R 3.3.2)                    \n httr            1.2.1      2016-07-03 CRAN (R 3.3.2)                    \n jsonlite        1.1        2016-09-14 CRAN (R 3.3.2)                    \n lazyeval        0.2.0      2016-06-12 CRAN (R 3.3.2)                    \n magrittr        1.5        2014-11-22 CRAN (R 3.3.2)                    \n memoise         1.0.0      2016-01-29 CRAN (R 3.3.2)                    \n munsell         0.4.3      2016-02-13 CRAN (R 3.3.2)                    \n plyr            1.8.4      2016-06-08 CRAN (R 3.3.2)                    \n purrr         * 0.2.2      2016-06-18 CRAN (R 3.3.2)                    \n R6              2.2.0      2016-10-05 CRAN (R 3.3.2)                    \n rappdirs        0.3.1      2016-03-28 CRAN (R 3.3.2)                    \n Rcpp            0.12.8     2016-11-17 CRAN (R 3.3.2)                    \n readr         * 1.0.0      2016-08-03 CRAN (R 3.3.2)                    \n RevoUtils       10.0.2     2016-11-22 local                             \n rprojroot       1.1        2016-10-29 CRAN (R 3.3.2)                    \n scales          0.4.1      2016-11-09 CRAN (R 3.3.2)                    \n sparklyr        0.5.1      2016-12-19 CRAN (R 3.3.2)                    \n tibble        * 1.2        2016-08-26 CRAN (R 3.3.2)                    \n tidyr         * 0.6.0      2016-08-12 CRAN (R 3.3.2)                    \n tidyverse     * 1.0.0      2016-09-09 CRAN (R 3.3.2)                    \n withr           1.0.2      2016-06-20 CRAN (R 3.3.2)                    \n xml2            1.1.0      2017-01-07 CRAN (R 3.3.2)                    \n yaml            2.1.14     2016-11-12 CRAN (R 3.3.2)         \n\n\n# \u6982\u8981\n\u3000\u5c11\u3057\u524d\u306b{sparklyr}\u3068\u3044\u3046R\u304b\u3089Spark\u3092\u4f7f\u3046\u30d1\u30c3\u30b1\u30fc\u30b8\u304cRStudio\u793e\u304b\u3089\u516c\u958b\u3055\u308c\u307e\u3057\u305f\u3002\u3053\u306e{sparklyr}\u306b\u306fS3\u4e0a\u306e\u30d5\u30a1\u30a4\u30eb\u3082\u8aad\u307f\u8fbc\u3081\u308b`spark_read_csv`\u3068\u3044\u3046\u95a2\u6570\u304c\u63d0\u4f9b\u3055\u308c\u3066\u304a\u308a\u3001[Amazon Athena](https://aws.amazon.com/jp/athena/)\u304c\u6771\u4eac\u30ea\u30fc\u30b8\u30e7\u30f3\u306b\u6765\u308b\u307e\u3067\u4ee3\u308f\u308a\u306b\u4f7f\u3048\u306a\u3044\u304b\u3068\u8a66\u3057\u3066\u307f\u307e\u3057\u305f\u3002\n\u3000\u4eca\u56de\u306f[AWS Public Datasets](https://aws.amazon.com/jp/datasets/)\u306b\u3042\u308b\u30c7\u30fc\u30bf\u30bb\u30c3\u30c8\u3092\u8aad\u307f\u8fbc\u3093\u3067\u307f\u307e\u3057\u305f\u304c\u3001\u5165\u529b\u5bfe\u8c61\u306eS3\u30d0\u30b1\u30c3\u30c8\u306b\u6a29\u9650\u304c\u3042\u308c\u3070\u540c\u3058\u3088\u3046\u306b\u6271\u3048\u308b\u3068\u601d\u3044\u307e\u3059\u3002\n\n- [sparklyr: R interface for Apache Spark](http://spark.rstudio.com)\n\n\n# \u4e8b\u524d\u6e96\u5099\n\u3000{sparklyr}\u306e\u6d3b\u7528\u306b\u3042\u305f\u3063\u3066\u5bfe\u8c61\u30d1\u30c3\u30b1\u30fc\u30b8\u306e\u30a4\u30f3\u30b9\u30c8\u30fc\u30eb\u3068\u3001Spark\u74b0\u5883\u306e\u8a2d\u5b9a\u304c\u5fc5\u8981\u306b\u306a\u308a\u307e\u3059\u3002\u5f8c\u8005\u306b\u3064\u3044\u3066\u306f{sparklyr}\u306b\u95a2\u6570\u304c\u7528\u610f\u3055\u308c\u3066\u3044\u308b\u306e\u3067\u3001\u4eca\u56de\u306f\u305d\u308c\u3092\u4f7f\u7528\u3057\u3066\u30ed\u30fc\u30ab\u30eb\u306b\u74b0\u5883\u69cb\u7bc9\u3057\u307e\u3059\u3002\n\u3000\u4eca\u56de\u306f\u8a66\u3057\u307e\u305b\u3093\u304c\u3001\u30ed\u30fc\u30ab\u30eb\u3067\u306f\u306a\u304fAWS\u4e0a\u306a\u3069\u306b\u5225\u69cb\u7bc9\u3057\u305fSpark\u74b0\u5883\u3082\u5229\u7528\u3067\u304d\u307e\u3059\u3002\u3053\u306e\u5834\u5408\u3001\u30bf\u30b9\u30af\u30ce\u30fc\u30c9\u3092\u30b9\u30dd\u30c3\u30c8\u30a4\u30f3\u30b9\u30bf\u30f3\u30b9\u3067\u69cb\u6210\u3059\u308b\u306a\u3069\u3067\u6bd4\u8f03\u7684\u5b89\u4fa1\u306b\u5927\u898f\u6a21\u30c7\u30fc\u30bf\u51e6\u7406\u74b0\u5883\u306e\u7528\u610f\u304c\u53ef\u80fd\u306b\u306a\u308a\u307e\u3059\u3002\n\u3000\u307e\u305f\u3001[AWS CLI(\u30b3\u30de\u30f3\u30c9\u30e9\u30a4\u30f3\u30a4\u30f3\u30bf\u30fc\u30d5\u30a7\u30a4\u30b9)](https://aws.amazon.com/jp/cli/)\u3092\u7528\u3044\u305f\u30d1\u30c3\u30b1\u30fc\u30b8\u3067S3\u306b\u30a2\u30af\u30bb\u30b9\u3057\u305f\u308a\u3057\u307e\u3059\u306e\u3067\u3001\u4e00\u7dd2\u306b\u30a4\u30f3\u30b9\u30c8\u30fc\u30eb\u3057\u307e\u3059\u3002\n\n- [AWS Documentation \u00bb Amazon Elastic MapReduce Documentation \u00bb \u30ea\u30ea\u30fc\u30b9\u30ac\u30a4\u30c9 \u00bb Apache Spark](http://docs.aws.amazon.com/ja_jp/ElasticMapReduce/latest/ReleaseGuide/emr-spark.html)\n- [Cluster Deployment](http://spark.rstudio.com/deployment.html#cluster_deployment)\n\n\n## Spark\u74b0\u5883\u8a2d\u5b9a\n\u3000\u524d\u8ff0\u306e\u901a\u308a\u3001{sparklyr}\u306e\u95a2\u6570\u3067\u30ed\u30fc\u30ab\u30eb\u306bSpark/Hadoop\u306e\u74b0\u5883\u3092\u69cb\u7bc9\u3057\u307e\u3059\u3002\u305f\u3060\u3057\u3001{sparklyr}\u306e\u30d0\u30fc\u30b8\u30e7\u30f3\u6b21\u7b2c\u3067\u5bfe\u5fdc\u3057\u3066\u3044\u306a\u3044Spark/Hadoop\u306e\u30d0\u30fc\u30b8\u30e7\u30f3\u304c\u3042\u308a\u307e\u3059\u306e\u3067\u3054\u6ce8\u610f\u304f\u3060\u3055\u3044\u3002\n\n```r:Spark\u74b0\u5883\u8a2d\u5b9a\n# {sparklyr}\u306e\u30a4\u30f3\u30b9\u30c8\u30fc\u30eb\n# \u518d\u73fe\u3067\u304d\u308b\u3088\u3046\u306brepos\u5f15\u6570\u306bMicrosoft R Open\u306e\u30b9\u30ca\u30c3\u30d7\u30b7\u30e7\u30c3\u30c8\u30ea\u30dd\u30b8\u30c8\u30ea\u3092\u6307\u5b9a\n# \u7279\u306b\u652f\u969c\u304c\u306a\u304f\u30a4\u30f3\u30b9\u30c8\u30fc\u30eb\u3055\u308c\u308b\u306f\u305a\u306a\u306e\u3067\u3001\u5b9f\u884c\u5c65\u6b74\u306f\u7701\u7565\ninstall.packages(pkgs = \"sparklyr\", repos = \"https://mran.microsoft.com/snapshot/2017-01-11/\")\n\n\n# \u30a4\u30f3\u30b9\u30c8\u30fc\u30eb\u3067\u304d\u305f\u3089\u30d1\u30c3\u30b1\u30fc\u30b8\u8aad\u307f\u8fbc\u307f\nlibrary(sparklyr)\nlibrary(tidyverse)\n\n# \u30ed\u30fc\u30ab\u30eb\u4e0a\u306bSpark\u3068Hadoop\u74b0\u5883\u304c\u3042\u308b\u304b\u78ba\u8a8d\n# \u307e\u3060\u69cb\u7bc9\u3057\u3066\u3044\u306a\u3044\u306e\u3067\u3001\u7a7a\u306e\u30c7\u30fc\u30bf\u30d5\u30ec\u30fc\u30e0\u304c\u8fd4\u3063\u3066\u304f\u308b\n> sparklyr::spark_installed_versions()\n[1] spark  hadoop dir   \n<0 \u884c> (\u307e\u305f\u306f\u9577\u3055 0 \u306e row.names) \n\n# {sparklyr}\u3067\u7528\u610f\u3055\u308c\u3066\u3044\u308b\u95a2\u6570\u3067\u30a4\u30f3\u30b9\u30c8\u30fc\u30eb\u3067\u304d\u308b\u30d0\u30fc\u30b8\u30e7\u30f3\u306e\u5019\u88dc\u3092\u8868\u793a\n# \u305f\u3060\u3057\u3001\u30a4\u30f3\u30b9\u30c8\u30fc\u30eb\u3067\u304d\u308b\u30d0\u30fc\u30b8\u30e7\u30f3\u3067\u3082{sparklyr}\u3067\u306f\u5229\u7528\u3067\u304d\u306a\u3044\u30d0\u30fc\u30b8\u30e7\u30f3\u3082\u8868\u793a\u3055\u308c\u308b\n> sparklyr::spark_available_versions()\nspark hadoop                                                   install\n5  1.6.2    2.6  spark_install(version = \"1.6.2\", hadoop_version = \"2.6\")\n6  1.6.2    2.4  spark_install(version = \"1.6.2\", hadoop_version = \"2.4\")\n7  1.6.2    2.3  spark_install(version = \"1.6.2\", hadoop_version = \"2.3\")\n8  1.6.2   cdh4 spark_install(version = \"1.6.2\", hadoop_version = \"cdh4\")\n9  1.6.1    2.6  spark_install(version = \"1.6.1\", hadoop_version = \"2.6\")\n10 1.6.1    2.4  spark_install(version = \"1.6.1\", hadoop_version = \"2.4\")\n11 1.6.1    2.3  spark_install(version = \"1.6.1\", hadoop_version = \"2.3\")\n12 1.6.1   cdh4 spark_install(version = \"1.6.1\", hadoop_version = \"cdh4\")\n13 1.6.0    2.6  spark_install(version = \"1.6.0\", hadoop_version = \"2.6\")\n14 1.6.0    2.4  spark_install(version = \"1.6.0\", hadoop_version = \"2.4\")\n15 1.6.0    2.3  spark_install(version = \"1.6.0\", hadoop_version = \"2.3\")\n16 1.6.0   cdh4 spark_install(version = \"1.6.0\", hadoop_version = \"cdh4\")\n17 2.0.0    2.7  spark_install(version = \"2.0.0\", hadoop_version = \"2.7\")\n18 2.0.0    2.6  spark_install(version = \"2.0.0\", hadoop_version = \"2.6\")\n19 2.0.0    2.4  spark_install(version = \"2.0.0\", hadoop_version = \"2.4\")\n20 2.0.0    2.3  spark_install(version = \"2.0.0\", hadoop_version = \"2.3\")\n21 2.0.1    2.7  spark_install(version = \"2.0.1\", hadoop_version = \"2.7\")\n22 2.0.1    2.6  spark_install(version = \"2.0.1\", hadoop_version = \"2.6\")\n23 2.0.1    2.4  spark_install(version = \"2.0.1\", hadoop_version = \"2.4\")\n24 2.0.1    2.3  spark_install(version = \"2.0.1\", hadoop_version = \"2.3\")\n25 2.0.2    2.7  spark_install(version = \"2.0.2\", hadoop_version = \"2.7\")\n26 2.0.2    2.6  spark_install(version = \"2.0.2\", hadoop_version = \"2.6\")\n27 2.0.2    2.4  spark_install(version = \"2.0.2\", hadoop_version = \"2.4\")\n28 2.0.2    2.3  spark_install(version = \"2.0.2\", hadoop_version = \"2.3\")\n29 2.1.0    2.7  spark_install(version = \"2.1.0\", hadoop_version = \"2.7\")\n30 2.1.0    2.6  spark_install(version = \"2.1.0\", hadoop_version = \"2.6\")\n31 2.1.0    2.4  spark_install(version = \"2.1.0\", hadoop_version = \"2.4\")\n32 2.1.0    2.3  spark_install(version = \"2.1.0\", hadoop_version = \"2.3\")\n\n# \u4e0a\u8a18\u306e\u5019\u88dc\u306e\u3046\u3061\u3001\u300cversion = \"2.1.0\", hadoop_version = \"2.7\"\u300d\u3092\u6307\u5b9a\u3057\u3066\u30a4\u30f3\u30b9\u30c8\u30fc\u30eb\n> sparklyr::spark_install(version = \"2.1.0\", hadoop_version = \"2.7\")\nInstalling Spark 2.1.0 for Hadoop 2.7 or later.\nDownloading from:\n  - 'https://d3kbcqa49mib13.cloudfront.net/spark-2.1.0-bin-hadoop2.7.tgz'\nInstalling to:\n  - '~/Library/Caches/spark/spark-2.1.0-bin-hadoop2.7'\nURL 'https://d3kbcqa49mib13.cloudfront.net/spark-2.1.0-bin-hadoop2.7.tgz' \u3092\u8a66\u3057\u3066\u3044\u307e\u3059 \nContent type 'application/x-tar' length 195636829 bytes (186.6 MB)\n==================================================\n  downloaded 186.6 MB\n\nInstallation complete.\n\n\n# \u30ed\u30fc\u30ab\u30eb\u4e0a\u306bSpark\u3068Hadoop\u74b0\u5883\u304c\u3042\u308b\u304b\u3001\u518d\u5ea6\u78ba\u8a8d\n# \u30a4\u30f3\u30b9\u30c8\u30fc\u30eb\u3055\u308c\u305f\u30d0\u30fc\u30b8\u30e7\u30f3\u304b\u3089\u306a\u308b\u30c7\u30fc\u30bf\u30d5\u30ec\u30fc\u30e0\u304c\u8fd4\u3063\u3066\u304f\u308b\n> sparklyr::spark_installed_versions()\nspark hadoop                       dir\n1 2.1.0    2.7 spark-2.1.0-bin-hadoop2.7\n\n# \u8a66\u3057\u306b\u63a5\u7d9a\u3059\u308b\u3068\u73fe\u30d0\u30fc\u30b8\u30e7\u30f3(0.5.1)\u3067\u306fSpark 2.1.0\u306b\u306f\u5bfe\u5fdc\u3057\u3066\u3044\u306a\u3044\n> sc <- sparklyr::spark_connect(master = \"local\")\nsparklyr does not currently support Spark version: 2.1.0\n\n# \u30a4\u30f3\u30b9\u30c8\u30fc\u30eb\u3057\u305f\u30d0\u30fc\u30b8\u30e7\u30f3\u3092\u524a\u9664\n> sparklyr::spark_uninstall(version = \"2.1.0\", hadoop_version = \"2.7\")\nspark-2.1.0-bin-hadoop2.7 successfully uninstalled.\n\n# \u6539\u3081\u3066\u300cversion = \"2.1.0\", hadoop_version = \"2.7\"\u300d\u3092\u6307\u5b9a\u3057\u3066\u30a4\u30f3\u30b9\u30c8\u30fc\u30eb\n> sparklyr::spark_install(version = \"2.0.2\", hadoop_version = \"2.7\")\nInstalling Spark 2.0.2 for Hadoop 2.7 or later.\nDownloading from:\n  - 'https://d3kbcqa49mib13.cloudfront.net/spark-2.0.2-bin-hadoop2.7.tgz'\nInstalling to:\n  - '~/Library/Caches/spark/spark-2.0.2-bin-hadoop2.7'\nURL 'https://d3kbcqa49mib13.cloudfront.net/spark-2.0.2-bin-hadoop2.7.tgz' \u3092\u8a66\u3057\u3066\u3044\u307e\u3059 \nContent type 'application/x-tar' length 187426587 bytes (178.7 MB)\n==================================================\n  downloaded 178.7 MB\n\nInstallation complete.\n\n\n# \u78ba\u8a8d\n> sparklyr::spark_installed_versions()\nspark hadoop                       dir\n1 2.0.2    2.7 spark-2.0.2-bin-hadoop2.7\n\n# \u63a5\u7d9a\u3067\u304d\u3066\u3082\u4f55\u3082\u8fd4\u3055\u306a\u3044\uff081\u7cfb\u4ee5\u964d\u306eRStudio\u3067\u306f\u53f3\u4e0a\u306eSpark\u30d1\u30cd\u30eb\u304c\u5207\u308a\u66ff\u308f\u308b\uff09\nsc <- sparklyr::spark_connect(master = \"local\")\n# \u63a5\u7d9a\u3055\u308c\u3066\u3044\u308b\u304b\u78ba\u8a8d\n> sparklyr::spark_connection_is_open(sc = sc)\n[1] TRUE\n\n# \u63a5\u7d9a\u3092\u5207\u3063\u3066\u518d\u78ba\u8a8d\nsparklyr::spark_disconnect(sc = sc)\n> sparklyr::spark_connection_is_open(sc = sc)\n[1] FALSE\n```\n\n## AWS CLI\u306e\u30a4\u30f3\u30b9\u30c8\u30fc\u30eb\n\u3000EC2\u3067\u3042\u308c\u3070AWS CLI\u304c\u4e8b\u524d\u306b\u30a4\u30f3\u30b9\u30c8\u30fc\u30eb\u3055\u308c\u3066\u3044\u307e\u3059\u304c\u3001\u81ea\u5206\u306eMac\u74b0\u5883\u3067\u306f\u7528\u610f\u3055\u308c\u3066\u3044\u306a\u3044\u306e\u3067\u5225\u9014\u30a4\u30f3\u30b9\u30c8\u30fc\u30eb\u3057\u307e\u3059\u3002\u8abf\u3079\u3066\u307f\u308b\u3068Homebrew\u3067\u30a4\u30f3\u30b9\u30c8\u30fc\u30eb\u3067\u304d\u308b\u3088\u3046\u306a\u306e\u3067\u3001\u4eca\u56de\u306f\u305d\u3061\u3089\u3067\u6e96\u5099\u3057\u307e\u3057\u305f\u3002\n\n```shell:AWS_CLI\n# \u4e00\u90e8\u306e\u307f\u8868\u793a\n$ brew info awscli\nawscli: stable 1.11.36 (bottled), HEAD\nOfficial Amazon AWS command-line interface\nhttps://aws.amazon.com/cli/\n\n# \u30a4\u30f3\u30b9\u30c8\u30fc\u30eb\uff08\u5c65\u6b74\u306f\u7701\u7565\uff09\n$ brew install awscli\n\n# \u30a4\u30f3\u30b9\u30c8\u30fc\u30eb\u5f8c\u306baws configure\u3067\u30a2\u30af\u30bb\u30b9\u30ad\u30fc\u3001\u30b7\u30fc\u30af\u30ec\u30c3\u30c8\u30a2\u30af\u30bb\u30b9\u30ad\u30fc\u3001\u30c7\u30d5\u30a9\u30eb\u30c8\u30ea\u30fc\u30b8\u30e7\u30f3\u3092\u81ea\u524d\u306e\u3082\u306e\u3092\u8a2d\u5b9a\n# aws_pdataset\u3068\u3044\u3046\u540d\u524d\u306eprofile\u3092\u4f5c\u3063\u3066\u53c2\u7167\u3067\u304d\u308b\u3088\u3046\u306b\u3057\u3066\u304a\u304f\n$ aws configure --profile aws_pdataset\n```\n\n# AWS Public Datasets\u306e\u30d0\u30b1\u30c3\u30c8\u69cb\u9020\u3092\u78ba\u8a8d\n\u3000AWS Public Datasets\u306b\u3042\u308b\u30c7\u30fc\u30bf\u30bb\u30c3\u30c8\u306e\u30d0\u30b1\u30c3\u30c8\u69cb\u9020\u3092\u8abf\u3079\u308b\u305f\u3081\u3001\u4e0b\u8a18\u306e\u30d1\u30c3\u30b1\u30fc\u30b8\u3092\u5229\u7528\u3057\u3066S3\u306b\u30a2\u30af\u30bb\u30b9\u3057\u3066\u78ba\u8a8d\u3057\u307e\u3057\u305f\u3002\u524d\u8ff0\u306e\u3068\u304a\u308a\u3001\u3053\u3061\u3089\u306e\u30d1\u30c3\u30b1\u30fc\u30b8\u3067\u306fAWS CLI\u3092\u5229\u7528\u3057\u3066\u3044\u307e\u3059\u3002\n\u3000\n- [Amazon Simple Storage Service (S3) API Client](https://github.com/cloudyr/aws.s3)\n\n```r:S3\u30d0\u30b1\u30c3\u30c8\u78ba\u8a8d\nlibrary(aws.signature)\nlibrary(aws.s3)\n\n# aws configure\u3067\u30a2\u30af\u30bb\u30b9\u30ad\u30fc\u306a\u3069\u3092\u8a2d\u5b9a\u3057\u3066\u3044\u306a\u3044\u5834\u5408\u306f\u4e0b\u8a18\u306e\u3088\u3046\u306b\u74b0\u5883\u5909\u6570\u3092\u30bb\u30c3\u30c8\u3059\u308b\u5fc5\u8981\u304c\u3042\u308b\n# \u30bb\u30ad\u30e5\u30ea\u30c6\u30a3\u89b3\u70b9\u304b\u3089\u5b9f\u30ad\u30fc\u306f\u4f0f\u305b\u3066\u3044\u307e\u3059\nSys.setenv(AWS_ACCESS_KEY_ID = \"***************\")\nSys.setenv(AWS_SECRET_ACCESS_KEY = \"***************\")\nSys.setenv(AWS_DEFAULT_REGION = \"us-east-1\")\n\n# profile\u540d\u3092\u6307\u5b9a\u3057\u3066\u3001aws configure\u3067\u8a2d\u5b9a\u3057\u305f\u30a2\u30af\u30bb\u30b9\u30ad\u30fc\u3084\u30b7\u30fc\u30af\u30ec\u30c3\u30c8\u30a2\u30af\u30bb\u30b9\u30ad\u30fc\u306a\u3069\u3092\u8aad\u307f\u8fbc\u307f\naws.signature::use_credentials(profile = \"aws_pdataset\")\n\n# \"1000genomes\"\u306e\u30c7\u30fc\u30bf\u30bb\u30c3\u30c8\u306e\u30d0\u30b1\u30c3\u30c8\u69cb\u9020\u3092\u95b2\u89a7\n# \u3053\u3053\u3067\u306f\"alignment_indices/2012\"\u304c\u4ed8\u304f\u3082\u306e\u309215\u500b\u8868\u793a\n> genomes <- aws.s3::get_bucket(bucket = \"1000genomes\", prefix = \"alignment_indices/2012\", max = 15, parse_response = TRUE)\nBucket: 1000genomes \n\n$Contents\nKey:            alignment_indices/20120522.alignment.chr20_cram.index \nLastModified:   2013-05-29T17:35:36.000Z \nETag:           \"ea7863d5db6acc3b6ca997bfa6d2c6c9\" \nSize (B):       270984 \nOwner:          1000genomes \nStorage class:  STANDARD \n\n$Contents\nKey:            alignment_indices/20120522.alignment.chr20_lossy_cram.index \nLastModified:   2013-05-27T16:33:30.000Z \nETag:           \"aeae5be28807b89f67ebdfe85e2fd676\" \nSize (B):       284256 \nOwner:          1000genomes \nStorage class:  STANDARD \n\n$Contents\nKey:            alignment_indices/20120522.alignment.index \nLastModified:   2013-06-03T18:15:51.000Z \nETag:           \"82d9523c2a48d18185f6ba905c306d7e\" \nSize (B):       1561723 \nOwner:          1000genomes \nStorage class:  STANDARD \n\n$Contents\nKey:            alignment_indices/20120522.alignment.index.bas.gz \nLastModified:   2013-06-03T18:14:53.000Z \nETag:           \"275801bf228b1ff33664dc0d538e320f\" \nSize (B):       1233947 \nOwner:          1000genomes \nStorage class:  STANDARD \n\n$Contents\nKey:            alignment_indices/20120522.alignment.mapped.binned_csra.index \nLastModified:   2014-09-02T22:15:39.000Z \nETag:           \"ab60350c0873f9527ce1347541027a8e\" \nSize (B):       131623 \nOwner:          1000genomes \nStorage class:  STANDARD \n\n$Contents\nKey:            alignment_indices/20120522.exome.alignment.chr20_cram.index \nLastModified:   2013-05-29T08:43:56.000Z \nETag:           \"7cf05ef22b7d2c9b5e64bf5cb9f03916\" \nSize (B):       215312 \nOwner:          1000genomes \nStorage class:  STANDARD \n\n$Contents\nKey:            alignment_indices/20120522.exome.alignment.chr20_lossy_cram.index \nLastModified:   2014-09-03T04:15:33.000Z \nETag:           \"fce87b37792304ab79e9584e224bf1b8\" \nSize (B):       225944 \nOwner:          1000genomes \nStorage class:  STANDARD \n\n$Contents\nKey:            alignment_indices/20120522.exome.alignment.index \nLastModified:   2013-06-03T18:14:54.000Z \nETag:           \"83ff92283546ad85101b80cf9e04e10b\" \nSize (B):       1240451 \nOwner:          1000genomes \nStorage class:  STANDARD \n\n$Contents\nKey:            alignment_indices/20120522.exome.alignment.index.HsMetrics.gz \nLastModified:   2014-09-03T03:54:02.000Z \nETag:           \"6742b3655a3cd388cc1ec3406b61f835\" \nSize (B):       118484 \nOwner:          1000genomes \nStorage class:  STANDARD \n\n$Contents\nKey:            alignment_indices/20120522.exome.alignment.index.HsMetrics.stats \nLastModified:   2013-05-28T11:39:20.000Z \nETag:           \"6757ae9b582c46174b764f4efe9097a6\" \nSize (B):       376 \nOwner:          1000genomes \nStorage class:  STANDARD \n\n$Contents\nKey:            alignment_indices/20120522.exome.alignment.index.bas.gz \nLastModified:   2013-06-03T18:15:57.000Z \nETag:           \"a7e71fab455a9f9634e0b4ec2c208658\" \nSize (B):       1617379 \nOwner:          1000genomes \nStorage class:  STANDARD \n\n$Contents\nKey:            alignment_indices/20120522.exome.alignment.mapped.binned_csra.index \nLastModified:   2014-09-02T12:22:40.000Z \nETag:           \"3b77f700a59c1f27b0f04a05bda4fc63\" \nSize (B):       104557 \nOwner:          1000genomes \nStorage class:  STANDARD \n\n$Contents\nKey:            alignment_indices/20120522_20111114.alignment_stats.exome.csv \nLastModified:   2013-06-03T18:08:02.000Z \nETag:           \"e4149d8e97a324892571fad80e0c6a6e\" \nSize (B):       1344 \nOwner:          1000genomes \nStorage class:  STANDARD \n\n$Contents\nKey:            alignment_indices/20120522_20111114.alignment_stats.low_coverage.csv \nLastModified:   2013-06-03T18:08:02.000Z \nETag:           \"b99c5dc76cd28a83cee962ecb33e6235\" \nSize (B):       1500 \nOwner:          1000genomes \nStorage class:  STANDARD \n\n$Contents\nKey:            alignment_indices/20121211.alignment.index \nLastModified:   2014-09-02T08:48:22.000Z \nETag:           \"9668dcf90d6d149ae612581cf404d7a1\" \nSize (B):       2332675 \nOwner:          1000genomes \nStorage class:  STANDARD \n```\n\n\u3000\u3053\u3053\u3067\u306f\u6b21\u306e\u3075\u305f\u3064\u306e\u30d5\u30a1\u30a4\u30eb\u3092\u8aad\u307f\u8fbc\u3093\u3067\u307f\u307e\u3059\u3002\n\n- alignment_indices/20120522.alignment.index  \n- alignment_indices/20120522.alignment.index.bas.gz\n\n\u3000\u30c7\u30fc\u30bf\u30d5\u30a9\u30fc\u30de\u30c3\u30c8\u306f\u4e0b\u8a18\u3092\u53c2\u8003\u307e\u3067\u306b\u3002\n- [IGSR: The International Genome Sample Resource - Data file formats](http://www.internationalgenome.org/formats)\n\n\n# AWS Public Datasets\u306b\u3042\u308b\u30d5\u30a1\u30a4\u30eb\u3092\u8aad\u307f\u8fbc\u3080\n\n\u3000{sparklyr}\u3067\u306fS3\u306b\u3042\u308b\u30d5\u30a1\u30a4\u30eb\u3092\u8aad\u307f\u8fbc\u3081\u308b\u95a2\u6570\u304c\u5b9a\u7fa9\u3055\u308c\u3066\u3044\u307e\u3059\u304c\u3001\u30c7\u30d5\u30a9\u30eb\u30c8\u306e\u8a2d\u5b9a\u306e\u307e\u307e\u3067\u306f\u30ed\u30fc\u30ab\u30eb\u307e\u305f\u306fEC2\u304b\u3089\u306f\u8aad\u307f\u8fbc\u3081\u307e\u305b\u3093\uff08EMR\u304b\u3089\u3060\u3068\u53ef\u80fd\uff1f\uff09\u3002\n\u3000\u3053\u306e\u4ef6\u306b\u3064\u3044\u3066\u306f\u3001\u4e0b\u8a18\u306e\u901a\u308a\u30d8\u30eb\u30d7\u30c9\u30ad\u30e5\u30e1\u30f3\u30c8\u306b\u306f\u8a18\u8ff0\u304c\u3042\u308a\u307e\u305b\u3093\u3002\n\n\u3000\u300espark_read_csv {sparklyr} - R Documentation\u300f\u3088\u308a\n> You can read data from HDFS (hdfs://), S3 (s3n://), as well as the local file system (file://).\n\n```r:\u30c7\u30d5\u30a9\u30eb\u30c8\u8a2d\u5b9a\u306e\u307e\u307e\nsc <- sparklyr::spark_connect(master = \"local\")\n> genome_alignment_indices <- sparklyr::spark_read_csv(\n+     sc = sc, name = \"alignment_indices\",\n+     path = \"s3a://1000genomes/20120522.alignment.index\",\n+     infer_schema = TRUE, header = TRUE, delimiter = \"\\t\"\n+ )\n \u30a8\u30e9\u30fc: java.lang.RuntimeException: java.lang.ClassNotFoundException: Class org.apache.hadoop.fs.s3a.S3AFileSystem not found\n\tat org.apache.hadoop.conf.Configuration.getClass(Configuration.java:2195)\n\tat org.apache.hadoop.fs.FileSystem.getFileSystemClass(FileSystem.java:2654)\n\tat org.apache.hadoop.fs.FileSystem.createFileSystem(FileSystem.java:2667)\n\tat org.apache.hadoop.fs.FileSystem.access$200(FileSystem.java:94)\n\tat org.apache.hadoop.fs.FileSystem$Cache.getInternal(FileSystem.java:2703)\n\tat org.apache.hadoop.fs.FileSystem$Cache.get(FileSystem.java:2685)\n\tat org.apache.hadoop.fs.FileSystem.get(FileSystem.java:373)\n\tat org.apache.hadoop.fs.Path.getFileSystem(Path.java:295)\n\tat org.apache.spark.sql.execution.datasources.DataSource$$anonfun$12.apply(DataSource.scala:381)\n\tat org.apache.spark.sql.execution.datasources.DataSource$$anonfun$12.apply(DataSource.scala:379)\n\tat scala.collection.TraversableLike$$anonfun$flatMap$1.apply(TraversableLike.scala:241)\n\tat scala.collection.TraversableLike$$anonfun$flatMap$1.apply(TraversableLike.scala:241)\n\tat scala.collection.immutable.List.foreach(List.scala:381)\n\tat scala.collection.TraversableLike$class.flatMap(TraversableLike.scala:241)\n\tat scala.collection.immutable.List.flatMap(List.scala:344)\n\tat org.apache.spark.sql.execution.datasources.DataSource.resolveRelation(DataSource.scala:379)\n\tat org.apache.spark.sql.DataFrameReader.load(DataFrameReader.scala:149)\n\tat org.apache.spark.sql.DataFrameReader.csv(DataFrameReader.scala:413)\n\tat org.apache.spark.sql.DataFrameReader.csv(DataFrameReader.scala:349)\n\tat sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n\tat sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\n\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n\tat java.lang.reflect.Method.invoke(Method.java:497)\n\tat sparklyr.Invoke$.invoke(invoke.scala:94)\n\tat sparklyr.StreamHandler$.handleMethodCall(stream.scala:89)\n\tat sparklyr.StreamHandler$.read(stream.scala:55)\n\tat sparklyr.BackendHandler.channelRead0(handler.scala:49)\n\tat sparklyr.BackendHandler.channelRead0(handler.scala:14)\n\tat io.netty.channel.SimpleChannelInboundHandler.channelRead(SimpleChannelInboundHandler.java:105)\n\tat io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:308)\n\tat io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:294)\n\tat io.netty.handler.codec.MessageToMessageDecoder.channelRead(MessageToMessageDecoder.java:103)\n\tat io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:308)\n\tat io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:294)\n\tat io.netty.handler.codec.ByteToMessageDecoder.channelRead(ByteToMessageDecoder.java:244)\n\tat io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:308)\n\tat io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:294)\n\tat io.netty.channel.DefaultChannelPipeline.fireChannelRead(DefaultChannelPipeline.java:846)\n\tat io.netty.channel.nio.AbstractNioByteChannel$NioByteUnsafe.read(AbstractNioByteChannel.java:131)\n\tat io.netty.channel.nio.NioEventLoop.processSelectedKey(NioEventLoop.java:511)\n\tat io.netty.channel.nio.NioEventLoop.processSelectedKeysOptimized(NioEventLoop.java:468)\n\tat io.netty.channel.nio.NioEventLoop.processSelectedKeys(NioEventLoop.java:382)\n\tat io.netty.channel.nio.NioEventLoop.run(NioEventLoop.java:354)\n\tat io.netty.util.concurrent.SingleThreadEventExecutor$2.run(SingleThreadEventExecutor.java:111)\n\tat io.netty.util.concurrent.DefaultThreadFactory$DefaultRunnableDecorator.run(DefaultThreadFactory.java:137)\n\tat java.lang.Thread.run(Thread.java:745)\nCaused by: java.lang.ClassNotFoundException: Class org.apache.hadoop.fs.s3a.S3AFileSystem not found\n\tat org.apache.hadoop.conf.Configuration.getClassByName(Configuration.java:2101)\n\tat org.apache.hadoop.conf.Configuration.getClass(Configuration.java:2193)\n\t... 45 more\n\n\n# \u63a5\u7d9a\u3092\u5207\u308b\nsparklyr::spark_disconnect(sc = sc)\n```\n\n\u3000\u3053\u308c\u306b\u5bfe\u5fdc\u3059\u308b\u306b\u306f\u3001\u63a5\u7d9a\u6642\u306e\u8a2d\u5b9a\u306bhadoop-aws\u3092\u30c7\u30d5\u30a9\u30eb\u30c8\u30d1\u30c3\u30b1\u30fc\u30b8\u3068\u3057\u3066\u8ffd\u52a0\u3057\u3066\u304a\u304f\u5fc5\u8981\u304c\u3042\u308a\u307e\u3059\u3002\u3053\u308c\u3092R\u4e0a\u3067\u3059\u308b\u306b\u306f`spark_config`\u3092\u4f7f\u3044\u307e\u3059\u3002\n\n- [Hadoop-AWS module: Integration with Amazon Web Services](https://hadoop.apache.org/docs/stable/hadoop-aws/tools/hadoop-aws/index.html)\n- [\u30ed\u30fc\u30ab\u30eb\u306eSpark\u3067S3\u306e\u30d5\u30a1\u30a4\u30eb\u3092\u6271\u3046](http://qiita.com/uryyyyyyy/items/b1f7a9fea928e1003602)\n\n\n```r:\u8a2d\u5b9a\u8ffd\u52a0\n# sparklyr::spark_config\u3067\u30c7\u30d5\u30a9\u30eb\u30c8\u8a2d\u5b9a\u30d5\u30a1\u30a4\u30eb\u3092\u8aad\u307f\u8fbc\u307f\nspark_config <- sparklyr::spark_config()\n\n# \u30c7\u30d5\u30a9\u30eb\u30c8\u30d1\u30c3\u30b1\u30fc\u30b8\u306bhadoop-aws\u3092\u8ffd\u52a0\nspark_config$sparklyr.defaultPackages <- append(\n  x = spark_config$sparklyr.defaultPackages, \"org.apache.hadoop:hadoop-aws:2.7.3\"\n)\n# \u30a4\u30f3\u30b9\u30c8\u30fc\u30eb\u72b6\u6cc1\u306b\u3088\u3063\u3066\u30d0\u30fc\u30b8\u30e7\u30f3\u306f\u7570\u306a\u308a\u305d\u3046\n> list.files(path = \"~/.ivy2/cache/org.apache.hadoop/hadoop-aws/jars/\")\n[1] \"hadoop-aws-2.7.2.jar\" \"hadoop-aws-2.7.3.jar\"\n\n\n# config\u5f15\u6570\u306b\u30bb\u30c3\u30c8\u3057\u305f\u8a2d\u5b9a\u3092\u6e21\u3057\u3066\u518d\u5ea6\u63a5\u7d9a\nsc <- sparklyr::spark_connect(master = \"local\", config = spark_config)\n> spark_connection_is_open(sc = sc)\n[1] TRUE\n\n# \u30a8\u30e9\u30fc\u304c\u306a\u304f\u7d50\u679c\u304c\u5f97\u3089\u308c\u308b\n# infer_schema\u5f15\u6570\u3092TRUE\u306b\u3057\u3066\u304a\u304f\u3068\u5404\u30ab\u30e9\u30e0\u306e\u578b\u3092\u63a8\u5b9a\u3057\u3066\u304f\u308c\u308b\ngenome_alignment_indices <- sparklyr::spark_read_csv(\n  sc = sc, name = \"alignment_indices\", path = \"s3a://1000genomes/alignment_indices/20100517.alignment.index\",\n  infer_schema = TRUE, header = TRUE, delimiter = \",\"\n)\n> genome_alignment_indices\nSource:   query [4,424 x 6]\nDatabase: spark connection master=local[4] app=sparklyr local=TRUE\n\n                                                                             BAM_FILE                          BAM_MD5\n                                                                                <chr>                            <chr>\n1   data/HG00096/alignment/HG00096.chrom11.ILLUMINA.bwa.GBR.low_coverage.20120522.bam e2425c6f57b2aa4ddb08f472d98221d0\n2   data/HG00096/alignment/HG00096.chrom20.ILLUMINA.bwa.GBR.low_coverage.20120522.bam c5cb5c7b356e95df899f7e780fa22e2b\n3    data/HG00096/alignment/HG00096.mapped.ILLUMINA.bwa.GBR.low_coverage.20120522.bam 336ea55913bc261b72875bd259753046\n4  data/HG00096/alignment/HG00096.unmapped.ILLUMINA.bwa.GBR.low_coverage.20120522.bam 21f4323f02d6d2a888a02bdfb24dc143\n5   data/HG00103/alignment/HG00103.chrom11.ILLUMINA.bwa.GBR.low_coverage.20120522.bam 09f5199ca81b87fba667a1d60d166474\n6   data/HG00103/alignment/HG00103.chrom20.ILLUMINA.bwa.GBR.low_coverage.20120522.bam 34f0cfc7d3584a64e104a1ebbc9209ab\n7    data/HG00103/alignment/HG00103.mapped.ILLUMINA.bwa.GBR.low_coverage.20120522.bam a09f7acc6a736daae40f689b8c9e40c2\n8  data/HG00103/alignment/HG00103.unmapped.ILLUMINA.bwa.GBR.low_coverage.20120522.bam 2d355139e1c8fe220efbf47f0e050bcf\n9   data/HG00106/alignment/HG00106.chrom11.ILLUMINA.bwa.GBR.low_coverage.20120522.bam cef7bda3308f06dcb9fe494c7addbd76\n10  data/HG00106/alignment/HG00106.chrom20.ILLUMINA.bwa.GBR.low_coverage.20120522.bam 81b3973ae3fa78083a9737f3bf800182\n# ... with 4,414 more rows, and 4 more variables: BAI_FILE <chr>, BAI_MD5 <chr>, BAS_FILE <chr>, BAS_MD5 <chr>\n\n\n# .gz\u30d5\u30a1\u30a4\u30eb\u3082\u5bfe\u5fdc\n# infer_schema\u5f15\u6570\u3092FALSE\u306b\u3059\u308b\u3068\u5404\u30ab\u30e9\u30e0\u306e\u578b\u304c\u6587\u5b57\u5217\u3068\u3057\u3066\u8aad\u307f\u8fbc\u307e\u308c\u308b\ngenome_alignment_indices_bas <- sparklyr::spark_read_csv(\n  sc = sc, name = \"alignment_indices_bas\", path = \"s3a://1000genomes/alignment_indices/20120522.alignment.index.bas.gz\",\n  infer_schema = FALSE, header = TRUE, delimiter = \"\\t\"\n)\n> genome_alignment_indices_bas\nSource:   query [2.78e+04 x 21]\nDatabase: spark connection master=local[4] app=sparklyr local=TRUE\n\n                                              bam_filename                              md5     study  sample platform\n                                                     <chr>                            <chr>     <chr>   <chr>    <chr>\n1   HG00096.chrom11.ILLUMINA.bwa.GBR.low_coverage.20120522 e2425c6f57b2aa4ddb08f472d98221d0 SRP001294 HG00096 ILLUMINA\n2   HG00096.chrom11.ILLUMINA.bwa.GBR.low_coverage.20120522 e2425c6f57b2aa4ddb08f472d98221d0 SRP001294 HG00096 ILLUMINA\n3   HG00096.chrom11.ILLUMINA.bwa.GBR.low_coverage.20120522 e2425c6f57b2aa4ddb08f472d98221d0 SRP001294 HG00096 ILLUMINA\n4   HG00096.chrom20.ILLUMINA.bwa.GBR.low_coverage.20120522 c5cb5c7b356e95df899f7e780fa22e2b SRP001294 HG00096 ILLUMINA\n5   HG00096.chrom20.ILLUMINA.bwa.GBR.low_coverage.20120522 c5cb5c7b356e95df899f7e780fa22e2b SRP001294 HG00096 ILLUMINA\n6   HG00096.chrom20.ILLUMINA.bwa.GBR.low_coverage.20120522 c5cb5c7b356e95df899f7e780fa22e2b SRP001294 HG00096 ILLUMINA\n7    HG00096.mapped.ILLUMINA.bwa.GBR.low_coverage.20120522 336ea55913bc261b72875bd259753046 SRP001294 HG00096 ILLUMINA\n8    HG00096.mapped.ILLUMINA.bwa.GBR.low_coverage.20120522 336ea55913bc261b72875bd259753046 SRP001294 HG00096 ILLUMINA\n9    HG00096.mapped.ILLUMINA.bwa.GBR.low_coverage.20120522 336ea55913bc261b72875bd259753046 SRP001294 HG00096 ILLUMINA\n10 HG00096.unmapped.ILLUMINA.bwa.GBR.low_coverage.20120522 21f4323f02d6d2a888a02bdfb24dc143 SRP001294 HG00096 ILLUMINA\n# ... with 2.779e+04 more rows, and 16 more variables: library <chr>, readgroup <chr>, `_total_bases` <chr>,\n#   `_mapped_bases` <chr>, `_total_reads` <chr>, `_mapped_reads` <chr>, `_mapped_reads_paired_in_sequencing` <chr>,\n#   `_mapped_reads_properly_paired` <chr>, `_of_mismatched_bases` <chr>, average_quality_of_mapped_bases <chr>,\n#   mean_insert_size <chr>, insert_size_sd <chr>, median_insert_size <chr>, insert_size_median_absolute_deviation <chr>,\n#   `_duplicate_reads` <chr>, `_duplicate_bases` <chr>\n\n\n# columns\u5f15\u6570\u306b\u540d\u524d\u4ed8\u304d\u30d9\u30af\u30c8\u30eb\u3092\u4e0e\u3048\u308b\u3053\u3068\u3067\u5404\u30ab\u30e9\u30e0\u306e\u578b\u3068\u540d\u524d\u3092\u6307\u5b9a\u3067\u304d\u308b\n# R\u3068Spark\u9593\u306e\u578b\u306e\u9055\u3044\u306f\u4e0b\u8a18\u306e\u30c9\u30ad\u30e5\u30e1\u30f3\u30c8\u3092\n# http://spark.apache.org/docs/latest/sparkr.html#data-type-mapping-between-r-and-spark\ncols <- c(\n  rep(x = \"string\", length = 7), rep(x = \"double\", length = 7), rep(x = \"float\", length = 5), \n  \"integer\", \"string\"\n)\nnames(x = cols) <- colnames(x = genome_alignment_indices_bas)\n\n# \u8b66\u544a\u30e1\u30c3\u30bb\u30fc\u30b8\u306b\u3064\u3044\u3066\u306f\u672a\u8abf\u67fb\ngenome_alignment_indices_bas_cols <- sparklyr::spark_read_csv(\n  sc = sc, name = \"alignment_indices_bas_cols\", path = \"s3a://1000genomes/alignment_indices/20120522.alignment.index.bas.gz\",\n  infer_schema = FALSE, header = TRUE, delimiter = \"\\t\",\n  columns = cols\n)\n \u8b66\u544a\u30e1\u30c3\u30bb\u30fc\u30b8: \n spark_csv_read(sc, spark_normalize_path(path), options, columns) \u3067: \n  Dataset has 1 columns but 'columns' has length 21\n\n> genome_alignment_indices_bas_cols\nSource:   query [2.78e+04 x 21]\nDatabase: spark connection master=local[4] app=sparklyr local=TRUE\n\n                                              bam_filename                              md5     study  sample platform    library readgroup\n                                                     <chr>                            <chr>     <chr>   <chr>    <chr>      <chr>     <chr>\n1   HG00096.chrom11.ILLUMINA.bwa.GBR.low_coverage.20120522 e2425c6f57b2aa4ddb08f472d98221d0 SRP001294 HG00096 ILLUMINA 2845856850 SRR062634\n2   HG00096.chrom11.ILLUMINA.bwa.GBR.low_coverage.20120522 e2425c6f57b2aa4ddb08f472d98221d0 SRP001294 HG00096 ILLUMINA 2845856850 SRR062635\n3   HG00096.chrom11.ILLUMINA.bwa.GBR.low_coverage.20120522 e2425c6f57b2aa4ddb08f472d98221d0 SRP001294 HG00096 ILLUMINA 2845856850 SRR062641\n4   HG00096.chrom20.ILLUMINA.bwa.GBR.low_coverage.20120522 c5cb5c7b356e95df899f7e780fa22e2b SRP001294 HG00096 ILLUMINA 2845856850 SRR062634\n5   HG00096.chrom20.ILLUMINA.bwa.GBR.low_coverage.20120522 c5cb5c7b356e95df899f7e780fa22e2b SRP001294 HG00096 ILLUMINA 2845856850 SRR062635\n6   HG00096.chrom20.ILLUMINA.bwa.GBR.low_coverage.20120522 c5cb5c7b356e95df899f7e780fa22e2b SRP001294 HG00096 ILLUMINA 2845856850 SRR062641\n7    HG00096.mapped.ILLUMINA.bwa.GBR.low_coverage.20120522 336ea55913bc261b72875bd259753046 SRP001294 HG00096 ILLUMINA 2845856850 SRR062634\n8    HG00096.mapped.ILLUMINA.bwa.GBR.low_coverage.20120522 336ea55913bc261b72875bd259753046 SRP001294 HG00096 ILLUMINA 2845856850 SRR062635\n9    HG00096.mapped.ILLUMINA.bwa.GBR.low_coverage.20120522 336ea55913bc261b72875bd259753046 SRP001294 HG00096 ILLUMINA 2845856850 SRR062641\n10 HG00096.unmapped.ILLUMINA.bwa.GBR.low_coverage.20120522 21f4323f02d6d2a888a02bdfb24dc143 SRP001294 HG00096 ILLUMINA 2845856850 SRR062634\n# ... with 2.779e+04 more rows, and 14 more variables: `_total_bases` <dbl>, `_mapped_bases` <dbl>, `_total_reads` <dbl>, `_mapped_reads` <dbl>,\n#   `_mapped_reads_paired_in_sequencing` <dbl>, `_mapped_reads_properly_paired` <dbl>, `_of_mismatched_bases` <dbl>,\n#   average_quality_of_mapped_bases <dbl>, mean_insert_size <dbl>, insert_size_sd <dbl>, median_insert_size <dbl>,\n#   insert_size_median_absolute_deviation <dbl>, `_duplicate_reads` <int>, `_duplicate_bases` <chr>\n\n\n# `$`\u306b\u3088\u308b\u53c2\u7167\u306f\u3067\u304d\u306a\u3044\u306e\u3067\u6ce8\u610f\n> genome_alignment_indices_bas_cols$bam_filename\nNULL\n\n# select\u3067\u53c2\u7167\n> genome_alignment_indices_bas_cols %>% \n+   dplyr::select(bam_filename) %>% \n+   head(n = 10)\nSource:   query [10 x 1]\nDatabase: spark connection master=local[4] app=sparklyr local=TRUE\n\n                                              bam_filename\n                                                     <chr>\n1   HG00096.chrom11.ILLUMINA.bwa.GBR.low_coverage.20120522\n2   HG00096.chrom11.ILLUMINA.bwa.GBR.low_coverage.20120522\n3   HG00096.chrom11.ILLUMINA.bwa.GBR.low_coverage.20120522\n4   HG00096.chrom20.ILLUMINA.bwa.GBR.low_coverage.20120522\n5   HG00096.chrom20.ILLUMINA.bwa.GBR.low_coverage.20120522\n6   HG00096.chrom20.ILLUMINA.bwa.GBR.low_coverage.20120522\n7    HG00096.mapped.ILLUMINA.bwa.GBR.low_coverage.20120522\n8    HG00096.mapped.ILLUMINA.bwa.GBR.low_coverage.20120522\n9    HG00096.mapped.ILLUMINA.bwa.GBR.low_coverage.20120522\n10 HG00096.unmapped.ILLUMINA.bwa.GBR.low_coverage.20120522\n\n\n# \u3068\u308a\u3042\u3048\u305a\u96c6\u8a08\u3057\u3066\u307f\u308b\n> genome_summarize <- genome_alignment_indices_bas_cols %>% \n  dplyr::group_by(readgroup) %>% \n  dplyr::summarize(\n    total_bases = sum(`_total_bases`),\n    mapped_bases = sum(`_mapped_bases`),\n    total_reads = sum(`_total_reads`),\n    mapped_reads = sum(`_mapped_reads`)\n  ) %>% \n  print\nSource:   query [6,949 x 5]\nDatabase: spark connection master=local[4] app=sparklyr local=TRUE\n\n   readgroup total_bases mapped_bases total_reads mapped_reads\n       <chr>       <dbl>        <dbl>       <dbl>        <dbl>\n1  ERR015528  6983935452   5952262482    64666069     62451949\n2  ERR020229 19111863316  16893939598   210020476    199362355\n3  ERR013151  4090595256   3654598436    37875882     36786031\n4  ERR015759  1341103068   1249066562    12417621     11811715\n5  ERR019905  2264878476   2181465658    20971097     20421069\n6  ERR013138  6858917784   6220244192    63508498     60258668\n7  SRR037779  2251299740   1995203950    29622365     27061710\n8  SRR037781  2203411836   1942146896    28992261     26343528\n9  SRR043409  4294927960   3987005465    59268712     57122507\n10 SRR044230  5247820064   4803974017    69050264     66265436\n# ... with 6,939 more rows\n\n# \u3068\u308a\u3042\u3048\u305aPCA\n> genome_summarize %>% \n+   sparklyr::ml_pca(features = c(\"total_bases\", \"mapped_bases\", \"total_reads\", \"mapped_reads\"))\n* No rows dropped by 'na.omit' call\nExplained variance:\n\n         PC1          PC2          PC3          PC4 \n9.977596e-01 2.239423e-03 9.743283e-07 1.377467e-08 \n\nRotation:\n                      PC1          PC2           PC3          PC4\ntotal_bases  -0.732068499  0.681081744  0.0140674519  0.002340459\nmapped_bases -0.681151089 -0.732137051  0.0001951216 -0.002914359\ntotal_reads  -0.007463459  0.009455473 -0.7330409740 -0.680077805\nmapped_reads -0.007294029  0.003686524 -0.6800389689  0.733130416\n\n# \u3068\u308a\u3042\u3048\u305a\u3001K-means\n> genome_cls <- genome_summarize %>% \n+   sparklyr::ml_kmeans(centers = 4, features = c(\"total_bases\", \"mapped_bases\", \"total_reads\", \"mapped_reads\"))\n* No rows dropped by 'na.omit' call\n> table(fitted(object = genome_cls))\n\n   0    1    2    3 \n4801   72 1815  261 \n```\n\n\u3000\u30b2\u30ce\u30e0\u306e\u77e5\u8b58\u3082\u30c7\u30fc\u30bf\u30bd\u30fc\u30b9\u306e\u7d20\u6027\u3082\u3088\u304f\u308f\u304b\u3089\u306a\u3044\u306e\u3067\u3001\u5206\u6790\u306f\u5148\u9001\u308a\u3002\n\n\n# \u307e\u3068\u3081\n\u3000{sparklyr}\u306e`spark_read_csv`\u3092\u7528\u3044\u308b\u3053\u3068\u3067\u3001S3\u30d0\u30b1\u30c3\u30c8\u4e0a\u306b\u3042\u308b\u30c7\u30fc\u30bf\u3092\u8aad\u307f\u8fbc\u3081\u307e\u3057\u305f\u3002\u3053\u308c\u306b\u3088\u308a\u3001S3\u30d0\u30b1\u30c3\u30c8\u306b\u3042\u308b\u30d5\u30a1\u30a4\u30eb\u3092\u304a\u624b\u8efd\u306b\u5206\u6790\u3067\u304d\u308b\u3088\u3046\u306b\u306a\u308a\u307e\u3059\u3057\u3001\u30c7\u30fc\u30bf\u691c\u8a3c\u306e\u305f\u3081\u306bRedshift\u306b\u30b3\u30d4\u30fc\u3068\u304b\u30c0\u30a6\u30f3\u30ed\u30fc\u30c9\u3057\u3066\u30d5\u30a1\u30a4\u30eb\u3092\u958b\u304f\u3068\u304b\u4e0d\u8981\u306b\u306a\u308a\u307e\u3059\u3002\n\u3000Amazon Athena\u304c\u3069\u308c\u304f\u3089\u3044\u4fbf\u5229\u304b\u5224\u65ad\u3057\u304b\u306d\u307e\u3059\u304c\u3001RStudio\u4e0a\u3067\u51e6\u7406\u3067\u304d\u307e\u3059\u306e\u3067R\u304a\u3058\u3055\u3093\u306f\u307e\u3059\u307e\u3059\u6357\u308a\u307e\u3059\u306d\u3002\n\u3000\u3061\u306a\u307f\u306b\u4eca\u56de\u3068\u540c\u3058\u3053\u3068\u306f{sparkr}\u306e`read.df`\u3067\u3082\u53ef\u80fd\u3067\u3059\u3002\u3069\u3061\u3089\u306e\u30d1\u30c3\u30b1\u30fc\u30b8\u304c\u3044\u3044\u304b\u60a9\u3080\u304b\u3082\u3057\u308c\u307e\u305b\u3093\u304c\u3001\u304a\u597d\u307f\u3067\u3068\u3057\u304b\u8a00\u3048\u307e\u305b\u3093\u3002\n\n- [SparkR (R on Spark)](http://spark.apache.org/docs/latest/sparkr.html)\n- [SparkR vs sparklyr](http://stackoverflow.com/questions/39494484/sparkr-vs-sparklyr)\n\n\u3000\u307e\u305f\u3001Java\u95a2\u4fc2\u306e\u30e9\u30a4\u30d6\u30e9\u30ea\u3092R\u3067\u6271\u3046\u5834\u5408\u306b\u3088\u304f\u3042\u308b\u8a71\u3067\u3059\u304c\u3001\u4f7f\u3048\u308b\u30e1\u30e2\u30ea\u30b5\u30a4\u30ba\u306f\u3042\u3089\u304b\u3058\u3081\u8a2d\u5b9a\u3057\u3066\u304a\u304d\u307e\u3057\u3087\u3046\u3002\n\n- [sparklyr - Configuration - Package Options](http://spark.rstudio.com/deployment.html#package_options)\n- [Spark Configuration - Available Properties](http://spark.apache.org/docs/latest/configuration.html#available-properties)\n\n```r:Spark\u30e1\u30e2\u30ea\u5468\u308a\u306e\u8a2d\u5b9a\n# SPARK_MEM\u306f\u8a2d\u5b9a\u3057\u306a\u304f\u3066\u3082\u3044\u3044\uff1f\n# Sys.setenv(\"SPARK_MEM\" = \"64g\")\nspark_conf <- sparklyr::spark_config()\nspark_conf$spark.executor.cores <- 2\nspark_conf$spark.executor.memory <- \"4G\"\nspark_conf$spark.driver.memory <- \"12G\"\n```\n\n## \u53c2\u8003\n- [Data Science in Spark with sparklyr Cheat Sheet](http://spark.rstudio.com/images/sparklyr-cheatsheet.pdf)\n- [Tutorial: Scalable R on Spark with SparkR, sparklyr and RevoScaleR](http://blog.revolutionanalytics.com/2016/10/tutorial-scalable-r-on-spark.html)\n- [Running sparklyr \u2013 RStudio\u2019s R Interface to Spark on Amazon EMR](https://aws.amazon.com/jp/blogs/big-data/running-sparklyr-rstudios-r-interface-to-spark-on-amazon-emr/)\n- [AWS EMR bootstrap to install RStudio Server along with sparklyr](https://gist.github.com/cosmincatalin/a2e2b63fcb6ca6e3aaac71717669ab7f)\n\n\n## \u5b9f\u884c\u74b0\u5883\n```r:\u5b9f\u884c\u74b0\u5883\n> devtools::session_info()\nSession info -----------------------------------------------------------------------------------------------------------------\n setting  value                       \n version  R version 3.3.2 (2016-10-31)\n system   x86_64, darwin15.6.0        \n ui       RStudio (1.0.136)           \n language (EN)                        \n collate  ja_JP.UTF-8                 \n tz       Asia/Tokyo                  \n date     2017-01-19                  \n\nPackages ---------------------------------------------------------------------------------------------------------------------\n package       * version    date       source                            \n assertthat      0.1        2013-12-06 CRAN (R 3.3.2)                    \n aws.s3        * 0.1.34     2017-01-11 local                             \n aws.signature * 0.2.6      2017-01-11 local                             \n backports       1.0.4      2016-10-24 CRAN (R 3.3.2)                    \n base64enc       0.1-3      2015-07-28 CRAN (R 3.3.2)                    \n colorspace      1.3-2      2016-12-14 CRAN (R 3.3.2)                    \n config          0.2        2016-08-02 cran (@0.2)                       \n curl            2.3        2016-11-24 cran (@2.3)                       \n DBI             0.5-1      2016-09-10 CRAN (R 3.3.2)                    \n devtools        1.12.0     2016-12-05 CRAN (R 3.3.2)                    \n digest          0.6.10     2016-08-02 CRAN (R 3.3.2)                    \n dplyr         * 0.5.0      2016-06-24 CRAN (R 3.3.2)                    \n ggfortify       0.3.0.9000 2016-12-31 Github (sinhrks/ggfortify@907a044)\n ggplot2       * 2.2.0      2016-11-11 CRAN (R 3.3.2)                    \n gridExtra       2.2.1      2016-02-29 CRAN (R 3.3.2)                    \n gtable          0.2.0      2016-02-26 CRAN (R 3.3.2)                    \n httr            1.2.1      2016-07-03 CRAN (R 3.3.2)                    \n jsonlite        1.1        2016-09-14 CRAN (R 3.3.2)                    \n lazyeval        0.2.0      2016-06-12 CRAN (R 3.3.2)                    \n magrittr        1.5        2014-11-22 CRAN (R 3.3.2)                    \n memoise         1.0.0      2016-01-29 CRAN (R 3.3.2)                    \n munsell         0.4.3      2016-02-13 CRAN (R 3.3.2)                    \n plyr            1.8.4      2016-06-08 CRAN (R 3.3.2)                    \n purrr         * 0.2.2      2016-06-18 CRAN (R 3.3.2)                    \n R6              2.2.0      2016-10-05 CRAN (R 3.3.2)                    \n rappdirs        0.3.1      2016-03-28 CRAN (R 3.3.2)                    \n Rcpp            0.12.8     2016-11-17 CRAN (R 3.3.2)                    \n readr         * 1.0.0      2016-08-03 CRAN (R 3.3.2)                    \n RevoUtils       10.0.2     2016-11-22 local                             \n rprojroot       1.1        2016-10-29 CRAN (R 3.3.2)                    \n scales          0.4.1      2016-11-09 CRAN (R 3.3.2)                    \n sparklyr        0.5.1      2016-12-19 CRAN (R 3.3.2)                    \n tibble        * 1.2        2016-08-26 CRAN (R 3.3.2)                    \n tidyr         * 0.6.0      2016-08-12 CRAN (R 3.3.2)                    \n tidyverse     * 1.0.0      2016-09-09 CRAN (R 3.3.2)                    \n withr           1.0.2      2016-06-20 CRAN (R 3.3.2)                    \n xml2            1.1.0      2017-01-07 CRAN (R 3.3.2)                    \n yaml            2.1.14     2016-11-12 CRAN (R 3.3.2)         \n", "tags": ["R", "Spark", "AWS"]}