{"context": " More than 1 year has passed since last update.Kubernetes\u3092\u7406\u89e3\u3059\u308b\u305f\u3081\u306b\u3001\u307e\u305a\u306f\u52d5\u304b\u3057\u611f\u899a\u3092\u63b4\u3080\u3002\u3069\u3093\u306a\u4ed5\u7d44\u307f\u304b\u306f\u5f8c\u3067\u30c9\u30ad\u30e5\u30e1\u30f3\u30c8\u3092\u8aad\u3067\u307e\u3068\u3081\u308b\u3002\n\u74b0\u5883\uff1aVirtualBox\n     CoreOS Alpha 845.0.0\n     Kernel version:4.2.2\n     docker version:1.8.3\nCoreOS\u306b\u3064\u3044\u3066\u306f\u5f8c\u65e5\u52c9\u5f37\u3002\u77e5\u3089\u306a\u3044\u3053\u3068\u304c\u4eca\u306e\u6642\u70b9\u3067\u306f\u591a\u3044\u306e\u3067\u3002\n\n1. kubernetes\u74b0\u5883\u306e\u78ba\u8a8d\n\n1.1. etcd\u304c\u6b63\u5e38\u306b\u52d5\u4f5c\u3057\u3066\u3044\u308b\u304b\u78ba\u8a8d\u3059\u308b\u3002\n\u30af\u30e9\u30b9\u30bf\u306e\u72b6\u614b\u3092etcdctl\u30b3\u30de\u30f3\u30c9\u3092\u4f7f\u7528\u3057\u3066\u78ba\u8a8d\u3059\u308b\u3002\n$ etcdctl cluster-health\nmember ce2a822cea30bfca is healthy: got healthy result from http://localhost:2379\ncluster is healthy\n\n\u203betcd\u306fKVS\u3067\u3001CoreOS\u3092\u4f7f\u3063\u3066\u69cb\u6210\u3059\u308b\u30af\u30e9\u30b9\u30bf\u306e\u5168\u30ce\u30fc\u30c9\u304c\u30a2\u30af\u30bb\u30b9\u53ef\u80fd\u306a\u30c7\u30fc\u30bf\u3092\u683c\u7d0d\u3059\u308b\u305f\u3081\u306b\u4f7f\u7528\u3055\u308c\u308b\u3002\ntop\u30ec\u30d9\u30eb\u306eKey\u3092\u78ba\u8a8d\n$ etcdctl ls\n/registry\n/coreos.com\n\nvalue\u3092\u5f97\u308b\u306b\u306fget\u3067\u30a8\u30f3\u30c9\u30dd\u30a4\u30f3\u30c8\u3092\u6307\u5b9a\u3002\u30c7\u30a3\u30ec\u30af\u30c8\u30ea\u306e\u5834\u5408\u306f\u4ee5\u4e0b\u306e\u3088\u3046\u306b\u30c7\u30a3\u30ec\u30af\u30c8\u30ea\u3068\u8fd4\u3063\u3066\u304f\u308b\u3002\n$ etcdctl get /coreos.com/              \n/coreos.com: is a directory\n\n\u4ee5\u4e0b\u306e\u3088\u3046\u306b\u3059\u308c\u3070\u5168\u3066\u306e\u968e\u5c64\u69cb\u9020\u60c5\u5831\u3092\u51fa\u529b\u3067\u304d\u308b\u3002\netcdctl ls / --recursive\n\n\u203bzookeeper\u3068\u4f3c\u3066\u3044\u308b\u3002\n\u5b9f\u969b\u306e\u30c7\u30fc\u30bf\u304c\u3069\u306e\u3088\u3046\u306b\u898b\u3048\u308b\u304b\u3001endpoint\u3092\u6307\u5b9a\u3057\u3066get\u3059\u308b\u3002\n$ etcdctl get /coreos.com/network/config\n{\"Network\":\"10.2.0.0/16\",\"Backend\":{\"Type\":\"vxlan\"}}\n\n\n1.2. kubernetes\u306eservice\u304c\u6b63\u5e38\u306b\u52d5\u4f5c\u3057\u3066\u3044\u308b\u304b\u78ba\u8a8d\u3059\u308b\u3002\n$ systemctl status kubelet.service\n\u25cf kubelet.service\n   Loaded: loaded (/etc/systemd/system/kubelet.service; enabled; vendor preset: disabled)\n   Active: active (running) since Thu 2015-10-29 05:52:17 UTC; 5h 21min ago\n Main PID: 601 (kubelet)\n   Memory: 4.8M\n      CPU: 592ms\n   CGroup: /system.slice/kubelet.service\n           \u251c\u2500601 /usr/bin/kubelet --api_servers=http://127.0.0.1:8080 --register-node=true -...\n           \u2514\u2500966 journalctl -f\n\u30fb\u30fb\u30fb\n\n$ docker ps |grep kube-api\nc5a23f6f1e0b        gcr.io/google_containers/hyperkube:v1.0.6        \"/hyperkube apiserver\"   5 hours ago         Up 5 hours                              k8s_kube-apiserver.ae2b1f58_kube-apserver-172.17.4.99_kube-system_b5fd6f0b2e57f08b39d588afd25c9206_c57e302b\n864e167abf14        gcr.io/google_containers/pause:0.8.0             \"/pause\"                 5 hours ago         Up 5 hours                              k8s_POD.e4cc795_kube-apiserver-172.17.4.99_kube-system_b5fd6f0b2e57f08b39d588afd25c9206_c1bedd4a\n\n\n1.3. kubernetes\u306estatus\u3092\u78ba\u8a8d\u3059\u308b\u3002\nmaster\u306e\u30a2\u30c9\u30ec\u30b9\u3084kubernetes.io/cluster-service=true\u306e\u30e9\u30d9\u30eb\u3092\u6301\u3063\u305f\u30b5\u30fc\u30d3\u30b9\u306e\u60c5\u5831\u3092\u8868\u793a\u3059\u308b\u3002\n$ kubectl cluster-info\nKubernetes master is running at https://172.17.4.99:443\nKubeDNS is running at https://172.17.4.99:443/api/v1/proxy/namespaces/kube-system/services/kube-dns\n\n\u30ea\u30bd\u30fc\u30b9\u60c5\u5831\uff08pods (po), replication controllers (rc), services (svc), nodes, events (ev), component statuses (cs), limit ranges (limits), nodes (no), persistent volumes (pv), persistent volume claims (pvc) or resource quotas\uff09\u3092\u8868\u793a\u3059\u308b\u3002\n$ kubectl get nodes\nNAME          LABELS                               STATUS\n172.17.4.99   kubernetes.io/hostname=172.17.4.99   Ready\n\n$ kubectl get pods        \nNAME      READY     STATUS    RESTARTS   AGE\n\nkubeconfig\u306e\u8a2d\u5b9a\u3092\u8868\u793a\n\n$ kubectl config view\napiVersion: v1\nclusters:\n- cluster:\n    certificate-authority: /home/core/ssl/ca.pem\n    server: https://172.17.4.99:443\n  name: vagrant\ncontexts:\n- context:\n    cluster: vagrant\n    user: vagrant-admin\n  name: vagrant\ncurrent-context: vagrant\nkind: Config\npreferences: {}\nusers:\n- name: vagrant-admin\n  user:\n    client-certificate: /home/core/ssl/admin.pem\n    client-key: /home/core/ssl/admin-key.pem\n\n\n2. Kubernetes\u3092\u4f7f\u3063\u3066\u3001cassandra\u74b0\u5883\u306e\u69cb\u7bc9\nhttp://kubernetes.io/v1.0/docs/user-guide/configuring-containers.html\nhttp://kubernetes.io/v1.0/examples/cassandra/README.html\n\n2.1. Pod\u306e\u4f5c\u6210\nKubernetes\u306eAPI Resource Schema\u3092\u4f7f\u7528\u3057\u3066\u8a2d\u5b9a\u30d5\u30a1\u30a4\u30eb\u3092\u4f5c\u6210\nKubernetes\u3067\u306f\u30a2\u30d7\u30ea\u30b1\u30fc\u30b7\u30e7\u30f3\u306e\u6700\u5c0f\u5358\u4f4d\u306fPod\u306a\u306e\u3067\u3001Pod\u306e\u5b9a\u7fa9\u3092\u307e\u305a\u884c\u3046\u3002Pod\u306f\u540c\u3058\u30db\u30b9\u30c8\u4e0a\u306b\u30b9\u30b1\u30b8\u30e5\u30fc\u30ea\u30f3\u30b0\u3055\u308c\u308b\u3002Pod\u5185\u306e\u5168\u3066\u306e\u30b3\u30f3\u30c6\u30ca\u306fnetwork namespace\u3092\u5171\u6709\u3057\u3001volume\u3082\u30b7\u30a7\u30a2\u53ef\u80fd\uff08\u30aa\u30d7\u30b7\u30e7\u30f3\uff09\u3002Kubernetes\u306fPod\u5185\u3067\u30b3\u30f3\u30c6\u30ca\u3092\u751f\u6210\u3059\u308b\u3002\n\ncassandra.yaml\napiVersion: v1 #\u73fe\u5728\u306e\u30d0\u30fc\u30b8\u30e7\u30f3\u306fv1\nkind: Pod # Pod\u306b\u3064\u3044\u3066\u5b9a\u7fa9\u3059\u308b\u3053\u3068\u3092\u660e\u793a\nmetadata:\n  labels:\n    name: cassandra # label\u540d\n  name: cassandra #\u751f\u6210\u3055\u308c\u308bPod\u306e\u540d\u524d\u3002\u30af\u30e9\u30b9\u30bf\u5185\u3067unique\u3067\u306a\u3051\u308c\u3070\u306a\u3089\u306a\u3044\u3002Pod\u5185\u306e\u30b3\u30f3\u30c6\u30ca\u540d\u306fcontainers[0].name\nspec:\n  containers:\n  - args:\n    - /run.sh\n    resources:\n      limits:\n        cpu: \"0.1\" # cluster manager\u306b0.1cpu\u3092\u8981\u6c42\n    image: gcr.io/google_containers/cassandra:v5 #Docker Image\u540d\u3002\u30a4\u30e1\u30fc\u30b8\u306f\u30c7\u30d5\u30a9\u30eb\u30c8\u3067\u306fDocker Hub\u304b\u3089\u53d6\u5f97\n    name: cassandra\n    ports: #\u5916\u90e8\u306b\u516c\u958b\u3059\u308b\u65b9\u6cd5\u3068\u30dd\u30fc\u30c8\u3092\u5b9a\u7fa9\n    - name: cql #Cassandra Query Language\n      containerPort: 9042\n    - name: thrift\n      containerPort: 9160\n    volumeMounts:\n    - name: data\n      mountPath: /cassandra_data\n    env: #Cassandra\u306e\u30d1\u30e9\u30e1\u30fc\u30bf\n    - name: MAX_HEAP_SIZE\n      value: 512M\n    - name: HEAP_NEWSIZE\n      value: 100M\n    - name: POD_NAMESPACE\n      valueFrom:\n        fieldRef:\n          fieldPath: metadata.namespace\n  volumes:\n    - name: data\n      emptyDir: {}\n\n\n\u4f5c\u3063\u305f\u8a2d\u5b9a\u30d5\u30a1\u30a4\u30eb\u3092\u6307\u5b9a\u3057\u3066\u30ea\u30bd\u30fc\u30b9\uff08Pod)\u3092\u4f5c\u6210\u3059\u308b\u3002\n$ kubectl create -f cassandra.yaml \npods/cassandra\n\nPod\u304c\u4f5c\u6210\u3055\u308c\u305f\u304b\u3069\u3046\u304b\u78ba\u8a8d\n$ kubectl get pods    \nNAME        READY     STATUS    RESTARTS   AGE\ncassandra   0/1       Running   0          8s\n\nResource\u306e\u8a73\u7d30\u306b\u3064\u3044\u3066\u78ba\u8a8d\u3002\u4ee5\u4e0b\u306fPod\u3060\u304cpods (po)\u4ee5\u5916\u306b, replicationcontrollers (rc), services (svc), nodes (no), events (ev), componentstatuses (cs), limitRanges (limits), persistentVolumes (pv), persistentVolumeClaims (pvc), resourceQuotas (quota) or secrets\u304c\u6307\u5b9a\u53ef\u80fd\u3002\n$ kubectl describe pod cassandra\nName:               cassandra\nNamespace:          default\nImage(s):           gcr.io/google_containers/cassandra:v5\nNode:               172.17.4.99/172.17.4.99\nLabels:             name=cassandra\nStatus:             Running\nReason:             \nMessage:            \nIP:             10.2.67.6\nReplication Controllers:    <none>\nContainers:\n  cassandra:\n    Image:  gcr.io/google_containers/cassandra:v5\n    Limits:\n      cpu:      100m\n    State:      Running\n      Started:      Fri, 30 Oct 2015 01:13:29 +0000\n    Ready:      True\n    Restart Count:  0\nConditions:\n  Type      Status\n  Ready     True \nEvents:\n  FirstSeen             LastSeen            Count   From            SubobjectPath               Reason      Message\n  Fri, 30 Oct 2015 01:13:29 +0000   Fri, 30 Oct 2015 01:13:29 +0000 1   {scheduler }                            scheduled   Successfully assigned cassandra to 172.17.4.99\n  Fri, 30 Oct 2015 01:13:29 +0000   Fri, 30 Oct 2015 01:13:29 +0000 1   {kubelet 172.17.4.99}   implicitly required container POD   pulled      Pod container image \"gcr.io/google_containers/pause:0.8.0\" already present on machine\n  Fri, 30 Oct 2015 01:13:29 +0000   Fri, 30 Oct 2015 01:13:29 +0000 1   {kubelet 172.17.4.99}   implicitly required container POD   created     Created with docker id 2843e181382d\n  Fri, 30 Oct 2015 01:13:29 +0000   Fri, 30 Oct 2015 01:13:29 +0000 1   {kubelet 172.17.4.99}   implicitly required container POD   started     Started with docker id 2843e181382d\n  Fri, 30 Oct 2015 01:13:29 +0000   Fri, 30 Oct 2015 01:13:29 +0000 1   {kubelet 172.17.4.99}   spec.containers{cassandra}      created     Created with docker id d77752ffb587\n  Fri, 30 Oct 2015 01:13:29 +0000   Fri, 30 Oct 2015 01:13:29 +0000 1   {kubelet 172.17.4.99}   spec.containers{cassandra}      started     Started with docker id d77752ffb587\n\n\n2.2. Service\u306e\u4f5c\u6210\nKubernetes\u3067\u306fService\u306f\u540c\u3058\u30bf\u30b9\u30af\u3092\u51e6\u7406\u3059\u308bPod\u306e\u96c6\u307e\u308a\u3068\u3057\u3066\u5b9a\u7fa9\u3055\u308c\u308b\u3002\n\ncassandra-service.yaml\napiVersion: v1  #\u73fe\u5728\u306e\u30d0\u30fc\u30b8\u30e7\u30f3\u306fv1\nkind: Service  #Service\u306b\u3064\u3044\u3066\u5b9a\u7fa9\nmetadata:\n  labels:\n    name: cassandra\n  name: cassandra\nspec:\n  ports:\n    - port: 9042\n  selector: #query over labels(Pods\u306e\u30bb\u30c3\u30c8\uff09. \u3053\u306e\u30b5\u30fc\u30d3\u30b9\u306b\u6240\u5c5e\u3059\u308bPod\u3092\u9078\u629e\u3002\n    name: cassandra #\u3053\u306e\u4f8b\u3067\u306fcassandora\u3068\u3044\u3046label\u304c\u4ed8\u3044\u305fPod\u304c\u3053\u306eservice\u306b\u6240\u5c5e\n\n\nService\u3092\u4f5c\u6210\u3002\n$ kubectl create -f cassandra-service.yaml \nservices/cassandra\n\nService\u304c\u4f5c\u6210\u3055\u308c\u3066\u3044\u308b\u304b\u78ba\u8a8d\n$ kubectl get services\nNAME         LABELS                                    SELECTOR         IP(S)       PORT(S)\ncassandra    name=cassandra                            name=cassandra   10.3.0.80   9042/TCP\nkubernetes   component=apiserver,provider=kubernetes   <none>           10.3.0.1    443/TCP\n\n$ kubectl describe service cassandra\nName:           cassandra\nNamespace:      default\nLabels:         name=cassandra\nSelector:       name=cassandra\nType:           ClusterIP\nIP:         10.3.0.80\nPort:           <unnamed>   9042/TCP\nEndpoints:      10.2.67.6:9042\nSession Affinity:   None\nNo events.\n\nPod\u5185\u306eContainer\u306e\u30ed\u30b0\u3092\u51fa\u529b\n$ kubectl logs cassandra\n\n\n2.3. Replication Controller\u306e\u4f5c\u6210\nKubernetes\u306b\u3088\u308a\u3001Cassandra\u30af\u30e9\u30b9\u30bf\u3092\u5bb9\u6613\u306b\u69cb\u7bc9\u3001\u30b9\u30b1\u30fc\u30eb\u3059\u308b\u3053\u3068\u304c\u3067\u304d\u308b\u3002\nReplication Controller\u306f\u540c\u8cea\u306ePod\u306e\u30bb\u30c3\u30c8\u3092\u30ec\u30d7\u30ea\u30b1\u30fc\u30c8\u3059\u308b\u3002\u6307\u5b9a\u3059\u308bPod\u306e\u6570\u306b\u306a\u308b\u3088\u3046Pod\u3092add,remove\u3059\u308b\u3002\n\ncassandra-controller.yaml\napiVersion: v1 #\u73fe\u5728\u306e\u30d0\u30fc\u30b8\u30e7\u30f3\u306fv1\nkind: ReplicationController #Replication Controller\u3092\u5b9a\u7fa9\nmetadata:\n  labels:\n    name: cassandra\n  name: cassandra\nspec:\n  replicas: 1 #replica\u306e\u6570\n  selector: #controller\u306eselector query\n    name: cassandra\n  template:\n    metadata:\n      labels:\n        name: cassandra\n    spec:\n      containers:\n        - command:\n            - /run.sh\n          resources:\n            limits:\n              cpu: 0.1\n          env:\n            - name: MAX_HEAP_SIZE\n              value: 512M\n            - name: HEAP_NEWSIZE\n              value: 100M\n            - name: POD_NAMESPACE\n              valueFrom:\n                fieldRef:\n                  fieldPath: metadata.namespace\n          image: gcr.io/google_containers/cassandra:v5\n          name: cassandra\n          ports:\n            - containerPort: 9042\n              name: cql\n            - containerPort: 9160\n              name: thrift\n          volumeMounts:\n            - mountPath: /cassandra_data\n              name: data\n      volumes:\n        - name: data\n          emptyDir: {}\n\n\nController\u3092\u4f5c\u6210\u3059\u308b\n$ kubectl create -f cassandra-controller.yaml \nreplicationcontrollers/cassandra\n\nController\u304c\u4f5c\u6210\u3055\u308c\u3066\u3044\u308b\u304b\u78ba\u8a8d\u3059\u308b\n$ kubectl get rc \nCONTROLLER   CONTAINER(S)   IMAGE(S)                                SELECTOR         REPLICAS\ncassandra    cassandra      gcr.io/google_containers/cassandra:v5   name=cassandra   1\n\n$ kubectl describe rc cassandra\nName:       cassandra\nNamespace:  default\nImage(s):   gcr.io/google_containers/cassandra:v5\nSelector:   name=cassandra\nLabels:     name=cassandra\nReplicas:   1 current / 1 desired\nPods Status:    1 Running / 0 Waiting / 0 Succeeded / 0 Failed\nNo events.\n\n\n2.4. \u30af\u30e9\u30b9\u30bf\u3092\u30b9\u30b1\u30fc\u30eb\u30a2\u30a6\u30c8\u3001\u30b9\u30b1\u30fc\u30eb\u30a4\u30f3\npod\u6570\u30922\u3078\u30b9\u30b1\u30fc\u30eb\u30a2\u30a6\u30c8\u3059\u308b\u3002\n$ kubectl scale rc cassandra --replicas=2\nscaled\n\n\u30af\u30e9\u30b9\u30bf\u5185\u306epod\u4e00\u89a7\u3092\u51fa\u529b\u3057\u3001label name=cassandra\u3067\u30d5\u30a3\u30eb\u30bf\u30ea\u30f3\u30b0\u3059\u308b\u30022\u3064\u306ecassandra pod\u3092\u78ba\u8a8d\u3059\u308b\u3053\u3068\u304c\u3067\u304d\u308b\u3002 \n$ kubectl get pods -l=\"name=cassandra\"\nNAME              READY     STATUS    RESTARTS   AGE\ncassandra         1/1       Running   0          10h\ncassandra-vb3mp   1/1       Running   0          1m\n\n\u7247\u65b9\u306freplication controller\u306b\u3088\u3063\u3066\u751f\u6210\u3055\u308c\u305f\u30e9\u30f3\u30c0\u30e0\u306a\u6587\u5b57\u5217\u304c\u4ed8\u52a0\u3055\u308c\u3066\u3044\u308b\u3002\nnodetool\u3092\u4f7f\u7528\u3057\u3066\u3001\u6b63\u3057\u304f\u52d5\u4f5c\u3057\u3066\u3044\u308b\u304b\u30af\u30e9\u30b9\u30bf\u306e\u72b6\u614b\u3092\u8abf\u3079\u308b\u3002kubectl exec\u3092\u4f7f\u7528\u3057\u3001\u30b3\u30f3\u30c6\u30ca\u306e\u4e2d\u3067\u30b3\u30de\u30f3\u30c9\u3092\u5b9f\u884c\u3002(kubectl exec POD -c CONTAINER -- COMMAND [args...])\n-t\u3067stdin\u3092tty\u3001-i\u3067\u30b3\u30f3\u30c6\u30ca\u306b\u5bfe\u3057\u3066stdin\u3092pass\u3059\u308b\u3002\ncore@localhost ~ $ kubectl exec -ti cassandra -- nodetool status\nDatacenter: datacenter1\n=======================\nStatus=Up/Down\n|/ State=Normal/Leaving/Joining/Moving\n--  Address    Load       Tokens  Owns (effective)  Host ID                               Rack\nDN  10.2.67.7  ?          256     100.0%            186ce662-cc93-4e6c-90f2-1c58ffd5834a  rack1\nUN  10.2.64.3  199.82 KB  256     100.0%            b5a7fb71-58f3-4870-8cf4-c8218feb46e6  rack1\n\ncqlsh\u3092\u5b9f\u884c\u3002\u3053\u306e\u3068\u6307\u5b9a\u3059\u308b\u306e\u306fService\u306eIP\u30a2\u30c9\u30ec\u30b9\u3082\u3057\u304f\u306f\u30b5\u30fc\u30d3\u30b9\u540d\u3002\n$ kubectl get service cassandra\nNAME        LABELS           SELECTOR         IP(S)       PORT(S)\ncassandra   name=cassandra   name=cassandra   10.3.0.80   9042/TCP\n\n$ kubectl exec -ti cassandra -- cqlsh 10.3.0.80    \nConnected to Test Cluster at 10.3.0.80:9042.\n[cqlsh 5.0.1 | Cassandra 2.1.7 | CQL spec 3.2.0 | Native protocol v3]\nUse HELP for help.\ncqlsh> \n\n$ kubectl exec -ti cassandra -- cqlsh cassandra.default.cluster.local\n\n\u74b0\u5883\u306e\u69cb\u7bc9\u3001\u30b9\u30b1\u30fc\u30eb\u30a2\u30a6\u30c8\u306a\u3069\u306f\u975e\u5e38\u306b\u901f\u304f\u3001\u3057\u304b\u3082\u5bb9\u6613\u3067\u3042\u308b\u3053\u3068\u3092\u5b9f\u611f\u3002\u6b21\u304b\u3089\u306f\u30c9\u30ad\u30e5\u30e1\u30f3\u30c8\u30d9\u30fc\u30b9\u3067\u3069\u3046\u3044\u3046\u4ed5\u7d44\u307f\u306a\u306e\u304b\u3092\u8abf\u3079\u3066\u307f\u308b\u3002\u3002\nKubernetes\u3092\u7406\u89e3\u3059\u308b\u305f\u3081\u306b\u3001\u307e\u305a\u306f\u52d5\u304b\u3057\u611f\u899a\u3092\u63b4\u3080\u3002\u3069\u3093\u306a\u4ed5\u7d44\u307f\u304b\u306f\u5f8c\u3067\u30c9\u30ad\u30e5\u30e1\u30f3\u30c8\u3092\u8aad\u3067\u307e\u3068\u3081\u308b\u3002\n\n\u74b0\u5883\uff1aVirtualBox\n     CoreOS Alpha 845.0.0\n     Kernel version:4.2.2\n     docker version:1.8.3\n\nCoreOS\u306b\u3064\u3044\u3066\u306f\u5f8c\u65e5\u52c9\u5f37\u3002\u77e5\u3089\u306a\u3044\u3053\u3068\u304c\u4eca\u306e\u6642\u70b9\u3067\u306f\u591a\u3044\u306e\u3067\u3002\n\n# 1. kubernetes\u74b0\u5883\u306e\u78ba\u8a8d\n#### 1.1. etcd\u304c\u6b63\u5e38\u306b\u52d5\u4f5c\u3057\u3066\u3044\u308b\u304b\u78ba\u8a8d\u3059\u308b\u3002\n\u30af\u30e9\u30b9\u30bf\u306e\u72b6\u614b\u3092etcdctl\u30b3\u30de\u30f3\u30c9\u3092\u4f7f\u7528\u3057\u3066\u78ba\u8a8d\u3059\u308b\u3002\n\n```\n$ etcdctl cluster-health\nmember ce2a822cea30bfca is healthy: got healthy result from http://localhost:2379\ncluster is healthy\n```\n\u203betcd\u306fKVS\u3067\u3001CoreOS\u3092\u4f7f\u3063\u3066\u69cb\u6210\u3059\u308b\u30af\u30e9\u30b9\u30bf\u306e\u5168\u30ce\u30fc\u30c9\u304c\u30a2\u30af\u30bb\u30b9\u53ef\u80fd\u306a\u30c7\u30fc\u30bf\u3092\u683c\u7d0d\u3059\u308b\u305f\u3081\u306b\u4f7f\u7528\u3055\u308c\u308b\u3002\n\ntop\u30ec\u30d9\u30eb\u306eKey\u3092\u78ba\u8a8d\n\n```\n$ etcdctl ls\n/registry\n/coreos.com\n```\n\nvalue\u3092\u5f97\u308b\u306b\u306fget\u3067\u30a8\u30f3\u30c9\u30dd\u30a4\u30f3\u30c8\u3092\u6307\u5b9a\u3002\u30c7\u30a3\u30ec\u30af\u30c8\u30ea\u306e\u5834\u5408\u306f\u4ee5\u4e0b\u306e\u3088\u3046\u306b\u30c7\u30a3\u30ec\u30af\u30c8\u30ea\u3068\u8fd4\u3063\u3066\u304f\u308b\u3002\n\n```\n$ etcdctl get /coreos.com/              \n/coreos.com: is a directory\n```\n\n\u4ee5\u4e0b\u306e\u3088\u3046\u306b\u3059\u308c\u3070\u5168\u3066\u306e\u968e\u5c64\u69cb\u9020\u60c5\u5831\u3092\u51fa\u529b\u3067\u304d\u308b\u3002\n\n```\netcdctl ls / --recursive\n```\n\u203bzookeeper\u3068\u4f3c\u3066\u3044\u308b\u3002\n\n\u5b9f\u969b\u306e\u30c7\u30fc\u30bf\u304c\u3069\u306e\u3088\u3046\u306b\u898b\u3048\u308b\u304b\u3001endpoint\u3092\u6307\u5b9a\u3057\u3066get\u3059\u308b\u3002\n\n```\n$ etcdctl get /coreos.com/network/config\n{\"Network\":\"10.2.0.0/16\",\"Backend\":{\"Type\":\"vxlan\"}}\n```\n#### 1.2. kubernetes\u306eservice\u304c\u6b63\u5e38\u306b\u52d5\u4f5c\u3057\u3066\u3044\u308b\u304b\u78ba\u8a8d\u3059\u308b\u3002\n\n```\n$ systemctl status kubelet.service\n\u25cf kubelet.service\n   Loaded: loaded (/etc/systemd/system/kubelet.service; enabled; vendor preset: disabled)\n   Active: active (running) since Thu 2015-10-29 05:52:17 UTC; 5h 21min ago\n Main PID: 601 (kubelet)\n   Memory: 4.8M\n      CPU: 592ms\n   CGroup: /system.slice/kubelet.service\n           \u251c\u2500601 /usr/bin/kubelet --api_servers=http://127.0.0.1:8080 --register-node=true -...\n           \u2514\u2500966 journalctl -f\n\u30fb\u30fb\u30fb\n```\n\n```\n$ docker ps |grep kube-api\nc5a23f6f1e0b        gcr.io/google_containers/hyperkube:v1.0.6        \"/hyperkube apiserver\"   5 hours ago         Up 5 hours                              k8s_kube-apiserver.ae2b1f58_kube-apserver-172.17.4.99_kube-system_b5fd6f0b2e57f08b39d588afd25c9206_c57e302b\n864e167abf14        gcr.io/google_containers/pause:0.8.0             \"/pause\"                 5 hours ago         Up 5 hours                              k8s_POD.e4cc795_kube-apiserver-172.17.4.99_kube-system_b5fd6f0b2e57f08b39d588afd25c9206_c1bedd4a\n```\n\n#### 1.3. kubernetes\u306estatus\u3092\u78ba\u8a8d\u3059\u308b\u3002\nmaster\u306e\u30a2\u30c9\u30ec\u30b9\u3084kubernetes.io/cluster-service=true\u306e\u30e9\u30d9\u30eb\u3092\u6301\u3063\u305f\u30b5\u30fc\u30d3\u30b9\u306e\u60c5\u5831\u3092\u8868\u793a\u3059\u308b\u3002\n\n```\n$ kubectl cluster-info\nKubernetes master is running at https://172.17.4.99:443\nKubeDNS is running at https://172.17.4.99:443/api/v1/proxy/namespaces/kube-system/services/kube-dns\n```\n\n\u30ea\u30bd\u30fc\u30b9\u60c5\u5831\uff08pods (po), replication controllers (rc), services (svc), nodes, events (ev), component statuses (cs), limit ranges (limits), nodes (no), persistent volumes (pv), persistent volume claims (pvc) or resource quotas\uff09\u3092\u8868\u793a\u3059\u308b\u3002\n\n```\n$ kubectl get nodes\nNAME          LABELS                               STATUS\n172.17.4.99   kubernetes.io/hostname=172.17.4.99   Ready\n\n$ kubectl get pods        \nNAME      READY     STATUS    RESTARTS   AGE\n```\n\nkubeconfig\u306e\u8a2d\u5b9a\u3092\u8868\u793a\n```\n$ kubectl config view\napiVersion: v1\nclusters:\n- cluster:\n    certificate-authority: /home/core/ssl/ca.pem\n    server: https://172.17.4.99:443\n  name: vagrant\ncontexts:\n- context:\n    cluster: vagrant\n    user: vagrant-admin\n  name: vagrant\ncurrent-context: vagrant\nkind: Config\npreferences: {}\nusers:\n- name: vagrant-admin\n  user:\n    client-certificate: /home/core/ssl/admin.pem\n    client-key: /home/core/ssl/admin-key.pem\n```\n\n# 2. Kubernetes\u3092\u4f7f\u3063\u3066\u3001cassandra\u74b0\u5883\u306e\u69cb\u7bc9\nhttp://kubernetes.io/v1.0/docs/user-guide/configuring-containers.html\nhttp://kubernetes.io/v1.0/examples/cassandra/README.html\n\n#### 2.1. Pod\u306e\u4f5c\u6210\nKubernetes\u306eAPI Resource Schema\u3092\u4f7f\u7528\u3057\u3066\u8a2d\u5b9a\u30d5\u30a1\u30a4\u30eb\u3092\u4f5c\u6210\nKubernetes\u3067\u306f\u30a2\u30d7\u30ea\u30b1\u30fc\u30b7\u30e7\u30f3\u306e\u6700\u5c0f\u5358\u4f4d\u306fPod\u306a\u306e\u3067\u3001Pod\u306e\u5b9a\u7fa9\u3092\u307e\u305a\u884c\u3046\u3002Pod\u306f\u540c\u3058\u30db\u30b9\u30c8\u4e0a\u306b\u30b9\u30b1\u30b8\u30e5\u30fc\u30ea\u30f3\u30b0\u3055\u308c\u308b\u3002Pod\u5185\u306e\u5168\u3066\u306e\u30b3\u30f3\u30c6\u30ca\u306fnetwork namespace\u3092\u5171\u6709\u3057\u3001volume\u3082\u30b7\u30a7\u30a2\u53ef\u80fd\uff08\u30aa\u30d7\u30b7\u30e7\u30f3\uff09\u3002Kubernetes\u306fPod\u5185\u3067\u30b3\u30f3\u30c6\u30ca\u3092\u751f\u6210\u3059\u308b\u3002\n\n```cassandra.yaml\napiVersion: v1 #\u73fe\u5728\u306e\u30d0\u30fc\u30b8\u30e7\u30f3\u306fv1\nkind: Pod # Pod\u306b\u3064\u3044\u3066\u5b9a\u7fa9\u3059\u308b\u3053\u3068\u3092\u660e\u793a\nmetadata:\n  labels:\n    name: cassandra # label\u540d\n  name: cassandra #\u751f\u6210\u3055\u308c\u308bPod\u306e\u540d\u524d\u3002\u30af\u30e9\u30b9\u30bf\u5185\u3067unique\u3067\u306a\u3051\u308c\u3070\u306a\u3089\u306a\u3044\u3002Pod\u5185\u306e\u30b3\u30f3\u30c6\u30ca\u540d\u306fcontainers[0].name\nspec:\n  containers:\n  - args:\n    - /run.sh\n    resources:\n      limits:\n        cpu: \"0.1\" # cluster manager\u306b0.1cpu\u3092\u8981\u6c42\n    image: gcr.io/google_containers/cassandra:v5 #Docker Image\u540d\u3002\u30a4\u30e1\u30fc\u30b8\u306f\u30c7\u30d5\u30a9\u30eb\u30c8\u3067\u306fDocker Hub\u304b\u3089\u53d6\u5f97\n    name: cassandra\n    ports: #\u5916\u90e8\u306b\u516c\u958b\u3059\u308b\u65b9\u6cd5\u3068\u30dd\u30fc\u30c8\u3092\u5b9a\u7fa9\n    - name: cql #Cassandra Query Language\n      containerPort: 9042\n    - name: thrift\n      containerPort: 9160\n    volumeMounts:\n    - name: data\n      mountPath: /cassandra_data\n    env: #Cassandra\u306e\u30d1\u30e9\u30e1\u30fc\u30bf\n    - name: MAX_HEAP_SIZE\n      value: 512M\n    - name: HEAP_NEWSIZE\n      value: 100M\n    - name: POD_NAMESPACE\n      valueFrom:\n        fieldRef:\n          fieldPath: metadata.namespace\n  volumes:\n    - name: data\n      emptyDir: {}\n```\n\n\u4f5c\u3063\u305f\u8a2d\u5b9a\u30d5\u30a1\u30a4\u30eb\u3092\u6307\u5b9a\u3057\u3066\u30ea\u30bd\u30fc\u30b9\uff08Pod)\u3092\u4f5c\u6210\u3059\u308b\u3002\n\n```\n$ kubectl create -f cassandra.yaml \npods/cassandra\n```\nPod\u304c\u4f5c\u6210\u3055\u308c\u305f\u304b\u3069\u3046\u304b\u78ba\u8a8d\n\n```\n$ kubectl get pods    \nNAME        READY     STATUS    RESTARTS   AGE\ncassandra   0/1       Running   0          8s\n```\n\nResource\u306e\u8a73\u7d30\u306b\u3064\u3044\u3066\u78ba\u8a8d\u3002\u4ee5\u4e0b\u306fPod\u3060\u304cpods (po)\u4ee5\u5916\u306b, replicationcontrollers (rc), services (svc), nodes (no), events (ev), componentstatuses (cs), limitRanges (limits), persistentVolumes (pv), persistentVolumeClaims (pvc), resourceQuotas (quota) or secrets\u304c\u6307\u5b9a\u53ef\u80fd\u3002\n\n```\n$ kubectl describe pod cassandra\nName:\t\t\t\tcassandra\nNamespace:\t\t\tdefault\nImage(s):\t\t\tgcr.io/google_containers/cassandra:v5\nNode:\t\t\t\t172.17.4.99/172.17.4.99\nLabels:\t\t\t\tname=cassandra\nStatus:\t\t\t\tRunning\nReason:\t\t\t\t\nMessage:\t\t\t\nIP:\t\t\t\t10.2.67.6\nReplication Controllers:\t<none>\nContainers:\n  cassandra:\n    Image:\tgcr.io/google_containers/cassandra:v5\n    Limits:\n      cpu:\t\t100m\n    State:\t\tRunning\n      Started:\t\tFri, 30 Oct 2015 01:13:29 +0000\n    Ready:\t\tTrue\n    Restart Count:\t0\nConditions:\n  Type\t\tStatus\n  Ready \tTrue \nEvents:\n  FirstSeen\t\t\t\tLastSeen\t\t\tCount\tFrom\t\t\tSubobjectPath\t\t\t\tReason\t\tMessage\n  Fri, 30 Oct 2015 01:13:29 +0000\tFri, 30 Oct 2015 01:13:29 +0000\t1\t{scheduler }\t\t\t\t\t\t\tscheduled\tSuccessfully assigned cassandra to 172.17.4.99\n  Fri, 30 Oct 2015 01:13:29 +0000\tFri, 30 Oct 2015 01:13:29 +0000\t1\t{kubelet 172.17.4.99}\timplicitly required container POD\tpulled\t\tPod container image \"gcr.io/google_containers/pause:0.8.0\" already present on machine\n  Fri, 30 Oct 2015 01:13:29 +0000\tFri, 30 Oct 2015 01:13:29 +0000\t1\t{kubelet 172.17.4.99}\timplicitly required container POD\tcreated\t\tCreated with docker id 2843e181382d\n  Fri, 30 Oct 2015 01:13:29 +0000\tFri, 30 Oct 2015 01:13:29 +0000\t1\t{kubelet 172.17.4.99}\timplicitly required container POD\tstarted\t\tStarted with docker id 2843e181382d\n  Fri, 30 Oct 2015 01:13:29 +0000\tFri, 30 Oct 2015 01:13:29 +0000\t1\t{kubelet 172.17.4.99}\tspec.containers{cassandra}\t\tcreated\t\tCreated with docker id d77752ffb587\n  Fri, 30 Oct 2015 01:13:29 +0000\tFri, 30 Oct 2015 01:13:29 +0000\t1\t{kubelet 172.17.4.99}\tspec.containers{cassandra}\t\tstarted\t\tStarted with docker id d77752ffb587\n```\n\n#### 2.2. Service\u306e\u4f5c\u6210\nKubernetes\u3067\u306fService\u306f\u540c\u3058\u30bf\u30b9\u30af\u3092\u51e6\u7406\u3059\u308bPod\u306e\u96c6\u307e\u308a\u3068\u3057\u3066\u5b9a\u7fa9\u3055\u308c\u308b\u3002\n\n```cassandra-service.yaml\napiVersion: v1  #\u73fe\u5728\u306e\u30d0\u30fc\u30b8\u30e7\u30f3\u306fv1\nkind: Service  #Service\u306b\u3064\u3044\u3066\u5b9a\u7fa9\nmetadata:\n  labels:\n    name: cassandra\n  name: cassandra\nspec:\n  ports:\n    - port: 9042\n  selector: #query over labels(Pods\u306e\u30bb\u30c3\u30c8\uff09. \u3053\u306e\u30b5\u30fc\u30d3\u30b9\u306b\u6240\u5c5e\u3059\u308bPod\u3092\u9078\u629e\u3002\n    name: cassandra #\u3053\u306e\u4f8b\u3067\u306fcassandora\u3068\u3044\u3046label\u304c\u4ed8\u3044\u305fPod\u304c\u3053\u306eservice\u306b\u6240\u5c5e\n```\nService\u3092\u4f5c\u6210\u3002\n\n```\n$ kubectl create -f cassandra-service.yaml \nservices/cassandra\n```\nService\u304c\u4f5c\u6210\u3055\u308c\u3066\u3044\u308b\u304b\u78ba\u8a8d\n\n```\n$ kubectl get services\nNAME         LABELS                                    SELECTOR         IP(S)       PORT(S)\ncassandra    name=cassandra                            name=cassandra   10.3.0.80   9042/TCP\nkubernetes   component=apiserver,provider=kubernetes   <none>           10.3.0.1    443/TCP\n```\n\n```\n$ kubectl describe service cassandra\nName:\t\t\tcassandra\nNamespace:\t\tdefault\nLabels:\t\t\tname=cassandra\nSelector:\t\tname=cassandra\nType:\t\t\tClusterIP\nIP:\t\t\t10.3.0.80\nPort:\t\t\t<unnamed>\t9042/TCP\nEndpoints:\t\t10.2.67.6:9042\nSession Affinity:\tNone\nNo events.\n```\n\nPod\u5185\u306eContainer\u306e\u30ed\u30b0\u3092\u51fa\u529b\n\n```\n$ kubectl logs cassandra\n```\n\n#### 2.3. Replication Controller\u306e\u4f5c\u6210\nKubernetes\u306b\u3088\u308a\u3001Cassandra\u30af\u30e9\u30b9\u30bf\u3092\u5bb9\u6613\u306b\u69cb\u7bc9\u3001\u30b9\u30b1\u30fc\u30eb\u3059\u308b\u3053\u3068\u304c\u3067\u304d\u308b\u3002\nReplication Controller\u306f\u540c\u8cea\u306ePod\u306e\u30bb\u30c3\u30c8\u3092\u30ec\u30d7\u30ea\u30b1\u30fc\u30c8\u3059\u308b\u3002\u6307\u5b9a\u3059\u308bPod\u306e\u6570\u306b\u306a\u308b\u3088\u3046Pod\u3092add,remove\u3059\u308b\u3002\n\n```cassandra-controller.yaml\napiVersion: v1 #\u73fe\u5728\u306e\u30d0\u30fc\u30b8\u30e7\u30f3\u306fv1\nkind: ReplicationController #Replication Controller\u3092\u5b9a\u7fa9\nmetadata:\n  labels:\n    name: cassandra\n  name: cassandra\nspec:\n  replicas: 1 #replica\u306e\u6570\n  selector: #controller\u306eselector query\n    name: cassandra\n  template:\n    metadata:\n      labels:\n        name: cassandra\n    spec:\n      containers:\n        - command:\n            - /run.sh\n          resources:\n            limits:\n              cpu: 0.1\n          env:\n            - name: MAX_HEAP_SIZE\n              value: 512M\n            - name: HEAP_NEWSIZE\n              value: 100M\n            - name: POD_NAMESPACE\n              valueFrom:\n                fieldRef:\n                  fieldPath: metadata.namespace\n          image: gcr.io/google_containers/cassandra:v5\n          name: cassandra\n          ports:\n            - containerPort: 9042\n              name: cql\n            - containerPort: 9160\n              name: thrift\n          volumeMounts:\n            - mountPath: /cassandra_data\n              name: data\n      volumes:\n        - name: data\n          emptyDir: {}\n```\n\nController\u3092\u4f5c\u6210\u3059\u308b\n\n```\n$ kubectl create -f cassandra-controller.yaml \nreplicationcontrollers/cassandra\n```\nController\u304c\u4f5c\u6210\u3055\u308c\u3066\u3044\u308b\u304b\u78ba\u8a8d\u3059\u308b\n\n```\n$ kubectl get rc \nCONTROLLER   CONTAINER(S)   IMAGE(S)                                SELECTOR         REPLICAS\ncassandra    cassandra      gcr.io/google_containers/cassandra:v5   name=cassandra   1\n```\n\n```\n$ kubectl describe rc cassandra\nName:\t\tcassandra\nNamespace:\tdefault\nImage(s):\tgcr.io/google_containers/cassandra:v5\nSelector:\tname=cassandra\nLabels:\t\tname=cassandra\nReplicas:\t1 current / 1 desired\nPods Status:\t1 Running / 0 Waiting / 0 Succeeded / 0 Failed\nNo events.\n```\n\n#### 2.4. \u30af\u30e9\u30b9\u30bf\u3092\u30b9\u30b1\u30fc\u30eb\u30a2\u30a6\u30c8\u3001\u30b9\u30b1\u30fc\u30eb\u30a4\u30f3\npod\u6570\u30922\u3078\u30b9\u30b1\u30fc\u30eb\u30a2\u30a6\u30c8\u3059\u308b\u3002\n\n```\n$ kubectl scale rc cassandra --replicas=2\nscaled\n```\n\u30af\u30e9\u30b9\u30bf\u5185\u306epod\u4e00\u89a7\u3092\u51fa\u529b\u3057\u3001label name=cassandra\u3067\u30d5\u30a3\u30eb\u30bf\u30ea\u30f3\u30b0\u3059\u308b\u30022\u3064\u306ecassandra pod\u3092\u78ba\u8a8d\u3059\u308b\u3053\u3068\u304c\u3067\u304d\u308b\u3002 \n\n```\n$ kubectl get pods -l=\"name=cassandra\"\nNAME              READY     STATUS    RESTARTS   AGE\ncassandra         1/1       Running   0          10h\ncassandra-vb3mp   1/1       Running   0          1m\n```\n\n\u7247\u65b9\u306freplication controller\u306b\u3088\u3063\u3066\u751f\u6210\u3055\u308c\u305f\u30e9\u30f3\u30c0\u30e0\u306a\u6587\u5b57\u5217\u304c\u4ed8\u52a0\u3055\u308c\u3066\u3044\u308b\u3002\nnodetool\u3092\u4f7f\u7528\u3057\u3066\u3001\u6b63\u3057\u304f\u52d5\u4f5c\u3057\u3066\u3044\u308b\u304b\u30af\u30e9\u30b9\u30bf\u306e\u72b6\u614b\u3092\u8abf\u3079\u308b\u3002kubectl exec\u3092\u4f7f\u7528\u3057\u3001\u30b3\u30f3\u30c6\u30ca\u306e\u4e2d\u3067\u30b3\u30de\u30f3\u30c9\u3092\u5b9f\u884c\u3002(kubectl exec POD -c CONTAINER -- COMMAND [args...])\n-t\u3067stdin\u3092tty\u3001-i\u3067\u30b3\u30f3\u30c6\u30ca\u306b\u5bfe\u3057\u3066stdin\u3092pass\u3059\u308b\u3002\n\n```\ncore@localhost ~ $ kubectl exec -ti cassandra -- nodetool status\nDatacenter: datacenter1\n=======================\nStatus=Up/Down\n|/ State=Normal/Leaving/Joining/Moving\n--  Address    Load       Tokens  Owns (effective)  Host ID                               Rack\nDN  10.2.67.7  ?          256     100.0%            186ce662-cc93-4e6c-90f2-1c58ffd5834a  rack1\nUN  10.2.64.3  199.82 KB  256     100.0%            b5a7fb71-58f3-4870-8cf4-c8218feb46e6  rack1\n```\n\ncqlsh\u3092\u5b9f\u884c\u3002\u3053\u306e\u3068\u6307\u5b9a\u3059\u308b\u306e\u306fService\u306eIP\u30a2\u30c9\u30ec\u30b9\u3082\u3057\u304f\u306f\u30b5\u30fc\u30d3\u30b9\u540d\u3002\n\n```\n$ kubectl get service cassandra\nNAME        LABELS           SELECTOR         IP(S)       PORT(S)\ncassandra   name=cassandra   name=cassandra   10.3.0.80   9042/TCP\n\n$ kubectl exec -ti cassandra -- cqlsh 10.3.0.80    \nConnected to Test Cluster at 10.3.0.80:9042.\n[cqlsh 5.0.1 | Cassandra 2.1.7 | CQL spec 3.2.0 | Native protocol v3]\nUse HELP for help.\ncqlsh> \n\n$ kubectl exec -ti cassandra -- cqlsh cassandra.default.cluster.local\n```\n\n\u74b0\u5883\u306e\u69cb\u7bc9\u3001\u30b9\u30b1\u30fc\u30eb\u30a2\u30a6\u30c8\u306a\u3069\u306f\u975e\u5e38\u306b\u901f\u304f\u3001\u3057\u304b\u3082\u5bb9\u6613\u3067\u3042\u308b\u3053\u3068\u3092\u5b9f\u611f\u3002\u6b21\u304b\u3089\u306f\u30c9\u30ad\u30e5\u30e1\u30f3\u30c8\u30d9\u30fc\u30b9\u3067\u3069\u3046\u3044\u3046\u4ed5\u7d44\u307f\u306a\u306e\u304b\u3092\u8abf\u3079\u3066\u307f\u308b\u3002\u3002\n\n\n\n", "tags": ["kubernetes", "docker"]}