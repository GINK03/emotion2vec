{"context": "GitHub \u306b\u3042\u308b DingKe/qrnn/ \u306e \u30b5\u30f3\u30d7\u30eb\u30b3\u30fc\u30c9 imbd_qrnn.py \n\nhttps://github.com/DingKe/qrnn/\n\n\u306f\u3001\n\nfrom keras.datasets import imdb\n\n\u3067\u3001keras\u306e\u7d44\u307f\u8fbc\u307f\u30c7\u30fc\u30bf\u30bb\u30c3\u30c8 imdb \u3092 \u8aad\u307f\u8fbc\u3093\u3067 \u3044\u308b\u3002\n\u3053\u306e\u30c7\u30fc\u30bf\u306f\u3001\u4ee5\u4e0b \u306e \u516c\u5f0f\u89e3\u8aac \u306b \u3088\u308b \u3068\u3001\n\nKeras Documentation \u30c7\u30fc\u30bf\u30bb\u30c3\u30c8 \u300cIMDB\u6620\u753b\u30ec\u30d3\u30e5\u30fc\u611f\u60c5\u5206\u985e\u300d\n\n\nIMDB\u6620\u753b\u30ec\u30d3\u30e5\u30fc\u611f\u60c5\u5206\u985e\n\u611f\u60c5(\u80af\u5b9a/\u5426\u5b9a)\u306e\u30e9\u30d9\u30eb\u4ed8\u3051\u3092\u3055\u308c\u305f\u300125,000\u306eIMDB\u6620\u753b\u30ec\u30d3\u30e5\u30fc\u306e\u30c7\u30fc\u30bf\u30bb\u30c3\u30c8\u3002\u30ec\u30d3\u30e5\u30fc\u306f\u524d\u51e6\u7406\u6e08\u307f\u3067\u3001\u5404\u30ec\u30d3\u30e5\u30fc\u306f\u5358\u8a9e\u306e\u30a4\u30f3\u30c7\u30c3\u30af\u30b9(\u6574\u6570\u5024)\u306e\u30b7\u30fc\u30b1\u30f3\u30b9\u3068\u3057\u3066\u30a8\u30f3\u30b3\u30fc\u30c9\u3055\u308c\u3066\u3044\u308b\u3002\u4fbf\u5b9c\u4e0a\u3001\u5358\u8a9e\u306f\u30c7\u30fc\u30bf\u30bb\u30c3\u30c8\u306b\u304a\u3044\u3066\u306e\u51fa\u73fe\u983b\u5ea6\u306b\u3088\u3063\u3066\u30a4\u30f3\u30c7\u30c3\u30af\u30b9\u3055\u308c\u3066\u3044\u308b\u3002\u305d\u306e\u305f\u3081\u4f8b\u3048\u3070\u3001\u6574\u6570\u5024\"3\"\u306f\u30c7\u30fc\u30bf\u306e\u4e2d\u30673\u756a\u76ee\u306b\u983b\u5ea6\u304c\u591a\u3044\u5358\u8a9e\u306b\u30a8\u30f3\u30b3\u30fc\u30c9\u3055\u308c\u308b\u3002\u3053\u308c\u306b\u3088\u3063\u3066\"\u4e0a\u4f4d20\u500b\u306e\u983b\u51fa\u8a9e\u3092\u9664\u3044\u305f\u3001\u4e0a\u4f4d10,000\u500b\u306e\u983b\u51fa\u8a9e\u306b\u3064\u3044\u3066\u306e\u307f\u8003\u3048\u308b\"\u3068\u3044\u3046\u3088\u3046\u306a\u30d5\u30a3\u30eb\u30bf\u30ea\u30f3\u30b0\u4f5c\u696d\u3092\u9ad8\u901f\u306b\u884c\u3046\u3053\u3068\u304c\u3067\u304d\u308b\u3002\n\u6163\u4f8b\u3068\u3057\u3066\u3001\"0\"\u306f\u7279\u5b9a\u306e\u5358\u8a9e\u3092\u8868\u3059\u306e\u3067\u306f\u306a\u304f\u3001\u4ee3\u308f\u308a\u306b\u672a\u77e5\u306e\u5358\u8a9e\u306b\u30a8\u30f3\u30b3\u30fc\u30c9\u3055\u308c\u308b\u3053\u3068\u306b\u306a\u3063\u3066\u3044\u308b\u3002\n\nfrom keras.datasets import imdb\n\n(X_train, y_train), (X_test, y_test) = imdb.load_data(path=\"imdb_full.pkl\",\n                                                     nb_words=None,\n                                                     skip_top=0,\n                                                     maxlen=None,\n                                                     seed=113,\n                                                     start_char=1,\n                                                     oov_char=2,\n                                                     index_from=3)\n\n\n\u8fd4\u308a\u5024:\n2\u3064\u306e\u30bf\u30d7\u30eb:\nX_train, X_test: \u30b7\u30fc\u30b1\u30f3\u30b9\u306e\u30ea\u30b9\u30c8\u3001\u30ea\u30b9\u30c8\u306f\u30a4\u30f3\u30c7\u30c3\u30af\u30b9(\u6574\u6570\u5024)\u3002\u5f15\u6570nb_words\u306b\u5177\u4f53\u7684\u306a\u6574\u6570\u5024\u304c\u4e0e\u3048\u3089\u308c\u305f\u5834\u5408\u3001\u53d6\u308a\u5f97\u308b\u30a4\u30f3\u30c7\u30c3\u30af\u30b9\u306e\u6700\u5927\u5024\u306fnb_words-1\u3068\u306a\u308b\u3002\u5f15\u6570maxlen\u306b\u5177\u4f53\u7684\u306a\u6570\u5024\u304c\u4e0e\u3048\u3089\u308c\u305f\u5834\u5408\u3001\u30b7\u30fc\u30b1\u30f3\u30b9\u306e\u6700\u5927\u9577\u306fmaxlen\u3068\u306a\u308b\u3002\ny_train, y_test: integer\u578b\u30e9\u30d9\u30eb(1\u307e\u305f\u306f0)\u306e\u30ea\u30b9\u30c8\u3002\n\n\u3068\u306e\u3053\u3068\u3002\n\u3064\u307e\u308a\u3001\u30e2\u30c7\u30eb\u5b66\u7fd2\u30d5\u30a7\u30fc\u30ba \u53ca\u3073 \u30e2\u30c7\u30eb\uff08\u5206\u985e\uff09\u4e88\u6e2c\u7cbe\u5ea6\u306e\u691c\u8a3c\u30d5\u30a7\u30fc\u30ba \u3067\u306f\u3001\u4ee5\u4e0b \u306e \u5f62\u5f0f\u306e\u30c7\u30fc\u30bf \u3092 \u5165\u529b\u5024 \u3068\u3057\u3066 \u53d7\u3051\u53d6\u308b\u3002\n\n\n\n\u6587\u7ae0\u30c7\u30fc\u30bf: \u5358\u8a9eID\u3000\uff08Int\u578b\u30aa\u30d6\u30b8\u30a7\u30af\u30c8\uff09\u3092\u8981\u7d20\u306b\u6301\u3064list\u578b\u30aa\u30d6\u30b8\u30a7\u30af\u30c8\n\n\u3092\u53d7\u3051\u53d6\u308a\u3001\u540c\u6642\u306b\u3001\u6587\u7ae0\u306e\uff12\u5024\u5206\u985e\u30af\u30e9\u30b9\u30e9\u30d9\u30eb\uff08\u300c\u80af\u5b9a\u300dor\u300c\u5426\u5b9a\u300d\u306e\u611f\u60c5\u30dd\u30b8\u30cd\u30ac \u30e9\u30d9\u30eb\uff09\u3068\u3057\u3066\u3001\n\n\n\u6587\u7ae0\u30af\u30e9\u30b9\u5206\u985e\u30e9\u30d9\u30eb\uff08\u611f\u60c5\u30dd\u30b8\u30cd\u30ac\uff12\u5024\u30e9\u30d9\u30eb\uff09: 0 or 1 \uff08Int\u578b\u30aa\u30d6\u30b8\u30a7\u30af\u30c8\uff09\n\n\n\u307e\u3068\u3081\u308b \u3068\u3001Int\u578b\u306e\u6570\u5024\u304c\u6642\u9593\u9806\u5e8f \u306b \u4e26\u3076 \u6570\u5024\u6642\u7cfb\u5217\u30c7\u30fc\u30bf\uff08list\u578b\uff09 \u3092 \u53d7\u3051\u3068\u308b\u30b9\u30af\u30ea\u30d7\u30c8 \u306b \u306a\u3063\u3066\u3044\u308b\u3002\n\u3053\u306e\u305f\u3081\u3001imbd_qrnn.py \u3000\u306f\u3001\u30b3\u30fc\u30c9\u3092\u66f8\u304d\u63db\u3048\u305a \u306b\u3001\u4ee5\u4e0b \u306e \u7d4c\u6e08\u91d1\u878d\u30c7\u30fc\u30bf\u306e\u3088\u3046 \u306a\u3001\u81ea\u7136\u8a00\u8a9e\u30c6\u30ad\u30b9\u30c8 \u4ee5\u5916 \u306e \u6642\u7cfb\u5217 \u6570\u5024\u30c7\u30fc\u30bf \u306e \uff12\u5024\u5206\u985e\u30bf\u30b9\u30af \u3082 \u884c\u3048\u308b\u306f\u305a\u3067\u3042\u308b\u3002\n\n( \u30bf\u30b9\u30af\u4f8b )\n\n\n\uff08\uff11\u9298\u67c4 \uff09 \u682a\u4fa1 \u306e \u300c\u5024\u4e0a\u304c\u308a\u5c40\u9762\u300d\u30fb\u300c\u5024\u4e0b\u304c\u308a\u5c40\u9762\u300d \uff12\u5024\u5206\u985e\u30bf\u30b9\u30af\n\n\n\u3010 \u5b66\u7fd2\u7528 \u53ca\u3073 \u691c\u8a3c\u7528 \u30c7\u30fc\u30bf\u5f62\u5f0f \u3011\n\n\n\n\u30c7\u30fc\u30bf\uff1a \u3042\u308b\uff11\u9298\u67c4\u306e\u682a\u4fa1\u306e\u5024\u52d5\u304d\u30c7\u30fc\u30bf\u3000\uff1d Int\u578b \u5e02\u5834\u4fa1\u683c \u306e\u5206\u6b21\u3001\u79d2\u6642etc \u6570\u5024\u30ea\u30b9\u30c8\n\n\u6559\u5e2b\u30e9\u30d9\u30eb\uff1a \u300c\u5024\u4e0a\u304c\u308a\u5c40\u9762\u300d\u30e9\u30d9\u30eb\uff1d\uff11 or \u300c\u5024\u4e0b\u304c\u308a\u5c40\u9762\u300d\u30e9\u30d9\u30eb= 0\n\n\n\n\u4ee5\u4e0b\u3001\u30c7\u30fc\u30bf\u30bb\u30c3\u30c8\u306e\u5185\u5bb9 \u3092 \u78ba\u8a8d\u3057\u305f\u7d50\u679c\n\n\nimbd_qrnn.p \u306e \u30c7\u30fc\u30bf\u53d6\u5f97\u90e8\u5206 \u306e \u30b3\u30fc\u30c9\n\n\nDingKe/qrnn/qrnn/imbd_qrnn.py\nfrom __future__ import print_function\nimport numpy as np\nnp.random.seed(1337)  # for reproducibility\n\nfrom keras.preprocessing import sequence\nfrom keras.utils import np_utils\nfrom keras.models import Sequential\nfrom keras.layers import Dense, Dropout, Activation, Embedding\nfrom keras.layers import LSTM, SimpleRNN, GRU\nfrom keras.regularizers import l2\nfrom keras.constraints import maxnorm\nfrom keras.datasets import imdb\n\n\uff08 \u4e2d\u7565 \uff09\n\nmax_features = 20000\nmaxlen = 80  # cut texts after this number of words (among top max_features most common words)\nbatch_size = 32 \n\n\nprint('Loading data...')\n(X_train, y_train), (X_test, y_test) = imdb.load_data(nb_words=max_features)\nprint(len(X_train), 'train sequences')\nprint(len(X_test), 'test sequences')\n\nprint('Pad sequences (samples x time)')\nX_train = sequence.pad_sequences(X_train, maxlen=maxlen)\nX_test = sequence.pad_sequences(X_test, maxlen=maxlen)\nprint('X_train shape:', X_train.shape)\nprint('X_test shape:', X_test.shape)\n\n\n\n\u4ee5\u4e0b\u3001\u30e2\u30c7\u30eb\u5b66\u7fd2\u7528\u306e\u30c7\u30fc\u30bf\u3068\u6559\u5e2b\u30e9\u30d9\u30eb\u3001\u30e2\u30c7\u30eb\u691c\u8a3c\u7528\u306e\u30c7\u30fc\u30bf\u3068\u6559\u5e2b\u30e9\u30d9\u30eb \u306e \u4e2d\u8eab \u3092 \u78ba\u8a8d\n\n\nPython 3.5.1 (anaconda3-2.5.0)\n(anaconda3-2.5.0) HirofumiYashima-no-MacBook:~ hirofumiyashima$ python --version\nPython 3.5.1 :: Anaconda 2.5.0 (x86_64)\n(anaconda3-2.5.0) HirofumiYashima-no-MacBook:~ hirofumiyashima$ \n(anaconda3-2.5.0) HirofumiYashima-no-MacBook:~ hirofumiyashima$ python\nPython 3.5.1 |Anaconda 2.5.0 (x86_64)| (default, Dec  7 2015, 11:24:55) \n[GCC 4.2.1 (Apple Inc. build 5577)] on darwin\nType \"help\", \"copyright\", \"credits\" or \"license\" for more information.\n>>> \n>>> from __future__ import print_function\n>>> import numpy as np\n>>> np.random.seed(1337)\n>>> \n>>> from keras.preprocessing import sequence\nUsing TensorFlow backend.\n>>> \n>>> from keras.utils import np_utils\n>>> from keras.models import Sequential\n>>> from keras.layers import Dense, Dropout, Activation, Embedding\n>>> from keras.layers import LSTM, SimpleRNN, GRU\n>>> from keras.regularizers import l2\n>>> from keras.constraints import maxnorm\n>>> from keras.datasets import imdb\n>>> \n>>> max_features = 20000\n>>> maxlen = 80\n>>> batch_size = 32 \n>>> \n>>> (X_train, y_train), (X_test, y_test) = imdb.load_data(nb_words=max_features)\n>>> print(len(X_train), 'train sequences')\n25000 train sequences\n>>> \n>>> print(len(y_train))\n25000\n>>> \n\n\n\n\u5b66\u7fd2\u7528\u30c7\u30fc\u30bf \u306f Int\u306e\u4e26\u3073\uff08\u5358\u8a9eID\u756a\u53f7 \u306e \u6642\u9593\u7cfb\u5217\uff09\n\n\nPython 3.5.1 (anaconda3-2.5.0)\n>>> print(X_train[0])\n[1, 14, 22, 16, 43, 530, 973, 1622, 1385, 65, 458, 4468, 66, 3941, 4, 173, 36, 256, 5, 25, 100, 43, 838, 112, 50, 670, 2, 9, 35, 480, 284, 5, 150, 4, 172, 112, 167, 2, 336, 385, 39, 4, 172, 4536, 1111, 17, 546, 38, 13, 447, 4, 192, 50, 16, 6, 147, 2025, 19, 14, 22, 4, 1920, 4613, 469, 4, 22, 71, 87, 12, 16, 43, 530, 38, 76, 15, 13, 1247, 4, 22, 17, 515, 17, 12, 16, 626, 18, 19193, 5, 62, 386, 12, 8, 316, 8, 106, 5, 4, 2223, 5244, 16, 480, 66, 3785, 33, 4, 130, 12, 16, 38, 619, 5, 25, 124, 51, 36, 135, 48, 25, 1415, 33, 6, 22, 12, 215, 28, 77, 52, 5, 14, 407, 16, 82, 10311, 8, 4, 107, 117, 5952, 15, 256, 4, 2, 7, 3766, 5, 723, 36, 71, 43, 530, 476, 26, 400, 317, 46, 7, 4, 12118, 1029, 13, 104, 88, 4, 381, 15, 297, 98, 32, 2071, 56, 26, 141, 6, 194, 7486, 18, 4, 226, 22, 21, 134, 476, 26, 480, 5, 144, 30, 5535, 18, 51, 36, 28, 224, 92, 25, 104, 4, 226, 65, 16, 38, 1334, 88, 12, 16, 283, 5, 16, 4472, 113, 103, 32, 15, 16, 5345, 19, 178, 32]\n>>> \n>>> print(X_train[1])\n[1, 194, 1153, 194, 8255, 78, 228, 5, 6, 1463, 4369, 5012, 134, 26, 4, 715, 8, 118, 1634, 14, 394, 20, 13, 119, 954, 189, 102, 5, 207, 110, 3103, 21, 14, 69, 188, 8, 30, 23, 7, 4, 249, 126, 93, 4, 114, 9, 2300, 1523, 5, 647, 4, 116, 9, 35, 8163, 4, 229, 9, 340, 1322, 4, 118, 9, 4, 130, 4901, 19, 4, 1002, 5, 89, 29, 952, 46, 37, 4, 455, 9, 45, 43, 38, 1543, 1905, 398, 4, 1649, 26, 6853, 5, 163, 11, 3215, 10156, 4, 1153, 9, 194, 775, 7, 8255, 11596, 349, 2637, 148, 605, 15358, 8003, 15, 123, 125, 68, 2, 6853, 15, 349, 165, 4362, 98, 5, 4, 228, 9, 43, 2, 1157, 15, 299, 120, 5, 120, 174, 11, 220, 175, 136, 50, 9, 4373, 228, 8255, 5, 2, 656, 245, 2350, 5, 4, 9837, 131, 152, 491, 18, 2, 32, 7464, 1212, 14, 9, 6, 371, 78, 22, 625, 64, 1382, 9, 8, 168, 145, 23, 4, 1690, 15, 16, 4, 1355, 5, 28, 6, 52, 154, 462, 33, 89, 78, 285, 16, 145, 95]\n>>>\n\n\n\n\u5b66\u7fd2\u7528\u30c7\u30fc\u30bf\u306e\u6b63\u89e3\u6559\u5e2b\u30e9\u30d9\u30eb\u306f\u30012\u5024\u5206\u985e\u306e\u30af\u30e9\u30b9\u30e9\u30d9\u30eb\uff080 \u3082\u3057\u304f\u306f 1\uff09\n\n\nPython 3.5.1 (anaconda3-2.5.0)\n>>> print(y_train[0])\n1\n>>> \n>>> print(y_train[1])\n0\n>>>\n>>> print(y_train[0:20])\n[1 0 0 1 0 0 1 0 1 0 1 0 0 0 0 0 1 1 0 1]\n>>>\n\n\n\n\u691c\u8a3c\u7528\u30c7\u30fc\u30bf \u3082 \u540c\u69d8\n\n\uff08 \u30c7\u30fc\u30bf\u306e\u4e2d\u8eab \uff09\n\nPython 3.5.1 (anaconda3-2.5.0)\n>>> print(X_test[0])\n[1, 89, 27, 2, 9289, 17, 199, 132, 5, 4191, 16, 1339, 24, 8, 760, 4, 1385, 7, 4, 22, 1368, 11415, 16, 5149, 17, 1635, 7, 2, 1368, 9, 4, 1357, 8, 14, 991, 13, 877, 38, 19, 27, 239, 13, 100, 235, 61, 483, 11960, 4, 7, 4, 20, 131, 1102, 72, 8, 14, 251, 27, 1146, 7, 308, 16, 735, 1517, 17, 29, 144, 28, 77, 2305, 18, 12]\n>>> \n>>> print(X_test[1])\n[1, 3452, 7, 16495, 517, 522, 31, 314, 17, 1909, 2046, 11778, 6829, 11424, 83, 4, 2314, 673, 33, 27, 568, 1709, 2923, 32, 4, 189, 22, 11, 975, 4135, 29, 2376, 4, 1287, 7, 4, 16495, 4217, 15, 1435, 455, 1394, 848, 1538, 4031, 96, 145, 11, 4, 204, 6156, 297, 5418, 29, 3044, 4, 1287, 8, 35, 4383, 1609, 121, 15286, 1233, 980, 2, 2100, 11627, 18273, 2, 3681, 304, 4, 1287, 145, 8, 41, 1472, 50, 2, 10737, 2, 16495, 4364, 34, 2782, 13092, 145, 295, 174, 772, 6, 2, 18, 274, 961, 90, 145, 8, 4041, 113, 155, 92, 140, 17, 2, 69, 3205, 16495, 505, 46, 24, 8, 30, 4, 132, 7, 41, 1306, 103, 32, 38, 59, 9560, 90, 11, 6, 297, 7389, 33, 63, 16495, 9, 329, 74, 654, 137, 2, 304, 6, 4548, 16495, 2949, 2, 41, 772, 15, 274, 961, 41, 145, 8, 113, 11, 4, 2995, 7, 6, 668, 4217, 1810, 17, 6, 3452, 1082, 181, 8, 30, 1571, 11, 3161, 2350, 28, 8, 157, 295, 8, 79, 8, 6, 6068, 11, 162, 6869, 121, 15286, 1249, 648, 69, 77, 3554, 19, 4, 2, 887, 8, 4416, 68, 4123, 145, 83, 406, 2350, 4, 2350, 7, 2, 13174, 3509, 1851, 27, 980, 18288, 10512, 2, 37, 26, 199, 23, 4, 521, 39, 3408, 1697, 2297, 7, 568, 3864, 2, 308, 3659, 80, 81, 1780, 10, 10, 526, 34, 10605, 18317, 13, 119, 3452, 7, 16495, 4, 229, 34, 1561, 2, 9, 87, 253, 55, 702, 728, 545, 441, 2072, 958, 7, 85, 189, 22, 19, 52, 5499, 39, 4, 636, 720, 121, 75, 67, 1655, 19161, 9792, 2377, 39, 4, 2553, 4, 4971, 108, 2281, 2, 6997, 4626, 10852, 39, 4, 6, 1726, 23, 4903, 890, 201, 488, 4664, 2377, 39, 4, 2195, 3135, 8, 4, 2974, 343, 39, 3452, 7, 5279, 10074, 54, 12, 2360, 19062, 4, 172, 136, 3452, 7, 16495, 115, 304, 410, 615, 63, 9, 43, 17, 73, 50, 26, 775, 7, 31, 2433, 532, 19266, 1994, 15, 2039, 4142, 93, 9032, 6, 171, 153, 908, 12, 152, 306, 1595, 8, 9155, 253, 33, 410, 4, 189, 512, 11, 831, 13, 119, 4, 136, 54, 3509, 18288, 26, 260, 6, 2711, 2, 731, 2599, 15, 16495, 5224, 29, 166, 163, 2, 795, 7320, 469, 198, 24, 8, 135, 15, 50, 218, 6, 1543, 52, 22, 11, 50, 17, 73, 88, 50, 91, 434, 9, 167, 18317, 1030, 8, 987, 52, 841, 6, 147, 281, 7, 253, 199, 406, 3161, 732, 7, 105, 26, 1451, 4091, 17, 257, 2162, 2712, 68, 205, 732, 7, 4816, 712, 15, 4, 4951, 7, 5512, 15, 36, 26, 1200, 496, 62, 540, 1203, 2536, 3452, 7, 16495, 9, 87, 18, 4, 91, 173, 47, 15, 194, 352, 6713, 44, 12, 33, 44, 2476, 1782, 1782, 13, 144, 440, 38, 4, 64, 155, 15, 13, 80, 135, 9, 15, 49, 7, 4, 5076, 302, 34, 1842, 26, 6, 117, 3463, 2631, 13, 191, 377, 101, 1683, 139, 11, 3452, 7, 16495, 345, 2670, 4, 22, 152, 9185, 4, 541, 599, 19, 6, 646, 12337, 3681, 5573, 15348, 83, 4472, 393, 11, 3532, 6, 14559, 5003, 3490, 84, 13058, 23, 2, 7, 3062, 294, 112, 2, 34, 6, 666, 2832, 6, 3314, 125, 5484, 12318, 998, 2, 13266, 4, 116, 9, 184, 52, 13092, 17, 16495, 9, 55, 163, 17, 29, 14578, 4, 31, 2433, 46, 13, 82, 40, 4, 139, 19, 2, 33, 4, 454, 169, 41, 55, 1279, 54, 442, 1658, 32, 15, 7717, 5745, 13, 191, 30, 4, 64, 31, 1348, 13, 1276, 104, 3452, 7, 16495, 9, 6, 777, 22, 964, 722, 39, 380, 8, 1363, 87, 1285, 189, 11, 3215, 4160, 33, 64, 7304, 234, 196, 12, 115, 461, 357, 42, 753, 6, 965, 1640, 7, 1923, 106, 12, 17, 515, 17, 25, 70]\n>>>\n\n\n\uff08 \u6b63\u89e3\u30e9\u30d9\u30eb \u306e \u4e2d\u8eab \uff09\n\nPython 3.5.1 (anaconda3-2.5.0)\n>>> print(y_test[0])\n1\n>>> \n>>> print(y_test[1])\n1\n>>> \n>>> print(y_test[0:20])\n[1 1 1 1 1 0 0 0 1 1 1 1 1 1 1 1 1 0 0 1]\n>>> \n\n\n\nQRNN \u3067 \u6570\u5024\u6642\u7cfb\u5217\u30c7\u30fc\u30bf\u306e\uff12\u5024\u5206\u985e\u30bf\u30b9\u30af \u3092 \u5b9f\u884c\u3057\u3066\u307f\u3088\u3046\u3002\n\n\u307e\u305a\u306f\u3001\n\n\uff08\u5b66\u7fd2\u5bfe\u8c61\uff09 \u5468\u671f\u3068\u632f\u5e45\u306e\u7570\u306a\u308b sin\u66f2\u7dda  \u306e 2\u30d1\u30bf\u30fc\u30f3 \uff08\u6559\u5e2b\u30e9\u30d9\u30eb\uff1a \uff12\u5024\u30af\u30e9\u30b9\u30e9\u30d9\u30eb\uff08 0 or 1 \uff09\uff09\n\uff08\u4e88\u6e2c\u7cbe\u5ea6\u691c\u8a3c\u6bb5\u968e\uff09 \u65b0\u898f\u30c7\u30fc\u30bf \u306e \u6240\u5c5e\u30af\u30e9\u30b9 \u3092 \u5206\u985e\u7cbe\u5ea6 \u3092 \u691c\u8a3c\n\n\u30bf\u30b9\u30af \u304b\u3089\u3001\u59cb\u3081\u3066\u307f\u305f\u3044\u3002\n\n\u3010 \u767a\u5c55\u601d\u8003 \u3011\n\n\n\u591a\u5909\u91cf\u6642\u7cfb\u5217\u30c7\u30fc\u30bf \u306e \u5206\u985e\u30fb\u56de\u5e30\u554f\u984c\n\n\n\u56de\u5e30\u554f\u984c\uff08\u56de\u5e30\u4e88\u6e2c\uff09 \u3082 \u884c\u3044\u305f\u3044\u3002\n\n\u6642\u7cfb\u5217\u30c7\u30fc\u30bf \u306e \u56de\u5e30\u4e88\u6e2c\u554f\u984c\uff08regression, prediction, forecast\uff09 \u3082\u3001 \u6b21\u306b\u304f\u308b\u5358\u8a9e\u3092\u4e88\u6e2c\u3059\u308bNLP\u30bf\u30b9\u30af\u306b\u53d6\u308a\u7d44\u3080QRNN\u5148\u884c\u4e8b\u4f8b \u3092 \u624b\u7acb\u3066 \u306b\u3001NLP \u4ee5\u5916 \u306e \u6570\u5024\u6642\u7cfb\u5217\u30c7\u30fc\u30bf \u3092 \u4f7f\u3063\u3066 \u5b9f\u884c\u3057\u3066\u307f\u305f\u3044\u3002\n\n\u591a\u5909\u91cf\u6642\u7cfb\u5217\u30c7\u30fc\u30bf \u306e \u5206\u985e\u30fb\u56de\u5e30\u554f\u984c\n\n\u3055\u3089 \u306b\u3001\u8907\u6570\u306e\u6570\u5024\u6642\u7cfb\u5217\u30c7\u30fc\u30bf \u306e \u6642\u9593\u5909\u52d5 \u5168\u4f53 \u3092\u30013D-CNN\u306e\u30a4\u30e1\u30fc\u30b8 \u3067\u3001 (multi-dimensional ?) QRNN \u30e2\u30c7\u30eb\u306e\u3088\u3046\u306a\u3082\u306e\u3067\u5b66\u7fd2\u3055\u305b\u308b\u3053\u3068 \u3092 \u5b9f\u73fe\u3067\u304d\u306a\u3044\u3060\u308d\u3046\u304b\uff1f\nRNN \u3084 LSTM \u3092\u7528\u3044\u3066\u3001\uff08\u53ef\u5909\u9577\uff09\u6642\u7cfb\u5217\u30c7\u30fc\u30bf \u306e \u5206\u985e\u30bf\u30b9\u30af \u306b\u53d6\u308a\u7d44\u3093\u3060 \u4e8b\u4f8b \u304c \u3042\u308b\u3002\n\n\u3086\u308b\u3075\u308f\u3081\u3082 \uff082016/10/09\uff09\u300cLSTM\u3067\u5206\u985e\u554f\u984c\u3092\u89e3\u304f(Python)\u300d\nHatena Blog \u3082\u3061\u3082\u3061\u3057\u3066\u3044\u308b (2015/12/07\uff09 \u300cRecurrent NN\u3067\u6587\u66f8\u306e\u30dd\u30b8\u30cd\u30ac\u5224\u5b9a\u3059\u308b\uff08\u30e2\u30c7\u30eb\u8003\u6848\u7de8\uff09\u300d \nLSTM Networks for Sentiment Analysis\n\n\u307e\u305f\u3001RNN \u3084 LSTM \u3067\u3001\u591a\u5909\u91cf\u30c7\u30fc\u30bf\uff08\u8907\u6570\u306e\u6642\u9593\u7cfb\u5217\u30c7\u30fc\u30bf\uff09\u306b \u5bfe\u3059\u308b \u5206\u985e\u30bf\u30b9\u30af \u306b\u53d6\u308a\u7d44\u3080\u65b9\u6cd5 \u306b \u3064\u3044\u3066\u3082\u3001\u4ee5\u4e0b \u306e\u3088\u3046 \u306b \u8b70\u8ad6 \u304c \u306a\u3055\u308c\u3066\u3044\u308b\u3002\n\uff08 Multi-dimensional RNN \u3084 Multi-Dimensional LSTM \u3067\u306f\u3001\u7e26\u6a2a\u5965\u884c\u304d\u7b49\u3001\uff12\u6b21\u5143\u4ee5\u4e0a \u306e \u5e83\u304c\u308a \u3092 \u6301\u3064\u5165\u529b\u30c7\u30fc\u30bf \u3092 \u6271\u3046\u3053\u3068 \u304c \u3067\u304d\u308b \uff09\n\nAlex Graves, Santiago Ferna \u0301ndez, Ju \u0308rgen Schmidhuber, Multi-Dimensional Recurrent Neural Networks\nGoogle group LSTM for classification of multidimensional time series with different lengths\n\n\nHi guys,\nI am trying to setup a neural network with a forward and a backward LSTM hidden layers for the classification of time series.\nThe time series have different time steps (sequences with different lengths) and have 9 dimensions. \nI have loaded the time series so that the shape is (batch size, max sequence length, number of features).\nThe mask per sequence is an vector having 1 for each timestep lower than the sequence length, and 0 for every timestep higher than the sequence length.\nBecause the purpose is classification it should have one output neuron to classify the entire sequence as 0 or 1.\nI have constructed the following network, do you think this model would be appropriate for classification?\n\n\nstackoverflow Multivariate time-series RNN using Tensorflow. Is this possible with an LSTM cell or similar?\nQuora How can I predict multivariate time series with LSTM, RNN or CNN?\n\n\nLet\u2019s say we record the price of A, B and C stocks every minute 10000 times. \nHow can I predict the price of A? \nCan I predict the price of A, B and C at the same time? I\u2019m looking for a simple python script.\n\n\nZhengping Che et.al, RECURRENT NEURAL NETWORKS FOR MULTIVARI- ATE TIME SERIES WITH MISSING VALUES\nAnvardh Nanduri and Lance Sherry, ANOMALY DETECTION IN AIRCRAFT DATA USING RECURRENT NEURAL NETWORKS (RNN)\n\n\nIn addition, by accepting sequences of multivariate data points as input and treating them as time series data, pre-trained RNNs models can be used for real-time anomaly detection on-board the aircraft.\n\n\n\u5869\u91ce \u525b\u5fd7\uff08\u30af\u30ec\u30c7\u30a3\u30fb\u30b9\u30a4\u30b9\u8a3c\u5238\u682a\u5f0f\u4f1a\u793e \u7d4c\u6e08\u8abf\u67fb\u90e8\uff09 \u300c\u6df1\u5c64\u5b66\u7fd2\u3068\u30a6\u30a7\u30fc\u30d6\u30ec\u30c3\u30c8\u3092\u7528\u3044\u305f\u591a\u5909\u91cf\u6642\u7cfb\u5217\u4e88\u6e2c\u5668\u300d\n\n\n1.\u306f\u3058\u3081\u306b1\n1) \u6642\u7cfb\u5217\u89e3\u6790(FAVAR)\u30012) \u6df1\u5c64\u5b66\u7fd2 (Stacked-LSTM)\u30013) \u30a6\u30a7\u30fc\u30d6\u30ec\u30c3\u30c8\u89e3\u6790\u3001\u306e 3 \u3064 \u3092\u7d44\u307f\u5408\u308f\u305b\u308b\u3053\u3068\u3067\u3001\u70ba\u66ff\u3001\u682a\u4fa1\u3001\u9271\u5de5\u696d\u751f\u7523\u306a \u3069\u3001\u69d8\u3005\u306a\u6642\u7cfb\u5217\u30c7\u30fc\u30bf\u306b\u5bfe\u3057\u3066\u4e00\u5b9a\u306e\u4e88\u6e2c\u529b\u3092\u78ba \u4fdd\u3067\u304d\u308b\u4eba\u5de5\u77e5\u80fd\u4e88\u6e2c\u5668(\u4ee5\u4e0b\u3001\u4e88\u6e2c\u5668)\u3092\u958b\u767a\u3057\u305f\u3002\n\u3053\u306e\u4e88\u6e2c\u5668\u306f\u3001\u4efb\u610f\u306b\u96c6\u3081\u305f\u5927\u91cf\u306e\u6642\u7cfb\u5217\u30c7\u30fc \u30bf\u304b\u3089\u3001\u76ee\u6a19\u3068\u3059\u308b\u5909\u6570\u306e\u4e88\u60f3\u306b\u5f79\u7acb\u3064\u30d1\u30bf\u30fc\u30f3\u3092 \u767a\u898b\u3057\u3001\u6709\u9650\u500b\u306e\u30d5\u30a1\u30af\u30bf\u30fc\u306b\u96c6\u7d04\u3059\u308b\u3002\n\u63a8\u5b9a\u3055\u308c\u305f\u30d5\u30a1\u30af\u30bf\u30fc\u306f\u3001\u5927\u91cf\u306e\u6642\u7cfb\u5217\u30c7\u30fc\u30bf\u3092\u30a6\u30a9\u30c3\u30c1\u3059 \u308b\u3053\u3068\u3067\u4e88\u6e2c\u5668(AI)\u304c\u62b1\u3044\u305f\u300c\u666f\u6cc1\u611f\u300d\u306e\u3088\u3046\u306a\u3082\u306e\u3067\u3042\u308b\u3002\n\u3053\u3046\u3057\u305f\u30d5\u30a1\u30af\u30bf\u30fc\u3092\u3001\u4e88\u6e2c\u3057\u305f\u3044\u5909 \u6570\u304b\u3089\u306a\u308b VAR(\u591a\u5909\u91cf\u81ea\u5df1\u56de\u5e30)\u30e2\u30c7\u30eb\u306b\u52a0\u3048\u308b \u3053\u3068\u3067\u3001\u305d\u306e\u7cbe\u5ea6\u3092\u5411\u4e0a\u3055\u305b\u308b\u3053\u3068\u304c\u3067\u304d\u305f\u3002\n\u540c\u4e88\u6e2c\u5668\u306f\u3001\u5e02\u5834\u3084\u7d4c\u6e08\u306e\u300c\u5148\u3092\u8aad\u3080\u300d\u305f\u3081\u306b\u3001 \u65e5\u3005\u3001\u5e02\u5834\u306e\u5024\u52d5\u304d\u3084 GDP \u306e\u5024\u3060\u3051\u3067\u306a\u304f\u3001\u95a2\u9023\u3059\u308b\u5927\u91cf\u306e\u30c7\u30fc\u30bf\u3092\u30a6\u30a9\u30c3\u30c1\u3057\u3001\u300c\u76f8\u5834\u611f\u300d\u3084\u300c\u666f\u6cc1\u611f\u300d\u3092\u5f62\u6210\u3057\u3066\u3044\u308b\u30d7\u30ed\u306e\u5e02\u5834\u53c2\u52a0\u8005(\u30d5\u30a9\u30fc\u30ad\u30e3\u30b9\u30bf \u30fc)\u306e\u77e5\u7684\u4f5c\u696d\u3092\u6a21\u3057\u305f\u3082\u306e\u3068\u3082\u8a00\u3048\u3088\u3046\u3002\n\n\u3053\u308c \u3092 \u5fdc\u7528\u3059\u308c\u3070\u3001\n\n\u8907\u6570\u9298\u67c4 \u306e \u682a\u4fa1\u6642\u7cfb\u5217\u5909\u52d5\u3001\n\u8907\u6570 \u306e \u30de\u30af\u30ed\u7d4c\u6e08\u6307\u6a19\n\u7279\u5b9a\u30ef\u30fc\u30c9 \u306e google\u691c\u7d22 and/or Twitter \uff08\u65e5\u6b21\uff09\u51fa\u73fe\u56de\u6570 \n\n\u306a\u3069\u3001\u8907\u6570\u306e\u30c7\u30fc\u30bf\u9805\u76ee \u304c \u6642\u9593\u3068\u5171\u306b\u5909\u52d5\u3059\u308b \u30c7\u30fc\u30bf\u7a7a\u9593 \u3092\u3001\n\n\u6642\u9593\u8ef8 + \u591a\u6b21\u5143\u7a7a\u9593\u8ef8\uff08\uff11\u30c7\u30fc\u30bf\u9805\u76ee\uff1d\uff11\u7a7a\u9593\u8ef8\uff09 \u3067 \u5f35\u3089\u308c\u308b \u591a\u6b21\u5143\u30d9\u30af\u30c8\u30eb\u7a7a\u9593 \n\n\u3068 \u89e3\u91c8\u3059\u308c\u3070\u3001\n\n\u3010 \u5b9f\u7e3e\u5024 \u3011\u8907\u6570\u4e8b\u8c61 \u306e \u6642\u9593\u63a8\u79fb\u5c65\u6b74 \u53ca\u3073 \uff08\u6559\u5e2b\u30e9\u30d9\u30eb\uff09\u7d4c\u6e08\u72b6\u614b\u30af\u30e9\u30b9\uff08\uff12\u30af\u30e9\u30b9 or \u591a\u30af\u30e9\u30b9\uff09 \n\n\u3092\u3000\u30d1\u30bf\u30fc\u30f3 \u3068\u3057\u3066 \u5b66\u7fd2\u3055\u305b\u3066\u3001\n\n\uff08\u65b0\u898f\u5165\u529b\uff09 \u76f4\u8fd1\u306e\u8db3\u5143\u3000\u306e\u3000\u5f53\u8a72\u8907\u6570\u4e8b\u8c61\u306e\u6642\u9593\u63a8\u79fb\u3092\u65b0\u898f\u306b\u30e2\u30c7\u30eb\u3000\u306b \u5165\u529b\u3055\u305b\u3066\u3001\n\uff08\u5c06\u6765\u4e88\u6e2c\uff09 \u672a\u6765\u306e\u7d4c\u6e08\u72b6\u614b\u3000\u3092 \u5206\u985e\u4e88\u6e2c\u3059\u308b\n\n\u3053\u3068 \u304c \u3067\u304d\u308b\u306f\u305a \u3067 \u3042\u308b\u3002\n\u4ee5\u4e0a \u3092\u3001multi-dimensional QRNN \u3067\u3082 \u3067\u304d\u306a\u3044\u3060\u308d\u3046\u304b\uff1f\n\n\uff08 \u53c2\u8003 \uff09\n\n\nMLP \u3068 Deep Boltzman Machines \u3092 \u4f7f\u3063\u305f \u591a\u5909\u91cf\u6642\u7cfb\u5217\u30c7\u30fc\u30bf \u306e \u56de\u5e30\u554f\u984c \u306e \u4e8b\u4f8b\n\n\nGilberto Batres-Estrada, Deep Learning for Multivariate Financial Time Series\n\nGitHub \u306b\u3042\u308b DingKe/qrnn/ \u306e \u30b5\u30f3\u30d7\u30eb\u30b3\u30fc\u30c9 __*imbd_qrnn.py*__ \n\n* [https://github.com/DingKe/qrnn/](https://github.com/DingKe/qrnn/)\n\n\u306f\u3001\n\n> from keras.datasets import imdb\n\n\u3067\u3001keras\u306e\u7d44\u307f\u8fbc\u307f\u30c7\u30fc\u30bf\u30bb\u30c3\u30c8 __*imdb*__ \u3092 \u8aad\u307f\u8fbc\u3093\u3067 \u3044\u308b\u3002\n\n\u3053\u306e\u30c7\u30fc\u30bf\u306f\u3001\u4ee5\u4e0b \u306e \u516c\u5f0f\u89e3\u8aac \u306b \u3088\u308b \u3068\u3001\n\n* [Keras Documentation \u30c7\u30fc\u30bf\u30bb\u30c3\u30c8 \u300cIMDB\u6620\u753b\u30ec\u30d3\u30e5\u30fc\u611f\u60c5\u5206\u985e\u300d](https://keras.io/ja/datasets/)\n\n> __IMDB\u6620\u753b\u30ec\u30d3\u30e5\u30fc\u611f\u60c5\u5206\u985e__\n>\n> \u611f\u60c5(\u80af\u5b9a/\u5426\u5b9a)\u306e\u30e9\u30d9\u30eb\u4ed8\u3051\u3092\u3055\u308c\u305f\u300125,000\u306eIMDB\u6620\u753b\u30ec\u30d3\u30e5\u30fc\u306e\u30c7\u30fc\u30bf\u30bb\u30c3\u30c8\u3002\u30ec\u30d3\u30e5\u30fc\u306f\u524d\u51e6\u7406\u6e08\u307f\u3067\u3001\u5404\u30ec\u30d3\u30e5\u30fc\u306f\u5358\u8a9e\u306e\u30a4\u30f3\u30c7\u30c3\u30af\u30b9(\u6574\u6570\u5024)\u306e\u30b7\u30fc\u30b1\u30f3\u30b9\u3068\u3057\u3066\u30a8\u30f3\u30b3\u30fc\u30c9\u3055\u308c\u3066\u3044\u308b\u3002\u4fbf\u5b9c\u4e0a\u3001\u5358\u8a9e\u306f\u30c7\u30fc\u30bf\u30bb\u30c3\u30c8\u306b\u304a\u3044\u3066\u306e\u51fa\u73fe\u983b\u5ea6\u306b\u3088\u3063\u3066\u30a4\u30f3\u30c7\u30c3\u30af\u30b9\u3055\u308c\u3066\u3044\u308b\u3002\u305d\u306e\u305f\u3081\u4f8b\u3048\u3070\u3001\u6574\u6570\u5024\"3\"\u306f\u30c7\u30fc\u30bf\u306e\u4e2d\u30673\u756a\u76ee\u306b\u983b\u5ea6\u304c\u591a\u3044\u5358\u8a9e\u306b\u30a8\u30f3\u30b3\u30fc\u30c9\u3055\u308c\u308b\u3002\u3053\u308c\u306b\u3088\u3063\u3066\"\u4e0a\u4f4d20\u500b\u306e\u983b\u51fa\u8a9e\u3092\u9664\u3044\u305f\u3001\u4e0a\u4f4d10,000\u500b\u306e\u983b\u51fa\u8a9e\u306b\u3064\u3044\u3066\u306e\u307f\u8003\u3048\u308b\"\u3068\u3044\u3046\u3088\u3046\u306a\u30d5\u30a3\u30eb\u30bf\u30ea\u30f3\u30b0\u4f5c\u696d\u3092\u9ad8\u901f\u306b\u884c\u3046\u3053\u3068\u304c\u3067\u304d\u308b\u3002\n>\n> \u6163\u4f8b\u3068\u3057\u3066\u3001\"0\"\u306f\u7279\u5b9a\u306e\u5358\u8a9e\u3092\u8868\u3059\u306e\u3067\u306f\u306a\u304f\u3001\u4ee3\u308f\u308a\u306b\u672a\u77e5\u306e\u5358\u8a9e\u306b\u30a8\u30f3\u30b3\u30fc\u30c9\u3055\u308c\u308b\u3053\u3068\u306b\u306a\u3063\u3066\u3044\u308b\u3002\n>\n>>```{python:}\n>>from keras.datasets import imdb\n>>\n>>(X_train, y_train), (X_test, y_test) = imdb.load_data(path=\"imdb_full.pkl\",\n>>                                                      nb_words=None,\n>>                                                      skip_top=0,\n>>                                                      maxlen=None,\n>>                                                      seed=113,\n>>                                                      start_char=1,\n>>                                                      oov_char=2,\n>>                                                      index_from=3)\n>>```\n>\n> __\u8fd4\u308a\u5024:__\n>\n> 2\u3064\u306e\u30bf\u30d7\u30eb:\n> X_train, X_test: \u30b7\u30fc\u30b1\u30f3\u30b9\u306e\u30ea\u30b9\u30c8\u3001\u30ea\u30b9\u30c8\u306f\u30a4\u30f3\u30c7\u30c3\u30af\u30b9(\u6574\u6570\u5024)\u3002\u5f15\u6570nb_words\u306b\u5177\u4f53\u7684\u306a\u6574\u6570\u5024\u304c\u4e0e\u3048\u3089\u308c\u305f\u5834\u5408\u3001\u53d6\u308a\u5f97\u308b\u30a4\u30f3\u30c7\u30c3\u30af\u30b9\u306e\u6700\u5927\u5024\u306fnb_words-1\u3068\u306a\u308b\u3002\u5f15\u6570maxlen\u306b\u5177\u4f53\u7684\u306a\u6570\u5024\u304c\u4e0e\u3048\u3089\u308c\u305f\u5834\u5408\u3001\u30b7\u30fc\u30b1\u30f3\u30b9\u306e\u6700\u5927\u9577\u306fmaxlen\u3068\u306a\u308b\u3002\n> y_train, y_test: integer\u578b\u30e9\u30d9\u30eb(1\u307e\u305f\u306f0)\u306e\u30ea\u30b9\u30c8\u3002\n>\n\n\u3068\u306e\u3053\u3068\u3002\n\n__\u3064\u307e\u308a\u3001\u30e2\u30c7\u30eb\u5b66\u7fd2\u30d5\u30a7\u30fc\u30ba \u53ca\u3073 \u30e2\u30c7\u30eb\uff08\u5206\u985e\uff09\u4e88\u6e2c\u7cbe\u5ea6\u306e\u691c\u8a3c\u30d5\u30a7\u30fc\u30ba \u3067\u306f\u3001\u4ee5\u4e0b \u306e \u5f62\u5f0f\u306e\u30c7\u30fc\u30bf \u3092 \u5165\u529b\u5024 \u3068\u3057\u3066 \u53d7\u3051\u53d6\u308b\u3002__\n\n___\n\n* __\u6587\u7ae0\u30c7\u30fc\u30bf__: \u5358\u8a9eID\u3000\uff08Int\u578b\u30aa\u30d6\u30b8\u30a7\u30af\u30c8\uff09\u3092\u8981\u7d20\u306b\u6301\u3064list\u578b\u30aa\u30d6\u30b8\u30a7\u30af\u30c8\n\n\u3092\u53d7\u3051\u53d6\u308a\u3001\u540c\u6642\u306b\u3001\u6587\u7ae0\u306e\uff12\u5024\u5206\u985e\u30af\u30e9\u30b9\u30e9\u30d9\u30eb\uff08\u300c\u80af\u5b9a\u300dor\u300c\u5426\u5b9a\u300d\u306e\u611f\u60c5\u30dd\u30b8\u30cd\u30ac \u30e9\u30d9\u30eb\uff09\u3068\u3057\u3066\u3001\n\n* __\u6587\u7ae0\u30af\u30e9\u30b9\u5206\u985e\u30e9\u30d9\u30eb__\uff08\u611f\u60c5\u30dd\u30b8\u30cd\u30ac\uff12\u5024\u30e9\u30d9\u30eb\uff09: 0 or 1 \uff08Int\u578b\u30aa\u30d6\u30b8\u30a7\u30af\u30c8\uff09\n\n___\n\n\u307e\u3068\u3081\u308b \u3068\u3001Int\u578b\u306e\u6570\u5024\u304c\u6642\u9593\u9806\u5e8f \u306b \u4e26\u3076 \u6570\u5024\u6642\u7cfb\u5217\u30c7\u30fc\u30bf\uff08list\u578b\uff09 \u3092 \u53d7\u3051\u3068\u308b\u30b9\u30af\u30ea\u30d7\u30c8 \u306b \u306a\u3063\u3066\u3044\u308b\u3002\n\n\u3053\u306e\u305f\u3081\u3001__*imbd_qrnn.py*__ \u3000\u306f\u3001\u30b3\u30fc\u30c9\u3092\u66f8\u304d\u63db\u3048\u305a \u306b\u3001\u4ee5\u4e0b \u306e \u7d4c\u6e08\u91d1\u878d\u30c7\u30fc\u30bf\u306e\u3088\u3046 \u306a\u3001\u81ea\u7136\u8a00\u8a9e\u30c6\u30ad\u30b9\u30c8 \u4ee5\u5916 \u306e \u6642\u7cfb\u5217 \u6570\u5024\u30c7\u30fc\u30bf \u306e \uff12\u5024\u5206\u985e\u30bf\u30b9\u30af \u3082 \u884c\u3048\u308b\u306f\u305a\u3067\u3042\u308b\u3002\n\n##__( \u30bf\u30b9\u30af\u4f8b )__\n\n* \uff08\uff11\u9298\u67c4 \uff09 \u682a\u4fa1 \u306e \u300c\u5024\u4e0a\u304c\u308a\u5c40\u9762\u300d\u30fb\u300c\u5024\u4e0b\u304c\u308a\u5c40\u9762\u300d \uff12\u5024\u5206\u985e\u30bf\u30b9\u30af\n\n##__\u3010 \u5b66\u7fd2\u7528 \u53ca\u3073 \u691c\u8a3c\u7528 \u30c7\u30fc\u30bf\u5f62\u5f0f \u3011__\n\n* __\u30c7\u30fc\u30bf__\uff1a \u3042\u308b\uff11\u9298\u67c4\u306e\u682a\u4fa1\u306e\u5024\u52d5\u304d\u30c7\u30fc\u30bf\u3000\uff1d Int\u578b \u5e02\u5834\u4fa1\u683c \u306e\u5206\u6b21\u3001\u79d2\u6642*etc* \u6570\u5024\u30ea\u30b9\u30c8\n* __\u6559\u5e2b\u30e9\u30d9\u30eb__\uff1a \u300c\u5024\u4e0a\u304c\u308a\u5c40\u9762\u300d\u30e9\u30d9\u30eb\uff1d\uff11 or \u300c\u5024\u4e0b\u304c\u308a\u5c40\u9762\u300d\u30e9\u30d9\u30eb= 0\n\n___\n\n\n##__\u4ee5\u4e0b\u3001\u30c7\u30fc\u30bf\u30bb\u30c3\u30c8\u306e\u5185\u5bb9 \u3092 \u78ba\u8a8d\u3057\u305f\u7d50\u679c__\n\n###__*imbd_qrnn.p* \u306e \u30c7\u30fc\u30bf\u53d6\u5f97\u90e8\u5206 \u306e \u30b3\u30fc\u30c9__\n\n```{python:DingKe/qrnn/qrnn/imbd_qrnn.py}\nfrom __future__ import print_function\nimport numpy as np\nnp.random.seed(1337)  # for reproducibility\n\nfrom keras.preprocessing import sequence\nfrom keras.utils import np_utils\nfrom keras.models import Sequential\nfrom keras.layers import Dense, Dropout, Activation, Embedding\nfrom keras.layers import LSTM, SimpleRNN, GRU\nfrom keras.regularizers import l2\nfrom keras.constraints import maxnorm\nfrom keras.datasets import imdb\n\n\uff08 \u4e2d\u7565 \uff09\n\nmax_features = 20000\nmaxlen = 80  # cut texts after this number of words (among top max_features most common words)\nbatch_size = 32 \n\n\nprint('Loading data...')\n(X_train, y_train), (X_test, y_test) = imdb.load_data(nb_words=max_features)\nprint(len(X_train), 'train sequences')\nprint(len(X_test), 'test sequences')\n\nprint('Pad sequences (samples x time)')\nX_train = sequence.pad_sequences(X_train, maxlen=maxlen)\nX_test = sequence.pad_sequences(X_test, maxlen=maxlen)\nprint('X_train shape:', X_train.shape)\nprint('X_test shape:', X_test.shape)\n```\n\n\n####__\u4ee5\u4e0b\u3001\u30e2\u30c7\u30eb\u5b66\u7fd2\u7528\u306e\u30c7\u30fc\u30bf\u3068\u6559\u5e2b\u30e9\u30d9\u30eb\u3001\u30e2\u30c7\u30eb\u691c\u8a3c\u7528\u306e\u30c7\u30fc\u30bf\u3068\u6559\u5e2b\u30e9\u30d9\u30eb \u306e \u4e2d\u8eab \u3092 \u78ba\u8a8d__\n\n```{python:Python 3.5.1 (anaconda3-2.5.0)}\n(anaconda3-2.5.0) HirofumiYashima-no-MacBook:~ hirofumiyashima$ python --version\nPython 3.5.1 :: Anaconda 2.5.0 (x86_64)\n(anaconda3-2.5.0) HirofumiYashima-no-MacBook:~ hirofumiyashima$ \n(anaconda3-2.5.0) HirofumiYashima-no-MacBook:~ hirofumiyashima$ python\nPython 3.5.1 |Anaconda 2.5.0 (x86_64)| (default, Dec  7 2015, 11:24:55) \n[GCC 4.2.1 (Apple Inc. build 5577)] on darwin\nType \"help\", \"copyright\", \"credits\" or \"license\" for more information.\n>>> \n>>> from __future__ import print_function\n>>> import numpy as np\n>>> np.random.seed(1337)\n>>> \n>>> from keras.preprocessing import sequence\nUsing TensorFlow backend.\n>>> \n>>> from keras.utils import np_utils\n>>> from keras.models import Sequential\n>>> from keras.layers import Dense, Dropout, Activation, Embedding\n>>> from keras.layers import LSTM, SimpleRNN, GRU\n>>> from keras.regularizers import l2\n>>> from keras.constraints import maxnorm\n>>> from keras.datasets import imdb\n>>> \n>>> max_features = 20000\n>>> maxlen = 80\n>>> batch_size = 32 \n>>> \n>>> (X_train, y_train), (X_test, y_test) = imdb.load_data(nb_words=max_features)\n>>> print(len(X_train), 'train sequences')\n25000 train sequences\n>>> \n>>> print(len(y_train))\n25000\n>>> \n```\n\n####__\u5b66\u7fd2\u7528\u30c7\u30fc\u30bf \u306f Int\u306e\u4e26\u3073\uff08\u5358\u8a9eID\u756a\u53f7 \u306e \u6642\u9593\u7cfb\u5217\uff09__\n\n```{python:Python 3.5.1 (anaconda3-2.5.0)}\n>>> print(X_train[0])\n[1, 14, 22, 16, 43, 530, 973, 1622, 1385, 65, 458, 4468, 66, 3941, 4, 173, 36, 256, 5, 25, 100, 43, 838, 112, 50, 670, 2, 9, 35, 480, 284, 5, 150, 4, 172, 112, 167, 2, 336, 385, 39, 4, 172, 4536, 1111, 17, 546, 38, 13, 447, 4, 192, 50, 16, 6, 147, 2025, 19, 14, 22, 4, 1920, 4613, 469, 4, 22, 71, 87, 12, 16, 43, 530, 38, 76, 15, 13, 1247, 4, 22, 17, 515, 17, 12, 16, 626, 18, 19193, 5, 62, 386, 12, 8, 316, 8, 106, 5, 4, 2223, 5244, 16, 480, 66, 3785, 33, 4, 130, 12, 16, 38, 619, 5, 25, 124, 51, 36, 135, 48, 25, 1415, 33, 6, 22, 12, 215, 28, 77, 52, 5, 14, 407, 16, 82, 10311, 8, 4, 107, 117, 5952, 15, 256, 4, 2, 7, 3766, 5, 723, 36, 71, 43, 530, 476, 26, 400, 317, 46, 7, 4, 12118, 1029, 13, 104, 88, 4, 381, 15, 297, 98, 32, 2071, 56, 26, 141, 6, 194, 7486, 18, 4, 226, 22, 21, 134, 476, 26, 480, 5, 144, 30, 5535, 18, 51, 36, 28, 224, 92, 25, 104, 4, 226, 65, 16, 38, 1334, 88, 12, 16, 283, 5, 16, 4472, 113, 103, 32, 15, 16, 5345, 19, 178, 32]\n>>> \n>>> print(X_train[1])\n[1, 194, 1153, 194, 8255, 78, 228, 5, 6, 1463, 4369, 5012, 134, 26, 4, 715, 8, 118, 1634, 14, 394, 20, 13, 119, 954, 189, 102, 5, 207, 110, 3103, 21, 14, 69, 188, 8, 30, 23, 7, 4, 249, 126, 93, 4, 114, 9, 2300, 1523, 5, 647, 4, 116, 9, 35, 8163, 4, 229, 9, 340, 1322, 4, 118, 9, 4, 130, 4901, 19, 4, 1002, 5, 89, 29, 952, 46, 37, 4, 455, 9, 45, 43, 38, 1543, 1905, 398, 4, 1649, 26, 6853, 5, 163, 11, 3215, 10156, 4, 1153, 9, 194, 775, 7, 8255, 11596, 349, 2637, 148, 605, 15358, 8003, 15, 123, 125, 68, 2, 6853, 15, 349, 165, 4362, 98, 5, 4, 228, 9, 43, 2, 1157, 15, 299, 120, 5, 120, 174, 11, 220, 175, 136, 50, 9, 4373, 228, 8255, 5, 2, 656, 245, 2350, 5, 4, 9837, 131, 152, 491, 18, 2, 32, 7464, 1212, 14, 9, 6, 371, 78, 22, 625, 64, 1382, 9, 8, 168, 145, 23, 4, 1690, 15, 16, 4, 1355, 5, 28, 6, 52, 154, 462, 33, 89, 78, 285, 16, 145, 95]\n>>>\n```\n\n####__\u5b66\u7fd2\u7528\u30c7\u30fc\u30bf\u306e\u6b63\u89e3\u6559\u5e2b\u30e9\u30d9\u30eb\u306f\u30012\u5024\u5206\u985e\u306e\u30af\u30e9\u30b9\u30e9\u30d9\u30eb\uff080 \u3082\u3057\u304f\u306f 1\uff09__\n\n```{python:Python 3.5.1 (anaconda3-2.5.0)}\n>>> print(y_train[0])\n1\n>>> \n>>> print(y_train[1])\n0\n>>>\n>>> print(y_train[0:20])\n[1 0 0 1 0 0 1 0 1 0 1 0 0 0 0 0 1 1 0 1]\n>>>\n```\n\n####__\u691c\u8a3c\u7528\u30c7\u30fc\u30bf \u3082 \u540c\u69d8__\n\n__\uff08 \u30c7\u30fc\u30bf\u306e\u4e2d\u8eab \uff09__\n\n```{python:Python 3.5.1 (anaconda3-2.5.0)} \n>>> print(X_test[0])\n[1, 89, 27, 2, 9289, 17, 199, 132, 5, 4191, 16, 1339, 24, 8, 760, 4, 1385, 7, 4, 22, 1368, 11415, 16, 5149, 17, 1635, 7, 2, 1368, 9, 4, 1357, 8, 14, 991, 13, 877, 38, 19, 27, 239, 13, 100, 235, 61, 483, 11960, 4, 7, 4, 20, 131, 1102, 72, 8, 14, 251, 27, 1146, 7, 308, 16, 735, 1517, 17, 29, 144, 28, 77, 2305, 18, 12]\n>>> \n>>> print(X_test[1])\n[1, 3452, 7, 16495, 517, 522, 31, 314, 17, 1909, 2046, 11778, 6829, 11424, 83, 4, 2314, 673, 33, 27, 568, 1709, 2923, 32, 4, 189, 22, 11, 975, 4135, 29, 2376, 4, 1287, 7, 4, 16495, 4217, 15, 1435, 455, 1394, 848, 1538, 4031, 96, 145, 11, 4, 204, 6156, 297, 5418, 29, 3044, 4, 1287, 8, 35, 4383, 1609, 121, 15286, 1233, 980, 2, 2100, 11627, 18273, 2, 3681, 304, 4, 1287, 145, 8, 41, 1472, 50, 2, 10737, 2, 16495, 4364, 34, 2782, 13092, 145, 295, 174, 772, 6, 2, 18, 274, 961, 90, 145, 8, 4041, 113, 155, 92, 140, 17, 2, 69, 3205, 16495, 505, 46, 24, 8, 30, 4, 132, 7, 41, 1306, 103, 32, 38, 59, 9560, 90, 11, 6, 297, 7389, 33, 63, 16495, 9, 329, 74, 654, 137, 2, 304, 6, 4548, 16495, 2949, 2, 41, 772, 15, 274, 961, 41, 145, 8, 113, 11, 4, 2995, 7, 6, 668, 4217, 1810, 17, 6, 3452, 1082, 181, 8, 30, 1571, 11, 3161, 2350, 28, 8, 157, 295, 8, 79, 8, 6, 6068, 11, 162, 6869, 121, 15286, 1249, 648, 69, 77, 3554, 19, 4, 2, 887, 8, 4416, 68, 4123, 145, 83, 406, 2350, 4, 2350, 7, 2, 13174, 3509, 1851, 27, 980, 18288, 10512, 2, 37, 26, 199, 23, 4, 521, 39, 3408, 1697, 2297, 7, 568, 3864, 2, 308, 3659, 80, 81, 1780, 10, 10, 526, 34, 10605, 18317, 13, 119, 3452, 7, 16495, 4, 229, 34, 1561, 2, 9, 87, 253, 55, 702, 728, 545, 441, 2072, 958, 7, 85, 189, 22, 19, 52, 5499, 39, 4, 636, 720, 121, 75, 67, 1655, 19161, 9792, 2377, 39, 4, 2553, 4, 4971, 108, 2281, 2, 6997, 4626, 10852, 39, 4, 6, 1726, 23, 4903, 890, 201, 488, 4664, 2377, 39, 4, 2195, 3135, 8, 4, 2974, 343, 39, 3452, 7, 5279, 10074, 54, 12, 2360, 19062, 4, 172, 136, 3452, 7, 16495, 115, 304, 410, 615, 63, 9, 43, 17, 73, 50, 26, 775, 7, 31, 2433, 532, 19266, 1994, 15, 2039, 4142, 93, 9032, 6, 171, 153, 908, 12, 152, 306, 1595, 8, 9155, 253, 33, 410, 4, 189, 512, 11, 831, 13, 119, 4, 136, 54, 3509, 18288, 26, 260, 6, 2711, 2, 731, 2599, 15, 16495, 5224, 29, 166, 163, 2, 795, 7320, 469, 198, 24, 8, 135, 15, 50, 218, 6, 1543, 52, 22, 11, 50, 17, 73, 88, 50, 91, 434, 9, 167, 18317, 1030, 8, 987, 52, 841, 6, 147, 281, 7, 253, 199, 406, 3161, 732, 7, 105, 26, 1451, 4091, 17, 257, 2162, 2712, 68, 205, 732, 7, 4816, 712, 15, 4, 4951, 7, 5512, 15, 36, 26, 1200, 496, 62, 540, 1203, 2536, 3452, 7, 16495, 9, 87, 18, 4, 91, 173, 47, 15, 194, 352, 6713, 44, 12, 33, 44, 2476, 1782, 1782, 13, 144, 440, 38, 4, 64, 155, 15, 13, 80, 135, 9, 15, 49, 7, 4, 5076, 302, 34, 1842, 26, 6, 117, 3463, 2631, 13, 191, 377, 101, 1683, 139, 11, 3452, 7, 16495, 345, 2670, 4, 22, 152, 9185, 4, 541, 599, 19, 6, 646, 12337, 3681, 5573, 15348, 83, 4472, 393, 11, 3532, 6, 14559, 5003, 3490, 84, 13058, 23, 2, 7, 3062, 294, 112, 2, 34, 6, 666, 2832, 6, 3314, 125, 5484, 12318, 998, 2, 13266, 4, 116, 9, 184, 52, 13092, 17, 16495, 9, 55, 163, 17, 29, 14578, 4, 31, 2433, 46, 13, 82, 40, 4, 139, 19, 2, 33, 4, 454, 169, 41, 55, 1279, 54, 442, 1658, 32, 15, 7717, 5745, 13, 191, 30, 4, 64, 31, 1348, 13, 1276, 104, 3452, 7, 16495, 9, 6, 777, 22, 964, 722, 39, 380, 8, 1363, 87, 1285, 189, 11, 3215, 4160, 33, 64, 7304, 234, 196, 12, 115, 461, 357, 42, 753, 6, 965, 1640, 7, 1923, 106, 12, 17, 515, 17, 25, 70]\n>>>\n```\n\n__\uff08 \u6b63\u89e3\u30e9\u30d9\u30eb \u306e \u4e2d\u8eab \uff09__\n\n\n```{python:Python 3.5.1 (anaconda3-2.5.0)} \n>>> print(y_test[0])\n1\n>>> \n>>> print(y_test[1])\n1\n>>> \n>>> print(y_test[0:20])\n[1 1 1 1 1 0 0 0 1 1 1 1 1 1 1 1 1 0 0 1]\n>>> \n```\n\n##__QRNN \u3067 \u6570\u5024\u6642\u7cfb\u5217\u30c7\u30fc\u30bf\u306e\uff12\u5024\u5206\u985e\u30bf\u30b9\u30af \u3092 \u5b9f\u884c\u3057\u3066\u307f\u3088\u3046\u3002__\n\n\u307e\u305a\u306f\u3001\n\n* \uff08\u5b66\u7fd2\u5bfe\u8c61\uff09 \u5468\u671f\u3068\u632f\u5e45\u306e\u7570\u306a\u308b sin\u66f2\u7dda  \u306e 2\u30d1\u30bf\u30fc\u30f3 \uff08\u6559\u5e2b\u30e9\u30d9\u30eb\uff1a \uff12\u5024\u30af\u30e9\u30b9\u30e9\u30d9\u30eb\uff08 0 or 1 \uff09\uff09\n* \uff08\u4e88\u6e2c\u7cbe\u5ea6\u691c\u8a3c\u6bb5\u968e\uff09 \u65b0\u898f\u30c7\u30fc\u30bf \u306e \u6240\u5c5e\u30af\u30e9\u30b9 \u3092 \u5206\u985e\u7cbe\u5ea6 \u3092 \u691c\u8a3c\n\n\u30bf\u30b9\u30af \u304b\u3089\u3001\u59cb\u3081\u3066\u307f\u305f\u3044\u3002\n\n#__\u3010 \u767a\u5c55\u601d\u8003 \u3011__\n##__\u591a\u5909\u91cf\u6642\u7cfb\u5217\u30c7\u30fc\u30bf \u306e \u5206\u985e\u30fb\u56de\u5e30\u554f\u984c__\n\n\n##__\u56de\u5e30\u554f\u984c\uff08\u56de\u5e30\u4e88\u6e2c\uff09 \u3082 \u884c\u3044\u305f\u3044\u3002__\n\n\u6642\u7cfb\u5217\u30c7\u30fc\u30bf \u306e \u56de\u5e30\u4e88\u6e2c\u554f\u984c\uff08_regression, prediction, forecast_\uff09 \u3082\u3001 \u6b21\u306b\u304f\u308b\u5358\u8a9e\u3092\u4e88\u6e2c\u3059\u308bNLP\u30bf\u30b9\u30af\u306b\u53d6\u308a\u7d44\u3080QRNN\u5148\u884c\u4e8b\u4f8b \u3092 \u624b\u7acb\u3066 \u306b\u3001NLP \u4ee5\u5916 \u306e \u6570\u5024\u6642\u7cfb\u5217\u30c7\u30fc\u30bf \u3092 \u4f7f\u3063\u3066 \u5b9f\u884c\u3057\u3066\u307f\u305f\u3044\u3002\n\n##__\u591a\u5909\u91cf\u6642\u7cfb\u5217\u30c7\u30fc\u30bf \u306e \u5206\u985e\u30fb\u56de\u5e30\u554f\u984c__\n\n\u3055\u3089 \u306b\u3001\u8907\u6570\u306e\u6570\u5024\u6642\u7cfb\u5217\u30c7\u30fc\u30bf \u306e \u6642\u9593\u5909\u52d5 \u5168\u4f53 \u3092\u30013D-CNN\u306e\u30a4\u30e1\u30fc\u30b8 \u3067\u3001 (multi-dimensional ?) QRNN \u30e2\u30c7\u30eb\u306e\u3088\u3046\u306a\u3082\u306e\u3067\u5b66\u7fd2\u3055\u305b\u308b\u3053\u3068 \u3092 \u5b9f\u73fe\u3067\u304d\u306a\u3044\u3060\u308d\u3046\u304b\uff1f\n\nRNN \u3084 LSTM \u3092\u7528\u3044\u3066\u3001\uff08\u53ef\u5909\u9577\uff09\u6642\u7cfb\u5217\u30c7\u30fc\u30bf \u306e \u5206\u985e\u30bf\u30b9\u30af \u306b\u53d6\u308a\u7d44\u3093\u3060 \u4e8b\u4f8b \u304c \u3042\u308b\u3002\n\n* [\u3086\u308b\u3075\u308f\u3081\u3082 \uff082016/10/09\uff09\u300cLSTM\u3067\u5206\u985e\u554f\u984c\u3092\u89e3\u304f(Python)\u300d](http://paper.hatenadiary.jp/entry/2016/10/09/211329)\n\n* [Hatena Blog \u3082\u3061\u3082\u3061\u3057\u3066\u3044\u308b (2015/12/07\uff09 \u300cRecurrent NN\u3067\u6587\u66f8\u306e\u30dd\u30b8\u30cd\u30ac\u5224\u5b9a\u3059\u308b\uff08\u30e2\u30c7\u30eb\u8003\u6848\u7de8\uff09\u300d](http://olanleed.hatenablog.com/entry/2015/12/07/233307) \n* [LSTM Networks for Sentiment Analysis](http://deeplearning.net/tutorial/lstm.html)\n\n\u307e\u305f\u3001RNN \u3084 LSTM \u3067\u3001\u591a\u5909\u91cf\u30c7\u30fc\u30bf\uff08\u8907\u6570\u306e\u6642\u9593\u7cfb\u5217\u30c7\u30fc\u30bf\uff09\u306b \u5bfe\u3059\u308b \u5206\u985e\u30bf\u30b9\u30af \u306b\u53d6\u308a\u7d44\u3080\u65b9\u6cd5 \u306b \u3064\u3044\u3066\u3082\u3001\u4ee5\u4e0b \u306e\u3088\u3046 \u306b \u8b70\u8ad6 \u304c \u306a\u3055\u308c\u3066\u3044\u308b\u3002\n\n\uff08 Multi-dimensional RNN \u3084 Multi-Dimensional LSTM \u3067\u306f\u3001\u7e26\u6a2a\u5965\u884c\u304d\u7b49\u3001\uff12\u6b21\u5143\u4ee5\u4e0a \u306e \u5e83\u304c\u308a \u3092 \u6301\u3064\u5165\u529b\u30c7\u30fc\u30bf \u3092 \u6271\u3046\u3053\u3068 \u304c \u3067\u304d\u308b \uff09\n\n* [Alex Graves, Santiago Ferna \u0301ndez, Ju \u0308rgen Schmidhuber, _Multi-Dimensional Recurrent Neural Networks_](http://people.idsia.ch/~juergen/icann_2007.pdf)\n* [Google group _LSTM for classification of multidimensional time series with different lengths_](https://groups.google.com/forum/#!topic/lasagne-users/BvFNtap1IZQ)\n\n> Hi guys,\n>\n> I am trying to setup a neural network with a forward and a backward LSTM hidden layers for __the classification of time series__.\n> __The time series have different time steps (sequences with different lengths) and have 9 dimensions__. \n>\n>I have loaded the time series so that the shape is (batch size, max sequence length, number of features).\n>\n>The mask per sequence is an vector having 1 for each timestep lower than the sequence length, and 0 for every timestep higher than the sequence length.\n>\n>Because the purpose is classification it should have one output neuron to classify the entire sequence as 0 or 1.\n>\n>I have constructed the following network, do you think this model would be appropriate for classification?\n\n* [stackoverflow _Multivariate time-series RNN using Tensorflow. Is this possible with an LSTM cell or similar?_](http://stackoverflow.com/questions/34045295/multivariate-time-series-rnn-using-tensorflow-is-this-possible-with-an-lstm-cel)\n* [Quora _How can I predict multivariate time series with LSTM, RNN or CNN?_](https://www.quora.com/How-can-I-predict-multivariate-time-series-with-LSTM-RNN-or-CNN)\n\n> Let\u2019s say we record the price of A, B and C stocks every minute 10000 times. \n> How can I predict the price of A? \n> Can I predict the price of A, B and C at the same time? I\u2019m looking for a simple python script.\n\n* [Zhengping Che _et.al, RECURRENT NEURAL NETWORKS FOR MULTIVARI- ATE TIME SERIES WITH MISSING VALUES_](https://arxiv.org/pdf/1606.01865.pdf)\n\n* [Anvardh Nanduri and Lance Sherry, _ANOMALY DETECTION IN AIRCRAFT DATA USING RECURRENT NEURAL NETWORKS (RNN)_](http://catsr.ite.gmu.edu/pubs/ICNS_2016_AnomalyDetectionRNN_01042015.pdf)\n\n> In addition, by accepting __sequences of multivariate data points as input and treating them as time series data__, pre-trained RNNs models can be used for real-time anomaly detection on-board the aircraft.\n\n* [\u5869\u91ce \u525b\u5fd7\uff08\u30af\u30ec\u30c7\u30a3\u30fb\u30b9\u30a4\u30b9\u8a3c\u5238\u682a\u5f0f\u4f1a\u793e \u7d4c\u6e08\u8abf\u67fb\u90e8\uff09 \u300c\u6df1\u5c64\u5b66\u7fd2\u3068\u30a6\u30a7\u30fc\u30d6\u30ec\u30c3\u30c8\u3092\u7528\u3044\u305f\u591a\u5909\u91cf\u6642\u7cfb\u5217\u4e88\u6e2c\u5668\u300d](http://sigfin.org/?plugin=attach&refer=SIG-FIN-017-03&openfile=SIG-FIN-017-03.pdf)\n\n> __1.\u306f\u3058\u3081\u306b1__\n>\n> 1) \u6642\u7cfb\u5217\u89e3\u6790(FAVAR)\u30012) \u6df1\u5c64\u5b66\u7fd2 (Stacked-LSTM)\u30013) \u30a6\u30a7\u30fc\u30d6\u30ec\u30c3\u30c8\u89e3\u6790\u3001\u306e 3 \u3064 \u3092\u7d44\u307f\u5408\u308f\u305b\u308b\u3053\u3068\u3067\u3001\u70ba\u66ff\u3001\u682a\u4fa1\u3001\u9271\u5de5\u696d\u751f\u7523\u306a \u3069\u3001\u69d8\u3005\u306a\u6642\u7cfb\u5217\u30c7\u30fc\u30bf\u306b\u5bfe\u3057\u3066\u4e00\u5b9a\u306e\u4e88\u6e2c\u529b\u3092\u78ba \u4fdd\u3067\u304d\u308b\u4eba\u5de5\u77e5\u80fd\u4e88\u6e2c\u5668(\u4ee5\u4e0b\u3001\u4e88\u6e2c\u5668)\u3092\u958b\u767a\u3057\u305f\u3002\n>\n> \u3053\u306e\u4e88\u6e2c\u5668\u306f\u3001\u4efb\u610f\u306b\u96c6\u3081\u305f\u5927\u91cf\u306e\u6642\u7cfb\u5217\u30c7\u30fc \u30bf\u304b\u3089\u3001\u76ee\u6a19\u3068\u3059\u308b\u5909\u6570\u306e\u4e88\u60f3\u306b\u5f79\u7acb\u3064\u30d1\u30bf\u30fc\u30f3\u3092 \u767a\u898b\u3057\u3001\u6709\u9650\u500b\u306e\u30d5\u30a1\u30af\u30bf\u30fc\u306b\u96c6\u7d04\u3059\u308b\u3002\n> \u63a8\u5b9a\u3055\u308c\u305f\u30d5\u30a1\u30af\u30bf\u30fc\u306f\u3001\u5927\u91cf\u306e\u6642\u7cfb\u5217\u30c7\u30fc\u30bf\u3092\u30a6\u30a9\u30c3\u30c1\u3059 \u308b\u3053\u3068\u3067\u4e88\u6e2c\u5668(AI)\u304c\u62b1\u3044\u305f\u300c\u666f\u6cc1\u611f\u300d\u306e\u3088\u3046\u306a\u3082\u306e\u3067\u3042\u308b\u3002\n>\n> \u3053\u3046\u3057\u305f\u30d5\u30a1\u30af\u30bf\u30fc\u3092\u3001\u4e88\u6e2c\u3057\u305f\u3044\u5909 \u6570\u304b\u3089\u306a\u308b VAR(\u591a\u5909\u91cf\u81ea\u5df1\u56de\u5e30)\u30e2\u30c7\u30eb\u306b\u52a0\u3048\u308b \u3053\u3068\u3067\u3001\u305d\u306e\u7cbe\u5ea6\u3092\u5411\u4e0a\u3055\u305b\u308b\u3053\u3068\u304c\u3067\u304d\u305f\u3002\n>\n> \u540c\u4e88\u6e2c\u5668\u306f\u3001\u5e02\u5834\u3084\u7d4c\u6e08\u306e\u300c\u5148\u3092\u8aad\u3080\u300d\u305f\u3081\u306b\u3001 \u65e5\u3005\u3001\u5e02\u5834\u306e\u5024\u52d5\u304d\u3084 GDP \u306e\u5024\u3060\u3051\u3067\u306a\u304f\u3001\u95a2\u9023\u3059\u308b\u5927\u91cf\u306e\u30c7\u30fc\u30bf\u3092\u30a6\u30a9\u30c3\u30c1\u3057\u3001\u300c\u76f8\u5834\u611f\u300d\u3084\u300c\u666f\u6cc1\u611f\u300d\u3092\u5f62\u6210\u3057\u3066\u3044\u308b\u30d7\u30ed\u306e\u5e02\u5834\u53c2\u52a0\u8005(\u30d5\u30a9\u30fc\u30ad\u30e3\u30b9\u30bf \u30fc)\u306e\u77e5\u7684\u4f5c\u696d\u3092\u6a21\u3057\u305f\u3082\u306e\u3068\u3082\u8a00\u3048\u3088\u3046\u3002\n\n\n\u3053\u308c \u3092 \u5fdc\u7528\u3059\u308c\u3070\u3001\n\n* \u8907\u6570\u9298\u67c4 \u306e \u682a\u4fa1\u6642\u7cfb\u5217\u5909\u52d5\u3001\n* \u8907\u6570 \u306e \u30de\u30af\u30ed\u7d4c\u6e08\u6307\u6a19\n* \u7279\u5b9a\u30ef\u30fc\u30c9 \u306e google\u691c\u7d22 and/or Twitter \uff08\u65e5\u6b21\uff09\u51fa\u73fe\u56de\u6570 \n\n\u306a\u3069\u3001\u8907\u6570\u306e\u30c7\u30fc\u30bf\u9805\u76ee \u304c \u6642\u9593\u3068\u5171\u306b\u5909\u52d5\u3059\u308b \u30c7\u30fc\u30bf\u7a7a\u9593 \u3092\u3001\n\n* \u6642\u9593\u8ef8 + \u591a\u6b21\u5143\u7a7a\u9593\u8ef8\uff08\uff11\u30c7\u30fc\u30bf\u9805\u76ee\uff1d\uff11\u7a7a\u9593\u8ef8\uff09 \u3067 \u5f35\u3089\u308c\u308b \u591a\u6b21\u5143\u30d9\u30af\u30c8\u30eb\u7a7a\u9593 \n\n\u3068 \u89e3\u91c8\u3059\u308c\u3070\u3001\n\n* \u3010 \u5b9f\u7e3e\u5024 \u3011\u8907\u6570\u4e8b\u8c61 \u306e \u6642\u9593\u63a8\u79fb\u5c65\u6b74 \u53ca\u3073 \uff08\u6559\u5e2b\u30e9\u30d9\u30eb\uff09\u7d4c\u6e08\u72b6\u614b\u30af\u30e9\u30b9\uff08\uff12\u30af\u30e9\u30b9 or \u591a\u30af\u30e9\u30b9\uff09 \n\n\u3092\u3000\u30d1\u30bf\u30fc\u30f3 \u3068\u3057\u3066 \u5b66\u7fd2\u3055\u305b\u3066\u3001\n\n* \uff08\u65b0\u898f\u5165\u529b\uff09 \u76f4\u8fd1\u306e\u8db3\u5143\u3000\u306e\u3000\u5f53\u8a72\u8907\u6570\u4e8b\u8c61\u306e\u6642\u9593\u63a8\u79fb\u3092\u65b0\u898f\u306b\u30e2\u30c7\u30eb\u3000\u306b \u5165\u529b\u3055\u305b\u3066\u3001\n* \uff08\u5c06\u6765\u4e88\u6e2c\uff09 \u672a\u6765\u306e\u7d4c\u6e08\u72b6\u614b\u3000\u3092 \u5206\u985e\u4e88\u6e2c\u3059\u308b\n\n\u3053\u3068 \u304c \u3067\u304d\u308b\u306f\u305a \u3067 \u3042\u308b\u3002\n\n\u4ee5\u4e0a \u3092\u3001multi-dimensional QRNN \u3067\u3082 \u3067\u304d\u306a\u3044\u3060\u308d\u3046\u304b\uff1f\n\n\n##__\uff08 \u53c2\u8003 \uff09__\n###__MLP \u3068 Deep Boltzman Machines \u3092 \u4f7f\u3063\u305f \u591a\u5909\u91cf\u6642\u7cfb\u5217\u30c7\u30fc\u30bf \u306e \u56de\u5e30\u554f\u984c \u306e \u4e8b\u4f8b__\n\n* [Gilberto Batres-Estrada, _Deep Learning for Multivariate Financial Time Series_](http://www.math.kth.se/matstat/seminarier/reports/M-exjobb15/150612a.pdf)\n", "tags": ["QRNN", "CNN", "\u6642\u7cfb\u5217\u89e3\u6790", "DeepLearning", "\u6df1\u5c64\u5b66\u7fd2"]}