{"tags": ["sparkstreaming", "Spark", "Kafka"], "context": "\n\u30a4\u30f3\u30d5\u30e9\u30a8\u30f3\u30b8\u30cb\u30a2\u3063\u307d\u304fNginx\u306e\u30a2\u30af\u30bb\u30b9\u30ed\u30b0\u3092\u30ea\u30a2\u30eb\u30bf\u30a4\u30e0\u96c6\u8a08\u3057\u3066\u307f\u308b\nSample\u304cScala\u304c\u591a\u3044\u306e\u3067Scala\u3067\u66f8\u3044\u3066\u307f\u305f(\u521dScala)\n\u306a\u3046\u306a\u611f\u3058\u3067Nginx=>Fluent=>Kafka=>SparkStreaming\nScala\u6c5a\u3044\u306e\u306f\u3086\u308b\u3057\u3066\u306d\n\u57fa\u672c\u7684\u306bWorkCount\u306esample\u3092\u3054\u306b\u3087\u3054\u306b\u3087\u3057\u305f\u3060\u3051\n\u3068\u308a\u3042\u3048\u305a\u96c6\u8a08\u3057\u3066\u307f\u308b\n\n\nSample\u30ed\u30b0\n\u3053\u3061\u3089\u3092\u4f7f\u308f\u305b\u3066\u3082\u3089\u3063\u3066LTSV\u306e\u30ed\u30b0\u3092\u7528\u610f\u3057\u307e\u3057\u305f\u3002\n\u6700\u5f8c\u306e\u884c\u3060\u3051\u9b54\u6539\u9020\u3057\u3066\u307e\u3059\u3002\n\nsample_apache_gen.rb\nputs \"time:#{Time.at(now).strftime('%d/%b/%Y:%H:%M:%S %z')}\\thost:#{record['host']}\\tforwardedfor:#{record['host']}\\treq:#{record['method']} #{record['path']} HTTP/1.1\\tstatus:#{record['code']}\\tsize:#{record['size']}\\treferer:#{record['referer']}\\tua:#{record['agent']}\"\n\n\n\nsample.log\ntime:22/Dec/2016:18:07:56 +0900 host:164.81.181.112     forwardedfor:164.81.181.112     req:GET /category/office HTTP/1.1      status:200      size:124        referer:/item/games/3481        ua:Mozilla/5.0 (iPhone; CPU iPhone OS 5_0_1 like Mac OS X) AppleWebKit/534.46 (KHTML, like Gecko) Version/5.1 Mobile/9A405 Safari/7534.48.3\ntime:22/Dec/2016:18:07:59 +0900 host:196.93.44.211      forwardedfor:196.93.44.211      req:GET /category/electronics?from=10 HTTP/1.1 status:200      size:136        referer:/category/electronics   ua:Mozilla/5.0 (Windows NT 6.1; WOW64; rv:10.0.1) Gecko/20100101 Firefox/10.0.1\ntime:22/Dec/2016:18:08:02 +0900 host:20.171.223.57      forwardedfor:20.171.223.57      req:GET /category/finance HTTP/1.1     status:200      size:78 referer:/category/office        ua:Mozilla/5.0 (compatible; MSIE 9.0; Windows NT 6.1; WOW64; Trident/5.0)\n\n\n\nFluent=>Kafka\u90e8\u5206\nfluent-plugin-kafka\u3092\u4f7f\u3063\u3066\u30ed\u30b0\u3092Kafka\u306b\u9001\u308a\u8fbc\u3080\n\n\u5168\u30e1\u30c3\u30bb\u30fc\u30b8\u3092String\u3068\u3057\u3066\u9001\u308a\u8fbc\u3080\nparse\u306fFluent\u3067\u306f\u306a\u304fSpark\u3067\u3084\u3089\u305b\u308b(\u3069\u3063\u3061\u304c\u3044\u3044\u304b\u306f\u77e5\u3089\u306a\u3044\u3051\u3069Slcala\u306e\u65b9\u304c\u65e9\u3044\u30a4\u30e1\u30fc\u30b8\uff0b\u52c9\u5f37\u306e\u305f\u3081)\n\ntd-agent-gem install fluent-plugin-kafka \u3057\u3066td-agent.conf\u3092\u304a\u304f\n\ntd-agent.conf\n<match **>\n  @type kafka\n  brokers 10.0.0.65:9092\n  zookeeper 10.0.0.65:2181\n  default_topic nginx\n</match>\n\n\n\nKafka\u6e96\u5099\n\n\u30c0\u30a6\u30f3\u30ed\u30fc\u30c9\u3057\u3066\u8a2d\u7f6e\nhttps://www.apache.org/dyn/closer.cgi?path=/kafka/0.10.1.0/kafka_2.10-0.10.1.0.tgz\n$ cd /opt\n$ wget https://www.apache.org/dyn/closer.cgi?path=/kafka/0.10.1.0/kafka_2.10-0.10.1.0.tgz\n$ tar xfvz kafka_2.10-0.10.1.0.tgz\n$ ln -s kafka_2.10-0.10.1.0 kafka\n$ cd kafka\n\n\nZookeeper\u3092\u666e\u901a\u306b\u8d77\u52d5\n$ ./bin/zookeeper-server-start.sh -daemon config/zookeeper.properties \n$ jps -v |grep zookeeper\n3839 QuorumPeerMain -Xmx512M -Xms512M -XX:+UseG1GC -XX:MaxGCPauseMillis=20 -XX:InitiatingHeapOccupancyPercent=35 -XX:+DisableExplicitGC -Djava.awt.headless=true -Xloggc:/opt/kafka/bin/../logs/zookeeper-gc.log -verbose:gc -XX:+PrintGCDetails -XX:+PrintGCDateStamps -XX:+PrintGCTimeStamps -Dcom.sun.management.jmxremote -Dcom.sun.management.jmxremote.authenticate=false -Dcom.sun.management.jmxremote.ssl=false -Dkafka.logs.dir=/opt/kafka/bin/../logs -Dlog4j.configuration=file:./bin/../config/log4j.properties\n\n\nKafka\u3092\u666e\u901a\u306b\u8d77\u52d5\n$ ./bin/kafka-server-start.sh -daemon config/server.properties\n$ jps -v |grep Kafka\n28603 Kafka -Xmx1G -Xms1G -XX:+UseG1GC -XX:MaxGCPauseMillis=20 -XX:InitiatingHeapOccupancyPercent=35 -XX:+DisableExplicitGC -Djava.awt.headless=true -Xloggc:/opt/kafka/bin/../logs/kafkaServer-gc.log -verbose:gc -XX:+PrintGCDetails -XX:+PrintGCDateStamps -XX:+PrintGCTimeStamps -Dcom.sun.management.jmxremote -Dcom.sun.management.jmxremote.authenticate=false -Dcom.sun.management.jmxremote.ssl=false -Dkafka.logs.dir=/opt/kafka/bin/../logs -Dlog4j.configuration=file:./bin/../config/log4j.properties\n\n\n\u30e1\u30c3\u30bb\u30fc\u30b8\u3092\u6d41\u3057\u8fbc\u3093\u3067\u898b\u308b\n\n\u30b3\u30f3\u30bd\u30fc\u30eb\u51fa\u529b\u3059\u308bWorker\u8d77\u52d5\n$ ./bin/kafka-console-consumer.sh --consumer-property=config/consumer.properties --zookeeper.0.0.65:2181 --topic nginx\n\n\nFluent\u306b\u30c7\u30fc\u30bf\u3092\u6d41\u3057\u8fbc\u3093\u3067\u898b\u308b\n$ head sample.log| /opt/td-agent/embendfluent-cat --none data.nginx\n\n\nWorker\u5074\u306e\u30b3\u30f3\u30bd\u30fc\u30eb\u3067\u51fa\u529b\u3055\u308c\u305f\u3089OK\n{\"message\":\"time:22/Dec/2016:18:07:56 +0900\\thost:164.81.181.112\\tforwardedfor:164.81.181.112\\treq:GET /category/office HTTP/1.1\\tstatus:200\\tsize:124\\treferer:/item/games/3481\\tua:Mozilla/5.0 (iPhone; CPU iPhone OS 5_0_1 like Mac OS X) AppleWebKit/534.46 (KHTML, like Gecko) Version/5.1 Mobile/9A405 Safari/7534.48.3\",\"timestamp\":\"2016-12-26T11:05:07+0900\"}\n{\"message\":\"time:22/Dec/2016:18:07:59 +0900\\thost:196.93.44.211\\tforwardedfor:196.93.44.211\\treq:GET /category/electronics?from=10 HTTP/1.1\\tstatus:200\\tsize:136\\treferer:/category/electronics\\tua:Mozilla/5.0 (Windows NT 6.1; WOW64; rv:10.0.1) Gecko/20100101 Firefox/10.0.1\",\"timestamp\":\"2016-12-26T11:05:07+0900\"}\n\n\nSpark\u306e\u6e96\u5099\n\u3053\u3061\u3089\u3067\u3082\u66f8\u3044\u305f\u306e\u3067\u7701\u7565\nspark-2.0.0.tgz\u3092\u53d6\u3063\u3066\u304d\u3066\u89e3\u51cd\u3057\u3066\u308b\u3060\u3051\n\nScala\u306e\u74b0\u5883\u4f5c\u6210\n\nScala\u3068SBT\u306e\u30a4\u30f3\u30b9\u30c8\u30fc\u30eb\n\nsbt 0.13.12\nscala 2.11.6-6\n\nhttps://dl.bintray.com/sbt/debian \u304b\u3089apt\u30a4\u30f3\u30b9\u30c8\u30fc\u30eb\n$ apt install scala=2.11.6-6 sbt=0.13.12\n\n\n\u30c7\u30a3\u30ec\u30af\u30c8\u30ea\u4f5c\u6210\n$ mkdir -p sample/src/main/scala/\n\n\nbuild.sbt\u4f5c\u6210\n$ cat sample/build.sbt \nimport scala.util.Properties\n\nname := \"Test\"\nversion := \"1.0\"\nscalaVersion := \"2.11.6\"\n\nlibraryDependencies += \"org.apache.spark\" % \"spark-core_2.11\" % \"2.0.0\"\nlibraryDependencies += \"org.apache.spark\" % \"spark-streaming_2.11\" % \"2.0.0\"\nlibraryDependencies += \"org.apache.spark\" % \"spark-streaming-kafka-0-8_2.11\" % \"2.0.0\"\nlibraryDependencies += \"net.liftweb\" % \"lift-json_2.11\" % \"3.0.1\"\nlibraryDependencies += \"com.github.seratch\" % \"ltsv4s_2.11\" % \"1.0.+\"\n\nassemblyMergeStrategy in assembly := {\n  case PathList(\"javax\", \"servlet\", xs @ _*)         => MergeStrategy.first\n  case PathList(ps @ _*) if ps.last endsWith \".properties\" => MergeStrategy.first\n  case PathList(ps @ _*) if ps.last endsWith \".xml\" => MergeStrategy.first\n  case PathList(ps @ _*) if ps.last endsWith \".types\" => MergeStrategy.first\n  case PathList(ps @ _*) if ps.last endsWith \".class\" => MergeStrategy.first\n  case \"application.conf\"                            => MergeStrategy.concat\n  case \"unwanted.txt\"                                => MergeStrategy.discard\n  case x =>\n    val oldStrategy = (assemblyMergeStrategy in assembly).value\n    oldStrategy(x)\n}\n\nassemblyMergeStrategy in assembly\u306b\u95a2\u3057\u3066\u306fassembly\u5b9f\u884c\u6642\u306b\u3044\u308d\u3044\u308d\u30a8\u30e9\u30fc\u306b\u306a\u3063\u3066\u3057\u307e\u3063\u305f\u306e\u3067\u30b3\u30d4\u30da\u3057\u3066\u307e\u3059(\u3088\u304f\u308f\u304b\u3063\u3066\u306a\u3044)\n\nassembly\u4f7f\u3046\u305f\u3081\u306b\u30d7\u30e9\u30b0\u30a4\u30f3\u8ffd\u52a0\n$ mkdir -p sample/project/\n$ cat sample/project/plugins.sbt \nresolvers += Resolver.url(\"artifactory\", url(\"http://scalasbt.artifactoryonline.com/scalasbt/sbt-plugin-releases\"))(Resolver.ivyStylePatterns)\n  addSbtPlugin(\"com.eed3si9n\" % \"sbt-assembly\" % \"0.14.3\")\n\n\nKafka\u53d6\u5f97\u3057\u3066print\u3059\u308b\u3060\u3051\u306e\u30b3\u30fc\u30c9\nsample\u901a\u308a\n\nsample/src/main/scala/Test.scala\npackage com.test.spark\n\nimport java.util.Date\nimport java.util.Calendar\nimport org.apache.kafka.clients.producer.{KafkaProducer, ProducerConfig, ProducerRecord}\nimport org.apache.spark.SparkConf\nimport org.apache.spark.streaming._\nimport org.apache.spark.streaming.kafka._\n\nobject KafkaWorker {\n  def main(args: Array[String]) {\n    // zkQuorum(127.0.0.1:2181), group(test), topics(nginx), numThreads(2), Sec\n    if (args.length < 5) {\n      System.exit(1)\n    }\n    val Array(zkQuorum, group, topics, numThreads, sec) = args\n    val secSleep    = sec.toInt\n    val topicMap    = topics.split(\",\").map((_, numThreads.toInt)).toMap\n    val sparkConf   = new SparkConf().setAppName(\"KafkaWorker\")\n    val ssc         = new StreamingContext(sparkConf, Seconds(secSleep))\n    val kafkaStream = KafkaUtils.createStream(ssc, zkQuorum, group, topicMap).map(_._2)\n    ssc.checkpoint(\"checkpoint\")\n\n    kafkaStream.foreachRDD{ rdd => \n      println(\"### Start %s ###\".format(Calendar.getInstance.getTime.toString))\n      rdd.foreach(print)\n      println(\"### END %s ###\\n\".format(Calendar.getInstance.getTime.toString))\n    }\n\n    ssc.start()\n    ssc.awaitTermination()\n  }\n}\n\n\n\n\u30b3\u30f3\u30d1\u30a4\u30eb\n$ cd sample/\n$ sbt assembly #\u5927\u91cf\u306bwarn\u304c\u3067\u308b\u3051\u3069Merging\u306a\u306e\u3067\u6c17\u306b\u3057\u306a\u3044\n$ ll target/scala-2.11/Test-assembly-1.0.jar \n-rw-r--r-- 1 root root 112868840 Dec 26 11:24 target/scala-2.11/Test-assembly-1.0.jar\n\n\nSpark\u3067Jar\u3092\u5b9f\u884c\n\u5f15\u6570\u306fSource\u306b\u66f8\u3044\u305f\u901a\u308a\u306b\nzkQuorum(127.0.0.1:2181), group(test), topics(nginx), numThreads(2), Sec \u306e\u9806\u756a\u3067\n$ cd /opt/spark\n$ ./bin/spark-submit --class com.test.spark.KafkaWorker  /root/sample/target/scala-2.11/Testsembly-1.0.jar 127.0.0.1:2181 test nginx 2 5\n### Start Mon Dec 26 11:31:05 JST 2016 ###\n### END Mon Dec 26 11:31:05 JST 2016 ###\n\n### Start Mon Dec 26 11:31:10 JST 2016 ###\n### END Mon Dec 26 11:31:10 JST 2016 ###\n\n\u5f15\u6570\u306b\u66f8\u3044\u305f5\u79d2\u304a\u304d\u306b\u51e6\u7406\u3057\u3066\u3044\u308b\u3063\u307d\u3044\u3053\u3068\u3092\u78ba\u8a8d\n\n\u30c7\u30fc\u30bf\u3092\u6d41\u3057\u8fbc\u3093\u3067\u898b\u308b\n$ head sample.log| /agent/embedded/bin/fluent-cat --none data.nginx\n\n### Start Mon Dec 26 11:32:20 JST 2016 ###\n{\"message\":\"time:22/Dec/2016:18:07:56 +0900\\thost:164.81.181.112\\tforwardedfor:164.81.181.112\\treq:GET /category/office HTTP/1.1\\tstatus:200\\tsize:124\\treferer:/item/games/3481\\tua:Mozilla/5.0 (iPhone; CPU iPhone OS 5_0_1 like Mac OS X) AppleWebKit/534.46 (KHTML, like Gecko) Version/5.1 Mobile/9A405 Safari/7534.48.3\",\"timestamp\":\"2016-12-26T11:32:16+0900\"}{\"message\":\"time:22/Dec/2016:18:07:59 +0900\\thost:196.93.44.211\\tforwardedfor:196.93.44.211\\treq:GET /category/electronics?from=10 HTTP/1.1\\tstatus:200\\tsize:136\\treferer:/category/electronics\\tua:Mozilla/5.0 (Windows NT 6.1; WOW64; rv:10.0.1) Gecko/20100101 Firefox/10.0.1\",\"timestamp\":\"2016-12-26T11:32:16+0900\"}{\"message\":\"time:22/Dec/2016:18:08:02 +0900\\thost:20.171.223.57\\tforwardedfor:20.171.223.57\\treq:GET /category/finance HTTP/1.1\\tstatus:200\\tsize:78\\treferer:/category/office\\tua:Mozilla/5.0 (compatible; MSIE 9.0; Windows NT 6.1; WOW64; Trident/5.0)\",\"timestamp\":\"2016-12-26T11:32:16+0900\"}{\"message\":\"time:22/Dec/2016:18:08:06 +0900\\thost:212.159.169.49\\tforwardedfor:212.159.169.49\\treq:GET /item/computers/2268 HTTP/1.1\\tstatus:200\\tsize:139\\treferer:/item/networking/248\\tua:Mozilla/5.0 (Windows NT 6.1; WOW64) AppleWebKit/535.11 (KHTML, like Gecko) Chrome/17.0.963.56 Safari/535.11\",\"timestamp\":\"2016-12-26T11:32:16+0900\"}{\"message\":\"time:22/Dec/2016:18:08:07 +0900\\thost:140.69.110.95\\tforwardedfor:140.69.110.95\\treq:GET /category/books HTTP/1.1\\tstatus:200\\tsize:109\\treferer:-\\tua:Mozilla/5.0 (Macintosh; Intel Mac OS X 10.6; rv:9.0.1) Gecko/20100101 Firefox/9.0.1\",\"timestamp\":\"2016-12-26T11:32:16+0900\"}{\"message\":\"time:22/Dec/2016:18:08:09 +0900\\thost:172.18.127.139\\tforwardedfor:172.18.127.139\\treq:GET /category/electronics HTTP/1.1\\tstatus:200\\tsize:135\\treferer:-\\tua:Mozilla/5.0 (Windows NT 6.0; rv:10.0.1) Gecko/20100101 Firefox/10.0.1\",\"timestamp\":\"2016-12-26T11:32:16+0900\"}{\"message\":\"time:22/Dec/2016:18:08:12 +0900\\thost:120.222.102.169\\tforwardedfor:120.222.102.169\\treq:POST /search/?c=Computers+Electronics HTTP/1.1\\tstatus:200\\tsize:128\\treferer:-\\tua:Mozilla/5.0 (Windows NT 6.1; WOW64) AppleWebKit/535.11 (KHTML, like Gecko) Chrome/17.0.963.56 Safari/535.11\",\"timestamp\":\"2016-12-26T11:32:16+0900\"}{\"message\":\"time:22/Dec/2016:18:08:16 +0900\\thost:116.150.211.139\\tforwardedfor:116.150.211.139\\treq:GET /category/electronics HTTP/1.1\\tstatus:200\\tsize:55\\treferer:-\\tua:Mozilla/4.0 (compatible; MSIE 8.0; Windows NT 6.1; WOW64; Trident/4.0; GTB7.2; SLCC2; .NET CLR 2.0.50727; .NET CLR 3.5.30729; .NET CLR 3.0.30729; Media Center PC 6.0; .NET4.0C)\",\"timestamp\":\"2016-12-26T11:32:16+0900\"}{\"message\":\"time:22/Dec/2016:18:08:16 +0900\\thost:192.42.23.199\\tforwardedfor:192.42.23.199\\treq:GET /category/networking HTTP/1.1\\tstatus:200\\tsize:59\\treferer:-\\tua:Mozilla/5.0 (Windows NT 6.1; WOW64) AppleWebKit/535.7 (KHTML, like Gecko) Chrome/16.0.912.77 Safari/535.7\",\"timestamp\":\"2016-12-26T11:32:16+0900\"}{\"message\":\"time:22/Dec/2016:18:08:16 +0900\\thost:220.84.166.98\\tforwardedfor:220.84.166.98\\treq:GET /category/toys HTTP/1.1\\tstatus:200\\tsize:124\\treferer:/item/office/4833\\tua:Mozilla/5.0 (compatible; Googlebot/2.1; +http://www.google.com/bot.html)\",\"timestamp\":\"2016-12-26T11:32:16+0900\"}\n### END Mon Dec 26 11:32:20 JST 2016 ###\n\n\u3061\u3083\u3093\u3068Kafka\u304b\u3089fetch\u3057\u3066print\u3057\u3066\u3044\u308b\u3002\n\n\u96c6\u8a08\u3057\u3066\u307f\u308b\n\u30a2\u30af\u30bb\u30b9\u30ed\u30b0\u306e\u30ea\u30af\u30a8\u30b9\u30c8\u30d1\u30b9\u306e1\u968e\u5c64\u76ee GET /category/office HTTP/1.1 \u306e category \u30925\u79d2\u6bce\u306b\u96c6\u8a08\u3057\u3066\u307f\u308b\nicon\u3068\u304bjs\u3068\u304b\u30a8\u30e9\u30fc\u30ec\u30b9\u30dd\u30f3\u30b9\u306f\u9664\u5916\u3057\u305f\u3044\u306e\u3067\u6761\u4ef6\u306f status == 200 \u304b\u3064 size > 100 \u3067\u30d5\u30a3\u30eb\u30bf\u30ea\u30f3\u30b0\u3057\u3066\u307f\u308b\n\nSource\n\nsample/src/main/scala/Test.scala\npackage com.test.spark\n\nimport java.util.HashMap\nimport java.util.Date\nimport java.util.Calendar\nimport org.apache.kafka.clients.producer.{KafkaProducer, ProducerConfig, ProducerRecord}\nimport org.apache.spark.SparkConf\nimport org.apache.spark.streaming._\nimport org.apache.spark.streaming.kafka._\nimport scala.util.parsing.json.JSON\nimport net.liftweb._\nimport net.liftweb.json._\nimport com.github.seratch.ltsv4s._\n\nobject KafkaWorker {\n  case class FluentEvent(\n      timestamp: String,\n      message: String\n    )\n\n  def main(args: Array[String]) {\n    // zkQuorum(127.0.0.1:2181), group(test), topics(imp), numThreads(2), Sec\n    if (args.length < 5) {\n      System.exit(1)\n    }\n    val Array(zkQuorum, group, topics, numThreads, sec) = args\n    val secSleep    = sec.toInt\n    val topicMap    = topics.split(\",\").map((_, numThreads.toInt)).toMap\n    val sparkConf   = new SparkConf().setAppName(\"KafkaWorker\")\n    val ssc         = new StreamingContext(sparkConf, Seconds(secSleep))\n    val kafkaStream = KafkaUtils.createStream(ssc, zkQuorum, group, topicMap).map(_._2)\n\n    ssc.checkpoint(\"checkpoint\")\n\n    val nginxStream = kafkaStream.map(convertFluentToMap(_))\n    // \u30b9\u30c6\u30fc\u30bf\u30b9\u30b3\u30fc\u30c9200\u4ee5\u4e0a\u3067respons\u304c100Byte\u4ee5\u4e0a\u306e\u30ea\u30af\u30a8\u30b9\u30c8\u3092\u30d1\u30b9(\u7b2c1\u968e\u5c64)\u306e\u307f\u62bd\u51fa\n    val pathsStream = nginxStream.map{nginxRecord =>\n      if (nginxRecord(\"size\").toInt >= 100 && nginxRecord(\"status\").toInt == 200 ){\n        reqToPath(nginxRecord(\"req\")).split(\"/\")(1)\n      }\n    }\n    // path\u6bce\u306bcount\u3059\u308b\n    val countPath = pathsStream.map((_, 1))\n      .reduceByKeyAndWindow(_ + _, Seconds(secSleep))\n      .map{case (path, count) => (count, path)}\n      .transform(_.sortByKey(false))\n\n    // OutPut\n    countPath.foreachRDD{ rdd => \n      println(\"### Start %s ###\".format(Calendar.getInstance.getTime.toString))\n      val path = rdd.take(10) \n      path.foreach{case (count, tag) => \n        tag match {\n          case tag: String => println(\"%s count (%s)\".format(count, tag))\n          case _ => println(\"%s count not match\".format(count))\n        }\n      }\n      println(\"### END %s ###\\n\".format(Calendar.getInstance.getTime.toString))\n    }\n\n    ssc.start()\n    ssc.awaitTermination()\n  }\n  def parseNginxLtsv(record: String) = { LTSV.parseLine(record) }\n  def parseFluentJson(record: String) = {\n    implicit val formats = DefaultFormats\n    parse(record).extract[FluentEvent].message\n  }\n  def convertFluentToMap(record: String) = { parseNginxLtsv(parseFluentJson(record)) }\n  def reqToPath(record: String) = { record.split(\" \")(1) }\n}\n\n\n\n\u52d5\u304b\u3057\u3066\u307f\u308b\n$ sbt assembly\n$ cd /opt/spark\n$ ./bin/spark-submit --class com.test.spark.KafkaWorker  /root/sample/target/scala-2.11/Test-assembly-1.0.jar 127.0.0.1:2181 test nginx 2 5\n### Start Mon Dec 26 12:32:25 JST 2016 ###                                      \n879 count not match\n285 count (category)\n190 count (item)\n48 count (search)\n### END Mon Dec 26 12:32:25 JST 2016 ###\n\n### Start Mon Dec 26 12:32:30 JST 2016 ###\n802 count not match\n267 count (category)\n175 count (item)\n38 count (search)\n### END Mon Dec 26 12:32:30 JST 2016 ###\n\n### Start Mon Dec 26 12:32:35 JST 2016 ###\n895 count not match\n321 count (category)\n181 count (item)\n53 count (search)\n### END Mon Dec 26 12:32:35 JST 2016 ###\n\n\u6642\u9593\u3042\u3063\u305f\u3089Fluent\u306eDataCounter\u3068\u304bNorikura\u3068\u304b\u3068\u6027\u80fd\u8a66\u9a13\u3068\u304b\u3057\u3066\u307f\u305f\u3044\u3002\n- \u30a4\u30f3\u30d5\u30e9\u30a8\u30f3\u30b8\u30cb\u30a2\u3063\u307d\u304fNginx\u306e\u30a2\u30af\u30bb\u30b9\u30ed\u30b0\u3092\u30ea\u30a2\u30eb\u30bf\u30a4\u30e0\u96c6\u8a08\u3057\u3066\u307f\u308b\n- Sample\u304cScala\u304c\u591a\u3044\u306e\u3067Scala\u3067\u66f8\u3044\u3066\u307f\u305f(\u521dScala)\n- \u306a\u3046\u306a\u611f\u3058\u3067Nginx=>Fluent=>Kafka=>SparkStreaming\n- Scala\u6c5a\u3044\u306e\u306f\u3086\u308b\u3057\u3066\u306d\n- \u57fa\u672c\u7684\u306bWorkCount\u306esample\u3092\u3054\u306b\u3087\u3054\u306b\u3087\u3057\u305f\u3060\u3051\n- \u3068\u308a\u3042\u3048\u305a\u96c6\u8a08\u3057\u3066\u307f\u308b\n\n# Sample\u30ed\u30b0\n\n[\u3053\u3061\u3089](https://github.com/treasure-data/td/blob/master/data/sample_apache_gen.rb)\u3092\u4f7f\u308f\u305b\u3066\u3082\u3089\u3063\u3066LTSV\u306e\u30ed\u30b0\u3092\u7528\u610f\u3057\u307e\u3057\u305f\u3002\n\u6700\u5f8c\u306e\u884c\u3060\u3051\u9b54\u6539\u9020\u3057\u3066\u307e\u3059\u3002\n\n```rb:sample_apache_gen.rb\nputs \"time:#{Time.at(now).strftime('%d/%b/%Y:%H:%M:%S %z')}\\thost:#{record['host']}\\tforwardedfor:#{record['host']}\\treq:#{record['method']} #{record['path']} HTTP/1.1\\tstatus:#{record['code']}\\tsize:#{record['size']}\\treferer:#{record['referer']}\\tua:#{record['agent']}\"\n```\n\n```sample.log\ntime:22/Dec/2016:18:07:56 +0900 host:164.81.181.112     forwardedfor:164.81.181.112     req:GET /category/office HTTP/1.1      status:200      size:124        referer:/item/games/3481        ua:Mozilla/5.0 (iPhone; CPU iPhone OS 5_0_1 like Mac OS X) AppleWebKit/534.46 (KHTML, like Gecko) Version/5.1 Mobile/9A405 Safari/7534.48.3\ntime:22/Dec/2016:18:07:59 +0900 host:196.93.44.211      forwardedfor:196.93.44.211      req:GET /category/electronics?from=10 HTTP/1.1 status:200      size:136        referer:/category/electronics   ua:Mozilla/5.0 (Windows NT 6.1; WOW64; rv:10.0.1) Gecko/20100101 Firefox/10.0.1\ntime:22/Dec/2016:18:08:02 +0900 host:20.171.223.57      forwardedfor:20.171.223.57      req:GET /category/finance HTTP/1.1     status:200      size:78 referer:/category/office        ua:Mozilla/5.0 (compatible; MSIE 9.0; Windows NT 6.1; WOW64; Trident/5.0)\n```\n\n# Fluent=>Kafka\u90e8\u5206\n\n[fluent-plugin-kafka](https://github.com/fluent/fluent-plugin-kafka)\u3092\u4f7f\u3063\u3066\u30ed\u30b0\u3092Kafka\u306b\u9001\u308a\u8fbc\u3080\n\n- \u5168\u30e1\u30c3\u30bb\u30fc\u30b8\u3092String\u3068\u3057\u3066\u9001\u308a\u8fbc\u3080\n- parse\u306fFluent\u3067\u306f\u306a\u304fSpark\u3067\u3084\u3089\u305b\u308b(\u3069\u3063\u3061\u304c\u3044\u3044\u304b\u306f\u77e5\u3089\u306a\u3044\u3051\u3069Slcala\u306e\u65b9\u304c\u65e9\u3044\u30a4\u30e1\u30fc\u30b8\uff0b\u52c9\u5f37\u306e\u305f\u3081)\n\n`td-agent-gem install fluent-plugin-kafka` \u3057\u3066td-agent.conf\u3092\u304a\u304f\n\n```td-agent.conf\n<match **>\n  @type kafka\n  brokers 10.0.0.65:9092\n  zookeeper 10.0.0.65:2181\n  default_topic nginx\n</match>\n```\n\n# Kafka\u6e96\u5099\n\n### \u30c0\u30a6\u30f3\u30ed\u30fc\u30c9\u3057\u3066\u8a2d\u7f6e\nhttps://www.apache.org/dyn/closer.cgi?path=/kafka/0.10.1.0/kafka_2.10-0.10.1.0.tgz\n\n```bash\n$ cd /opt\n$ wget https://www.apache.org/dyn/closer.cgi?path=/kafka/0.10.1.0/kafka_2.10-0.10.1.0.tgz\n$ tar xfvz kafka_2.10-0.10.1.0.tgz\n$ ln -s kafka_2.10-0.10.1.0 kafka\n$ cd kafka\n```\n\n## Zookeeper\u3092\u666e\u901a\u306b\u8d77\u52d5\n\n```bash\n$ ./bin/zookeeper-server-start.sh -daemon config/zookeeper.properties \n$ jps -v |grep zookeeper\n3839 QuorumPeerMain -Xmx512M -Xms512M -XX:+UseG1GC -XX:MaxGCPauseMillis=20 -XX:InitiatingHeapOccupancyPercent=35 -XX:+DisableExplicitGC -Djava.awt.headless=true -Xloggc:/opt/kafka/bin/../logs/zookeeper-gc.log -verbose:gc -XX:+PrintGCDetails -XX:+PrintGCDateStamps -XX:+PrintGCTimeStamps -Dcom.sun.management.jmxremote -Dcom.sun.management.jmxremote.authenticate=false -Dcom.sun.management.jmxremote.ssl=false -Dkafka.logs.dir=/opt/kafka/bin/../logs -Dlog4j.configuration=file:./bin/../config/log4j.properties\n```\n\n## Kafka\u3092\u666e\u901a\u306b\u8d77\u52d5\n\n```\n$ ./bin/kafka-server-start.sh -daemon config/server.properties\n$ jps -v |grep Kafka\n28603 Kafka -Xmx1G -Xms1G -XX:+UseG1GC -XX:MaxGCPauseMillis=20 -XX:InitiatingHeapOccupancyPercent=35 -XX:+DisableExplicitGC -Djava.awt.headless=true -Xloggc:/opt/kafka/bin/../logs/kafkaServer-gc.log -verbose:gc -XX:+PrintGCDetails -XX:+PrintGCDateStamps -XX:+PrintGCTimeStamps -Dcom.sun.management.jmxremote -Dcom.sun.management.jmxremote.authenticate=false -Dcom.sun.management.jmxremote.ssl=false -Dkafka.logs.dir=/opt/kafka/bin/../logs -Dlog4j.configuration=file:./bin/../config/log4j.properties\n```\n\n## \u30e1\u30c3\u30bb\u30fc\u30b8\u3092\u6d41\u3057\u8fbc\u3093\u3067\u898b\u308b\n\n### \u30b3\u30f3\u30bd\u30fc\u30eb\u51fa\u529b\u3059\u308bWorker\u8d77\u52d5\n\n```bash\n$ ./bin/kafka-console-consumer.sh --consumer-property=config/consumer.properties --zookeeper.0.0.65:2181 --topic nginx\n```\n\n### Fluent\u306b\u30c7\u30fc\u30bf\u3092\u6d41\u3057\u8fbc\u3093\u3067\u898b\u308b\n\n```bash\n$ head sample.log| /opt/td-agent/embendfluent-cat --none data.nginx\n```\n\n### Worker\u5074\u306e\u30b3\u30f3\u30bd\u30fc\u30eb\u3067\u51fa\u529b\u3055\u308c\u305f\u3089OK\n\n```bash\n{\"message\":\"time:22/Dec/2016:18:07:56 +0900\\thost:164.81.181.112\\tforwardedfor:164.81.181.112\\treq:GET /category/office HTTP/1.1\\tstatus:200\\tsize:124\\treferer:/item/games/3481\\tua:Mozilla/5.0 (iPhone; CPU iPhone OS 5_0_1 like Mac OS X) AppleWebKit/534.46 (KHTML, like Gecko) Version/5.1 Mobile/9A405 Safari/7534.48.3\",\"timestamp\":\"2016-12-26T11:05:07+0900\"}\n{\"message\":\"time:22/Dec/2016:18:07:59 +0900\\thost:196.93.44.211\\tforwardedfor:196.93.44.211\\treq:GET /category/electronics?from=10 HTTP/1.1\\tstatus:200\\tsize:136\\treferer:/category/electronics\\tua:Mozilla/5.0 (Windows NT 6.1; WOW64; rv:10.0.1) Gecko/20100101 Firefox/10.0.1\",\"timestamp\":\"2016-12-26T11:05:07+0900\"}\n```\n\n# Spark\u306e\u6e96\u5099\n\n[\u3053\u3061\u3089](http://qiita.com/akishitara/items/e4e3825f7144c748225e#spark-setup)\u3067\u3082\u66f8\u3044\u305f\u306e\u3067\u7701\u7565\nspark-2.0.0.tgz\u3092\u53d6\u3063\u3066\u304d\u3066\u89e3\u51cd\u3057\u3066\u308b\u3060\u3051\n\n# Scala\u306e\u74b0\u5883\u4f5c\u6210\n\n## Scala\u3068SBT\u306e\u30a4\u30f3\u30b9\u30c8\u30fc\u30eb\n\n- sbt 0.13.12\n- scala 2.11.6-6\n\nhttps://dl.bintray.com/sbt/debian \u304b\u3089apt\u30a4\u30f3\u30b9\u30c8\u30fc\u30eb\n\n```bash\n$ apt install scala=2.11.6-6 sbt=0.13.12\n```\n\n## \u30c7\u30a3\u30ec\u30af\u30c8\u30ea\u4f5c\u6210\n\n```bash\n$ mkdir -p sample/src/main/scala/\n```\n\n## build.sbt\u4f5c\u6210\n\n```scala\n$ cat sample/build.sbt \nimport scala.util.Properties\n\nname := \"Test\"\nversion := \"1.0\"\nscalaVersion := \"2.11.6\"\n\nlibraryDependencies += \"org.apache.spark\" % \"spark-core_2.11\" % \"2.0.0\"\nlibraryDependencies += \"org.apache.spark\" % \"spark-streaming_2.11\" % \"2.0.0\"\nlibraryDependencies += \"org.apache.spark\" % \"spark-streaming-kafka-0-8_2.11\" % \"2.0.0\"\nlibraryDependencies += \"net.liftweb\" % \"lift-json_2.11\" % \"3.0.1\"\nlibraryDependencies += \"com.github.seratch\" % \"ltsv4s_2.11\" % \"1.0.+\"\n\nassemblyMergeStrategy in assembly := {\n  case PathList(\"javax\", \"servlet\", xs @ _*)         => MergeStrategy.first\n  case PathList(ps @ _*) if ps.last endsWith \".properties\" => MergeStrategy.first\n  case PathList(ps @ _*) if ps.last endsWith \".xml\" => MergeStrategy.first\n  case PathList(ps @ _*) if ps.last endsWith \".types\" => MergeStrategy.first\n  case PathList(ps @ _*) if ps.last endsWith \".class\" => MergeStrategy.first\n  case \"application.conf\"                            => MergeStrategy.concat\n  case \"unwanted.txt\"                                => MergeStrategy.discard\n  case x =>\n    val oldStrategy = (assemblyMergeStrategy in assembly).value\n    oldStrategy(x)\n}\n```\n\nassemblyMergeStrategy in assembly\u306b\u95a2\u3057\u3066\u306fassembly\u5b9f\u884c\u6642\u306b\u3044\u308d\u3044\u308d\u30a8\u30e9\u30fc\u306b\u306a\u3063\u3066\u3057\u307e\u3063\u305f\u306e\u3067\u30b3\u30d4\u30da\u3057\u3066\u307e\u3059(\u3088\u304f\u308f\u304b\u3063\u3066\u306a\u3044)\n\n## assembly\u4f7f\u3046\u305f\u3081\u306b\u30d7\u30e9\u30b0\u30a4\u30f3\u8ffd\u52a0\n\n```scala\n$ mkdir -p sample/project/\n$ cat sample/project/plugins.sbt \nresolvers += Resolver.url(\"artifactory\", url(\"http://scalasbt.artifactoryonline.com/scalasbt/sbt-plugin-releases\"))(Resolver.ivyStylePatterns)\n  addSbtPlugin(\"com.eed3si9n\" % \"sbt-assembly\" % \"0.14.3\")\n```\n\n## Kafka\u53d6\u5f97\u3057\u3066print\u3059\u308b\u3060\u3051\u306e\u30b3\u30fc\u30c9\n\nsample\u901a\u308a\n\n```Scala:sample/src/main/scala/Test.scala\npackage com.test.spark\n\nimport java.util.Date\nimport java.util.Calendar\nimport org.apache.kafka.clients.producer.{KafkaProducer, ProducerConfig, ProducerRecord}\nimport org.apache.spark.SparkConf\nimport org.apache.spark.streaming._\nimport org.apache.spark.streaming.kafka._\n\nobject KafkaWorker {\n  def main(args: Array[String]) {\n    // zkQuorum(127.0.0.1:2181), group(test), topics(nginx), numThreads(2), Sec\n    if (args.length < 5) {\n      System.exit(1)\n    }\n    val Array(zkQuorum, group, topics, numThreads, sec) = args\n    val secSleep    = sec.toInt\n    val topicMap    = topics.split(\",\").map((_, numThreads.toInt)).toMap\n    val sparkConf   = new SparkConf().setAppName(\"KafkaWorker\")\n    val ssc         = new StreamingContext(sparkConf, Seconds(secSleep))\n    val kafkaStream = KafkaUtils.createStream(ssc, zkQuorum, group, topicMap).map(_._2)\n    ssc.checkpoint(\"checkpoint\")\n\n    kafkaStream.foreachRDD{ rdd => \n      println(\"### Start %s ###\".format(Calendar.getInstance.getTime.toString))\n      rdd.foreach(print)\n      println(\"### END %s ###\\n\".format(Calendar.getInstance.getTime.toString))\n    }\n\n    ssc.start()\n    ssc.awaitTermination()\n  }\n}\n```\n\n## \u30b3\u30f3\u30d1\u30a4\u30eb\n\n```bash\n$ cd sample/\n$ sbt assembly #\u5927\u91cf\u306bwarn\u304c\u3067\u308b\u3051\u3069Merging\u306a\u306e\u3067\u6c17\u306b\u3057\u306a\u3044\n$ ll target/scala-2.11/Test-assembly-1.0.jar \n-rw-r--r-- 1 root root 112868840 Dec 26 11:24 target/scala-2.11/Test-assembly-1.0.jar\n```\n\n## Spark\u3067Jar\u3092\u5b9f\u884c\n\n\u5f15\u6570\u306fSource\u306b\u66f8\u3044\u305f\u901a\u308a\u306b\nzkQuorum(127.0.0.1:2181), group(test), topics(nginx), numThreads(2), Sec \u306e\u9806\u756a\u3067\n\n```bash\n$ cd /opt/spark\n$ ./bin/spark-submit --class com.test.spark.KafkaWorker  /root/sample/target/scala-2.11/Testsembly-1.0.jar 127.0.0.1:2181 test nginx 2 5\n### Start Mon Dec 26 11:31:05 JST 2016 ###\n### END Mon Dec 26 11:31:05 JST 2016 ###\n\n### Start Mon Dec 26 11:31:10 JST 2016 ###\n### END Mon Dec 26 11:31:10 JST 2016 ###\n```\n\n\u5f15\u6570\u306b\u66f8\u3044\u305f5\u79d2\u304a\u304d\u306b\u51e6\u7406\u3057\u3066\u3044\u308b\u3063\u307d\u3044\u3053\u3068\u3092\u78ba\u8a8d\n\n## \u30c7\u30fc\u30bf\u3092\u6d41\u3057\u8fbc\u3093\u3067\u898b\u308b\n\n```bash\n$ head sample.log| /agent/embedded/bin/fluent-cat --none data.nginx\n```\n\n```\n### Start Mon Dec 26 11:32:20 JST 2016 ###\n{\"message\":\"time:22/Dec/2016:18:07:56 +0900\\thost:164.81.181.112\\tforwardedfor:164.81.181.112\\treq:GET /category/office HTTP/1.1\\tstatus:200\\tsize:124\\treferer:/item/games/3481\\tua:Mozilla/5.0 (iPhone; CPU iPhone OS 5_0_1 like Mac OS X) AppleWebKit/534.46 (KHTML, like Gecko) Version/5.1 Mobile/9A405 Safari/7534.48.3\",\"timestamp\":\"2016-12-26T11:32:16+0900\"}{\"message\":\"time:22/Dec/2016:18:07:59 +0900\\thost:196.93.44.211\\tforwardedfor:196.93.44.211\\treq:GET /category/electronics?from=10 HTTP/1.1\\tstatus:200\\tsize:136\\treferer:/category/electronics\\tua:Mozilla/5.0 (Windows NT 6.1; WOW64; rv:10.0.1) Gecko/20100101 Firefox/10.0.1\",\"timestamp\":\"2016-12-26T11:32:16+0900\"}{\"message\":\"time:22/Dec/2016:18:08:02 +0900\\thost:20.171.223.57\\tforwardedfor:20.171.223.57\\treq:GET /category/finance HTTP/1.1\\tstatus:200\\tsize:78\\treferer:/category/office\\tua:Mozilla/5.0 (compatible; MSIE 9.0; Windows NT 6.1; WOW64; Trident/5.0)\",\"timestamp\":\"2016-12-26T11:32:16+0900\"}{\"message\":\"time:22/Dec/2016:18:08:06 +0900\\thost:212.159.169.49\\tforwardedfor:212.159.169.49\\treq:GET /item/computers/2268 HTTP/1.1\\tstatus:200\\tsize:139\\treferer:/item/networking/248\\tua:Mozilla/5.0 (Windows NT 6.1; WOW64) AppleWebKit/535.11 (KHTML, like Gecko) Chrome/17.0.963.56 Safari/535.11\",\"timestamp\":\"2016-12-26T11:32:16+0900\"}{\"message\":\"time:22/Dec/2016:18:08:07 +0900\\thost:140.69.110.95\\tforwardedfor:140.69.110.95\\treq:GET /category/books HTTP/1.1\\tstatus:200\\tsize:109\\treferer:-\\tua:Mozilla/5.0 (Macintosh; Intel Mac OS X 10.6; rv:9.0.1) Gecko/20100101 Firefox/9.0.1\",\"timestamp\":\"2016-12-26T11:32:16+0900\"}{\"message\":\"time:22/Dec/2016:18:08:09 +0900\\thost:172.18.127.139\\tforwardedfor:172.18.127.139\\treq:GET /category/electronics HTTP/1.1\\tstatus:200\\tsize:135\\treferer:-\\tua:Mozilla/5.0 (Windows NT 6.0; rv:10.0.1) Gecko/20100101 Firefox/10.0.1\",\"timestamp\":\"2016-12-26T11:32:16+0900\"}{\"message\":\"time:22/Dec/2016:18:08:12 +0900\\thost:120.222.102.169\\tforwardedfor:120.222.102.169\\treq:POST /search/?c=Computers+Electronics HTTP/1.1\\tstatus:200\\tsize:128\\treferer:-\\tua:Mozilla/5.0 (Windows NT 6.1; WOW64) AppleWebKit/535.11 (KHTML, like Gecko) Chrome/17.0.963.56 Safari/535.11\",\"timestamp\":\"2016-12-26T11:32:16+0900\"}{\"message\":\"time:22/Dec/2016:18:08:16 +0900\\thost:116.150.211.139\\tforwardedfor:116.150.211.139\\treq:GET /category/electronics HTTP/1.1\\tstatus:200\\tsize:55\\treferer:-\\tua:Mozilla/4.0 (compatible; MSIE 8.0; Windows NT 6.1; WOW64; Trident/4.0; GTB7.2; SLCC2; .NET CLR 2.0.50727; .NET CLR 3.5.30729; .NET CLR 3.0.30729; Media Center PC 6.0; .NET4.0C)\",\"timestamp\":\"2016-12-26T11:32:16+0900\"}{\"message\":\"time:22/Dec/2016:18:08:16 +0900\\thost:192.42.23.199\\tforwardedfor:192.42.23.199\\treq:GET /category/networking HTTP/1.1\\tstatus:200\\tsize:59\\treferer:-\\tua:Mozilla/5.0 (Windows NT 6.1; WOW64) AppleWebKit/535.7 (KHTML, like Gecko) Chrome/16.0.912.77 Safari/535.7\",\"timestamp\":\"2016-12-26T11:32:16+0900\"}{\"message\":\"time:22/Dec/2016:18:08:16 +0900\\thost:220.84.166.98\\tforwardedfor:220.84.166.98\\treq:GET /category/toys HTTP/1.1\\tstatus:200\\tsize:124\\treferer:/item/office/4833\\tua:Mozilla/5.0 (compatible; Googlebot/2.1; +http://www.google.com/bot.html)\",\"timestamp\":\"2016-12-26T11:32:16+0900\"}\n### END Mon Dec 26 11:32:20 JST 2016 ###\n```\n\n\u3061\u3083\u3093\u3068Kafka\u304b\u3089fetch\u3057\u3066print\u3057\u3066\u3044\u308b\u3002\n\n\n# \u96c6\u8a08\u3057\u3066\u307f\u308b\n\n\u30a2\u30af\u30bb\u30b9\u30ed\u30b0\u306e\u30ea\u30af\u30a8\u30b9\u30c8\u30d1\u30b9\u306e1\u968e\u5c64\u76ee `GET /category/office HTTP/1.1` \u306e `category` \u30925\u79d2\u6bce\u306b\u96c6\u8a08\u3057\u3066\u307f\u308b\nicon\u3068\u304bjs\u3068\u304b\u30a8\u30e9\u30fc\u30ec\u30b9\u30dd\u30f3\u30b9\u306f\u9664\u5916\u3057\u305f\u3044\u306e\u3067\u6761\u4ef6\u306f `status == 200` \u304b\u3064 `size > 100` \u3067\u30d5\u30a3\u30eb\u30bf\u30ea\u30f3\u30b0\u3057\u3066\u307f\u308b\n\n## Source\n\n```Scala:sample/src/main/scala/Test.scala\npackage com.test.spark\n\nimport java.util.HashMap\nimport java.util.Date\nimport java.util.Calendar\nimport org.apache.kafka.clients.producer.{KafkaProducer, ProducerConfig, ProducerRecord}\nimport org.apache.spark.SparkConf\nimport org.apache.spark.streaming._\nimport org.apache.spark.streaming.kafka._\nimport scala.util.parsing.json.JSON\nimport net.liftweb._\nimport net.liftweb.json._\nimport com.github.seratch.ltsv4s._\n\nobject KafkaWorker {\n  case class FluentEvent(\n      timestamp: String,\n      message: String\n    )\n\n  def main(args: Array[String]) {\n    // zkQuorum(127.0.0.1:2181), group(test), topics(imp), numThreads(2), Sec\n    if (args.length < 5) {\n      System.exit(1)\n    }\n    val Array(zkQuorum, group, topics, numThreads, sec) = args\n    val secSleep    = sec.toInt\n    val topicMap    = topics.split(\",\").map((_, numThreads.toInt)).toMap\n    val sparkConf   = new SparkConf().setAppName(\"KafkaWorker\")\n    val ssc         = new StreamingContext(sparkConf, Seconds(secSleep))\n    val kafkaStream = KafkaUtils.createStream(ssc, zkQuorum, group, topicMap).map(_._2)\n\n    ssc.checkpoint(\"checkpoint\")\n\n    val nginxStream = kafkaStream.map(convertFluentToMap(_))\n    // \u30b9\u30c6\u30fc\u30bf\u30b9\u30b3\u30fc\u30c9200\u4ee5\u4e0a\u3067respons\u304c100Byte\u4ee5\u4e0a\u306e\u30ea\u30af\u30a8\u30b9\u30c8\u3092\u30d1\u30b9(\u7b2c1\u968e\u5c64)\u306e\u307f\u62bd\u51fa\n    val pathsStream = nginxStream.map{nginxRecord =>\n      if (nginxRecord(\"size\").toInt >= 100 && nginxRecord(\"status\").toInt == 200 ){\n        reqToPath(nginxRecord(\"req\")).split(\"/\")(1)\n      }\n    }\n    // path\u6bce\u306bcount\u3059\u308b\n    val countPath = pathsStream.map((_, 1))\n      .reduceByKeyAndWindow(_ + _, Seconds(secSleep))\n      .map{case (path, count) => (count, path)}\n      .transform(_.sortByKey(false))\n\n    // OutPut\n    countPath.foreachRDD{ rdd => \n      println(\"### Start %s ###\".format(Calendar.getInstance.getTime.toString))\n      val path = rdd.take(10) \n      path.foreach{case (count, tag) => \n        tag match {\n          case tag: String => println(\"%s count (%s)\".format(count, tag))\n          case _ => println(\"%s count not match\".format(count))\n        }\n      }\n      println(\"### END %s ###\\n\".format(Calendar.getInstance.getTime.toString))\n    }\n\n    ssc.start()\n    ssc.awaitTermination()\n  }\n  def parseNginxLtsv(record: String) = { LTSV.parseLine(record) }\n  def parseFluentJson(record: String) = {\n    implicit val formats = DefaultFormats\n    parse(record).extract[FluentEvent].message\n  }\n  def convertFluentToMap(record: String) = { parseNginxLtsv(parseFluentJson(record)) }\n  def reqToPath(record: String) = { record.split(\" \")(1) }\n}\n```\n\n## \u52d5\u304b\u3057\u3066\u307f\u308b\n\n```bash\n$ sbt assembly\n$ cd /opt/spark\n$ ./bin/spark-submit --class com.test.spark.KafkaWorker  /root/sample/target/scala-2.11/Test-assembly-1.0.jar 127.0.0.1:2181 test nginx 2 5\n### Start Mon Dec 26 12:32:25 JST 2016 ###                                      \n879 count not match\n285 count (category)\n190 count (item)\n48 count (search)\n### END Mon Dec 26 12:32:25 JST 2016 ###\n\n### Start Mon Dec 26 12:32:30 JST 2016 ###\n802 count not match\n267 count (category)\n175 count (item)\n38 count (search)\n### END Mon Dec 26 12:32:30 JST 2016 ###\n\n### Start Mon Dec 26 12:32:35 JST 2016 ###\n895 count not match\n321 count (category)\n181 count (item)\n53 count (search)\n### END Mon Dec 26 12:32:35 JST 2016 ###\n```\n\n\u6642\u9593\u3042\u3063\u305f\u3089Fluent\u306eDataCounter\u3068\u304bNorikura\u3068\u304b\u3068\u6027\u80fd\u8a66\u9a13\u3068\u304b\u3057\u3066\u307f\u305f\u3044\u3002\n"}