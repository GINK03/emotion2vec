{"tags": ["TensorFlow", "DeepLearning", "docker", "nvidia-docker", "GPU"], "context": "\n\n\u80cc\u666f\n\u4ee5\u524d\u81ea\u4f5cGPU\u30de\u30b7\u30f3\u4e0a\u3067DeepLearning\u7528\u306e\u74b0\u5883\u3092\u69cb\u7bc9\u3057\u305f\u306e\u3067\u3059\u304c\u3001\n\nGPU\u306e\u30c9\u30e9\u30a4\u30d0\u30a4\u30f3\u30b9\u30c8\u30fc\u30eb\nCuda/Cudnn\u306e\u30a4\u30f3\u30b9\u30c8\u30fc\u30eb\nDeepLearning\u30e9\u30a4\u30d6\u30e9\u30ea\u306e\u30a4\u30f3\u30b9\u30c8\u30fc\u30eb\n\u52d5\u4f5c\u30c6\u30b9\u30c8\n\n\u3068\u30b9\u30c6\u30c3\u30d7\u304c\u591a\u304f\u3001\u30cf\u30de\u308b\u3068\u7d50\u69cb\u30a4\u30f3\u30b9\u30c8\u30fc\u30eb\u306b\u82e6\u52b4\u3057\u307e\u3059\u3002\n\u307e\u305f\u3001Cuda/Cudnn\u3001\u5404\u30e9\u30a4\u30d6\u30e9\u30ea\u5171\u306b\u30d0\u30fc\u30b8\u30e7\u30f3\u30a2\u30c3\u30d7\u304c\u983b\u7e41\u3067\u3042\u3063\u305f\u308a\u3001\u8272\u3005\u3068\u30e2\u30b8\u30e5\u30fc\u30eb\u3092\u5165\u308c\u3066\u3044\u308b\u3046\u3061\u306b\u4f9d\u5b58\u95a2\u4fc2\u304c\u58ca\u308c\u3066\u3057\u307e\u3063\u305f\u308a\u4f55\u304b\u3068\u74b0\u5883\u3092\u4f5c\u308a\u76f4\u3057\u305f\u304f\u306a\u308b\u3053\u3068\u3082\u591a\u3044\u3067\u3059\u3002\n\u7c21\u5358\u306b\u74b0\u5883\u3092\u4f5c\u308a\u76f4\u305b\u308b\u3088\u3046\u306b\u3057\u305f\u3044\u3068\u601d\u3044\u3001NVIDIA\u304c\u63d0\u4f9b\u3057\u3066\u3044\u308bnvidia-docker\u3092\u7528\u3044\u305f\u74b0\u5883\u69cb\u7bc9\u306e\u65b9\u6cd5\u3092\u8a66\u3057\u3066\u307f\u307e\u3057\u305f\u3002\n\n\u76ee\u7684\nGPU\u30de\u30b7\u30f3\u4e0a\u3067\u306eDeepLearning\u7528\u74b0\u5883\u306e\u69cb\u7bc9\u306f\u4f55\u304b\u3068\u624b\u9593\u304c\u591a\u3044\u306e\u3067\u6700\u5927\u9650\u697d\u3057\u305f\u3044\u3002\n\u30af\u30e9\u30a6\u30c9\u306e\u30b5\u30fc\u30d0\u4e0a\u3084\u81ea\u4f5cPC\u4e0a\u3067\u3055\u304f\u3063\u3068Tensorflow on GPU\u74b0\u5883\u3092\u69cb\u7bc9\u3057\u305f\u3044\u3002\n\n\u4f7f\u3046\u3082\u306e\n\nGPU\u642d\u8f09\u306e\u30b5\u30fc\u30d0\uff08\u4eca\u56de\u306fIBM Softlayer\uff09\n\n\nOS : CentOS7.2\nCPU : 2.4GHz Intel Xeon-Haswell x 2\nGPU : NVIDIA GRID K2 x 1\n\n\nnvidia-docker (https://github.com/NVIDIA/nvidia-docker)\ndocker (https://www.docker.com/)\nTensorflow (https://github.com/tensorflow/tensorflow)\n\n\u203b2016/9/30\u8ffd\u8a18\nTensorflow\u306e\u30d0\u30fc\u30b8\u30e7\u30f30.10.0\u3067\u3082\u52d5\u304f\u3053\u3068\u3092\u78ba\u8a8d\u3057\u307e\u3057\u305f\u3002\n - Tensorflow version : 0.10.0\n - GPU \uff1a NVIDIA Corporation GK210GL [Tesla K80]\n - Driver : http://jp.download.nvidia.com/XFree86/Linux-x86_64/361.93.02/NVIDIA-Linux-x86_64-361.93.02.run\n   (BETA\u7248\u3068\u66f8\u304b\u308c\u3066\u3044\u305f\u3051\u3069\u52d5\u304d\u307e\u3057\u305f) \n\nnvidia-docker\u3068\u306f\ndocker\u306e\u30e9\u30c3\u30d1\u30fc\u3068\u3057\u3066\u5b9f\u88c5\u3055\u308c\u3066\u3044\u308b\u30c4\u30fc\u30eb\u3067\u3001\u30db\u30b9\u30c8OS\u4e0a\u306bNVIDIA\u306e\u30c9\u30e9\u30a4\u30d0\u304c\u30a4\u30f3\u30b9\u30c8\u30fc\u30eb\u3055\u308c\u3066\u3044\u308c\u3070\u3001CudaToolkit\u3092\u542b\u3093\u3060\u30b3\u30f3\u30c6\u30ca\u304b\u3089GPU\u3092\u5229\u7528\u51fa\u6765\u308b\u3088\u3046\u306b\u306a\u308a\u307e\u3059\u3002\n\u53c2\u8003\uff09http://www.nvidia.co.jp/object/docker-container-jp.html\n\n\u5c0e\u5165\u624b\u9806\n\u4ee5\u4e0b\u306e\u624b\u9806\u3067\u5c0e\u5165\u3067\u304d\u307e\u3059\u3002\n\n\u30c9\u30e9\u30a4\u30d0\u30a4\u30f3\u30b9\u30c8\u30fc\u30eb\uff08\u30db\u30b9\u30c8OS\u4e0a\uff09\nDocker\u30a4\u30f3\u30b9\u30c8\u30fc\u30eb\uff08\u30db\u30b9\u30c8OS\u4e0a\uff09\nnvidia-docker\u30a4\u30f3\u30b9\u30c8\u30fc\u30eb\uff08\u30db\u30b9\u30c8OS\u4e0a\uff09\nTensorflow + GPU \u306e\u30a4\u30e1\u30fc\u30b8\u4f5c\u6210\uff06\u5b9f\u884c\n\n\n1. \u30c9\u30e9\u30a4\u30d0\u30a4\u30f3\u30b9\u30c8\u30fc\u30eb\nnouveau\u30b0\u30e9\u30d5\u30a3\u30c3\u30af\u30b9\u30c9\u30e9\u30a4\u30d0\u3092\u7121\u52b9\u5316\u3057\u305f\u5f8c\u3001NVIDIA\u306e\u30c9\u30e9\u30a4\u30d0\u3092\u30a4\u30f3\u30b9\u30c8\u30fc\u30eb\u3057\u307e\u3059\u3002\n\uff08nouveau\u3092\u7121\u52b9\u5316\u3057\u306a\u3044\u3068\u30c9\u30e9\u30a4\u30d0\u30a4\u30f3\u30b9\u30c8\u30fc\u30eb\u304c\u5931\u6557\u3059\u308b\u305f\u3081\uff09\n## nouveau \u30c9\u30e9\u30a4\u30d0\u30fc\u3092\u7121\u52b9\u306b\u3059\u308b\nsudo su -\n\n# nouveau\u304c\u8aad\u307f\u8fbc\u307e\u308c\u3066\u3044\u308b\u3053\u3068\u3092\u78ba\u8a8d\nlsmod | grep nouveau\n---\nnouveau              1403757  0\nvideo                  24400  1 nouveau\nmxm_wmi                13021  1 nouveau\ni2c_algo_bit           13413  1 nouveau\ndrm_kms_helper        125008  1 nouveau\nttm                    93441  1 nouveau\ndrm                   349210  3 ttm,drm_kms_helper,nouveau\ni2c_core               40582  5 drm,i2c_i801,drm_kms_helper,i2c_algo_bit,nouveau\nwmi                    19070  2 mxm_wmi,nouveau\n---\n\n# nouveau\u306a\u3057\u306e\u8d77\u52d5\u30a4\u30e1\u30fc\u30b8\u751f\u6210\nmv /boot/initramfs-$(uname -r).img /boot/initramfs-$(uname -r)-nouveau.img\ndracut --omit-drivers nouveau /boot/initramfs-$(uname -r).img $(uname -r)\n\n# \u4f9d\u5b58\u304b\u3089\u30ed\u30fc\u30c9\u3055\u308c\u306a\u3044\u3088\u3046\u306b\u8a2d\u5b9a\u5909\u66f4\necho 'blacklist nouveau' >> /etc/modprobe.d/modprobe.conf\necho 'blacklist nouveau' >> /etc/modprobe.d/nouveau_blacklist.conf\n\n# \u518d\u8d77\u52d5\nreboot now\n\n# nouveau\u304c\u8aad\u307f\u8fbc\u307e\u308c\u3066\u3044\u306a\u3044\u3053\u3068\u3092\u78ba\u8a8d\nlsmod | grep nouveau\n\n## nvidia drive \u306e\u30a4\u30f3\u30b9\u30c8\u30fc\u30eb  \nyum -y install pciutils gcc kernel-devel tmux git\n\n# GPU\u306e\u578b\u756a\u3092\u78ba\u8a8d\nlspci | grep -i nvidia\n---\n83:00.0 VGA compatible controller: NVIDIA Corporation GK104GL [GRID K2] (rev a1)\n84:00.0 VGA compatible controller: NVIDIA Corporation GK104GL [GRID K2] (rev a1)\n---\n\n# http://www.nvidia.co.jp/Download/index.aspx?lang=jp\n# \u3053\u3053\u304b\u3089GPU\u306b\u5408\u3063\u305f\u6700\u65b0\u306e\u30c9\u30e9\u30a4\u30d0\u3092\u63a2\u3059\n# GRID -> GRID Series -> Linux 64bit\ncd /tmp/\nwget http://us.download.nvidia.com/XFree86/Linux-x86_64/367.27/NVIDIA-Linux-x86_64-367.27.run\nsh NVIDIA-Linux-x86_64-367.27.run\n# \u8a98\u5c0e\u306b\u3057\u305f\u304c\u3063\u3066\u30a4\u30f3\u30b9\u30c8\u30fc\u30eb\u3059\u308b\n\n\n2. Docker\u30a4\u30f3\u30b9\u30c8\u30fc\u30eb\n\u516c\u5f0f\u306e\u30a4\u30f3\u30b9\u30c8\u30fc\u30eb\u30de\u30cb\u30e5\u30a2\u30eb\u306b\u5f93\u3063\u3066\u30a4\u30f3\u30b9\u30c8\u30fc\u30eb\u3057\u307e\u3059\u3002\nsudo tee /etc/yum.repos.d/docker.repo <<-'EOF'\n[dockerrepo]\nname=Docker Repository\nbaseurl=https://yum.dockerproject.org/repo/main/centos/7/\nenabled=1\ngpgcheck=1\ngpgkey=https://yum.dockerproject.org/gpg\nEOF\n\nsudo yum install docker-engine\nsudo service docker start\nsudo docker run hello-world\n# Hello from Docker! \u306e\u30e1\u30c3\u30bb\u30fc\u30b8\u3092\u78ba\u8a8d\n\n# \u81ea\u52d5\u8d77\u52d5\u8a2d\u5b9a\nsudo chkconfig docker on\n\n# \u4e00\u5fdcdocker-compose\u3082\u30a4\u30f3\u30b9\u30c8\u30fc\u30eb\nsudo sh -c 'curl -L https://github.com/docker/compose/releases/download/1.10.0/docker-compose-`uname -s`-`uname -m` > /usr/local/bin/docker-compose'\nsudo chmod +x /usr/local/bin/docker-compose\n\n\n3. nvidia-docker\u30a4\u30f3\u30b9\u30c8\u30fc\u30eb\n\u516c\u5f0f\u306eQuickStart\u306b\u5f93\u3063\u3066\u30a4\u30f3\u30b9\u30c8\u30fc\u30eb\u3057\u307e\u3059\u3002\n### nvidia-docker install\n# Install nvidia-docker and nvidia-docker-plugin\nwget -P /tmp https://github.com/NVIDIA/nvidia-docker/releases/download/v1.0.0-rc.3/nvidia-docker-1.0.0.rc.3-1.x86_64.rpm\nsudo rpm -i /tmp/nvidia-docker*.rpm && rm /tmp/nvidia-docker*.rpm\nsudo systemctl start nvidia-docker\nsudo systemctl enable nvidia-docker\n\n# Test nvidia-smi\nnvidia-docker run --rm nvidia/cuda nvidia-smi\n# \u4ee5\u4e0b\u306e\u69d8\u306a\u51fa\u529b\u3092\u78ba\u8a8d\n---\n+-----------------------------------------------------------------------------+\n| NVIDIA-SMI 367.27                 Driver Version: 367.27                    |\n|-------------------------------+----------------------+----------------------+\n| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n|===============================+======================+======================|\n|   0  GRID K2             Off  | 0000:83:00.0     Off |                  Off |\n| N/A   31C    P8    18W / 117W |   3794MiB /  4036MiB |      0%      Default |\n+-------------------------------+----------------------+----------------------+\n|   1  GRID K2             Off  | 0000:84:00.0     Off |                  Off |\n| N/A   28C    P8    17W / 117W |     38MiB /  4036MiB |      0%      Default |\n+-------------------------------+----------------------+----------------------+\n\n+-----------------------------------------------------------------------------+\n| Processes:                                                       GPU Memory |\n|  GPU       PID  Type  Process name                               Usage      |\n|=============================================================================|\n+-----------------------------------------------------------------------------+\n---\n\n\n4. Tensorflow + GPU \u306e\u30a4\u30e1\u30fc\u30b8\u4f5c\u6210\uff06\u5b9f\u884c\nhttps://github.com/tensorflow/tensorflow/tree/master/tensorflow/tools/docker\nTensorflow\u304c\u63d0\u4f9b\u3057\u3066\u3044\u308bDockerhub\u306e\u30a4\u30e1\u30fc\u30b8\u3092\u4f7f\u3046\u3068\u4ee5\u4e0b\u306e\u69d8\u306a\u30a8\u30e9\u30fc\u304c\u51fa\u308b\u306e\u3067 (2016/7/20\u6642\u70b9)\u3001\nF tensorflow/stream_executor/cuda/cuda_dnn.cc:204] could not find cudnnCreate in cudnn DSO; dlerror: /usr/local/lib/python2.7/dist-packages/tensorflow/python/_pywrap_tensorflow.so: undefined symbol: cudnnCreate\n[I 16:47:11.347 NotebookApp] KernelRestarter: restarting kernel (1/5)\n\ngithub\u306emaster\u306b\u3042\u308bDocker\u30d5\u30a1\u30a4\u30eb\u304b\u3089\u30a4\u30e1\u30fc\u30b8\u3092\u30d3\u30eb\u30c9\u3057\u307e\u3059\u3002\n## run tensorflow docker\n\n# \u203b\u3053\u308c\u3046\u307e\u304f\u52d5\u304b\u306a\u304b\u3063\u305f\n#nvidia-docker run -it -p 8888:8888 gcr.io/tensorflow/tensorflow:latest-gpu\n\n# Tensorflow\u306emaster\u306b\u3042\u308bDockerfile\u304b\u3089\u30d3\u30eb\u30c9\u3059\u308b\ngit clone https://github.com/tensorflow/tensorflow.git\ncd tensorflow/tensorflow/tools/docker\ndocker build -t $USER/tensorflow-suffix -f Dockerfile.gpu .\nnvidia-docker run -it -p 8888:8888 $USER/tensorflow-suffix\n\nDocker\u3092\u8d77\u52d5\u5f8c\nhttp://${HOST_IP}:8888/\n\u306b\u30a2\u30af\u30bb\u30b9\u3059\u308c\u3070jupyter\u306e\u753b\u9762\u304c\u78ba\u8a8d\u3067\u304d\u307e\u3059\u3002\n\n3_mnist_from_scratch.ipynb \u306enotebook\u3092\u8d77\u52d5\u3057\u3066 Cell -> Run All \u3067\u30b5\u30f3\u30d7\u30eb\u304c\u52d5\u304f\u3053\u3068\u3092\u78ba\u8a8d\u3057\u307e\u3059\u3002\u7d50\u679c\u3092\u78ba\u8a8d\u3002\n\njupyter\u306e\u30ed\u30b0\u3067GPU\u3092\u4f7f\u3063\u3066\u8a08\u7b97\u3055\u308c\u3066\u3044\u308b\u3053\u3068\u3092\u78ba\u8a8d\u3057\u307e\u3059\u3002\nI tensorflow/stream_executor/dso_loader.cc:108] successfully opened CUDA library libcublas.so locally\nI tensorflow/stream_executor/dso_loader.cc:108] successfully opened CUDA library libcudnn.so locally\nI tensorflow/stream_executor/dso_loader.cc:108] successfully opened CUDA library libcufft.so locally\nI tensorflow/stream_executor/dso_loader.cc:108] successfully opened CUDA library libcuda.so locally\nI tensorflow/stream_executor/dso_loader.cc:108] successfully opened CUDA library libcurand.so locally\nI tensorflow/core/common_runtime/gpu/gpu_init.cc:102] Found device 0 with properties:\nname: GRID K2\nmajor: 3 minor: 0 memoryClockRate (GHz) 0.745\npciBusID 0000:83:00.0\nTotal memory: 3.94GiB\nFree memory: 3.91GiB\nW tensorflow/stream_executor/cuda/cuda_driver.cc:572] creating context when one is currently active; existing: 0x6f991e0\nI tensorflow/core/common_runtime/gpu/gpu_init.cc:102] Found device 1 with properties:\nname: GRID K2\nmajor: 3 minor: 0 memoryClockRate (GHz) 0.745\npciBusID 0000:84:00.0\nTotal memory: 3.94GiB\nFree memory: 3.91GiB\nI tensorflow/core/common_runtime/gpu/gpu_init.cc:126] DMA: 0 1\nI tensorflow/core/common_runtime/gpu/gpu_init.cc:136] 0:   Y Y\nI tensorflow/core/common_runtime/gpu/gpu_init.cc:136] 1:   Y Y\nI tensorflow/core/common_runtime/gpu/gpu_device.cc:806] Creating TensorFlow device (/gpu:0) -> (device: 0, name: GRID K2, pci bus id: 0000:83:$0.0)\nI tensorflow/core/common_runtime/gpu/gpu_device.cc:806] Creating TensorFlow device (/gpu:1) -> (device: 1, name: GRID K2, pci bus id: 0000:84:$0.0)\nW tensorflow/core/common_runtime/bfc_allocator.cc:213] Ran out of memory trying to allocate 2.92GiB. The caller indicates that this is not a failure, but may mean that there could be performance gains if more memory is available.\nW tensorflow/core/common_runtime/bfc_allocator.cc:213] Ran out of memory trying to allocate 2.59GiB. The caller indicates that this is not a failure, but may mean that there could be performance gains if more memory is available.\nW tensorflow/core/common_runtime/bfc_allocator.cc:213] Ran out of memory trying to allocate 5.84GiB. The caller indicates that this is not a failure, but may mean that there could be performance gains if more memory is available.\nW tensorflow/core/common_runtime/bfc_allocator.cc:213] Ran out of memory trying to allocate 5.19GiB. The caller indicates that this is not a failure, but may mean that there could be performance gains if more memory is available.\nW tensorflow/core/common_runtime/bfc_allocator.cc:213] Ran out of memory trying to allocate 5.20GiB. The caller indicates that this is not a failure, but may mean that there could be performance gains if more memory is available.\n\n\u4ee5\u4e0a\u3067\u3059\u3002\n\nReference\nnvidia-docker\u3067tensorflow\u3092\u52d5\u304b\u3059 - Qiita\nUbuntu14.04.3\u3067nvidia-docker\u4f7f\u3063\u3066Caffe\u3092\u30a4\u30f3\u30b9\u30c8\u30fc\u30eb\u3057\u3066\u307f\u305f - Qiita\n# \u80cc\u666f\n\u4ee5\u524d\u81ea\u4f5cGPU\u30de\u30b7\u30f3\u4e0a\u3067DeepLearning\u7528\u306e\u74b0\u5883\u3092\u69cb\u7bc9\u3057\u305f\u306e\u3067\u3059\u304c\u3001\n\n1. GPU\u306e\u30c9\u30e9\u30a4\u30d0\u30a4\u30f3\u30b9\u30c8\u30fc\u30eb\n1. Cuda/Cudnn\u306e\u30a4\u30f3\u30b9\u30c8\u30fc\u30eb\n1. DeepLearning\u30e9\u30a4\u30d6\u30e9\u30ea\u306e\u30a4\u30f3\u30b9\u30c8\u30fc\u30eb\n1. \u52d5\u4f5c\u30c6\u30b9\u30c8\n\n\u3068\u30b9\u30c6\u30c3\u30d7\u304c\u591a\u304f\u3001\u30cf\u30de\u308b\u3068\u7d50\u69cb\u30a4\u30f3\u30b9\u30c8\u30fc\u30eb\u306b\u82e6\u52b4\u3057\u307e\u3059\u3002\n\u307e\u305f\u3001Cuda/Cudnn\u3001\u5404\u30e9\u30a4\u30d6\u30e9\u30ea\u5171\u306b\u30d0\u30fc\u30b8\u30e7\u30f3\u30a2\u30c3\u30d7\u304c\u983b\u7e41\u3067\u3042\u3063\u305f\u308a\u3001\u8272\u3005\u3068\u30e2\u30b8\u30e5\u30fc\u30eb\u3092\u5165\u308c\u3066\u3044\u308b\u3046\u3061\u306b\u4f9d\u5b58\u95a2\u4fc2\u304c\u58ca\u308c\u3066\u3057\u307e\u3063\u305f\u308a\u4f55\u304b\u3068\u74b0\u5883\u3092\u4f5c\u308a\u76f4\u3057\u305f\u304f\u306a\u308b\u3053\u3068\u3082\u591a\u3044\u3067\u3059\u3002\n\u7c21\u5358\u306b\u74b0\u5883\u3092\u4f5c\u308a\u76f4\u305b\u308b\u3088\u3046\u306b\u3057\u305f\u3044\u3068\u601d\u3044\u3001NVIDIA\u304c\u63d0\u4f9b\u3057\u3066\u3044\u308bnvidia-docker\u3092\u7528\u3044\u305f\u74b0\u5883\u69cb\u7bc9\u306e\u65b9\u6cd5\u3092\u8a66\u3057\u3066\u307f\u307e\u3057\u305f\u3002\n\n\n# \u76ee\u7684\nGPU\u30de\u30b7\u30f3\u4e0a\u3067\u306eDeepLearning\u7528\u74b0\u5883\u306e\u69cb\u7bc9\u306f\u4f55\u304b\u3068\u624b\u9593\u304c\u591a\u3044\u306e\u3067\u6700\u5927\u9650\u697d\u3057\u305f\u3044\u3002\n\u30af\u30e9\u30a6\u30c9\u306e\u30b5\u30fc\u30d0\u4e0a\u3084\u81ea\u4f5cPC\u4e0a\u3067\u3055\u304f\u3063\u3068Tensorflow on GPU\u74b0\u5883\u3092\u69cb\u7bc9\u3057\u305f\u3044\u3002\n\n# \u4f7f\u3046\u3082\u306e\n\n- GPU\u642d\u8f09\u306e\u30b5\u30fc\u30d0\uff08\u4eca\u56de\u306fIBM Softlayer\uff09\n    - OS : CentOS7.2\n    - CPU : 2.4GHz Intel Xeon-Haswell x 2\n    - GPU : NVIDIA GRID K2 x 1\n- nvidia-docker (https://github.com/NVIDIA/nvidia-docker)\n- docker (https://www.docker.com/)\n- Tensorflow (https://github.com/tensorflow/tensorflow)\n\n\u203b2016/9/30\u8ffd\u8a18\nTensorflow\u306e\u30d0\u30fc\u30b8\u30e7\u30f30.10.0\u3067\u3082\u52d5\u304f\u3053\u3068\u3092\u78ba\u8a8d\u3057\u307e\u3057\u305f\u3002\n - Tensorflow version : 0.10.0\n - GPU \uff1a NVIDIA Corporation GK210GL [Tesla K80]\n - Driver : http://jp.download.nvidia.com/XFree86/Linux-x86_64/361.93.02/NVIDIA-Linux-x86_64-361.93.02.run\n   (BETA\u7248\u3068\u66f8\u304b\u308c\u3066\u3044\u305f\u3051\u3069\u52d5\u304d\u307e\u3057\u305f) \n\n# nvidia-docker\u3068\u306f\ndocker\u306e\u30e9\u30c3\u30d1\u30fc\u3068\u3057\u3066\u5b9f\u88c5\u3055\u308c\u3066\u3044\u308b\u30c4\u30fc\u30eb\u3067\u3001\u30db\u30b9\u30c8OS\u4e0a\u306bNVIDIA\u306e\u30c9\u30e9\u30a4\u30d0\u304c\u30a4\u30f3\u30b9\u30c8\u30fc\u30eb\u3055\u308c\u3066\u3044\u308c\u3070\u3001CudaToolkit\u3092\u542b\u3093\u3060\u30b3\u30f3\u30c6\u30ca\u304b\u3089GPU\u3092\u5229\u7528\u51fa\u6765\u308b\u3088\u3046\u306b\u306a\u308a\u307e\u3059\u3002\n\u53c2\u8003\uff09http://www.nvidia.co.jp/object/docker-container-jp.html\n\n# \u5c0e\u5165\u624b\u9806\n\u4ee5\u4e0b\u306e\u624b\u9806\u3067\u5c0e\u5165\u3067\u304d\u307e\u3059\u3002\n\n1. \u30c9\u30e9\u30a4\u30d0\u30a4\u30f3\u30b9\u30c8\u30fc\u30eb\uff08\u30db\u30b9\u30c8OS\u4e0a\uff09\n1. Docker\u30a4\u30f3\u30b9\u30c8\u30fc\u30eb\uff08\u30db\u30b9\u30c8OS\u4e0a\uff09\n1. nvidia-docker\u30a4\u30f3\u30b9\u30c8\u30fc\u30eb\uff08\u30db\u30b9\u30c8OS\u4e0a\uff09\n1. Tensorflow + GPU \u306e\u30a4\u30e1\u30fc\u30b8\u4f5c\u6210\uff06\u5b9f\u884c\n\n## 1. \u30c9\u30e9\u30a4\u30d0\u30a4\u30f3\u30b9\u30c8\u30fc\u30eb\nnouveau\u30b0\u30e9\u30d5\u30a3\u30c3\u30af\u30b9\u30c9\u30e9\u30a4\u30d0\u3092\u7121\u52b9\u5316\u3057\u305f\u5f8c\u3001NVIDIA\u306e\u30c9\u30e9\u30a4\u30d0\u3092\u30a4\u30f3\u30b9\u30c8\u30fc\u30eb\u3057\u307e\u3059\u3002\n\uff08nouveau\u3092\u7121\u52b9\u5316\u3057\u306a\u3044\u3068\u30c9\u30e9\u30a4\u30d0\u30a4\u30f3\u30b9\u30c8\u30fc\u30eb\u304c\u5931\u6557\u3059\u308b\u305f\u3081\uff09\n\n```bash\n## nouveau \u30c9\u30e9\u30a4\u30d0\u30fc\u3092\u7121\u52b9\u306b\u3059\u308b\nsudo su -\n\n# nouveau\u304c\u8aad\u307f\u8fbc\u307e\u308c\u3066\u3044\u308b\u3053\u3068\u3092\u78ba\u8a8d\nlsmod | grep nouveau\n---\nnouveau              1403757  0\nvideo                  24400  1 nouveau\nmxm_wmi                13021  1 nouveau\ni2c_algo_bit           13413  1 nouveau\ndrm_kms_helper        125008  1 nouveau\nttm                    93441  1 nouveau\ndrm                   349210  3 ttm,drm_kms_helper,nouveau\ni2c_core               40582  5 drm,i2c_i801,drm_kms_helper,i2c_algo_bit,nouveau\nwmi                    19070  2 mxm_wmi,nouveau\n---\n  \n# nouveau\u306a\u3057\u306e\u8d77\u52d5\u30a4\u30e1\u30fc\u30b8\u751f\u6210\nmv /boot/initramfs-$(uname -r).img /boot/initramfs-$(uname -r)-nouveau.img\ndracut --omit-drivers nouveau /boot/initramfs-$(uname -r).img $(uname -r)\n  \n# \u4f9d\u5b58\u304b\u3089\u30ed\u30fc\u30c9\u3055\u308c\u306a\u3044\u3088\u3046\u306b\u8a2d\u5b9a\u5909\u66f4\necho 'blacklist nouveau' >> /etc/modprobe.d/modprobe.conf\necho 'blacklist nouveau' >> /etc/modprobe.d/nouveau_blacklist.conf\n  \n# \u518d\u8d77\u52d5\nreboot now\n\n# nouveau\u304c\u8aad\u307f\u8fbc\u307e\u308c\u3066\u3044\u306a\u3044\u3053\u3068\u3092\u78ba\u8a8d\nlsmod | grep nouveau\n  \n## nvidia drive \u306e\u30a4\u30f3\u30b9\u30c8\u30fc\u30eb  \nyum -y install pciutils gcc kernel-devel tmux git\n\n# GPU\u306e\u578b\u756a\u3092\u78ba\u8a8d\nlspci | grep -i nvidia\n---\n83:00.0 VGA compatible controller: NVIDIA Corporation GK104GL [GRID K2] (rev a1)\n84:00.0 VGA compatible controller: NVIDIA Corporation GK104GL [GRID K2] (rev a1)\n---\n\n# http://www.nvidia.co.jp/Download/index.aspx?lang=jp\n# \u3053\u3053\u304b\u3089GPU\u306b\u5408\u3063\u305f\u6700\u65b0\u306e\u30c9\u30e9\u30a4\u30d0\u3092\u63a2\u3059\n# GRID -> GRID Series -> Linux 64bit\ncd /tmp/\nwget http://us.download.nvidia.com/XFree86/Linux-x86_64/367.27/NVIDIA-Linux-x86_64-367.27.run\nsh NVIDIA-Linux-x86_64-367.27.run\n# \u8a98\u5c0e\u306b\u3057\u305f\u304c\u3063\u3066\u30a4\u30f3\u30b9\u30c8\u30fc\u30eb\u3059\u308b\n```\n\n## 2. Docker\u30a4\u30f3\u30b9\u30c8\u30fc\u30eb\n[\u516c\u5f0f\u306e\u30a4\u30f3\u30b9\u30c8\u30fc\u30eb\u30de\u30cb\u30e5\u30a2\u30eb](https://docs.docker.com/engine/installation/linux/centos/)\u306b\u5f93\u3063\u3066\u30a4\u30f3\u30b9\u30c8\u30fc\u30eb\u3057\u307e\u3059\u3002\n\n```bash\nsudo tee /etc/yum.repos.d/docker.repo <<-'EOF'\n[dockerrepo]\nname=Docker Repository\nbaseurl=https://yum.dockerproject.org/repo/main/centos/7/\nenabled=1\ngpgcheck=1\ngpgkey=https://yum.dockerproject.org/gpg\nEOF\n  \nsudo yum install docker-engine\nsudo service docker start\nsudo docker run hello-world\n# Hello from Docker! \u306e\u30e1\u30c3\u30bb\u30fc\u30b8\u3092\u78ba\u8a8d\n\n# \u81ea\u52d5\u8d77\u52d5\u8a2d\u5b9a\nsudo chkconfig docker on\n\n# \u4e00\u5fdcdocker-compose\u3082\u30a4\u30f3\u30b9\u30c8\u30fc\u30eb\nsudo sh -c 'curl -L https://github.com/docker/compose/releases/download/1.10.0/docker-compose-`uname -s`-`uname -m` > /usr/local/bin/docker-compose'\nsudo chmod +x /usr/local/bin/docker-compose\n```\n\n## 3. nvidia-docker\u30a4\u30f3\u30b9\u30c8\u30fc\u30eb\n[\u516c\u5f0f\u306eQuickStart](https://github.com/NVIDIA/nvidia-docker)\u306b\u5f93\u3063\u3066\u30a4\u30f3\u30b9\u30c8\u30fc\u30eb\u3057\u307e\u3059\u3002\n\n```bash\n### nvidia-docker install\n# Install nvidia-docker and nvidia-docker-plugin\nwget -P /tmp https://github.com/NVIDIA/nvidia-docker/releases/download/v1.0.0-rc.3/nvidia-docker-1.0.0.rc.3-1.x86_64.rpm\nsudo rpm -i /tmp/nvidia-docker*.rpm && rm /tmp/nvidia-docker*.rpm\nsudo systemctl start nvidia-docker\nsudo systemctl enable nvidia-docker\n \n# Test nvidia-smi\nnvidia-docker run --rm nvidia/cuda nvidia-smi\n# \u4ee5\u4e0b\u306e\u69d8\u306a\u51fa\u529b\u3092\u78ba\u8a8d\n---\n+-----------------------------------------------------------------------------+\n| NVIDIA-SMI 367.27                 Driver Version: 367.27                    |\n|-------------------------------+----------------------+----------------------+\n| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n|===============================+======================+======================|\n|   0  GRID K2             Off  | 0000:83:00.0     Off |                  Off |\n| N/A   31C    P8    18W / 117W |   3794MiB /  4036MiB |      0%      Default |\n+-------------------------------+----------------------+----------------------+\n|   1  GRID K2             Off  | 0000:84:00.0     Off |                  Off |\n| N/A   28C    P8    17W / 117W |     38MiB /  4036MiB |      0%      Default |\n+-------------------------------+----------------------+----------------------+\n\n+-----------------------------------------------------------------------------+\n| Processes:                                                       GPU Memory |\n|  GPU       PID  Type  Process name                               Usage      |\n|=============================================================================|\n+-----------------------------------------------------------------------------+\n---\n```\n\n## 4. Tensorflow + GPU \u306e\u30a4\u30e1\u30fc\u30b8\u4f5c\u6210\uff06\u5b9f\u884c\nhttps://github.com/tensorflow/tensorflow/tree/master/tensorflow/tools/docker\nTensorflow\u304c\u63d0\u4f9b\u3057\u3066\u3044\u308bDockerhub\u306e\u30a4\u30e1\u30fc\u30b8\u3092\u4f7f\u3046\u3068\u4ee5\u4e0b\u306e\u69d8\u306a\u30a8\u30e9\u30fc\u304c\u51fa\u308b\u306e\u3067 (2016/7/20\u6642\u70b9)\u3001\n\n```\nF tensorflow/stream_executor/cuda/cuda_dnn.cc:204] could not find cudnnCreate in cudnn DSO; dlerror: /usr/local/lib/python2.7/dist-packages/tensorflow/python/_pywrap_tensorflow.so: undefined symbol: cudnnCreate\n[I 16:47:11.347 NotebookApp] KernelRestarter: restarting kernel (1/5)\n```\n\ngithub\u306emaster\u306b\u3042\u308bDocker\u30d5\u30a1\u30a4\u30eb\u304b\u3089\u30a4\u30e1\u30fc\u30b8\u3092\u30d3\u30eb\u30c9\u3057\u307e\u3059\u3002\n\n```bash\n## run tensorflow docker\n\n# \u203b\u3053\u308c\u3046\u307e\u304f\u52d5\u304b\u306a\u304b\u3063\u305f\n#nvidia-docker run -it -p 8888:8888 gcr.io/tensorflow/tensorflow:latest-gpu\n  \n# Tensorflow\u306emaster\u306b\u3042\u308bDockerfile\u304b\u3089\u30d3\u30eb\u30c9\u3059\u308b\ngit clone https://github.com/tensorflow/tensorflow.git\ncd tensorflow/tensorflow/tools/docker\ndocker build -t $USER/tensorflow-suffix -f Dockerfile.gpu .\nnvidia-docker run -it -p 8888:8888 $USER/tensorflow-suffix\n```\n\nDocker\u3092\u8d77\u52d5\u5f8c\nhttp://${HOST_IP}:8888/\n\u306b\u30a2\u30af\u30bb\u30b9\u3059\u308c\u3070jupyter\u306e\u753b\u9762\u304c\u78ba\u8a8d\u3067\u304d\u307e\u3059\u3002\n\n![jupyter_home.png](https://qiita-image-store.s3.amazonaws.com/0/39236/85f7665b-fb97-6dd6-118d-9a9bc82856d3.png)\n\n3_mnist_from_scratch.ipynb \u306enotebook\u3092\u8d77\u52d5\u3057\u3066 Cell -> Run All \u3067\u30b5\u30f3\u30d7\u30eb\u304c\u52d5\u304f\u3053\u3068\u3092\u78ba\u8a8d\u3057\u307e\u3059\u3002\u7d50\u679c\u3092\u78ba\u8a8d\u3002\n\n![3_mnist_from_scratch_result.png](https://qiita-image-store.s3.amazonaws.com/0/39236/74058b74-aa5b-c862-b6cc-1877aca6825b.png)\n\njupyter\u306e\u30ed\u30b0\u3067GPU\u3092\u4f7f\u3063\u3066\u8a08\u7b97\u3055\u308c\u3066\u3044\u308b\u3053\u3068\u3092\u78ba\u8a8d\u3057\u307e\u3059\u3002\n\n```\nI tensorflow/stream_executor/dso_loader.cc:108] successfully opened CUDA library libcublas.so locally\nI tensorflow/stream_executor/dso_loader.cc:108] successfully opened CUDA library libcudnn.so locally\nI tensorflow/stream_executor/dso_loader.cc:108] successfully opened CUDA library libcufft.so locally\nI tensorflow/stream_executor/dso_loader.cc:108] successfully opened CUDA library libcuda.so locally\nI tensorflow/stream_executor/dso_loader.cc:108] successfully opened CUDA library libcurand.so locally\nI tensorflow/core/common_runtime/gpu/gpu_init.cc:102] Found device 0 with properties:\nname: GRID K2\nmajor: 3 minor: 0 memoryClockRate (GHz) 0.745\npciBusID 0000:83:00.0\nTotal memory: 3.94GiB\nFree memory: 3.91GiB\nW tensorflow/stream_executor/cuda/cuda_driver.cc:572] creating context when one is currently active; existing: 0x6f991e0\nI tensorflow/core/common_runtime/gpu/gpu_init.cc:102] Found device 1 with properties:\nname: GRID K2\nmajor: 3 minor: 0 memoryClockRate (GHz) 0.745\npciBusID 0000:84:00.0\nTotal memory: 3.94GiB\nFree memory: 3.91GiB\nI tensorflow/core/common_runtime/gpu/gpu_init.cc:126] DMA: 0 1\nI tensorflow/core/common_runtime/gpu/gpu_init.cc:136] 0:   Y Y\nI tensorflow/core/common_runtime/gpu/gpu_init.cc:136] 1:   Y Y\nI tensorflow/core/common_runtime/gpu/gpu_device.cc:806] Creating TensorFlow device (/gpu:0) -> (device: 0, name: GRID K2, pci bus id: 0000:83:$0.0)\nI tensorflow/core/common_runtime/gpu/gpu_device.cc:806] Creating TensorFlow device (/gpu:1) -> (device: 1, name: GRID K2, pci bus id: 0000:84:$0.0)\nW tensorflow/core/common_runtime/bfc_allocator.cc:213] Ran out of memory trying to allocate 2.92GiB. The caller indicates that this is not a failure, but may mean that there could be performance gains if more memory is available.\nW tensorflow/core/common_runtime/bfc_allocator.cc:213] Ran out of memory trying to allocate 2.59GiB. The caller indicates that this is not a failure, but may mean that there could be performance gains if more memory is available.\nW tensorflow/core/common_runtime/bfc_allocator.cc:213] Ran out of memory trying to allocate 5.84GiB. The caller indicates that this is not a failure, but may mean that there could be performance gains if more memory is available.\nW tensorflow/core/common_runtime/bfc_allocator.cc:213] Ran out of memory trying to allocate 5.19GiB. The caller indicates that this is not a failure, but may mean that there could be performance gains if more memory is available.\nW tensorflow/core/common_runtime/bfc_allocator.cc:213] Ran out of memory trying to allocate 5.20GiB. The caller indicates that this is not a failure, but may mean that there could be performance gains if more memory is available.\n```\n\n\u4ee5\u4e0a\u3067\u3059\u3002\n\n# Reference\n[nvidia-docker\u3067tensorflow\u3092\u52d5\u304b\u3059 - Qiita](http://qiita.com/ymfj/items/6d2658240aaa02663453)\n[Ubuntu14.04.3\u3067nvidia-docker\u4f7f\u3063\u3066Caffe\u3092\u30a4\u30f3\u30b9\u30c8\u30fc\u30eb\u3057\u3066\u307f\u305f - Qiita](http://qiita.com/daxanya1/items/f04c7f75a6d2ecb92b23)\n"}