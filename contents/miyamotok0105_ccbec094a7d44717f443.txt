{"context": "opencv\u306f\u306f\u3058\u3081\u306fmake\u3057\u305f\u308a\u3057\u305f\u3051\u3069\u3046\u307e\u304f\u3044\u304b\u306a\u3044\u306e\u3067\u3001brew\u3067\u5165\u308c\u305f\n\u62e1\u5f35\u6a5f\u80fd\u306fconda\u306a\u3069\u3067\u3082\u63d0\u4f9b\u3055\u308c\u3066\u306a\u3044\u306e\u3067\u3059\u3002\n\u30bd\u30fc\u30b9\u3053\u3053\nhttps://github.com/miyamotok0105/opencv3_textdetection\n\u7d50\u8ad6\u304b\u3089\u8a00\u3046\u3068\u30c1\u30e5\u30fc\u30cb\u30f3\u30b0\u304c\u5927\u5909\u3002\u3082\u3063\u3068\u7c21\u5358\u306b\u3044\u304f\u3088\u3068\u304b\u3042\u308a\u307e\u3057\u305f\u3089\u610f\u898b\u304a\u5f85\u3061\u3057\u3066\u307e\u3059\u3002\n\n\u3084\u308a\u305f\u304b\u3063\u305f\u3053\u3068\u3053\u3044\u3064\n\u6587\u5b57\u9818\u57df\u691c\u51fa\u7528\u306eERFilter\u306e\u4f7f\u3044\u65b9\nopencv\u3067\u9818\u57df\u691c\u51fa\u3067\u304d\u308b\u3089\u3057\u3044\u3002\nopencv\u306e\u30d0\u30fc\u30b8\u30e7\u30f3\uff13\u3067\u3055\u3089\u306b\u62e1\u5f35\u6a5f\u80fd\u306a\u306e\u3067\u3059\u306d\u3002\n\u307e\u3060\u3061\u3083\u3093\u3068\u30c6\u30b9\u30c8\u3067\u304d\u3066\u306a\u304b\u3063\u305f\u308a\u3059\u308b\u6a5f\u80fd\u306f\u3053\u3063\u3061\u306b\u5165\u3063\u3066\u308b\u305d\u3046\u306a\u3002\n\u516c\u5f0f\nhttps://github.com/opencv/opencv_contrib\n\u5165\u308c\u3066\u307f\u308b\u3068\npython textdetection.py scenetext_word01.jpg \n\ntextdetection.py\n       A demo script of the Extremal Region Filter algorithm described in:\n       Neumann L., Matas J.: Real-Time Scene Text Localization and Recognition, CVPR 2012\n\nTraceback (most recent call last):\n  File \"textdetection.py\", line 28, in <module>\n    channels = cv2.text.computeNMChannels(img)\nAttributeError: module 'cv2.text' has no attribute 'computeNMChannels'\n\n\n--with-contrib\u30aa\u30d7\u30b7\u30e7\u30f3\u304c\u62e1\u5f35\u6a5f\u80fd\u306a\u308f\u3051\u306a\u3093\u3060\u3051\u3069\u3082\nC++\n\u30e0\u30c3\u30c1\u30e3\u4f55\u56de\u3082brew\u5165\u308c\u3066\u6d88\u3057\u3066\u3069\u308c\u306a\u3089\u52d5\u304f\u3093\u3060\u3068\u3002\nbrew install opencv3 --c++11 --with-tbb --with-gstreamer --with-opengl --with-openni --with-contrib\n\u3067\u3001\u3053\u3044\u3064\u3002\u3069\u3046\u3057\u305f\u3089\u3044\u3044\u306e\u3060\u3002\u3002\u3002\nlibrary not found for -lippicv\n\u89e3\u6c7a\u3057\u305f\u30da\u30fc\u30b8\nhttps://www.learnopencv.com/install-opencv-3-on-yosemite-osx-10-10-x/\n\u30e2\u30ea\u30c3\u30af\u3055\u3093\u3000\u3042\u308a\u304c\u3068\u3046\u3002\nippicv\u3092\u63a2\u3059\nfind /usr/local -name \"libippicv.a\"\n\u3053\u3053\u304c\u898b\u3064\u304b\u3063\u305f\u5834\u5408\n/usr/local/Cellar/opencv3/3.1.0_3/share/OpenCV/3rdparty/lib/libippicv.a\n\u30ea\u30dc\u30ea\u30c3\u30af\u30ea\u30f3\u30af\u3092\u8cbc\u308b\nln -s /usr/local/Cellar/opencv3/3.1.0_3/share/OpenCV/3rdparty/lib/libippicv.a /usr/local/lib/\n\n\u3053\u3093\u306a\u306e\u3067\u3061\u3083\u3063\u305f\u5834\u5408\n\nfatal error: 'opencv2/text.hpp' file not found\ninclude  \"opencv2/text.hpp\"\n\u3053\u3093\u306a\u611f\u3058\u3067\u30d1\u30b9\u3092\u901a\u3059\u3002\n~/.bashrc\nexport PKG_CONFIG_PATH=/usr/local/opt/opencv3/lib/pkgconfig\nexport LD_LIBRARY_PATH=/usr/local/opt/opencv3/lib\n\nValueError: too many values to unpack\nfindContours\u306f\u30d0\u30fc\u30b8\u30e7\u30f3\u306b\u3088\u3063\u3066\u623b\u308a\u5024\u304c\u5909\u308f\u3063\u3066\u308b\u3088\u3046\u3067\u3001\n_, \u3092\u306f\u3058\u3081\u306b\u8ffd\u52a0\u304c\u5fc5\u8981\u3002\n\u53e4\u3044\u30d0\u30fc\u30b8\u30e7\u30f3\ncontours, _ = cv2.findContours(skin_ycrcb, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n\u65b0\u3057\u3044\u30d0\u30fc\u30b8\u30e7\u30f3\n, contours, _ = cv2.findContours(skin_ycrcb, cv2.RETREXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n\n\u7d50\u679c\n\u592a\u6587\u5b57\u306f\u306a\u3093\u3068\u306a\u304f\u3044\u3051\u308b\n\n\n\n\n\n\n\n\n\n\n590 590\u753b\u50cf\u3067\u3002\n\u90e8\u5206\u7684\u306b\u8a8d\u8b58\u3055\u308c\u3066\u308b\u3002\n\n\n\n\n\n\n\n\n\n\n256 256\u306b\u5909\u63db\u3057\u3066\u307f\u305f\u3002\n\n\n\n\n\n\n\n\n\n\npython\u7248\u306f\u307e\u3060\u30a8\u30e9\u30fc\u306b\u306a\u3063\u3066\u308b\n\u308f\u304b\u308b\u65b9\u3044\u307e\u3057\u305f\u3089\u9023\u7d61\u304a\u5f85\u3061\u3057\u3066\u3044\u307e\u3059\u3002\ncv\u306e\u30d0\u30fc\u30b8\u30e7\u30f3\u78ba\u8a8d\u65b9\u6cd5\npython\n\n\n\nimport cv2\ncv2.version\n'3.1.0'\n\n\n\n\u30d3\u30eb\u30c9\u6642\u306b\u4f7f\u7528\u3059\u308b pkg-config \u306e\u30d1\u30b9 (PKG_CONFIG_PATH)\n\u5171\u6709\u30e9\u30a4\u30d6\u30e9\u30ea\u306e\u30d1\u30b9 (LD_LIBRARY_PATH)\n.bashrc\u306b\u8ffd\u8a18\nexport PKG_CONFIG_PATH=/usr/local/opt/opencv3/lib/pkgconfig\nexport LD_LIBRARY_PATH=/usr/local/opt/opencv3/lib\npython\u306e\u30d1\u30b9\u3092\u901a\u3059\nhttp://qiita.com/massaru129/items/f065f79b1322a82edb1d\n\n\u4ee3\u66ff\u3048\u6848\n\nOCR\nhttps://github.com/rishirdua/ocr-recognition/blob/master/Readme.md\n\nr-cnn\nEnd-to-End Text Recognition with Convolutional Neural Networks\nhttps://crypto.stanford.edu/~dwu4/papers/ICPR2012.pdf\nEND-TO-END TEXT RECOGNITION WITH CONVOLUTIONAL NEURAL\nNETWORKS\n\nhttps://crypto.stanford.edu/~dwu4/papers/HonorThesis.pdf\n\nopencv\u516c\u5f0f\u3000erfilter\nhttp://docs.opencv.org/3.0-beta/modules/text/doc/erfilter.html\n\nvoid computeNMChannels(InputArray _src, OutputArrayOfArrays _channels, int _mode)\n\u8272\u60c5\u5831\u3068\u304b\u30cf\u30d5\u5909\u63db\u3068\u304b\u7d44\u307f\u5408\u308f\u305b\u3066\u3001\u6700\u7d42\u7684\u306bSVM\u3068\u304b\u3067\u5b66\u7fd2\u3055\u305b\u305f\u65b9\u304c\u3088\u3044\u306e\u3067\u306f\n\u3053\u3046\u3044\u3046\u6fc3\u6de1\u306e\u30d2\u30b9\u30c8\u30b0\u30e9\u30e0\u3092\u7528\u3044\u308b\u624b\u6cd5\u3067\u3082\u7d50\u69cb\u3044\u3051\u308b\u306e\u3067\u306f\nhttp://www.aso.ecei.tohoku.ac.jp/publication_data/509.pdf\nopencv\u4f8b\nhttp://stackoverflow.com/questions/24385714/detect-text-region-in-image-using-opencv\n\n\u304a\u307e\u3051\nc++\nhttp://www.bohyoh.com/Books/MeikaiCPP01/index.html\nopencv\u30b5\u30f3\u30d7\u30eb\nhttp://opencv.jp/cookbook/opencv_img.html\n\u7279\u5fb4\u91cf\u62bd\u51fa\nhttp://qiita.com/hmichu/items/f5f1c778a155c7c414fd\nocr\nhttp://stackoverflow.com/questions/28591117/how-do-i-segment-a-document-using-tesseract-then-output-the-resulting-bounding-b\n\u6700\u8fd1\u508d\u88dc\u9593\uff08\u30cb\u30a2\u30ec\u30b9\u30c8\u30cd\u30a4\u30d0\u30fc\u3000Nearest neighbor\uff09\u7b49\nhttp://imagingsolution.blog107.fc2.com/blog-entry-142.html\nopencv\u306f\u306f\u3058\u3081\u306fmake\u3057\u305f\u308a\u3057\u305f\u3051\u3069\u3046\u307e\u304f\u3044\u304b\u306a\u3044\u306e\u3067\u3001brew\u3067\u5165\u308c\u305f\n\u62e1\u5f35\u6a5f\u80fd\u306fconda\u306a\u3069\u3067\u3082\u63d0\u4f9b\u3055\u308c\u3066\u306a\u3044\u306e\u3067\u3059\u3002\n\n\u30bd\u30fc\u30b9\u3053\u3053\nhttps://github.com/miyamotok0105/opencv3_textdetection\n\n\u7d50\u8ad6\u304b\u3089\u8a00\u3046\u3068\u30c1\u30e5\u30fc\u30cb\u30f3\u30b0\u304c\u5927\u5909\u3002\u3082\u3063\u3068\u7c21\u5358\u306b\u3044\u304f\u3088\u3068\u304b\u3042\u308a\u307e\u3057\u305f\u3089\u610f\u898b\u304a\u5f85\u3061\u3057\u3066\u307e\u3059\u3002\n![detect_2016-10-21 23.16.22.png](https://qiita-image-store.s3.amazonaws.com/0/64334/41890889-8783-667e-09da-1a4b7ff06e20.png)\n\n\u3084\u308a\u305f\u304b\u3063\u305f\u3053\u3068\u3053\u3044\u3064\n[\u6587\u5b57\u9818\u57df\u691c\u51fa\u7528\u306eERFilter\u306e\u4f7f\u3044\u65b9](http://qiita.com/TaroYamada/items/3334e879cf978740b542)\n\nopencv\u3067\u9818\u57df\u691c\u51fa\u3067\u304d\u308b\u3089\u3057\u3044\u3002\nopencv\u306e\u30d0\u30fc\u30b8\u30e7\u30f3\uff13\u3067\u3055\u3089\u306b\u62e1\u5f35\u6a5f\u80fd\u306a\u306e\u3067\u3059\u306d\u3002\n\u307e\u3060\u3061\u3083\u3093\u3068\u30c6\u30b9\u30c8\u3067\u304d\u3066\u306a\u304b\u3063\u305f\u308a\u3059\u308b\u6a5f\u80fd\u306f\u3053\u3063\u3061\u306b\u5165\u3063\u3066\u308b\u305d\u3046\u306a\u3002\n\n\u516c\u5f0f\nhttps://github.com/opencv/opencv_contrib\n\n\u5165\u308c\u3066\u307f\u308b\u3068\n\npython textdetection.py scenetext_word01.jpg \n\n\n```python:textdetection.py\n       A demo script of the Extremal Region Filter algorithm described in:\n       Neumann L., Matas J.: Real-Time Scene Text Localization and Recognition, CVPR 2012\n\nTraceback (most recent call last):\n  File \"textdetection.py\", line 28, in <module>\n    channels = cv2.text.computeNMChannels(img)\nAttributeError: module 'cv2.text' has no attribute 'computeNMChannels'\n```\n\n\n--with-contrib\u30aa\u30d7\u30b7\u30e7\u30f3\u304c\u62e1\u5f35\u6a5f\u80fd\u306a\u308f\u3051\u306a\u3093\u3060\u3051\u3069\u3082\nC++\n\u30e0\u30c3\u30c1\u30e3\u4f55\u56de\u3082brew\u5165\u308c\u3066\u6d88\u3057\u3066\u3069\u308c\u306a\u3089\u52d5\u304f\u3093\u3060\u3068\u3002\nbrew install opencv3 --c++11 --with-tbb --with-gstreamer --with-opengl --with-openni --with-contrib\n\n\n\u3067\u3001\u3053\u3044\u3064\u3002\u3069\u3046\u3057\u305f\u3089\u3044\u3044\u306e\u3060\u3002\u3002\u3002\nlibrary not found for -lippicv\n\n\n\u89e3\u6c7a\u3057\u305f\u30da\u30fc\u30b8\nhttps://www.learnopencv.com/install-opencv-3-on-yosemite-osx-10-10-x/\n\u30e2\u30ea\u30c3\u30af\u3055\u3093\u3000\u3042\u308a\u304c\u3068\u3046\u3002\n\nippicv\u3092\u63a2\u3059\nfind /usr/local -name \"libippicv.a\"\n\u3053\u3053\u304c\u898b\u3064\u304b\u3063\u305f\u5834\u5408\n/usr/local/Cellar/opencv3/3.1.0_3/share/OpenCV/3rdparty/lib/libippicv.a\n  \n\u30ea\u30dc\u30ea\u30c3\u30af\u30ea\u30f3\u30af\u3092\u8cbc\u308b\nln -s /usr/local/Cellar/opencv3/3.1.0_3/share/OpenCV/3rdparty/lib/libippicv.a /usr/local/lib/\n\n#\u3053\u3093\u306a\u306e\u3067\u3061\u3083\u3063\u305f\u5834\u5408\n\n##fatal error: 'opencv2/text.hpp' file not found\ninclude  \"opencv2/text.hpp\"\n\n\u3053\u3093\u306a\u611f\u3058\u3067\u30d1\u30b9\u3092\u901a\u3059\u3002\n~/.bashrc\nexport PKG_CONFIG_PATH=/usr/local/opt/opencv3/lib/pkgconfig\nexport LD_LIBRARY_PATH=/usr/local/opt/opencv3/lib\n\n##ValueError: too many values to unpack\nfindContours\u306f\u30d0\u30fc\u30b8\u30e7\u30f3\u306b\u3088\u3063\u3066\u623b\u308a\u5024\u304c\u5909\u308f\u3063\u3066\u308b\u3088\u3046\u3067\u3001\n_, \u3092\u306f\u3058\u3081\u306b\u8ffd\u52a0\u304c\u5fc5\u8981\u3002\n\n\u53e4\u3044\u30d0\u30fc\u30b8\u30e7\u30f3\ncontours, _ = cv2.findContours(skin_ycrcb, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n\n\u65b0\u3057\u3044\u30d0\u30fc\u30b8\u30e7\u30f3\n_, contours, _ = cv2.findContours(skin_ycrcb, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n\n\n#\u7d50\u679c\n\u592a\u6587\u5b57\u306f\u306a\u3093\u3068\u306a\u304f\u3044\u3051\u308b\n![detect_2016-10-21 22.55.02.png](https://qiita-image-store.s3.amazonaws.com/0/64334/edb7a9e5-34c3-e7dc-d466-76d561b65c2e.png)\n![detect_2016-10-21 23.02.23.png](https://qiita-image-store.s3.amazonaws.com/0/64334/f273f059-b4c8-90f1-00a3-3f0f6a3bed2d.png)\n![detect_2016-10-21 23.16.22.png](https://qiita-image-store.s3.amazonaws.com/0/64334/80e340ee-178c-5147-f374-8d0b2d035c7b.png)\n![detect_2016-10-21 23.25.06.png](https://qiita-image-store.s3.amazonaws.com/0/64334/be24e005-f818-fe89-9186-7e7cb82992ab.png)\n![detect_2016-10-21 23.25.12.png](https://qiita-image-store.s3.amazonaws.com/0/64334/d80f4864-fe96-4aaa-064e-1683c93a6c78.png)\n![detect_2016-10-21 23.27.55.png](https://qiita-image-store.s3.amazonaws.com/0/64334/bb810a7b-f0b9-ffb7-da51-7ff873de9a82.png)\n![detect_2016-10-21 23.30.10.png](https://qiita-image-store.s3.amazonaws.com/0/64334/bda011fd-2a09-67e4-a568-ac4517b39249.png)\n![detect_2016-10-21 23.31.52.png](https://qiita-image-store.s3.amazonaws.com/0/64334/1e9ef697-c77e-f349-2b21-845e27ae05ac.png)\n![detect_2016-10-21 23.32.46.png](https://qiita-image-store.s3.amazonaws.com/0/64334/744818dd-cca9-432e-a6e9-b4e4e988a7c0.png)\n![detect_2016-10-21 23.33.09.png](https://qiita-image-store.s3.amazonaws.com/0/64334/d4dd3c26-6eec-308e-324b-19cb25a79e3d.png)\n\n590 590\u753b\u50cf\u3067\u3002\n\u90e8\u5206\u7684\u306b\u8a8d\u8b58\u3055\u308c\u3066\u308b\u3002\n![detect_590_1fc36f6427e8a492511dccee47b8607e.png](https://qiita-image-store.s3.amazonaws.com/0/64334/60acdeb9-1044-ab1e-e11e-554c9825bf53.png)\n![detect_590_3b6a5931c91204b45d5e7446b51d706c.jpg](https://qiita-image-store.s3.amazonaws.com/0/64334/8b5436cc-8633-6977-205f-9f5665c3ed76.jpeg)\n![detect_590_32ed93a61d856e376ae52b616d63f453.jpg](https://qiita-image-store.s3.amazonaws.com/0/64334/0aaf6a9d-900e-550e-a320-7b7aff13fc3d.jpeg)\n![detect_590_b.jpg](https://qiita-image-store.s3.amazonaws.com/0/64334/31fe2849-2997-7413-36dd-ada94511b12e.jpeg)\n![detect_590_rirekisho_sp.jpg](https://qiita-image-store.s3.amazonaws.com/0/64334/dcdd8e99-7ed0-6e3e-6cc3-cf83d64567ba.jpeg)\n![detect_590_rirekisyo.jpg](https://qiita-image-store.s3.amazonaws.com/0/64334/65c466d3-cee3-ca20-e5af-a157342f9787.jpeg)\n![detect_590_rirekisyosample.jpg](https://qiita-image-store.s3.amazonaws.com/0/64334/aa747295-ea8b-af58-5238-bdea657e639e.jpeg)\n![detect_590_\u30c0\u30a6\u30f3\u30ed\u30fc\u30c9.png](https://qiita-image-store.s3.amazonaws.com/0/64334/6138ce0f-8147-de85-4857-3fc830b9a7aa.png)\n![detect_590_\u6cd5\u4eba\u8a2d\u7acb\u5c4a\u30b5\u30f3\u30d7\u30eb\uff08\u5e02\u753a\u6751\uff09\u753b\u50cf.png](https://qiita-image-store.s3.amazonaws.com/0/64334/9c0ffc84-5765-a3ce-17ef-c67b504cfdb1.png)\n![detect_590_\u6cd5\u4eba\u8a2d\u7acb\u5c4a\u51fa\u66f8\u30b5\u30f3\u30d7\u30eb\uff08\u56fd\u7a0e\uff09\u753b\u50cf.png](https://qiita-image-store.s3.amazonaws.com/0/64334/e8ffb8e0-42c9-27a3-d6e2-b973a8f382f1.png)\n\n\n256 256\u306b\u5909\u63db\u3057\u3066\u307f\u305f\u3002\n![detect_256_1fc36f6427e8a492511dccee47b8607e.png](https://qiita-image-store.s3.amazonaws.com/0/64334/04cc7278-d8fd-fb71-37e1-39d244bd41eb.png)\n![detect_256_3b6a5931c91204b45d5e7446b51d706c.jpg](https://qiita-image-store.s3.amazonaws.com/0/64334/52f89e1e-ec96-011d-a1ef-bac046dc944f.jpeg)\n![detect_256_32ed93a61d856e376ae52b616d63f453.jpg](https://qiita-image-store.s3.amazonaws.com/0/64334/9f1267af-750d-f4f0-0a94-e8285765cb81.jpeg)\n![detect_256_b.jpg](https://qiita-image-store.s3.amazonaws.com/0/64334/4936ae47-c245-9b8f-43c5-3beb21a01963.jpeg)\n![detect_256_rirekisho_sp.jpg](https://qiita-image-store.s3.amazonaws.com/0/64334/5c578846-04d4-25fb-0f0f-d41bc4f003ac.jpeg)\n![detect_256_rirekisyo.jpg](https://qiita-image-store.s3.amazonaws.com/0/64334/b951c9f2-eea6-4b62-3c35-d34cd74a287f.jpeg)\n![detect_256_rirekisyosample.jpg](https://qiita-image-store.s3.amazonaws.com/0/64334/0c4be6c1-55cb-a4b9-ee7c-bf59b5187a2e.jpeg)\n![detect_256_\u6cd5\u4eba\u8a2d\u7acb\u5c4a\u30b5\u30f3\u30d7\u30eb\uff08\u5e02\u753a\u6751\uff09\u753b\u50cf.png](https://qiita-image-store.s3.amazonaws.com/0/64334/4d5d7dde-0dad-77b4-08f8-99f940a3765c.png)\n![detect_256_\u6cd5\u4eba\u8a2d\u7acb\u5c4a\u51fa\u66f8\u30b5\u30f3\u30d7\u30eb\uff08\u56fd\u7a0e\uff09\u753b\u50cf.png](https://qiita-image-store.s3.amazonaws.com/0/64334/df55da54-2772-2a82-8650-8c72bd6de9ed.png)\n\n\n#python\u7248\u306f\u307e\u3060\u30a8\u30e9\u30fc\u306b\u306a\u3063\u3066\u308b\n\u308f\u304b\u308b\u65b9\u3044\u307e\u3057\u305f\u3089\u9023\u7d61\u304a\u5f85\u3061\u3057\u3066\u3044\u307e\u3059\u3002\n\ncv\u306e\u30d0\u30fc\u30b8\u30e7\u30f3\u78ba\u8a8d\u65b9\u6cd5\n\npython\n>>> import cv2\n>>> cv2.__version__\n'3.1.0'\n>>> \n\n\u30d3\u30eb\u30c9\u6642\u306b\u4f7f\u7528\u3059\u308b pkg-config \u306e\u30d1\u30b9 (PKG_CONFIG_PATH)\n\u5171\u6709\u30e9\u30a4\u30d6\u30e9\u30ea\u306e\u30d1\u30b9 (LD_LIBRARY_PATH)\n\n.bashrc\u306b\u8ffd\u8a18\nexport PKG_CONFIG_PATH=/usr/local/opt/opencv3/lib/pkgconfig\nexport LD_LIBRARY_PATH=/usr/local/opt/opencv3/lib\n\npython\u306e\u30d1\u30b9\u3092\u901a\u3059\nhttp://qiita.com/massaru129/items/f065f79b1322a82edb1d\n\n\n#\u4ee3\u66ff\u3048\u6848\n\n\n##OCR\nhttps://github.com/rishirdua/ocr-recognition/blob/master/Readme.md\n\n##r-cnn\n\nEnd-to-End Text Recognition with Convolutional Neural Networks\nhttps://crypto.stanford.edu/~dwu4/papers/ICPR2012.pdf\n\nEND-TO-END TEXT RECOGNITION WITH CONVOLUTIONAL NEURAL\nNETWORKS\nhttps://crypto.stanford.edu/~dwu4/papers/HonorThesis.pdf\n----------\n\nopencv\u516c\u5f0f\u3000erfilter\nhttp://docs.opencv.org/3.0-beta/modules/text/doc/erfilter.html\n#void computeNMChannels(InputArray _src, OutputArrayOfArrays _channels, int _mode)\n\n\u8272\u60c5\u5831\u3068\u304b\u30cf\u30d5\u5909\u63db\u3068\u304b\u7d44\u307f\u5408\u308f\u305b\u3066\u3001\u6700\u7d42\u7684\u306bSVM\u3068\u304b\u3067\u5b66\u7fd2\u3055\u305b\u305f\u65b9\u304c\u3088\u3044\u306e\u3067\u306f\n\u3053\u3046\u3044\u3046\u6fc3\u6de1\u306e\u30d2\u30b9\u30c8\u30b0\u30e9\u30e0\u3092\u7528\u3044\u308b\u624b\u6cd5\u3067\u3082\u7d50\u69cb\u3044\u3051\u308b\u306e\u3067\u306f\nhttp://www.aso.ecei.tohoku.ac.jp/publication_data/509.pdf\n\nopencv\u4f8b\nhttp://stackoverflow.com/questions/24385714/detect-text-region-in-image-using-opencv\n\n#\u304a\u307e\u3051\nc++\nhttp://www.bohyoh.com/Books/MeikaiCPP01/index.html\n\nopencv\u30b5\u30f3\u30d7\u30eb\nhttp://opencv.jp/cookbook/opencv_img.html\n\n\u7279\u5fb4\u91cf\u62bd\u51fa\nhttp://qiita.com/hmichu/items/f5f1c778a155c7c414fd\n\nocr\nhttp://stackoverflow.com/questions/28591117/how-do-i-segment-a-document-using-tesseract-then-output-the-resulting-bounding-b\n\u6700\u8fd1\u508d\u88dc\u9593\uff08\u30cb\u30a2\u30ec\u30b9\u30c8\u30cd\u30a4\u30d0\u30fc\u3000Nearest neighbor\uff09\u7b49\nhttp://imagingsolution.blog107.fc2.com/blog-entry-142.html\n", "tags": ["OpenCV", "C++"]}