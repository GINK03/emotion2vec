{"context": "\u904e\u53bb\uff16\u56de\u3067\u3001Ubuntu14.04\u3001CUDA\u3001chainer\u3001dqn\u3001LIS\u3001Tensorflow\u3001Open AI Gym\u3092\u9806\u6b21\u30a4\u30f3\u30b9\u30c8\u30fc\u30eb\u3057\u3001\u6700\u5f8c\u306bOpen AI Gym\u306e\u30b5\u30f3\u30d7\u30eb\u30b3\u30fc\u30c9\u3092\u3061\u3087\u3063\u3068\u3044\u3058\u3063\u305f\u3002\nhttp://qiita.com/masataka46/items/cc37d36137a4a162c04a\n\u4eca\u56de\u3082\u524d\u56de\u3068\u540c\u69d8\u3001Open AI Gym\u306eHP\u306b\u8f09\u3063\u3066\u308bCartPole\u30b2\u30fc\u30e0\u306e\u30b5\u30f3\u30d7\u30eb\u30b3\u30fc\u30c9\u3092\u3044\u3058\u308a\u306a\u304c\u3089\u3001\u4ed5\u7d44\u307f\u3092\u5b66\u3093\u3067\u3044\u304f\u3002\u516c\u5f0fHP\u306f\u3053\u3061\u3089\u3002\nhttps://gym.openai.com/docs\nCartPole-v0\u306e\u30b5\u30f3\u30d7\u30eb\u30b3\u30fc\u30c9\uff08test06.py\uff09\u306f\u3053\u3061\u3089\u3002\nimport gym\nenv = gym.make('CartPole-v0')\nfor i_episode in range(20):\n    observation = env.reset()\n    for t in range(100):\n        env.render()\n        print(observation)\n        action = env.action_space.sample()\n        observation, reward, done, info = env.step(action)\n        if done:\n            print(\"Episode finished after {} timesteps\".format(t+1))\n            break\n\n\nstep\u95a2\u6570\n\u524d\u56de\uff18\u884c\u76ee\u307e\u3067\u898b\u305f\u306e\u3067\u3001\u4eca\u56de\u306f\uff19\u884c\u76ee\u3002env.step()\u306baction\u3092\u653e\u308a\u8fbc\u3080\u3068\u3001\u623b\u308a\u5024\u3068\u3057\u3066\u3044\u308d\u3044\u308d\u8fd4\u3063\u3066\u304d\u3066\u3044\u308b\u3002action\u306f\uff17\u884c\u76ee\u3067\u30e9\u30f3\u30c0\u30e0\u306a\u5024\u3092\u751f\u6210\u3057\u3066\u3044\u308b\u306e\u3067\u3001\u30e9\u30f3\u30c0\u30e0\u306b\u9078\u629e\u3055\u308c\u305facttion\uff08\u4f8b\u3048\u3070\u53f3\uff09\u3092\u653e\u308a\u8fbc\u3093\u3067\u3044\u308b\u308f\u3051\u3060\u3002\n\u3053\u306estep\u95a2\u6570\u306fcore.py\u306eEnv\u30af\u30e9\u30b9\u306b\u8a18\u8f09\u3055\u308c\u3066\u3044\u308b\u3002\nhttps://github.com/openai/gym/blob/master/gym/core.py\ndef step(self, action):\n    self.monitor._before_step(action)\n    observation, reward, done, info = self._step(action)\n    done = self.monitor._after_step(observation, reward, done, info)\n    return observation, reward, done, info\n\n\u3053\u306e\u95a2\u6570\u5185\u306b\u66f8\u304b\u308c\u3066\u3044\u308b\u89e3\u8aac\u3092\u307e\u3068\u3081\u308b\u3068\u4ee5\u4e0b\u3002\n\uff08\uff11\uff09\u74b0\u5883\u3092\uff11step\u9032\u3081\u308b\u3002\u3082\u3057episode\u306e\u7d42\u308f\u308a\u306b\u9054\u3059\u308c\u3070\u3001reset()\u3092\u81ea\u52d5\u7684\u306b\u547c\u3073\u51fa\u3059\u3002\n\uff08\uff12\uff09\u5f15\u6570\u3068\u3057\u3066action\u30aa\u30d6\u30b8\u30a7\u30af\u30c8\u3092\u3068\u308a\u3001\u623b\u308a\u5024\u3068\u3057\u3066observation\u3001reward\u3001done\u3001info\u3092\u542b\u3080\u30bf\u30d7\u30eb\u3092\u8fd4\u3059\u3002\n\uff08\uff13\uff09done\u306fboolean\u578b\u3067episode\u304c\u7d42\u308f\u3063\u305f\u304b\u5426\u304b\u3092\u4fdd\u6301\u3002\n\uff08\uff14\uff09info\u306fdictionary\u578b\u3067\u30c7\u30d0\u30c3\u30b0\u60c5\u5831\u306a\u3069\u4e88\u5099\u306e\u8a3a\u65ad\u60c5\u5831\u3092\u4fdd\u6301\u3002\n\u6b21\u306bstep\u95a2\u6570\u306e\u4e2d\u8eab\u3092\u898b\u3066\u3044\u304f\u3002\uff12\u884c\u76ee\u306emonitor\u306f\u3088\u304f\u308f\u304b\u3089\u3093\u304c\u3001\u753b\u9762\u3078\u306e\u51fa\u529b\u95a2\u4fc2\u304b\uff1f\n\uff13\u884c\u76ee\u306f_step\u306baction\u3092\u653e\u308a\u8fbc\u3093\u3067\u3001\uff14\u3064\u306e\u60c5\u5831\u304c\u8fd4\u3063\u3066\u304d\u3066\u3044\u308b\u3002\uff14\u884c\u76ee\u3082\u753b\u9762\u3078\u306e\u51fa\u529b\u95a2\u4fc2\u304b\uff1f\uff15\u884c\u76ee\u3067\uff14\u3064\u306e\u5024\u3092\u8fd4\u3059\u3002\n\u91cd\u8981\u306a\u306e\u306f\uff13\u884c\u76ee\u306e_step\u95a2\u6570\u3002\u3053\u308c\u306b\u95a2\u3057\u3066\u306f\n # Override in ALL subclasses\ndef _step(self, action): raise NotImplementedError\n\n\u3068\u3042\u308b\u3002\u4eca\u56de\u306f\u3069\u3053\u304b\u3067\u5b9f\u88c5\u3055\u308c\u3066\u3044\u308b\u306e\u3060\u308d\u3046\u304b\uff1f\n\nif done\u306e\u90e8\u5206\n\u6b21\u306b\uff19\u884c\u76ee\u4ee5\u964d\u306eif\u6587\u3002\u5148\u307b\u3069\u898b\u305f\u3088\u3046\u306bdone\u306fepisode\u304c\u7d42\u4e86\u3059\u308c\u3070TRUE\u3092\u8fd4\u3059\u3002\u3088\u3063\u3066\u3001\u3053\u306eif\u6587\u306fepisode\u304c\u7d42\u4e86\u3057\u305f\u6642\u306b\u300c\u301ctimesteps\u3067\u7d42\u4e86\u3057\u307e\u3057\u305f\u3088\u300d\u3068\u51fa\u529b\u3059\u308b\u3082\u306e\u3002\n\nreward\u3082\u51fa\u529b\u3059\u308b\n\u6b21\u306breward\u304c\u3069\u3093\u306a\u5024\u306a\u306e\u304b\u3001\u51fa\u529b\u3057\u3066\u78ba\u304b\u3081\u3066\u307f\u308b\u3002test06.py\u306e\uff19\u884c\u76ee\u3068\uff11\uff10\u884c\u76ee\u306e\u9593\u306b\u4ee5\u4e0b\u3092\u8ffd\u52a0\u3059\u308b\u3002\nprint(\"reward is \"),\nprint(reward)\n\n\u51fa\u529b\u306f\u3053\u3093\u306a\u611f\u3058\u3002\n[ 0.01509218 -0.01367975 -0.00316408  0.01795877]\nreward is  1.0\n[ 0.01481859 -0.20875618 -0.00280491  0.30964172]\nreward is  1.0\n[ 0.01064347 -0.40383806  0.00338793  0.60143874]\nreward is  1.0\n[ 0.0025667  -0.20876366  0.0154167   0.30982487]\nreward is  1.0\n[-0.00160857 -0.01386472  0.0216132   0.02204353]\nreward is  1.0\n\n\u5831\u916c\u306f\u305a\u3063\u30681.0\u3068\u306a\u3063\u3066\u3044\u308b\u3002\u57fa\u6e96\u304c\u3088\u304f\u308f\u304b\u3089\u3093\u304c\u3001pole\u304c\u5012\u308c\u306a\u304b\u3063\u305f\u3089\u6bce\u6642\u523b1.0\u3082\u3089\u3048\u308b\u306e\u3060\u308d\u3046\u304b\uff1f\n\nobservation\u306b\u3082\u3068\u3065\u3044\u3066action\u3092\u64cd\u4f5c\u3059\u308b\n\u5b9f\u88c5\u306e\u4e2d\u5fc3\u306f\u3001\u6211\u3005\u304c\u53d7\u3051\u53d6\u3063\u305fobservation\u306b\u5bfe\u3057\u3066\u3069\u306e\u3088\u3046\u306aaction\u3092\u8fd4\u3059\u304b\u3001\u3068\u3044\u3046\u90e8\u5206\u3060\u308d\u3046\u3002\u3057\u304b\u3057test06.py\u306e\u30b3\u30fc\u30c9\u3067\u306f\u3001\uff19\u884c\u76ee\u3067observation\u3092\u53d7\u3051\u53d6\u3063\u3066\u3044\u308b\u306b\u3082\u95a2\u308f\u3089\u305a\u3001\u305d\u308c\u3068\u306f\u95a2\u4fc2\u306a\u304f\uff18\u884c\u76ee\u3067\u30e9\u30f3\u30c0\u30e0\u306aaction\u3092\u6e21\u3057\u3066\u3044\u308b\u3002\u3053\u308c\u306f\u9762\u767d\u304f\u306a\u3044\u3002\n\u305d\u3053\u3067\u3001\u4ee5\u4e0b\u306e\u3088\u3046\u306bobsevation\u306e\u5024\u3092\u51e6\u7406\u3057\u3001\u305d\u308c\u3092action\u306b\u53cd\u6620\u3055\u305b\u3066\u307f\u308b\u3002\nimport gym\nenv = gym.make('CartPole-v0')\ntotal_reward_sum = [0] * 20\nfor i_episode in range(20):\n    observation = env.reset()\n    total_reward = 0\n    for t in range(100):\n        env.render()\n        print(observation)\n        #action = env.action_space.sample()\n        sum_obs = observation[0] + observation[1] + observation[2] + observation[3]\n        if sum_obs > 0:\n            action = 1\n        else:\n            action = 0\n        observation, reward, done, info = env.step(action)\n        total_reward += 1\n        if done:\n            print(\"Episode finished after {} timesteps\".format(t+1))\n            print(\"total reward is\"),\n            print(total_reward)\n            total_reward_sum[i_episode] = total_reward\n            if i_episode == 19:\n                print(\"all total reward is\"),\n                print(total_reward_sum)\n            break\n        if t == 99:\n            print(\"Episode finished after {} timesteps\".format(t+1))\n            print(\"total reward is\"),\n            print(total_reward)\n            total_reward_sum[i_episode] = total_reward\n            if i_episode == 19:\n                print(\"all total reward is\"),\n                print(total_reward_sum)\n\n\u30c8\u30fc\u30bf\u30eb\u306a\u5831\u916c\u306e\u51fa\u529b\u3092episode\u7d42\u4e86\u6642\u306e\u307f\u3067\u306a\u304f\u3001max\u306e\uff11\uff10\uff10timestep\u7d42\u4e86\u6642\u306b\u3082\u8a2d\u5b9a\u3057\u305f\u306e\u306f\u3001\u3053\u306e\u30a2\u30eb\u30b4\u30ea\u30ba\u30e0\u304c\u826f\u3059\u304e\u3066\u3001\u68d2\u304c\u5012\u308c\u308b\u3053\u3068\u7121\u304f\u6bce\u56de\u307b\u307cmax\u307e\u3067\u9054\u3059\u308b\u305f\u3081\u3002\u5b9f\u969b\u3001episode\uff12\uff10\u56de\u5206\u306e\u30c8\u30fc\u30bf\u30eb\u5831\u916c\u306f\u4ee5\u4e0b\u306e\u3088\u3046\u306b\u306a\u3063\u305f\u3002\nall total reward is [100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 97, 100, 100, 100, 100, 100, 100, 74, 100]\n\n\u4f55\u3082\u8003\u3048\u305a\u306b\u4f5c\u3063\u305f\u306e\u306b\u3001\u7d20\u6674\u3089\u3057\u3044\u306d\uff01\u3061\u306a\u307f\u306baction\u3092\u53f3\u3068\u5de6\u5165\u308c\u66ff\u3048\u305f\u7d50\u679c\u304c\u4ee5\u4e0b\u3002\nall total reward is [8, 9, 9, 9, 10, 9, 9, 10, 9, 9, 10, 9, 9, 9, 8, 10, 10, 9, 9, 9]\n\n\u3081\u3063\u3061\u3083\u65e9\u304f\u5012\u308c\u3066\u3044\u308b\u3002\u3068\u3044\u3046\u304b\u5012\u308c\u308b\u306e\u3092\u52a9\u9577\u3055\u305b\u3066\u308b\u306d\u3002\n\u904e\u53bb\uff16\u56de\u3067\u3001Ubuntu14.04\u3001CUDA\u3001chainer\u3001dqn\u3001LIS\u3001Tensorflow\u3001Open AI Gym\u3092\u9806\u6b21\u30a4\u30f3\u30b9\u30c8\u30fc\u30eb\u3057\u3001\u6700\u5f8c\u306bOpen AI Gym\u306e\u30b5\u30f3\u30d7\u30eb\u30b3\u30fc\u30c9\u3092\u3061\u3087\u3063\u3068\u3044\u3058\u3063\u305f\u3002\nhttp://qiita.com/masataka46/items/cc37d36137a4a162c04a\n\n\u4eca\u56de\u3082\u524d\u56de\u3068\u540c\u69d8\u3001Open AI Gym\u306eHP\u306b\u8f09\u3063\u3066\u308bCartPole\u30b2\u30fc\u30e0\u306e\u30b5\u30f3\u30d7\u30eb\u30b3\u30fc\u30c9\u3092\u3044\u3058\u308a\u306a\u304c\u3089\u3001\u4ed5\u7d44\u307f\u3092\u5b66\u3093\u3067\u3044\u304f\u3002\u516c\u5f0fHP\u306f\u3053\u3061\u3089\u3002\nhttps://gym.openai.com/docs\n\nCartPole-v0\u306e\u30b5\u30f3\u30d7\u30eb\u30b3\u30fc\u30c9\uff08test06.py\uff09\u306f\u3053\u3061\u3089\u3002\n\n```py\nimport gym\nenv = gym.make('CartPole-v0')\nfor i_episode in range(20):\n    observation = env.reset()\n    for t in range(100):\n        env.render()\n        print(observation)\n        action = env.action_space.sample()\n        observation, reward, done, info = env.step(action)\n        if done:\n            print(\"Episode finished after {} timesteps\".format(t+1))\n            break\n```\n\n##step\u95a2\u6570\n\u524d\u56de\uff18\u884c\u76ee\u307e\u3067\u898b\u305f\u306e\u3067\u3001\u4eca\u56de\u306f\uff19\u884c\u76ee\u3002env.step()\u306baction\u3092\u653e\u308a\u8fbc\u3080\u3068\u3001\u623b\u308a\u5024\u3068\u3057\u3066\u3044\u308d\u3044\u308d\u8fd4\u3063\u3066\u304d\u3066\u3044\u308b\u3002action\u306f\uff17\u884c\u76ee\u3067\u30e9\u30f3\u30c0\u30e0\u306a\u5024\u3092\u751f\u6210\u3057\u3066\u3044\u308b\u306e\u3067\u3001\u30e9\u30f3\u30c0\u30e0\u306b\u9078\u629e\u3055\u308c\u305facttion\uff08\u4f8b\u3048\u3070\u53f3\uff09\u3092\u653e\u308a\u8fbc\u3093\u3067\u3044\u308b\u308f\u3051\u3060\u3002\n\n\u3053\u306estep\u95a2\u6570\u306fcore.py\u306eEnv\u30af\u30e9\u30b9\u306b\u8a18\u8f09\u3055\u308c\u3066\u3044\u308b\u3002\nhttps://github.com/openai/gym/blob/master/gym/core.py\n\n```py\ndef step(self, action):\n    self.monitor._before_step(action)\n    observation, reward, done, info = self._step(action)\n    done = self.monitor._after_step(observation, reward, done, info)\n    return observation, reward, done, info\n```\n\n\u3053\u306e\u95a2\u6570\u5185\u306b\u66f8\u304b\u308c\u3066\u3044\u308b\u89e3\u8aac\u3092\u307e\u3068\u3081\u308b\u3068\u4ee5\u4e0b\u3002\n\uff08\uff11\uff09\u74b0\u5883\u3092\uff11step\u9032\u3081\u308b\u3002\u3082\u3057episode\u306e\u7d42\u308f\u308a\u306b\u9054\u3059\u308c\u3070\u3001reset()\u3092\u81ea\u52d5\u7684\u306b\u547c\u3073\u51fa\u3059\u3002\n\uff08\uff12\uff09\u5f15\u6570\u3068\u3057\u3066action\u30aa\u30d6\u30b8\u30a7\u30af\u30c8\u3092\u3068\u308a\u3001\u623b\u308a\u5024\u3068\u3057\u3066observation\u3001reward\u3001done\u3001info\u3092\u542b\u3080\u30bf\u30d7\u30eb\u3092\u8fd4\u3059\u3002\n\uff08\uff13\uff09done\u306fboolean\u578b\u3067episode\u304c\u7d42\u308f\u3063\u305f\u304b\u5426\u304b\u3092\u4fdd\u6301\u3002\n\uff08\uff14\uff09info\u306fdictionary\u578b\u3067\u30c7\u30d0\u30c3\u30b0\u60c5\u5831\u306a\u3069\u4e88\u5099\u306e\u8a3a\u65ad\u60c5\u5831\u3092\u4fdd\u6301\u3002\n\n\u6b21\u306bstep\u95a2\u6570\u306e\u4e2d\u8eab\u3092\u898b\u3066\u3044\u304f\u3002\uff12\u884c\u76ee\u306emonitor\u306f\u3088\u304f\u308f\u304b\u3089\u3093\u304c\u3001\u753b\u9762\u3078\u306e\u51fa\u529b\u95a2\u4fc2\u304b\uff1f\n\n\uff13\u884c\u76ee\u306f_step\u306baction\u3092\u653e\u308a\u8fbc\u3093\u3067\u3001\uff14\u3064\u306e\u60c5\u5831\u304c\u8fd4\u3063\u3066\u304d\u3066\u3044\u308b\u3002\uff14\u884c\u76ee\u3082\u753b\u9762\u3078\u306e\u51fa\u529b\u95a2\u4fc2\u304b\uff1f\uff15\u884c\u76ee\u3067\uff14\u3064\u306e\u5024\u3092\u8fd4\u3059\u3002\n\n\u91cd\u8981\u306a\u306e\u306f\uff13\u884c\u76ee\u306e_step\u95a2\u6570\u3002\u3053\u308c\u306b\u95a2\u3057\u3066\u306f\n\n```py\n # Override in ALL subclasses\ndef _step(self, action): raise NotImplementedError\n```\n\n\u3068\u3042\u308b\u3002\u4eca\u56de\u306f\u3069\u3053\u304b\u3067\u5b9f\u88c5\u3055\u308c\u3066\u3044\u308b\u306e\u3060\u308d\u3046\u304b\uff1f\n\n##if done\u306e\u90e8\u5206\n\u6b21\u306b\uff19\u884c\u76ee\u4ee5\u964d\u306eif\u6587\u3002\u5148\u307b\u3069\u898b\u305f\u3088\u3046\u306bdone\u306fepisode\u304c\u7d42\u4e86\u3059\u308c\u3070TRUE\u3092\u8fd4\u3059\u3002\u3088\u3063\u3066\u3001\u3053\u306eif\u6587\u306fepisode\u304c\u7d42\u4e86\u3057\u305f\u6642\u306b\u300c\u301ctimesteps\u3067\u7d42\u4e86\u3057\u307e\u3057\u305f\u3088\u300d\u3068\u51fa\u529b\u3059\u308b\u3082\u306e\u3002\n\n##reward\u3082\u51fa\u529b\u3059\u308b\n\u6b21\u306breward\u304c\u3069\u3093\u306a\u5024\u306a\u306e\u304b\u3001\u51fa\u529b\u3057\u3066\u78ba\u304b\u3081\u3066\u307f\u308b\u3002test06.py\u306e\uff19\u884c\u76ee\u3068\uff11\uff10\u884c\u76ee\u306e\u9593\u306b\u4ee5\u4e0b\u3092\u8ffd\u52a0\u3059\u308b\u3002\n\n```py\nprint(\"reward is \"),\nprint(reward)\n```\n\n\u51fa\u529b\u306f\u3053\u3093\u306a\u611f\u3058\u3002\n\n```\n[ 0.01509218 -0.01367975 -0.00316408  0.01795877]\nreward is  1.0\n[ 0.01481859 -0.20875618 -0.00280491  0.30964172]\nreward is  1.0\n[ 0.01064347 -0.40383806  0.00338793  0.60143874]\nreward is  1.0\n[ 0.0025667  -0.20876366  0.0154167   0.30982487]\nreward is  1.0\n[-0.00160857 -0.01386472  0.0216132   0.02204353]\nreward is  1.0\n```\n\n\u5831\u916c\u306f\u305a\u3063\u30681.0\u3068\u306a\u3063\u3066\u3044\u308b\u3002\u57fa\u6e96\u304c\u3088\u304f\u308f\u304b\u3089\u3093\u304c\u3001pole\u304c\u5012\u308c\u306a\u304b\u3063\u305f\u3089\u6bce\u6642\u523b1.0\u3082\u3089\u3048\u308b\u306e\u3060\u308d\u3046\u304b\uff1f\n\n##observation\u306b\u3082\u3068\u3065\u3044\u3066action\u3092\u64cd\u4f5c\u3059\u308b\n\u5b9f\u88c5\u306e\u4e2d\u5fc3\u306f\u3001\u6211\u3005\u304c\u53d7\u3051\u53d6\u3063\u305fobservation\u306b\u5bfe\u3057\u3066\u3069\u306e\u3088\u3046\u306aaction\u3092\u8fd4\u3059\u304b\u3001\u3068\u3044\u3046\u90e8\u5206\u3060\u308d\u3046\u3002\u3057\u304b\u3057test06.py\u306e\u30b3\u30fc\u30c9\u3067\u306f\u3001\uff19\u884c\u76ee\u3067observation\u3092\u53d7\u3051\u53d6\u3063\u3066\u3044\u308b\u306b\u3082\u95a2\u308f\u3089\u305a\u3001\u305d\u308c\u3068\u306f\u95a2\u4fc2\u306a\u304f\uff18\u884c\u76ee\u3067\u30e9\u30f3\u30c0\u30e0\u306aaction\u3092\u6e21\u3057\u3066\u3044\u308b\u3002\u3053\u308c\u306f\u9762\u767d\u304f\u306a\u3044\u3002\n\n\u305d\u3053\u3067\u3001\u4ee5\u4e0b\u306e\u3088\u3046\u306bobsevation\u306e\u5024\u3092\u51e6\u7406\u3057\u3001\u305d\u308c\u3092action\u306b\u53cd\u6620\u3055\u305b\u3066\u307f\u308b\u3002\n\n```py\nimport gym\nenv = gym.make('CartPole-v0')\ntotal_reward_sum = [0] * 20\nfor i_episode in range(20):\n    observation = env.reset()\n    total_reward = 0\n    for t in range(100):\n        env.render()\n        print(observation)\n        #action = env.action_space.sample()\n        sum_obs = observation[0] + observation[1] + observation[2] + observation[3]\n        if sum_obs > 0:\n            action = 1\n        else:\n            action = 0\n        observation, reward, done, info = env.step(action)\n        total_reward += 1\n        if done:\n            print(\"Episode finished after {} timesteps\".format(t+1))\n            print(\"total reward is\"),\n            print(total_reward)\n            total_reward_sum[i_episode] = total_reward\n            if i_episode == 19:\n                print(\"all total reward is\"),\n                print(total_reward_sum)\n            break\n        if t == 99:\n            print(\"Episode finished after {} timesteps\".format(t+1))\n            print(\"total reward is\"),\n            print(total_reward)\n            total_reward_sum[i_episode] = total_reward\n            if i_episode == 19:\n                print(\"all total reward is\"),\n                print(total_reward_sum)\n```\n\n\u30c8\u30fc\u30bf\u30eb\u306a\u5831\u916c\u306e\u51fa\u529b\u3092episode\u7d42\u4e86\u6642\u306e\u307f\u3067\u306a\u304f\u3001max\u306e\uff11\uff10\uff10timestep\u7d42\u4e86\u6642\u306b\u3082\u8a2d\u5b9a\u3057\u305f\u306e\u306f\u3001\u3053\u306e\u30a2\u30eb\u30b4\u30ea\u30ba\u30e0\u304c\u826f\u3059\u304e\u3066\u3001\u68d2\u304c\u5012\u308c\u308b\u3053\u3068\u7121\u304f\u6bce\u56de\u307b\u307cmax\u307e\u3067\u9054\u3059\u308b\u305f\u3081\u3002\u5b9f\u969b\u3001episode\uff12\uff10\u56de\u5206\u306e\u30c8\u30fc\u30bf\u30eb\u5831\u916c\u306f\u4ee5\u4e0b\u306e\u3088\u3046\u306b\u306a\u3063\u305f\u3002\n\n```\nall total reward is [100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 97, 100, 100, 100, 100, 100, 100, 74, 100]\n```\n\n\u4f55\u3082\u8003\u3048\u305a\u306b\u4f5c\u3063\u305f\u306e\u306b\u3001\u7d20\u6674\u3089\u3057\u3044\u306d\uff01\u3061\u306a\u307f\u306baction\u3092\u53f3\u3068\u5de6\u5165\u308c\u66ff\u3048\u305f\u7d50\u679c\u304c\u4ee5\u4e0b\u3002\n\n```\nall total reward is [8, 9, 9, 9, 10, 9, 9, 10, 9, 9, 10, 9, 9, 9, 8, 10, 10, 9, 9, 9]\n```\n\n\u3081\u3063\u3061\u3083\u65e9\u304f\u5012\u308c\u3066\u3044\u308b\u3002\u3068\u3044\u3046\u304b\u5012\u308c\u308b\u306e\u3092\u52a9\u9577\u3055\u305b\u3066\u308b\u306d\u3002\n", "tags": ["ATARI", "Ubuntu14.04", "OpenAI", "DeepLearning", "DQN"]}