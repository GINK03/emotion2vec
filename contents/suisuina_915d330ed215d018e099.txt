{"tags": ["deepdream", "DeepLearning", "python2.7", "Caffe"], "context": " More than 1 year has passed since last update.deepdream\u3092\u52d5\u304b\u3059\u3068\u3053\u308d\u307e\u3067\u3092\u8a18\u8f09\u3057\u307e\u3059\n\nCUDA7.0\u30a4\u30f3\u30b9\u30c8\u30fc\u30eb\nhttps://developer.nvidia.com/\n\nopen cv\u306a\u3069\u3092\u30a4\u30f3\u30b9\u30c8\u30fc\u30eb\n$ brew install --fresh -vd snappy leveldb gflags glog szip lmdb\n$ brew tap homebrew/science\n$ brew install hdf5 opencv\n$ brew install --build-from-source --with-python --fresh -vd protobuf\n$ brew install --build-from-source --fresh -vd boost boost-python\n$ brew install openblas\n\n\npython\u306e\u30a4\u30f3\u30b9\u30c8\u30fc\u30eb\n\u4eca\u56de\u306fpyenv\u306banaconda\u3092\u5165\u308c\u307e\u3059\n\uff08anaconda\u3092\u63a8\u5968\u3057\u3066\u3044\u308b\u307f\u305f\u3044\uff09\n$ brew install pyenv\n$ pyenv install anaconda-2.1.0\n$ pyenv local anaconda-2.1.0\n$ pyenv global anaconda-2.1.0\n\n\ncaffe\u3092\u30af\u30ed\u30fc\u30f3\n$ cd ~/\n$ git clone https://github.com/BVLC/caffe.git\n\n\nMakefile.config\u306e\u30b3\u30d4\u30fc\n$ cd caffe\n$ pip install -r python/requirements.txt\n$ cp Makefile.config.example Makefile.config\n\n\nMakefile.config\u306e\u7de8\u96c6\n\u4ee5\u4e0b\u306e\u5909\u6570\u306e\u30b3\u30e1\u30f3\u30c8\u30a2\u30a6\u30c8\u3092\u5916\u3057\u3066\u4fee\u6b63\u3057\u3066\u304f\u3060\u3055\u3044\n\u5404\u30d1\u30b9\u306f\u74b0\u5883\u306b\u5408\u308f\u305b\u3066\u66f8\u304d\u63db\u3048\u3066\u304f\u3060\u3055\u3044\n\nMakefile.config\nBLAS := open\nBLAS_INCLUDE := /usr/local/Cellar/openblas/0.2.15/include\nBLAS_LIB := /usr/local/Cellar/openblas/0.2.15/lib\n\nANACONDA_HOME := /Users/username/.pyenv/versions/anaconda-2.1.0\nPYTHON_INCLUDE := $(ANACONDA_HOME)/include \\\n                 $(ANACONDA_HOME)/include/python2.7 \\\n                 $(ANACONDA_HOME)/lib/python2.7/site-packages/numpy/core/include \\\n\n\n# We need to be able to find libpythonX.X.so or .dylib.\nPYTHON_LIB := $(ANACONDA_HOME)/lib\n\n\n\n\n\u30e2\u30c7\u30eb\u306e\u30c0\u30a6\u30f3\u30ed\u30fc\u30c9\n\u4ee5\u4e0b\u306e\u30ea\u30f3\u30af\u304b\u3089\u30c0\u30a6\u30f3\u30ed\u30fc\u30c9\u3057\u3066\u3001~/caffe/models/bvlc_googlenet/ \u306b\u4fdd\u5b58\nbvlc_googlenet.caffemodel\n\n.bashrc\u306b\u30d1\u30b9\u3092\u8ffd\u52a0\nexport DYLD_FALLBACK_LIBRARY_PATH=/usr/local/cuda/lib:~/.pyenv/versions/anaconda-2.1.0/lib\nexport PYTHONPATH=~/caffe/python/:$PYTHONPATH\n\nsource ~/.bashrc \u3067\u53cd\u6620\n\n\u30b3\u30f3\u30d1\u30a4\u30eb\n$ make clean\n$ make all -j4\n$ make test\n$ make runtest\n$ make pycaffe\n\n\u4ee5\u4e0b\u306e\u30b3\u30de\u30f3\u30c9\u3067\u30a8\u30e9\u30fc\u304c\u51fa\u306a\u3051\u308c\u3070\u3001caffe\u306e\u30a4\u30f3\u30b9\u30c8\u30fc\u30eb\u306f\u6210\u529f\n$ python \n>>> import caffe\n\n\nipython notebook\u306e\u30a4\u30f3\u30b9\u30c8\u30fc\u30eb\n\uff08deepdream\u306e\u30bd\u30fc\u30b9\u30b3\u30fc\u30c9\u306fipython notebook\u5f62\u5f0f\u306b\u306a\u3063\u3066\u3044\u308b\uff09\n$ pip install \"ipython[notebook]\"\n\n\ndeepdream\u306e\u30af\u30ed\u30fc\u30f3\n$ git clone git@github.com:google/deepdream.git\n\n\nipython notebook\u3092\u5b9f\u884c\n$ cd deepdream\n$ ipython trust dream.ipynb\n$ ipython notebook\n\n\u3046\u307e\u304f\u3044\u304f\u3068\u3001\u30d6\u30e9\u30a6\u30b6\u4e0a\u3067notebook\u304c\u305f\u3061\u3042\u304c\u308b\u306e\u3067\u3001dream.ipynb\u3092\u9078\u629e\u3057\u3066\u7acb\u3061\u4e0a\u304c\u3063\u305f\u753b\u9762\u304b\u3089\u518d\u751f\u30dc\u30bf\u30f3\u3092\u62bc\u3057\u3066\u3001\u30bd\u30fc\u30b9\u30b3\u30fc\u30c9\u3054\u3068\u306b\u6319\u52d5\u3092\u78ba\u8a8d\u3067\u304d\u307e\u3059\u3002\n\u9032\u3081\u3066\u3044\u304f\u3068\u3001frames/\u914d\u4e0b\u306b\u751f\u6210\u3055\u308c\u305f\u753b\u50cf\u304c\u4fdd\u5b58\u3055\u308c\u307e\u3059\u3002\n\u306a\u304a\u3001python\u3067\u5b9f\u884c\u3059\u308b\u5834\u5408\u306f\u4ee5\u4e0b\u306e\u30bd\u30fc\u30b9\u3067\u5b9f\u884c\u3067\u304d\u307e\u3059\nfrom cStringIO import StringIO\nimport numpy as np\nimport scipy.ndimage as nd\nimport PIL.Image\nfrom IPython.display import clear_output, Image, display\nfrom google.protobuf import text_format\n\nimport caffe\n\ndef showarray(a, fmt='jpeg'):\n    a = np.uint8(np.clip(a, 0, 255))\n    f = StringIO()\n    PIL.Image.fromarray(a).save(f, fmt)\n    display(Image(data=f.getvalue()))\n\nmodel_path = '../caffe/models/bvlc_googlenet/' # substitute your path here\nnet_fn   = model_path + 'deploy.prototxt'\nparam_fn = model_path + 'bvlc_googlenet.caffemodel'\n\n\n# Patching model to be able to compute gradients.\n# Note that you can also manually add \"force_backward: true\" line to \"deploy.prototxt\".\nmodel = caffe.io.caffe_pb2.NetParameter()\ntext_format.Merge(open(net_fn).read(), model)\nmodel.force_backward = True\nopen('tmp.prototxt', 'w').write(str(model))\n\nnet = caffe.Classifier('tmp.prototxt', param_fn,\n                       mean = np.float32([104.0, 116.0, 122.0]), # ImageNet mean, training set dependent\n                       channel_swap = (2,1,0)) # the reference model has channels in BGR order instead of RGB\n\n\n\n# a couple of utility functions for converting to and from Caffe's input image layout\ndef preprocess(net, img):\n    return np.float32(np.rollaxis(img, 2)[::-1]) - net.transformer.mean['data']\ndef deprocess(net, img):\n    return np.dstack((img + net.transformer.mean['data'])[::-1])\n\ndef objective_L2(dst):\n    dst.diff[:] = dst.data\n\ndef make_step(net, step_size=1.5, end='inception_4c/output',\n              jitter=32, clip=True, objective=objective_L2):\n    '''Basic gradient ascent step.'''\n\n    src = net.blobs['data'] # input image is stored in Net's 'data' blob\n    dst = net.blobs[end]\n\n    ox, oy = np.random.randint(-jitter, jitter+1, 2)\n    src.data[0] = np.roll(np.roll(src.data[0], ox, -1), oy, -2) # apply jitter shift\n\n    net.forward(end=end)\n    objective(dst)  # specify the optimization objective\n    net.backward(start=end)\n    g = src.diff[0]\n    # apply normalized ascent step to the input image\n    src.data[:] += step_size/np.abs(g).mean() * g\n\n    src.data[0] = np.roll(np.roll(src.data[0], -ox, -1), -oy, -2) # unshift image\n\n    if clip:\n        bias = net.transformer.mean['data']\n        src.data[:] = np.clip(src.data, -bias, 255-bias)\n\n\ndef deepdream(net, base_img, iter_n=10, octave_n=4, octave_scale=1.4,\n              end='inception_4c/output', clip=True, **step_params):\n    # prepare base images for all octaves\n    octaves = [preprocess(net, base_img)]\n    for i in xrange(octave_n-1):\n        octaves.append(nd.zoom(octaves[-1], (1, 1.0/octave_scale,1.0/octave_scale), order=1))\n\n    src = net.blobs['data']\n    detail = np.zeros_like(octaves[-1]) # allocate image for network-produced details\n    for octave, octave_base in enumerate(octaves[::-1]):\n        h, w = octave_base.shape[-2:]\n        if octave > 0:\n            # upscale details from the previous octave\n            h1, w1 = detail.shape[-2:]\n            detail = nd.zoom(detail, (1, 1.0*h/h1,1.0*w/w1), order=1)\n\n        src.reshape(1,3,h,w) # resize the network's input image size\n        src.data[0] = octave_base+detail\n        for i in xrange(iter_n):\n            make_step(net, end=end, clip=clip, **step_params)\n\n            # visualization\n            vis = deprocess(net, src.data[0])\n            if not clip: # adjust image contrast if clipping is disabled\n                vis = vis*(255.0/np.percentile(vis, 99.98))\n            showarray(vis)\n            print octave, i, end, vis.shape\n            clear_output(wait=True)\n\n        # extract details produced on the current octave\n        detail = src.data[0]-octave_base\n        # returning the resulting image\n    return deprocess(net, src.data[0])\n\nimg = np.float32(PIL.Image.open('sky1024px.jpg'))\nfor i in xrange(100):\n    img = deepdream(net, img, end='inception_4e/pool') PIL.Image.fromarray(np.uint8(img)).save(\"frames/result-%03d.png\" % i)\n\n\u3046\u307e\u304f\u3044\u304f\u3068\u3053\u3093\u306a\u611f\u3058\n\n\n\nfinetune_flickr_style\u3092\u4f7f\u3046\u3068\u3001floating point exception\u3067\u30a8\u30e9\u30fc\u306b\u306a\u308b\u306e\u3067\u8981\u8abf\u67fb\ndeepdream\u3092\u52d5\u304b\u3059\u3068\u3053\u308d\u307e\u3067\u3092\u8a18\u8f09\u3057\u307e\u3059\n\n## CUDA7.0\u30a4\u30f3\u30b9\u30c8\u30fc\u30eb\nhttps://developer.nvidia.com/\n\n\n## open cv\u306a\u3069\u3092\u30a4\u30f3\u30b9\u30c8\u30fc\u30eb\n\n```\n$ brew install --fresh -vd snappy leveldb gflags glog szip lmdb\n$ brew tap homebrew/science\n$ brew install hdf5 opencv\n$ brew install --build-from-source --with-python --fresh -vd protobuf\n$ brew install --build-from-source --fresh -vd boost boost-python\n$ brew install openblas\n```\n\n## python\u306e\u30a4\u30f3\u30b9\u30c8\u30fc\u30eb\n\u4eca\u56de\u306fpyenv\u306banaconda\u3092\u5165\u308c\u307e\u3059\n\uff08anaconda\u3092\u63a8\u5968\u3057\u3066\u3044\u308b\u307f\u305f\u3044\uff09\n\n```\n$ brew install pyenv\n$ pyenv install anaconda-2.1.0\n$ pyenv local anaconda-2.1.0\n$ pyenv global anaconda-2.1.0\n```\n\n## caffe\u3092\u30af\u30ed\u30fc\u30f3\n\n```\n$ cd ~/\n$ git clone https://github.com/BVLC/caffe.git\n```\n\n\n## Makefile.config\u306e\u30b3\u30d4\u30fc\n\n```\n$ cd caffe\n$ pip install -r python/requirements.txt\n$ cp Makefile.config.example Makefile.config\n```\n\n## Makefile.config\u306e\u7de8\u96c6\n\u4ee5\u4e0b\u306e\u5909\u6570\u306e\u30b3\u30e1\u30f3\u30c8\u30a2\u30a6\u30c8\u3092\u5916\u3057\u3066\u4fee\u6b63\u3057\u3066\u304f\u3060\u3055\u3044\n\u5404\u30d1\u30b9\u306f\u74b0\u5883\u306b\u5408\u308f\u305b\u3066\u66f8\u304d\u63db\u3048\u3066\u304f\u3060\u3055\u3044\n\n```Makefile.config\nBLAS := open\nBLAS_INCLUDE := /usr/local/Cellar/openblas/0.2.15/include\nBLAS_LIB := /usr/local/Cellar/openblas/0.2.15/lib\n\nANACONDA_HOME := /Users/username/.pyenv/versions/anaconda-2.1.0\nPYTHON_INCLUDE := $(ANACONDA_HOME)/include \\\n                 $(ANACONDA_HOME)/include/python2.7 \\\n                 $(ANACONDA_HOME)/lib/python2.7/site-packages/numpy/core/include \\\n\n\n# We need to be able to find libpythonX.X.so or .dylib.\nPYTHON_LIB := $(ANACONDA_HOME)/lib\n\n```\n\n## \u30e2\u30c7\u30eb\u306e\u30c0\u30a6\u30f3\u30ed\u30fc\u30c9\n\u4ee5\u4e0b\u306e\u30ea\u30f3\u30af\u304b\u3089\u30c0\u30a6\u30f3\u30ed\u30fc\u30c9\u3057\u3066\u3001~/caffe/models/bvlc_googlenet/ \u306b\u4fdd\u5b58\n<a href=\"http://dl.caffe.berkeleyvision.org/bvlc_googlenet.caffemodel\">bvlc_googlenet.caffemodel</a>\n\n\n## .bashrc\u306b\u30d1\u30b9\u3092\u8ffd\u52a0\n\n```\nexport DYLD_FALLBACK_LIBRARY_PATH=/usr/local/cuda/lib:~/.pyenv/versions/anaconda-2.1.0/lib\nexport PYTHONPATH=~/caffe/python/:$PYTHONPATH\n```\nsource ~/.bashrc \u3067\u53cd\u6620\n\n\n## \u30b3\u30f3\u30d1\u30a4\u30eb\n\n```\n$ make clean\n$ make all -j4\n$ make test\n$ make runtest\n$ make pycaffe\n```\n\n\u4ee5\u4e0b\u306e\u30b3\u30de\u30f3\u30c9\u3067\u30a8\u30e9\u30fc\u304c\u51fa\u306a\u3051\u308c\u3070\u3001caffe\u306e\u30a4\u30f3\u30b9\u30c8\u30fc\u30eb\u306f\u6210\u529f\n\n```\n$ python \n>>> import caffe\n```\n\n## ipython notebook\u306e\u30a4\u30f3\u30b9\u30c8\u30fc\u30eb\n\uff08deepdream\u306e\u30bd\u30fc\u30b9\u30b3\u30fc\u30c9\u306fipython notebook\u5f62\u5f0f\u306b\u306a\u3063\u3066\u3044\u308b\uff09\n\n```\n$ pip install \"ipython[notebook]\"\n```\n\n\n## deepdream\u306e\u30af\u30ed\u30fc\u30f3\n\n```\n$ git clone git@github.com:google/deepdream.git\n```\n\n## ipython notebook\u3092\u5b9f\u884c\n\n```\n$ cd deepdream\n$ ipython trust dream.ipynb\n$ ipython notebook\n```\n\n\u3046\u307e\u304f\u3044\u304f\u3068\u3001\u30d6\u30e9\u30a6\u30b6\u4e0a\u3067notebook\u304c\u305f\u3061\u3042\u304c\u308b\u306e\u3067\u3001dream.ipynb\u3092\u9078\u629e\u3057\u3066\u7acb\u3061\u4e0a\u304c\u3063\u305f\u753b\u9762\u304b\u3089\u518d\u751f\u30dc\u30bf\u30f3\u3092\u62bc\u3057\u3066\u3001\u30bd\u30fc\u30b9\u30b3\u30fc\u30c9\u3054\u3068\u306b\u6319\u52d5\u3092\u78ba\u8a8d\u3067\u304d\u307e\u3059\u3002\n\u9032\u3081\u3066\u3044\u304f\u3068\u3001frames/\u914d\u4e0b\u306b\u751f\u6210\u3055\u308c\u305f\u753b\u50cf\u304c\u4fdd\u5b58\u3055\u308c\u307e\u3059\u3002\n\n\n\u306a\u304a\u3001python\u3067\u5b9f\u884c\u3059\u308b\u5834\u5408\u306f\u4ee5\u4e0b\u306e\u30bd\u30fc\u30b9\u3067\u5b9f\u884c\u3067\u304d\u307e\u3059\n\n```\nfrom cStringIO import StringIO\nimport numpy as np\nimport scipy.ndimage as nd\nimport PIL.Image\nfrom IPython.display import clear_output, Image, display\nfrom google.protobuf import text_format\n\nimport caffe\n\ndef showarray(a, fmt='jpeg'):\n    a = np.uint8(np.clip(a, 0, 255))\n    f = StringIO()\n    PIL.Image.fromarray(a).save(f, fmt)\n    display(Image(data=f.getvalue()))\n\nmodel_path = '../caffe/models/bvlc_googlenet/' # substitute your path here\nnet_fn   = model_path + 'deploy.prototxt'\nparam_fn = model_path + 'bvlc_googlenet.caffemodel'\n\n\n# Patching model to be able to compute gradients.\n# Note that you can also manually add \"force_backward: true\" line to \"deploy.prototxt\".\nmodel = caffe.io.caffe_pb2.NetParameter()\ntext_format.Merge(open(net_fn).read(), model)\nmodel.force_backward = True\nopen('tmp.prototxt', 'w').write(str(model))\n\nnet = caffe.Classifier('tmp.prototxt', param_fn,\n                       mean = np.float32([104.0, 116.0, 122.0]), # ImageNet mean, training set dependent\n                       channel_swap = (2,1,0)) # the reference model has channels in BGR order instead of RGB\n\n\n\n# a couple of utility functions for converting to and from Caffe's input image layout\ndef preprocess(net, img):\n    return np.float32(np.rollaxis(img, 2)[::-1]) - net.transformer.mean['data']\ndef deprocess(net, img):\n    return np.dstack((img + net.transformer.mean['data'])[::-1])\n\ndef objective_L2(dst):\n    dst.diff[:] = dst.data\n\ndef make_step(net, step_size=1.5, end='inception_4c/output',\n              jitter=32, clip=True, objective=objective_L2):\n    '''Basic gradient ascent step.'''\n\n    src = net.blobs['data'] # input image is stored in Net's 'data' blob\n    dst = net.blobs[end]\n\n    ox, oy = np.random.randint(-jitter, jitter+1, 2)\n    src.data[0] = np.roll(np.roll(src.data[0], ox, -1), oy, -2) # apply jitter shift\n\n    net.forward(end=end)\n    objective(dst)  # specify the optimization objective\n    net.backward(start=end)\n    g = src.diff[0]\n    # apply normalized ascent step to the input image\n    src.data[:] += step_size/np.abs(g).mean() * g\n\n    src.data[0] = np.roll(np.roll(src.data[0], -ox, -1), -oy, -2) # unshift image\n\n    if clip:\n        bias = net.transformer.mean['data']\n        src.data[:] = np.clip(src.data, -bias, 255-bias)\n\n\ndef deepdream(net, base_img, iter_n=10, octave_n=4, octave_scale=1.4,\n              end='inception_4c/output', clip=True, **step_params):\n    # prepare base images for all octaves\n    octaves = [preprocess(net, base_img)]\n    for i in xrange(octave_n-1):\n        octaves.append(nd.zoom(octaves[-1], (1, 1.0/octave_scale,1.0/octave_scale), order=1))\n\n    src = net.blobs['data']\n    detail = np.zeros_like(octaves[-1]) # allocate image for network-produced details\n    for octave, octave_base in enumerate(octaves[::-1]):\n        h, w = octave_base.shape[-2:]\n        if octave > 0:\n            # upscale details from the previous octave\n            h1, w1 = detail.shape[-2:]\n            detail = nd.zoom(detail, (1, 1.0*h/h1,1.0*w/w1), order=1)\n\n        src.reshape(1,3,h,w) # resize the network's input image size\n        src.data[0] = octave_base+detail\n        for i in xrange(iter_n):\n            make_step(net, end=end, clip=clip, **step_params)\n\n            # visualization\n            vis = deprocess(net, src.data[0])\n            if not clip: # adjust image contrast if clipping is disabled\n                vis = vis*(255.0/np.percentile(vis, 99.98))\n            showarray(vis)\n            print octave, i, end, vis.shape\n            clear_output(wait=True)\n\n        # extract details produced on the current octave\n        detail = src.data[0]-octave_base\n        # returning the resulting image\n    return deprocess(net, src.data[0])\n\nimg = np.float32(PIL.Image.open('sky1024px.jpg'))\nfor i in xrange(100):\n    img = deepdream(net, img, end='inception_4e/pool') PIL.Image.fromarray(np.uint8(img)).save(\"frames/result-%03d.png\" % i)\n```\n\n\u3046\u307e\u304f\u3044\u304f\u3068\u3053\u3093\u306a\u611f\u3058\n![result-000.png](https://qiita-image-store.s3.amazonaws.com/0/66003/dfe8984d-b8b1-984a-0bda-1f4180e14bf3.png)\n![result-007.png](https://qiita-image-store.s3.amazonaws.com/0/66003/f1dae763-5325-ea18-d541-88c05ff38b61.png)\n![result-060.png](https://qiita-image-store.s3.amazonaws.com/0/66003/e43596ba-b75b-c751-41fe-5ff88cb98001.png)\n\nfinetune_flickr_style\u3092\u4f7f\u3046\u3068\u3001floating point exception\u3067\u30a8\u30e9\u30fc\u306b\u306a\u308b\u306e\u3067\u8981\u8abf\u67fb\n"}