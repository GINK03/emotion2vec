{"context": "\n\n\u306f\u3058\u3081\u306b\n\u4eca\u5f8c\u8af8\u3005\u306e\u30e2\u30c7\u30eb\u3092Fine-tuning\u3059\u308b\u3053\u3068\u3092\u8003\u3048\u3066\u3001chainer\u3067\u3082\u305d\u306e\u6280\u8853\u3092\u8eab\u306b\u4ed8\u3051\u305f\u3044\u3002\n\u4eca\u56de\u306fcaffe model\u3092\u8aad\u307f\u8fbc\u3093\u3067\u63a8\u8ad6\u3060\u3051\u3059\u308b\u3002\n\u53c2\u8003\u306b\u3057\u305f\u30b5\u30a4\u30c8\u306f\u3053\u3061\u3089\nhttp://qiita.com/dsanno/items/2c9ccfc53b5019475e0e\n\u306a\u3069\n\n\u74b0\u5883\nOS:Ubuntu14.04\nGPU:GTX1070\nCUDA:8.0 RC\ncuDNN:5.1\npython2.7.6\n\u306a\u3069\n\ncaffemodel\u3092\u30c0\u30a6\u30f3\u30ed\u30fc\u30c9\u3059\u308b\n\u4eca\u56de\u4f7f\u7528\u3059\u308b\u30e2\u30c7\u30eb\u306fGoogLeNet\u3002\u3053\u3061\u3089\u304b\u3089\nhttp://dl.caffe.berkeleyvision.org/bvlc_googlenet.caffemodel\n\u30c0\u30a6\u30f3\u30ed\u30fc\u30c9\u3059\u308b\u3002\n\n\u753b\u50cf\u3092numpy\u914d\u5217\u3078\u6574\u5f62\u3059\u308b\n\u753b\u50cf\u3092\u5165\u529b\u306b\u9069\u3057\u305fnumpy\u914d\u5217\u3078\u6574\u5f62\u3059\u308b\u3002PIL\u3092\u4f7f\u3046\u306e\u3067\u3001\u4e8b\u524d\u306bPillow\u306e\u30a4\u30f3\u30b9\u30c8\u30fc\u30eb\u304c\u5fc5\u8981\u3067\u3042\u308b\u3002\n\u307e\u305a\u753b\u50cf\u306e\u7e26\u6a2a\u306e\u3046\u3061\u5c0f\u3055\u3044\u65b9\u304c224\u3068\u306a\u308b\u3088\u3046\u306b\u7e2e\u5c0f\u3059\u308b\u3002\u6b21\u306b\u5927\u304d\u3044\u65b9\u3092\u5207\u308a\u53d6\u3063\u3066(224*224)\u3068\u3059\u308b\u3002\u3053\u308c\u3092float32\u306enumpy\u914d\u5217\u306b\u3059\u308b\u3002\n\nval_GoogLeNet.py\n# -*- coding: utf-8 -*-\nfrom chainer.functions import caffe\nfrom PIL import Image\nimport numpy as np\n\nimage = Image.open('sample01.jpg').convert('RGB')\nw_in, h_in = 224, 224 # GoogLeNet in_size\nw_img, h_img = image.size # get the size of image\n\n# reduce the size of image\nif w_img > h_img:\n    shape = (w_in * w_img / h_img, h_in)\nelse:\n    shape = (w_in, h_in * h_img / w_img)\nmod_img = image.resize(shape)\n\n# cut both ends\n\nx_space = (shape[0] - w_img) / 2\ny_space = (shape[1] - h_img) / 2\nin_img = mod_img.crop((x_space, y_space, x_space + w_img, y_space + h_img))\npixels = np.asarray(in_img).astype(np.float32)\n\n\n\u6b21\u306bnumpy\u914d\u5217\u3092\u5165\u529b\u306b\u9069\u3057\u305f\u5f62\u306b\u6574\u3048\u308b\u3002\u753b\u50cf\u304b\u3089numpy\u3092\u4f5c\u6210\u3057\u305f\u6642\u70b9\u3067\u306f(y, x, RGB)\u3068\u306a\u3063\u3066\u3044\u308b\u3002\u3053\u308c\u3092(index, BGR, y ,x)\u3068\u3059\u308b\u3002\n\nval_GoogLeNet.py\n#change RGB to BGR\npixels = pixels[:,:,::-1]\n\n#change axis\npixels = pixels.transpose(2, 0, 1)\n\n\n\u6b21\u306b\u5e73\u5747\u753b\u50cf\u3092\u5f15\u3044\u305f\u5f8c\u3001\uff14\u6b21\u5143\u306b\u3059\u308b\n\nval_GoogLeNet.py\n#subtract mean image\nmean_img = np.ndarray((3, 224, 224), dtype=np.float32)\nmean_img[0] = 103.939\nmean_img[1] = 116.779\nmean_img[2] = 123.68\npixels -= self.mean_img\n\n#change to 4 dim\npixels = pixels.reshape(1, 3, 224, 224)\n\n\n\nmodel\u306e\u5f62\u3092\u78ba\u8a8d\u3059\u308b\ncaffemodel\u3092\u8aad\u307f\u8fbc\u3080\u524d\u306b\u3001\u5fc5\u8981\u306a\u60c5\u5831\u3092\u78ba\u8a8d\u3059\u308b\u3002\n\u4ee5\u4e0b\u306e\u30b5\u30a4\u30c8\u306b\u3042\u308b\u30b3\u30fc\u30c9\u304b\u3089model\u306e\u5f62\u3092\u78ba\u8a8d\u3059\u308b\u3002\nhttps://github.com/BVLC/caffe/blob/master/models/bvlc_googlenet/train_val.prototxt\n\ntrain_val.prototxt\nname: \"GoogleNet\"\nlayer {\n  name: \"data\"\n  type: \"Data\"\n  top: \"data\"\n  top: \"label\"\n  include {\n    phase: TRAIN\n}\n\n.......\n.......\n.......\n\nlayer {\n  name: \"loss3/top-5\"\n  type: \"Accuracy\"\n  bottom: \"loss3/classifier\"\n  bottom: \"label\"\n  top: \"loss3/top-5\"\n  include {\n    phase: TEST\n  }\n  accuracy_param {\n    top_k: 5\n  }\n}\n\n\n\u5165\u529b\u5c64\u306etop\u304c\"data\"\u3067\u3042\u308a\u3001\u51fa\u529b\u5c64\u306ebottom\u304c\"loss3/classifier\"\u3067\u3042\u308b\u3053\u3068\u3092\u78ba\u8a8d\u3002\n\ncaffemodel\u3092\u8aad\u307f\u8fbc\u3080\nchainer\u306e\u6a5f\u80fd\u3092\u4f7f\u3063\u3066caffemodel\u3092\u8aad\u307f\u8fbc\u3080\u3002\u3053\u308c\u306bnumpy\u914d\u5217\u3092\u5165\u529b\u3059\u308b\u3002\n\nval_GoogLeNet.py\nimport chainer\nimport chainer.functions as F\n\n#read caffemodel\nfunc = caffe.CaffeFunction('bvlc_googlenet.caffemodel')\n\n#define input and output\nx = chainer.Variable(pixels, volatile=True)\ny, = func(inputs={'data': x}, outputs=['loss3/classifier'],\n        disable=['loss1/ave_pool', 'loss2/ave_pool'], train = False)\nprediction = F.softmax(y)\n\n\n`prediction[0]'\u304c\u51fa\u529b\u7d50\u679c\u3060\u304c\u3001\u6570\u5024\u3054\u3068\u306e\u78ba\u7387\u3068\u3057\u3066\u8868\u793a\u3055\u308c\u3066\u3044\u308b\u3002\u3053\u306e\u6570\u5024\u3068\u30e9\u30d9\u30eb\u3092\u5bfe\u5fdc\u3055\u305b\u308b\u30e9\u30d9\u30eb\u5bfe\u5fdc\u8868\u3092\u30c0\u30a6\u30f3\u30ed\u30fc\u30c9\u3059\u308b\u3002\nwget http://dl.caffe.berkeleyvision.org/caffe_ilsvrc12.tar.gz\ntar xfvz caffe_ilsvrc12.tar.gz\nawk '{$1=\"\";print}' synset_words.txt > labels.txt\n\n\u3053\u306e\u8868\u306e\uff11\u5217\u76ee\u3092\u6368\u3066\u3001\uff12\u5217\u76ee\u306e\u30e9\u30d9\u30eb\u306e\u307f\u3068\u3057\u3001label.txt\u3078\u4fdd\u5b58\u3059\u308b\u3002\nawk '{$1=\"\";print}' synset_words.txt > labels.txt\n\n\n\u7d50\u679c\u3092\u51fa\u529b\u3059\u308b\n\u307e\u305a\u30e9\u30d9\u30eb\u3092\u8aad\u307f\u8fbc\u3080\u3002\u305d\u306e\u4e0a\u3067\u30b9\u30b3\u30a2\u3068\u30e9\u30d9\u30eb\u3092\u7d10\u3065\u3051\u3001\u30b9\u30b3\u30a2\u306e\u9ad8\u3044\u9806\u306b\u3059\u308b\u3002\n\nval_GoogLeNet.py\n#load labels\ncategories = np.loadtxt('labels.txt', str, delimiter=\"\\n\")\nresult = zip(prediction.data.reshape((prediction.data.size,)), categories)\nresult = sorted(result, reverse=True)\n\n#print result of 1st to 5th\nfor i, (score, label) in enumerate(result[:5]):\n    print '{:>3d} {:>6.2f}% {}'.format(i + 1, score * 100, label)\n\n\n\n\u5b9f\u884c\u4f8b\n\u4ee5\u4e0b\u306e\u5199\u771f\u306f\u5927\u5bae\u99c5\u3067\u958b\u50ac\u3055\u308c\u305f\u798f\u5cf6\u770c\u306ePR\u30a4\u30d9\u30f3\u30c8\u306b\u3066\u5c55\u793a\u3055\u308c\u3066\u3044\u305f\u6050\u7adc\u3067\u3059\u3002\n\n\u3053\u308c\u306e\u5b9f\u884c\u4f8b\u306f\u4ee5\u4e0b\u3067\u3059\u3002\npython val_GoogLeNet.py\n  1  45.46%  common iguana, iguana, Iguana iguana\n  2  15.96%  triceratops\n  3   8.78%  Chesapeake Bay retriever\n  4   3.37%  tiger, Panthera tigris\n  5   3.08%  frilled lizard, Chlamydosaurus kingi\n\n\u30a4\u30b0\u30a2\u30ca\u304c45%\u3001\u30c8\u30ea\u30b1\u30e9\u30c8\u30d7\u30b9\u304c16%\u3002\u6050\u7adc\u3067\u306f\u3042\u308b\u304c\u30a4\u30b0\u30a2\u30ca\u306b\u4f3c\u305f\u5f62\u72b6\u306a\u306e\u3067\u3001\u9060\u304b\u3089\u305a\u3068\u3044\u3063\u305f\u3068\u3053\u308d\u304b\u3002\n##\u306f\u3058\u3081\u306b\n\u4eca\u5f8c\u8af8\u3005\u306e\u30e2\u30c7\u30eb\u3092Fine-tuning\u3059\u308b\u3053\u3068\u3092\u8003\u3048\u3066\u3001chainer\u3067\u3082\u305d\u306e\u6280\u8853\u3092\u8eab\u306b\u4ed8\u3051\u305f\u3044\u3002\n\u4eca\u56de\u306fcaffe model\u3092\u8aad\u307f\u8fbc\u3093\u3067\u63a8\u8ad6\u3060\u3051\u3059\u308b\u3002\n\n\u53c2\u8003\u306b\u3057\u305f\u30b5\u30a4\u30c8\u306f\u3053\u3061\u3089\nhttp://qiita.com/dsanno/items/2c9ccfc53b5019475e0e\n\u306a\u3069\n##\u74b0\u5883\nOS:Ubuntu14.04\nGPU:GTX1070\nCUDA:8.0 RC\ncuDNN:5.1\npython2.7.6\n\u306a\u3069\n##caffemodel\u3092\u30c0\u30a6\u30f3\u30ed\u30fc\u30c9\u3059\u308b\n\u4eca\u56de\u4f7f\u7528\u3059\u308b\u30e2\u30c7\u30eb\u306fGoogLeNet\u3002\u3053\u3061\u3089\u304b\u3089\nhttp://dl.caffe.berkeleyvision.org/bvlc_googlenet.caffemodel\n\u30c0\u30a6\u30f3\u30ed\u30fc\u30c9\u3059\u308b\u3002\n##\u753b\u50cf\u3092numpy\u914d\u5217\u3078\u6574\u5f62\u3059\u308b\n\u753b\u50cf\u3092\u5165\u529b\u306b\u9069\u3057\u305fnumpy\u914d\u5217\u3078\u6574\u5f62\u3059\u308b\u3002PIL\u3092\u4f7f\u3046\u306e\u3067\u3001\u4e8b\u524d\u306bPillow\u306e\u30a4\u30f3\u30b9\u30c8\u30fc\u30eb\u304c\u5fc5\u8981\u3067\u3042\u308b\u3002\n\n\u307e\u305a\u753b\u50cf\u306e\u7e26\u6a2a\u306e\u3046\u3061\u5c0f\u3055\u3044\u65b9\u304c224\u3068\u306a\u308b\u3088\u3046\u306b\u7e2e\u5c0f\u3059\u308b\u3002\u6b21\u306b\u5927\u304d\u3044\u65b9\u3092\u5207\u308a\u53d6\u3063\u3066`(224*224)`\u3068\u3059\u308b\u3002\u3053\u308c\u3092`float32`\u306enumpy\u914d\u5217\u306b\u3059\u308b\u3002\n\n```val_GoogLeNet.py\n# -*- coding: utf-8 -*-\nfrom chainer.functions import caffe\nfrom PIL import Image\nimport numpy as np\n\nimage = Image.open('sample01.jpg').convert('RGB')\nw_in, h_in = 224, 224 # GoogLeNet in_size\nw_img, h_img = image.size # get the size of image\n\n# reduce the size of image\nif w_img > h_img:\n    shape = (w_in * w_img / h_img, h_in)\nelse:\n    shape = (w_in, h_in * h_img / w_img)\nmod_img = image.resize(shape)\n\n# cut both ends\n    \nx_space = (shape[0] - w_img) / 2\ny_space = (shape[1] - h_img) / 2\nin_img = mod_img.crop((x_space, y_space, x_space + w_img, y_space + h_img))\npixels = np.asarray(in_img).astype(np.float32)\n```\n\n\u6b21\u306bnumpy\u914d\u5217\u3092\u5165\u529b\u306b\u9069\u3057\u305f\u5f62\u306b\u6574\u3048\u308b\u3002\u753b\u50cf\u304b\u3089numpy\u3092\u4f5c\u6210\u3057\u305f\u6642\u70b9\u3067\u306f(y, x, RGB)\u3068\u306a\u3063\u3066\u3044\u308b\u3002\u3053\u308c\u3092(index, BGR, y ,x)\u3068\u3059\u308b\u3002\n\n```val_GoogLeNet.py\n#change RGB to BGR\npixels = pixels[:,:,::-1]\n\n#change axis\npixels = pixels.transpose(2, 0, 1)\n```\n\n\u6b21\u306b\u5e73\u5747\u753b\u50cf\u3092\u5f15\u3044\u305f\u5f8c\u3001\uff14\u6b21\u5143\u306b\u3059\u308b\n\n```val_GoogLeNet.py\n#subtract mean image\nmean_img = np.ndarray((3, 224, 224), dtype=np.float32)\nmean_img[0] = 103.939\nmean_img[1] = 116.779\nmean_img[2] = 123.68\npixels -= self.mean_img\n\n#change to 4 dim\npixels = pixels.reshape(1, 3, 224, 224)\n```\n\n##model\u306e\u5f62\u3092\u78ba\u8a8d\u3059\u308b\ncaffemodel\u3092\u8aad\u307f\u8fbc\u3080\u524d\u306b\u3001\u5fc5\u8981\u306a\u60c5\u5831\u3092\u78ba\u8a8d\u3059\u308b\u3002\n\n\u4ee5\u4e0b\u306e\u30b5\u30a4\u30c8\u306b\u3042\u308b\u30b3\u30fc\u30c9\u304b\u3089model\u306e\u5f62\u3092\u78ba\u8a8d\u3059\u308b\u3002\nhttps://github.com/BVLC/caffe/blob/master/models/bvlc_googlenet/train_val.prototxt\n\n```train_val.prototxt\nname: \"GoogleNet\"\nlayer {\n  name: \"data\"\n  type: \"Data\"\n  top: \"data\"\n  top: \"label\"\n  include {\n    phase: TRAIN\n}\n\n.......\n.......\n.......\n\nlayer {\n  name: \"loss3/top-5\"\n  type: \"Accuracy\"\n  bottom: \"loss3/classifier\"\n  bottom: \"label\"\n  top: \"loss3/top-5\"\n  include {\n    phase: TEST\n  }\n  accuracy_param {\n    top_k: 5\n  }\n}\n```\n\n\u5165\u529b\u5c64\u306etop\u304c`\"data\"`\u3067\u3042\u308a\u3001\u51fa\u529b\u5c64\u306ebottom\u304c`\"loss3/classifier\"`\u3067\u3042\u308b\u3053\u3068\u3092\u78ba\u8a8d\u3002\n##caffemodel\u3092\u8aad\u307f\u8fbc\u3080\nchainer\u306e\u6a5f\u80fd\u3092\u4f7f\u3063\u3066caffemodel\u3092\u8aad\u307f\u8fbc\u3080\u3002\u3053\u308c\u306bnumpy\u914d\u5217\u3092\u5165\u529b\u3059\u308b\u3002\n\n```val_GoogLeNet.py\nimport chainer\nimport chainer.functions as F\n\n#read caffemodel\nfunc = caffe.CaffeFunction('bvlc_googlenet.caffemodel')\n\n#define input and output\nx = chainer.Variable(pixels, volatile=True)\ny, = func(inputs={'data': x}, outputs=['loss3/classifier'],\n        disable=['loss1/ave_pool', 'loss2/ave_pool'], train = False)\nprediction = F.softmax(y)\n```\n\n`prediction[0]'\u304c\u51fa\u529b\u7d50\u679c\u3060\u304c\u3001\u6570\u5024\u3054\u3068\u306e\u78ba\u7387\u3068\u3057\u3066\u8868\u793a\u3055\u308c\u3066\u3044\u308b\u3002\u3053\u306e\u6570\u5024\u3068\u30e9\u30d9\u30eb\u3092\u5bfe\u5fdc\u3055\u305b\u308b\u30e9\u30d9\u30eb\u5bfe\u5fdc\u8868\u3092\u30c0\u30a6\u30f3\u30ed\u30fc\u30c9\u3059\u308b\u3002\n\n```\nwget http://dl.caffe.berkeleyvision.org/caffe_ilsvrc12.tar.gz\ntar xfvz caffe_ilsvrc12.tar.gz\nawk '{$1=\"\";print}' synset_words.txt > labels.txt\n```\n\n\u3053\u306e\u8868\u306e\uff11\u5217\u76ee\u3092\u6368\u3066\u3001\uff12\u5217\u76ee\u306e\u30e9\u30d9\u30eb\u306e\u307f\u3068\u3057\u3001label.txt\u3078\u4fdd\u5b58\u3059\u308b\u3002\n\n```\nawk '{$1=\"\";print}' synset_words.txt > labels.txt\n```\n\n##\u7d50\u679c\u3092\u51fa\u529b\u3059\u308b\n\u307e\u305a\u30e9\u30d9\u30eb\u3092\u8aad\u307f\u8fbc\u3080\u3002\u305d\u306e\u4e0a\u3067\u30b9\u30b3\u30a2\u3068\u30e9\u30d9\u30eb\u3092\u7d10\u3065\u3051\u3001\u30b9\u30b3\u30a2\u306e\u9ad8\u3044\u9806\u306b\u3059\u308b\u3002\n\n```val_GoogLeNet.py\n#load labels\ncategories = np.loadtxt('labels.txt', str, delimiter=\"\\n\")\nresult = zip(prediction.data.reshape((prediction.data.size,)), categories)\nresult = sorted(result, reverse=True)\n\n#print result of 1st to 5th\nfor i, (score, label) in enumerate(result[:5]):\n    print '{:>3d} {:>6.2f}% {}'.format(i + 1, score * 100, label)\n```\n\n##\u5b9f\u884c\u4f8b\n\u4ee5\u4e0b\u306e\u5199\u771f\u306f\u5927\u5bae\u99c5\u3067\u958b\u50ac\u3055\u308c\u305f\u798f\u5cf6\u770c\u306ePR\u30a4\u30d9\u30f3\u30c8\u306b\u3066\u5c55\u793a\u3055\u308c\u3066\u3044\u305f\u6050\u7adc\u3067\u3059\u3002\n![sample01.jpg](https://qiita-image-store.s3.amazonaws.com/0/116706/508b6014-64d2-80c3-b66b-2437ca9ef91b.jpeg)\n\u3053\u308c\u306e\u5b9f\u884c\u4f8b\u306f\u4ee5\u4e0b\u3067\u3059\u3002\n\n```\npython val_GoogLeNet.py\n  1  45.46%  common iguana, iguana, Iguana iguana\n  2  15.96%  triceratops\n  3   8.78%  Chesapeake Bay retriever\n  4   3.37%  tiger, Panthera tigris\n  5   3.08%  frilled lizard, Chlamydosaurus kingi\n```\n\n\u30a4\u30b0\u30a2\u30ca\u304c45%\u3001\u30c8\u30ea\u30b1\u30e9\u30c8\u30d7\u30b9\u304c16%\u3002\u6050\u7adc\u3067\u306f\u3042\u308b\u304c\u30a4\u30b0\u30a2\u30ca\u306b\u4f3c\u305f\u5f62\u72b6\u306a\u306e\u3067\u3001\u9060\u304b\u3089\u305a\u3068\u3044\u3063\u305f\u3068\u3053\u308d\u304b\u3002\n", "tags": ["Chainer", "Caffe", "Ubuntu14.04", "python2.7"]}