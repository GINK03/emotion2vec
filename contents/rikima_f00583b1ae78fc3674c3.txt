{"context": "def deleteFile(filepath: String, uri: String = \"hdfs://localhost:9000\") {\n\n    val hadoopConf = new org.apache.hadoop.conf.Configuration()\n    val hdfs = org.apache.hadoop.fs.FileSystem.get(new java.net.URI(uri), hadoopConf)\n    try { \n        hdfs.delete(new org.apache.hadoop.fs.Path(filepath), true) \n    } catch { \n      case e : Throwable => e.printStackTrace\n    }\n}\n\n\u307f\u305f\u3044\u306a\u611f\u3058\u3067\u3001\n\ndateframe\u3092\u4f7f\u3048\u3070\u3001overwrite option\u3067save\u3067\u304d\u308b\n\nhttp://stackoverflow.com/questions/27033823/how-to-overwrite-the-output-directory-in-spark\n\n\n```\ndef deleteFile(filepath: String, uri: String = \"hdfs://localhost:9000\") {\n\n    val hadoopConf = new org.apache.hadoop.conf.Configuration()\n    val hdfs = org.apache.hadoop.fs.FileSystem.get(new java.net.URI(uri), hadoopConf)\n    try { \n        hdfs.delete(new org.apache.hadoop.fs.Path(filepath), true) \n    } catch { \n      case e : Throwable => e.printStackTrace\n    }\n}\n```\n\n\u307f\u305f\u3044\u306a\u611f\u3058\u3067\u3001\n\n- dateframe\u3092\u4f7f\u3048\u3070\u3001overwrite option\u3067save\u3067\u304d\u308b\n\n\nhttp://stackoverflow.com/questions/27033823/how-to-overwrite-the-output-directory-in-spark\n", "tags": ["Spark"]}