{"context": "\n\n\u3010\u6982\u8981\u3011\n\u3000\u3042\u308b\u30bf\u30b0\u306e\u4e2d\u3067\u30b9\u30c8\u30c3\u30af\u6570Top10\u306e\u8a18\u4e8b\u3092\u62bd\u51fa\u3057\u307e\u3059\u3002\n\n\u3010\u74b0\u5883\u3011\n\u3000windows8.1\n\u3000python3.5\n\n\u3010\u30d7\u30ed\u30b0\u30e9\u30e0\u3011\n\u3000Python\u30bf\u30b0\u306e\u30e9\u30f3\u30af\u4ed8\u3051\u3092\u884c\u3044\u307e\u3057\u305f\u3002\n\u3000\u5b9f\u884c\u65b9\u6cd5\u3000\u2192\u3000python stock_rank.py > output.html\n\nstock_rank.py\n# -*- coding: utf-8 -*-\n\nimport urllib.request\nfrom bs4 import BeautifulSoup\n\n# Contribution\u6570\u306e\u521d\u671f\u5316\ncont = []\nfor i in range(10):\n    cont.append(0)\n\n# \u30bf\u30a4\u30c8\u30eb\u306e\u521d\u671f\u5316\ntitle = []\nfor i in range(10):\n    title.append(\"\")\n\npage_num = 1\n\nwhile True:\n    try:\n        html = urllib.request.urlopen(\"https://qiita.com/tags/Python/items?page=\" + str(page_num)).read()\n\n        soup = BeautifulSoup(html, \"html.parser\")\n\n        # \u30af\u30e9\u30b9\u3092\u6307\u5b9a\u3057\u3066html\u62bd\u51fa\n        title_all = soup.find_all(class_=\"publicItem_body\")\n\n        # publicItem_body\u30af\u30e9\u30b9\u304c\u306a\u3044\u30da\u30fc\u30b8\u306f\u3068\u3070\u3059\n        if len(title_all) == 0:\n            continue\n\n        for i in range(20):\n            try:          \n                # \u30af\u30e9\u30b9\u3092\u6307\u5b9a\u3057\u3066html\u62bd\u51fa\n                cont_all = soup.find_all(class_=\"publicItem_stockCount\")\n                # \u90aa\u9b54\u306a\u30bf\u30b0\u3092\u524a\u9664\n                cont_sakujo = str(cont_all[i]).replace('<i class=\"fa fa-stock \"></i>','')\n                # cont_all_after\u306fstr\u578b\u306e\u305f\u3081string\u30d7\u30ed\u30d1\u30c6\u30a3\u306f\u4f7f\u3048\u306a\u3044\n                # \u305d\u306e\u305f\u3081BeautifulSoup\u578b\u3078\u5909\u63db\n                cont_kazu = int(BeautifulSoup(cont_sakujo, \"html.parser\").string)\n\n                for j in range(10):\n                    if cont_kazu >= cont[j]:\n                        # Contribution\u6570\u4ee3\u5165            \n                        cont.insert(j, cont_kazu)\n                        cont.pop()\n                        # \u30bf\u30a4\u30c8\u30eb\u4ee3\u5165\n                        title.insert(j, title_all[i])\n                        title.pop()\n                        break\n\n            # \u8ab0\u306b\u3082\u30b9\u30c8\u30c3\u30af\u3055\u308c\u3066\u3044\u306a\u3044\u8a18\u4e8b\u306f\u3068\u3070\u3059\n            except:\n                continue\n\n        page_num += 1\n\n    # HTTP Error 404\n    except:\n        break\n\nfor i in range(len(title)):\n    print (str(cont[i]) + \"\u3000\" + str(title[i].a).replace('href=\"', 'href=\"http://qiita.com') + \"<br>\")\n\n\n\n\u3010\u7d50\u679c\u3011\n\u3000\u30a8\u30f3\u30b3\u30fc\u30c9\u3092utf-8\u3067\u8868\u793a\u3059\u308b\u3068\u6587\u5b57\u5316\u3051\u304c\u767a\u751f\u3057\u305f\u306e\u3067\u3001shift-jis\u306b\u3057\u307e\u3057\u305f\u3002\n\n\n\u3010\u554f\u984c\u70b9\u3011\n\u3000\u30d7\u30ed\u30b0\u30e9\u30e0\u5b9f\u884c\u6642\u9593\u304c\u9577\u3044(>_<)\n\n\u3010\u53c2\u8003\u30b5\u30a4\u30c8\u3011\n\u3000Python3 + urllib + BeautifulSoup\u3067\u30cd\u30c3\u30c8\u4e0a\u306e\u60c5\u5831\u3092\u53d6\u5f97\u3059\u308b\n\u3000Python\u3068Beautiful Soup\u3067\u30b9\u30af\u30ec\u30a4\u30d4\u30f3\u30b0\n\u3000Beautiful Soup\u3092\u4f7f\u3063\u3066\u30b9\u30af\u30ec\u30a4\u30d4\u30f3\u30b0\n#\u3010\u6982\u8981\u3011\n\u3000\u3042\u308b\u30bf\u30b0\u306e\u4e2d\u3067\u30b9\u30c8\u30c3\u30af\u6570Top10\u306e\u8a18\u4e8b\u3092\u62bd\u51fa\u3057\u307e\u3059\u3002\n\n#\u3010\u74b0\u5883\u3011\n\u3000windows8.1\n\u3000python3.5\n\n#\u3010\u30d7\u30ed\u30b0\u30e9\u30e0\u3011\n\u3000Python\u30bf\u30b0\u306e\u30e9\u30f3\u30af\u4ed8\u3051\u3092\u884c\u3044\u307e\u3057\u305f\u3002\n\u3000\u5b9f\u884c\u65b9\u6cd5\u3000\u2192\u3000`python stock_rank.py > output.html`\n\n```py:stock_rank.py\n# -*- coding: utf-8 -*-\n\nimport urllib.request\nfrom bs4 import BeautifulSoup\n\n# Contribution\u6570\u306e\u521d\u671f\u5316\ncont = []\nfor i in range(10):\n    cont.append(0)\n    \n# \u30bf\u30a4\u30c8\u30eb\u306e\u521d\u671f\u5316\ntitle = []\nfor i in range(10):\n    title.append(\"\")\n\npage_num = 1\n\nwhile True:\n    try:\n        html = urllib.request.urlopen(\"https://qiita.com/tags/Python/items?page=\" + str(page_num)).read()\n        \n        soup = BeautifulSoup(html, \"html.parser\")\n        \n        # \u30af\u30e9\u30b9\u3092\u6307\u5b9a\u3057\u3066html\u62bd\u51fa\n        title_all = soup.find_all(class_=\"publicItem_body\")\n        \n        # publicItem_body\u30af\u30e9\u30b9\u304c\u306a\u3044\u30da\u30fc\u30b8\u306f\u3068\u3070\u3059\n        if len(title_all) == 0:\n            continue\n        \n        for i in range(20):\n            try:          \n                # \u30af\u30e9\u30b9\u3092\u6307\u5b9a\u3057\u3066html\u62bd\u51fa\n                cont_all = soup.find_all(class_=\"publicItem_stockCount\")\n                # \u90aa\u9b54\u306a\u30bf\u30b0\u3092\u524a\u9664\n                cont_sakujo = str(cont_all[i]).replace('<i class=\"fa fa-stock \"></i>','')\n                # cont_all_after\u306fstr\u578b\u306e\u305f\u3081string\u30d7\u30ed\u30d1\u30c6\u30a3\u306f\u4f7f\u3048\u306a\u3044\n                # \u305d\u306e\u305f\u3081BeautifulSoup\u578b\u3078\u5909\u63db\n                cont_kazu = int(BeautifulSoup(cont_sakujo, \"html.parser\").string)\n                \n                for j in range(10):\n                    if cont_kazu >= cont[j]:\n                        # Contribution\u6570\u4ee3\u5165            \n                        cont.insert(j, cont_kazu)\n                        cont.pop()\n                        # \u30bf\u30a4\u30c8\u30eb\u4ee3\u5165\n                        title.insert(j, title_all[i])\n                        title.pop()\n                        break\n                \n            # \u8ab0\u306b\u3082\u30b9\u30c8\u30c3\u30af\u3055\u308c\u3066\u3044\u306a\u3044\u8a18\u4e8b\u306f\u3068\u3070\u3059\n            except:\n                continue\n        \n        page_num += 1\n        \n    # HTTP Error 404\n    except:\n        break\n\nfor i in range(len(title)):\n    print (str(cont[i]) + \"\u3000\" + str(title[i].a).replace('href=\"', 'href=\"http://qiita.com') + \"<br>\")\n```\n\n#\u3010\u7d50\u679c\u3011\n\u3000\u30a8\u30f3\u30b3\u30fc\u30c9\u3092utf-8\u3067\u8868\u793a\u3059\u308b\u3068\u6587\u5b57\u5316\u3051\u304c\u767a\u751f\u3057\u305f\u306e\u3067\u3001shift-jis\u306b\u3057\u307e\u3057\u305f\u3002\n<img width=\"589\" alt=\"rank.png\" src=\"https://qiita-image-store.s3.amazonaws.com/0/121997/fefa4b07-2952-2807-1d5d-98ad80e1745d.png\">\n\n\n#\u3010\u554f\u984c\u70b9\u3011\n\u3000\u30d7\u30ed\u30b0\u30e9\u30e0\u5b9f\u884c\u6642\u9593\u304c\u9577\u3044(>_<)\n\n#\u3010\u53c2\u8003\u30b5\u30a4\u30c8\u3011\n\u3000[Python3 + urllib + BeautifulSoup\u3067\u30cd\u30c3\u30c8\u4e0a\u306e\u60c5\u5831\u3092\u53d6\u5f97\u3059\u308b](http://qiita.com/piruty_joy/items/d360f436d1b57cc9c980)\n\u3000[Python\u3068Beautiful Soup\u3067\u30b9\u30af\u30ec\u30a4\u30d4\u30f3\u30b0](http://qiita.com/itkr/items/513318a9b5b92bd56185)\n\u3000[Beautiful Soup\u3092\u4f7f\u3063\u3066\u30b9\u30af\u30ec\u30a4\u30d4\u30f3\u30b0](http://qiita.com/rusarusa/items/d7f014ba80d6fe7a3e07)\n", "tags": ["Qiita", "\u30b9\u30af\u30ec\u30a4\u30d4\u30f3\u30b0", "Python", "python3", "Windows8.1"]}