{"context": " More than 1 year has passed since last update.\n\nFuel\nOverview \u2014 Fuel 0.1.1 documentation\n\n\u4e3b\u306b\n\nDataset\nDataStream\nIterationScheme\n\n\u304c\u3042\u308a\u307e\u3059\u304c\u3001 Dataset \u306e\u4f8b\u3092\u793a\u3057\u307e\u3059\u3002\nfuel.datasets.base.Dataset\u3092\u7d99\u627f\u3057\u305f\u30af\u30e9\u30b9\u3067\u3069\u3093\u306a\u30c7\u30fc\u30bf\u306a\u306e\u304b\u3092\u5b9a\u7fa9\u3059\u308b\u3002\n\u4f8b\u3048\u3070\u3001\uff12\u6b21\u5143\u306e\u30b0\u30ec\u30a4\u30b9\u30b1\u30fc\u30eb\u306e\u753b\u50cf\u30c7\u30fc\u30bf\u3092\u5206\u985e\u3057\u305f\u30c8\u30ec\u30fc\u30cb\u30f3\u30b0\u30c7\u30fc\u30bf\u3067\u30d0\u30c3\u30c1\u51e6\u7406\u3092\u3059\u308b\u3088\u3046\u306a\u5834\u5408\u3002\n>>> dataset.axis_labels\nOrderedDict([('features', ('batch', 'height', 'width')), ('targets', ('batch', 'index'))])\n\n\u3057\u304b\u3057\u3001 Dataset \u306f\u6570\u5024\u5316\u3055\u308c\u305f\u3082\u306e\u3092\u6271\u3046\u306e\u3067\u3001\u30c6\u30ad\u30b9\u30c8\u30c7\u30fc\u30bf\u306f\u3069\u3046\u3059\u308c\u3070\u3044\u3044\u306e\u304b\u3001\u3068\u306a\u308b\u3002\n\u305d\u3053\u3067\u3001 TextFile \u306a\u308b\u30af\u30e9\u30b9\u304c\u7528\u610f\u3055\u308c\u3066\u3044\u308b\u3002\n\nTextFile\nTextFile \u2014 Fuel 0.1.1 documentation\n\u4f8b\u3048\u3070\u3001\u4ee5\u4e0b\u306e\u3088\u3046\u306a vocab.pkl \u304c\u3042\u3063\u305f\u3068\u3059\u308b\u3002\n>>> import cPickle\n>>> d = cPickle.load(open('vocab.pkl'))\n>>> d\n{'and': 12, 'cute': 13, 'forget': 14, 'it': 15, 'an': 16, 'break-': 17, 'are': 18, 'horrendous': 19, '&apos;re': 20, '<UNK>': 0, 'again': 5, 'what': 22, 'make': 23, ',': 6, '.': 3, 'start': 24, 'pronunciation': 25, 'asking': 26, 'roxanne': 27, 'you': 7, 'out': 21, 'public': 29, '?': 8, '&apos;d': 30, 'we': 9, 'okay': 31, 'that': 10, '<S>': 1, 'andrew': 32, 'if': 33, '&apos;s': 4, 'quad': 34, 'with': 11, 'barrett': 35, 'me': 36, 'on': 37, 'incredibly': 28, 'your': 38, 'name': 39, 'this': 40, 'well': 41, 'up': 42, 'thought': 43, 'i': 44, 'korrine': 45, 'so': 46, 'can': 47, 'quick': 48, 'the': 49, '</S>': 2, 'having': 50}\n\n\u307e\u305f\u3001\u4ee5\u4e0b\u306e\u3088\u3046\u306a train_post.txt.tok \u304c\u3042\u3063\u305f\u3068\u3059\u308b\u3002\n\ntrain_post.txt.tok\nCan we make this quick ? Roxanne Korrine and Andrew Barrett are having an incredibly horrendous public break- up on the quad . Again .\nYou &apos;re asking me out . That &apos;s so cute . What &apos;s your name again ?\n\n\n\u3059\u308b\u3068\u3053\u3093\u306a\u611f\u3058\u3002\n>>> import cPickle\n>>> d = cPickle.load(open('vocab.pkl'))\n>>> def get_key(n):\n...     for k, v in d.items():\n...             if v == n:\n...                     return k\n...     return '<NULL>'\n... \n>>> from fuel.datasets.text import TextFile\n>>> text_data = TextFile(['train_post.txt.tok'], d)\n>>> s = text_data.open()\n>>> data = text_data.get_data(s)\n>>> \" \".join([get_key(n) for n in data[0]])\n'<S> <UNK> we make this quick ? <UNK> <UNK> and <UNK> <UNK> are having an incredibly horrendous public break- up on the quad . <UNK> . </S>'\n>>> \n>>> def lower(s):\n...     return s.lower()\n... \n>>> text_data = TextFile(['train_post.txt.tok'], d, preprocess=lower)\n>>> s = text_data.open()\n>>> data = text_data.get_data(s)\n>>> \" \".join([get_key(n) for n in data[0]])\n'<S> can we make this quick ? roxanne korrine and andrew barrett are having an incredibly horrendous public break- up on the quad . again . </S>'\n>>> \n>>> data = text_data.get_data(s)\n>>> data[0]\n[1, 7, 20, 26, 36, 21, 3, 10, 4, 46, 13, 3, 22, 4, 38, 39, 5, 8, 2]\n>>> \" \".join([get_key(n) for n in data[0]])\n'<S> you &apos;re asking me out . that &apos;s so cute . what &apos;s your name again ? </S>'\n\n\u8f9e\u66f8\u3092\u4f5c\u308b\u6642\u70b9\u3067 lowercase \u306b\u3057\u3066\u3057\u307e\u3063\u305f\u306e\u3067\u3001 preprocess \u3092\u6307\u5b9a\u3057\u3066\u3044\u307e\u3059\u3002\n\u3053\u3093\u306a\u611f\u3058\u3067\u8f9e\u66f8\u3092\u6e21\u3057\u3066\u3042\u3052\u308b\u3053\u3068\u3067\u3001\u5bfe\u5fdc\u3057\u305f\u6570\u5b57\u306b\u5909\u63db\u3057\u3066\u304f\u308c\u308b\u3068\u3044\u3046\u3082\u306e\u3067\u3059\u3002\n\u307e\u3042\u305d\u3082\u305d\u3082 Fuel \u3092\u4f7f\u3046\u5834\u5408\u306b\u9650\u308b\u8a71\u3067\u3059\u304c\u3002\n\n\u53c2\u8003\n\u30c8\u30fc\u30af\u30ca\u30a4\u30ba\u3068\u8f9e\u66f8\u306e\u4f5c\u6210\u3092\u4e8b\u524d\u306b\u3059\u308b\u5fc5\u8981\u304c\u3042\u308b\u306e\u3067\u3001\u4ee5\u4e0b\u306e\u51e6\u7406\u3092\u3057\u307e\u3057\u305f\u3002\n\nTokenize\nmosesdecoder/tokenizer.perl at master \u00b7 moses-smt/mosesdecoder\n\u4e0a\u306e\u30b9\u30af\u30ea\u30d7\u30c8\u3092\u304a\u501f\u308a\u3057\u305f\u3002\nperl tokenizer.perl < train_post.txt -l en 2>/dev/null > train_post.txt.tok\n\n\ntrain_post.txt\nCan we make this quick?  Roxanne Korrine and Andrew Barrett are having an incredibly horrendous public break- up on the quad.  Again.\nYou're asking me out.  That's so cute. What's your name again?\n\n\n\ntrain_post.txt.tok\nCan we make this quick ? Roxanne Korrine and Andrew Barrett are having an incredibly horrendous public break- up on the quad . Again .\nYou &apos;re asking me out . That &apos;s so cute . What &apos;s your name again ?\n\n\n&apos; \u306b\u95a2\u3057\u3066\u306f\u4f55\u3089\u304b\u306e\u5bfe\u51e6\u3092\u3057\u306a\u3044\u3068\u3002\u3002\n\nVocabrary\nGroundHog/preprocess.py at master \u00b7 lisa-groundhog/GroundHog\n\u4e0a\u306e\u30b9\u30af\u30ea\u30d7\u30c8\u3092\u304a\u501f\u308a\u3057\u305f\u3002\npython preprocess.py -l train_post.txt.tok\n\n\u5b9f\u884c\u3059\u308b\u3068 vocab.pkl \u304c\u751f\u6210\u3055\u308c\u308b\u3002\n\n\n-d \u30aa\u30d7\u30b7\u30e7\u30f3\u3067\u751f\u6210\u3055\u308c\u308b\u8f9e\u66f8\u306e\u30d1\u30b9\u3092\u6307\u5b9a\u3067\u304d\u308b\u3002\u30c7\u30d5\u30a9\u30eb\u30c8\u304c vocab.pkl \u3002\n\n-l \u30aa\u30d7\u30b7\u30e7\u30f3\u3067\u5c0f\u6587\u5b57\u306b\u3067\u304d\u308b\u3002\n\n-v \u30aa\u30d7\u30b7\u30e7\u30f3\u3067\u8a9e\u5f59\u6570\u3092\u6307\u5b9a\u3067\u304d\u308b\u3002\u6307\u5b9a\u3057\u306a\u3044\u3068\u5168\u5358\u8a9e\u3002\n\n\u3057\u304b\u3057\u3001\u8907\u6570\u306e\u30d5\u30a1\u30a4\u30eb\u304b\u3089\u8f9e\u66f8\u3092\u4f5c\u308a\u305f\u3044\u6642\npython preprocess.py -l train_post.txt.tok train_reply.txt.tok\n\n\u306e\u3088\u3046\u306b\u3059\u308b\u3068\u3046\u307e\u304f\u3044\u304b\u306a\u3044\u3002\n\u539f\u56e0\u306f\u3053\u3053\u3002\nvocab_count = counter.most_common()\n\n\u3092\nvocab_count = combined_counter.most_common()\n\n\u306b\u4fee\u6b63\u3002\n\u8a9e\u5f59\u6570\u3092\u6307\u5b9a\u3059\u308c\u3070\u3001\u8907\u6570\u30d5\u30a1\u30a4\u30eb\u3067\u3082\u554f\u984c\u306a\u3044\u3002\n\u57fa\u672c\u8a9e\u5f59\u6570\u3092\u6307\u5b9a\u3057\u306a\u3044\u6642\u306a\u3093\u3066\u306a\u3044\u306e\u304b\u306a\u3002\u3002\u3002\n\u307e\u305f\u3001 text_data = TextFile(['train_post.txt.tok'], d) \u306e\u969b\u306bBOS\u306e\u8a18\u53f7\u3092\u6307\u5b9a\u3067\u304d\u308b\u304c\u3001\u30c7\u30d5\u30a9\u30eb\u30c8\u306f\u4ee5\u4e0b\u3002\n\n\n\nsynbol\nmeaning\n\n\n\n\n<UNK>\nUnknown term\n\n\n<S>\nBegin of sentence\n\n\n</S>\nEnd of sentence\n\n\n\n\u8f9e\u66f8\u5185\u306b\uff13\u3064\u304c\u306a\u3044\u3068\u30a8\u30e9\u30fc\u304c\u51fa\u308b\u306e\u3067\nvocab = {'<UNK>': 0, '<S>': 1, '</S>': 2}\nfor i, (word, count) in enumerate(vocab_count):\n   vocab[word] = i + 3\n\n\u306e\u3088\u3046\u306b\u4fee\u6b63\u3002\n\n## Fuel\n\n[Overview \u2014 Fuel 0.1.1 documentation](http://fuel.readthedocs.org/en/latest/overview.html)\n\n![](http://fuel.readthedocs.org/en/latest/_images/graphviz-70d0ae0bb9320e12759315333184e6e457a62dc1.png)\n\n\u4e3b\u306b\n\n* Dataset\n* DataStream\n* IterationScheme\n\n\u304c\u3042\u308a\u307e\u3059\u304c\u3001 `Dataset` \u306e\u4f8b\u3092\u793a\u3057\u307e\u3059\u3002\n\n[`fuel.datasets.base.Dataset`](http://fuel.readthedocs.org/en/latest/api/dataset.html)\u3092\u7d99\u627f\u3057\u305f\u30af\u30e9\u30b9\u3067\u3069\u3093\u306a\u30c7\u30fc\u30bf\u306a\u306e\u304b\u3092\u5b9a\u7fa9\u3059\u308b\u3002\n\u4f8b\u3048\u3070\u3001\uff12\u6b21\u5143\u306e\u30b0\u30ec\u30a4\u30b9\u30b1\u30fc\u30eb\u306e\u753b\u50cf\u30c7\u30fc\u30bf\u3092\u5206\u985e\u3057\u305f\u30c8\u30ec\u30fc\u30cb\u30f3\u30b0\u30c7\u30fc\u30bf\u3067\u30d0\u30c3\u30c1\u51e6\u7406\u3092\u3059\u308b\u3088\u3046\u306a\u5834\u5408\u3002\n\n```\n>>> dataset.axis_labels\nOrderedDict([('features', ('batch', 'height', 'width')), ('targets', ('batch', 'index'))])\n```\n\n\u3057\u304b\u3057\u3001 `Dataset` \u306f\u6570\u5024\u5316\u3055\u308c\u305f\u3082\u306e\u3092\u6271\u3046\u306e\u3067\u3001\u30c6\u30ad\u30b9\u30c8\u30c7\u30fc\u30bf\u306f\u3069\u3046\u3059\u308c\u3070\u3044\u3044\u306e\u304b\u3001\u3068\u306a\u308b\u3002\n\u305d\u3053\u3067\u3001 `TextFile` \u306a\u308b\u30af\u30e9\u30b9\u304c\u7528\u610f\u3055\u308c\u3066\u3044\u308b\u3002\n\n## TextFile\n\n[TextFile \u2014 Fuel 0.1.1 documentation](http://fuel.readthedocs.org/en/latest/api/dataset.html#fuel.datasets.text.TextFile)\n\n\u4f8b\u3048\u3070\u3001\u4ee5\u4e0b\u306e\u3088\u3046\u306a `vocab.pkl` \u304c\u3042\u3063\u305f\u3068\u3059\u308b\u3002\n\n```python\n>>> import cPickle\n>>> d = cPickle.load(open('vocab.pkl'))\n>>> d\n{'and': 12, 'cute': 13, 'forget': 14, 'it': 15, 'an': 16, 'break-': 17, 'are': 18, 'horrendous': 19, '&apos;re': 20, '<UNK>': 0, 'again': 5, 'what': 22, 'make': 23, ',': 6, '.': 3, 'start': 24, 'pronunciation': 25, 'asking': 26, 'roxanne': 27, 'you': 7, 'out': 21, 'public': 29, '?': 8, '&apos;d': 30, 'we': 9, 'okay': 31, 'that': 10, '<S>': 1, 'andrew': 32, 'if': 33, '&apos;s': 4, 'quad': 34, 'with': 11, 'barrett': 35, 'me': 36, 'on': 37, 'incredibly': 28, 'your': 38, 'name': 39, 'this': 40, 'well': 41, 'up': 42, 'thought': 43, 'i': 44, 'korrine': 45, 'so': 46, 'can': 47, 'quick': 48, 'the': 49, '</S>': 2, 'having': 50}\n```\n\n\u307e\u305f\u3001\u4ee5\u4e0b\u306e\u3088\u3046\u306a `train_post.txt.tok` \u304c\u3042\u3063\u305f\u3068\u3059\u308b\u3002\n\n```train_post.txt.tok\nCan we make this quick ? Roxanne Korrine and Andrew Barrett are having an incredibly horrendous public break- up on the quad . Again .\nYou &apos;re asking me out . That &apos;s so cute . What &apos;s your name again ?\n```\n\n\u3059\u308b\u3068\u3053\u3093\u306a\u611f\u3058\u3002\n\n```python\n>>> import cPickle\n>>> d = cPickle.load(open('vocab.pkl'))\n>>> def get_key(n):\n...     for k, v in d.items():\n...             if v == n:\n...                     return k\n...     return '<NULL>'\n... \n>>> from fuel.datasets.text import TextFile\n>>> text_data = TextFile(['train_post.txt.tok'], d)\n>>> s = text_data.open()\n>>> data = text_data.get_data(s)\n>>> \" \".join([get_key(n) for n in data[0]])\n'<S> <UNK> we make this quick ? <UNK> <UNK> and <UNK> <UNK> are having an incredibly horrendous public break- up on the quad . <UNK> . </S>'\n>>> \n>>> def lower(s):\n...     return s.lower()\n... \n>>> text_data = TextFile(['train_post.txt.tok'], d, preprocess=lower)\n>>> s = text_data.open()\n>>> data = text_data.get_data(s)\n>>> \" \".join([get_key(n) for n in data[0]])\n'<S> can we make this quick ? roxanne korrine and andrew barrett are having an incredibly horrendous public break- up on the quad . again . </S>'\n>>> \n>>> data = text_data.get_data(s)\n>>> data[0]\n[1, 7, 20, 26, 36, 21, 3, 10, 4, 46, 13, 3, 22, 4, 38, 39, 5, 8, 2]\n>>> \" \".join([get_key(n) for n in data[0]])\n'<S> you &apos;re asking me out . that &apos;s so cute . what &apos;s your name again ? </S>'\n```\n\n\u8f9e\u66f8\u3092\u4f5c\u308b\u6642\u70b9\u3067 `lowercase` \u306b\u3057\u3066\u3057\u307e\u3063\u305f\u306e\u3067\u3001 `preprocess` \u3092\u6307\u5b9a\u3057\u3066\u3044\u307e\u3059\u3002\n\n\u3053\u3093\u306a\u611f\u3058\u3067\u8f9e\u66f8\u3092\u6e21\u3057\u3066\u3042\u3052\u308b\u3053\u3068\u3067\u3001\u5bfe\u5fdc\u3057\u305f\u6570\u5b57\u306b\u5909\u63db\u3057\u3066\u304f\u308c\u308b\u3068\u3044\u3046\u3082\u306e\u3067\u3059\u3002\n\n\u307e\u3042\u305d\u3082\u305d\u3082 `Fuel` \u3092\u4f7f\u3046\u5834\u5408\u306b\u9650\u308b\u8a71\u3067\u3059\u304c\u3002\n\n## \u53c2\u8003\n\n\u30c8\u30fc\u30af\u30ca\u30a4\u30ba\u3068\u8f9e\u66f8\u306e\u4f5c\u6210\u3092\u4e8b\u524d\u306b\u3059\u308b\u5fc5\u8981\u304c\u3042\u308b\u306e\u3067\u3001\u4ee5\u4e0b\u306e\u51e6\u7406\u3092\u3057\u307e\u3057\u305f\u3002\n\n### Tokenize\n\n[mosesdecoder/tokenizer.perl at master \u00b7 moses-smt/mosesdecoder](https://github.com/moses-smt/mosesdecoder/blob/master/scripts/tokenizer/tokenizer.perl)\n\n\u4e0a\u306e\u30b9\u30af\u30ea\u30d7\u30c8\u3092\u304a\u501f\u308a\u3057\u305f\u3002\n\n```\nperl tokenizer.perl < train_post.txt -l en 2>/dev/null > train_post.txt.tok\n```\n\n```train_post.txt\nCan we make this quick?  Roxanne Korrine and Andrew Barrett are having an incredibly horrendous public break- up on the quad.  Again.\nYou're asking me out.  That's so cute. What's your name again?\n```\n\n```train_post.txt.tok\nCan we make this quick ? Roxanne Korrine and Andrew Barrett are having an incredibly horrendous public break- up on the quad . Again .\nYou &apos;re asking me out . That &apos;s so cute . What &apos;s your name again ?\n```\n\n`&apos;` \u306b\u95a2\u3057\u3066\u306f\u4f55\u3089\u304b\u306e\u5bfe\u51e6\u3092\u3057\u306a\u3044\u3068\u3002\u3002\n\n### Vocabrary\n\n[GroundHog/preprocess.py at master \u00b7 lisa-groundhog/GroundHog](https://github.com/lisa-groundhog/GroundHog/blob/master/experiments/nmt/preprocess/preprocess.py#L168)\n\n\u4e0a\u306e\u30b9\u30af\u30ea\u30d7\u30c8\u3092\u304a\u501f\u308a\u3057\u305f\u3002\n\n```\npython preprocess.py -l train_post.txt.tok\n```\n\n\u5b9f\u884c\u3059\u308b\u3068 `vocab.pkl` \u304c\u751f\u6210\u3055\u308c\u308b\u3002\n\n* `-d` \u30aa\u30d7\u30b7\u30e7\u30f3\u3067\u751f\u6210\u3055\u308c\u308b\u8f9e\u66f8\u306e\u30d1\u30b9\u3092\u6307\u5b9a\u3067\u304d\u308b\u3002\u30c7\u30d5\u30a9\u30eb\u30c8\u304c `vocab.pkl` \u3002\n* `-l` \u30aa\u30d7\u30b7\u30e7\u30f3\u3067\u5c0f\u6587\u5b57\u306b\u3067\u304d\u308b\u3002\n* `-v` \u30aa\u30d7\u30b7\u30e7\u30f3\u3067\u8a9e\u5f59\u6570\u3092\u6307\u5b9a\u3067\u304d\u308b\u3002\u6307\u5b9a\u3057\u306a\u3044\u3068\u5168\u5358\u8a9e\u3002\n\n\u3057\u304b\u3057\u3001\u8907\u6570\u306e\u30d5\u30a1\u30a4\u30eb\u304b\u3089\u8f9e\u66f8\u3092\u4f5c\u308a\u305f\u3044\u6642\n\n```\npython preprocess.py -l train_post.txt.tok train_reply.txt.tok\n```\n\n\u306e\u3088\u3046\u306b\u3059\u308b\u3068\u3046\u307e\u304f\u3044\u304b\u306a\u3044\u3002\n\u539f\u56e0\u306f[\u3053\u3053](https://github.com/lisa-groundhog/GroundHog/blob/master/experiments/nmt/preprocess/preprocess.py#L168)\u3002\n\n```\nvocab_count = counter.most_common()\n```\n\n\u3092\n\n```\nvocab_count = combined_counter.most_common()\n```\n\n\u306b\u4fee\u6b63\u3002\n\n\u8a9e\u5f59\u6570\u3092\u6307\u5b9a\u3059\u308c\u3070\u3001\u8907\u6570\u30d5\u30a1\u30a4\u30eb\u3067\u3082\u554f\u984c\u306a\u3044\u3002\n\u57fa\u672c\u8a9e\u5f59\u6570\u3092\u6307\u5b9a\u3057\u306a\u3044\u6642\u306a\u3093\u3066\u306a\u3044\u306e\u304b\u306a\u3002\u3002\u3002\n\n\u307e\u305f\u3001 `text_data = TextFile(['train_post.txt.tok'], d)` \u306e\u969b\u306b`BOS`\u306e\u8a18\u53f7\u3092\u6307\u5b9a\u3067\u304d\u308b\u304c\u3001\u30c7\u30d5\u30a9\u30eb\u30c8\u306f\u4ee5\u4e0b\u3002\n\n|synbol|meaning|\n|:-:|:-:|\n|\\<UNK\\>|Unknown term|\n|\\<S\\>|Begin of sentence|\n|\\</S\\>|End of sentence|\n\n\u8f9e\u66f8\u5185\u306b\uff13\u3064\u304c\u306a\u3044\u3068\u30a8\u30e9\u30fc\u304c\u51fa\u308b\u306e\u3067\n\n```\nvocab = {'<UNK>': 0, '<S>': 1, '</S>': 2}\nfor i, (word, count) in enumerate(vocab_count):\n   vocab[word] = i + 3\n```\n\n\u306e\u3088\u3046\u306b\u4fee\u6b63\u3002\n", "tags": ["NLP", "fuel", "Python"]}