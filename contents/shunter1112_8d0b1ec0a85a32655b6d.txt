{"context": " More than 1 year has passed since last update.\u306f\u3058\u3081\u307e\u3057\u3066\u3001Shunter\u3067\u3059\u3002\n\u5f53\u65b9\u300110\u6708\u304b\u3089\u6a5f\u68b0\u5b66\u7fd2/\u4eba\u5de5\u77e5\u80fd\u306b\u3064\u3044\u3066\u52c9\u5f37\u3092\u3057\u3066\u3044\u308b\u304a\u3058\u3055\u3093\u3067\u3059\u3002\n\u6628\u4eca\u306e Deep Learning \u30d6\u30fc\u30e0\u306b\u4e57\u3063\u304b\u3063\u3066\u30a2\u30eb\u30b4\u30ea\u30ba\u30e0\u306e\u52c9\u5f37\u3068\u5e73\u884c\u3057\u3066\u30d5\u30ec\u30fc\u30e0\u30ef\u30fc\u30af\u3067\u904a\u3076\u3053\u3068\u3092\u3057\u3066\u304d\u307e\u3057\u305f\u3002\u3044\u308d\u3044\u308d\u8a66\u3059\u306a\u304b\u3067\u3001\u632b\u6298\u3057\u306a\u304c\u3089\u3082Chainer\u304c\u552f\u4e00\u300c\u3053\u308c\u306a\u3089\u3044\u3051\u308b\uff01\u300d\u3068\u601d\u308f\u305b\u3066\u304f\u308c\u305f\u30d5\u30ec\u30fc\u30e0\u30ef\u30fc\u30af\u3067\u3059\u3002\n\u56fd\u7523\u3060\u3057(Ruby\u597d\u304d\u3001\u540c\u3058\u306b\u304a\u3044\u611f\u3058\u308b)\u3001\u74b0\u5883\u69cb\u7bc9\u3067\u5168\u7136\u3064\u307e\u3065\u304b\u306a\u304b\u3063\u305f\u3057\u3001\u672c\u5bb6\u30c9\u30ad\u30e5\u30e1\u30f3\u30c8\u30c1\u30e5\u30fc\u30c8\u30ea\u30a2\u30eb\u3082\u89aa\u5207\u3067\u3001\u3068\u3063\u3064\u304d\u3084\u3059\u304b\u3063\u305f\u3067\u3059\u3002\n\u81ea\u5206\u3092\u596e\u3044\u7acb\u305f\u305b\u308b\u305f\u3081\u306b\u3082\u3001\u30a2\u30c9\u30d9\u30f3\u30c8\u30ab\u30ec\u30f3\u30c0\u30fc\u306b\u53c2\u52a0\u3057\u3066\u306a\u306b\u304b\u4f5c\u308d\u3046\u3068\u601d\u3044\u3001\u672c\u8a18\u4e8b\u3092\u66f8\u3044\u3066\u3044\u307e\u3059\u3002\n\u7d50\u679c\u304b\u3089\u8a00\u3046\u3068\u5931\u6557\u3057\u307e\u3057\u305f\u3002\u305d\u306e\u8ecc\u8de1\u3092\u5171\u6709\u3067\u304d\u308c\u3070\u5e78\u3044\u3067\u3059\u3002\n\n\u4f5c\u308a\u305f\u304b\u3063\u305f\u3082\u306e\n\u30a6\u30a9\u30fc\u30ea\u30fc\u3092\u63a2\u305b\u3092\u6a5f\u68b0\u5b66\u7fd2\u3067\u3084\u308b\uff01\n\u753b\u50cf\u3092\u5165\u529b\u3059\u308b\u3068\u305d\u306e\u306a\u304b\u304b\u3089\u30a6\u30a9\u30fc\u30ea\u30fc\u3092\u63a2\u3057\u3060\u3057\u3066\u304f\u308c\u308b\u3082\u306e\u3067\u3059\u3002\n\n\u30c7\u30fc\u30bf\u53ce\u96c6\n\n\u6b63\u89e3\u30c7\u30fc\u30bf\n\u306f\u3058\u3081\u306b\u3001\u30a6\u30a9\u30fc\u30ea\u30fc\u3092\u5b66\u3070\u305b\u307e\u3059\u3002\n\u7406\u60f3\u3092\u8a00\u3048\u3070\u672c\u5f53\u306e\u6b63\u89e3\u304c\u6b32\u3057\u3044\u3068\u3053\u308d\u306a\u3093\u3067\u3059\u304c\u3001\n\u306a\u304b\u306a\u304b\u6b63\u89e3\u30c7\u30fc\u30bf\u304c\u3042\u308a\u307e\u305b\u3093\u3002\n\u30a6\u30a9\u30fc\u30ea\u30fc\u306e\u9854\u3068\u3044\u3048\u3070\u3053\u3061\u3089\u3002\npositive_images/1.png\n\npositive_images/2.png\n\npositive_images/3.png\n\npositive_images/4.png\n\npositive_images/5.png\n\n\u5927\u91cf\u306b\u30c7\u30fc\u30bf\u304c\u6b32\u3057\u3044\u3068\u3053\u308d\u306a\u306e\u3067\u3059\u304c\u3001\u3053\u308c\u3089\u3092\u4f7f\u3063\u3066\u30c7\u30fc\u30bf\u3092\u751f\u6210\u3057\u307e\u3057\u305f\u3002\n\u30c7\u30fc\u30bf\u751f\u6210\u306f\u3001openCV\u306e\u3000createsamples \u3092\u4f7f\u3063\u3066\u3044\u307e\u3059\u3002\n\u53c2\u8003\nhttp://www.pro-s.co.jp/engineerblog/opencv/post_6397.html\n\u203b\uff08\u3048\u3001OpenCV\u3067\u30a6\u30a9\u30fc\u30ea\u30fc\u63a2\u305b\u3070\u3044\u3044\u3058\u3083\u3093\uff01\u3068\u3044\u3046\u30c4\u30c3\u30b3\u30df\u306f\u306a\u3057\u3067...\uff09 \nopencv_createsamples \u306f\u753b\u50cf\u3092\u8aad\u307f\u8fbc\u3093\u3067\u3001\u753b\u50cf\u3092\u6b6a\u307e\u305b\u3066\u3001.vec\u30d5\u30a1\u30a4\u30eb\u306b\u3057\u3066\u304f\u308c\u307e\u3059\u3002\necho 'generate sample from postive image'\n\nfor file in ./positive_images/* \ndo\n    sub=${file##*/}\n    num=${sub%.*}\n    opencv_createsamples -img $file -vec ./vectors/positive/$num.vec -maxxangle 0.2 -maxyangle 0.2 -maxzangle 0.2 -w 32 -h 32\ndone\n\nvec\u30d5\u30a1\u30a4\u30eb\u3060\u3068\u3001Chainer\u3067\u6271\u3044\u3065\u3089\u305d\u3046\u306a\u306e\u3067\uff08\u5b9f\u614b\u304c\u3088\u304f\u308f\u304b\u3063\u3066\u306a\u3044\u306e\u3067\uff09vec\u3092\u753b\u50cf\u306b\u3057\u3066\u4fdd\u5b58\u3057\u307e\u3059\u3002\n\u307e\u305f\u3001\u6b6a\u307f\u3067\u3082\u5ea7\u6a19\u7684\u306b\u3086\u3089\u304e\u304c\u304a\u3053\u3089\u306a\u3044\u306e\u3067\u3001\u5927\u304d\u3081\u306b\u753b\u50cf\u3092\u4f5c\u3063\u3066\u3001\u305d\u3053\u304b\u3089\u30de\u30fc\u30b8\u30f3\u3092\u30e9\u30f3\u30c0\u30e0\u306b\u8a2d\u5b9a\u3057\u3066\u7e26\u6a2a\u3067\u3086\u3089\u304e\u304c\u8d77\u304d\u308b\u3088\u3046\u306b\u3057\u3066\u3044\u307e\u3059\u3002\necho 'convert positive vector to images'\n\nfor file in ./vectors/positive/* \ndo\n    python showvec.py -i $file -f positive \ndone\n\n\nshowvec.py\nimport struct,array\nimport os\nimport cv2\nimport numpy as np\nimport argparse\nimport random\n\nparser = argparse.ArgumentParser(\n    description='A Converter from Vector to Images')\nparser.add_argument('--img', '-i', default='', help='path of input image')\nparser.add_argument('--folder', '-f', default='', help='name of parent folder')\nargs = parser.parse_args()\n\ndef showvec(fn, width=32, height=32, resize=1.0):\n  f = open(fn,'rb')\n  HEADERTYP = '<iihh' # img count, img size, min, max\n\n  # read header\n  imgcount,imgsize,_,_ = struct.unpack(HEADERTYP, f.read(12))\n\n  for i in range(imgcount):\n    img  = np.zeros((height,width),np.uint8)\n\n    f.read(1) # read gap byte\n    data = array.array('h')\n    data.fromfile(f,imgsize)\n    for r in range(height):\n      for c in range(width):\n        img[r,c] = data[r * width + c]\n\n    img = cv2.resize(img, (0,0), fx=resize, fy=resize, interpolation=cv2.INTER_LINEAR)\n    rand_x = random.randint(0, (32-28))\n    rand_y = random.randint(0, (32-28))\n    clopped_img = img[rand_x:rand_x+28, rand_y:rand_y+28]\n    filename = \"./data/\" + args.folder + \"/\" + fn.split(\"/\")[-1].replace(\".vec\",\"\") + \"_\" + str(i) + \".png\"\n    cv2.imwrite(filename, clopped_img)\n\nshowvec(args.img)\n\n\n\u3059\u308b\u3068\u4ee5\u4e0b\u306e\u69d8\u306a\u753b\u50cf\u304c5000\u679a\u751f\u6210\u3055\u308c\u307e\u3059\u3002\ndata/positive/*.png\n\n\n\n\n\n...\n\n\u5931\u6557\u30c7\u30fc\u30bf\n\u3053\u3053\u3067\u306f\u3001\u30a6\u30a9\u30fc\u30ea\u30fc\u3067\u306a\u3044\u753b\u50cf\u304c\u6b32\u3057\u3044\u306e\u3067\u3001\u9069\u5f53\u306a\u753b\u50cf\u3092\u8aad\u307f\u8fbc\u3093\u3067\n\u3001\u30e9\u30f3\u30c0\u30e0\u306b\u30b0\u30ec\u30fc\u30b9\u30b1\u30fc\u30eb\u3092\u3057\u306628x28\u306e\u9818\u57df\u3092\u9078\u3093\u3067\u753b\u50cf\u3068\u3057\u3066\u5207\u308a\u51fa\u3057\u3066\u3044\u307e\u3059\u3002\n\ngenerate_negative.py\nimport cv\nimport cv2\nimport random \nimport numpy as np\n\nimg = cv2.imread('/path/to/image/you_want_to_crop')\nwidth, height, channels = img.shape\nimg = cv2.cvtColor(img, cv2.cv.CV_BGR2GRAY)\n\nwsize = 28\ngennum = 16000\n\nnp.asarray(img)\n\nfor i in range(gennum):\n  x = random.randint(0,width - wsize)\n  y = random.randint(0,height - wsize)\n  cropped_img = img[x:x+wsize, y:y+wsize]\n  filename = \"./data/negative/\"+str(i)+\".png\"\n  cv2.imwrite(filename, cropped_img)\n\n\n\n16000\u679a\u306e\u30e9\u30f3\u30c0\u30e0\u306a\u753b\u50cf\u304c\u751f\u6210\u3055\u308c\u307e\u3059\u3002\ndata/negative/*.png\n\n\n\n\n\n...\n\n\u753b\u50cf\u3092Python\u306e\u30aa\u30d6\u30b8\u30a7\u30af\u30c8\u306b...\n\u57fa\u672c\u7684\u306b\u306fPython\u306e\u5909\u6570\u304b\u3089\u3044\u308d\u3044\u308d\u30b4\u30cb\u30e7\u30b4\u30cb\u30e7\u3059\u308b\u306e\u3067\u3001\n\u305d\u3046\u3067\u304d\u308b\u3088\u3046\u306b\u3001\u7528\u610f\u3057\u305f\u753b\u50cf\u3092numpy\u30aa\u30d6\u30b8\u30a7\u30af\u30c8\u5316\u3057\u3001\n\u6b63\u89e3\u30c7\u30fc\u30bf\u3068\u4e00\u7dd2\u306bPython\u306e\u30aa\u30d6\u30b8\u30a7\u30af\u30c8\u306b\u683c\u7d0d\u3057\u3001pickle\u5316\u3057\u3066\u3044\u307e\u3059\u3002\n\ngenerate_pickle.py\nimport cv\nimport cv2\nimport numpy as np\nimport os\nimport glob\nfrom six.moves import cPickle\n\nstack = []\n\ndata_dictionary = {\"data\":[], \"label\":[]}\n\ndef pack_image_into_data(dir, label, stack):\n\n    path = './data/' + dir + '/*.png'\n    images = glob.glob(path)\n    for img_name in images : \n        img = cv2.imread(img_name)\n        resized_img = cv2.resize(img, (28, 28))\n        image_gray = cv2.cvtColor(resized_img, cv2.cv.CV_BGR2GRAY)\n        npimage = np.asarray(image_gray).reshape(1,784)[0]\n        npimage = npimage/255.\n        stack.append((npimage, label))\n    return stack\n\nstack = pack_image_into_data(\"negative\", 0, stack)\nstack = pack_image_into_data(\"positive\", 1, stack)\nstack = np.asarray(stack)\n\nnp.random.shuffle(stack)\nstack = stack.tolist()\nfor t in stack :\n    data_dictionary[\"data\"].append(t[0])    \n    data_dictionary[\"label\"].append(t[1])   \n\nwith open('data.pkl', 'wb') as output:\n  cPickle.dump(data_dictionary, output, -1)\n  print data_dictionary[\"data\"][0].shape\n  print data_dictionary[\"label\"][0]\n  print \"Saved \", len(data_dictionary[\"data\"]), \" images with \", len(data_dictionary[\"label\"]), \" labels.\"\n\n\n\n\u30e2\u30c7\u30eb\u306e\u5b66\u7fd2\nChainer\u306e\u51fa\u756a\u3067\u3059\uff01\n\u753b\u50cf\u8a8d\u8b58\u306b\u3064\u3044\u3066\u306fCNN\u3092\u7d44\u3080\u307b\u3046\u304c\u826f\u3044\u3068\u3044\u3046\u306e\u304c\u4e00\u822c\u7684\u3067\u3059\u304c\u3001\n12\u6708\u6bb5\u968e\u3067\u52c9\u5f37\u304c\u304a\u3063\u3064\u3044\u3066\u304a\u3089\u305a\u3001MNIST\u306e\u6587\u5b57\u8a8d\u8b58\u3068\u540c\u3058\u3088\u3046\u306b\n28x28\u306e\u5165\u529b\u304b\u3089\u3059\u3079\u3066\u5168\u7d50\u5408\u5c64\u306e\uff14\u5c64\u30cb\u30e5\u30fc\u30e9\u30eb\u30cd\u30c3\u30c8\u30ef\u30fc\u30af\u3092\u7d44\u3093\u3067\u3057\u307e\u3057\u307e\u3057\u305f\u3002\n\u5b9f\u969b\u306eChainer\u306e\u30b3\u30fc\u30c9\n\ntrain.py\nfrom six.moves import cPickle\nimport numpy as np\nimport argparse\nfrom chainer import cuda, Variable, FunctionSet, optimizers\nimport chainer.functions  as F\nimport matplotlib.pyplot as plt\nimport pdb\nimport six\n\n\ndef unpickle(file):\n    fo = open(file, 'rb')\n    dict = cPickle.load(fo)\n    fo.close()\n    return dict\n\nall_data = unpickle(\"./data.pkl\")\nx_all = np.asarray(all_data[\"data\"]).astype(np.float32)\ny_all = np.asarray(all_data[\"label\"]).astype(np.int32)\n\nx_train, x_test = np.split(x_all, [18000])\ny_train, y_test = np.split(y_all, [18000])\n\n## Build Model\nmodel = FunctionSet( \n  l1 = F.Linear(784, 200),\n  l2 = F.Linear(200, 80),\n  l3 = F.Linear(80, 20),\n  l4 = F.Linear(20, 2)\n)\n\noptimizer = optimizers.SGD()\noptimizer.setup(model)\n\ndef forward(x_data, y_data):\n  x = Variable(x_data)\n  t = Variable(y_data)\n  h1 = F.relu(model.l1(x))\n  h2 = F.relu(model.l2(h1))\n  h3 = F.relu(model.l3(h2))\n  y = model.l4(h3)\n  return F.softmax_cross_entropy(y, t), F.accuracy(y, t)\n\naccuracy_data = []\n\nbatchsize = 1000\ndatasize = 18000  \nfor epoch in range(40):\n  print('epoch %d' % epoch)\n  indexes = np.random.permutation(datasize)\n  for i in range(0, datasize, batchsize):\n    x_batch = x_train[indexes[i : i + batchsize]]\n    y_batch = y_train[indexes[i : i + batchsize]]\n    optimizer.zero_grads()\n    loss, accuracy = forward(x_batch, y_batch)\n    loss.backward()\n    accuracy_data.append(accuracy.data)\n    optimizer.update()\n\nsum_loss, sum_accuracy = 0, 0\n\nplt.plot(accuracy_data, 'k--')\nplt.show()\nplt.savefig(\"accuracy.png\")\n\nfor i in range(0, 3000, batchsize):\n  x_batch = x_test[i : i + batchsize]\n  y_batch = y_test[i : i + batchsize]\n  loss, accuracy = forward(x_batch, y_batch)\n  sum_loss      += loss.data * batchsize\n  sum_accuracy  += accuracy.data * batchsize\n\nmean_loss     = sum_loss / 3000\nmean_accuracy = sum_accuracy / 3000\n\nprint('mean_loss %.2f' % mean_loss)\nprint('mean_accuracy %d' % (mean_accuracy * 100))\n\nif (mean_accuracy * 100) > 90:\n  with open('trained_model.pkl', 'wb') as output:\n    six.moves.cPickle.dump(model, output, -1)\n    print \"model has saved, it has enough quality as trained model :)\"\n\n\n\u5b66\u7fd2\u3057\u305f\u30e2\u30c7\u30eb\u306f\u3001pickle\u3092\u4f7f\u3063\u3066\u3001trained_model.pkl\u3068\u3057\u3066\u30b7\u30ea\u30a2\u30e9\u30a4\u30ba\u3057\u3066\u3044\u307e\u3059\u3002\n\n\u691c\u51fa\n\u672c\u3092\u8cb7\u3044\u307e\u3057\u305f\uff01\n\n\u753b\u50cf\u3092\u30b9\u30ad\u30e3\u30f3\u3057\u3066 ... \n\n\u691c\u51fa\u306e\u30d7\u30ed\u30b0\u30e9\u30e0\u3092\u66f8\u3044\u3066\u307f\u307e\u3057\u305f\u3002\n\ndetect.py\nimport cv\nimport cv2\nimport numpy as np\nfrom chainer import cuda, Function, FunctionSet, gradient_check, Variable, optimizers, utils\nimport chainer.functions as F\nimport six\nimport argparse\nimport sliding_window as sw\nfrom PIL import Image\nfrom PIL import ImageOps\n\nparser = argparse.ArgumentParser(\n    description='A Neural Algorithm of Artistic Style')\nparser.add_argument('--img', '-i', default='',\n                    help='path of input image')\nargs = parser.parse_args()\n\nwith open('trained_model.pkl', 'rb') as model_pickle:\n  model = six.moves.cPickle.load(model_pickle)\n\nratio = 0.7\n\ndef forward(x_data):\n  x = Variable(x_data)\n  h1 = F.relu(model.l1(x))\n  h2 = F.relu(model.l2(h1))\n  h3 = F.relu(model.l3(h2))\n  y = F.softmax(model.l4(h3))\n  return y\n\nimg = Image.open(args.img)\n(iw, ih) = img.size\nprint iw\nprint ih\n\nnew_width = int(iw*ratio) \nnew_height = int(ih*ratio)\nprint new_width\nprint new_height\n\noriginal_img = cv2.imread(args.img)\n\noriginal_img = cv2.resize(original_img, (new_width, new_height))\n\nimg = cv2.cvtColor(original_img, cv2.cv.CV_BGR2GRAY)\nimg = np.asarray(img).astype(np.float32) / 255.\n\ndef judge(array, r, c, wsize):\n\n  xd = np.asarray(array).reshape((1,784)).astype(np.float32)\n  yd = forward(xd).data[0]\n  prob = yd[1]/(yd[0]+yd[1])\n  threshold = 0.8\n  if(prob > threshold):\n    print \"------ detected (\" + str(c) + \",\" + str(r) + \")  P(\" + str(prob) + \" )-------------\"\n    cv2.rectangle(original_img, (c, r), (c+wsize, r+wsize), (0,255,0), 3) \n\nsw.slide_window(img, 28, 14, judge)\n\ncv2.imwrite('./result.png',original_img)\ncv2.imshow('img',original_img)\ncv2.waitKey(0)\ncv2.destroyAllWindows()\n\n\n\n\u3084\u3063\u3066\u3044\u308b\u3053\u3068\u306f...\n1. \u5b66\u7fd2\u3055\u305b\u305f\u30e2\u30c7\u30eb\u306e\u8aad\u307f\u8fbc\u307f\n2. \u753b\u50cf\u309228x28\u304c\u9854\u306e\u5927\u304d\u3055\u306b\u306a\u308b\u3088\u3046\u306b\u7e2e\u5c0f\uff08ratio\u3067\u30cf\u30fc\u30c9\u30b3\u30fc\u30c7\u30a3\u30f3\u30b0) \n3. Sliding Window\u306728x28\u306e\u7a93\u3092\u8d70\u3089\u305b\u3001\u30a6\u30a9\u30fc\u30ea\u30fc\u3060\u3063\u305f\u3089\u56db\u89d2\u3092\u5143\u753b\u50cf\u306b\u66f8\u304d\u3053\u3080\n4. \u5143\u753b\u50cf + \u56db\u89d2 \u3092\u753b\u50cf\u3068\u3057\u3066\u66f8\u304d\u51fa\u3057\n\u7d50\u679c\u306f\u4ee5\u4e0b\u306e\u3068\u304a\u308a\u3067\u3059\u3002\n\n\u9ec4\u7dd1\u8272\u306e\u56db\u89d2\u304c\u691c\u51fa\u3057\u305f\u5834\u6240\u3067\u3059\u3002\n\u5931\u6557!! \n\n\u306a\u305c\u5931\u6557\uff1f \u81ea\u5206\u306a\u308a\u306b\u7406\u7531\u3092\u8003\u3048\u305f\n\u6642\u9593\u7684\u306b\u4f59\u88d5\u304c\u306a\u304b\u3063\u305f\u306e\u3067\u3001\u7406\u60f3\u7684\u306b\u3069\u3046\u3059\u308b\u3079\u304d\u304b\u3092\u8e0f\u307e\u3048\u3066\u3044\u304f\u3064\u304b\u3002\n\n\u672c\u5f53\u306f\uff11\u518a\u81ea\u529b\u3067\u30a6\u30a9\u30fc\u30ea\u30fc\u3092\u63a2\u3057\u3066\u3001\u305d\u308c\u3092\u6b63\u89e3\u30c7\u30fc\u30bf\u306b\u542b\u3081\u308b\u3079\u304d\u3060\u3063\u305f\u3002\n\n\n\u6b63\u89e3\u30c7\u30fc\u30bf\u304c\u5168\u90e8\u771f\u6b63\u9762\u3067\u6c4e\u5316\u6027\u80fd\u843d\u3061\u3066\u308b\u306f\u305a\n\u3057\u307e\u3057\u307e\u306b\u53cd\u5fdc\u3057\u3066\u3044\u308b\u306e\u306f\u3001\u30a6\u30a9\u30fc\u30ea\u30fc\u306e\u6b63\u89e3\u30c7\u30fc\u30bf\u306e2/5\u304c\u80cc\u666f\u30dc\u30fc\u30c0\u3060\u3063\u305f\u304b\u3089\u304b\u306a\u3068\u601d\u3046\n\n\n\u672c\u5f53\u306f\u3001\u6b63\u89e3\u30c7\u30fc\u30bf\u3092\u5897\u3084\u3059\u30d7\u30ed\u30b0\u30e9\u30e0\u3082\u81ea\u5206\u3067\u66f8\u304f\u3079\u304d\u3060\u3063\u305f\n\n\n\u8272\u30c7\u30fc\u30bf\u6b8b\u3057\u305f\u304b\u3063\u305f\n\u30db\u30ef\u30a4\u30c8\u30ce\u30a4\u30ba\u52a0\u3048\u305f\u304b\u3063\u305f\nZ\u8ef8\u306e\u56de\u8ee2\u306b\u3088\u308b\u6b6a\u307f\uff08opencv_createsamples\u304c\u3084\u3063\u3066\u304f\u308c\u308b\uff09\u3092\u52a0\u3048\u3089\u308c\u305f\u3089\u3001\u9854\u306e\u5411\u304d\u306b\u5bfe\u3059\u308b\u6c4e\u5316\u6027\u80fd\u3042\u304c\u3063\u305f\u6c17\u304c\u3059\u308b\n\n\n\u30e2\u30c7\u30eb\u306f\u3084\u3063\u3071\u308aCNN\u306b\u3059\u308b\u3079\u304d\u3060\u3063\u305f\n\n\nFCNN\u306f\u904e\u5b66\u7fd2\u304c\u8d77\u304d\u3084\u3059\u3044\u3089\u3057\u3044\u3058\u3083\u306a\u3044\u3067\u3059\u304b\nChainer\u306eConvoltional2D \u306e\u5f15\u6570\u306e\u95a2\u4fc2\u6027\u304c\u7406\u89e3\u3067\u304d\u306a\u304b\u3063\u305f\u304b\u3089\u3001\u3082\u3063\u3068\u52c9\u5f37\u3057\u306a\u304d\u3083\n\n\n\u691c\u51fa\u30d7\u30ed\u30b0\u30e9\u30e0\u306b\u30a4\u30e1\u30fc\u30b8\u30cf\u30a4\u30e9\u30eb\u30ad\u30fc\u3092\u5b9f\u88c5\u3057\u305f\u307b\u3046\u304c\u3088\u304b\u3063\u305f\n\n\n\u7a93\u306e\u5927\u304d\u3055\u304c\u30d2\u30e5\u30fc\u30ea\u30b9\u30c6\u30a3\u30c3\u30af\u306b\u6c7a\u307e\u3063\u3066\u3044\u305f\u306e\u304c\u3061\u3087\u3063\u3068\u3002 \n\n\n\n\n\u6700\u5f8c\u306b\n\u3082\u3063\u3068\u6642\u9593\u304c\u78ba\u4fdd\u3067\u304d\u305f\u3089\u3001\u5931\u6557\u3057\u305f\u7406\u7531\u3092\u304d\u3061\u3093\u3068\u62ed\u3063\u3066\u3001\u3061\u3083\u3093\u3068\u30a6\u30a9\u30fc\u30ea\u30fc\u691c\u51fa\u5668\u3064\u304f\u308a\u305f\u3044\u3067\u3059\u3002\n\u73fe\u72b6\u306e\u30b3\u30fc\u30c9\u306f\u3001Github\u306b\u30a2\u30c3\u30d7\u3057\u3066\u3044\u307e\u3059\u3002\n\u826f\u304b\u3063\u305f\u3089\u30b3\u30e1\u30f3\u30c8\u3044\u305f\u3060\u3051\u308b\u3068\u5e78\u3044\u3067\u3059\u3002\n\u306f\u3058\u3081\u307e\u3057\u3066\u3001Shunter\u3067\u3059\u3002\n\n\u5f53\u65b9\u300110\u6708\u304b\u3089\u6a5f\u68b0\u5b66\u7fd2/\u4eba\u5de5\u77e5\u80fd\u306b\u3064\u3044\u3066\u52c9\u5f37\u3092\u3057\u3066\u3044\u308b\u304a\u3058\u3055\u3093\u3067\u3059\u3002\n\n\u6628\u4eca\u306e Deep Learning \u30d6\u30fc\u30e0\u306b\u4e57\u3063\u304b\u3063\u3066\u30a2\u30eb\u30b4\u30ea\u30ba\u30e0\u306e\u52c9\u5f37\u3068\u5e73\u884c\u3057\u3066\u30d5\u30ec\u30fc\u30e0\u30ef\u30fc\u30af\u3067\u904a\u3076\u3053\u3068\u3092\u3057\u3066\u304d\u307e\u3057\u305f\u3002\u3044\u308d\u3044\u308d\u8a66\u3059\u306a\u304b\u3067\u3001\u632b\u6298\u3057\u306a\u304c\u3089\u3082Chainer\u304c\u552f\u4e00\u300c\u3053\u308c\u306a\u3089\u3044\u3051\u308b\uff01\u300d\u3068\u601d\u308f\u305b\u3066\u304f\u308c\u305f\u30d5\u30ec\u30fc\u30e0\u30ef\u30fc\u30af\u3067\u3059\u3002\n\n\u56fd\u7523\u3060\u3057(Ruby\u597d\u304d\u3001\u540c\u3058\u306b\u304a\u3044\u611f\u3058\u308b)\u3001\u74b0\u5883\u69cb\u7bc9\u3067\u5168\u7136\u3064\u307e\u3065\u304b\u306a\u304b\u3063\u305f\u3057\u3001\u672c\u5bb6\u30c9\u30ad\u30e5\u30e1\u30f3\u30c8\u30c1\u30e5\u30fc\u30c8\u30ea\u30a2\u30eb\u3082\u89aa\u5207\u3067\u3001\u3068\u3063\u3064\u304d\u3084\u3059\u304b\u3063\u305f\u3067\u3059\u3002\n\n\u81ea\u5206\u3092\u596e\u3044\u7acb\u305f\u305b\u308b\u305f\u3081\u306b\u3082\u3001\u30a2\u30c9\u30d9\u30f3\u30c8\u30ab\u30ec\u30f3\u30c0\u30fc\u306b\u53c2\u52a0\u3057\u3066\u306a\u306b\u304b\u4f5c\u308d\u3046\u3068\u601d\u3044\u3001\u672c\u8a18\u4e8b\u3092\u66f8\u3044\u3066\u3044\u307e\u3059\u3002\n\n\u7d50\u679c\u304b\u3089\u8a00\u3046\u3068**\u5931\u6557\u3057\u307e\u3057\u305f**\u3002\u305d\u306e\u8ecc\u8de1\u3092\u5171\u6709\u3067\u304d\u308c\u3070\u5e78\u3044\u3067\u3059\u3002\n\n# \u4f5c\u308a\u305f\u304b\u3063\u305f\u3082\u306e\n \n\u30a6\u30a9\u30fc\u30ea\u30fc\u3092\u63a2\u305b\u3092\u6a5f\u68b0\u5b66\u7fd2\u3067\u3084\u308b\uff01\n\n\u753b\u50cf\u3092\u5165\u529b\u3059\u308b\u3068\u305d\u306e\u306a\u304b\u304b\u3089\u30a6\u30a9\u30fc\u30ea\u30fc\u3092\u63a2\u3057\u3060\u3057\u3066\u304f\u308c\u308b\u3082\u306e\u3067\u3059\u3002\n\n## \u30c7\u30fc\u30bf\u53ce\u96c6\n\n### \u6b63\u89e3\u30c7\u30fc\u30bf\n\n\u306f\u3058\u3081\u306b\u3001\u30a6\u30a9\u30fc\u30ea\u30fc\u3092\u5b66\u3070\u305b\u307e\u3059\u3002\n\n\u7406\u60f3\u3092\u8a00\u3048\u3070\u672c\u5f53\u306e\u6b63\u89e3\u304c\u6b32\u3057\u3044\u3068\u3053\u308d\u306a\u3093\u3067\u3059\u304c\u3001\n\u306a\u304b\u306a\u304b\u6b63\u89e3\u30c7\u30fc\u30bf\u304c\u3042\u308a\u307e\u305b\u3093\u3002\n\n\u30a6\u30a9\u30fc\u30ea\u30fc\u306e\u9854\u3068\u3044\u3048\u3070\u3053\u3061\u3089\u3002\n\n`positive_images/1.png`\n<img width=\"139\" alt=\"1.png\" src=\"https://qiita-image-store.s3.amazonaws.com/0/57586/1bb2d54a-1d9e-b5b1-0b5c-e3ea1bbcfa28.png\">\n`positive_images/2.png`\n<img width=\"111\" alt=\"2.png\" src=\"https://qiita-image-store.s3.amazonaws.com/0/57586/74997f36-1705-9fd8-edef-5e1935b881b2.png\">\n`positive_images/3.png`\n<img width=\"56\" alt=\"3.png\" src=\"https://qiita-image-store.s3.amazonaws.com/0/57586/4676d401-83a8-bf82-9b32-2946d57aaa0f.png\">\n`positive_images/4.png`\n<img width=\"56\" alt=\"4.png\" src=\"https://qiita-image-store.s3.amazonaws.com/0/57586/d33cb06f-a86c-e3ba-fa23-6c83d41f6327.png\">\n`positive_images/5.png`\n<img width=\"47\" alt=\"5.png\" src=\"https://qiita-image-store.s3.amazonaws.com/0/57586/16f0a887-91b0-8134-58c3-e4f482466834.png\">\n\n\u5927\u91cf\u306b\u30c7\u30fc\u30bf\u304c\u6b32\u3057\u3044\u3068\u3053\u308d\u306a\u306e\u3067\u3059\u304c\u3001\u3053\u308c\u3089\u3092\u4f7f\u3063\u3066\u30c7\u30fc\u30bf\u3092\u751f\u6210\u3057\u307e\u3057\u305f\u3002\n\u30c7\u30fc\u30bf\u751f\u6210\u306f\u3001openCV\u306e\u3000createsamples \u3092\u4f7f\u3063\u3066\u3044\u307e\u3059\u3002\n\n\u53c2\u8003\nhttp://www.pro-s.co.jp/engineerblog/opencv/post_6397.html\n\n\u203b\uff08\u3048\u3001OpenCV\u3067\u30a6\u30a9\u30fc\u30ea\u30fc\u63a2\u305b\u3070\u3044\u3044\u3058\u3083\u3093\uff01\u3068\u3044\u3046\u30c4\u30c3\u30b3\u30df\u306f\u306a\u3057\u3067...\uff09 \n\nopencv_createsamples \u306f\u753b\u50cf\u3092\u8aad\u307f\u8fbc\u3093\u3067\u3001\u753b\u50cf\u3092\u6b6a\u307e\u305b\u3066\u3001.vec\u30d5\u30a1\u30a4\u30eb\u306b\u3057\u3066\u304f\u308c\u307e\u3059\u3002\n\n```bash\necho 'generate sample from postive image'\n\nfor file in ./positive_images/* \ndo\n\tsub=${file##*/}\n\tnum=${sub%.*}\n\topencv_createsamples -img $file -vec ./vectors/positive/$num.vec -maxxangle 0.2 -maxyangle 0.2 -maxzangle 0.2 -w 32 -h 32\ndone\n```\n\nvec\u30d5\u30a1\u30a4\u30eb\u3060\u3068\u3001Chainer\u3067\u6271\u3044\u3065\u3089\u305d\u3046\u306a\u306e\u3067\uff08\u5b9f\u614b\u304c\u3088\u304f\u308f\u304b\u3063\u3066\u306a\u3044\u306e\u3067\uff09vec\u3092\u753b\u50cf\u306b\u3057\u3066\u4fdd\u5b58\u3057\u307e\u3059\u3002\n\n\u307e\u305f\u3001\u6b6a\u307f\u3067\u3082\u5ea7\u6a19\u7684\u306b\u3086\u3089\u304e\u304c\u304a\u3053\u3089\u306a\u3044\u306e\u3067\u3001\u5927\u304d\u3081\u306b\u753b\u50cf\u3092\u4f5c\u3063\u3066\u3001\u305d\u3053\u304b\u3089\u30de\u30fc\u30b8\u30f3\u3092\u30e9\u30f3\u30c0\u30e0\u306b\u8a2d\u5b9a\u3057\u3066\u7e26\u6a2a\u3067\u3086\u3089\u304e\u304c\u8d77\u304d\u308b\u3088\u3046\u306b\u3057\u3066\u3044\u307e\u3059\u3002\n\n```bash\necho 'convert positive vector to images'\n\nfor file in ./vectors/positive/* \ndo\n\tpython showvec.py -i $file -f positive \ndone\n```\n\n```showvec.py\nimport struct,array\nimport os\nimport cv2\nimport numpy as np\nimport argparse\nimport random\n\nparser = argparse.ArgumentParser(\n    description='A Converter from Vector to Images')\nparser.add_argument('--img', '-i', default='', help='path of input image')\nparser.add_argument('--folder', '-f', default='', help='name of parent folder')\nargs = parser.parse_args()\n\ndef showvec(fn, width=32, height=32, resize=1.0):\n  f = open(fn,'rb')\n  HEADERTYP = '<iihh' # img count, img size, min, max\n\n  # read header\n  imgcount,imgsize,_,_ = struct.unpack(HEADERTYP, f.read(12))\n\n  for i in range(imgcount):\n    img  = np.zeros((height,width),np.uint8)\n\n    f.read(1) # read gap byte\n    data = array.array('h')\n    data.fromfile(f,imgsize)\n    for r in range(height):\n      for c in range(width):\n        img[r,c] = data[r * width + c]\n\n    img = cv2.resize(img, (0,0), fx=resize, fy=resize, interpolation=cv2.INTER_LINEAR)\n    rand_x = random.randint(0, (32-28))\n    rand_y = random.randint(0, (32-28))\n    clopped_img = img[rand_x:rand_x+28, rand_y:rand_y+28]\n    filename = \"./data/\" + args.folder + \"/\" + fn.split(\"/\")[-1].replace(\".vec\",\"\") + \"_\" + str(i) + \".png\"\n    cv2.imwrite(filename, clopped_img)\n    \nshowvec(args.img)\n```\n\n\u3059\u308b\u3068\u4ee5\u4e0b\u306e\u69d8\u306a\u753b\u50cf\u304c5000\u679a\u751f\u6210\u3055\u308c\u307e\u3059\u3002\n\n`data/positive/*.png`\n![1_3.png](https://qiita-image-store.s3.amazonaws.com/0/57586/667653ec-30cd-dd65-56b9-bf4d6e6dd9b3.png)\n![1_41.png](https://qiita-image-store.s3.amazonaws.com/0/57586/f17eabaf-789a-97c2-30a9-40c4501faa97.png)\n![1_77.png](https://qiita-image-store.s3.amazonaws.com/0/57586/5d9e46a3-f9ad-fde5-a1e7-1880c7ad147d.png)\n![1_99.png](https://qiita-image-store.s3.amazonaws.com/0/57586/6e7356e8-c12a-0a14-7081-4534c15bff7f.png)\n![1_115.png](https://qiita-image-store.s3.amazonaws.com/0/57586/15e72a3d-1ad8-fda0-5a1f-9af14ad94f3f.png)\n...\n\n### \u5931\u6557\u30c7\u30fc\u30bf\n\n\u3053\u3053\u3067\u306f\u3001\u30a6\u30a9\u30fc\u30ea\u30fc\u3067\u306a\u3044\u753b\u50cf\u304c\u6b32\u3057\u3044\u306e\u3067\u3001\u9069\u5f53\u306a\u753b\u50cf\u3092\u8aad\u307f\u8fbc\u3093\u3067\n\u3001\u30e9\u30f3\u30c0\u30e0\u306b\u30b0\u30ec\u30fc\u30b9\u30b1\u30fc\u30eb\u3092\u3057\u306628x28\u306e\u9818\u57df\u3092\u9078\u3093\u3067\u753b\u50cf\u3068\u3057\u3066\u5207\u308a\u51fa\u3057\u3066\u3044\u307e\u3059\u3002\n\n``` generate_negative.py\nimport cv\nimport cv2\nimport random \nimport numpy as np\n\nimg = cv2.imread('/path/to/image/you_want_to_crop')\nwidth, height, channels = img.shape\nimg = cv2.cvtColor(img, cv2.cv.CV_BGR2GRAY)\n\nwsize = 28\ngennum = 16000\n\nnp.asarray(img)\n\nfor i in range(gennum):\n  x = random.randint(0,width - wsize)\n  y = random.randint(0,height - wsize)\n  cropped_img = img[x:x+wsize, y:y+wsize]\n  filename = \"./data/negative/\"+str(i)+\".png\"\n  cv2.imwrite(filename, cropped_img)\n\n```\n\n16000\u679a\u306e\u30e9\u30f3\u30c0\u30e0\u306a\u753b\u50cf\u304c\u751f\u6210\u3055\u308c\u307e\u3059\u3002\n\n`data/negative/*.png`\n![1.png](https://qiita-image-store.s3.amazonaws.com/0/57586/45577760-a425-4624-e990-caf69ecae1ab.png)\n![167.png](https://qiita-image-store.s3.amazonaws.com/0/57586/26a2578c-523d-fbc5-b13f-9694e8667059.png)\n![172.png](https://qiita-image-store.s3.amazonaws.com/0/57586/388643e7-cd08-c9a2-378d-e7dcf73c9eab.png)\n![187.png](https://qiita-image-store.s3.amazonaws.com/0/57586/6c5a3a9e-172b-66ca-f340-aa4f7e6e49ee.png)\n![191.png](https://qiita-image-store.s3.amazonaws.com/0/57586/c4dcb56f-cfb9-486b-da0e-93af334827d2.png)\n...\n\n## \u753b\u50cf\u3092Python\u306e\u30aa\u30d6\u30b8\u30a7\u30af\u30c8\u306b... \n\n\u57fa\u672c\u7684\u306b\u306fPython\u306e\u5909\u6570\u304b\u3089\u3044\u308d\u3044\u308d\u30b4\u30cb\u30e7\u30b4\u30cb\u30e7\u3059\u308b\u306e\u3067\u3001\n\u305d\u3046\u3067\u304d\u308b\u3088\u3046\u306b\u3001\u7528\u610f\u3057\u305f\u753b\u50cf\u3092numpy\u30aa\u30d6\u30b8\u30a7\u30af\u30c8\u5316\u3057\u3001\n\u6b63\u89e3\u30c7\u30fc\u30bf\u3068\u4e00\u7dd2\u306bPython\u306e\u30aa\u30d6\u30b8\u30a7\u30af\u30c8\u306b\u683c\u7d0d\u3057\u3001pickle\u5316\u3057\u3066\u3044\u307e\u3059\u3002\n\n```generate_pickle.py\nimport cv\nimport cv2\nimport numpy as np\nimport os\nimport glob\nfrom six.moves import cPickle\n\nstack = []\n\ndata_dictionary = {\"data\":[], \"label\":[]}\n\ndef pack_image_into_data(dir, label, stack):\n\n\tpath = './data/' + dir + '/*.png'\n\timages = glob.glob(path)\n\tfor img_name in images : \n\t\timg = cv2.imread(img_name)\n\t\tresized_img = cv2.resize(img, (28, 28))\n\t\timage_gray = cv2.cvtColor(resized_img, cv2.cv.CV_BGR2GRAY)\n\t\tnpimage = np.asarray(image_gray).reshape(1,784)[0]\n\t\tnpimage = npimage/255.\n\t\tstack.append((npimage, label))\n\treturn stack\n\nstack = pack_image_into_data(\"negative\", 0, stack)\nstack = pack_image_into_data(\"positive\", 1, stack)\nstack = np.asarray(stack)\n\nnp.random.shuffle(stack)\nstack = stack.tolist()\nfor t in stack :\n\tdata_dictionary[\"data\"].append(t[0])  \t\n\tdata_dictionary[\"label\"].append(t[1])  \t\n\nwith open('data.pkl', 'wb') as output:\n  cPickle.dump(data_dictionary, output, -1)\n  print data_dictionary[\"data\"][0].shape\n  print data_dictionary[\"label\"][0]\n  print \"Saved \", len(data_dictionary[\"data\"]), \" images with \", len(data_dictionary[\"label\"]), \" labels.\"\n```\n\n## \u30e2\u30c7\u30eb\u306e\u5b66\u7fd2\n\n**Chainer\u306e\u51fa\u756a\u3067\u3059\uff01**\n\n\u753b\u50cf\u8a8d\u8b58\u306b\u3064\u3044\u3066\u306fCNN\u3092\u7d44\u3080\u307b\u3046\u304c\u826f\u3044\u3068\u3044\u3046\u306e\u304c\u4e00\u822c\u7684\u3067\u3059\u304c\u3001\n12\u6708\u6bb5\u968e\u3067\u52c9\u5f37\u304c\u304a\u3063\u3064\u3044\u3066\u304a\u3089\u305a\u3001MNIST\u306e\u6587\u5b57\u8a8d\u8b58\u3068\u540c\u3058\u3088\u3046\u306b\n28x28\u306e\u5165\u529b\u304b\u3089\u3059\u3079\u3066\u5168\u7d50\u5408\u5c64\u306e\uff14\u5c64\u30cb\u30e5\u30fc\u30e9\u30eb\u30cd\u30c3\u30c8\u30ef\u30fc\u30af\u3092\u7d44\u3093\u3067\u3057\u307e\u3057\u307e\u3057\u305f\u3002\n\n\u5b9f\u969b\u306eChainer\u306e\u30b3\u30fc\u30c9\n\n``` train.py\nfrom six.moves import cPickle\nimport numpy as np\nimport argparse\nfrom chainer import cuda, Variable, FunctionSet, optimizers\nimport chainer.functions  as F\nimport matplotlib.pyplot as plt\nimport pdb\nimport six\n\n\ndef unpickle(file):\n    fo = open(file, 'rb')\n    dict = cPickle.load(fo)\n    fo.close()\n    return dict\n\nall_data = unpickle(\"./data.pkl\")\nx_all = np.asarray(all_data[\"data\"]).astype(np.float32)\ny_all = np.asarray(all_data[\"label\"]).astype(np.int32)\n\nx_train, x_test = np.split(x_all, [18000])\ny_train, y_test = np.split(y_all, [18000])\n\n## Build Model\nmodel = FunctionSet( \n  l1 = F.Linear(784, 200),\n  l2 = F.Linear(200, 80),\n  l3 = F.Linear(80, 20),\n  l4 = F.Linear(20, 2)\n)\n\noptimizer = optimizers.SGD()\noptimizer.setup(model)\n\ndef forward(x_data, y_data):\n  x = Variable(x_data)\n  t = Variable(y_data)\n  h1 = F.relu(model.l1(x))\n  h2 = F.relu(model.l2(h1))\n  h3 = F.relu(model.l3(h2))\n  y = model.l4(h3)\n  return F.softmax_cross_entropy(y, t), F.accuracy(y, t)\n\naccuracy_data = []\n\nbatchsize = 1000\ndatasize = 18000  \nfor epoch in range(40):\n  print('epoch %d' % epoch)\n  indexes = np.random.permutation(datasize)\n  for i in range(0, datasize, batchsize):\n    x_batch = x_train[indexes[i : i + batchsize]]\n    y_batch = y_train[indexes[i : i + batchsize]]\n    optimizer.zero_grads()\n    loss, accuracy = forward(x_batch, y_batch)\n    loss.backward()\n    accuracy_data.append(accuracy.data)\n    optimizer.update()\n\nsum_loss, sum_accuracy = 0, 0\n\nplt.plot(accuracy_data, 'k--')\nplt.show()\nplt.savefig(\"accuracy.png\")\n\nfor i in range(0, 3000, batchsize):\n  x_batch = x_test[i : i + batchsize]\n  y_batch = y_test[i : i + batchsize]\n  loss, accuracy = forward(x_batch, y_batch)\n  sum_loss      += loss.data * batchsize\n  sum_accuracy  += accuracy.data * batchsize\n\nmean_loss     = sum_loss / 3000\nmean_accuracy = sum_accuracy / 3000\n\nprint('mean_loss %.2f' % mean_loss)\nprint('mean_accuracy %d' % (mean_accuracy * 100))\n\nif (mean_accuracy * 100) > 90:\n  with open('trained_model.pkl', 'wb') as output:\n    six.moves.cPickle.dump(model, output, -1)\n    print \"model has saved, it has enough quality as trained model :)\"\n```\n\n\u5b66\u7fd2\u3057\u305f\u30e2\u30c7\u30eb\u306f\u3001pickle\u3092\u4f7f\u3063\u3066\u3001`trained_model.pkl`\u3068\u3057\u3066\u30b7\u30ea\u30a2\u30e9\u30a4\u30ba\u3057\u3066\u3044\u307e\u3059\u3002\n\n## \u691c\u51fa\n\n\u672c\u3092\u8cb7\u3044\u307e\u3057\u305f\uff01\n\n![IMG_3287.JPG](https://qiita-image-store.s3.amazonaws.com/0/57586/e71efb1b-9c72-0964-d930-63e7d794d46e.jpeg)\n\n\u753b\u50cf\u3092\u30b9\u30ad\u30e3\u30f3\u3057\u3066 ... \n\n![3.jpg](https://dl.dropboxusercontent.com/u/5738192/img/3.jpg)\n\n\u691c\u51fa\u306e\u30d7\u30ed\u30b0\u30e9\u30e0\u3092\u66f8\u3044\u3066\u307f\u307e\u3057\u305f\u3002\n\n```detect.py\nimport cv\nimport cv2\nimport numpy as np\nfrom chainer import cuda, Function, FunctionSet, gradient_check, Variable, optimizers, utils\nimport chainer.functions as F\nimport six\nimport argparse\nimport sliding_window as sw\nfrom PIL import Image\nfrom PIL import ImageOps\n\nparser = argparse.ArgumentParser(\n    description='A Neural Algorithm of Artistic Style')\nparser.add_argument('--img', '-i', default='',\n                    help='path of input image')\nargs = parser.parse_args()\n\nwith open('trained_model.pkl', 'rb') as model_pickle:\n  model = six.moves.cPickle.load(model_pickle)\n\nratio = 0.7\n\ndef forward(x_data):\n  x = Variable(x_data)\n  h1 = F.relu(model.l1(x))\n  h2 = F.relu(model.l2(h1))\n  h3 = F.relu(model.l3(h2))\n  y = F.softmax(model.l4(h3))\n  return y\n\nimg = Image.open(args.img)\n(iw, ih) = img.size\nprint iw\nprint ih\n\nnew_width = int(iw*ratio) \nnew_height = int(ih*ratio)\nprint new_width\nprint new_height\n\noriginal_img = cv2.imread(args.img)\n\noriginal_img = cv2.resize(original_img, (new_width, new_height))\n\nimg = cv2.cvtColor(original_img, cv2.cv.CV_BGR2GRAY)\nimg = np.asarray(img).astype(np.float32) / 255.\n\ndef judge(array, r, c, wsize):\n\n  xd = np.asarray(array).reshape((1,784)).astype(np.float32)\n  yd = forward(xd).data[0]\n  prob = yd[1]/(yd[0]+yd[1])\n  threshold = 0.8\n  if(prob > threshold):\n    print \"------ detected (\" + str(c) + \",\" + str(r) + \")  P(\" + str(prob) + \" )-------------\"\n    cv2.rectangle(original_img, (c, r), (c+wsize, r+wsize), (0,255,0), 3) \n\nsw.slide_window(img, 28, 14, judge)\n\ncv2.imwrite('./result.png',original_img)\ncv2.imshow('img',original_img)\ncv2.waitKey(0)\ncv2.destroyAllWindows()\n\n```\n\n\u3084\u3063\u3066\u3044\u308b\u3053\u3068\u306f...\n1. \u5b66\u7fd2\u3055\u305b\u305f\u30e2\u30c7\u30eb\u306e\u8aad\u307f\u8fbc\u307f\n2. \u753b\u50cf\u309228x28\u304c\u9854\u306e\u5927\u304d\u3055\u306b\u306a\u308b\u3088\u3046\u306b\u7e2e\u5c0f\uff08ratio\u3067\u30cf\u30fc\u30c9\u30b3\u30fc\u30c7\u30a3\u30f3\u30b0) \n3. Sliding Window\u306728x28\u306e\u7a93\u3092\u8d70\u3089\u305b\u3001\u30a6\u30a9\u30fc\u30ea\u30fc\u3060\u3063\u305f\u3089\u56db\u89d2\u3092\u5143\u753b\u50cf\u306b\u66f8\u304d\u3053\u3080\n4. \u5143\u753b\u50cf + \u56db\u89d2 \u3092\u753b\u50cf\u3068\u3057\u3066\u66f8\u304d\u51fa\u3057\n\n\u7d50\u679c\u306f\u4ee5\u4e0b\u306e\u3068\u304a\u308a\u3067\u3059\u3002\n\n![result.jpg](https://dl.dropboxusercontent.com/u/5738192/img/result.png)\n\n\u9ec4\u7dd1\u8272\u306e\u56db\u89d2\u304c\u691c\u51fa\u3057\u305f\u5834\u6240\u3067\u3059\u3002\n\n**\u5931\u6557!!** \n\n## \u306a\u305c\u5931\u6557\uff1f \u81ea\u5206\u306a\u308a\u306b\u7406\u7531\u3092\u8003\u3048\u305f\n\n\u6642\u9593\u7684\u306b\u4f59\u88d5\u304c\u306a\u304b\u3063\u305f\u306e\u3067\u3001\u7406\u60f3\u7684\u306b\u3069\u3046\u3059\u308b\u3079\u304d\u304b\u3092\u8e0f\u307e\u3048\u3066\u3044\u304f\u3064\u304b\u3002\n\n- \u672c\u5f53\u306f\uff11\u518a\u81ea\u529b\u3067\u30a6\u30a9\u30fc\u30ea\u30fc\u3092\u63a2\u3057\u3066\u3001\u305d\u308c\u3092\u6b63\u89e3\u30c7\u30fc\u30bf\u306b\u542b\u3081\u308b\u3079\u304d\u3060\u3063\u305f\u3002\n  - \u6b63\u89e3\u30c7\u30fc\u30bf\u304c\u5168\u90e8\u771f\u6b63\u9762\u3067\u6c4e\u5316\u6027\u80fd\u843d\u3061\u3066\u308b\u306f\u305a\n  - \u3057\u307e\u3057\u307e\u306b\u53cd\u5fdc\u3057\u3066\u3044\u308b\u306e\u306f\u3001\u30a6\u30a9\u30fc\u30ea\u30fc\u306e\u6b63\u89e3\u30c7\u30fc\u30bf\u306e2/5\u304c\u80cc\u666f\u30dc\u30fc\u30c0\u3060\u3063\u305f\u304b\u3089\u304b\u306a\u3068\u601d\u3046\n- \u672c\u5f53\u306f\u3001\u6b63\u89e3\u30c7\u30fc\u30bf\u3092\u5897\u3084\u3059\u30d7\u30ed\u30b0\u30e9\u30e0\u3082\u81ea\u5206\u3067\u66f8\u304f\u3079\u304d\u3060\u3063\u305f\n  - \u8272\u30c7\u30fc\u30bf\u6b8b\u3057\u305f\u304b\u3063\u305f\n  - \u30db\u30ef\u30a4\u30c8\u30ce\u30a4\u30ba\u52a0\u3048\u305f\u304b\u3063\u305f\n  - Z\u8ef8\u306e\u56de\u8ee2\u306b\u3088\u308b\u6b6a\u307f\uff08opencv_createsamples\u304c\u3084\u3063\u3066\u304f\u308c\u308b\uff09\u3092\u52a0\u3048\u3089\u308c\u305f\u3089\u3001\u9854\u306e\u5411\u304d\u306b\u5bfe\u3059\u308b\u6c4e\u5316\u6027\u80fd\u3042\u304c\u3063\u305f\u6c17\u304c\u3059\u308b\n- \u30e2\u30c7\u30eb\u306f\u3084\u3063\u3071\u308aCNN\u306b\u3059\u308b\u3079\u304d\u3060\u3063\u305f\n  - FCNN\u306f\u904e\u5b66\u7fd2\u304c\u8d77\u304d\u3084\u3059\u3044\u3089\u3057\u3044\u3058\u3083\u306a\u3044\u3067\u3059\u304b\n  - Chainer\u306eConvoltional2D \u306e\u5f15\u6570\u306e\u95a2\u4fc2\u6027\u304c\u7406\u89e3\u3067\u304d\u306a\u304b\u3063\u305f\u304b\u3089\u3001\u3082\u3063\u3068\u52c9\u5f37\u3057\u306a\u304d\u3083\n- \u691c\u51fa\u30d7\u30ed\u30b0\u30e9\u30e0\u306b\u30a4\u30e1\u30fc\u30b8\u30cf\u30a4\u30e9\u30eb\u30ad\u30fc\u3092\u5b9f\u88c5\u3057\u305f\u307b\u3046\u304c\u3088\u304b\u3063\u305f\n  - \u7a93\u306e\u5927\u304d\u3055\u304c\u30d2\u30e5\u30fc\u30ea\u30b9\u30c6\u30a3\u30c3\u30af\u306b\u6c7a\u307e\u3063\u3066\u3044\u305f\u306e\u304c\u3061\u3087\u3063\u3068\u3002 \n\n## \u6700\u5f8c\u306b\n\n\u3082\u3063\u3068\u6642\u9593\u304c\u78ba\u4fdd\u3067\u304d\u305f\u3089\u3001\u5931\u6557\u3057\u305f\u7406\u7531\u3092\u304d\u3061\u3093\u3068\u62ed\u3063\u3066\u3001\u3061\u3083\u3093\u3068\u30a6\u30a9\u30fc\u30ea\u30fc\u691c\u51fa\u5668\u3064\u304f\u308a\u305f\u3044\u3067\u3059\u3002\n\n\u73fe\u72b6\u306e\u30b3\u30fc\u30c9\u306f\u3001[Github](https://github.com/shunter1112/wally_detector)\u306b\u30a2\u30c3\u30d7\u3057\u3066\u3044\u307e\u3059\u3002\n\n\u826f\u304b\u3063\u305f\u3089\u30b3\u30e1\u30f3\u30c8\u3044\u305f\u3060\u3051\u308b\u3068\u5e78\u3044\u3067\u3059\u3002\n\n \n", "tags": ["MachineLearning", "Chainer", "AdventCalendar2015"]}