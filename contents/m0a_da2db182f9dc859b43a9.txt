{"context": " More than 1 year has passed since last update.\n\n\u306f\u3058\u3081\u306b\ncoursera\u306eMachine Learning(\u6a5f\u68b0\u5b66\u7fd2)\u5b66\u3093\u3060\u3053\u3068\u30e1\u30e2(1)\u306e\u7d9a\u304d\u3067\u3059\u3002\n\u524d\u56de\u306f\u7dda\u5f62\u56de\u5e30\u30e2\u30c7\u30eb\u3068\u30ed\u30b8\u30b9\u30c6\u30a3\u30c3\u30af\u56de\u5e30\u30e2\u30c7\u30eb\u307e\u3067\u3067\u3057\u305f\u3002\n\u4eca\u56de\u306f\u81ea\u5206\u304c\u5143\u3005\u52c9\u5f37\u3057\u305f\u304b\u3063\u305fNN(\u30cb\u30e5\u30fc\u30e9\u30eb\u30cd\u30c3\u30c8\u30ef\u30fc\u30af)\u3067\u3059\u3002\n\u5b66\u7fd2\u4e2d\u3044\u304d\u306a\u308a\u6587\u5b57\u8a8d\u8b58(OCR)\u306e\u5b9f\u88c5\u306b\u89e6\u308b\u3053\u3068\u306b\u306a\u308b\u306e\u3067\u30c6\u30f3\u30b7\u30e7\u30f3\u304c\u4e0a\u308a\u307e\u3059\u3002\n\u624b\u52d5\u3067\u5b9f\u88c5\u3057\u3088\u3046\u3068\u3059\u308b\u3068\u5168\u304f\u60f3\u50cf\u304c\u3064\u304b\u306a\u3044\u6587\u5b57\u8a8d\u8b58\u3067\u3059\u304c\u3001NN\u3092\u4f7f\u3044\u3001\u6a5f\u68b0\u5b66\u7fd2\u3092\u884c\u3046\u3053\u3068\u3067\u3001\u7c21\u5358\u306b\u5b9f\u88c5\u3067\u304d\u3066\u3057\u307e\u3044\u611f\u52d5\u3057\u307e\u3059\u3002\n\u6b63\u76f4\u4e00\u3064\u4e00\u3064\u306e\u6570\u5f0f\u306f\u4e01\u5be7\u306b\u8aac\u660e\u3057\u3066\u304f\u308c\u308b\u306e\u3067\u306a\u3093\u3068\u304b\u7406\u89e3\u3067\u304d\u308b\u306e\u3067\u3059\u304c(\u4e00\u90e8\u306e\u504f\u5fae\u5206\u306f\u9664\u304f)\n\u6700\u7d42\u7684\u306b\u51fa\u6765\u4e0a\u304c\u308b\u52d5\u4f5c\u306f\u306a\u3093\u3067\u52d5\u304f\u3093\u3060\u30fc\u3063\u3068\u601d\u3063\u3066\u3057\u307e\u3044\u307e\u3059\u3002\n\u8133\u3063\u3066\u4e0d\u601d\u8b70\u3067\u3059\u3002\n\n\u30cb\u30e5\u30fc\u30e9\u30eb\u30cd\u30c3\u30c8\u30ef\u30fc\u30af\n\u30d1\u30e9\u30e1\u30fc\u30bf\u306e\u6570\u304c\u81a8\u5927\u306b\u5897\u3048\u305f\u308a\u3057\u305f\u5834\u5408\u306e\u5206\u985e\u306e\u554f\u984c\u3092\u30ed\u30b8\u30b9\u30c6\u30a3\u30c3\u30af\u56de\u5e30\u3067\u89e3\u304f\u306b\u306f\u9650\u754c\u304c\u6765\u307e\u3059\u3002\n\u305d\u306e\u305f\u3081\u306b\u3053\u306eNN\u3092\u4f7f\u3044\u307e\u3059\u3002\n\n$a^{(j)}_i$ activation(\u51fa\u529b) of unit i in layer j\n$x_0$,$a_0$\u306f\u30d0\u30a4\u30a2\u30b9\u30e6\u30cb\u30c3\u30c8\u3067\u5e38\u306b1\u3092\u53d6\u308a\u307e\u3059\u3002\n$\\theta^{(j)}$ \u306f\u91cd\u307f\u3065\u3051\u5236\u5fa1\u306e\u305f\u3081\u306e\u884c\u5217 layer j (input)\u304b\u3089layer j+1(output)\u306e\u30de\u30c3\u30d4\u30f3\u30b0\u306b\u5bfe\u5fdc\n$a_1^{(2)} = g(\\theta_{1,0}^{(1)} \\cdot x_0 + \\theta_{1,1}^{(1)} \\cdot x_1  + \\theta_{1,2}^{(1)} \\cdot x_2 + \\theta_{1,3}^{(1)} \\cdot x_3  )$\n$a_2^{(2)} = g(\\theta_{2,0}^{(1)} \\cdot x_0 + \\theta_{2,1}^{(1)} \\cdot x_1  + \\theta_{2,2}^{(1)} \\cdot x_2 + \\theta_{2,3}^{(1)} \\cdot x_3  )$\n$a_3^{(2)} = g(\\theta_{3,0}^{(1)} \\cdot x_0 + \\theta_{3,1}^{(1)} \\cdot x_1  + \\theta_{3,2}^{(1)} \\cdot x_2 + \\theta_{3,3}^{(1)} \\cdot x_3  )$\n$h_\\theta (x) = a_1^{(3)} = g(\\theta_{3,0}^{(2)} \\cdot a_0^{(2)} + \\theta_{3,1}^{(2)} \\cdot a_1^{(2)}  + \\theta_{3,2}^{(2)} \\cdot a_2^{(2)} + \\theta_{3,3}^{(2)} \\cdot a_3^{(2)} )$\nnetwork\u306b\u3064\u3044\u3066\u3001layer j\u306e\u30e6\u30cb\u30c3\u30c8\u6570\u304c$s_{j}$\u500b\u3067\u3001layer j+1 \u306e\u30e6\u30cb\u30c3\u30c8\u6570\u304c $s_{(j+1)}$\u500b\u306e\u5834\u5408\u3001\n$\\theta^{(j)}$ \u306f $(s_{(j+1)}) \\times (s_{j}+1)$\u6b21\u5143\u306e\u884c\u5217\n\n\u30b3\u30b9\u30c8\u95a2\u6570(cost function)\n\n\u4e0a\u8a18\u306e\u3088\u3046\u306aNN\u3092\u8003\u3048\u307e\u3059\u3002\nLayer\u6570L\u3092\u5b9a\u7fa9\u3057\u307e\u3059\u3002\u4e0a\u56f3\u306e\u5834\u5408\u306fL=4\u3068\u306a\u308a\u307e\u3059\u3002\n\u5404\u30ec\u30a4\u30e4\u30fc\u6bce\u306e\u30cb\u30e5\u30fc\u30ed\u30f3\u306e\u30e6\u30cb\u30c3\u30c8\u6570$S_l$\u3092\u5b9a\u7fa9\u3057\u307e\u3059\u3002(\u30d0\u30a4\u30a2\u30b9\u30e6\u30cb\u30c3\u30c8\u306f\u542b\u307e\u306a\u3044)\n\u4e0a\u56f3\u306e\u5834\u5408\u3001$S_1=4$,$S_2=6$,$S_3=6$,$S_4=S_L=4$\u3068\u306a\u308a\u307e\u3059\u3002\noutput unit\u306e\u500b\u6570k\u3092\u5b9a\u7fa9\u3057\u307e\u3059\u3002\n$K=4$\u3068\u306a\u308a\u307e\u3059\u3002\n\nbinaryClassfication\n1 output unit\u306e\u5834\u5408\n$S_L=1$\n$K=1$\n$y \\in 0,1$\n$h_\\theta(x) \\in R$\n\nMulti-class classfication(k classes)\nk output units\u306e\u5834\u5408\n$S_L=k$\n$K=k$\ny = $R^k$\n$h_\\theta(x) \\in R^k$\n\u4f8b $\\begin{eqnarray}\n\\left[\\begin{array}{ccc} 1 \\ 0 \\ 0 \\ 0 \\end{array}\\right],\n\\left[\\begin{array}{ccc} 0 \\ 1 \\ 0 \\ 0\\end{array}\\right],\n\\left[\\begin{array}{ccc} 0 \\ 0 \\ 1 \\ 0\\end{array}\\right],\n\\left[\\begin{array}{ccc} 0 \\ 0 \\ 0 \\ 1\\end{array}\\right]\n\\end{eqnarray} $\nk >= 3\u3067\u3042\u308b\u3053\u3068\u3002\n\n\u30b3\u30b9\u30c8\u95a2\u6570\n$h_{\\theta}(x) \\in R^k$\n$(h_{\\theta}(x))_k $\u306fk\u756a\u76ee\u306eoutput\u3092\u610f\u5473\u3057\u307e\u3059\u3002\n\nJ(\\theta)=\\frac{1}{m}[\\sum_{i=1}^{m}\\sum_{k=1}^{K}y_k^{(i)}log(h_\\theta(x))_k+\n\n(1-y_k^{(i)})log(1-h_{\\theta}(x))_k]\n\n+ \\frac{\\lambda }{ 2m}\\sum_{l=1}^{L-1}\\sum_{i=1}^{S_{l}}\\sum_{i=1}^{S_{l+1}}(\\theta_{ji})^2\n\n$\\frac{\\lambda }{ 2m}\\sum_{l=1}^{L-1}\\sum_{i=1}^{S_{l}}\\sum_{i=1}^{S_{l+1}}(\\theta_{ji})^2$\u306e\u90e8\u5206\u306f\u4e00\u898b\u308f\u304b\u308a\u3065\u3089\u3044\u3067\u3059\u304c\u3001\n\u30d0\u30a4\u30a2\u30b9\u30e6\u30cb\u30c3\u30c8\u306e$\\theta$\u3092\u9664\u304f\u5168\u8981\u7d20\u30922\u4e57\u3057\u3066\u8db3\u3057\u5408\u308f\u305b\u308b\u3063\u3066\u3053\u3068\u3067\u3059\u3002\n\n\u30d0\u30c3\u30af\u30d7\u30ed\u30d1\u30b2\u30fc\u30b7\u30e7\u30f3\u30a2\u30eb\u30b4\u30ea\u30ba\u30e0(back propagation algorithm)\n\nlayer $l$\u306e\u30ce\u30fc\u30c9$j$\u306e\u51fa\u529b$a^{(l)}_j$\u306b\u3064\u3044\u3066\nlayer1\u306f$a^{(1)}$,layer2\u306f$a^{(2)}$,layer3\u306f$a^{(3)}$,layer4\u306f$a^{(4)}$\u3068\u5b9a\u7fa9\u3057\u307e\u3059\u3002\n$a^{(1)} = x$\n$z^{(2)}=\\theta^{(1)}a^{(1)}$\n$a^{(2)} = g(z^{(2)})$  (add  $ a_0^{(2)}$)\n$z^{(3)}=\\theta^{(2)}a^{(2)}$\n$a^{(3)} = g(z^{(3)})$  (add  $ a_0^{(3)}$)\n$z^{(4)}=\\theta^{(3)}a^{(3)}$\n$a^{(3)} =h_{\\theta}(x) = g(z^{(4)})$\nlayer $l$\u306e\u30ce\u30fc\u30c9$j$\u306e\u8aa4\u5dee(error)\u3092 $\\delta^{(l)}_j$ \u3068\u5b9a\u7fa9\u3057\u307e\u3059\u3002\n$\\delta_j^{(4)}=a_j^{(4)} - y_j$ ($ a_{j}^{(4)} = (h_\\theta(x))_{j} $)\n$ \\delta^{(4)} = a^{(4)} - y$         \n$ \\delta^{(3)} = (\\theta^{(3)})^{T}  .* g^{'}(z^{(3)})$\n$ \\delta^{(2)} = (\\theta^{(2)})^{T}  .* g^{'}(z^{(2)})$         \n($g^{'}(z^{(3)}) = a^{(3)} .* (1-a^{(3)})$  )\n($g^{'}(z^{(2)}) = a^{(2)} .* (1-a^{(2)})$  )\n\n\u5b9f\u88c5\nTraining set \u5b9a\u7fa9 \n${ (x^{(1)},y^{(1)}), \\ldots ,  (x^{(m)},y^{(m)}) }$\nset $\\Delta^{(l)}_{ij} = 0$\nFor i =1 to m \n\u3000\u3000set  $a^{(1)} = x^{(i)}$\n\u3000\u3000$a^{(l)}$\u306b\u3064\u3044\u3066\u3001forward propagation\u306e\u8a08\u7b97\u5b9f\u884c \u3000$l=2,3,\\ldots,L$\n\u3000\u3000$\\delta^{(L)} = a^{(L)} - y^{(i)} $\u3092\u8a08\u7b97\n\u3000\u3000$\\delta^{(L-1)},\\delta^{(L-2)},\\ldots,\\delta^{(2)}$\u3068\u8a08\u7b97($\\delta^{(1)}\u306f\u5165\u529b\u306b\u5bfe\u5fdc\u3059\u308b\u305f\u3081\u8a08\u7b97\u3057\u306a\u3044$)\n\u3000\u3000$\\Delta_{ij}^{(l)} := \\Delta^{(l)}_{ij} + a^{(l)}_j \\delta^{(l+1)}$\n\u3000\u3000\u4e0a\u8a18\u3092\u30d9\u30af\u30c8\u30eb\u6f14\u7b97\u3068\u3059\u308b\u3068\u4ee5\u4e0b\u306b\u306a\u308b\u3002\n\u3000\u3000\u3000\u3000$\\Delta^{(l)} := \\Delta^{(l)} + \\delta^{(l+1)}(a^{(l)} )^T$\nEndFor\n$j \\neq 0$\u306e\u6642\n$D_{ij}:=\\frac{1}{m}\\Delta_{ij}^{(l)} + \\frac{\\lambda}{m}\\theta_{ij}^{(l)}$  \n$j = 0$\u306e\u6642\n$D_{ij}:=\\frac{1}{m}\\Delta_{ij}^{(l)}$\n$\\frac{\\delta}{\\delta\\theta_{ij}^{(l)}}J(\\theta)=D_{ij}^{(l)}$\n$j \\neq 0$\u306e\u6642\u306e\u5bfe\u5fdc\u306f\u6b63\u898f\u5316\u306e\u305f\u3081\u3067\u3001\u8981\u3059\u308b\u306b\u30d0\u30a4\u30a2\u30b9\u30e6\u30cb\u30c3\u30c8\u4ee5\u5916\u306b\u3064\u3044\u3066\u5bfe\u5fdc\u3059\u308b\u3063\u3066\u3053\u3068\u3067\u3059\u3002\n\nGradient Checking\n\u30d0\u30c3\u30af\u30d7\u30ed\u30d1\u30b2\u30fc\u30b7\u30e7\u30f3\u30a2\u30eb\u30b4\u30ea\u30ba\u30e0(back propagation algorithm)\u306f\u5b9f\u88c5\u304c\u30df\u30b9\u3063\u3066\u3044\u308b\u53ef\u80fd\u6027\u304c\u3042\u308b\u305f\u3081(\u96e3\u3057\u3044\u305f\u3081)\n\u30c6\u30b9\u30c8\u3059\u308b\u305f\u3081\u306e\u4ed5\u7d44\u307f\u3068\u3057\u3066\u3053\u308c\u3092\u5b66\u3073\u307e\u3059\u3002\n$\\theta=R^n$\n\u3053\u308c\u306f\u3064\u307e\u308a\u3001\n$\\theta = [\\theta_1,\\theta_2,\\theta_3,\\ldots,\\theta_n]$\n$J_\\theta(x)$\u306b\u3064\u3044\u3066\u3001\u504f\u5fae\u5206\u3059\u308b\u3068\n\n\\frac{\\delta}{\\delta\\theta_1}J(x)\\cong \\frac{J(\\theta_1+\\epsilon,\\theta_2,\\theta_3,\\ldots,\\theta_n) - J(\\theta_1-\\epsilon,\\theta_2,\\theta_3,\\ldots,\\theta_n)}{2\\epsilon} \\\\\n\n\\frac{\\delta}{\\delta\\theta_2}J(x)\\cong \\frac{J(\\theta_1,\\theta_2+\\epsilon,\\theta_3,\\ldots,\\theta_n) \n- J(\\theta_1,\\theta_2-\\epsilon,\\theta_3,\\ldots,\\theta_n)}{2\\epsilon} \\\\\n\n\\frac{\\delta}{\\delta\\theta_3}J(x)\\cong \\frac{J(\\theta_1,\\theta_2,\\theta_3+\\epsilon,\\ldots,\\theta_n) \n- J(\\theta_1,\\theta_2,\\theta_3-\\epsilon,\\ldots,\\theta_n)}{2\\epsilon} \\\\\n\n\n\\\\\\vdots\\\\\n\n\\frac{\\delta}{\\delta\\theta_n}J(x)\\cong \\frac{J(\\theta_1,\\theta_2,\\theta_3,\\ldots,\\theta_n+\\epsilon) -\n J(\\theta_1,\\theta_2,\\theta_3,\\ldots,\\theta_n-\\epsilon)}{2\\epsilon}\n\n\n$\\epsilon$\u304c\u5341\u5206\u5c0f\u3055\u308c\u3070\u3001\u4e00\u81f4\u3059\u308b\u3002\ncode \u4f8b\nfor i =1:n\n   thetaPlus = theta;\n   thetaPlus(i) = thetaPlus(i) + EPSILON;\n   thetaMinus(i) = thetaMinus(i) - EPSILON;\n   gradApprox(i) = (J(thetaPlus)- J(thetaMinus))/(2*EPSILON);\nendfor;\n\n\n\ngradApprox(l) \u3092\u5148\u307b\u3069\u306eBP(\u30d0\u30c3\u30af\u30d7\u30ed\u30d1\u30b2\u30fc\u30b7\u30e7\u30f3)\u306b\u3066\u53d6\u5f97\u3057\u305f$D^{(l)}$\u3068\u6bd4\u8f03\u3059\u308b\n\n\u30e9\u30f3\u30c0\u30e0\u521d\u671f\u5316\n$\\theta$\u306e\u521d\u671f\u5024\u306b\u3064\u3044\u3066\u306f\u7dda\u5f62\u56de\u5e30\u30e2\u30c7\u30eb\u3068\u30ed\u30b8\u30b9\u30c6\u30a3\u30c3\u30af\u56de\u5e30\u30e2\u30c7\u30eb\u3067\u306f0\u3067\u3057\u305f\u304c\u3001\nNN\u306b\u3064\u3044\u3066\u306f\u554f\u984c\u304c\u8d77\u3053\u308a\u307e\u3059\u3002\n\u5b9f\u969b\u306b $\\theta_{ij}^{(l)} = 0$ \u3068\u3057\u305f\u5834\u5408\n$a_1^{(2)} = a_2^{(2)} $\u306b\u306a\u308a\u307e\u3059\u3002\u306a\u305c\u306a\u3089\u540c\u3058$x$\u3092\u30d1\u30e9\u30e1\u30fc\u30bf\u3092\u6301\u3064\u305f\u3081\u3067\u3059\n\u7d50\u679cBP\u306b\u3088\u308b$\\delta$\u3082\u540c\u3058\u306b\u306a\u308a\u307e\u3059\u3002\n$\\delta_1^{(2)} = \\delta_2^{(2)}$\n\u6700\u7d42\u7684\u306b\n$\\frac{\\delta}{\\delta\\theta_{0,1}^{(1)}}J(\\theta) = \\frac{\\delta}{\\delta\\theta_{0,2}^{(1)}}J(\\theta)$\n\u3064\u307e\u308a\n$\\theta_{0,1}^{(1)} = \\theta_{0,2}^{(1)}$\n\u3064\u307e\u308a\n$a_1^{(2)} = a_2^{(2)} $\u306b\u306a\u308a\u307e\u3059\u3002\n\u3053\u3046\u3057\u3066\u3053\u306e\u95a2\u4fc2\u304c\u4f55\u5ea6\u7e70\u308a\u8fd4\u3057\u3066\u3082\u6210\u308a\u7acb\u3064\u306e\u3067\u3059\u3002\n\u3053\u306e\u5bfe\u79f0\u6027\u3092\u30e9\u30f3\u30c0\u30e0\u521d\u671f\u5316\u3067\u7e70\u308a\u8fd4\u3057\u307e\u3059\u3002\ncode\u4f8b\n\u5341\u5206\u5c0f\u3055\u3044\u5024$\\epsilon$\u3092\u5b9a\u7fa9\u3057\u307e\u3059\u3002\n$-\\epsilon \\leq \\theta_{ij}^{(l)} \\leq \\epsilon$\ntheta1 = rand(10,11) * (2*INIT_EPSILON) - INIT_EPSILON;\ntheta2 = rand(1,11) *  (2*INIT_EPSILON) - INIT_EPSILON;\n\n\n\u307e\u3068\u3081\n\u5168\u4f53\u306e\u624b\u9806\u3068\u3057\u3066\u4ee5\u4e0b\u306e\u3088\u3046\u306b\u9032\u3081\u307e\u3059\n\n$\\theta$\u306e\u30e9\u30f3\u30c0\u30e0\u521d\u671f\u5316\nFP\u306b\u3088\u308b$h_\\theta(x^{(i)})\u5b9f\u88c5$\ncost\u95a2\u6570$J(\\theta)$\u306e\u5b9f\u88c5\nBP\u306b\u3088\u308b\u504f\u5fae\u5206\u306e\u5b9f\u88c5\ngd\u306b\u3088\u308b\u5b9f\u88c5\u306e\u30c1\u30a7\u30c3\u30af\ngd\u30c1\u30a7\u30c3\u30af\u306b\u554f\u984c\u306a\u3051\u308c\u3070gd disclose\n$J(\\theta)$\u306e\u6700\u5c0f\u5024\u3092\u6c42\u3081\u308b(\u5b66\u7fd2\u306e\u5b9f\u884c)\n\n\n# \u306f\u3058\u3081\u306b\n\n[coursera\u306eMachine Learning(\u6a5f\u68b0\u5b66\u7fd2)\u5b66\u3093\u3060\u3053\u3068\u30e1\u30e2(1)](http://qiita.com/m0a/items/9ab63946b1c808da1238)\u306e\u7d9a\u304d\u3067\u3059\u3002\n\n\u524d\u56de\u306f\u7dda\u5f62\u56de\u5e30\u30e2\u30c7\u30eb\u3068\u30ed\u30b8\u30b9\u30c6\u30a3\u30c3\u30af\u56de\u5e30\u30e2\u30c7\u30eb\u307e\u3067\u3067\u3057\u305f\u3002\n\u4eca\u56de\u306f\u81ea\u5206\u304c\u5143\u3005\u52c9\u5f37\u3057\u305f\u304b\u3063\u305fNN(\u30cb\u30e5\u30fc\u30e9\u30eb\u30cd\u30c3\u30c8\u30ef\u30fc\u30af)\u3067\u3059\u3002\n\n\u5b66\u7fd2\u4e2d\u3044\u304d\u306a\u308a\u6587\u5b57\u8a8d\u8b58(OCR)\u306e\u5b9f\u88c5\u306b\u89e6\u308b\u3053\u3068\u306b\u306a\u308b\u306e\u3067\u30c6\u30f3\u30b7\u30e7\u30f3\u304c\u4e0a\u308a\u307e\u3059\u3002\n\u624b\u52d5\u3067\u5b9f\u88c5\u3057\u3088\u3046\u3068\u3059\u308b\u3068\u5168\u304f\u60f3\u50cf\u304c\u3064\u304b\u306a\u3044\u6587\u5b57\u8a8d\u8b58\u3067\u3059\u304c\u3001NN\u3092\u4f7f\u3044\u3001\u6a5f\u68b0\u5b66\u7fd2\u3092\u884c\u3046\u3053\u3068\u3067\u3001\u7c21\u5358\u306b\u5b9f\u88c5\u3067\u304d\u3066\u3057\u307e\u3044\u611f\u52d5\u3057\u307e\u3059\u3002\n\n\u6b63\u76f4\u4e00\u3064\u4e00\u3064\u306e\u6570\u5f0f\u306f\u4e01\u5be7\u306b\u8aac\u660e\u3057\u3066\u304f\u308c\u308b\u306e\u3067\u306a\u3093\u3068\u304b\u7406\u89e3\u3067\u304d\u308b\u306e\u3067\u3059\u304c(\u4e00\u90e8\u306e\u504f\u5fae\u5206\u306f\u9664\u304f)\n\u6700\u7d42\u7684\u306b\u51fa\u6765\u4e0a\u304c\u308b\u52d5\u4f5c\u306f\u306a\u3093\u3067\u52d5\u304f\u3093\u3060\u30fc\u3063\u3068\u601d\u3063\u3066\u3057\u307e\u3044\u307e\u3059\u3002\n\u8133\u3063\u3066\u4e0d\u601d\u8b70\u3067\u3059\u3002\n\n\n# \u30cb\u30e5\u30fc\u30e9\u30eb\u30cd\u30c3\u30c8\u30ef\u30fc\u30af\n\n\u30d1\u30e9\u30e1\u30fc\u30bf\u306e\u6570\u304c\u81a8\u5927\u306b\u5897\u3048\u305f\u308a\u3057\u305f\u5834\u5408\u306e\u5206\u985e\u306e\u554f\u984c\u3092\u30ed\u30b8\u30b9\u30c6\u30a3\u30c3\u30af\u56de\u5e30\u3067\u89e3\u304f\u306b\u306f\u9650\u754c\u304c\u6765\u307e\u3059\u3002\n\u305d\u306e\u305f\u3081\u306b\u3053\u306eNN\u3092\u4f7f\u3044\u307e\u3059\u3002\n\n\n![NN.png](http://i.imgur.com/AoYrqr6.png)\n\n$a^{(j)}_i$ activation(\u51fa\u529b) of unit i in layer j\n\n$x_0$,$a_0$\u306f\u30d0\u30a4\u30a2\u30b9\u30e6\u30cb\u30c3\u30c8\u3067\u5e38\u306b1\u3092\u53d6\u308a\u307e\u3059\u3002\n\n\n$\\theta^{(j)}$ \u306f\u91cd\u307f\u3065\u3051\u5236\u5fa1\u306e\u305f\u3081\u306e\u884c\u5217 layer j (input)\u304b\u3089layer j+1(output)\u306e\u30de\u30c3\u30d4\u30f3\u30b0\u306b\u5bfe\u5fdc\n\n$a_1^{(2)} = g(\\theta_{1,0}^{(1)} \\cdot x_0 + \\theta_{1,1}^{(1)} \\cdot x_1  + \\theta_{1,2}^{(1)} \\cdot x_2 + \\theta_{1,3}^{(1)} \\cdot x_3  )$\n$a_2^{(2)} = g(\\theta_{2,0}^{(1)} \\cdot x_0 + \\theta_{2,1}^{(1)} \\cdot x_1  + \\theta_{2,2}^{(1)} \\cdot x_2 + \\theta_{2,3}^{(1)} \\cdot x_3  )$\n$a_3^{(2)} = g(\\theta_{3,0}^{(1)} \\cdot x_0 + \\theta_{3,1}^{(1)} \\cdot x_1  + \\theta_{3,2}^{(1)} \\cdot x_2 + \\theta_{3,3}^{(1)} \\cdot x_3  )$\n\n$h_\\theta (x) = a_1^{(3)} = g(\\theta_{3,0}^{(2)} \\cdot a_0^{(2)} + \\theta_{3,1}^{(2)} \\cdot a_1^{(2)}  + \\theta_{3,2}^{(2)} \\cdot a_2^{(2)} + \\theta_{3,3}^{(2)} \\cdot a_3^{(2)} )$\n\n\nnetwork\u306b\u3064\u3044\u3066\u3001layer j\u306e\u30e6\u30cb\u30c3\u30c8\u6570\u304c$s_{j}$\u500b\u3067\u3001layer j+1 \u306e\u30e6\u30cb\u30c3\u30c8\u6570\u304c $s_{(j+1)}$\u500b\u306e\u5834\u5408\u3001\n$\\theta^{(j)}$ \u306f $(s_{(j+1)}) \\times (s_{j}+1)$\u6b21\u5143\u306e\u884c\u5217\n\n## \u30b3\u30b9\u30c8\u95a2\u6570(cost function)\n\n![nn2.png](http://i.imgur.com/b7LaC3A.png)\n\n\u4e0a\u8a18\u306e\u3088\u3046\u306aNN\u3092\u8003\u3048\u307e\u3059\u3002\n\nLayer\u6570L\u3092\u5b9a\u7fa9\u3057\u307e\u3059\u3002\u4e0a\u56f3\u306e\u5834\u5408\u306fL=4\u3068\u306a\u308a\u307e\u3059\u3002\n\u5404\u30ec\u30a4\u30e4\u30fc\u6bce\u306e\u30cb\u30e5\u30fc\u30ed\u30f3\u306e\u30e6\u30cb\u30c3\u30c8\u6570$S_l$\u3092\u5b9a\u7fa9\u3057\u307e\u3059\u3002(\u30d0\u30a4\u30a2\u30b9\u30e6\u30cb\u30c3\u30c8\u306f\u542b\u307e\u306a\u3044)\n\u4e0a\u56f3\u306e\u5834\u5408\u3001$S_1=4$,$S_2=6$,$S_3=6$,$S_4=S_L=4$\u3068\u306a\u308a\u307e\u3059\u3002\noutput unit\u306e\u500b\u6570k\u3092\u5b9a\u7fa9\u3057\u307e\u3059\u3002\n$K=4$\u3068\u306a\u308a\u307e\u3059\u3002\n\n\n\n\n\n###  binaryClassfication\n\n1 output unit\u306e\u5834\u5408\n$S_L=1$\n$K=1$\n$y \\in 0,1$\n$h_\\theta(x) \\in R$\n\n### Multi-class classfication(k classes)\nk output units\u306e\u5834\u5408\n$S_L=k$\n$K=k$\ny = $R^k$\n$h_\\theta(x) \\in R^k$\n\n\u4f8b $\\begin{eqnarray}\n\\left[\\begin{array}{ccc} 1 \\\\ 0 \\\\ 0 \\\\ 0 \\end{array}\\right],\n\\left[\\begin{array}{ccc} 0 \\\\ 1 \\\\ 0 \\\\ 0\\end{array}\\right],\n\\left[\\begin{array}{ccc} 0 \\\\ 0 \\\\ 1 \\\\ 0\\end{array}\\right],\n\\left[\\begin{array}{ccc} 0 \\\\ 0 \\\\ 0 \\\\ 1\\end{array}\\right]\n\\end{eqnarray} $\n\nk >= 3\u3067\u3042\u308b\u3053\u3068\u3002\n\n### \u30b3\u30b9\u30c8\u95a2\u6570\n\n$h_{\\theta}(x) \\in R^k$\n$(h_{\\theta}(x))_k $\u306fk\u756a\u76ee\u306eoutput\u3092\u610f\u5473\u3057\u307e\u3059\u3002\n\n\n```math\n\nJ(\\theta)=\\frac{1}{m}[\\sum_{i=1}^{m}\\sum_{k=1}^{K}y_k^{(i)}log(h_\\theta(x))_k+\n\n(1-y_k^{(i)})log(1-h_{\\theta}(x))_k]\n\n+ \\frac{\\lambda }{ 2m}\\sum_{l=1}^{L-1}\\sum_{i=1}^{S_{l}}\\sum_{i=1}^{S_{l+1}}(\\theta_{ji})^2\n```\n\n\n$\\frac{\\lambda }{ 2m}\\sum_{l=1}^{L-1}\\sum_{i=1}^{S_{l}}\\sum_{i=1}^{S_{l+1}}(\\theta_{ji})^2$\u306e\u90e8\u5206\u306f\u4e00\u898b\u308f\u304b\u308a\u3065\u3089\u3044\u3067\u3059\u304c\u3001\n\u30d0\u30a4\u30a2\u30b9\u30e6\u30cb\u30c3\u30c8\u306e$\\theta$\u3092\u9664\u304f\u5168\u8981\u7d20\u30922\u4e57\u3057\u3066\u8db3\u3057\u5408\u308f\u305b\u308b\u3063\u3066\u3053\u3068\u3067\u3059\u3002\n\n\n## \u30d0\u30c3\u30af\u30d7\u30ed\u30d1\u30b2\u30fc\u30b7\u30e7\u30f3\u30a2\u30eb\u30b4\u30ea\u30ba\u30e0(back propagation algorithm)\n\n![nn2.png](http://i.imgur.com/b7LaC3A.png)\n\nlayer $l$\u306e\u30ce\u30fc\u30c9$j$\u306e\u51fa\u529b$a^{(l)}_j$\u306b\u3064\u3044\u3066\nlayer1\u306f$a^{(1)}$,layer2\u306f$a^{(2)}$,layer3\u306f$a^{(3)}$,layer4\u306f$a^{(4)}$\u3068\u5b9a\u7fa9\u3057\u307e\u3059\u3002\n\n$a^{(1)} = x$\n$z^{(2)}=\\theta^{(1)}a^{(1)}$\n$a^{(2)} = g(z^{(2)})$  (add  $ a_0^{(2)}$)\n$z^{(3)}=\\theta^{(2)}a^{(2)}$\n$a^{(3)} = g(z^{(3)})$  (add  $ a_0^{(3)}$)\n$z^{(4)}=\\theta^{(3)}a^{(3)}$\n$a^{(3)} =h_{\\theta}(x) = g(z^{(4)})$\n\nlayer $l$\u306e\u30ce\u30fc\u30c9$j$\u306e\u8aa4\u5dee(error)\u3092 $\\delta^{(l)}_j$ \u3068\u5b9a\u7fa9\u3057\u307e\u3059\u3002\n\n$\\delta_j^{(4)}=a_j^{(4)} - y_j$ ($ a_{j}^{(4)} = (h_\\theta(x))_{j} $)\n\n$ \\delta^{(4)} = a^{(4)} - y$         \n\n$ \\delta^{(3)} = (\\theta^{(3)})^{T}  .* g^{'}(z^{(3)})$         \n$ \\delta^{(2)} = (\\theta^{(2)})^{T}  .* g^{'}(z^{(2)})$         \n\n($g^{'}(z^{(3)}) = a^{(3)} .* (1-a^{(3)})$  )\n($g^{'}(z^{(2)}) = a^{(2)} .* (1-a^{(2)})$  )\n\n### \u5b9f\u88c5\n\nTraining set \u5b9a\u7fa9 \n${ (x^{(1)},y^{(1)}), \\ldots ,  (x^{(m)},y^{(m)}) \\}$\n\nset $\\Delta^{(l)}_{ij} = 0$\n\nFor i =1 to m \n\u3000\u3000set  $a^{(1)} = x^{(i)}$\n\u3000\u3000$a^{(l)}$\u306b\u3064\u3044\u3066\u3001forward propagation\u306e\u8a08\u7b97\u5b9f\u884c \u3000$l=2,3,\\ldots,L$\n\u3000\u3000$\\delta^{(L)} = a^{(L)} - y^{(i)} $\u3092\u8a08\u7b97\n\u3000\u3000$\\delta^{(L-1)},\\delta^{(L-2)},\\ldots,\\delta^{(2)}$\u3068\u8a08\u7b97($\\delta^{(1)}\u306f\u5165\u529b\u306b\u5bfe\u5fdc\u3059\u308b\u305f\u3081\u8a08\u7b97\u3057\u306a\u3044$)\n\n\u3000\u3000$\\Delta_{ij}^{(l)} := \\Delta^{(l)}_{ij} + a^{(l)}_j \\delta^{(l+1)}$\n\n\u3000\u3000\u4e0a\u8a18\u3092\u30d9\u30af\u30c8\u30eb\u6f14\u7b97\u3068\u3059\u308b\u3068\u4ee5\u4e0b\u306b\u306a\u308b\u3002\n\u3000\u3000\u3000\u3000$\\Delta^{(l)} := \\Delta^{(l)} + \\delta^{(l+1)}(a^{(l)} )^T$\nEndFor\n\n$j \\neq 0$\u306e\u6642\n$D_{ij}:=\\frac{1}{m}\\Delta_{ij}^{(l)} + \\frac{\\lambda}{m}\\theta_{ij}^{(l)}$  \n\n$j = 0$\u306e\u6642\n$D_{ij}:=\\frac{1}{m}\\Delta_{ij}^{(l)}$\n\n\n$\\frac{\\delta}{\\delta\\theta_{ij}^{(l)}}J(\\theta)=D_{ij}^{(l)}$\n\n$j \\neq 0$\u306e\u6642\u306e\u5bfe\u5fdc\u306f\u6b63\u898f\u5316\u306e\u305f\u3081\u3067\u3001\u8981\u3059\u308b\u306b\u30d0\u30a4\u30a2\u30b9\u30e6\u30cb\u30c3\u30c8\u4ee5\u5916\u306b\u3064\u3044\u3066\u5bfe\u5fdc\u3059\u308b\u3063\u3066\u3053\u3068\u3067\u3059\u3002\n\n\n\n## Gradient Checking\n\n\u30d0\u30c3\u30af\u30d7\u30ed\u30d1\u30b2\u30fc\u30b7\u30e7\u30f3\u30a2\u30eb\u30b4\u30ea\u30ba\u30e0(back propagation algorithm)\u306f\u5b9f\u88c5\u304c\u30df\u30b9\u3063\u3066\u3044\u308b\u53ef\u80fd\u6027\u304c\u3042\u308b\u305f\u3081(\u96e3\u3057\u3044\u305f\u3081)\n\u30c6\u30b9\u30c8\u3059\u308b\u305f\u3081\u306e\u4ed5\u7d44\u307f\u3068\u3057\u3066\u3053\u308c\u3092\u5b66\u3073\u307e\u3059\u3002\n\n$\\theta=R^n$\n\u3053\u308c\u306f\u3064\u307e\u308a\u3001\n$\\theta = [\\theta_1,\\theta_2,\\theta_3,\\ldots,\\theta_n]$\n$J_\\theta(x)$\u306b\u3064\u3044\u3066\u3001\u504f\u5fae\u5206\u3059\u308b\u3068\n\n```math\n\n\\frac{\\delta}{\\delta\\theta_1}J(x)\\cong \\frac{J(\\theta_1+\\epsilon,\\theta_2,\\theta_3,\\ldots,\\theta_n) - J(\\theta_1-\\epsilon,\\theta_2,\\theta_3,\\ldots,\\theta_n)}{2\\epsilon} \\\\\n\n\\frac{\\delta}{\\delta\\theta_2}J(x)\\cong \\frac{J(\\theta_1,\\theta_2+\\epsilon,\\theta_3,\\ldots,\\theta_n) \n- J(\\theta_1,\\theta_2-\\epsilon,\\theta_3,\\ldots,\\theta_n)}{2\\epsilon} \\\\\n\n\\frac{\\delta}{\\delta\\theta_3}J(x)\\cong \\frac{J(\\theta_1,\\theta_2,\\theta_3+\\epsilon,\\ldots,\\theta_n) \n- J(\\theta_1,\\theta_2,\\theta_3-\\epsilon,\\ldots,\\theta_n)}{2\\epsilon} \\\\\n\n\n\\\\\\vdots\\\\\n\n\\frac{\\delta}{\\delta\\theta_n}J(x)\\cong \\frac{J(\\theta_1,\\theta_2,\\theta_3,\\ldots,\\theta_n+\\epsilon) -\n J(\\theta_1,\\theta_2,\\theta_3,\\ldots,\\theta_n-\\epsilon)}{2\\epsilon}\n\n```\n\n$\\epsilon$\u304c\u5341\u5206\u5c0f\u3055\u308c\u3070\u3001\u4e00\u81f4\u3059\u308b\u3002\n\n\ncode \u4f8b\n\n```\nfor i =1:n\n   thetaPlus = theta;\n   thetaPlus(i) = thetaPlus(i) + EPSILON;\n   thetaMinus(i) = thetaMinus(i) - EPSILON;\n   gradApprox(i) = (J(thetaPlus)- J(thetaMinus))/(2*EPSILON);\nendfor;\n\n\n```\ngradApprox(l) \u3092\u5148\u307b\u3069\u306eBP(\u30d0\u30c3\u30af\u30d7\u30ed\u30d1\u30b2\u30fc\u30b7\u30e7\u30f3)\u306b\u3066\u53d6\u5f97\u3057\u305f$D^{(l)}$\u3068\u6bd4\u8f03\u3059\u308b\n\n\n## \u30e9\u30f3\u30c0\u30e0\u521d\u671f\u5316\n\n$\\theta$\u306e\u521d\u671f\u5024\u306b\u3064\u3044\u3066\u306f\u7dda\u5f62\u56de\u5e30\u30e2\u30c7\u30eb\u3068\u30ed\u30b8\u30b9\u30c6\u30a3\u30c3\u30af\u56de\u5e30\u30e2\u30c7\u30eb\u3067\u306f0\u3067\u3057\u305f\u304c\u3001\nNN\u306b\u3064\u3044\u3066\u306f\u554f\u984c\u304c\u8d77\u3053\u308a\u307e\u3059\u3002\n\n\u5b9f\u969b\u306b $\\theta_{ij}^{(l)} = 0$ \u3068\u3057\u305f\u5834\u5408\n\n$a_1^{(2)} = a_2^{(2)} $\u306b\u306a\u308a\u307e\u3059\u3002\u306a\u305c\u306a\u3089\u540c\u3058$x$\u3092\u30d1\u30e9\u30e1\u30fc\u30bf\u3092\u6301\u3064\u305f\u3081\u3067\u3059\n\u7d50\u679cBP\u306b\u3088\u308b$\\delta$\u3082\u540c\u3058\u306b\u306a\u308a\u307e\u3059\u3002\n$\\delta_1^{(2)} = \\delta_2^{(2)}$\n\u6700\u7d42\u7684\u306b\n\n$\\frac{\\delta}{\\delta\\theta_{0,1}^{(1)}}J(\\theta) = \\frac{\\delta}{\\delta\\theta_{0,2}^{(1)}}J(\\theta)$\n\n\u3064\u307e\u308a\n$\\theta_{0,1}^{(1)} = \\theta_{0,2}^{(1)}$\n\u3064\u307e\u308a\n$a_1^{(2)} = a_2^{(2)} $\u306b\u306a\u308a\u307e\u3059\u3002\n\u3053\u3046\u3057\u3066\u3053\u306e\u95a2\u4fc2\u304c\u4f55\u5ea6\u7e70\u308a\u8fd4\u3057\u3066\u3082\u6210\u308a\u7acb\u3064\u306e\u3067\u3059\u3002\n\u3053\u306e\u5bfe\u79f0\u6027\u3092\u30e9\u30f3\u30c0\u30e0\u521d\u671f\u5316\u3067\u7e70\u308a\u8fd4\u3057\u307e\u3059\u3002\n\ncode\u4f8b\n\n\u5341\u5206\u5c0f\u3055\u3044\u5024$\\epsilon$\u3092\u5b9a\u7fa9\u3057\u307e\u3059\u3002\n\n$-\\epsilon \\leq \\theta_{ij}^{(l)} \\leq \\epsilon$\n\n```\ntheta1 = rand(10,11) * (2*INIT_EPSILON) - INIT_EPSILON;\ntheta2 = rand(1,11) *  (2*INIT_EPSILON) - INIT_EPSILON;\n```\n\n## \u307e\u3068\u3081\n\n\u5168\u4f53\u306e\u624b\u9806\u3068\u3057\u3066\u4ee5\u4e0b\u306e\u3088\u3046\u306b\u9032\u3081\u307e\u3059\n\n1. $\\theta$\u306e\u30e9\u30f3\u30c0\u30e0\u521d\u671f\u5316\n2. FP\u306b\u3088\u308b$h_\\theta(x^{(i)})\u5b9f\u88c5$\n3. cost\u95a2\u6570$J(\\theta)$\u306e\u5b9f\u88c5\n4. BP\u306b\u3088\u308b\u504f\u5fae\u5206\u306e\u5b9f\u88c5\n5. gd\u306b\u3088\u308b\u5b9f\u88c5\u306e\u30c1\u30a7\u30c3\u30af\n6. gd\u30c1\u30a7\u30c3\u30af\u306b\u554f\u984c\u306a\u3051\u308c\u3070gd disclose\n7. $J(\\theta)$\u306e\u6700\u5c0f\u5024\u3092\u6c42\u3081\u308b(\u5b66\u7fd2\u306e\u5b9f\u884c)\n\n\n\n\n\n\n\n", "tags": ["\u6a5f\u68b0\u5b66\u7fd2", "coursera"]}