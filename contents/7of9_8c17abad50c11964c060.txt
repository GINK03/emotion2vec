{"context": "\n\u52d5\u4f5c\u74b0\u5883\nUbuntu 14.04 LTS desktop amd64\nGeForce GTX 750 Ti\nASRock Z170M Pro4S [Intel Z170chipset]\nTensorFlow v0.11\ncuDNN v5.1 for Linux\nCUDA v7.5\nPython 2.7.6\n\n\nTensorFlow\u3068\u3044\u3046Deep Learning\u95a2\u9023\u30b3\u30fc\u30c9\u3092\u5b66\u7fd2\u4e2d\u3002\nhttps://www.tensorflow.org/versions/master/tutorials/mnist/tf/index.html#tensorflow-mechanics-101\nmnist_with_summary.py\u306b\u3064\u3044\u3066\n  def nn_layer(input_tensor, input_dim, output_dim, layer_name, act=tf.nn.relu):\n    \"\"\"Reusable code for making a simple neural net layer.\n\n    It does a matrix multiply, bias add, and then uses relu to nonlinearize.\n    It also sets up name scoping so that the resultant graph is easy to read,\n    and adds a number of summary ops.\n    \"\"\"\n    # Adding a name scope ensures logical grouping of the layers in the graph.\n    with tf.name_scope(layer_name):\n      # This Variable will hold the state of the weights for the layer\n      with tf.name_scope('weights'):\n        weights = weight_variable([input_dim, output_dim])\n        variable_summaries(weights, layer_name + '/weights')\n      with tf.name_scope('biases'):\n        biases = bias_variable([output_dim])\n        variable_summaries(biases, layer_name + '/biases')\n      with tf.name_scope('Wx_plus_b'):\n        preactivate = tf.matmul(input_tensor, weights) + biases\n        tf.histogram_summary(layer_name + '/pre_activations', preactivate)\n      activations = act(preactivate, name='activation')\n      tf.histogram_summary(layer_name + '/activations', activations)\n      return activations\n\n\u4e0a\u8a18\u306e\n  def nn_layer(input_tensor, input_dim, output_dim, layer_name, act=tf.nn.relu):\n\n\u3068\u4ee5\u4e0b\u306b\u3066\u6d3b\u6027\u5316\u95a2\u6570\u3092ReLU\u4ee5\u5916\u306b\u5207\u66ff\u3048\u3057\u3084\u3059\u304f\u3057\u3066\u3044\u308b\u3002\n      activations = act(preactivate, name='activation')\n\n\u95a2\u9023\n\u6df1\u5c64\u5b66\u7fd2 by \u5ca1\u8c37\u8cb4\u4e4b\u3055\u3093 2.2 \u6d3b\u6027\u5316\u95a2\u6570\n```txt:\u52d5\u4f5c\u74b0\u5883\nUbuntu 14.04 LTS desktop amd64\nGeForce GTX 750 Ti\nASRock Z170M Pro4S [Intel Z170chipset]\nTensorFlow v0.11\ncuDNN v5.1 for Linux\nCUDA v7.5\nPython 2.7.6\n```\n\nTensorFlow\u3068\u3044\u3046Deep Learning\u95a2\u9023\u30b3\u30fc\u30c9\u3092\u5b66\u7fd2\u4e2d\u3002\nhttps://www.tensorflow.org/versions/master/tutorials/mnist/tf/index.html#tensorflow-mechanics-101\n\nmnist_with_summary.py\u306b\u3064\u3044\u3066\n\n```py\n  def nn_layer(input_tensor, input_dim, output_dim, layer_name, act=tf.nn.relu):\n    \"\"\"Reusable code for making a simple neural net layer.\n\n    It does a matrix multiply, bias add, and then uses relu to nonlinearize.\n    It also sets up name scoping so that the resultant graph is easy to read,\n    and adds a number of summary ops.\n    \"\"\"\n    # Adding a name scope ensures logical grouping of the layers in the graph.\n    with tf.name_scope(layer_name):\n      # This Variable will hold the state of the weights for the layer\n      with tf.name_scope('weights'):\n        weights = weight_variable([input_dim, output_dim])\n        variable_summaries(weights, layer_name + '/weights')\n      with tf.name_scope('biases'):\n        biases = bias_variable([output_dim])\n        variable_summaries(biases, layer_name + '/biases')\n      with tf.name_scope('Wx_plus_b'):\n        preactivate = tf.matmul(input_tensor, weights) + biases\n        tf.histogram_summary(layer_name + '/pre_activations', preactivate)\n      activations = act(preactivate, name='activation')\n      tf.histogram_summary(layer_name + '/activations', activations)\n      return activations\n```\n\n\u4e0a\u8a18\u306e\n\n```\n  def nn_layer(input_tensor, input_dim, output_dim, layer_name, act=tf.nn.relu):\n```\n\u3068\u4ee5\u4e0b\u306b\u3066\u6d3b\u6027\u5316\u95a2\u6570\u3092ReLU\u4ee5\u5916\u306b\u5207\u66ff\u3048\u3057\u3084\u3059\u304f\u3057\u3066\u3044\u308b\u3002\n\n```\n      activations = act(preactivate, name='activation')\n```\n\n\u95a2\u9023\n\u6df1\u5c64\u5b66\u7fd2 by \u5ca1\u8c37\u8cb4\u4e4b\u3055\u3093 2.2 \u6d3b\u6027\u5316\u95a2\u6570\n\n\n\n\n", "tags": ["TensorFlow", "borgWarp"]}