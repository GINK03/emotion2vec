{"context": " More than 1 year has passed since last update.\n\n\u30b9\u30af\u30ea\u30d7\u30c8\u8cc7\u6e90 \u3068 \u5b9f\u884c\u624b\u9806\n\n\u5de5\u7a0b\uff13\u306e\u30b9\u30af\u30ea\u30d7\u30c8\u306f\u3001\u4ee5\u4e0b\u306e\u30a6\u30a7\u30d6\u30b5\u30a4\u30c8\u304b\u3089\u62dd\u501f\u3057\u307e\u3057\u305f\n\n\n \u30c7\u30fc\uff082011\u5e7410\u670815\u65e5\u4ed8\uff09\u300c\u65e5\u672c\u8a9e\u4fc2\u308a\u53d7\u3051\u89e3\u6790\u5668 CaboCha Ruby \u62e1\u5f35\u306e\u57fa\u672c\u7684\u306a\u4f7f\u3044\u65b9\u3068\u3061\u3087\u3063\u3068\u3057\u305f\u5fdc\u7528\u300d \n\n\n1. \u30af\u30ed\u30a6\u30ea\u30f3\u30b0\u5bfe\u8c61\u8a18\u4e8b \u306eURL\u30fb\u8a18\u4e8b\u30bf\u30a4\u30c8\u30eb \u4e00\u89a7\u30ea\u30b9\u30c8 \u751f\u6210\n\uff08\u30b9\u30af\u30ea\u30d7\u30c8\u540d\uff09   create_article_title_url_list.py\n\uff08\u51fa\u529b\u30d5\u30a1\u30a4\u30eb\uff09   title_url_list_all_articles.txt\n\n2. \u5404\u8a18\u4e8b URL \u306b\u30a2\u30af\u30bb\u30b9\u3057\u3066\u3001html\u30d5\u30a1\u30a4\u30eb \u3068 \u8a18\u4e8b\u672c\u6587\u30c6\u30ad\u30b9\u30c8\u30fb\u30d5\u30a1\u30a4\u30eb\u751f\u6210\n\uff08\u30b9\u30af\u30ea\u30d7\u30c8\u540d\uff09   create_kiji_honbun_textfile_htmlfile.py\n\uff08\u8aad\u307f\u8fbc\u307f\u30d5\u30a1\u30a4\u30eb\uff09title_url_list_all_articles.txt\n\uff08\u51fa\u529b\u30d5\u30a1\u30a4\u30eb\uff09\n\u3000\u3000\u3000\u3000\u3000\u3000\u3000\u3000\uff08\uff11\uff09 \u8a18\u4e8b\u672c\u6587\u30c6\u30ad\u30b9\u30c8\u30d5\u30a1\u30a4\u30eb\uff08\u8a18\u4e8b\u672c\u6570\u5206\u3001\u30d5\u30a1\u30a4\u30eb\u751f\u6210\uff09  \n\u3000\u3000\u3000\u3000\u3000\u3000\u3000\u3000\uff08\uff12\uff09 \u8a18\u4e8bHTML\u30d5\u30a1\u30a4\u30eb\uff08\u8a18\u4e8b\u672c\u6570\u5206\u3001\u30d5\u30a1\u30a4\u30eb\u751f\u6210\uff09\n\u3000\u3000\u3000\u3000\u3000\u3000\u3000\u3000\uff08\uff13\uff09 kiji_metadata_file_1.csv   \uff08\u51fa\u529b\u5148\uff09  \u30eb\u30fc\u30c8\u30c7\u30a3\u30ec\u30af\u30c8\u30ea\n\n\u203b\uff08\u66f8\u5f0f\uff09\u300c\u65b0\u805e\u793e\u540d\u3000\u8a18\u4e8b\u30bf\u30a4\u30c8\u30eb\u3000\u30b9\u30af\u30ec\u30a4\u30d4\u30f3\u30b0\u5b9f\u884c\u5e74\u6708\u65e5\u6642\u5206\u79d2\u3000\u8a18\u4e8b\u672c\u6587\u6587\u5b57\u6570\u300d\uff08\u30bf\u30d6\u533a\u5207\u308a\uff09\n\n3. \u5404\u8a18\u4e8b \u672c\u6587\u30c6\u30ad\u30b9\u30c8\u30d5\u30a1\u30a4\u30eb \u3092\u4fc2\u308a\u53d7\u3051\u5206\u89e3\u3057\u3066\u3001\u300cXXX\uff08\u4e3b\u8a9e\u30d5\u30ec\u30fc\u30ba\uff09 => YYY\uff08\u8ff0\u8a9e\u30d5\u30ec\u30fc\u30ba\uff09\u300d\u306e\u5168\u30da\u30a2 \u51fa\u529b\n\uff08\u30b9\u30af\u30ea\u30d7\u30c8\u540d\uff09 get_kakariuke_wordpairs.rb\n\uff08\u8aad\u307f\u8fbc\u307f\u30d5\u30a1\u30a4\u30eb\uff09 \u5404\u8a18\u4e8b\u306e\u8a18\u4e8b\u672c\u6587\u30c6\u30ad\u30b9\u30c8\u30d5\u30a1\u30a4\u30eb\n\uff08\u51fa\u529b\u30d5\u30a1\u30a4\u30eb\uff09word_pairs:\u301c \uff08\u8a18\u4e8b\u672c\u6570\u5206\u3001\u30d5\u30a1\u30a4\u30eb\u751f\u6210)  \uff08\u51fa\u529b\u5148\uff09 kiji_honbun_textfile\n\n4. \u6307\u5b9a\u3057\u305f\u300c\u4e3b\u8a9e\u30d5\u30ec\u30fc\u30ba => \u8ff0\u8a9e\u30d5\u30ec\u30fc\u30ba\u300d\u306e\u691c\u51fa\u56de\u6570\u3092\u96c6\u8a08 & \u51fa\u529b\n\uff08\u30b9\u30af\u30ea\u30d7\u30c8\u540d\uff09matched_wordpairs_counter.py\n\uff08\u8aad\u8fbc\u307f\u30d5\u30a1\u30a4\u30eb\uff09\u5404\u8a18\u4e8b\u306eword_pairs:\u301c \u30d5\u30a1\u30a4\u30eb\n\uff08\u51fa\u529b\u30d5\u30a1\u30a4\u30eb\uff09 \n\u3000\u3000\u3000\u3000\u3000\u3000\u3000\u3000\uff08\uff11\uff09 kiji_evaluation_result.csv \uff08\u691c\u7d22\u8a9e\u53e5\u30d2\u30c3\u30c8\u3057\u305f\u8a18\u4e8b \u672c\u6570\u5206\uff09\n\u3000\u3000\u3000\u3000\u3000\u3000\u3000\u3000\uff08\uff12\uff09 kiji_scores.csv (\uff11\u30d5\u30a1\u30a4\u30eb\uff09 \n\u4eca\u56de\u306f\u3001\uff08\u4e3b\u8a9e \u8a9e\u53e5\uff09\u300c List 1 \u306e\u3046\u3061\u3001\u3044\u305a\u308c\u304b\u306e\u5358\u8a9e \u300d ==>>\uff08\u8ff0\u8a9e \u8a9e\u53e5\uff09 \u300c List 2 \u306e\u3046\u3061\u3001\u3044\u305a\u308c\u304b\u306e\u5358\u8a9e \u300d\n\u306b\u8a72\u5f53\u3059\u308b \u4fc2\u308a\u53d7\u3051\u30da\u30a2 \u6587 \u3092 \u5168\u4fc2\u308a\u53d7\u3051\u8a9e\u53e5\u30da\u30a2\u4e00\u89a7\u30ea\u30b9\u30c8 \u306e\u306a\u304b\u304b\u3089\u3001\u691c\u51fa\u3057\u3066\u307f\u307e\u3059\u3002\n\nList 1 : \u4fc2\u308a\u53d7\u3051\u5143 \u5358\u8a9e\u30ea\u30b9\u30c8\n\"TPP\", \"JA\u5168\u4e2d\", \"\u8fb2\u696d\u56e3\u4f53\", \"\u81ea\u6c11\u515a\", \"\u9996\u5e2d\u4ea4\u6e09\u5b98\", \"USTR\"\nList 2 : \u4fc2\u308a\u53d7\u3051\u5148 \u5358\u8a9e\u30ea\u30b9\u30c8\n\"\u5206\u304b\u3063\u305f\", \"\u5224\u660e\", \"\u8abf\u6574\", \"\u4ea4\u6e09\", \"\u59a5\u7d50\", \"\u5354\u8b70\", \"\u7d99\u7d9a\", \"\u6301\u3061\u8d8a\u3057\", \"\u59a5\u5354\", \"\u767a\u8868\"\n\n\n5. \u8a18\u4e8b \u5c5e\u6027\u30c7\u30fc\u30bf\u4e00\u89a7\u30d5\u30a1\u30a4\u30eb \u751f\u6210\u2460 (\u300c\u8a18\u4e8b\u30bf\u30a4\u30c8\u30eb\uff11 - \u8a18\u4e8b\u306e\u65b0\u805e\u793e\u30b5\u30a4\u30c8\u63b2\u8f09\u5e74\u6708\u65e5\u300d \u30ea\u30b9\u30c8\u30d5\u30a1\u30a4\u30eb\u51fa\u529b\uff09\n\uff08\u30b9\u30af\u30ea\u30d7\u30c8\u540d\uff09create_article_website_posted_date_list.py\n\uff08\u8aad\u307f\u8fbc\u307f\u30d5\u30a1\u30a4\u30eb\uff09\u5404\u8a18\u4e8b\u306ehtml\u30d5\u30a1\u30a4\u30eb\n\uff08\u51fa\u529b\u30d5\u30a1\u30a4\u30eb\uff09kiji_title_date_list.csv \uff08\u51fa\u529b\u5148\uff09html_file\u30c7\u30a3\u30ec\u30af\u30c8\u30ea\n                           <\u66f8\u5f0f> \u300c\u8a18\u4e8b\u30bf\u30a4\u30c8\u30eb\uff11 - \u8a18\u4e8b\u306e\u65b0\u805e\u793e\u30b5\u30a4\u30c8\u63b2\u8f09\u5e74\u6708\u65e5\u300d\n\n6. \u8a18\u4e8b \u5c5e\u6027\u30c7\u30fc\u30bf\u4e00\u89a7\u30d5\u30a1\u30a4\u30eb \u751f\u6210\u2460 \uff08\u4ee5\u4e0b\u306e\u4e00\u89a7\u30d5\u30a1\u30a4\u30eb\u3092\u751f\u6210\uff09\n\uff08\u30b9\u30af\u30ea\u30d7\u30c8\u540d\uff09create_kiji_metadata_files.py\n\uff08\u51fa\u529b\u30d5\u30a1\u30a4\u30eb\uff09\n\u3000\u3000\u3000\u3000\u3000\u3000\u3000\u3000\uff08\uff11\uff09 \u65b0\u805e\u793e\u540d-\u8a18\u4e8b\u30bf\u30a4\u30c8\u30eb-\u8a18\u4e8b\u30b9\u30af\u30ec\u30a4\u30d4\u30f3\u30b0\u6642\u523b-\u8a18\u4e8b\u6587\u5b57\u6570-\u30a6\u30a7\u30d6\u30b5\u30a4\u30c8\u8a18\u4e8b\u63b2\u8f09\u5e74\u6708\u65e5.csv\n\u3000\u3000\u3000\u3000\u3000\u3000\u3000\u3000\uff08\uff12\uff09 \u8a18\u4e8b\u30bf\u30a4\u30c8\u30eb \u8a18\u4e8b\u8a55\u70b9.csv\n\u3000\u3000\u3000\u3000\u3000\u3000\u3000\u3000\uff08\uff13\uff09 \u8a18\u4e8b\u30bf\u30a4\u30c8\u30eb-\u8a18\u4e8b\u6b04\u540d.csv\n\n7. \u8a18\u4e8b\u30bf\u30a4\u30c8\u30eb - \u8a18\u4e8b\u672c\u6587 \u306e\u4e00\u89a7\u30d5\u30a1\u30a4\u30eb \u751f\u6210\ncreate_kiji_title_honbun_list.py\n\n\uff08\u51fa\u529b\u30d5\u30a1\u30a4\u30eb\uff09  kiji_title_honbun_list \n\n\n\n\u8cc7\u6e90\u914d\u7f6e\u95a2\u4fc2\n\u3010root\u30c7\u30a3\u30ec\u30af\u30c8\u30ea\u3011: \u2460 create_article_title_url_list.py / \u2461 create_kiji_honbun_textfile_htmlfile.py / \u2465 create_kiji_metadata_files.py\n   |\n   |\n   |---\u3010kiji_honbun_textfile \u30c7\u30a3\u30ec\u30af\u30c8\u30ea\u3011 \u2462   get_kakariuke_wordpairs.rb  /  \u2463 matched_wordpairs_counter.py / \u2466 create_kiji_title_honbun_list.py\n   |\n   |---\u3010html_file \u30c7\u30a3\u30ec\u30af\u30c8\u30ea\u3011\u2464 create_article_website_posted_date_list.py \n\n\n\u30b9\u30af\u30ea\u30d7\u30c8\n\ncreate_article_title_url_list.py\n\n\ncreate_article_title_url_list.py\n#!/usr/bin/env python2.7\n# ~*- coding: utf-8 -*-\n\nimport re, os, urllib2, types, codecs\nfrom bs4 import BeautifulSoup\n\n\ndef get_soup_from_url(url):\n    htmlfile = url.read()\n    soup = BeautifulSoup(htmlfile)\n    return soup\n\n\ndef output_title_list(tag, tab_name):\n    if not(tag):\n        return \"\"\n\n    anchor_tag_list = tag.findAll(\"a\")\n    output_file_path = os.getcwd()+\"/titles_\"+tab_name+\".txt\"\n\n    ng_pattern = re.compile(\"(\\A[0-9]+\\Z)\")\n\n    article_title_list = [\"\"] \n\n    for anchor_tag in anchor_tag_list:\n        article_title = anchor_tag.string.encode('utf-8')\n\n        if (\"\u7d9a\u304d\u3092\u8aad\u3080\" in article_title) or (\"\u3082\u3063\u3068\u898b\u308b\" in article_title):\n            continue\n\n        if ng_pattern.search(article_title):\n            continue\n\n        if (\"\u6b21\u3078\" in article_title) or (\"\u524d\u3078\" in article_title):\n            continue\n\n        article_title_list.append(str(article_title).decode('utf-8'))\n\n\n    del article_title_list[0]\n    return article_title_list\n\n\n\ndef output_url_list(tag, tab_name):\n    if not(tag):\n        return \"\"\n\n    li_tag_list = tag.findAll(\"li\")\n\n    pattern = re.compile(\"(\\/.+html)\")\n    url_head_string = \"http://www.sankei.com\"\n\n    article_url_list = [\"\"]\n\n    for li_tag in li_tag_list:\n        url_unicode = unicode(li_tag)\n\n        if \"html\" in url_unicode:\n            url = pattern.search(url_unicode)\n            if not url:\n                continue\n            else:\n                article_url_list.append(url_head_string+url.group(0))\n\n\n    del article_url_list[0]\n    return article_url_list\n\n\ndef output_article_info_list(tag, tab_name):\n    article_title_list = output_title_list(tag, tab_name)\n    article_url_list = output_url_list(tag, tab_name)\n\n    return [article_title_list, article_url_list]\n\n\n#======================== \u30e1\u30bd\u30c3\u30c9\u5b9a\u7fa9\u304a\u308f\u308a ===================================\n\n\n\n#==== \u300c\u30db\u30fc\u30e0\u300d\u6b04 \u30c7\u30d5\u30a9\u30eb\u30c8\u8868\u793a\u30da\u30fc\u30b8 \u753b\u9762\u63b2\u8f09\u5168\u8a18\u4e8b\u60c5\u5831\u51fa\u529b\uff08\u300c\u3082\u3063\u3068\u898b\u308b\u300d\u30af\u30ea\u30c3\u30af\u524d\uff09\nurl_home_top = urllib2.urlopen('http://www.sankei.com/')\ntab_name = \"home_top\"\n\nsoup = get_soup_from_url(url_home_top)\n\n# Home\u6b04\u30c7\u30d5\u30a9\u30eb\u30c8\u753b\u9762\u3000\u6700\u4e0a\u6bb5\u306e\u5927\u30b5\u30a4\u30ba\u6587\u5b57\u8868\u8a18 \u8a18\u4e8b\uff11\u672c \ndiv_tag_1 = soup.find(\"section\", {\"class\" : \"modToppick clearfix\"})\n\n# Home\u6b04\u30c7\u30d5\u30a9\u30eb\u30c8\u753b\u9762\u3000\u666e\u901a\u30b5\u30a4\u30ba\u6587\u5b57\u8868\u8a18 \u305d\u306e\u4ed6 \u8907\u6570 \u8a18\u4e8b \ndiv_tag_2 = soup.find(\"section\", {\"class\" : \"modToplist\"})\n\ntop_article_title, top_article_url = output_article_info_list(div_tag_1, tab_name)\narticle_title_list, article_url_list = output_article_info_list(div_tag_2, tab_name)\n\n#===== \u304a\u308f\u308a (\u300c\u30db\u30fc\u30e0\u300d\u6b04 \u30c7\u30d5\u30a9\u30eb\u30c8\u8868\u793a\u30da\u30fc\u30b8)=======================================\n\n\n#==== \u300c\u901f\u5831\u300d\u6b04 \u30da\u30fc\u30b8 \u753b\u9762\u63b2\u8f09\u5168\u8a18\u4e8b\u60c5\u5831\u51fa\u529b\uff08\u300c\u30db\u30fc\u30e0\u300d\u753b\u9762 \u4e0b\u306e\u300c\u3082\u3063\u3068\u898b\u308b\u300d\u30af\u30ea\u30c3\u30af\u5f8c\u306b\u9077\u79fb\u3059\u308b\u753b\u9762\uff09\n\n#\u300c\u901f\u5831 \u8a73\u7d30\u30da\u30fc\u30b8\u300d\u306f\u8907\u6570\u30da\u30fc\u30b8\u306b\u308f\u305f\u308b\u305f\u3081\u3001\u5404\u8a18\u4e8b\u76ee\u6b21\u30da\u30fc\u30b8\u306eURL\u3092\u53d6\u5f97\nurl_home_detail_1 = urllib2.urlopen('http://www.sankei.com/flash/newslist/flash-n1.html')\nsoup = get_soup_from_url(url_home_detail_1)\n\nindex_page_url_list = ['http://www.sankei.com/flash/newslist/flash-n1.html'] \n\ndiv_tag = soup.find(\"div\", {\"class\" : \"pagenator\"})\nanchor_tag_list = div_tag.findAll(\"a\", {\"class\" : \"page\"})\npattern = re.compile(\"(\\/.+html)\")\nurl_head_string = \"http://www.sankei.com/flash/newslist\"\n\n\nfor anchor_tag in anchor_tag_list:\n    url_unicode = unicode(anchor_tag)\n    if \"html\" in url_unicode:\n        url = pattern.search(url_unicode)\n        if url:\n            index_page_url_list.append(url_head_string+url.group(0))\n\n\ntitle_list_sokuhou_article = []\nurl_list_sokuhou_article = []\n\nfor index_page_url in index_page_url_list:\n\n    #\u8a18\u4e8b\u76ee\u6b21\u30da\u30fc\u30b8 \uff11\u30da\u30fc\u30b8\u3054\u3068\u306b\u3001\u305d\u308c\u305e\u308c\u4e0b\u8a18\u3092\u5b9f\u884c\u3057\u3066\u3001\u76ee\u6b21\u8a18\u8f09 \u8a18\u4e8b\u306e\u30bf\u30a4\u30c8\u30eb\u30fbURL\u3092\u30d5\u30a1\u30a4\u30eb\u306b\u51fa\u529b\n    tab_name = \"home\"\n    url = urllib2.urlopen(index_page_url)\n    soup = get_soup_from_url(url)\n    div_tag = soup.find(\"section\", {\"class\" : \"indexText clearfix\"})\n\n    title_partlist_sokuhou_article, url_partlist_sokuhou_article = output_article_info_list(div_tag, tab_name)\n    title_list_sokuhou_article.extend(title_partlist_sokuhou_article)\n    url_list_sokuhou_article.extend(url_partlist_sokuhou_article)\n\n#===== \u304a\u308f\u308a (\u901f\u5831\u6b04 \u8a73\u7d30\u8868\u793a\u30da\u30fc\u30b8)=======================================\n\n\n#==== \u300c\u4e8b\u4ef6\u300d\u6b04 \u8a73\u7d30\u30da\u30fc\u30b8 \u753b\u9762\u63b2\u8f09\u5168\u8a18\u4e8b\u60c5\u5831\u51fa\u529b\uff08\u300c\u4e8b\u4ef6\u300d\u6b04 \u4e0b\u306e\u300c\u3082\u3063\u3068\u898b\u308b\u300d\u30af\u30ea\u30c3\u30af\u5f8c\uff09\n\n#\u300c\u4e8b\u4ef6 \u8a73\u7d30\u30da\u30fc\u30b8\u300d\u306f\u8907\u6570\u30da\u30fc\u30b8\u306b\u308f\u305f\u308b\u305f\u3081\u3001\u5404\u8a18\u4e8b\u76ee\u6b21\u30da\u30fc\u30b8\u306eURL\u3092\u53d6\u5f97\njiken_detail_1 = urllib2.urlopen('http://www.sankei.com/affairs/newslist/affairs-n1.html')\nsoup = get_soup_from_url(jiken_detail_1)\n\nindex_page_url_list = ['http://www.sankei.com/affairs/newslist/affairs-n1.html'] \n\ndiv_tag = soup.find(\"div\", {\"class\" : \"pagenator\"})\nanchor_tag_list = div_tag.findAll(\"a\", {\"class\" : \"page\"})\npattern = re.compile(\"(\\/.+html)\")\nurl_head_string = \"http://www.sankei.com/affairs/newslist\"\n\nfor anchor_tag in anchor_tag_list:\n    url_unicode = unicode(anchor_tag)\n    if \"html\" in url_unicode:\n        url = pattern.search(url_unicode)\n        if url:\n            index_page_url_list.append(url_head_string+url.group(0))\n\ntitle_list_jiken_article = []\nurl_list_jiken_article = []\n\nfor index_page_url in index_page_url_list:\n\n    #\u8a18\u4e8b\u76ee\u6b21\u30da\u30fc\u30b8 \uff11\u30da\u30fc\u30b8\u3054\u3068\u306b\u3001\u305d\u308c\u305e\u308c\u4e0b\u8a18\u3092\u5b9f\u884c\u3057\u3066\u3001\u76ee\u6b21\u8a18\u8f09 \u8a18\u4e8b\u306e\u30bf\u30a4\u30c8\u30eb\u30fbURL\u3092\u30d5\u30a1\u30a4\u30eb\u306b\u51fa\u529b\n    tab_name = \"jiken\"\n    url = urllib2.urlopen(index_page_url)\n    soup = get_soup_from_url(url)\n    div_tag = soup.find(\"section\", {\"class\" : \"indexText clearfix\"})\n\n    title_partlist_jiken_article, url_partlist_jiken_article = output_article_info_list(div_tag, tab_name)\n    title_list_jiken_article.extend(title_partlist_jiken_article)\n    url_list_jiken_article.extend(url_partlist_jiken_article)\n\n#===== \u304a\u308f\u308a (\u300c\u4e8b\u4ef6\u300d\u6b04 \u8a73\u7d30\u8868\u793a\u30da\u30fc\u30b8)=======================================\n\n\n#==== \u300c\u653f\u6cbb\u300d\u6b04 \u8a73\u7d30\u30da\u30fc\u30b8 \u753b\u9762\u63b2\u8f09\u5168\u8a18\u4e8b\u60c5\u5831\u51fa\u529b\uff08\u300c\u653f\u6cbb\u300d\u6b04 \u4e0b\u306e\u300c\u3082\u3063\u3068\u898b\u308b\u300d\u30af\u30ea\u30c3\u30af\u5f8c\uff09\n\n#\u300c\u653f\u6cbb \u8a73\u7d30\u30da\u30fc\u30b8\u300d\u306f\u8907\u6570\u30da\u30fc\u30b8\u306b\u308f\u305f\u308b\u305f\u3081\u3001\u5404\u8a18\u4e8b\u76ee\u6b21\u30da\u30fc\u30b8\u306eURL\u3092\u53d6\u5f97\nseiji_detail_1 = urllib2.urlopen('http://www.sankei.com/politics/newslist/politics-n1.html')\nsoup = get_soup_from_url(seiji_detail_1)\n\nindex_page_url_list = ['http://www.sankei.com/politics/newslist/politics-n1.html'] \n\ndiv_tag = soup.find(\"div\", {\"class\" : \"pagenator\"})\nanchor_tag_list = div_tag.findAll(\"a\", {\"class\" : \"page\"})\npattern = re.compile(\"(\\/.+html)\")\nurl_head_string = \"http://www.sankei.com/politics/newslist\"#\n\nfor anchor_tag in anchor_tag_list:\n    url_unicode = unicode(anchor_tag)\n    if \"html\" in url_unicode:\n        url = pattern.search(url_unicode)\n        if url:\n            index_page_url_list.append(url_head_string+url.group(0))\n\n\ntitle_list_seiji_article = []\nurl_list_seiji_article = []\n\nfor index_page_url in index_page_url_list:\n\n    #\u8a18\u4e8b\u76ee\u6b21\u30da\u30fc\u30b8 \uff11\u30da\u30fc\u30b8\u3054\u3068\u306b\u3001\u305d\u308c\u305e\u308c\u4e0b\u8a18\u3092\u5b9f\u884c\u3057\u3066\u3001\u76ee\u6b21\u8a18\u8f09 \u8a18\u4e8b\u306e\u30bf\u30a4\u30c8\u30eb\u30fbURL\u3092\u30d5\u30a1\u30a4\u30eb\u306b\u51fa\u529b\n    tab_name = \"seiji\"\n    url = urllib2.urlopen(index_page_url)\n    soup = get_soup_from_url(url)\n    div_tag = soup.find(\"section\", {\"class\" : \"indexText clearfix\"})\n\n    title_partlist_seiji_article, url_partlist_seiji_article = output_article_info_list(div_tag, tab_name)\n    title_list_seiji_article.extend(title_partlist_seiji_article)\n    url_list_seiji_article.extend(url_partlist_seiji_article)\n\n#===== \u304a\u308f\u308a (\u300c\u653f\u6cbb\u300d\u6b04 \u8a73\u7d30\u8868\u793a\u30da\u30fc\u30b8)=======================================\n\n\n#==== \u300c\u56fd\u969b\u300d\u6b04 \u8a73\u7d30\u30da\u30fc\u30b8 \u753b\u9762\u63b2\u8f09\u5168\u8a18\u4e8b\u60c5\u5831\u51fa\u529b\uff08\u300c\u56fd\u969b\u300d\u6b04 \u4e0b\u306e\u300c\u3082\u3063\u3068\u898b\u308b\u300d\u30af\u30ea\u30c3\u30af\u5f8c\uff09\n\n#\u300c\u56fd\u969b \u8a73\u7d30\u30da\u30fc\u30b8\u300d\u306f\u8907\u6570\u30da\u30fc\u30b8\u306b\u308f\u305f\u308b\u305f\u3081\u3001\u5404\u8a18\u4e8b\u76ee\u6b21\u30da\u30fc\u30b8\u306eURL\u3092\u53d6\u5f97\nkokusai_detail_1 = urllib2.urlopen('http://www.sankei.com/world/newslist/world-n1.html')\nsoup = get_soup_from_url(kokusai_detail_1)\n\nindex_page_url_list = ['http://www.sankei.com/world/newslist/world-n1.html'] \n\ndiv_tag = soup.find(\"div\", {\"class\" : \"pagenator\"})\nanchor_tag_list = div_tag.findAll(\"a\", {\"class\" : \"page\"})\npattern = re.compile(\"(\\/.+html)\")\nurl_head_string = \"http://www.sankei.com/world/newslist\"#\n\nfor anchor_tag in anchor_tag_list:\n    url_unicode = unicode(anchor_tag)\n    if \"html\" in url_unicode:\n        url = pattern.search(url_unicode)\n        if url:\n            index_page_url_list.append(url_head_string+url.group(0))\n\ntitle_list_kokusai_article = []\nurl_list_kokusai_article = []\n\nfor index_page_url in index_page_url_list:\n\n    #\u8a18\u4e8b\u76ee\u6b21\u30da\u30fc\u30b8 \uff11\u30da\u30fc\u30b8\u3054\u3068\u306b\u3001\u305d\u308c\u305e\u308c\u4e0b\u8a18\u3092\u5b9f\u884c\u3057\u3066\u3001\u76ee\u6b21\u8a18\u8f09 \u8a18\u4e8b\u306e\u30bf\u30a4\u30c8\u30eb\u30fbURL\u3092\u30d5\u30a1\u30a4\u30eb\u306b\u51fa\u529b\n    tab_name = \"kokusai\"\n    url = urllib2.urlopen(index_page_url)\n    soup = get_soup_from_url(url)\n    div_tag = soup.find(\"section\", {\"class\" : \"indexText clearfix\"})\n\n    title_partlist_kokusai_article, url_partlist_kokusai_article = output_article_info_list(div_tag, tab_name)\n    title_list_kokusai_article.extend(title_partlist_kokusai_article)\n    url_list_kokusai_article.extend(url_partlist_kokusai_article)\n\n\n#===== \u304a\u308f\u308a (\u300c\u56fd\u969b\u300d\u6b04 \u8a73\u7d30\u8868\u793a\u30da\u30fc\u30b8)=======================================\n\n\n#==== \u300c\u7d4c\u6e08\u300d\u6b04 \u8a73\u7d30\u30da\u30fc\u30b8 \u753b\u9762\u63b2\u8f09\u5168\u8a18\u4e8b\u60c5\u5831\u51fa\u529b\uff08\u300c\u7d4c\u6e08\u300d\u6b04 \u4e0b\u306e\u300c\u3082\u3063\u3068\u898b\u308b\u300d\u30af\u30ea\u30c3\u30af\u5f8c\uff09\n\n#\u300c\u7d4c\u6e08 \u8a73\u7d30\u30da\u30fc\u30b8\u300d\u306f\u8907\u6570\u30da\u30fc\u30b8\u306b\u308f\u305f\u308b\u305f\u3081\u3001\u5404\u8a18\u4e8b\u76ee\u6b21\u30da\u30fc\u30b8\u306eURL\u3092\u53d6\u5f97\nkeizai_detail_1 = urllib2.urlopen('http://www.sankei.com/economy/newslist/economy-n1.html')\nsoup = get_soup_from_url(keizai_detail_1)\n\nindex_page_url_list = ['http://www.sankei.com/economy/newslist/economy-n1.html'] \n\ndiv_tag = soup.find(\"div\", {\"class\" : \"pagenator\"})\nanchor_tag_list = div_tag.findAll(\"a\", {\"class\" : \"page\"})\npattern = re.compile(\"(\\/.+html)\")\nurl_head_string = \"http://www.sankei.com/economy/newslist\"#\n\nfor anchor_tag in anchor_tag_list:\n    url_unicode = unicode(anchor_tag)\n    if \"html\" in url_unicode:\n        url = pattern.search(url_unicode)\n        if url:\n            index_page_url_list.append(url_head_string+url.group(0))\n\n\ntitle_list_keizai_article = []\nurl_list_keizai_article = []\n\nfor index_page_url in index_page_url_list:\n\n    #\u8a18\u4e8b\u76ee\u6b21\u30da\u30fc\u30b8 \uff11\u30da\u30fc\u30b8\u3054\u3068\u306b\u3001\u305d\u308c\u305e\u308c\u4e0b\u8a18\u3092\u5b9f\u884c\u3057\u3066\u3001\u76ee\u6b21\u8a18\u8f09 \u8a18\u4e8b\u306e\u30bf\u30a4\u30c8\u30eb\u30fbURL\u3092\u30d5\u30a1\u30a4\u30eb\u306b\u51fa\u529b\n    tab_name = \"keizai\"\n    url = urllib2.urlopen(index_page_url)\n    soup = get_soup_from_url(url)\n    div_tag = soup.find(\"section\", {\"class\" : \"indexText clearfix\"})\n\n    title_partlist_keizai_article, url_partlist_keizai_article = output_article_info_list(div_tag, tab_name)\n    title_list_keizai_article.extend(title_partlist_keizai_article)\n    url_list_keizai_article.extend(url_partlist_keizai_article)\n\n#===== \u304a\u308f\u308a (\u300c\u7d4c\u6e08\u300d\u6b04 \u8a73\u7d30\u8868\u793a\u30da\u30fc\u30b8)=======================================\n\n\n#==== \u300c\u30b3\u30e9\u30e0\u300d\u6b04 \u8a73\u7d30\u30da\u30fc\u30b8 \u753b\u9762\u63b2\u8f09\u5168\u8a18\u4e8b\u60c5\u5831\u51fa\u529b\uff08\u300c\u30b3\u30e9\u30e0\u300d\u6b04 \u4e0b\u306e\u300c\u3082\u3063\u3068\u898b\u308b\u300d\u30af\u30ea\u30c3\u30af\u5f8c\uff09\n\n#\u300c\u30b3\u30e9\u30e0 \u8a73\u7d30\u30da\u30fc\u30b8\u300d\u306f\u8907\u6570\u30da\u30fc\u30b8\u306b\u308f\u305f\u308b\u305f\u3081\u3001\u5404\u8a18\u4e8b\u76ee\u6b21\u30da\u30fc\u30b8\u306eURL\u3092\u53d6\u5f97\nkoramu_detail_1 = urllib2.urlopen('http://www.sankei.com/column/newslist/column-n1.html')\nsoup = get_soup_from_url(koramu_detail_1)\n\nindex_page_url_list = ['http://www.sankei.com/column/newslist/column-n1.html'] \n\ndiv_tag = soup.find(\"div\", {\"class\" : \"pagenator\"})\nanchor_tag_list = div_tag.findAll(\"a\", {\"class\" : \"page\"})\npattern = re.compile(\"(\\/.+html)\")\nurl_head_string = \"http://www.sankei.com/column/newslist\"#\n\nfor anchor_tag in anchor_tag_list:\n    url_unicode = unicode(anchor_tag)\n    if \"html\" in url_unicode:\n        url = pattern.search(url_unicode)\n        if url:\n            index_page_url_list.append(url_head_string+url.group(0))\n\n\ntitle_list_koramu_article = []\nurl_list_koramu_article = []\n\nfor index_page_url in index_page_url_list:\n\n    #\u8a18\u4e8b\u76ee\u6b21\u30da\u30fc\u30b8 \uff11\u30da\u30fc\u30b8\u3054\u3068\u306b\u3001\u305d\u308c\u305e\u308c\u4e0b\u8a18\u3092\u5b9f\u884c\u3057\u3066\u3001\u76ee\u6b21\u8a18\u8f09 \u8a18\u4e8b\u306e\u30bf\u30a4\u30c8\u30eb\u30fbURL\u3092\u30d5\u30a1\u30a4\u30eb\u306b\u51fa\u529b\n    tab_name = \"column\"\n    url = urllib2.urlopen(index_page_url)\n    soup = get_soup_from_url(url)\n    div_tag = soup.find(\"section\", {\"class\" : \"indexText clearfix\"})\n\n    title_partlist_koramu_article, url_partlist_koramu_article = output_article_info_list(div_tag, tab_name)\n    title_list_koramu_article.extend(title_partlist_koramu_article)\n    url_list_koramu_article.extend(url_partlist_koramu_article)\n\n\n#===== \u304a\u308f\u308a (\u300c\u30b3\u30e9\u30e0\u300d\u6b04 \u8a73\u7d30\u8868\u793a\u30da\u30fc\u30b8)=======================================\n\n\n#==== \u3059\u3079\u3066\u306e\u6b04 \u63b2\u8f09\u8a18\u4e8b \u8a18\u4e8b\u30bf\u30a4\u30c8\u30eb\u30fbURL\u30ea\u30b9\u30c8 \uff08\uff12\u4ef6\u4ee5\u4e0a\u306e\u6b04\u306b\u91cd\u8907 \u63b2\u8f09\u3055\u308c\u3066\u3044\u308b\u8a18\u4e8b\u306f\u3001\uff11\u56de\u306e\u307f\u8868\u793a\uff09\n\n#\u3000\u540c\u4e00\u30bf\u30a4\u30c8\u30eb\u306e\u8a18\u4e8b\u304c\u3001\u8907\u6570\u306e\u6b04\u306b\u63b2\u8f09\u3055\u308c\u308b\u5834\u5408\u3001\u30bf\u30a4\u30c8\u30eb\u306f\uff11\u3064\u3001URL\u306f\u8907\u6570 \u306b\u306a\u308b\u3002\u3053\u306e\u305f\u3081\u3001\u30bf\u30a4\u30c8\u30eb\u30ea\u30b9\u30c8\u3068URL\u30ea\u30b9\u30c8\u3092\u5225\u3005\u306b\u91cd\u8907\u6392\u9664\u3059\u308b\u3068\u30bf\u30a4\u30c8\u30eb\u30ea\u30b9\u30c8\u306e\u8981\u7d20\u6570\u306e\u307f\u5c11\u306a\u304f\u306a\u308b\u3002\n#  \u4e0a\u8a18\u306e\u7406\u7531\u304b\u3089\u3001\u300c\u8a18\u4e8b\u30bf\u30a4\u30c8\u30eb - \u8a18\u4e8bURL\u300d \u306e\u7d44\u307f\u5408\u308f\u305b\u3092 key-value \u30c7\u30fc\u30bf\u306e\u3088\u3046\u306b\u751f\u6210\u3057\u3066\u3001\u5f53\u8a72\u30c7\u30fc\u30bf\u306e\u91cd\u8907\u6392\u9664\u3092\u884c\u3046\n\n\n# \u8f9e\u66f8\u306e\u521d\u671f\u5316\nsokuhou_dict = {\"key_top\": \"value_top\"}  \n\n# \u300c\u901f\u5831\u300d\u6b04\u306e\u8a18\u4e8b\nif len(title_list_sokuhou_article) == len(url_list_sokuhou_article):\n    print \"\u300c\u901f\u5831\u300d\u6b04\u306e\u8a18\u4e8b\u306f\u3001\u8a18\u4e8b\u30bf\u30a4\u30c8\u30eb\u4ef6\u6570 \u3068 \u8a18\u4e8bURL\u4ef6\u6570 \u304c\u9f5f\u9f6c\u306a\u304f\u4e00\u81f4\u3057\u307e\u3057\u305f\u3002\u554f\u984c\u3042\u308a\u307e\u305b\u3093\u3002\\n\"\n    for i in range(0, len(title_list_sokuhou_article)):\n        sokuhou_dict[title_list_sokuhou_article[i]] = url_list_sokuhou_article[i]\nelse:\n    print \"\u300c\u901f\u5831\u300d\u6b04\u306e\u8a18\u4e8b\u306f\u3001\u8a18\u4e8b\u30bf\u30a4\u30c8\u30eb\u4ef6\u6570 \u3068 \u8a18\u4e8bURL\u4ef6\u6570 \u304c\u4e00\u81f4\u3057\u307e\u305b\u3093\u3002\u30ea\u30b9\u30c8\u306e\u95a2\u4fc2\u6027\u306b\u9f5f\u9f6c\u304c\u3042\u308a\u307e\u3059\u3002\\n\"\n\ndel(sokuhou_dict[\"key_top\"])\n\n\n# \u300c\u4e8b\u4ef6\u300d\u6b04\u306e\u8a18\u4e8b\njiken_dict = {\"key_top\": \"value_top\"}  \n\nif len(title_list_jiken_article) == len(url_list_jiken_article):\n    print \"\u300c\u4e8b\u4ef6\u300d\u6b04\u306e\u8a18\u4e8b\u306f\u3001\u8a18\u4e8b\u30bf\u30a4\u30c8\u30eb\u4ef6\u6570 \u3068 \u8a18\u4e8bURL\u4ef6\u6570 \u304c\u9f5f\u9f6c\u306a\u304f\u4e00\u81f4\u3057\u307e\u3057\u305f\u3002\u554f\u984c\u3042\u308a\u307e\u305b\u3093\u3002\\n\"\n    for i in range(0, len(title_list_jiken_article)):\n        jiken_dict[title_list_jiken_article[i]] = url_list_jiken_article[i]\nelse:\n    print \"\u300c\u4e8b\u4ef6\u300d\u6b04\u306e\u8a18\u4e8b\u306f\u3001\u8a18\u4e8b\u30bf\u30a4\u30c8\u30eb\u4ef6\u6570 \u3068 \u8a18\u4e8bURL\u4ef6\u6570 \u304c\u4e00\u81f4\u3057\u307e\u305b\u3093\u3002\u30ea\u30b9\u30c8\u306e\u95a2\u4fc2\u6027\u306b\u9f5f\u9f6c\u304c\u3042\u308a\u307e\u3059\u3002\\n\"\n\ndel(jiken_dict[\"key_top\"])\n\n\n# \u300c\u653f\u6cbb\u300d\u6b04\u306e\u8a18\u4e8b\nseiji_dict = {\"key_top\": \"value_top\"} \n\nif len(title_list_seiji_article) == len(url_list_seiji_article):\n    print \"\u300c\u653f\u6cbb\u300d\u6b04\u306e\u8a18\u4e8b\u306f\u3001\u8a18\u4e8b\u30bf\u30a4\u30c8\u30eb\u4ef6\u6570 \u3068 \u8a18\u4e8bURL\u4ef6\u6570 \u304c\u9f5f\u9f6c\u306a\u304f\u4e00\u81f4\u3057\u307e\u3057\u305f\u3002\u554f\u984c\u3042\u308a\u307e\u305b\u3093\u3002\\n\"\n    for i in range(0, len(title_list_seiji_article)):\n        seiji_dict[title_list_seiji_article[i]] = url_list_seiji_article[i]\nelse:\n    print \"\u300c\u653f\u6cbb\u300d\u6b04\u306e\u8a18\u4e8b\u306f\u3001\u8a18\u4e8b\u30bf\u30a4\u30c8\u30eb\u4ef6\u6570 \u3068 \u8a18\u4e8bURL\u4ef6\u6570 \u304c\u4e00\u81f4\u3057\u307e\u305b\u3093\u3002\u30ea\u30b9\u30c8\u306e\u95a2\u4fc2\u6027\u306b\u9f5f\u9f6c\u304c\u3042\u308a\u307e\u3059\u3002\\n\"\n\ndel(seiji_dict[\"key_top\"])\n\n\n# \u300c\u56fd\u969b\u300d\u6b04\u306e\u8a18\u4e8b\nkokusai_dict = {\"key_top\": \"value_top\"}\n\nif len(title_list_kokusai_article) == len(url_list_kokusai_article):\n    print \"\u300c\u56fd\u969b\u300d\u6b04\u306e\u8a18\u4e8b\u306f\u3001\u8a18\u4e8b\u30bf\u30a4\u30c8\u30eb\u4ef6\u6570 \u3068 \u8a18\u4e8bURL\u4ef6\u6570 \u304c\u9f5f\u9f6c\u306a\u304f\u4e00\u81f4\u3057\u307e\u3057\u305f\u3002\u554f\u984c\u3042\u308a\u307e\u305b\u3093\u3002\\n\"\n    for i in range(0, len(title_list_kokusai_article)):\n        kokusai_dict[title_list_kokusai_article[i]] = url_list_kokusai_article[i]\nelse:\n    print \"\u300c\u56fd\u969b\u300d\u6b04\u306e\u8a18\u4e8b\u306f\u3001\u8a18\u4e8b\u30bf\u30a4\u30c8\u30eb\u4ef6\u6570 \u3068 \u8a18\u4e8bURL\u4ef6\u6570 \u304c\u4e00\u81f4\u3057\u307e\u305b\u3093\u3002\u30ea\u30b9\u30c8\u306e\u95a2\u4fc2\u6027\u306b\u9f5f\u9f6c\u304c\u3042\u308a\u307e\u3059\u3002\\n\"\n\ndel(kokusai_dict[\"key_top\"])\n\n\n# \u300c\u7d4c\u6e08\u300d\u6b04\u306e\u8a18\u4e8b\nkeizai_dict = {\"key_top\": \"value_top\"}\n\nif len(title_list_keizai_article) == len(url_list_keizai_article):\n    print \"\u300c\u7d4c\u6e08\u300d\u6b04\u306e\u8a18\u4e8b\u306f\u3001\u8a18\u4e8b\u30bf\u30a4\u30c8\u30eb\u4ef6\u6570 \u3068 \u8a18\u4e8bURL\u4ef6\u6570 \u304c\u9f5f\u9f6c\u306a\u304f\u4e00\u81f4\u3057\u307e\u3057\u305f\u3002\u554f\u984c\u3042\u308a\u307e\u305b\u3093\u3002\\n\"\n    for i in range(0, len(title_list_keizai_article)):\n        keizai_dict[title_list_keizai_article[i]] = url_list_keizai_article[i]\nelse:\n    print \"\u300c\u7d4c\u6e08\u300d\u6b04\u306e\u8a18\u4e8b\u306f\u3001\u8a18\u4e8b\u30bf\u30a4\u30c8\u30eb\u4ef6\u6570 \u3068 \u8a18\u4e8bURL\u4ef6\u6570 \u304c\u4e00\u81f4\u3057\u307e\u305b\u3093\u3002\u30ea\u30b9\u30c8\u306e\u95a2\u4fc2\u6027\u306b\u9f5f\u9f6c\u304c\u3042\u308a\u307e\u3059\u3002\\n\"\n\ndel(keizai_dict[\"key_top\"])\n\n\n# \u300c\u30b3\u30e9\u30e0\u300d\u6b04\u306e\u8a18\u4e8b\nkoramu_dict = {\"key_top\": \"value_top\"}\n\nif len(title_list_koramu_article) == len(url_list_koramu_article):\n    print \"\u300c\u30b3\u30e9\u30e0\u300d\u6b04\u306e\u8a18\u4e8b\u306f\u3001\u8a18\u4e8b\u30bf\u30a4\u30c8\u30eb\u4ef6\u6570 \u3068 \u8a18\u4e8bURL\u4ef6\u6570 \u304c\u9f5f\u9f6c\u306a\u304f\u4e00\u81f4\u3057\u307e\u3057\u305f\u3002\u554f\u984c\u3042\u308a\u307e\u305b\u3093\u3002\\n\"\n    for i in range(0, len(title_list_koramu_article)):\n        koramu_dict[title_list_koramu_article[i]] = url_list_koramu_article[i]\nelse:\n    print \"\u300c\u30b3\u30e9\u30e0\u300d\u6b04\u306e\u8a18\u4e8b\u306f\u3001\u8a18\u4e8b\u30bf\u30a4\u30c8\u30eb\u4ef6\u6570 \u3068 \u8a18\u4e8bURL\u4ef6\u6570 \u304c\u4e00\u81f4\u3057\u307e\u305b\u3093\u3002\u30ea\u30b9\u30c8\u306e\u95a2\u4fc2\u6027\u306b\u9f5f\u9f6c\u304c\u3042\u308a\u307e\u3059\u3002\\n\"\n\ndel(koramu_dict[\"key_top\"])\n\n\n### \u3059\u3079\u3066\u306e\u8f9e\u66f8\u3092\u7d50\u5408 (\u53c2\u8003\uff09http://qiita.com/kk6/items/6362a5fc9f3f06a5969a\n### \u3010\u8981\u8abf\u67fb \u3011 reduce\u30e1\u30bd\u30c3\u30c9\u306f\u3001key\u304c\u91cd\u8907\u3057\u3066\u3001value\u304c\u91cd\u8907\u3057\u306a\u3044\uff08\u8f9e\u66f8\u306e\uff09\u8981\u7d20\u3092\u3001key\u304c\u540c\u3058\u3068\u3044\u3046\u7406\u7531\u3067\u30011\u4ef6\u306b\uff08\u5f8c\u7d9a\u306evalue\u3067\u4e0a\u66f8\u304d\u3057\u3066\uff09\u6271\u3046\u3053\u3068\u306f\u306a\u3044\u304b\uff1f\nall_dicts = [sokuhou_dict, jiken_dict, seiji_dict, kokusai_dict, keizai_dict, koramu_dict]\ngeneral_dict = reduce(lambda fst, scd: dict(fst, **scd), all_dicts)\n\n### \u8f9e\u66f8\u306e\u51fa\u529b \uff08\u53c2\u8003 \uff09http://www.yukun.info/blog/2008/06/python-dict2.html\noutput_file_path = os.getcwd()+\"/title_url_list_all_articles.txt\"\noutput_file = codecs.open(output_file_path, 'a', 'utf-8')\n\nfor k, v in general_dict.items():\n    output_file.write(k + \"   \" + v + \"\\n\")\n\noutput_file.close()\n\n\n\n\uff12\uff0ecreate_kiji_honbun_textfile_htmlfile.py\n\n\ncreate_kiji_honbun_textfile_htmlfile.py\n#!/usr/bin/enb python2.7\n# -*- coding: utf-8 -*-\n\nimport urllib2, re, codecs, os, sys, types, codecs, traceback, chardet\nfrom bs4 import BeautifulSoup\nfrom datetime import *\nimport time\n\ndef is_skip_file(file_name):\n    if not (\".txt\" in file_name):\n        return True\n\n    if  (\"#\" in file_name):\n        return True\n\n\ndef create_output_textfile(file_name):\n    filepath = os.getcwd()+\"/kiji_honbun_textfile/\"+file_name\n    return codecs.open(filepath, 'w','utf-8')\n\n\ndef strip_tags(paragraph):\n    if paragraph.string is None:\n        return \"\"\n\n    return paragraph.string\n\n\ndef is_skip_file(file_name):\n    if not (\".txt\" in file_name):\n        return True\n\n    if  (\"#\" in file_name):\n        return True\n\n\ndef strip_tags(paragraph):\n    if paragraph.string is None:\n        return \"\"\n\n    return paragraph.string\n\n\ndef get_articlebody_within_ptags(ptag_list):\n    text_list = []\n\n    for ptag in ptag_list:\n        text_list.append(strip_tags(ptag))\n\n    return \"\".join(text_list)\n\n\ndef get_honbun_within_divtag(divtag):\n    ptag_list = divtag.findAll(\"p\")\n    return get_articlebody_within_ptags(ptag_list)\n\n\n\ndef get_honbun_of_one_webpage(url):\n\n    webpage = urllib2.urlopen(url)\n    time.sleep(1.0)\n\n    html_file = webpage.read()\n    soup = BeautifulSoup(html_file)\n\n    section_tag = soup.find(\"section\", {\"class\" : \"articleText clearfix\"})\n    if section_tag is None:\n        return None\n\n    article_tag = section_tag.find(\"article\")\n    if article_tag is None:\n        return None\n\n    div_tag = article_tag.find(\"div\", {\"class\" : \"fontMiddiumText\"})\n    if div_tag is None:\n        return None\n    else:\n        return get_honbun_within_divtag(div_tag)\n\n\n\ndef get_honbun_of_all_webpages_of_one_article(article_top_page_url):\n\n    #\u8907\u6570\u30da\u30fc\u30b8\u306b\u307e\u305f\u304c\u308b\u8a18\u4e8b\u306e\u5bfe\u5fdc\u3092\u7528\u610f\n    article_top_page_website = urllib2.urlopen(article_top_page_url)\n    top_page_htmlfile = article_top_page_website.read()\n    article_top_page_soup = BeautifulSoup(top_page_htmlfile)\n\n    article_all_pages_url_list = [article_top_page_url]\n\n    div_tag = article_top_page_soup.find(\"div\", {\"class\" : \"pagenator\"})\n\n    if div_tag is not None:\n        anchor_tag_list = div_tag.findAll(\"a\", {\"class\" : \"page\"})\n        pattern = re.compile(\"(\\/.+html)\")\n        url_head_string = \"http://www.sankei.com/\"\n\n        for anchor_tag in anchor_tag_list:\n            url_unicode = unicode(anchor_tag)\n            if \"html\" in url_unicode:\n                url = pattern.search(url_unicode)\n                if url:\n                    url_string = url_head_string + url.group(0) \n                    url_string = url_string.replace(\"//../..\", \"\")\n                    article_all_pages_url_list.append(url_string)\n\n        honbun = [\"\"]\n\n        for article_one_page_url in article_all_pages_url_list:\n            #\u8a18\u4e8b\u76ee\u6b21\u30da\u30fc\u30b8 \uff11\u30da\u30fc\u30b8\u3054\u3068\u306b\u3001\u305d\u308c\u305e\u308c\u4e0b\u8a18\u3092\u5b9f\u884c\u3057\u3066\u3001\u76ee\u6b21\u8a18\u8f09 \u8a18\u4e8b\u306e\u30bf\u30a4\u30c8\u30eb\u30fbURL\u3092\u30d5\u30a1\u30a4\u30eb\u306b\u51fa\u529b  \n            article_one_page_honbun = get_honbun_of_one_webpage(article_one_page_url)\n            honbun.append(article_one_page_honbun)\n\n\n        del honbun[0] # honbun\u30ea\u30b9\u30c8\u306e\u521d\u671f\u5316\u5ba3\u8a00\u6642\u306b\u3001\u5148\u982d\u8981\u7d20\u306b\u5165\u308c\u305f NULL \u3092\u524a\u9664\n        honbun = \"\".join(honbun) # \u30ea\u30b9\u30c8\u578b\u30aa\u30d6\u30b8\u30a7\u30af\u30c8\u3092\u3001string\u578b\u306b\u578b\u5909\u63db (\u5404\u30a6\u30a7\u30d6\u30da\u30fc\u30b8\u63b2\u8f09\u306e\u672c\u6587\u3092\u3001\u6539\u884c\u6587\u5b57\u3092\u631f\u3093\u3067\u884c\u7d50\u5408\uff09\n        return honbun\n\n\n    #\u8907\u6570\u30da\u30fc\u30b8\u306b\u307e\u305f\u304c\u3089\u305a\u3001\u30c8\u30c3\u30d7\u30da\u30fc\u30b8\uff11\u30da\u30fc\u30b8\u3057\u304b\u306a\u3044\u8a18\u4e8b\u306e\u5834\u5408\u306e\u51e6\u7406\n    else:\n        honbun = get_honbun_of_one_webpage(article_top_page_url)\n        return honbun\n\n\n\n# \u4ee5\u4e0a\u3001\u30e1\u30bd\u30c3\u30c9\u5b9a\u7fa9 \u304a\u308a========================================================\n\narticle_info_list = open(\"title_url_list_all_articles.txt\", 'r')\n\nfor line in article_info_list:\n    url_startpoint = line.find(\"http\")\n    url_startpoint = int(url_startpoint)\n\n    url = line[url_startpoint: ]\n    url = str(url)\n\n    if  \"/../\" in url:\n        url = url.replace(\"/../\", \"/\")\n\n    title_endpoint = url_startpoint - 1\n    title_endpoint = int(title_endpoint)\n\n    title = line[0:title_endpoint] #\u300c\u8a18\u4e8b\u8868\u984c\u540d  \u8a18\u4e8b\u63b2\u8f09URL\u300d\u6587\u5b57\u5217\u306e\u3046\u3061\u3001\u5148\u982d\u6587\u5b57\u304b\u3089\u3001\u8a18\u4e8b\u63b2\u8f09URL\u304c\u59cb\u307e\u308b http \u306eh\u306e1\u6587\u5b57\u524d\u307e\u3067\u306e\u7bc4\u56f2\u3092\u62bd\u51fa\n    title = title.rstrip() #\u8a18\u4e8b\u8868\u984c\u6587\u5b57\u5217\u306e\u3046\u3061\u3001\u672b\u5c3e\u306e\u7a7a\u767d\u6587\u5b57\u3092\u9664\u53bb\n\n    try:\n        scraping_timestamp = datetime.now().strftime('%Y-%m-%d %H:%M:%S') #str\u578b\u30aa\u30d6\u30b8\u30a7\u30af\u30c8\n        html_file = urllib2.urlopen(url)\n        #\u4ee5\u4e0b\u3001HTML\u30d5\u30a1\u30a4\u30eb\u3092parse\u5b9f\u884c\u3002\u8a18\u4e8b\u672c\u6587\u306e\u307f\u629c\u304d\u51fa\u3057\u3066\u3001\u30c6\u30ad\u30b9\u30c8\u30d5\u30a1\u30a4\u30eb\u306b\u51fa\u529b\n        kiji_honbun = get_honbun_of_all_webpages_of_one_article(url)\n        #\u4ee5\u4e0b\u3001HTML\u30d5\u30a1\u30a4\u30eb\u3092\u30c6\u30ad\u30b9\u30c8\u30d5\u30a1\u30a4\u30eb\u306b\u51fa\u529b\n        html_lines = html_file.read()        \n        kiji_metadata_output = u\"\u7523\u7d4c\u65b0\u805e\".encode('utf-8') + \"\\t\" + title + \"\\t\" + scraping_timestamp\n        html_file_output_filename = os.getcwd() + \"/html_file/\" +str(title)+\".txt\" \n        output_textfile = open(html_file_output_filename, 'w')\n        output_textfile.write(html_lines)\n        output_textfile.close()\n        os.system('nkf -w --overwrite '+ html_file_output_filename) # call UNIX nkf -w command: change character code to UTF-8\n        time.sleep(1.0)\n\n    except urllib2.HTTPError:\n        print 'HTTPError\u767a\u751f!'\n        print('\u30a8\u30e9\u30fcURL:  '+ url)\n\n    except Exception, e:\n        print e, 'HTTPError\u4ee5\u5916\u306e\u30a8\u30e9\u30fc\u767a\u751f\uff01'\n\n\n    # print chardet.detect(kiji_honbun)  \u7d50\u679c\u306f\u3001ascii                                              \n    kiji_honbun_utf_8 = kiji_honbun.encode('utf-8')\n    mojisuu = len(kiji_honbun_utf_8)\n    kiji_metadata_output = kiji_metadata_output + \"\\t\" + str(mojisuu).encode('utf-8') + \"\\n\"\n    #print chardet.detect(kiji_honbun)  #\u7d50\u679c\u306f\u3001utf-8                                               \n\n\n    honbun_output_filename = os.getcwd() + \"/kiji_honbun_textfile/\" + str(title) + \".txt\"\n    honbun_output_file = open(honbun_output_filename, 'w')\n    honbun_output_file.write(kiji_honbun_utf_8)\n    honbun_output_file.close()\n\n    kiji_metadata_output_file_name = os.getcwd() + \"/kiji_metadata_file_1.csv\"\n    kiji_metadata_output_file = open(kiji_metadata_output_file_name, \"a\")\n    kiji_metadata_output_file.write(kiji_metadata_output)\n    kiji_metadata_output_file.close()\n\narticle_info_list.close()\n\n\n\n\uff13\uff0eget_kakariuke_wordpairs.rb\n\n\nruby1.9.1\n# -*- coding: utf-8 -*-\nrequire 'CaboCha'\n\n# sentence\u3092\u4fc2\u308a\u53d7\u3051\u89e3\u6790\u3057\u3066\u7d50\u679c\u30c4\u30ea\u30fc\u3092\u5f97\u308b\n\n# \u8aad\u307f\u8fbc\u3093\u3060\u30d5\u30a1\u30a4\u30eb\u306e\u4e2d\u8eab\u3092 sentence \u30aa\u30d6\u30b8\u30a7\u30af\u30c8\u306b\u683c\u7d0d\u3059\u308b\n\ndef GetKijiFilesNamesPaths()\n        current_directory_path = Dir::getwd\n\n        files_names = Dir::entries(current_directory_path) \n\n        files_path = Array.new\n        files_name = Array.new\n\n        files_names.each do |file_name|\n              unless (file_name == \"\") && (file_name.include?(\"word_pairs\"))\n                   if file_name.include?(\".txt\") \n                          unless file_name.include?(\"#\") or file_name.include?(\"~\")\n                unless file_name.include?(\"list\")\n                                   files_path.push(current_directory_path + \"/\" + file_name)\n                                   files_name.push(file_name)\n                            end\n                          end\n           end\n              end\n        end\n        return files_path, files_name\nend\n\n\n#=== \u8a18\u4e8b\u30d5\u30a1\u30a4\u30eb\u306e\u5185\u5bb9\uff08\u672c\u6587\u30c6\u30ad\u30b9\u30c8\u30c7\u30fc\u30bf\uff09\u3092\u5168\u30d5\u30a1\u30a4\u30eb\u5206\u3001Array\u30aa\u30d6\u30b8\u30a7\u30af\u30c8 sentence[]\u3000\u306b\u683c\u7d0d===\n\nfiles_path, files_name = GetKijiFilesNamesPaths()\n\nsentence = Array.new\nn = 0\n\nwhile n < files_path.size\n\n          sentence[n] = File.read(files_path[n], :encoding => Encoding::UTF_8)\n          n+=1\nend\n\n\n#=== Array\u30aa\u30d6\u30b8\u30a7\u30af\u30c8\u304b\u3089\u8a18\u4e8b\uff11\u672c\u6bce\u306e\u672c\u6587\u30c6\u30ad\u30b9\u30c8\u3092\u53d6\u308a\u51fa\u3057\u3066\u3001\u300c\u4fc2\u308a\u53d7\u3051\u5143 <--> \u4fc2\u308a\u53d7\u3051\u5148\u300d \u30da\u30a2\u3092 \uff11\u30da\u30a2\uff11\u884c\u3065\u3064\u30d5\u30a1\u30a4\u30eb\u306b\u51fa\u529b===\n\nm = 0\n\n# m \u306f\u3001\u3044\u307e\u51e6\u7406\u3057\u3066\u3044\u308b\u8a18\u4e8b\u30d5\u30a1\u30a4\u30eb\u306e\u4ef6\u6570\nwhile m < sentence.length\n\n  #\u4fc2\u308a\u53d7\u3051\u8a9e\u53e5\u30da\u30a2 \u51fa\u529b\u30d5\u30a1\u30a4\u30eb\u3092\u7528\u610f\n  # \u3010\u30d5\u30a1\u30a4\u30eb\u540d\u3011 files_name[m]    \n    output_filename = \"word_pairs:\" + files_name[m] \n\n    File.open(output_filename, \"w\") do |output_file|\n        output_file.puts(\" \")\n    end\n\n   #\u4fc2\u308a\u53d7\u3051\u8a9e\u53e5\u30da\u30a2\u3092\u62bd\u51fa\n    parser = CaboCha::Parser.new;\n    tree = parser.parse(sentence[m])\n\n   # \u7a7a\u306e\u30cf\u30c3\u30b7\u30e5\u3092\u7528\u610f\n    word_pairs_hash = Hash.new()\n\n\n   # \u5168\u3066\u306e\u30c1\u30e3\u30f3\u30af\u306b\u5bfe\u3057\u3066\n     (0 ... tree.chunk_size).each do |i|\n        chunk = tree.chunk(i)\n\n        # link\u304c\u7e4b\u304c\u3063\u3066\u3044\u308c\u3070\n        if (chunk.link >= 0)\n          # \u30ea\u30f3\u30af\u5143\u3068\n          chunk_from = (0 ... chunk.token_size).map do |j|\n              tree.token(chunk.token_pos + j).normalized_surface\n          end.join(\"-\")\n\n\n          # \u30ea\u30f3\u30af\u5148\u3092\n          chunk = tree.chunk(chunk.link)\n\n          chunk_to = (0 ... chunk.token_size).map do |j|\n              tree.token(chunk.token_pos + j).normalized_surface\n          end.join(\"-\")\n\n      # \u30d5\u30a1\u30a4\u30eb\u306b\u51fa\u529b\n          # \u3010\u30d5\u30a1\u30a4\u30eb\u540d\u3011 files_name[m]    \n          output_filename = \"word_pairs:\" + files_name[m] \n\n          File.open(output_filename, \"a\") do |output_file|\n              output_file.puts(\"#{chunk_from} => #{chunk_to}\")\n          end\n\n         # puts \"#{chunk_from} => #{chunk_to}\"\n\n        end\n     end\n\n   # \u6b21\u306e\u8a18\u4e8b\u672c\u6587\u30d5\u30a1\u30a4\u30eb\u306b\u79fb\u52d5\n    m += 1  \nend\n\n\n\n\uff14\uff0ematched_wordpairs_counter.py\n\n\nmatched_wordpairs_counter.py\n#!/usr/bin/enb python2.7                                                       \n# -*- coding: utf-8 -*-  \n\nimport os, codecs\n\nfile_names = os.listdir(os.getcwd())\n\nfor file_name in file_names:\n     if \"word_pairs\" in file_name:\n        score = 0\n        file_word_pairs = codecs.open(file_name, 'r','utf-8')\n        word_pairs = file_word_pairs.readlines()\n\n\n        for one_word_pair in word_pairs: \n            i = one_word_pair.find(\"=\")\n            j = one_word_pair.find(\">\")\n\n            from_word_end_position = int(i) -1\n            to_word_starts_position = int(j) + 1\n\n            from_word = one_word_pair[:from_word_end_position]\n            to_word = one_word_pair[to_word_starts_position:]\n\n            from_word = from_word.replace(unichr(0x3010), \"\")  # \u3010 \u3092\u524a\u9664\n            from_word = from_word.replace(unichr(0x3011), \"\")  # \u3011\u3092\u524a\u9664\n            from_word = from_word.replace(\"___-\", \"\")  \n\n            to_word = to_word.replace(unichr(0x3010), \"\")\n            to_word = to_word.replace(unichr(0x3011), \"\")\n            to_word = to_word.replace(\"___-\", \"\")\n\n\n            #\u72ec\u81ea\u30cd\u30bf \u8a18\u4e8b\u5019\u88dc \u691c\u51fa\u6761\u4ef6\n            from_search_words = [u\"TPP\", u\"JA\u5168\u4e2d\", u\"\u8fb2\u696d\u56e3\u4f53\", u\"\u81ea\u6c11\u515a\", u\"\u9996\u5e2d\u4ea4\u6e09\u5b98\", u\"USTR\"]\n            to_search_words = [u\"\u5206\u304b\u3063\u305f\", u\"\u5224\u660e\", u\"\u8abf\u6574\", u\"\u4ea4\u6e09\", u\"\u59a5\u7d50\", u\"\u5354\u8b70\", u\"\u7d99\u7d9a\", u\"\u6301\u3061\u8d8a\u3057\", u\"\u59a5\u5354\", u\"\u767a\u8868\"]  \n\n            #\u72ec\u81ea\u30cd\u30bf \u8a18\u4e8b\u5019\u88dc \u691c\u51fa &\u3000\u7d50\u679c\u51fa\u529b  (\u53c2\u8003\uff09http://d.hatena.ne.jp/podhmo/20111213/1323788999\n            kiji_title = \"\"\n            search_words_hit_phrase = \"\"\n            output_line_list = [\" \"]\n\n            if any([x in from_word for x in from_search_words]) and any([y in to_word for y in to_search_words]):\n                score += 1\n                kiji_title = file_name.replace(\"word_pairs:\", \"\").strip()\n                output_hit_phrase = one_word_pair.replace('=>','\\t')\n                output_hit_phrase = output_hit_phrase.strip()\n                output = kiji_title + \"\\t\" + output_hit_phrase.encode('utf-8') + \"\\n\"\n                f = open(\"kiji_evaluation_result.csv\", \"a\")\n                f.write(output)\n                f.close()\n\n\n        kiji_title = file_name.replace(\"word_pairs:\", \"\").strip()\n        score_message = kiji_title + \"\\t\" + str(score) + \"\u70b9\\n\"                \n        g = open(\"kiji_scores.csv\", \"a\")\n        g.write(score_message)\n        g.close()\n\n#        os.system('nkf -s --overwrite *.csv')\n\n\n\n\uff15\uff0ecreate_article_website_posted_date_list.py\n\n\ncreate_article_website_posted_date_list.py\n#!/usr/bin/enb python2.7\n# -*- coding: utf-8 -*-\n\n# \u3053\u306e\u30b9\u30af\u30ea\u30d7\u30c8\u30fb\u30d5\u30a1\u30a4\u30eb\u306f\u3001\u89e3\u6790\u5bfe\u8c61\u3068\u306a\u308b\u5404\u8a18\u4e8b\u306eHTML\u30d5\u30a1\u30a4\u30eb\u683c\u7d0d\u5148\u30c7\u30a3\u30ec\u30af\u30c8\u30ea\u306b\u914d\u7f6e\u3057\u3066\u3001\u5b9f\u884c\u3059\u308b\u3053\u3068\u3002\nimport re, codecs, os, csv\n\nhtml_file_names = os.listdir(os.getcwd())\noutput_message_list = []\n\nfor html_file_name in html_file_names:\n    if \"txt\" in html_file_name:\n        try:\n            f = codecs.open(html_file_name, 'r', 'utf-8')\n            lines = f.readlines()\n\n            for line in lines:\n                try:\n                    if \"r_publish_date\" in line:\n                        p = re.compile(r\"<[^>]*?>\")\n                        kiji_date = p.sub(\"\", line)\n                        output_message = html_file_name.replace(\".txt\", \"\") + \"\\t\" + kiji_date.encode('utf-8')\n                        output_message_list.append(output_message)\n                except:\n                    pass\n\n        except:\n            pass\n\n\nfor message in output_message_list:\n    g = open(\"kiji_title_date_list.csv\", 'a')\n    g.write(message)\n    g.close()\n\n\n#os.system('nkf -s --overwrite kiji_title_date_list.csv')\n\n\n\n\uff16\uff0ecreate_kiji_title_honbun_list.py\n\n\ncreate_kiji_metadata_files.py\n#!/usr/bin/enb python2.7\n# -*- coding: utf-8 -*-\n\n# \u3053\u306e\u30b9\u30af\u30ea\u30d7\u30c8\u30fb\u30d5\u30a1\u30a4\u30eb\u306f\u3001\u89e3\u6790\u95a2\u9023\u30c7\u30a3\u30ec\u30af\u30c8\u30ea\u306e\u30c8\u30c3\u30d7\u30c7\u30a3\u30ec\u30af\u30c8\u30ea\u306b\u683c\u7d0d\n# http://d.hatena.ne.jp/Tommy1/20131209/1386545113\n#  (1) \u307e\u305a\u6700\u521d\u306b\u3001\u5404\u9805\u76ee\u3054\u3068\u306b\u3001\u300c\u8a18\u4e8b\u540d\u300d\u30ea\u30b9\u30c8 \u3068 \u300c\u53d6\u5f97\u9805\u76ee\u300d\u30ea\u30b9\u30c8\u3092\u4f5c\u6210 \n#  (2) \u6b21\u306b\u3001\u5404\u9805\u76ee\u3054\u3068\u306b\u3001\u300c\u8a18\u4e8b\u540d\u300d-\u300c\u53d6\u5f97\u9805\u76ee\u300d\u306e\u30ab\u30e9\u30e0\u6570\uff12\u500b\u306e\u30c7\u30fc\u30bf\u30d5\u30ec\u30fc\u30e0\u3092\u4f5c\u6210\u3002http://d.hatena.ne.jp/dichika/20120819/1345385529\n#  (3) \u6b21\u306b\u3001\u5404\u9805\u76ee\u3054\u3068\u306b\u4f5c\u6210\u3057\u305f \u30c7\u30fc\u30bf\u30d5\u30ec\u30fc\u30e0\u3092\u3001\u300c\u8a18\u4e8b\u540d\u300d\u3092\u7d50\u5408\u30ad\u30fc\u306b\u3057\u3066\u3001pd.merge(df1, df2)\u3059\u308b\u3002\uff11\u3064\u3067\u3082\u9805\u76ee\u304c\u6b20\u3051\u305f\u8a18\u4e8b\u306f\u3001\u30de\u30fc\u30b8\u3057\u305f\u7d50\u679c\u306e\u30c7\u30fc\u30bf\u30d5\u30ec\u30fc\u30e0\u306b\u306f\u66f8\u304d\u51fa\u3055\u308c\u306a\u3044\uff08inner\u7d50\u5408\u306e\u5834\u5408\u3002outer\u7d50\u5408\u306e\u5834\u5408\u306f\u3001right / left\u5916\u90e8\u7d50\u5408\u53ef\u80fd\uff09\n#      \u306a\u304a\u3001\u30c7\u30fc\u30bf\u30d5\u30ec\u30fc\u30e0\u306a\u306e\u3067\u3001\u30c7\u30d5\u30a9\u30eb\u30c8\u3067\u3001\u884c\u540d\u306b\u3001index\u306e\u6570\u5024\u304c\u5272\u308a\u632f\u3089\u308c\u308b\u3002\uff0a\n# http://d.hatena.ne.jp/dichika/20120819/1345385529 \u30a4\u30f3\u30c7\u30c3\u30af\u30b9\u540d\u3092\u4efb\u610f\u306e\u6570\u5024\u3084\u6587\u5b57\u5217 \u6307\u5b9a\u3082\u53ef\u80fd\n# http://oceanmarine.sakura.ne.jp/sphinx/group/group_pandas.html#pandasseries,  http://everydayprog.blogspot.jp/2011_07_01_archive.html  \n#  (4) \u6700\u5f8c\u306b\u3001\u30c7\u30fc\u30bf\u30d5\u30ec\u30fc\u30e0\u3092\u30d5\u30a1\u30a4\u30eb\u51fa\u529b\u3059\u308b output_df.to_csv('output_file_name.csv', sep='\\t', header=True, index_label=True)\n#\n# \uff0a\u30ab\u30e9\u30e0\u5024\u306e\u91cd\u8907\u30c1\u30a7\u30c3\u30af http://blog.kzfmix.com/tag/pandas df.duplicated() \u91cd\u8907\u30ab\u30e9\u30e0\u5024\u306b True\u304c\u8fd4\u3055\u308c\u308b\n# \uff0a\u91cd\u8907\u30ab\u30e9\u30e0\u306e\u524a\u9664\uff08\uff11\u884c\u3060\u3051\u6b8b\u3059\uff09 df.drop_duplicates()\n\nimport re, codecs, os, csv\nimport pandas as pd\nfrom pandas import DataFrame\n\n#df_1: \u300c\u65b0\u805e\u793e\u540d\u3000\u8a18\u4e8b\u30bf\u30a4\u30c8\u30eb \u8a18\u4e8b\u30b9\u30af\u30ec\u30a4\u30d4\u30f3\u30b0\u6642\u523b \u8a18\u4e8b\u6587\u5b57\u6570\u300d\u3000\u60c5\u5831 \u53d6\u5f97\ndf_1 = pd.read_csv('kiji_metadata_file_1.csv', header=None, sep='\\t')\ndf_1.columns = ['newspaper_name', 'title', 'scraping_timestamp', 'moji_suu']\n\n\n#df_2: \u300c\u8a18\u4e8b\u30bf\u30a4\u30c8\u30eb\u3000\u8a18\u4e8b\u65b0\u805e\u793e\u30a6\u30a7\u30d6\u30b5\u30a4\u30c8\u63b2\u8f09\u5e74\u6708\u65e5\u300d \u60c5\u5831 \u53d6\u5f97\n\ndf_2 = pd.read_csv('./html_file/kiji_title_date_list.csv', header=None, sep='\\t')\ndf_2.columns = ['title', 'newsweb_posted_date']\n\n\n#=============================================================================================\n\n#df_3: \u300c\u8a18\u4e8b\u30bf\u30a4\u30c8\u30eb \u8a18\u4e8b\u6b04\u540d\u300d \u60c5\u5831 \u53d6\u5f97\n\nf = codecs.open(\"title_url_list_all_articles.txt\", 'r', 'utf-8')\nkiji_info_lines = f.readlines()\n\nurl_search_words = [\"/politics/\", \"/economy/\",\"/world/\", \"/affairs/\", \"/column/\", \"west\"]   \ncolumn_names = [u\"\u653f\u6cbb\u6b04\", u\"\u7d4c\u6e08\u6b04\", u\"\u56fd\u969b\u6b04\", u\"\u4e8b\u4ef6\u6b04\", u\"\u30b3\u30e9\u30e0\", u\"\u95a2\u897f\"]\n\n\nkiji_title_list = []\nkiji_category_list = []\n\nfor line in kiji_info_lines:\n    url_first_letter_location = int(line.find(\"http\"))\n    n = url_first_letter_location - 1\n\n    kiji_title = line[:n]\n    kiji_url = line[url_first_letter_location:]\n\n\n    for i in range(0, len(column_names)):\n        if url_search_words[i] in kiji_url:\n            kiji_title = kiji_title.encode('utf-8') \n            kiji_title_list.append(kiji_title)            \n            kiji_category =  column_names[i].encode('utf-8') \n            kiji_category_list.append(kiji_category)\n        else:\n            pass\n\n\ndict_3 = {'title' : kiji_title_list, 'kiji_category' : kiji_category_list}\ndf_3 = DataFrame(dict_3)\ndf_3.columns = ['kiji_category', 'title']\n\ndel kiji_title_list\n\n#=============================================================================================\n\n#df_4: \u300c\u8a18\u4e8b\u30bf\u30a4\u30c8\u30eb \u8a18\u4e8b\u8a55\u70b9\u300d \u60c5\u5831 \u53d6\u5f97\ndf_4 = pd.read_csv('./kiji_honbun_textfile/kiji_scores.csv', header= None, sep='\\t')\ndf_4.columns = ['title', 'score']\n\n\n#==== \u5404DataFrame\u30aa\u30d6\u30b8\u30a7\u30af\u30c8\u306e\u7d50\u5408\uff08\u7d50\u5408\u5217: title)\n\nmerged_df = pd.merge(df_1, df_2, on = 'title', how = \"inner\")\n#merged_df.columns = [\"news_paper_name\", \"title\", \"scraping_timestamp\", \"moji_suu\", \"newsweb_posted_date\"]\n#merged_df_2 = pd.merge(meged_df_1, df_3, on = 'title', how = \"inner\")\n#merged_df_2 = pd.merge(meged_df_1, df_4, on = 'title', how = \"inner\")  \n\n# score\u5217\u306e\u5024\u3067\u964d\u9806\u30bd\u30fc\u30c8\ndf_4 = df_4.sort(columns=\"score\", ascending=False)\n\n#==== \u6700\u5f8c\u306b\u307e\u3068\u3081\u3066\u3001\u30d5\u30a1\u30a4\u30eb\u51fa\u529b\n\n#print(merged_df)\n#print(df_3)\n#print(df_4)\n\nmerged_df.to_csv(\"./meta_data_file/\u65b0\u805e\u793e\u540d-\u8a18\u4e8b\u30bf\u30a4\u30c8\u30eb-\u8a18\u4e8b\u30b9\u30af\u30ec\u30a4\u30d4\u30f3\u30b0\u6642\u523b-\u8a18\u4e8b\u6587\u5b57\u6570-\u30a6\u30a7\u30d6\u30b5\u30a4\u30c8\u8a18\u4e8b\u63b2\u8f09\u5e74\u6708\u65e5.csv\", sep='\\t', header=True, index_label=\"number\")\ndf_3.to_csv(\"./meta_data_file/\u8a18\u4e8b\u30bf\u30a4\u30c8\u30eb-\u8a18\u4e8b\u6b04\u540d.csv\", sep='\\t', header=True, index=False)\ndf_4.to_csv(\"./meta_data_file/\u8a18\u4e8b\u30bf\u30a4\u30c8\u30eb \u8a18\u4e8b\u8a55\u70b9.csv\", sep='\\t', header=True, index=False)\n\n\n#merged_df.to_csv(\"./meta_data_file/shiftjis/\u65b0\u805e\u793e\u540d-\u8a18\u4e8b\u30bf\u30a4\u30c8\u30eb-\u8a18\u4e8b\u30b9\u30af\u30ec\u30a4\u30d4\u30f3\u30b0\u6642\u523b-\u8a18\u4e8b\u6587\u5b57\u6570-\u30a6\u30a7\u30d6\u30b5\u30a4\u30c8\u8a18\u4e8b\u63b2\u8f09\u5e74\u6708\u65e5.csv\", sep='\\t', header=True, index_label=\"number\")\n#df_3.to_csv(\"./meta_data_file/shiftjis/\u8a18\u4e8b\u30bf\u30a4\u30c8\u30eb-\u8a18\u4e8b\u6b04\u540d.csv\", sep='\\t', header=True, index=False)\n#df_4.to_csv(\"./meta_data_file/shiftjis/\u8a18\u4e8b\u30bf\u30a4\u30c8\u30eb \u8a18\u4e8b\u8a55\u70b9.csv\", sep='\\t', header=True, index=False)\n\n#os.system('nkf -s  --overwrite ./meta_data_file/shiftjis/*.csv') \n\n\n\ncreate_kiji_title_honbun_list.py\n#!/usr/bin/env/python2.7                                                       \n# -*- coding: utf-8 -*-  \n\nimport os, codecs\n\nfile_names = os.listdir(os.getcwd())\n\nfor file_name in file_names:\n     if (\"txt\" in file_name) and (\"word\" not in file_name) and (\"kiji_title_honbun_list.txt\" != file_name) and (\"score\" not in file_name):\n         try:\n              f = codecs.open(file_name, 'r','utf-8')\n\n              kiji_honbun = f.read()\n              kiji_title = file_name\n\n              one_kiji_file_output = kiji_title + \"\u3000\uff1a\u3000\" + kiji_honbun.encode('utf-8')  +\"\\n\"\n\n              g = open(\"kiji_title_honbun_list.txt\", \"a\")\n              g.write(one_kiji_file_output)\n              g.close()\n         except:\n              pass\n\n#os.system('nkf -s  --overwrite sjis_kiji_title_honbun_list.txt')\n\n\n\n\n\u5b9f\u884c\n\n\uff08\u5de5\u7a0b \uff11\uff09 \u30af\u30ed\u30a6\u30ea\u30f3\u30b0\u5bfe\u8c61\u8a18\u4e8b \u306eURL\u30fb\u8a18\u4e8b\u30bf\u30a4\u30c8\u30eb \u4e00\u89a7\u30ea\u30b9\u30c8 \u751f\u6210\n\n\ntitle_url_list_all_articles.txt \u3092\u5b9f\u884c\n\n\n\n\u4ee5\u4e0b\u306e\u30c6\u30ad\u30b9\u30c8\u30d5\u30a1\u30a4\u30eb\u304c\u751f\u6210\u3055\u308c\u307e\u3059\n\n\ntitle_url_list_all_articles.txt\n\n\n\n\u4e2d\u8eab\u3092\u958b\u304f\u3068\u3001\u8a18\u4e8b\u30bf\u30a4\u30c8\u30eb \u3068 \u63b2\u8f09URL \u306e\u4e00\u89a7\u304c\u51fa\u529b\u3055\u308c\u3066\u3044\u307e\u3059\n\n\n\n\uff08\u5de5\u7a0b\uff12 \u6e96\u5099\uff09\n\u5de5\u7a0b\uff12 \u3067\u751f\u6210\u3055\u308c\u308b\u30d5\u30a1\u30a4\u30eb\u306e\u683c\u7d0d\u5148\u30c7\u30a3\u30ec\u30af\u30c8\u30ea\u3092\u7528\u610f\n\nhtml_file \u30c7\u30a3\u30ec\u30af\u30c8\u30ea\nkiji_honbun_textfile \u30c7\u30a3\u30ec\u30af\u30c8\u30ea\n\n\n\n\n\uff08\u5de5\u7a0b \uff12\uff09 \u5404\u8a18\u4e8b URL \u306b\u30a2\u30af\u30bb\u30b9\u3057\u3066\u3001html\u30d5\u30a1\u30a4\u30eb \u3068 \u8a18\u4e8b\u672c\u6587\u30c6\u30ad\u30b9\u30c8\u30fb\u30d5\u30a1\u30a4\u30eb\u751f\u6210\n\n\ncreate_kiji_honbun_textfile_htmlfile.py \u3092\u5b9f\u884c\n\n\u30a8\u30e9\u30fc\u30e1\u30c3\u30bb\u30fc\u30b8\u304c\u3044\u304f\u3064\u304b\u51fa\u305f\u5f8c\u3001\u5b9f\u884c\u7d42\u4e86\n\n\nhtml_file \u30c7\u30a3\u30ec\u30af\u30c8\u30ea\u306b\u3001\u30ea\u30b9\u30c8\u4e00\u89a7\u4e2d\u306e\u5168\u8a18\u4e8b\u306ehtml\u30d5\u30a1\u30a4\u30eb\u304c\u751f\u6210\u3055\u308c\u3066\u3044\u307e\u3059\n\n\n\uff08 \u8a18\u4e8b\u672c\u6570\u5206\u3001610 \u4ef6\u306e html \u30d5\u30a1\u30a4\u30eb\u304c\u751f\u6210\u3055\u308c\u305f \uff09\n\n\n\nkiji_honbun_textfile \u30c7\u30a3\u30ec\u30af\u30c8\u30ea\u306b\u3001\u30ea\u30b9\u30c8\u4e00\u89a7\u4e2d\u306e\u5168\u8a18\u4e8b\u306e\u8a18\u4e8b\u672c\u6587\u30c6\u30ad\u30b9\u30c8\u30d5\u30a1\u30a4\u30eb\u304c\u751f\u6210\u3055\u308c\u3066\u3044\u307e\u3059\n\n\n\uff08 \u8a18\u4e8b\u672c\u6570\u5206\u3001610 \u4ef6\u306e \u8a18\u4e8b\u672c\u6587\u30c6\u30ad\u30b9\u30c8\u30fb\u30d5\u30a1\u30a4\u30eb\u304c\u751f\u6210\u3055\u308c\u305f \uff09\n\n\n\n\uff08 html \u30d5\u30a1\u30a4\u30eb\u306e\u4e2d\u8eab )\n\n\n\n\n\uff08 \u8a18\u4e8b\u672c\u6587\u30c6\u30ad\u30b9\u30c8\u30fb\u30d5\u30a1\u30a4\u30eb \u306e\u4e2d\u8eab )\n\n\n\n\uff08 kiji_metadata_file_1.csv \u30d5\u30a1\u30a4\u30eb \u306e\u4e2d\u8eab\uff09\n\n\n\n\uff08\u5de5\u7a0b \uff13\uff09 \u5404\u8a18\u4e8b \u672c\u6587\u30c6\u30ad\u30b9\u30c8\u30d5\u30a1\u30a4\u30eb \u3092\u4fc2\u308a\u53d7\u3051\u5206\u89e3\u5b9f\u884c\n\n\nget_kakariuke_wordpairs.rb \u3092\u5b9f\u884c\n\n\n\uff08 \u8a18\u4e8b\u672c\u6570\u5206\u3001610 \u4ef6\u306e\u4fc2\u308a\u53d7\u3051\u7d50\u679c\u30d5\u30a1\u30a4\u30eb\u304c\u751f\u6210\u3055\u308c\u305f \uff09\n\n\n\nword_pairs \u3067\u59cb\u307e\u308b\u30d5\u30a1\u30a4\u30eb\u304c\u3001\u751f\u6210\u3055\u308c\u305f\u30d5\u30a1\u30a4\u30eb\u3067\u3059\n\n\n\n\uff08 \u4e2d\u8eab\u3092\u958b\u3044\u3066\u307f\u308b \uff09\n\n\n\n\uff08\u5de5\u7a0b \uff14\uff09 \u6307\u5b9a\u3057\u305f\u300c\u4e3b\u8a9e\u30d5\u30ec\u30fc\u30ba => \u8ff0\u8a9e\u30d5\u30ec\u30fc\u30ba\u300d\u306e\u691c\u51fa\u56de\u6570 \u96c6\u8a08\u3092\u5b9f\u884c\n\n\u4eca\u56de\u306f\u3001\uff08\u4e3b\u8a9e \u8a9e\u53e5\uff09\u300c List 1 \u306e\u3046\u3061\u3001\u3044\u305a\u308c\u304b\u306e\u5358\u8a9e \u300d ==>>\uff08\u8ff0\u8a9e \u8a9e\u53e5\uff09 \u300c List 2 \u306e\u3046\u3061\u3001\u3044\u305a\u308c\u304b\u306e\u5358\u8a9e \u300d\n\u306b\u8a72\u5f53\u3059\u308b \u4fc2\u308a\u53d7\u3051\u30da\u30a2 \u6587 \u3092 \u5168\u4fc2\u308a\u53d7\u3051\u8a9e\u53e5\u30da\u30a2\u4e00\u89a7\u30ea\u30b9\u30c8 \u306e\u306a\u304b\u304b\u3089\u3001\u691c\u51fa\u3057\u3066\u307f\u307e\u3059\u3002\n\nList 1 : \u4fc2\u308a\u53d7\u3051\u5143 \u5358\u8a9e\u30ea\u30b9\u30c8\n\"TPP\", \"JA\u5168\u4e2d\", \"\u8fb2\u696d\u56e3\u4f53\", \"\u81ea\u6c11\u515a\", \"\u9996\u5e2d\u4ea4\u6e09\u5b98\", \"USTR\"\nList 2 : \u4fc2\u308a\u53d7\u3051\u5148 \u5358\u8a9e\u30ea\u30b9\u30c8\n\"\u5206\u304b\u3063\u305f\", \"\u5224\u660e\", \"\u8abf\u6574\", \"\u4ea4\u6e09\", \"\u59a5\u7d50\", \"\u5354\u8b70\", \"\u7d99\u7d9a\", \"\u6301\u3061\u8d8a\u3057\", \"\u59a5\u5354\", \"\u767a\u8868\"\n\n\nmatched_wordpairs_counter.py \u3092\u5b9f\u884c\n\n\n\u4ee5\u4e0b\u306e\u30d5\u30a1\u30a4\u30eb\u304c\u3001\u751f\u6210\u3055\u308c\u307e\u3059\n\n\nkiji_evaluation_result.csv\nkiji_scores.csv\n\n\n\n\u4eca\u56de\u53ce\u96c6\u3057\u305f\u8a18\u4e8b\u306e\u306a\u304b\u304b\u3089\u3001\u6307\u5b9a\u3057\u305f\u300c\u4fc2\u308a\u53d7\u3051\u5143=>\u5148 \u8a9e\u53e5\u30da\u30a2\u300d\u3092\u691c\u51fa\u3057\u305f\u3068\u3053\u308d\u3001\u30d2\u30c3\u30c8\u3057\u305f\u306e\u306f\u4ee5\u4e0b\u306e\uff11\u4ef6\u3060\u3051\u3067\u3057\u305f\n\n\n\uff08 kiji_evaluation_result.csv\u3000\u30d5\u30a1\u30a4\u30eb \u306e\u4e2d\u8eab \uff09\n\n\n\n\uff08 kiji_scores.csv \u30d5\u30a1\u30a4\u30eb \u306e\u4e2d\u8eab\uff09\n\n\n\n\uff08\u5de5\u7a0b \uff15\uff09  \u8a18\u4e8b \u5c5e\u6027\u30c7\u30fc\u30bf\u4e00\u89a7\u30d5\u30a1\u30a4\u30eb \u751f\u6210\u2460 (\u300c\u8a18\u4e8b\u30bf\u30a4\u30c8\u30eb\uff11 - \u8a18\u4e8b\u306e\u65b0\u805e\u793e\u30b5\u30a4\u30c8\u63b2\u8f09\u5e74\u6708\u65e5\u300d \u30ea\u30b9\u30c8\u30d5\u30a1\u30a4\u30eb\u51fa\u529b\uff09\n\n\ncreate_article_website_posted_date_list.py \u3092\u5b9f\u884c\n\n\u4ee5\u4e0b\u306e\u30d5\u30a1\u30a4\u30eb\u304c\u751f\u6210\u3055\u308c\u307e\u3059\n\n\nkiji_title_date_list.csv\n\n\n\n\uff08 kiji_title_date_list.csv \u30d5\u30a1\u30a4\u30eb \u306e\u4e2d\u8eab \uff09\n\n\n\n\uff08\u5de5\u7a0b \uff16\u3000\u6e96\u5099\uff09  meta_data_file \u30c7\u30a3\u30ec\u30af\u30c8\u30ea \u3092\u4f5c\u6210\n\n\n\n\uff08\u5de5\u7a0b \uff16\uff09  \u8a18\u4e8b \u5c5e\u6027\u30c7\u30fc\u30bf\u4e00\u89a7\u30d5\u30a1\u30a4\u30eb \u751f\u6210\u2460 \uff08\u4ee5\u4e0b\u306e\u4e00\u89a7\u30d5\u30a1\u30a4\u30eb\u3092\u751f\u6210\uff09\n\n\ncreate_kiji_metadata_files.py \u3092\u5b9f\u884c\n\n\n\u4ee5\u4e0b\u306e\u30d5\u30a1\u30a4\u30eb\u304c\u751f\u6210\u3055\u308c\u307e\u3059\n\n\n\u8a18\u4e8b\u30bf\u30a4\u30c8\u30eb_\u8a18\u4e8b\u8a55\u70b9.csv\n\u8a18\u4e8b\u30bf\u30a4\u30c8\u30eb\u30fb\u8a18\u4e8b\u6b04\u540d.csv\n\u65b0\u805e\u793e\u540d\u30fb\u8a18\u4e8b\u30bf\u30a4\u30c8\u30eb\u30fb\u8a18\u4e8b\u30b9\u30af\u30ec\u30a4\u30d4\u30f3\u30b0\u6642\u523b\u30fb\u671f\uff4a\u6587\u5b57\u6570\u30fb\u30a6\u30a7\u30d6\u30b5\u30a4\u30c8\u8a18\u4e8b\u63b2\u8f09\u5e74\u6708\u65e5.csv\n\n\n\n\uff08 \u5404\u30d5\u30a1\u30a4\u30eb\u306e\u51fa\u529b\u884c\u6570\u3092\u78ba\u8a8d \uff09\n\n\n\n\uff08 \u8a18\u4e8b\u30bf\u30a4\u30c8\u30eb_\u8a18\u4e8b\u8a55\u70b9.csv\u3000\u30d5\u30a1\u30a4\u30eb \u306e\u4e2d\u8eab \uff09\n\n\n\n\uff08 \u8a18\u4e8b\u30bf\u30a4\u30c8\u30eb\u30fb\u8a18\u4e8b\u6b04\u540d.csv\u3000\u30d5\u30a1\u30a4\u30eb \u306e\u4e2d\u8eab \uff09\n\n\n\n\uff08 \u65b0\u805e\u793e\u540d\u30fb\u8a18\u4e8b\u30bf\u30a4\u30c8\u30eb\u30fb\u8a18\u4e8b\u30b9\u30af\u30ec\u30a4\u30d4\u30f3\u30b0\u6642\u523b\u30fb\u671f\uff4a\u6587\u5b57\u6570\u30fb\u30a6\u30a7\u30d6\u30b5\u30a4\u30c8\u8a18\u4e8b\u63b2\u8f09\u5e74\u6708\u65e5.csv \u30d5\u30a1\u30a4\u30eb \u306e\u4e2d\u8eab \uff09\n\n\n\n\uff08\u5de5\u7a0b \uff17\uff09 \u8a18\u4e8b\u30bf\u30a4\u30c8\u30eb - \u8a18\u4e8b\u672c\u6587 \u306e\u4e00\u89a7\u30d5\u30a1\u30a4\u30eb \u751f\u6210\n\n\ncreate_kiji_title_honbun_list.py \u3092\u5b9f\u884c\n\n\u4ee5\u4e0b\u306e\u30d5\u30a1\u30a4\u30eb\u304c\u751f\u6210\u3055\u308c\u307e\u3059\n\n\nkiji_title_honbun_list.txt\n\n\n\n\uff08 kiji_title_honbun_list.txt \u30d5\u30a1\u30a4\u30eb \u306e\u4e2d\u8eab \uff09\n\n\n\n\n# \u30b9\u30af\u30ea\u30d7\u30c8\u8cc7\u6e90 \u3068 \u5b9f\u884c\u624b\u9806\n\n####**\u5de5\u7a0b\uff13\u306e\u30b9\u30af\u30ea\u30d7\u30c8\u306f\u3001\u4ee5\u4e0b\u306e\u30a6\u30a7\u30d6\u30b5\u30a4\u30c8\u304b\u3089\u62dd\u501f\u3057\u307e\u3057\u305f**\n#### **[ \u30c7\u30fc\uff082011\u5e7410\u670815\u65e5\u4ed8\uff09\u300c\u65e5\u672c\u8a9e\u4fc2\u308a\u53d7\u3051\u89e3\u6790\u5668 CaboCha Ruby \u62e1\u5f35\u306e\u57fa\u672c\u7684\u306a\u4f7f\u3044\u65b9\u3068\u3061\u3087\u3063\u3068\u3057\u305f\u5fdc\u7528\u300d ](http://ultraist.hatenablog.com/entry/20111015/1318662808)**\n\n\n#### 1. \u30af\u30ed\u30a6\u30ea\u30f3\u30b0\u5bfe\u8c61\u8a18\u4e8b \u306e_URL_\u30fb\u8a18\u4e8b\u30bf\u30a4\u30c8\u30eb \u4e00\u89a7\u30ea\u30b9\u30c8 \u751f\u6210\n\uff08\u30b9\u30af\u30ea\u30d7\u30c8\u540d\uff09   create_article_title_url_list.py\n\n\uff08\u51fa\u529b\u30d5\u30a1\u30a4\u30eb\uff09   title_url_list_all_articles.txt\n\n#### 2. \u5404\u8a18\u4e8b _URL_ \u306b\u30a2\u30af\u30bb\u30b9\u3057\u3066\u3001_html_\u30d5\u30a1\u30a4\u30eb \u3068 \u8a18\u4e8b\u672c\u6587\u30c6\u30ad\u30b9\u30c8\u30fb\u30d5\u30a1\u30a4\u30eb\u751f\u6210\n\uff08\u30b9\u30af\u30ea\u30d7\u30c8\u540d\uff09   create_kiji_honbun_textfile_htmlfile.py\n\n\uff08\u8aad\u307f\u8fbc\u307f\u30d5\u30a1\u30a4\u30eb\uff09title_url_list_all_articles.txt\n\uff08\u51fa\u529b\u30d5\u30a1\u30a4\u30eb\uff09\n\u3000\u3000\u3000\u3000\u3000\u3000\u3000\u3000\uff08\uff11\uff09 \u8a18\u4e8b\u672c\u6587\u30c6\u30ad\u30b9\u30c8\u30d5\u30a1\u30a4\u30eb\uff08\u8a18\u4e8b\u672c\u6570\u5206\u3001\u30d5\u30a1\u30a4\u30eb\u751f\u6210\uff09  \n                                  \n\u3000\u3000\u3000\u3000\u3000\u3000\u3000\u3000\uff08\uff12\uff09 \u8a18\u4e8bHTML\u30d5\u30a1\u30a4\u30eb\uff08\u8a18\u4e8b\u672c\u6570\u5206\u3001\u30d5\u30a1\u30a4\u30eb\u751f\u6210\uff09\n                         \n\u3000\u3000\u3000\u3000\u3000\u3000\u3000\u3000\uff08\uff13\uff09 kiji_metadata_file_1.csv   \uff08\u51fa\u529b\u5148\uff09  \u30eb\u30fc\u30c8\u30c7\u30a3\u30ec\u30af\u30c8\u30ea\n###### \u203b\uff08\u66f8\u5f0f\uff09\u300c\u65b0\u805e\u793e\u540d\u3000\u8a18\u4e8b\u30bf\u30a4\u30c8\u30eb\u3000\u30b9\u30af\u30ec\u30a4\u30d4\u30f3\u30b0\u5b9f\u884c\u5e74\u6708\u65e5\u6642\u5206\u79d2\u3000\u8a18\u4e8b\u672c\u6587\u6587\u5b57\u6570\u300d\uff08\u30bf\u30d6\u533a\u5207\u308a\uff09\n\n#### 3. \u5404\u8a18\u4e8b \u672c\u6587\u30c6\u30ad\u30b9\u30c8\u30d5\u30a1\u30a4\u30eb \u3092\u4fc2\u308a\u53d7\u3051\u5206\u89e3\u3057\u3066\u3001\u300cXXX\uff08\u4e3b\u8a9e\u30d5\u30ec\u30fc\u30ba\uff09 => YYY\uff08\u8ff0\u8a9e\u30d5\u30ec\u30fc\u30ba\uff09\u300d\u306e\u5168\u30da\u30a2 \u51fa\u529b \n\uff08\u30b9\u30af\u30ea\u30d7\u30c8\u540d\uff09 get_kakariuke_wordpairs.rb\n\n\uff08\u8aad\u307f\u8fbc\u307f\u30d5\u30a1\u30a4\u30eb\uff09 \u5404\u8a18\u4e8b\u306e\u8a18\u4e8b\u672c\u6587\u30c6\u30ad\u30b9\u30c8\u30d5\u30a1\u30a4\u30eb\n\uff08\u51fa\u529b\u30d5\u30a1\u30a4\u30eb\uff09word_pairs:\u301c \uff08\u8a18\u4e8b\u672c\u6570\u5206\u3001\u30d5\u30a1\u30a4\u30eb\u751f\u6210)  \uff08\u51fa\u529b\u5148\uff09 kiji_honbun_textfile\n\n\n#### 4. \u6307\u5b9a\u3057\u305f\u300c\u4e3b\u8a9e\u30d5\u30ec\u30fc\u30ba => \u8ff0\u8a9e\u30d5\u30ec\u30fc\u30ba\u300d\u306e\u691c\u51fa\u56de\u6570\u3092\u96c6\u8a08 & \u51fa\u529b\n\uff08\u30b9\u30af\u30ea\u30d7\u30c8\u540d\uff09matched_wordpairs_counter.py\n\n\uff08\u8aad\u8fbc\u307f\u30d5\u30a1\u30a4\u30eb\uff09\u5404\u8a18\u4e8b\u306eword_pairs:\u301c \u30d5\u30a1\u30a4\u30eb\n\uff08\u51fa\u529b\u30d5\u30a1\u30a4\u30eb\uff09 \n\u3000\u3000\u3000\u3000\u3000\u3000\u3000\u3000\uff08\uff11\uff09 kiji_evaluation_result.csv \uff08\u691c\u7d22\u8a9e\u53e5\u30d2\u30c3\u30c8\u3057\u305f\u8a18\u4e8b \u672c\u6570\u5206\uff09\n\n\u3000\u3000\u3000\u3000\u3000\u3000\u3000\u3000\uff08\uff12\uff09 kiji_scores.csv (\uff11\u30d5\u30a1\u30a4\u30eb\uff09 \n\n\n**\u4eca\u56de\u306f\u3001\uff08\u4e3b\u8a9e \u8a9e\u53e5\uff09\u300c _List 1_ \u306e\u3046\u3061\u3001\u3044\u305a\u308c\u304b\u306e\u5358\u8a9e \u300d ==>>\uff08\u8ff0\u8a9e \u8a9e\u53e5\uff09 \u300c _List 2_ \u306e\u3046\u3061\u3001\u3044\u305a\u308c\u304b\u306e\u5358\u8a9e \u300d\n\u306b\u8a72\u5f53\u3059\u308b \u4fc2\u308a\u53d7\u3051\u30da\u30a2 \u6587 \u3092 \u5168\u4fc2\u308a\u53d7\u3051\u8a9e\u53e5\u30da\u30a2\u4e00\u89a7\u30ea\u30b9\u30c8 \u306e\u306a\u304b\u304b\u3089\u3001\u691c\u51fa\u3057\u3066\u307f\u307e\u3059\u3002**\n\n1. **_List 1_ : \u4fc2\u308a\u53d7\u3051\u5143 \u5358\u8a9e\u30ea\u30b9\u30c8**\n\t\"TPP\", \"JA\u5168\u4e2d\", \"\u8fb2\u696d\u56e3\u4f53\", \"\u81ea\u6c11\u515a\", \"\u9996\u5e2d\u4ea4\u6e09\u5b98\", \"USTR\"\n\n2. **_List 2_ : \u4fc2\u308a\u53d7\u3051\u5148 \u5358\u8a9e\u30ea\u30b9\u30c8**\n\t\"\u5206\u304b\u3063\u305f\", \"\u5224\u660e\", \"\u8abf\u6574\", \"\u4ea4\u6e09\", \"\u59a5\u7d50\", \"\u5354\u8b70\", \"\u7d99\u7d9a\", \"\u6301\u3061\u8d8a\u3057\", \"\u59a5\u5354\", \"\u767a\u8868\"\n\t\n\n#### 5. \u8a18\u4e8b \u5c5e\u6027\u30c7\u30fc\u30bf\u4e00\u89a7\u30d5\u30a1\u30a4\u30eb \u751f\u6210\u2460 (\u300c\u8a18\u4e8b\u30bf\u30a4\u30c8\u30eb\uff11 - \u8a18\u4e8b\u306e\u65b0\u805e\u793e\u30b5\u30a4\u30c8\u63b2\u8f09\u5e74\u6708\u65e5\u300d \u30ea\u30b9\u30c8\u30d5\u30a1\u30a4\u30eb\u51fa\u529b\uff09\n\uff08\u30b9\u30af\u30ea\u30d7\u30c8\u540d\uff09create_article_website_posted_date_list.py\n\uff08\u8aad\u307f\u8fbc\u307f\u30d5\u30a1\u30a4\u30eb\uff09\u5404\u8a18\u4e8b\u306ehtml\u30d5\u30a1\u30a4\u30eb\n\uff08\u51fa\u529b\u30d5\u30a1\u30a4\u30eb\uff09kiji_title_date_list.csv \uff08\u51fa\u529b\u5148\uff09html_file\u30c7\u30a3\u30ec\u30af\u30c8\u30ea\n\t\t\t\t\t\t   <\u66f8\u5f0f> \u300c\u8a18\u4e8b\u30bf\u30a4\u30c8\u30eb\uff11 - \u8a18\u4e8b\u306e\u65b0\u805e\u793e\u30b5\u30a4\u30c8\u63b2\u8f09\u5e74\u6708\u65e5\u300d\n\n\n#### 6. \u8a18\u4e8b \u5c5e\u6027\u30c7\u30fc\u30bf\u4e00\u89a7\u30d5\u30a1\u30a4\u30eb \u751f\u6210\u2460 \uff08\u4ee5\u4e0b\u306e\u4e00\u89a7\u30d5\u30a1\u30a4\u30eb\u3092\u751f\u6210\uff09\n\uff08\u30b9\u30af\u30ea\u30d7\u30c8\u540d\uff09create_kiji_metadata_files.py\n\uff08\u51fa\u529b\u30d5\u30a1\u30a4\u30eb\uff09\n\u3000\u3000\u3000\u3000\u3000\u3000\u3000\u3000\uff08\uff11\uff09 \u65b0\u805e\u793e\u540d-\u8a18\u4e8b\u30bf\u30a4\u30c8\u30eb-\u8a18\u4e8b\u30b9\u30af\u30ec\u30a4\u30d4\u30f3\u30b0\u6642\u523b-\u8a18\u4e8b\u6587\u5b57\u6570-\u30a6\u30a7\u30d6\u30b5\u30a4\u30c8\u8a18\u4e8b\u63b2\u8f09\u5e74\u6708\u65e5.csv\n\u3000\u3000\u3000\u3000\u3000\u3000\u3000\u3000\uff08\uff12\uff09 \u8a18\u4e8b\u30bf\u30a4\u30c8\u30eb \u8a18\u4e8b\u8a55\u70b9.csv\n\u3000\u3000\u3000\u3000\u3000\u3000\u3000\u3000\uff08\uff13\uff09 \u8a18\u4e8b\u30bf\u30a4\u30c8\u30eb-\u8a18\u4e8b\u6b04\u540d.csv\n\n#### 7. \u8a18\u4e8b\u30bf\u30a4\u30c8\u30eb - \u8a18\u4e8b\u672c\u6587 \u306e\u4e00\u89a7\u30d5\u30a1\u30a4\u30eb \u751f\u6210\n\tcreate_kiji_title_honbun_list.py\n\n\t\uff08\u51fa\u529b\u30d5\u30a1\u30a4\u30eb\uff09  kiji_title_honbun_list \n \n\n___\n\n# \u8cc7\u6e90\u914d\u7f6e\u95a2\u4fc2\n\n  \u3010root\u30c7\u30a3\u30ec\u30af\u30c8\u30ea\u3011: \u2460 create_article_title_url_list.py / \u2461 create_kiji_honbun_textfile_htmlfile.py / \u2465 create_kiji_metadata_files.py\n   |\n   |\n   |---\u3010kiji_honbun_textfile \u30c7\u30a3\u30ec\u30af\u30c8\u30ea\u3011 \u2462   get_kakariuke_wordpairs.rb  /  \u2463 matched_wordpairs_counter.py / \u2466 create_kiji_title_honbun_list.py\n   |        \n   |---\u3010html_file \u30c7\u30a3\u30ec\u30af\u30c8\u30ea\u3011\u2464 create_article_website_posted_date_list.py \n\n___\n\n# \u30b9\u30af\u30ea\u30d7\u30c8\n\n### **create_article_title_url_list.py**\n\n```{Python:create_article_title_url_list.py}\n#!/usr/bin/env python2.7\n# ~*- coding: utf-8 -*-\n\nimport re, os, urllib2, types, codecs\nfrom bs4 import BeautifulSoup\n\n\ndef get_soup_from_url(url):\n    htmlfile = url.read()\n    soup = BeautifulSoup(htmlfile)\n    return soup\n\n\ndef output_title_list(tag, tab_name):\n    if not(tag):\n        return \"\"\n    \n    anchor_tag_list = tag.findAll(\"a\")\n    output_file_path = os.getcwd()+\"/titles_\"+tab_name+\".txt\"\n       \n    ng_pattern = re.compile(\"(\\A[0-9]+\\Z)\")\n    \n    article_title_list = [\"\"] \n  \n    for anchor_tag in anchor_tag_list:\n        article_title = anchor_tag.string.encode('utf-8')\n        \n        if (\"\u7d9a\u304d\u3092\u8aad\u3080\" in article_title) or (\"\u3082\u3063\u3068\u898b\u308b\" in article_title):\n            continue\n\n        if ng_pattern.search(article_title):\n            continue\n        \n        if (\"\u6b21\u3078\" in article_title) or (\"\u524d\u3078\" in article_title):\n            continue\n        \n        article_title_list.append(str(article_title).decode('utf-8'))\n\n\n    del article_title_list[0]\n    return article_title_list\n    \n\n\ndef output_url_list(tag, tab_name):\n    if not(tag):\n        return \"\"\n    \n    li_tag_list = tag.findAll(\"li\")\n\n    pattern = re.compile(\"(\\/.+html)\")\n    url_head_string = \"http://www.sankei.com\"\n\n    article_url_list = [\"\"]\n\n    for li_tag in li_tag_list:\n        url_unicode = unicode(li_tag)\n\n        if \"html\" in url_unicode:\n            url = pattern.search(url_unicode)\n            if not url:\n                continue\n            else:\n                article_url_list.append(url_head_string+url.group(0))\n\n\n    del article_url_list[0]\n    return article_url_list\n\n\ndef output_article_info_list(tag, tab_name):\n    article_title_list = output_title_list(tag, tab_name)\n    article_url_list = output_url_list(tag, tab_name)\n    \n    return [article_title_list, article_url_list]\n\n\n#======================== \u30e1\u30bd\u30c3\u30c9\u5b9a\u7fa9\u304a\u308f\u308a ===================================\n\n\n\n#==== \u300c\u30db\u30fc\u30e0\u300d\u6b04 \u30c7\u30d5\u30a9\u30eb\u30c8\u8868\u793a\u30da\u30fc\u30b8 \u753b\u9762\u63b2\u8f09\u5168\u8a18\u4e8b\u60c5\u5831\u51fa\u529b\uff08\u300c\u3082\u3063\u3068\u898b\u308b\u300d\u30af\u30ea\u30c3\u30af\u524d\uff09\nurl_home_top = urllib2.urlopen('http://www.sankei.com/')\ntab_name = \"home_top\"\n\nsoup = get_soup_from_url(url_home_top)\n\n# Home\u6b04\u30c7\u30d5\u30a9\u30eb\u30c8\u753b\u9762\u3000\u6700\u4e0a\u6bb5\u306e\u5927\u30b5\u30a4\u30ba\u6587\u5b57\u8868\u8a18 \u8a18\u4e8b\uff11\u672c \ndiv_tag_1 = soup.find(\"section\", {\"class\" : \"modToppick clearfix\"})\n\n# Home\u6b04\u30c7\u30d5\u30a9\u30eb\u30c8\u753b\u9762\u3000\u666e\u901a\u30b5\u30a4\u30ba\u6587\u5b57\u8868\u8a18 \u305d\u306e\u4ed6 \u8907\u6570 \u8a18\u4e8b \ndiv_tag_2 = soup.find(\"section\", {\"class\" : \"modToplist\"})\n\ntop_article_title, top_article_url = output_article_info_list(div_tag_1, tab_name)\narticle_title_list, article_url_list = output_article_info_list(div_tag_2, tab_name)\n\n#===== \u304a\u308f\u308a (\u300c\u30db\u30fc\u30e0\u300d\u6b04 \u30c7\u30d5\u30a9\u30eb\u30c8\u8868\u793a\u30da\u30fc\u30b8)=======================================\n\n\n#==== \u300c\u901f\u5831\u300d\u6b04 \u30da\u30fc\u30b8 \u753b\u9762\u63b2\u8f09\u5168\u8a18\u4e8b\u60c5\u5831\u51fa\u529b\uff08\u300c\u30db\u30fc\u30e0\u300d\u753b\u9762 \u4e0b\u306e\u300c\u3082\u3063\u3068\u898b\u308b\u300d\u30af\u30ea\u30c3\u30af\u5f8c\u306b\u9077\u79fb\u3059\u308b\u753b\u9762\uff09\n\n#\u300c\u901f\u5831 \u8a73\u7d30\u30da\u30fc\u30b8\u300d\u306f\u8907\u6570\u30da\u30fc\u30b8\u306b\u308f\u305f\u308b\u305f\u3081\u3001\u5404\u8a18\u4e8b\u76ee\u6b21\u30da\u30fc\u30b8\u306eURL\u3092\u53d6\u5f97\nurl_home_detail_1 = urllib2.urlopen('http://www.sankei.com/flash/newslist/flash-n1.html')\nsoup = get_soup_from_url(url_home_detail_1)\n\nindex_page_url_list = ['http://www.sankei.com/flash/newslist/flash-n1.html'] \n\ndiv_tag = soup.find(\"div\", {\"class\" : \"pagenator\"})\nanchor_tag_list = div_tag.findAll(\"a\", {\"class\" : \"page\"})\npattern = re.compile(\"(\\/.+html)\")\nurl_head_string = \"http://www.sankei.com/flash/newslist\"\n\n\nfor anchor_tag in anchor_tag_list:\n    url_unicode = unicode(anchor_tag)\n    if \"html\" in url_unicode:\n        url = pattern.search(url_unicode)\n        if url:\n            index_page_url_list.append(url_head_string+url.group(0))\n\n\ntitle_list_sokuhou_article = []\nurl_list_sokuhou_article = []\n\nfor index_page_url in index_page_url_list:\n   \n    #\u8a18\u4e8b\u76ee\u6b21\u30da\u30fc\u30b8 \uff11\u30da\u30fc\u30b8\u3054\u3068\u306b\u3001\u305d\u308c\u305e\u308c\u4e0b\u8a18\u3092\u5b9f\u884c\u3057\u3066\u3001\u76ee\u6b21\u8a18\u8f09 \u8a18\u4e8b\u306e\u30bf\u30a4\u30c8\u30eb\u30fbURL\u3092\u30d5\u30a1\u30a4\u30eb\u306b\u51fa\u529b\n    tab_name = \"home\"\n    url = urllib2.urlopen(index_page_url)\n    soup = get_soup_from_url(url)\n    div_tag = soup.find(\"section\", {\"class\" : \"indexText clearfix\"})\n\n    title_partlist_sokuhou_article, url_partlist_sokuhou_article = output_article_info_list(div_tag, tab_name)\n    title_list_sokuhou_article.extend(title_partlist_sokuhou_article)\n    url_list_sokuhou_article.extend(url_partlist_sokuhou_article)\n    \n#===== \u304a\u308f\u308a (\u901f\u5831\u6b04 \u8a73\u7d30\u8868\u793a\u30da\u30fc\u30b8)=======================================\n\n\n#==== \u300c\u4e8b\u4ef6\u300d\u6b04 \u8a73\u7d30\u30da\u30fc\u30b8 \u753b\u9762\u63b2\u8f09\u5168\u8a18\u4e8b\u60c5\u5831\u51fa\u529b\uff08\u300c\u4e8b\u4ef6\u300d\u6b04 \u4e0b\u306e\u300c\u3082\u3063\u3068\u898b\u308b\u300d\u30af\u30ea\u30c3\u30af\u5f8c\uff09\n\n#\u300c\u4e8b\u4ef6 \u8a73\u7d30\u30da\u30fc\u30b8\u300d\u306f\u8907\u6570\u30da\u30fc\u30b8\u306b\u308f\u305f\u308b\u305f\u3081\u3001\u5404\u8a18\u4e8b\u76ee\u6b21\u30da\u30fc\u30b8\u306eURL\u3092\u53d6\u5f97\njiken_detail_1 = urllib2.urlopen('http://www.sankei.com/affairs/newslist/affairs-n1.html')\nsoup = get_soup_from_url(jiken_detail_1)\n\nindex_page_url_list = ['http://www.sankei.com/affairs/newslist/affairs-n1.html'] \n\ndiv_tag = soup.find(\"div\", {\"class\" : \"pagenator\"})\nanchor_tag_list = div_tag.findAll(\"a\", {\"class\" : \"page\"})\npattern = re.compile(\"(\\/.+html)\")\nurl_head_string = \"http://www.sankei.com/affairs/newslist\"\n\nfor anchor_tag in anchor_tag_list:\n    url_unicode = unicode(anchor_tag)\n    if \"html\" in url_unicode:\n        url = pattern.search(url_unicode)\n        if url:\n            index_page_url_list.append(url_head_string+url.group(0))\n\ntitle_list_jiken_article = []\nurl_list_jiken_article = []\n\nfor index_page_url in index_page_url_list:\n\n    #\u8a18\u4e8b\u76ee\u6b21\u30da\u30fc\u30b8 \uff11\u30da\u30fc\u30b8\u3054\u3068\u306b\u3001\u305d\u308c\u305e\u308c\u4e0b\u8a18\u3092\u5b9f\u884c\u3057\u3066\u3001\u76ee\u6b21\u8a18\u8f09 \u8a18\u4e8b\u306e\u30bf\u30a4\u30c8\u30eb\u30fbURL\u3092\u30d5\u30a1\u30a4\u30eb\u306b\u51fa\u529b\n    tab_name = \"jiken\"\n    url = urllib2.urlopen(index_page_url)\n    soup = get_soup_from_url(url)\n    div_tag = soup.find(\"section\", {\"class\" : \"indexText clearfix\"})\n\n    title_partlist_jiken_article, url_partlist_jiken_article = output_article_info_list(div_tag, tab_name)\n    title_list_jiken_article.extend(title_partlist_jiken_article)\n    url_list_jiken_article.extend(url_partlist_jiken_article)\n   \n#===== \u304a\u308f\u308a (\u300c\u4e8b\u4ef6\u300d\u6b04 \u8a73\u7d30\u8868\u793a\u30da\u30fc\u30b8)=======================================\n\n\n#==== \u300c\u653f\u6cbb\u300d\u6b04 \u8a73\u7d30\u30da\u30fc\u30b8 \u753b\u9762\u63b2\u8f09\u5168\u8a18\u4e8b\u60c5\u5831\u51fa\u529b\uff08\u300c\u653f\u6cbb\u300d\u6b04 \u4e0b\u306e\u300c\u3082\u3063\u3068\u898b\u308b\u300d\u30af\u30ea\u30c3\u30af\u5f8c\uff09\n\n#\u300c\u653f\u6cbb \u8a73\u7d30\u30da\u30fc\u30b8\u300d\u306f\u8907\u6570\u30da\u30fc\u30b8\u306b\u308f\u305f\u308b\u305f\u3081\u3001\u5404\u8a18\u4e8b\u76ee\u6b21\u30da\u30fc\u30b8\u306eURL\u3092\u53d6\u5f97\nseiji_detail_1 = urllib2.urlopen('http://www.sankei.com/politics/newslist/politics-n1.html')\nsoup = get_soup_from_url(seiji_detail_1)\n\nindex_page_url_list = ['http://www.sankei.com/politics/newslist/politics-n1.html'] \n\ndiv_tag = soup.find(\"div\", {\"class\" : \"pagenator\"})\nanchor_tag_list = div_tag.findAll(\"a\", {\"class\" : \"page\"})\npattern = re.compile(\"(\\/.+html)\")\nurl_head_string = \"http://www.sankei.com/politics/newslist\"#\n\nfor anchor_tag in anchor_tag_list:\n    url_unicode = unicode(anchor_tag)\n    if \"html\" in url_unicode:\n        url = pattern.search(url_unicode)\n        if url:\n            index_page_url_list.append(url_head_string+url.group(0))\n\n\ntitle_list_seiji_article = []\nurl_list_seiji_article = []\n\nfor index_page_url in index_page_url_list:\n\n    #\u8a18\u4e8b\u76ee\u6b21\u30da\u30fc\u30b8 \uff11\u30da\u30fc\u30b8\u3054\u3068\u306b\u3001\u305d\u308c\u305e\u308c\u4e0b\u8a18\u3092\u5b9f\u884c\u3057\u3066\u3001\u76ee\u6b21\u8a18\u8f09 \u8a18\u4e8b\u306e\u30bf\u30a4\u30c8\u30eb\u30fbURL\u3092\u30d5\u30a1\u30a4\u30eb\u306b\u51fa\u529b\n    tab_name = \"seiji\"\n    url = urllib2.urlopen(index_page_url)\n    soup = get_soup_from_url(url)\n    div_tag = soup.find(\"section\", {\"class\" : \"indexText clearfix\"})\n\n    title_partlist_seiji_article, url_partlist_seiji_article = output_article_info_list(div_tag, tab_name)\n    title_list_seiji_article.extend(title_partlist_seiji_article)\n    url_list_seiji_article.extend(url_partlist_seiji_article)\n   \n#===== \u304a\u308f\u308a (\u300c\u653f\u6cbb\u300d\u6b04 \u8a73\u7d30\u8868\u793a\u30da\u30fc\u30b8)=======================================\n\n\n#==== \u300c\u56fd\u969b\u300d\u6b04 \u8a73\u7d30\u30da\u30fc\u30b8 \u753b\u9762\u63b2\u8f09\u5168\u8a18\u4e8b\u60c5\u5831\u51fa\u529b\uff08\u300c\u56fd\u969b\u300d\u6b04 \u4e0b\u306e\u300c\u3082\u3063\u3068\u898b\u308b\u300d\u30af\u30ea\u30c3\u30af\u5f8c\uff09\n\n#\u300c\u56fd\u969b \u8a73\u7d30\u30da\u30fc\u30b8\u300d\u306f\u8907\u6570\u30da\u30fc\u30b8\u306b\u308f\u305f\u308b\u305f\u3081\u3001\u5404\u8a18\u4e8b\u76ee\u6b21\u30da\u30fc\u30b8\u306eURL\u3092\u53d6\u5f97\nkokusai_detail_1 = urllib2.urlopen('http://www.sankei.com/world/newslist/world-n1.html')\nsoup = get_soup_from_url(kokusai_detail_1)\n\nindex_page_url_list = ['http://www.sankei.com/world/newslist/world-n1.html'] \n\ndiv_tag = soup.find(\"div\", {\"class\" : \"pagenator\"})\nanchor_tag_list = div_tag.findAll(\"a\", {\"class\" : \"page\"})\npattern = re.compile(\"(\\/.+html)\")\nurl_head_string = \"http://www.sankei.com/world/newslist\"#\n\nfor anchor_tag in anchor_tag_list:\n    url_unicode = unicode(anchor_tag)\n    if \"html\" in url_unicode:\n        url = pattern.search(url_unicode)\n        if url:\n            index_page_url_list.append(url_head_string+url.group(0))\n\ntitle_list_kokusai_article = []\nurl_list_kokusai_article = []\n\nfor index_page_url in index_page_url_list:\n\n    #\u8a18\u4e8b\u76ee\u6b21\u30da\u30fc\u30b8 \uff11\u30da\u30fc\u30b8\u3054\u3068\u306b\u3001\u305d\u308c\u305e\u308c\u4e0b\u8a18\u3092\u5b9f\u884c\u3057\u3066\u3001\u76ee\u6b21\u8a18\u8f09 \u8a18\u4e8b\u306e\u30bf\u30a4\u30c8\u30eb\u30fbURL\u3092\u30d5\u30a1\u30a4\u30eb\u306b\u51fa\u529b\n    tab_name = \"kokusai\"\n    url = urllib2.urlopen(index_page_url)\n    soup = get_soup_from_url(url)\n    div_tag = soup.find(\"section\", {\"class\" : \"indexText clearfix\"})\n\n    title_partlist_kokusai_article, url_partlist_kokusai_article = output_article_info_list(div_tag, tab_name)\n    title_list_kokusai_article.extend(title_partlist_kokusai_article)\n    url_list_kokusai_article.extend(url_partlist_kokusai_article)\n\n   \n#===== \u304a\u308f\u308a (\u300c\u56fd\u969b\u300d\u6b04 \u8a73\u7d30\u8868\u793a\u30da\u30fc\u30b8)=======================================\n\n\n#==== \u300c\u7d4c\u6e08\u300d\u6b04 \u8a73\u7d30\u30da\u30fc\u30b8 \u753b\u9762\u63b2\u8f09\u5168\u8a18\u4e8b\u60c5\u5831\u51fa\u529b\uff08\u300c\u7d4c\u6e08\u300d\u6b04 \u4e0b\u306e\u300c\u3082\u3063\u3068\u898b\u308b\u300d\u30af\u30ea\u30c3\u30af\u5f8c\uff09\n\n#\u300c\u7d4c\u6e08 \u8a73\u7d30\u30da\u30fc\u30b8\u300d\u306f\u8907\u6570\u30da\u30fc\u30b8\u306b\u308f\u305f\u308b\u305f\u3081\u3001\u5404\u8a18\u4e8b\u76ee\u6b21\u30da\u30fc\u30b8\u306eURL\u3092\u53d6\u5f97\nkeizai_detail_1 = urllib2.urlopen('http://www.sankei.com/economy/newslist/economy-n1.html')\nsoup = get_soup_from_url(keizai_detail_1)\n\nindex_page_url_list = ['http://www.sankei.com/economy/newslist/economy-n1.html'] \n\ndiv_tag = soup.find(\"div\", {\"class\" : \"pagenator\"})\nanchor_tag_list = div_tag.findAll(\"a\", {\"class\" : \"page\"})\npattern = re.compile(\"(\\/.+html)\")\nurl_head_string = \"http://www.sankei.com/economy/newslist\"#\n\nfor anchor_tag in anchor_tag_list:\n    url_unicode = unicode(anchor_tag)\n    if \"html\" in url_unicode:\n        url = pattern.search(url_unicode)\n        if url:\n            index_page_url_list.append(url_head_string+url.group(0))\n\n\ntitle_list_keizai_article = []\nurl_list_keizai_article = []\n\nfor index_page_url in index_page_url_list:\n\n    #\u8a18\u4e8b\u76ee\u6b21\u30da\u30fc\u30b8 \uff11\u30da\u30fc\u30b8\u3054\u3068\u306b\u3001\u305d\u308c\u305e\u308c\u4e0b\u8a18\u3092\u5b9f\u884c\u3057\u3066\u3001\u76ee\u6b21\u8a18\u8f09 \u8a18\u4e8b\u306e\u30bf\u30a4\u30c8\u30eb\u30fbURL\u3092\u30d5\u30a1\u30a4\u30eb\u306b\u51fa\u529b\n    tab_name = \"keizai\"\n    url = urllib2.urlopen(index_page_url)\n    soup = get_soup_from_url(url)\n    div_tag = soup.find(\"section\", {\"class\" : \"indexText clearfix\"})\n\n    title_partlist_keizai_article, url_partlist_keizai_article = output_article_info_list(div_tag, tab_name)\n    title_list_keizai_article.extend(title_partlist_keizai_article)\n    url_list_keizai_article.extend(url_partlist_keizai_article)\n   \n#===== \u304a\u308f\u308a (\u300c\u7d4c\u6e08\u300d\u6b04 \u8a73\u7d30\u8868\u793a\u30da\u30fc\u30b8)=======================================\n\n\n#==== \u300c\u30b3\u30e9\u30e0\u300d\u6b04 \u8a73\u7d30\u30da\u30fc\u30b8 \u753b\u9762\u63b2\u8f09\u5168\u8a18\u4e8b\u60c5\u5831\u51fa\u529b\uff08\u300c\u30b3\u30e9\u30e0\u300d\u6b04 \u4e0b\u306e\u300c\u3082\u3063\u3068\u898b\u308b\u300d\u30af\u30ea\u30c3\u30af\u5f8c\uff09\n\n#\u300c\u30b3\u30e9\u30e0 \u8a73\u7d30\u30da\u30fc\u30b8\u300d\u306f\u8907\u6570\u30da\u30fc\u30b8\u306b\u308f\u305f\u308b\u305f\u3081\u3001\u5404\u8a18\u4e8b\u76ee\u6b21\u30da\u30fc\u30b8\u306eURL\u3092\u53d6\u5f97\nkoramu_detail_1 = urllib2.urlopen('http://www.sankei.com/column/newslist/column-n1.html')\nsoup = get_soup_from_url(koramu_detail_1)\n\nindex_page_url_list = ['http://www.sankei.com/column/newslist/column-n1.html'] \n\ndiv_tag = soup.find(\"div\", {\"class\" : \"pagenator\"})\nanchor_tag_list = div_tag.findAll(\"a\", {\"class\" : \"page\"})\npattern = re.compile(\"(\\/.+html)\")\nurl_head_string = \"http://www.sankei.com/column/newslist\"#\n\nfor anchor_tag in anchor_tag_list:\n    url_unicode = unicode(anchor_tag)\n    if \"html\" in url_unicode:\n        url = pattern.search(url_unicode)\n        if url:\n            index_page_url_list.append(url_head_string+url.group(0))\n\n\ntitle_list_koramu_article = []\nurl_list_koramu_article = []\n\nfor index_page_url in index_page_url_list:\n\n    #\u8a18\u4e8b\u76ee\u6b21\u30da\u30fc\u30b8 \uff11\u30da\u30fc\u30b8\u3054\u3068\u306b\u3001\u305d\u308c\u305e\u308c\u4e0b\u8a18\u3092\u5b9f\u884c\u3057\u3066\u3001\u76ee\u6b21\u8a18\u8f09 \u8a18\u4e8b\u306e\u30bf\u30a4\u30c8\u30eb\u30fbURL\u3092\u30d5\u30a1\u30a4\u30eb\u306b\u51fa\u529b\n    tab_name = \"column\"\n    url = urllib2.urlopen(index_page_url)\n    soup = get_soup_from_url(url)\n    div_tag = soup.find(\"section\", {\"class\" : \"indexText clearfix\"})\n\n    title_partlist_koramu_article, url_partlist_koramu_article = output_article_info_list(div_tag, tab_name)\n    title_list_koramu_article.extend(title_partlist_koramu_article)\n    url_list_koramu_article.extend(url_partlist_koramu_article)\n\n   \n#===== \u304a\u308f\u308a (\u300c\u30b3\u30e9\u30e0\u300d\u6b04 \u8a73\u7d30\u8868\u793a\u30da\u30fc\u30b8)=======================================\n\n\n#==== \u3059\u3079\u3066\u306e\u6b04 \u63b2\u8f09\u8a18\u4e8b \u8a18\u4e8b\u30bf\u30a4\u30c8\u30eb\u30fbURL\u30ea\u30b9\u30c8 \uff08\uff12\u4ef6\u4ee5\u4e0a\u306e\u6b04\u306b\u91cd\u8907 \u63b2\u8f09\u3055\u308c\u3066\u3044\u308b\u8a18\u4e8b\u306f\u3001\uff11\u56de\u306e\u307f\u8868\u793a\uff09\n\n#\u3000\u540c\u4e00\u30bf\u30a4\u30c8\u30eb\u306e\u8a18\u4e8b\u304c\u3001\u8907\u6570\u306e\u6b04\u306b\u63b2\u8f09\u3055\u308c\u308b\u5834\u5408\u3001\u30bf\u30a4\u30c8\u30eb\u306f\uff11\u3064\u3001URL\u306f\u8907\u6570 \u306b\u306a\u308b\u3002\u3053\u306e\u305f\u3081\u3001\u30bf\u30a4\u30c8\u30eb\u30ea\u30b9\u30c8\u3068URL\u30ea\u30b9\u30c8\u3092\u5225\u3005\u306b\u91cd\u8907\u6392\u9664\u3059\u308b\u3068\u30bf\u30a4\u30c8\u30eb\u30ea\u30b9\u30c8\u306e\u8981\u7d20\u6570\u306e\u307f\u5c11\u306a\u304f\u306a\u308b\u3002\n#  \u4e0a\u8a18\u306e\u7406\u7531\u304b\u3089\u3001\u300c\u8a18\u4e8b\u30bf\u30a4\u30c8\u30eb - \u8a18\u4e8bURL\u300d \u306e\u7d44\u307f\u5408\u308f\u305b\u3092 key-value \u30c7\u30fc\u30bf\u306e\u3088\u3046\u306b\u751f\u6210\u3057\u3066\u3001\u5f53\u8a72\u30c7\u30fc\u30bf\u306e\u91cd\u8907\u6392\u9664\u3092\u884c\u3046\n\n\n# \u8f9e\u66f8\u306e\u521d\u671f\u5316\nsokuhou_dict = {\"key_top\": \"value_top\"}  \n\n# \u300c\u901f\u5831\u300d\u6b04\u306e\u8a18\u4e8b\nif len(title_list_sokuhou_article) == len(url_list_sokuhou_article):\n    print \"\u300c\u901f\u5831\u300d\u6b04\u306e\u8a18\u4e8b\u306f\u3001\u8a18\u4e8b\u30bf\u30a4\u30c8\u30eb\u4ef6\u6570 \u3068 \u8a18\u4e8bURL\u4ef6\u6570 \u304c\u9f5f\u9f6c\u306a\u304f\u4e00\u81f4\u3057\u307e\u3057\u305f\u3002\u554f\u984c\u3042\u308a\u307e\u305b\u3093\u3002\\n\"\n    for i in range(0, len(title_list_sokuhou_article)):\n        sokuhou_dict[title_list_sokuhou_article[i]] = url_list_sokuhou_article[i]\nelse:\n    print \"\u300c\u901f\u5831\u300d\u6b04\u306e\u8a18\u4e8b\u306f\u3001\u8a18\u4e8b\u30bf\u30a4\u30c8\u30eb\u4ef6\u6570 \u3068 \u8a18\u4e8bURL\u4ef6\u6570 \u304c\u4e00\u81f4\u3057\u307e\u305b\u3093\u3002\u30ea\u30b9\u30c8\u306e\u95a2\u4fc2\u6027\u306b\u9f5f\u9f6c\u304c\u3042\u308a\u307e\u3059\u3002\\n\"\n\ndel(sokuhou_dict[\"key_top\"])\n\n\n# \u300c\u4e8b\u4ef6\u300d\u6b04\u306e\u8a18\u4e8b\njiken_dict = {\"key_top\": \"value_top\"}  \n\nif len(title_list_jiken_article) == len(url_list_jiken_article):\n    print \"\u300c\u4e8b\u4ef6\u300d\u6b04\u306e\u8a18\u4e8b\u306f\u3001\u8a18\u4e8b\u30bf\u30a4\u30c8\u30eb\u4ef6\u6570 \u3068 \u8a18\u4e8bURL\u4ef6\u6570 \u304c\u9f5f\u9f6c\u306a\u304f\u4e00\u81f4\u3057\u307e\u3057\u305f\u3002\u554f\u984c\u3042\u308a\u307e\u305b\u3093\u3002\\n\"\n    for i in range(0, len(title_list_jiken_article)):\n        jiken_dict[title_list_jiken_article[i]] = url_list_jiken_article[i]\nelse:\n    print \"\u300c\u4e8b\u4ef6\u300d\u6b04\u306e\u8a18\u4e8b\u306f\u3001\u8a18\u4e8b\u30bf\u30a4\u30c8\u30eb\u4ef6\u6570 \u3068 \u8a18\u4e8bURL\u4ef6\u6570 \u304c\u4e00\u81f4\u3057\u307e\u305b\u3093\u3002\u30ea\u30b9\u30c8\u306e\u95a2\u4fc2\u6027\u306b\u9f5f\u9f6c\u304c\u3042\u308a\u307e\u3059\u3002\\n\"\n\ndel(jiken_dict[\"key_top\"])\n\n\n# \u300c\u653f\u6cbb\u300d\u6b04\u306e\u8a18\u4e8b\nseiji_dict = {\"key_top\": \"value_top\"} \n\nif len(title_list_seiji_article) == len(url_list_seiji_article):\n    print \"\u300c\u653f\u6cbb\u300d\u6b04\u306e\u8a18\u4e8b\u306f\u3001\u8a18\u4e8b\u30bf\u30a4\u30c8\u30eb\u4ef6\u6570 \u3068 \u8a18\u4e8bURL\u4ef6\u6570 \u304c\u9f5f\u9f6c\u306a\u304f\u4e00\u81f4\u3057\u307e\u3057\u305f\u3002\u554f\u984c\u3042\u308a\u307e\u305b\u3093\u3002\\n\"\n    for i in range(0, len(title_list_seiji_article)):\n        seiji_dict[title_list_seiji_article[i]] = url_list_seiji_article[i]\nelse:\n    print \"\u300c\u653f\u6cbb\u300d\u6b04\u306e\u8a18\u4e8b\u306f\u3001\u8a18\u4e8b\u30bf\u30a4\u30c8\u30eb\u4ef6\u6570 \u3068 \u8a18\u4e8bURL\u4ef6\u6570 \u304c\u4e00\u81f4\u3057\u307e\u305b\u3093\u3002\u30ea\u30b9\u30c8\u306e\u95a2\u4fc2\u6027\u306b\u9f5f\u9f6c\u304c\u3042\u308a\u307e\u3059\u3002\\n\"\n\ndel(seiji_dict[\"key_top\"])\n\n\n# \u300c\u56fd\u969b\u300d\u6b04\u306e\u8a18\u4e8b\nkokusai_dict = {\"key_top\": \"value_top\"}\n\nif len(title_list_kokusai_article) == len(url_list_kokusai_article):\n    print \"\u300c\u56fd\u969b\u300d\u6b04\u306e\u8a18\u4e8b\u306f\u3001\u8a18\u4e8b\u30bf\u30a4\u30c8\u30eb\u4ef6\u6570 \u3068 \u8a18\u4e8bURL\u4ef6\u6570 \u304c\u9f5f\u9f6c\u306a\u304f\u4e00\u81f4\u3057\u307e\u3057\u305f\u3002\u554f\u984c\u3042\u308a\u307e\u305b\u3093\u3002\\n\"\n    for i in range(0, len(title_list_kokusai_article)):\n        kokusai_dict[title_list_kokusai_article[i]] = url_list_kokusai_article[i]\nelse:\n    print \"\u300c\u56fd\u969b\u300d\u6b04\u306e\u8a18\u4e8b\u306f\u3001\u8a18\u4e8b\u30bf\u30a4\u30c8\u30eb\u4ef6\u6570 \u3068 \u8a18\u4e8bURL\u4ef6\u6570 \u304c\u4e00\u81f4\u3057\u307e\u305b\u3093\u3002\u30ea\u30b9\u30c8\u306e\u95a2\u4fc2\u6027\u306b\u9f5f\u9f6c\u304c\u3042\u308a\u307e\u3059\u3002\\n\"\n\ndel(kokusai_dict[\"key_top\"])\n\n\n# \u300c\u7d4c\u6e08\u300d\u6b04\u306e\u8a18\u4e8b\nkeizai_dict = {\"key_top\": \"value_top\"}\n\nif len(title_list_keizai_article) == len(url_list_keizai_article):\n    print \"\u300c\u7d4c\u6e08\u300d\u6b04\u306e\u8a18\u4e8b\u306f\u3001\u8a18\u4e8b\u30bf\u30a4\u30c8\u30eb\u4ef6\u6570 \u3068 \u8a18\u4e8bURL\u4ef6\u6570 \u304c\u9f5f\u9f6c\u306a\u304f\u4e00\u81f4\u3057\u307e\u3057\u305f\u3002\u554f\u984c\u3042\u308a\u307e\u305b\u3093\u3002\\n\"\n    for i in range(0, len(title_list_keizai_article)):\n        keizai_dict[title_list_keizai_article[i]] = url_list_keizai_article[i]\nelse:\n    print \"\u300c\u7d4c\u6e08\u300d\u6b04\u306e\u8a18\u4e8b\u306f\u3001\u8a18\u4e8b\u30bf\u30a4\u30c8\u30eb\u4ef6\u6570 \u3068 \u8a18\u4e8bURL\u4ef6\u6570 \u304c\u4e00\u81f4\u3057\u307e\u305b\u3093\u3002\u30ea\u30b9\u30c8\u306e\u95a2\u4fc2\u6027\u306b\u9f5f\u9f6c\u304c\u3042\u308a\u307e\u3059\u3002\\n\"\n\ndel(keizai_dict[\"key_top\"])\n\n\n# \u300c\u30b3\u30e9\u30e0\u300d\u6b04\u306e\u8a18\u4e8b\nkoramu_dict = {\"key_top\": \"value_top\"}\n\nif len(title_list_koramu_article) == len(url_list_koramu_article):\n    print \"\u300c\u30b3\u30e9\u30e0\u300d\u6b04\u306e\u8a18\u4e8b\u306f\u3001\u8a18\u4e8b\u30bf\u30a4\u30c8\u30eb\u4ef6\u6570 \u3068 \u8a18\u4e8bURL\u4ef6\u6570 \u304c\u9f5f\u9f6c\u306a\u304f\u4e00\u81f4\u3057\u307e\u3057\u305f\u3002\u554f\u984c\u3042\u308a\u307e\u305b\u3093\u3002\\n\"\n    for i in range(0, len(title_list_koramu_article)):\n        koramu_dict[title_list_koramu_article[i]] = url_list_koramu_article[i]\nelse:\n    print \"\u300c\u30b3\u30e9\u30e0\u300d\u6b04\u306e\u8a18\u4e8b\u306f\u3001\u8a18\u4e8b\u30bf\u30a4\u30c8\u30eb\u4ef6\u6570 \u3068 \u8a18\u4e8bURL\u4ef6\u6570 \u304c\u4e00\u81f4\u3057\u307e\u305b\u3093\u3002\u30ea\u30b9\u30c8\u306e\u95a2\u4fc2\u6027\u306b\u9f5f\u9f6c\u304c\u3042\u308a\u307e\u3059\u3002\\n\"\n\ndel(koramu_dict[\"key_top\"])\n\n\n### \u3059\u3079\u3066\u306e\u8f9e\u66f8\u3092\u7d50\u5408 (\u53c2\u8003\uff09http://qiita.com/kk6/items/6362a5fc9f3f06a5969a\n### \u3010\u8981\u8abf\u67fb \u3011 reduce\u30e1\u30bd\u30c3\u30c9\u306f\u3001key\u304c\u91cd\u8907\u3057\u3066\u3001value\u304c\u91cd\u8907\u3057\u306a\u3044\uff08\u8f9e\u66f8\u306e\uff09\u8981\u7d20\u3092\u3001key\u304c\u540c\u3058\u3068\u3044\u3046\u7406\u7531\u3067\u30011\u4ef6\u306b\uff08\u5f8c\u7d9a\u306evalue\u3067\u4e0a\u66f8\u304d\u3057\u3066\uff09\u6271\u3046\u3053\u3068\u306f\u306a\u3044\u304b\uff1f\nall_dicts = [sokuhou_dict, jiken_dict, seiji_dict, kokusai_dict, keizai_dict, koramu_dict]\ngeneral_dict = reduce(lambda fst, scd: dict(fst, **scd), all_dicts)\n\n### \u8f9e\u66f8\u306e\u51fa\u529b \uff08\u53c2\u8003 \uff09http://www.yukun.info/blog/2008/06/python-dict2.html\noutput_file_path = os.getcwd()+\"/title_url_list_all_articles.txt\"\noutput_file = codecs.open(output_file_path, 'a', 'utf-8')\n\nfor k, v in general_dict.items():\n    output_file.write(k + \"   \" + v + \"\\n\")\n\noutput_file.close()\n```\n\n\n### **\uff12\uff0ecreate_kiji_honbun_textfile_htmlfile.py**\n\n```{Python:create_kiji_honbun_textfile_htmlfile.py}\n#!/usr/bin/enb python2.7\n# -*- coding: utf-8 -*-\n\nimport urllib2, re, codecs, os, sys, types, codecs, traceback, chardet\nfrom bs4 import BeautifulSoup\nfrom datetime import *\nimport time\n\ndef is_skip_file(file_name):\n    if not (\".txt\" in file_name):\n        return True\n\n    if  (\"#\" in file_name):\n        return True\n\n\ndef create_output_textfile(file_name):\n    filepath = os.getcwd()+\"/kiji_honbun_textfile/\"+file_name\n    return codecs.open(filepath, 'w','utf-8')\n\n\ndef strip_tags(paragraph):\n    if paragraph.string is None:\n        return \"\"\n\n    return paragraph.string\n\n\ndef is_skip_file(file_name):\n    if not (\".txt\" in file_name):\n        return True\n\n    if  (\"#\" in file_name):\n        return True\n\n\ndef strip_tags(paragraph):\n    if paragraph.string is None:\n        return \"\"\n\n    return paragraph.string\n\n\ndef get_articlebody_within_ptags(ptag_list):\n    text_list = []\n\n    for ptag in ptag_list:\n        text_list.append(strip_tags(ptag))\n\n    return \"\".join(text_list)\n\n\ndef get_honbun_within_divtag(divtag):\n    ptag_list = divtag.findAll(\"p\")\n    return get_articlebody_within_ptags(ptag_list)\n\n\n\ndef get_honbun_of_one_webpage(url):\n\n    webpage = urllib2.urlopen(url)\n    time.sleep(1.0)\n\n    html_file = webpage.read()\n    soup = BeautifulSoup(html_file)\n\n    section_tag = soup.find(\"section\", {\"class\" : \"articleText clearfix\"})\n    if section_tag is None:\n        return None\n\n    article_tag = section_tag.find(\"article\")\n    if article_tag is None:\n        return None\n\n    div_tag = article_tag.find(\"div\", {\"class\" : \"fontMiddiumText\"})\n    if div_tag is None:\n        return None\n    else:\n        return get_honbun_within_divtag(div_tag)\n\n\n\ndef get_honbun_of_all_webpages_of_one_article(article_top_page_url):\n    \n    #\u8907\u6570\u30da\u30fc\u30b8\u306b\u307e\u305f\u304c\u308b\u8a18\u4e8b\u306e\u5bfe\u5fdc\u3092\u7528\u610f\n    article_top_page_website = urllib2.urlopen(article_top_page_url)\n    top_page_htmlfile = article_top_page_website.read()\n    article_top_page_soup = BeautifulSoup(top_page_htmlfile)\n    \n    article_all_pages_url_list = [article_top_page_url]\n\n    div_tag = article_top_page_soup.find(\"div\", {\"class\" : \"pagenator\"})\n \n    if div_tag is not None:\n        anchor_tag_list = div_tag.findAll(\"a\", {\"class\" : \"page\"})\n        pattern = re.compile(\"(\\/.+html)\")\n        url_head_string = \"http://www.sankei.com/\"\n        \n        for anchor_tag in anchor_tag_list:\n            url_unicode = unicode(anchor_tag)\n            if \"html\" in url_unicode:\n                url = pattern.search(url_unicode)\n                if url:\n                    url_string = url_head_string + url.group(0) \n                    url_string = url_string.replace(\"//../..\", \"\")\n                    article_all_pages_url_list.append(url_string)\n                    \n        honbun = [\"\"]\n\n        for article_one_page_url in article_all_pages_url_list:\n            #\u8a18\u4e8b\u76ee\u6b21\u30da\u30fc\u30b8 \uff11\u30da\u30fc\u30b8\u3054\u3068\u306b\u3001\u305d\u308c\u305e\u308c\u4e0b\u8a18\u3092\u5b9f\u884c\u3057\u3066\u3001\u76ee\u6b21\u8a18\u8f09 \u8a18\u4e8b\u306e\u30bf\u30a4\u30c8\u30eb\u30fbURL\u3092\u30d5\u30a1\u30a4\u30eb\u306b\u51fa\u529b  \n            article_one_page_honbun = get_honbun_of_one_webpage(article_one_page_url)\n            honbun.append(article_one_page_honbun)\n\n\n        del honbun[0] # honbun\u30ea\u30b9\u30c8\u306e\u521d\u671f\u5316\u5ba3\u8a00\u6642\u306b\u3001\u5148\u982d\u8981\u7d20\u306b\u5165\u308c\u305f NULL \u3092\u524a\u9664\n        honbun = \"\".join(honbun) # \u30ea\u30b9\u30c8\u578b\u30aa\u30d6\u30b8\u30a7\u30af\u30c8\u3092\u3001string\u578b\u306b\u578b\u5909\u63db (\u5404\u30a6\u30a7\u30d6\u30da\u30fc\u30b8\u63b2\u8f09\u306e\u672c\u6587\u3092\u3001\u6539\u884c\u6587\u5b57\u3092\u631f\u3093\u3067\u884c\u7d50\u5408\uff09\n        return honbun\n\n\n    #\u8907\u6570\u30da\u30fc\u30b8\u306b\u307e\u305f\u304c\u3089\u305a\u3001\u30c8\u30c3\u30d7\u30da\u30fc\u30b8\uff11\u30da\u30fc\u30b8\u3057\u304b\u306a\u3044\u8a18\u4e8b\u306e\u5834\u5408\u306e\u51e6\u7406\n    else:\n        honbun = get_honbun_of_one_webpage(article_top_page_url)\n        return honbun\n\n \n\n# \u4ee5\u4e0a\u3001\u30e1\u30bd\u30c3\u30c9\u5b9a\u7fa9 \u304a\u308a========================================================\n\narticle_info_list = open(\"title_url_list_all_articles.txt\", 'r')\n\nfor line in article_info_list:\n    url_startpoint = line.find(\"http\")\n    url_startpoint = int(url_startpoint)\n\n    url = line[url_startpoint: ]\n    url = str(url)\n    \n    if  \"/../\" in url:\n        url = url.replace(\"/../\", \"/\")\n\n    title_endpoint = url_startpoint - 1\n    title_endpoint = int(title_endpoint)\n\n    title = line[0:title_endpoint] #\u300c\u8a18\u4e8b\u8868\u984c\u540d  \u8a18\u4e8b\u63b2\u8f09URL\u300d\u6587\u5b57\u5217\u306e\u3046\u3061\u3001\u5148\u982d\u6587\u5b57\u304b\u3089\u3001\u8a18\u4e8b\u63b2\u8f09URL\u304c\u59cb\u307e\u308b http \u306eh\u306e1\u6587\u5b57\u524d\u307e\u3067\u306e\u7bc4\u56f2\u3092\u62bd\u51fa\n    title = title.rstrip() #\u8a18\u4e8b\u8868\u984c\u6587\u5b57\u5217\u306e\u3046\u3061\u3001\u672b\u5c3e\u306e\u7a7a\u767d\u6587\u5b57\u3092\u9664\u53bb\n    \n    try:\n        scraping_timestamp = datetime.now().strftime('%Y-%m-%d %H:%M:%S') #str\u578b\u30aa\u30d6\u30b8\u30a7\u30af\u30c8\n        html_file = urllib2.urlopen(url)\n        #\u4ee5\u4e0b\u3001HTML\u30d5\u30a1\u30a4\u30eb\u3092parse\u5b9f\u884c\u3002\u8a18\u4e8b\u672c\u6587\u306e\u307f\u629c\u304d\u51fa\u3057\u3066\u3001\u30c6\u30ad\u30b9\u30c8\u30d5\u30a1\u30a4\u30eb\u306b\u51fa\u529b\n        kiji_honbun = get_honbun_of_all_webpages_of_one_article(url)\n        #\u4ee5\u4e0b\u3001HTML\u30d5\u30a1\u30a4\u30eb\u3092\u30c6\u30ad\u30b9\u30c8\u30d5\u30a1\u30a4\u30eb\u306b\u51fa\u529b\n        html_lines = html_file.read()        \n        kiji_metadata_output = u\"\u7523\u7d4c\u65b0\u805e\".encode('utf-8') + \"\\t\" + title + \"\\t\" + scraping_timestamp\n        html_file_output_filename = os.getcwd() + \"/html_file/\" +str(title)+\".txt\" \n        output_textfile = open(html_file_output_filename, 'w')\n        output_textfile.write(html_lines)\n        output_textfile.close()\n        os.system('nkf -w --overwrite '+ html_file_output_filename) # call UNIX nkf -w command: change character code to UTF-8\n        time.sleep(1.0)\n        \n    except urllib2.HTTPError:\n        print 'HTTPError\u767a\u751f!'\n        print('\u30a8\u30e9\u30fcURL:  '+ url)\n        \n    except Exception, e:\n        print e, 'HTTPError\u4ee5\u5916\u306e\u30a8\u30e9\u30fc\u767a\u751f\uff01'\n \n \t\n    # print chardet.detect(kiji_honbun)  \u7d50\u679c\u306f\u3001ascii                                              \n    kiji_honbun_utf_8 = kiji_honbun.encode('utf-8')\n    mojisuu = len(kiji_honbun_utf_8)\n    kiji_metadata_output = kiji_metadata_output + \"\\t\" + str(mojisuu).encode('utf-8') + \"\\n\"\n    #print chardet.detect(kiji_honbun)  #\u7d50\u679c\u306f\u3001utf-8                                               \n   \n        \n    honbun_output_filename = os.getcwd() + \"/kiji_honbun_textfile/\" + str(title) + \".txt\"\n    honbun_output_file = open(honbun_output_filename, 'w')\n    honbun_output_file.write(kiji_honbun_utf_8)\n    honbun_output_file.close()\n\n    kiji_metadata_output_file_name = os.getcwd() + \"/kiji_metadata_file_1.csv\"\n    kiji_metadata_output_file = open(kiji_metadata_output_file_name, \"a\")\n    kiji_metadata_output_file.write(kiji_metadata_output)\n    kiji_metadata_output_file.close()\n\narticle_info_list.close()\n```\n\n\n### **\uff13\uff0eget_kakariuke_wordpairs.rb**\n```{ruby:ruby1.9.1}\n# -*- coding: utf-8 -*-\nrequire 'CaboCha'\n\n# sentence\u3092\u4fc2\u308a\u53d7\u3051\u89e3\u6790\u3057\u3066\u7d50\u679c\u30c4\u30ea\u30fc\u3092\u5f97\u308b\n\n# \u8aad\u307f\u8fbc\u3093\u3060\u30d5\u30a1\u30a4\u30eb\u306e\u4e2d\u8eab\u3092 sentence \u30aa\u30d6\u30b8\u30a7\u30af\u30c8\u306b\u683c\u7d0d\u3059\u308b\n\ndef GetKijiFilesNamesPaths()\n        current_directory_path = Dir::getwd\n\n        files_names = Dir::entries(current_directory_path) \n\n        files_path = Array.new\n        files_name = Array.new\n\n        files_names.each do |file_name|\n              unless (file_name == \"\") && (file_name.include?(\"word_pairs\"))\n                   if file_name.include?(\".txt\") \n                          unless file_name.include?(\"#\") or file_name.include?(\"~\")\n\t\t\t\tunless file_name.include?(\"list\")\n                       \t\t       files_path.push(current_directory_path + \"/\" + file_name)\n                        \t       files_name.push(file_name)\n                        \tend\n                          end\n\t\t   end\n              end\n        end\n    \treturn files_path, files_name\nend\n\n\n#=== \u8a18\u4e8b\u30d5\u30a1\u30a4\u30eb\u306e\u5185\u5bb9\uff08\u672c\u6587\u30c6\u30ad\u30b9\u30c8\u30c7\u30fc\u30bf\uff09\u3092\u5168\u30d5\u30a1\u30a4\u30eb\u5206\u3001Array\u30aa\u30d6\u30b8\u30a7\u30af\u30c8 sentence[]\u3000\u306b\u683c\u7d0d===\n\nfiles_path, files_name = GetKijiFilesNamesPaths()\n                  \nsentence = Array.new\nn = 0\n\nwhile n < files_path.size\n\n          sentence[n] = File.read(files_path[n], :encoding => Encoding::UTF_8)\n          n+=1\nend\n\n\n#=== Array\u30aa\u30d6\u30b8\u30a7\u30af\u30c8\u304b\u3089\u8a18\u4e8b\uff11\u672c\u6bce\u306e\u672c\u6587\u30c6\u30ad\u30b9\u30c8\u3092\u53d6\u308a\u51fa\u3057\u3066\u3001\u300c\u4fc2\u308a\u53d7\u3051\u5143 <--> \u4fc2\u308a\u53d7\u3051\u5148\u300d \u30da\u30a2\u3092 \uff11\u30da\u30a2\uff11\u884c\u3065\u3064\u30d5\u30a1\u30a4\u30eb\u306b\u51fa\u529b===\n\nm = 0\n\n# m \u306f\u3001\u3044\u307e\u51e6\u7406\u3057\u3066\u3044\u308b\u8a18\u4e8b\u30d5\u30a1\u30a4\u30eb\u306e\u4ef6\u6570\nwhile m < sentence.length\n\n  #\u4fc2\u308a\u53d7\u3051\u8a9e\u53e5\u30da\u30a2 \u51fa\u529b\u30d5\u30a1\u30a4\u30eb\u3092\u7528\u610f\n  # \u3010\u30d5\u30a1\u30a4\u30eb\u540d\u3011 files_name[m]    \n    output_filename = \"word_pairs:\" + files_name[m] \n \n    File.open(output_filename, \"w\") do |output_file|\n        output_file.puts(\" \")\n    end\n\n   #\u4fc2\u308a\u53d7\u3051\u8a9e\u53e5\u30da\u30a2\u3092\u62bd\u51fa\n    parser = CaboCha::Parser.new;\n    tree = parser.parse(sentence[m])\n   \n   # \u7a7a\u306e\u30cf\u30c3\u30b7\u30e5\u3092\u7528\u610f\n    word_pairs_hash = Hash.new()\n\n\n   # \u5168\u3066\u306e\u30c1\u30e3\u30f3\u30af\u306b\u5bfe\u3057\u3066\n     (0 ... tree.chunk_size).each do |i|\n        chunk = tree.chunk(i)\n  \n        # link\u304c\u7e4b\u304c\u3063\u3066\u3044\u308c\u3070\n        if (chunk.link >= 0)\n          # \u30ea\u30f3\u30af\u5143\u3068\n          chunk_from = (0 ... chunk.token_size).map do |j|\n              tree.token(chunk.token_pos + j).normalized_surface\n          end.join(\"-\")\n\n    \n          # \u30ea\u30f3\u30af\u5148\u3092\n          chunk = tree.chunk(chunk.link)\n\n          chunk_to = (0 ... chunk.token_size).map do |j|\n              tree.token(chunk.token_pos + j).normalized_surface\n          end.join(\"-\")\n\n\t  # \u30d5\u30a1\u30a4\u30eb\u306b\u51fa\u529b\n          # \u3010\u30d5\u30a1\u30a4\u30eb\u540d\u3011 files_name[m]    \n          output_filename = \"word_pairs:\" + files_name[m] \n \n          File.open(output_filename, \"a\") do |output_file|\n              output_file.puts(\"#{chunk_from} => #{chunk_to}\")\n          end\n\n         # puts \"#{chunk_from} => #{chunk_to}\"\n\n        end\n     end\n \n   # \u6b21\u306e\u8a18\u4e8b\u672c\u6587\u30d5\u30a1\u30a4\u30eb\u306b\u79fb\u52d5\n    m += 1\t\nend\n```\n\n### **\uff14\uff0ematched_wordpairs_counter.py**\n\n```{Python:matched_wordpairs_counter.py}\n#!/usr/bin/enb python2.7                                                       \n# -*- coding: utf-8 -*-  \n\nimport os, codecs\n\nfile_names = os.listdir(os.getcwd())\n\nfor file_name in file_names:\n     if \"word_pairs\" in file_name:\n        score = 0\n        file_word_pairs = codecs.open(file_name, 'r','utf-8')\n        word_pairs = file_word_pairs.readlines()\n    \n      \n        for one_word_pair in word_pairs: \n            i = one_word_pair.find(\"=\")\n            j = one_word_pair.find(\">\")\n            \n            from_word_end_position = int(i) -1\n            to_word_starts_position = int(j) + 1\n            \n            from_word = one_word_pair[:from_word_end_position]\n            to_word = one_word_pair[to_word_starts_position:]\n\n            from_word = from_word.replace(unichr(0x3010), \"\")  # \u3010 \u3092\u524a\u9664\n            from_word = from_word.replace(unichr(0x3011), \"\")  # \u3011\u3092\u524a\u9664\n            from_word = from_word.replace(\"___-\", \"\")  \n \n            to_word = to_word.replace(unichr(0x3010), \"\")\n            to_word = to_word.replace(unichr(0x3011), \"\")\n            to_word = to_word.replace(\"___-\", \"\")\n\n\n            #\u72ec\u81ea\u30cd\u30bf \u8a18\u4e8b\u5019\u88dc \u691c\u51fa\u6761\u4ef6\n            from_search_words = [u\"TPP\", u\"JA\u5168\u4e2d\", u\"\u8fb2\u696d\u56e3\u4f53\", u\"\u81ea\u6c11\u515a\", u\"\u9996\u5e2d\u4ea4\u6e09\u5b98\", u\"USTR\"]\n            to_search_words = [u\"\u5206\u304b\u3063\u305f\", u\"\u5224\u660e\", u\"\u8abf\u6574\", u\"\u4ea4\u6e09\", u\"\u59a5\u7d50\", u\"\u5354\u8b70\", u\"\u7d99\u7d9a\", u\"\u6301\u3061\u8d8a\u3057\", u\"\u59a5\u5354\", u\"\u767a\u8868\"]  \n\n            #\u72ec\u81ea\u30cd\u30bf \u8a18\u4e8b\u5019\u88dc \u691c\u51fa &\u3000\u7d50\u679c\u51fa\u529b  (\u53c2\u8003\uff09http://d.hatena.ne.jp/podhmo/20111213/1323788999\n            kiji_title = \"\"\n            search_words_hit_phrase = \"\"\n            output_line_list = [\" \"]\n\n            if any([x in from_word for x in from_search_words]) and any([y in to_word for y in to_search_words]):\n                score += 1\n                kiji_title = file_name.replace(\"word_pairs:\", \"\").strip()\n                output_hit_phrase = one_word_pair.replace('=>','\\t')\n                output_hit_phrase = output_hit_phrase.strip()\n                output = kiji_title + \"\\t\" + output_hit_phrase.encode('utf-8') + \"\\n\"\n                f = open(\"kiji_evaluation_result.csv\", \"a\")\n                f.write(output)\n                f.close()\n\n                \n        kiji_title = file_name.replace(\"word_pairs:\", \"\").strip()\n        score_message = kiji_title + \"\\t\" + str(score) + \"\u70b9\\n\"                \n        g = open(\"kiji_scores.csv\", \"a\")\n        g.write(score_message)\n        g.close()\n\n#        os.system('nkf -s --overwrite *.csv')\n```\n\n## **\uff15\uff0ecreate_article_website_posted_date_list.py**\n\n```{Python:create_article_website_posted_date_list.py}\n#!/usr/bin/enb python2.7\n# -*- coding: utf-8 -*-\n\n# \u3053\u306e\u30b9\u30af\u30ea\u30d7\u30c8\u30fb\u30d5\u30a1\u30a4\u30eb\u306f\u3001\u89e3\u6790\u5bfe\u8c61\u3068\u306a\u308b\u5404\u8a18\u4e8b\u306eHTML\u30d5\u30a1\u30a4\u30eb\u683c\u7d0d\u5148\u30c7\u30a3\u30ec\u30af\u30c8\u30ea\u306b\u914d\u7f6e\u3057\u3066\u3001\u5b9f\u884c\u3059\u308b\u3053\u3068\u3002\nimport re, codecs, os, csv\n\nhtml_file_names = os.listdir(os.getcwd())\noutput_message_list = []\n\nfor html_file_name in html_file_names:\n    if \"txt\" in html_file_name:\n        try:\n            f = codecs.open(html_file_name, 'r', 'utf-8')\n            lines = f.readlines()\n\n            for line in lines:\n                try:\n                    if \"r_publish_date\" in line:\n                        p = re.compile(r\"<[^>]*?>\")\n                        kiji_date = p.sub(\"\", line)\n                        output_message = html_file_name.replace(\".txt\", \"\") + \"\\t\" + kiji_date.encode('utf-8')\n                        output_message_list.append(output_message)\n                except:\n                    pass\n\n        except:\n            pass\n\n\nfor message in output_message_list:\n    g = open(\"kiji_title_date_list.csv\", 'a')\n    g.write(message)\n    g.close()\n\n    \n#os.system('nkf -s --overwrite kiji_title_date_list.csv')\n```\n\n## **\uff16\uff0ecreate_kiji_title_honbun_list.py**\n\n```{Python:create_kiji_metadata_files.py}\n#!/usr/bin/enb python2.7\n# -*- coding: utf-8 -*-\n\n# \u3053\u306e\u30b9\u30af\u30ea\u30d7\u30c8\u30fb\u30d5\u30a1\u30a4\u30eb\u306f\u3001\u89e3\u6790\u95a2\u9023\u30c7\u30a3\u30ec\u30af\u30c8\u30ea\u306e\u30c8\u30c3\u30d7\u30c7\u30a3\u30ec\u30af\u30c8\u30ea\u306b\u683c\u7d0d\n# http://d.hatena.ne.jp/Tommy1/20131209/1386545113\n#  (1) \u307e\u305a\u6700\u521d\u306b\u3001\u5404\u9805\u76ee\u3054\u3068\u306b\u3001\u300c\u8a18\u4e8b\u540d\u300d\u30ea\u30b9\u30c8 \u3068 \u300c\u53d6\u5f97\u9805\u76ee\u300d\u30ea\u30b9\u30c8\u3092\u4f5c\u6210 \n#  (2) \u6b21\u306b\u3001\u5404\u9805\u76ee\u3054\u3068\u306b\u3001\u300c\u8a18\u4e8b\u540d\u300d-\u300c\u53d6\u5f97\u9805\u76ee\u300d\u306e\u30ab\u30e9\u30e0\u6570\uff12\u500b\u306e\u30c7\u30fc\u30bf\u30d5\u30ec\u30fc\u30e0\u3092\u4f5c\u6210\u3002http://d.hatena.ne.jp/dichika/20120819/1345385529\n#  (3) \u6b21\u306b\u3001\u5404\u9805\u76ee\u3054\u3068\u306b\u4f5c\u6210\u3057\u305f \u30c7\u30fc\u30bf\u30d5\u30ec\u30fc\u30e0\u3092\u3001\u300c\u8a18\u4e8b\u540d\u300d\u3092\u7d50\u5408\u30ad\u30fc\u306b\u3057\u3066\u3001pd.merge(df1, df2)\u3059\u308b\u3002\uff11\u3064\u3067\u3082\u9805\u76ee\u304c\u6b20\u3051\u305f\u8a18\u4e8b\u306f\u3001\u30de\u30fc\u30b8\u3057\u305f\u7d50\u679c\u306e\u30c7\u30fc\u30bf\u30d5\u30ec\u30fc\u30e0\u306b\u306f\u66f8\u304d\u51fa\u3055\u308c\u306a\u3044\uff08inner\u7d50\u5408\u306e\u5834\u5408\u3002outer\u7d50\u5408\u306e\u5834\u5408\u306f\u3001right / left\u5916\u90e8\u7d50\u5408\u53ef\u80fd\uff09\n#      \u306a\u304a\u3001\u30c7\u30fc\u30bf\u30d5\u30ec\u30fc\u30e0\u306a\u306e\u3067\u3001\u30c7\u30d5\u30a9\u30eb\u30c8\u3067\u3001\u884c\u540d\u306b\u3001index\u306e\u6570\u5024\u304c\u5272\u308a\u632f\u3089\u308c\u308b\u3002\uff0a\n# http://d.hatena.ne.jp/dichika/20120819/1345385529 \u30a4\u30f3\u30c7\u30c3\u30af\u30b9\u540d\u3092\u4efb\u610f\u306e\u6570\u5024\u3084\u6587\u5b57\u5217 \u6307\u5b9a\u3082\u53ef\u80fd\n# http://oceanmarine.sakura.ne.jp/sphinx/group/group_pandas.html#pandasseries,  http://everydayprog.blogspot.jp/2011_07_01_archive.html  \n#  (4) \u6700\u5f8c\u306b\u3001\u30c7\u30fc\u30bf\u30d5\u30ec\u30fc\u30e0\u3092\u30d5\u30a1\u30a4\u30eb\u51fa\u529b\u3059\u308b output_df.to_csv('output_file_name.csv', sep='\\t', header=True, index_label=True)\n#\n# \uff0a\u30ab\u30e9\u30e0\u5024\u306e\u91cd\u8907\u30c1\u30a7\u30c3\u30af http://blog.kzfmix.com/tag/pandas df.duplicated() \u91cd\u8907\u30ab\u30e9\u30e0\u5024\u306b True\u304c\u8fd4\u3055\u308c\u308b\n# \uff0a\u91cd\u8907\u30ab\u30e9\u30e0\u306e\u524a\u9664\uff08\uff11\u884c\u3060\u3051\u6b8b\u3059\uff09 df.drop_duplicates()\n\nimport re, codecs, os, csv\nimport pandas as pd\nfrom pandas import DataFrame\n\n#df_1: \u300c\u65b0\u805e\u793e\u540d\u3000\u8a18\u4e8b\u30bf\u30a4\u30c8\u30eb \u8a18\u4e8b\u30b9\u30af\u30ec\u30a4\u30d4\u30f3\u30b0\u6642\u523b \u8a18\u4e8b\u6587\u5b57\u6570\u300d\u3000\u60c5\u5831 \u53d6\u5f97\ndf_1 = pd.read_csv('kiji_metadata_file_1.csv', header=None, sep='\\t')\ndf_1.columns = ['newspaper_name', 'title', 'scraping_timestamp', 'moji_suu']\n\n\n#df_2: \u300c\u8a18\u4e8b\u30bf\u30a4\u30c8\u30eb\u3000\u8a18\u4e8b\u65b0\u805e\u793e\u30a6\u30a7\u30d6\u30b5\u30a4\u30c8\u63b2\u8f09\u5e74\u6708\u65e5\u300d \u60c5\u5831 \u53d6\u5f97\n\ndf_2 = pd.read_csv('./html_file/kiji_title_date_list.csv', header=None, sep='\\t')\ndf_2.columns = ['title', 'newsweb_posted_date']\n\n\n#=============================================================================================\n\n#df_3: \u300c\u8a18\u4e8b\u30bf\u30a4\u30c8\u30eb \u8a18\u4e8b\u6b04\u540d\u300d \u60c5\u5831 \u53d6\u5f97\n\nf = codecs.open(\"title_url_list_all_articles.txt\", 'r', 'utf-8')\nkiji_info_lines = f.readlines()\n\nurl_search_words = [\"/politics/\", \"/economy/\",\"/world/\", \"/affairs/\", \"/column/\", \"west\"]   \ncolumn_names = [u\"\u653f\u6cbb\u6b04\", u\"\u7d4c\u6e08\u6b04\", u\"\u56fd\u969b\u6b04\", u\"\u4e8b\u4ef6\u6b04\", u\"\u30b3\u30e9\u30e0\", u\"\u95a2\u897f\"]\n\n\nkiji_title_list = []\nkiji_category_list = []\n\nfor line in kiji_info_lines:\n    url_first_letter_location = int(line.find(\"http\"))\n    n = url_first_letter_location - 1\n\n    kiji_title = line[:n]\n    kiji_url = line[url_first_letter_location:]\n\n    \n    for i in range(0, len(column_names)):\n        if url_search_words[i] in kiji_url:\n            kiji_title = kiji_title.encode('utf-8') \n            kiji_title_list.append(kiji_title)            \n            kiji_category =  column_names[i].encode('utf-8') \n            kiji_category_list.append(kiji_category)\n        else:\n            pass\n\n\ndict_3 = {'title' : kiji_title_list, 'kiji_category' : kiji_category_list}\ndf_3 = DataFrame(dict_3)\ndf_3.columns = ['kiji_category', 'title']\n\ndel kiji_title_list\n\n#=============================================================================================\n\n#df_4: \u300c\u8a18\u4e8b\u30bf\u30a4\u30c8\u30eb \u8a18\u4e8b\u8a55\u70b9\u300d \u60c5\u5831 \u53d6\u5f97\ndf_4 = pd.read_csv('./kiji_honbun_textfile/kiji_scores.csv', header= None, sep='\\t')\ndf_4.columns = ['title', 'score']\n\n\n#==== \u5404DataFrame\u30aa\u30d6\u30b8\u30a7\u30af\u30c8\u306e\u7d50\u5408\uff08\u7d50\u5408\u5217: title)\n\nmerged_df = pd.merge(df_1, df_2, on = 'title', how = \"inner\")\n#merged_df.columns = [\"news_paper_name\", \"title\", \"scraping_timestamp\", \"moji_suu\", \"newsweb_posted_date\"]\n#merged_df_2 = pd.merge(meged_df_1, df_3, on = 'title', how = \"inner\")\n#merged_df_2 = pd.merge(meged_df_1, df_4, on = 'title', how = \"inner\")  \n\n# score\u5217\u306e\u5024\u3067\u964d\u9806\u30bd\u30fc\u30c8\ndf_4 = df_4.sort(columns=\"score\", ascending=False)\n\n#==== \u6700\u5f8c\u306b\u307e\u3068\u3081\u3066\u3001\u30d5\u30a1\u30a4\u30eb\u51fa\u529b\n\n#print(merged_df)\n#print(df_3)\n#print(df_4)\n\nmerged_df.to_csv(\"./meta_data_file/\u65b0\u805e\u793e\u540d-\u8a18\u4e8b\u30bf\u30a4\u30c8\u30eb-\u8a18\u4e8b\u30b9\u30af\u30ec\u30a4\u30d4\u30f3\u30b0\u6642\u523b-\u8a18\u4e8b\u6587\u5b57\u6570-\u30a6\u30a7\u30d6\u30b5\u30a4\u30c8\u8a18\u4e8b\u63b2\u8f09\u5e74\u6708\u65e5.csv\", sep='\\t', header=True, index_label=\"number\")\ndf_3.to_csv(\"./meta_data_file/\u8a18\u4e8b\u30bf\u30a4\u30c8\u30eb-\u8a18\u4e8b\u6b04\u540d.csv\", sep='\\t', header=True, index=False)\ndf_4.to_csv(\"./meta_data_file/\u8a18\u4e8b\u30bf\u30a4\u30c8\u30eb \u8a18\u4e8b\u8a55\u70b9.csv\", sep='\\t', header=True, index=False)\n\n\n#merged_df.to_csv(\"./meta_data_file/shiftjis/\u65b0\u805e\u793e\u540d-\u8a18\u4e8b\u30bf\u30a4\u30c8\u30eb-\u8a18\u4e8b\u30b9\u30af\u30ec\u30a4\u30d4\u30f3\u30b0\u6642\u523b-\u8a18\u4e8b\u6587\u5b57\u6570-\u30a6\u30a7\u30d6\u30b5\u30a4\u30c8\u8a18\u4e8b\u63b2\u8f09\u5e74\u6708\u65e5.csv\", sep='\\t', header=True, index_label=\"number\")\n#df_3.to_csv(\"./meta_data_file/shiftjis/\u8a18\u4e8b\u30bf\u30a4\u30c8\u30eb-\u8a18\u4e8b\u6b04\u540d.csv\", sep='\\t', header=True, index=False)\n#df_4.to_csv(\"./meta_data_file/shiftjis/\u8a18\u4e8b\u30bf\u30a4\u30c8\u30eb \u8a18\u4e8b\u8a55\u70b9.csv\", sep='\\t', header=True, index=False)\n\n#os.system('nkf -s  --overwrite ./meta_data_file/shiftjis/*.csv') \n```\n\n\n```{Python:create_kiji_title_honbun_list.py}\n#!/usr/bin/env/python2.7                                                       \n# -*- coding: utf-8 -*-  \n\nimport os, codecs\n\nfile_names = os.listdir(os.getcwd())\n\nfor file_name in file_names:\n     if (\"txt\" in file_name) and (\"word\" not in file_name) and (\"kiji_title_honbun_list.txt\" != file_name) and (\"score\" not in file_name):\n         try:\n              f = codecs.open(file_name, 'r','utf-8')\n          \n              kiji_honbun = f.read()\n              kiji_title = file_name\n              \n              one_kiji_file_output = kiji_title + \"\u3000\uff1a\u3000\" + kiji_honbun.encode('utf-8')  +\"\\n\"\n              \n              g = open(\"kiji_title_honbun_list.txt\", \"a\")\n              g.write(one_kiji_file_output)\n              g.close()\n         except:\n              pass\n\n#os.system('nkf -s  --overwrite sjis_kiji_title_honbun_list.txt')\n```\n     \n___\n\n# \u5b9f\u884c\n\n#### **\uff08\u5de5\u7a0b \uff11\uff09 \u30af\u30ed\u30a6\u30ea\u30f3\u30b0\u5bfe\u8c61\u8a18\u4e8b \u306e_URL_\u30fb\u8a18\u4e8b\u30bf\u30a4\u30c8\u30eb \u4e00\u89a7\u30ea\u30b9\u30c8 \u751f\u6210**\n\n##### **title_url_list_all_articles.txt** \u3092\u5b9f\u884c\n\n![pic_1.png](https://qiita-image-store.s3.amazonaws.com/0/43487/adac772d-a2ac-f2c5-6fa8-d58c70f4ca64.png)\n\n![pic_2.png](https://qiita-image-store.s3.amazonaws.com/0/43487/70540b8c-b37f-79fb-ba03-0cb3b264036d.png)\n\n##### **\u4ee5\u4e0b\u306e\u30c6\u30ad\u30b9\u30c8\u30d5\u30a1\u30a4\u30eb\u304c\u751f\u6210\u3055\u308c\u307e\u3059**\n\n* **title_url_list_all_articles.txt**\n\n![pic_3.png](https://qiita-image-store.s3.amazonaws.com/0/43487/ddce1ec5-bf72-ef06-cb4d-aca04e5663fd.png)\n\n##### **\u4e2d\u8eab\u3092\u958b\u304f\u3068\u3001\u8a18\u4e8b\u30bf\u30a4\u30c8\u30eb \u3068 \u63b2\u8f09_URL_ \u306e\u4e00\u89a7\u304c\u51fa\u529b\u3055\u308c\u3066\u3044\u307e\u3059**\n\n![pic_4.png](https://qiita-image-store.s3.amazonaws.com/0/43487/445cee14-d9c6-0964-71a6-d12d359fc6ac.png)\n\n#### \uff08\u5de5\u7a0b\uff12 \u6e96\u5099\uff09\n**\u5de5\u7a0b\uff12 \u3067\u751f\u6210\u3055\u308c\u308b\u30d5\u30a1\u30a4\u30eb\u306e\u683c\u7d0d\u5148\u30c7\u30a3\u30ec\u30af\u30c8\u30ea\u3092\u7528\u610f**\n\n* html_file \u30c7\u30a3\u30ec\u30af\u30c8\u30ea\n* kiji_honbun_textfile \u30c7\u30a3\u30ec\u30af\u30c8\u30ea\n\n![pic_5.png](https://qiita-image-store.s3.amazonaws.com/0/43487/723c04e0-ca2b-461f-a3d8-759d919d6d33.png)\n\n![pic_6.png](https://qiita-image-store.s3.amazonaws.com/0/43487/e62b29c8-57a5-aa85-1b5f-fdb895894e25.png)\n\n#### **\uff08\u5de5\u7a0b \uff12\uff09 \u5404\u8a18\u4e8b _URL_ \u306b\u30a2\u30af\u30bb\u30b9\u3057\u3066\u3001_html_\u30d5\u30a1\u30a4\u30eb \u3068 \u8a18\u4e8b\u672c\u6587\u30c6\u30ad\u30b9\u30c8\u30fb\u30d5\u30a1\u30a4\u30eb\u751f\u6210**\n\n##### **create_kiji_honbun_textfile_htmlfile.py** \u3092\u5b9f\u884c\n\n##### \u30a8\u30e9\u30fc\u30e1\u30c3\u30bb\u30fc\u30b8\u304c\u3044\u304f\u3064\u304b\u51fa\u305f\u5f8c\u3001\u5b9f\u884c\u7d42\u4e86\n\n![pic_7.png](https://qiita-image-store.s3.amazonaws.com/0/43487/1cec9766-e148-dafc-880a-f0454430fe18.png)\n\n##### **html_file \u30c7\u30a3\u30ec\u30af\u30c8\u30ea\u306b\u3001\u30ea\u30b9\u30c8\u4e00\u89a7\u4e2d\u306e\u5168\u8a18\u4e8b\u306e_html_\u30d5\u30a1\u30a4\u30eb\u304c\u751f\u6210\u3055\u308c\u3066\u3044\u307e\u3059**\n###### **\uff08 \u8a18\u4e8b\u672c\u6570\u5206\u3001610 \u4ef6\u306e _html_ \u30d5\u30a1\u30a4\u30eb\u304c\u751f\u6210\u3055\u308c\u305f \uff09**\n![pic_8.png](https://qiita-image-store.s3.amazonaws.com/0/43487/549a23b0-ba32-8217-ce4e-5599411236bb.png)\n\n##### **kiji_honbun_textfile \u30c7\u30a3\u30ec\u30af\u30c8\u30ea\u306b\u3001\u30ea\u30b9\u30c8\u4e00\u89a7\u4e2d\u306e\u5168\u8a18\u4e8b\u306e\u8a18\u4e8b\u672c\u6587\u30c6\u30ad\u30b9\u30c8\u30d5\u30a1\u30a4\u30eb\u304c\u751f\u6210\u3055\u308c\u3066\u3044\u307e\u3059**\n###### **\uff08 \u8a18\u4e8b\u672c\u6570\u5206\u3001610 \u4ef6\u306e \u8a18\u4e8b\u672c\u6587\u30c6\u30ad\u30b9\u30c8\u30fb\u30d5\u30a1\u30a4\u30eb\u304c\u751f\u6210\u3055\u308c\u305f \uff09**\n![pic_9.png](https://qiita-image-store.s3.amazonaws.com/0/43487/40f50c3a-26aa-5a9d-90ef-71744b4b2b5d.png)\n\n\n##### **\uff08 _html_ \u30d5\u30a1\u30a4\u30eb\u306e\u4e2d\u8eab )**\n\n![pic_10.png](https://qiita-image-store.s3.amazonaws.com/0/43487/bc45ef98-fe55-687e-b27e-c6c7cbfaa6f7.png)\n\n\n![pic_11.png](https://qiita-image-store.s3.amazonaws.com/0/43487/8cdf92e8-114a-aef7-6786-ccded2b97860.png)\n\n##### **\uff08 \u8a18\u4e8b\u672c\u6587\u30c6\u30ad\u30b9\u30c8\u30fb\u30d5\u30a1\u30a4\u30eb \u306e\u4e2d\u8eab )**\n\n![pic_12.png](https://qiita-image-store.s3.amazonaws.com/0/43487/11fac817-10c7-7cf5-e344-29c07232c291.png)\n\n##### **\uff08 _kiji_metadata_file_1.csv_ \u30d5\u30a1\u30a4\u30eb \u306e\u4e2d\u8eab\uff09**\n\n![pic_13.png](https://qiita-image-store.s3.amazonaws.com/0/43487/6896754a-fd84-9d32-d0f8-d9d42eb0a94b.png)\n\n\n#### **\uff08\u5de5\u7a0b \uff13\uff09 \u5404\u8a18\u4e8b \u672c\u6587\u30c6\u30ad\u30b9\u30c8\u30d5\u30a1\u30a4\u30eb \u3092\u4fc2\u308a\u53d7\u3051\u5206\u89e3\u5b9f\u884c**\n\n##### **get_kakariuke_wordpairs.rb** \u3092\u5b9f\u884c\n\n![pic_14.png](https://qiita-image-store.s3.amazonaws.com/0/43487/600a615e-5f1b-90bf-73b3-7ca5d4947e93.png)\n\n##### **\uff08 \u8a18\u4e8b\u672c\u6570\u5206\u3001610 \u4ef6\u306e\u4fc2\u308a\u53d7\u3051\u7d50\u679c\u30d5\u30a1\u30a4\u30eb\u304c\u751f\u6210\u3055\u308c\u305f \uff09**\n\n![pic_15.png](https://qiita-image-store.s3.amazonaws.com/0/43487/53827b64-79c2-9ab0-ed95-b975038ac031.png)\n\n##### **_word_pairs_ \u3067\u59cb\u307e\u308b\u30d5\u30a1\u30a4\u30eb\u304c\u3001\u751f\u6210\u3055\u308c\u305f\u30d5\u30a1\u30a4\u30eb\u3067\u3059**\n\n![pic_16.png](https://qiita-image-store.s3.amazonaws.com/0/43487/a788bfb6-51c6-8952-1a74-575eed7da4df.png)\n\n##### **\uff08 \u4e2d\u8eab\u3092\u958b\u3044\u3066\u307f\u308b \uff09**\n\n![pic_17.png](https://qiita-image-store.s3.amazonaws.com/0/43487/0195f921-b613-ea79-538e-8663da761802.png)\n\n\n#### **\uff08\u5de5\u7a0b \uff14\uff09 \u6307\u5b9a\u3057\u305f\u300c\u4e3b\u8a9e\u30d5\u30ec\u30fc\u30ba => \u8ff0\u8a9e\u30d5\u30ec\u30fc\u30ba\u300d\u306e\u691c\u51fa\u56de\u6570 \u96c6\u8a08\u3092\u5b9f\u884c**\n\n\n\u4eca\u56de\u306f\u3001\uff08\u4e3b\u8a9e \u8a9e\u53e5\uff09\u300c _List 1_ \u306e\u3046\u3061\u3001\u3044\u305a\u308c\u304b\u306e\u5358\u8a9e \u300d ==>>\uff08\u8ff0\u8a9e \u8a9e\u53e5\uff09 \u300c _List 2_ \u306e\u3046\u3061\u3001\u3044\u305a\u308c\u304b\u306e\u5358\u8a9e \u300d\n\u306b\u8a72\u5f53\u3059\u308b \u4fc2\u308a\u53d7\u3051\u30da\u30a2 \u6587 \u3092 \u5168\u4fc2\u308a\u53d7\u3051\u8a9e\u53e5\u30da\u30a2\u4e00\u89a7\u30ea\u30b9\u30c8 \u306e\u306a\u304b\u304b\u3089\u3001\u691c\u51fa\u3057\u3066\u307f\u307e\u3059\u3002\n\n1. **_List 1_ : \u4fc2\u308a\u53d7\u3051\u5143 \u5358\u8a9e\u30ea\u30b9\u30c8**\n\t\"TPP\", \"JA\u5168\u4e2d\", \"\u8fb2\u696d\u56e3\u4f53\", \"\u81ea\u6c11\u515a\", \"\u9996\u5e2d\u4ea4\u6e09\u5b98\", \"USTR\"\n\n2. **_List 2_ : \u4fc2\u308a\u53d7\u3051\u5148 \u5358\u8a9e\u30ea\u30b9\u30c8**\n\t\"\u5206\u304b\u3063\u305f\", \"\u5224\u660e\", \"\u8abf\u6574\", \"\u4ea4\u6e09\", \"\u59a5\u7d50\", \"\u5354\u8b70\", \"\u7d99\u7d9a\", \"\u6301\u3061\u8d8a\u3057\", \"\u59a5\u5354\", \"\u767a\u8868\"\n\n##### **matched_wordpairs_counter.py** \u3092\u5b9f\u884c\n\n![pic_18.png](https://qiita-image-store.s3.amazonaws.com/0/43487/b2621753-e449-5d39-65fb-f54cbdfdfd5f.png)\n\n##### **\u4ee5\u4e0b\u306e\u30d5\u30a1\u30a4\u30eb\u304c\u3001\u751f\u6210\u3055\u308c\u307e\u3059**\n* kiji_evaluation_result.csv\n* kiji_scores.csv\n\n![pic_19.png](https://qiita-image-store.s3.amazonaws.com/0/43487/c99e398a-8599-68dd-977e-ed49f21dc736.png)\n\n### **\u4eca\u56de\u53ce\u96c6\u3057\u305f\u8a18\u4e8b\u306e\u306a\u304b\u304b\u3089\u3001\u6307\u5b9a\u3057\u305f\u300c\u4fc2\u308a\u53d7\u3051\u5143=>\u5148 \u8a9e\u53e5\u30da\u30a2\u300d\u3092\u691c\u51fa\u3057\u305f\u3068\u3053\u308d\u3001\u30d2\u30c3\u30c8\u3057\u305f\u306e\u306f\u4ee5\u4e0b\u306e\uff11\u4ef6\u3060\u3051\u3067\u3057\u305f**\n\n##### **\uff08 kiji_evaluation_result.csv\u3000\u30d5\u30a1\u30a4\u30eb \u306e\u4e2d\u8eab \uff09**\n\n\n![pic_20.png](https://qiita-image-store.s3.amazonaws.com/0/43487/302bc052-d9ff-f62e-caa3-c631304da5af.png)\n\n##### **\uff08 kiji_scores.csv \u30d5\u30a1\u30a4\u30eb \u306e\u4e2d\u8eab\uff09**\n![pic_21.png](https://qiita-image-store.s3.amazonaws.com/0/43487/f7a5294e-eace-6a4b-e5af-ec07dcc43881.png)\n\n\n\n#### **\uff08\u5de5\u7a0b \uff15\uff09  \u8a18\u4e8b \u5c5e\u6027\u30c7\u30fc\u30bf\u4e00\u89a7\u30d5\u30a1\u30a4\u30eb \u751f\u6210\u2460 (\u300c\u8a18\u4e8b\u30bf\u30a4\u30c8\u30eb\uff11 - \u8a18\u4e8b\u306e\u65b0\u805e\u793e\u30b5\u30a4\u30c8\u63b2\u8f09\u5e74\u6708\u65e5\u300d \u30ea\u30b9\u30c8\u30d5\u30a1\u30a4\u30eb\u51fa\u529b\uff09**\n\n##### **create_article_website_posted_date_list.py** \u3092\u5b9f\u884c\n\n##### **\u4ee5\u4e0b\u306e\u30d5\u30a1\u30a4\u30eb\u304c\u751f\u6210\u3055\u308c\u307e\u3059**\n* kiji_title_date_list.csv\n\n![pic_22.png](https://qiita-image-store.s3.amazonaws.com/0/43487/5acc2e2f-0924-becb-26fc-d65c52f81a2c.png)\n\n###### **\uff08 kiji_title_date_list.csv \u30d5\u30a1\u30a4\u30eb \u306e\u4e2d\u8eab \uff09**\n\n![pic_23.png](https://qiita-image-store.s3.amazonaws.com/0/43487/1691ce5f-5428-a272-9b60-09deb25e884f.png)\n\n#### **\uff08\u5de5\u7a0b \uff16\u3000\u6e96\u5099\uff09  meta_data_file \u30c7\u30a3\u30ec\u30af\u30c8\u30ea \u3092\u4f5c\u6210**\n\n![pic_24.png](https://qiita-image-store.s3.amazonaws.com/0/43487/1f6ca71f-e01f-a4a5-98f0-2cf2ed1f145e.png)\n\n#### **\uff08\u5de5\u7a0b \uff16\uff09  \u8a18\u4e8b \u5c5e\u6027\u30c7\u30fc\u30bf\u4e00\u89a7\u30d5\u30a1\u30a4\u30eb \u751f\u6210\u2460 \uff08\u4ee5\u4e0b\u306e\u4e00\u89a7\u30d5\u30a1\u30a4\u30eb\u3092\u751f\u6210\uff09**\n\n##### **create_kiji_metadata_files.py** \u3092\u5b9f\u884c\n\n![pic_25.png](https://qiita-image-store.s3.amazonaws.com/0/43487/47ab60b4-9dd3-080e-b8e5-5939b504669f.png)\n\n##### **\u4ee5\u4e0b\u306e\u30d5\u30a1\u30a4\u30eb\u304c\u751f\u6210\u3055\u308c\u307e\u3059**\n* \u8a18\u4e8b\u30bf\u30a4\u30c8\u30eb_\u8a18\u4e8b\u8a55\u70b9.csv\n* \u8a18\u4e8b\u30bf\u30a4\u30c8\u30eb\u30fb\u8a18\u4e8b\u6b04\u540d.csv\n* \u65b0\u805e\u793e\u540d\u30fb\u8a18\u4e8b\u30bf\u30a4\u30c8\u30eb\u30fb\u8a18\u4e8b\u30b9\u30af\u30ec\u30a4\u30d4\u30f3\u30b0\u6642\u523b\u30fb\u671f\uff4a\u6587\u5b57\u6570\u30fb\u30a6\u30a7\u30d6\u30b5\u30a4\u30c8\u8a18\u4e8b\u63b2\u8f09\u5e74\u6708\u65e5.csv\n\n![pic_26.png](https://qiita-image-store.s3.amazonaws.com/0/43487/4462b7b3-f39f-e269-709b-80fcfcec4bba.png)\n\n##### **\uff08 \u5404\u30d5\u30a1\u30a4\u30eb\u306e\u51fa\u529b\u884c\u6570\u3092\u78ba\u8a8d \uff09**\n\n![pic_27.png](https://qiita-image-store.s3.amazonaws.com/0/43487/9c1fd935-41c4-a1ff-3190-1e747055e871.png)\n\n##### **\uff08 \u8a18\u4e8b\u30bf\u30a4\u30c8\u30eb_\u8a18\u4e8b\u8a55\u70b9.csv\u3000\u30d5\u30a1\u30a4\u30eb \u306e\u4e2d\u8eab \uff09**\n\n![pic_28.png](https://qiita-image-store.s3.amazonaws.com/0/43487/921a797c-ab54-daaf-4137-7f0a44cd48c0.png)\n\n##### **\uff08 \u8a18\u4e8b\u30bf\u30a4\u30c8\u30eb\u30fb\u8a18\u4e8b\u6b04\u540d.csv\u3000\u30d5\u30a1\u30a4\u30eb \u306e\u4e2d\u8eab \uff09**\n![pic_29.png](https://qiita-image-store.s3.amazonaws.com/0/43487/8aab7965-df02-feee-9e65-7ef36b975c03.png)\n\n##### **\uff08 \u65b0\u805e\u793e\u540d\u30fb\u8a18\u4e8b\u30bf\u30a4\u30c8\u30eb\u30fb\u8a18\u4e8b\u30b9\u30af\u30ec\u30a4\u30d4\u30f3\u30b0\u6642\u523b\u30fb\u671f\uff4a\u6587\u5b57\u6570\u30fb\u30a6\u30a7\u30d6\u30b5\u30a4\u30c8\u8a18\u4e8b\u63b2\u8f09\u5e74\u6708\u65e5.csv \u30d5\u30a1\u30a4\u30eb \u306e\u4e2d\u8eab \uff09**\n![pic_30.png](https://qiita-image-store.s3.amazonaws.com/0/43487/d39bdcfa-8f60-59e9-2dd9-5440824a4923.png)\n\n\n#### **\uff08\u5de5\u7a0b \uff17\uff09 \u8a18\u4e8b\u30bf\u30a4\u30c8\u30eb - \u8a18\u4e8b\u672c\u6587 \u306e\u4e00\u89a7\u30d5\u30a1\u30a4\u30eb \u751f\u6210**\n\n##### **create_kiji_title_honbun_list.py** \u3092\u5b9f\u884c\n\n##### **\u4ee5\u4e0b\u306e\u30d5\u30a1\u30a4\u30eb\u304c\u751f\u6210\u3055\u308c\u307e\u3059**\n* kiji_title_honbun_list.txt\n\n![pic_31.png](https://qiita-image-store.s3.amazonaws.com/0/43487/1404e2f9-6a86-6a2d-8d56-173c16f604de.png)\n\n##### **\uff08 kiji_title_honbun_list.txt \u30d5\u30a1\u30a4\u30eb \u306e\u4e2d\u8eab \uff09**\n\n![pic_32.png](https://qiita-image-store.s3.amazonaws.com/0/43487/915e2d2c-65f0-170c-97b1-3a42297b4efa.png)\n", "tags": ["\u30b9\u30af\u30ec\u30a4\u30d4\u30f3\u30b0", "Python", "NLP", "\u81ea\u7136\u8a00\u8a9e\u51e6\u7406"]}