{"context": "\u3042\u308a\u305d\u3046\u3067\u7121\u304b\u3063\u305f\u306e\u3067\u8a18\u4e8b\u306b\u3057\u3066\u307f\u305f\u3002\n4\u6b21\u5143\u306e\u7279\u5fb4\u91cf\u3092\u6301\u3064\u30c7\u30fc\u30bf\u304c6\u3064\u3042\u3063\u305f\u3068\u3059\u308b\u3002\n\nsample.csv\n1,2,3,4\n1,2,3,5\n1,2,4,5\n4,3,2,1\n5,3,2,1\n5,4,2,1\n\n\n\u3053\u308c\u3092K-means\u306b\u3088\u308a\u30af\u30e9\u30b9\u30bf\u30ea\u30f3\u30b0\u3057\u305f\u4e0a\u3067\u3001PCA\u3067\u6b21\u5143\u524a\u6e1b\u3057\u3066\u6563\u5e03\u56f3\u306b\u30d7\u30ed\u30c3\u30c8\u3059\u308b\u3002\nK-means\u306e\u30c9\u30ad\u30e5\u30e1\u30f3\u30c8\u306f\u3053\u3053\u3001PCA\u306e\u30c9\u30ad\u30e5\u30e1\u30f3\u30c8\u306f\u3053\u3053\u3001pyplot\u306e\u30c9\u30ad\u30e5\u30e1\u30f3\u30c8\u306f\u3053\u3053\u3002\n\nsample.py\n# -*- coding: UTF-8 -*-\nimport numpy as np\nfrom sklearn.cluster import KMeans\nfrom sklearn.decomposition import PCA\nimport matplotlib.pyplot as plt\n\n# sample.csv\u3092\u8aad\u307f\u8fbc\u3080\nusers = np.loadtxt('./sample.csv', delimiter=\",\")\n\n# K-means\u306b\u3088\u308b\u30af\u30e9\u30b9\u30bf\u30ea\u30f3\u30b0\nmodel = KMeans(n_clusters=2).fit(users)\n\n# PCA\u3067\u6b21\u5143\u524a\u6e1b\npca = PCA(n_components=2)\nusers_r = pca.fit_transform(users)\n\n# \u7d50\u679c\u3092\u6563\u5e03\u56f3\u306b\u30d7\u30ed\u30c3\u30c8\nplt.figure()\nfor (i, label) in enumerate(model.labels_):\n    if label == 0:\n        plt.scatter(users_r[i, 0], users_r[i, 1], c='red')\n    elif label == 1:\n        plt.scatter(users_r[i, 0], users_r[i, 1], c='blue')\nplt.show()\n\n\n\u6b21\u306e\u3088\u3046\u306a\u6563\u5e03\u56f3\u304c\u5f97\u3089\u308c\u308b\u3002\n\n\u3042\u308a\u305d\u3046\u3067\u7121\u304b\u3063\u305f\u306e\u3067\u8a18\u4e8b\u306b\u3057\u3066\u307f\u305f\u3002\n4\u6b21\u5143\u306e\u7279\u5fb4\u91cf\u3092\u6301\u3064\u30c7\u30fc\u30bf\u304c6\u3064\u3042\u3063\u305f\u3068\u3059\u308b\u3002\n\n```sample.csv\n1,2,3,4\n1,2,3,5\n1,2,4,5\n4,3,2,1\n5,3,2,1\n5,4,2,1\n```\n\n\u3053\u308c\u3092K-means\u306b\u3088\u308a\u30af\u30e9\u30b9\u30bf\u30ea\u30f3\u30b0\u3057\u305f\u4e0a\u3067\u3001PCA\u3067\u6b21\u5143\u524a\u6e1b\u3057\u3066\u6563\u5e03\u56f3\u306b\u30d7\u30ed\u30c3\u30c8\u3059\u308b\u3002\nK-means\u306e\u30c9\u30ad\u30e5\u30e1\u30f3\u30c8\u306f[\u3053\u3053](http://scikit-learn.org/stable/modules/generated/sklearn.cluster.KMeans.html)\u3001PCA\u306e\u30c9\u30ad\u30e5\u30e1\u30f3\u30c8\u306f[\u3053\u3053](http://scikit-learn.org/stable/modules/generated/sklearn.decomposition.PCA.html)\u3001pyplot\u306e\u30c9\u30ad\u30e5\u30e1\u30f3\u30c8\u306f[\u3053\u3053](http://matplotlib.org/users/pyplot_tutorial.html)\u3002\n\n```sample.py\n# -*- coding: UTF-8 -*-\nimport numpy as np\nfrom sklearn.cluster import KMeans\nfrom sklearn.decomposition import PCA\nimport matplotlib.pyplot as plt\n\n# sample.csv\u3092\u8aad\u307f\u8fbc\u3080\nusers = np.loadtxt('./sample.csv', delimiter=\",\")\n\n# K-means\u306b\u3088\u308b\u30af\u30e9\u30b9\u30bf\u30ea\u30f3\u30b0\nmodel = KMeans(n_clusters=2).fit(users)\n\n# PCA\u3067\u6b21\u5143\u524a\u6e1b\npca = PCA(n_components=2)\nusers_r = pca.fit_transform(users)\n\n# \u7d50\u679c\u3092\u6563\u5e03\u56f3\u306b\u30d7\u30ed\u30c3\u30c8\nplt.figure()\nfor (i, label) in enumerate(model.labels_):\n    if label == 0:\n        plt.scatter(users_r[i, 0], users_r[i, 1], c='red')\n    elif label == 1:\n        plt.scatter(users_r[i, 0], users_r[i, 1], c='blue')\nplt.show()\n```\n\n\u6b21\u306e\u3088\u3046\u306a\u6563\u5e03\u56f3\u304c\u5f97\u3089\u308c\u308b\u3002\n![figure_1.png](https://qiita-image-store.s3.amazonaws.com/0/127582/c15a0fd0-2ec9-7d29-19a4-3b650d5661d5.png)\n", "tags": ["Python", "scikit-learn", "\u30c7\u30fc\u30bf\u5206\u6790"]}