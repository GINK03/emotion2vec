{"context": " More than 1 year has passed since last update.\n\n\u3053\u306e\u30b7\u30ea\u30fc\u30ba\n\nSpark on Docker\u3067\u5206\u6563\u578b\u6a5f\u68b0\u5b66\u7fd2\u3092\u59cb\u3081\u308b - Part 1: \u30a4\u30f3\u30b9\u30c8\u30fc\u30eb\nSpark on Docker\u3067\u5206\u6563\u578b\u6a5f\u68b0\u5b66\u7fd2\u3092\u59cb\u3081\u308b - Part 2: Ubuntu\u3067IPython Notebook\u3092\u4f7f\u3046\nSpark on Docker\u3067\u5206\u6563\u578b\u6a5f\u68b0\u5b66\u7fd2\u3092\u59cb\u3081\u308b - Part 3: \u30ed\u30fc\u30ab\u30eb\u30e2\u30fc\u30c9\u3067spark-shell\u3092\u8d77\u52d5\u3059\u308b\nSpark on Docker\u3067\u5206\u6563\u578b\u6a5f\u68b0\u5b66\u7fd2\u3092\u59cb\u3081\u308b - Part 4: Ambari\u3067Hadoop\u3068Spark\u306esingle node\u30bb\u30c3\u30c8\u30a2\u30c3\u30d7\n\n\n\u3000\u524d\u56de\u306e\u30bb\u30c3\u30c8\u30a2\u30c3\u30d7\u304b\u3089Spark\u306e\u30d0\u30fc\u30b8\u30e7\u30f3\u3082\u4e0a\u304c\u3063\u3066\u3044\u308b\u306e\u3067\u65b0\u3057\u3044\u74b0\u5883\u3092\u7528\u610f\u3057\u307e\u3059\u3002\u4eca\u56de\u306f1\u3064\u306eJVM\u4e0a\u3067\u52d5\u4f5c\u3059\u308b\u30ed\u30fc\u30ab\u30eb\u30e2\u30fc\u30c9\u3092\u30bb\u30c3\u30c8\u30a2\u30c3\u30d7\u3057\u307e\u3059\u3002\u30c7\u30b9\u30af\u30c8\u30c3\u30d7\u30e2\u30fc\u30c9\u3068\u3082\u547c\u3070\u308c\u307e\u3059\u304c\u3001spark-shell\u3092\u4f7f\u3063\u305f\u30c6\u30b9\u30c8\u3084\u30b5\u30f3\u30d7\u30eb\u30b3\u30fc\u30c9\u306e\u5b9f\u884c\u7528\u306b\u624b\u8efd\u306b\u4f7f\u3046\u3053\u3068\u304c\u3067\u304d\u307e\u3059\u3002\n\nDockerfile\n\u3000\u3069\u306e\u74b0\u5883\u3067\u3082\u52d5\u4f5c\u3059\u308b\u3088\u3046\u306bDockerfile\u306b\u307e\u3068\u3081\u3066\u30a4\u30e1\u30fc\u30b8\u3092\u4f5c\u6210\u3057\u307e\u3059\u3002\n\nDockerfile\nFROM java:openjdk-7-jdk\n\nRUN curl -s http://ftp.jaist.ac.jp/pub/apache/spark/spark-1.5.1/spark-1.5.1-bin-hadoop2.6.tgz | tar -xz -C /usr/local/\nRUN cd /usr/local && ln -s spark-1.5.1-bin-hadoop2.6 spark\n\nWORKDIR /usr/local/spark\nRUN cd conf && cp log4j.properties.template log4j.properties && \\\n    sed -i 's/log4j.rootCategory=INFO/log4j.rootCategory=WARN/' log4j.properties\n\nCMD [\"/bin/bash\"]\n\n\nDocker\u30a4\u30e1\u30fc\u30b8\u3092\u30d3\u30eb\u30c9\u3057\u3066\u30b3\u30f3\u30c6\u30ca\u3092\u5b9f\u884c\u3057\u307e\u3059\u3002\u300clocal[N]\u300d\u306eN\u306f\u5b9f\u884c\u3059\u308b\u30b9\u30ec\u30c3\u30c9\u6570\u3067\u3059\u3002\u300c*\u300d\u3092\u6307\u5b9a\u3059\u308b\u3068\u5229\u7528\u3067\u304d\u308bCPU\u306e\u30b3\u30a2\u6570\u3092\u4f7f\u3044\u307e\u3059\u3002\n$ docker build -t spark-local .\n$ docker run --rm -it spark-local\n$ ./bin/spark-shell --master local[*]\n15/11/29 16:35:07 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\nWelcome to\n      ____              __\n     / __/__  ___ _____/ /__\n    _\\ \\/ _ \\/ _ `/ __/  '_/\n   /___/ .__/\\_,_/_/ /_/\\_\\   version 1.5.2\n      /_/\n\nUsing Scala version 2.10.4 (OpenJDK 64-Bit Server VM, Java 1.7.0_91)\nType in expressions to have them evaluated.\nType :help for more information.\n15/11/29 16:35:18 WARN MetricsSystem: Using default name DAGScheduler for source because spark.app.id is not set.\nSpark context available as sc.\n15/11/29 16:35:23 WARN Connection: BoneCP specified but not present in CLASSPATH (or one of dependencies)\n15/11/29 16:35:24 WARN Connection: BoneCP specified but not present in CLASSPATH (or one of dependencies)\n (or one of dependencies)\n15/11/29 16:35:33 WARN ObjectStore: Version information not found in metastore. hive.metastore.schema.verification is not enabled so recording the schema version 1.2.0\n15/11/29 16:35:33 WARN ObjectStore: Failed to get database default, returning NoSuchObjectException\n15/11/29 16:35:37 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n15/11/29 16:35:39 WARN Connection: BoneCP specified but not present in CLASSPATH (or one of dependencies)\n15/11/29 16:35:39 WARN Connection: BoneCP specified but not present in CLASSPATH (or one of dependencies)\n15/11/29 16:35:46 WARN ObjectStore: Version information not found in metastore. hive.metastore.schema.verification is not enabled so recording the schema version 1.2.0\n15/11/29 16:35:47 WARN ObjectStore: Failed to get database default, returning NoSuchObjectException\nSQL context available as sqlContext.\n\nscala>\n\n\u3000log4j.properties\u306erootCategory\u3092WARN\u306b\u3057\u3066\u3044\u307e\u3059\u304c\u305d\u308c\u3067\u3082\u30ed\u30b0\u304c\u305f\u304f\u3055\u3093\u8868\u793a\u3055\u308c\u307e\u3059\u3002\n\u3000spark-shell\u306e\u52d5\u4f5c\u78ba\u8a8d\u3068\u3057\u3066\u300cLISCENSE\u300d\u30d5\u30a1\u30a4\u30eb\u306e\u884c\u6570\u3092\u30ab\u30a6\u30f3\u30c8\u3059\u308b\u7c21\u5358\u306a\u30b3\u30fc\u30c9\u3092\u5b9f\u884c\u3057\u3066\u307f\u307e\u3059\u3002\u307e\u305f\u300cSpark\u300d\u3068\u3044\u3046\u6587\u5b57\u3092\u542b\u3080\u884c\u6570\u3092\u30ab\u30a6\u30f3\u30c8\u3057\u3066\u6a19\u6e96\u51fa\u529b\u3057\u307e\u3059\u3002\nscala> val lines = sc.textFile(\"LICENSE\")\nlines: org.apache.spark.rdd.RDD[String] = MapPartitionsRDD[1] at textFile at <console>:21\n\nscala> val count = lines.count\ncount: Long = 294\n\nscala> val sparks = lines.filter(line => line.contains(\"Spark\"))\nsparks: org.apache.spark.rdd.RDD[String] = MapPartitionsRDD[8] at filter at <console>:23\n\nscala> sparks.count\nres7: Long = 3\n\nscala> sparks.foreach(println)\nApache Spark Subcomponents:\nThe Apache Spark project contains subcomponents with separate copyright\n        except for Main.Scala, SparkHelper.scala and ExecutorClassLoader.scala),\n\n\u3000\u30d5\u30a1\u30a4\u30eb\u64cd\u4f5c\u306bHDFS\u3084S3\u3092\u4f7f\u3063\u3066\u3044\u306a\u3044\u306e\u3067\u3001\u6c17\u306b\u306a\u3063\u305f\u30b3\u30fc\u30c9\u306f\u3055\u3063\u3068Docker\u30b3\u30f3\u30c6\u30ca\u306espark-shell\u3092\u8d77\u52d5\u3057\u3066\u3059\u3050\u306b\u78ba\u8a8d\u3059\u308b\u3053\u3068\u304c\u3067\u304d\u307e\u3059\u3002\n## \u3053\u306e\u30b7\u30ea\u30fc\u30ba\n\n* [Spark on Docker\u3067\u5206\u6563\u578b\u6a5f\u68b0\u5b66\u7fd2\u3092\u59cb\u3081\u308b - Part 1: \u30a4\u30f3\u30b9\u30c8\u30fc\u30eb](http://qiita.com/masato/items/fe93157293114999b0d8)\n* [Spark on Docker\u3067\u5206\u6563\u578b\u6a5f\u68b0\u5b66\u7fd2\u3092\u59cb\u3081\u308b - Part 2: Ubuntu\u3067IPython Notebook\u3092\u4f7f\u3046](http://qiita.com/masato/items/be383a81e323f3b5b42e)\n* [Spark on Docker\u3067\u5206\u6563\u578b\u6a5f\u68b0\u5b66\u7fd2\u3092\u59cb\u3081\u308b - Part 3: \u30ed\u30fc\u30ab\u30eb\u30e2\u30fc\u30c9\u3067spark-shell\u3092\u8d77\u52d5\u3059\u308b](http://qiita.com/masato/items/9398cccde46cf62aa609)\n* [Spark on Docker\u3067\u5206\u6563\u578b\u6a5f\u68b0\u5b66\u7fd2\u3092\u59cb\u3081\u308b - Part 4: Ambari\u3067Hadoop\u3068Spark\u306esingle node\u30bb\u30c3\u30c8\u30a2\u30c3\u30d7](http://qiita.com/masato/items/34cf33b6a956a2f723f9)\n* \n\n\u3000\u524d\u56de\u306e\u30bb\u30c3\u30c8\u30a2\u30c3\u30d7\u304b\u3089Spark\u306e\u30d0\u30fc\u30b8\u30e7\u30f3\u3082\u4e0a\u304c\u3063\u3066\u3044\u308b\u306e\u3067\u65b0\u3057\u3044\u74b0\u5883\u3092\u7528\u610f\u3057\u307e\u3059\u3002\u4eca\u56de\u306f1\u3064\u306eJVM\u4e0a\u3067\u52d5\u4f5c\u3059\u308b\u30ed\u30fc\u30ab\u30eb\u30e2\u30fc\u30c9\u3092\u30bb\u30c3\u30c8\u30a2\u30c3\u30d7\u3057\u307e\u3059\u3002\u30c7\u30b9\u30af\u30c8\u30c3\u30d7\u30e2\u30fc\u30c9\u3068\u3082\u547c\u3070\u308c\u307e\u3059\u304c\u3001spark-shell\u3092\u4f7f\u3063\u305f\u30c6\u30b9\u30c8\u3084\u30b5\u30f3\u30d7\u30eb\u30b3\u30fc\u30c9\u306e\u5b9f\u884c\u7528\u306b\u624b\u8efd\u306b\u4f7f\u3046\u3053\u3068\u304c\u3067\u304d\u307e\u3059\u3002\n\n\n## Dockerfile\n\n\u3000\u3069\u306e\u74b0\u5883\u3067\u3082\u52d5\u4f5c\u3059\u308b\u3088\u3046\u306bDockerfile\u306b\u307e\u3068\u3081\u3066\u30a4\u30e1\u30fc\u30b8\u3092\u4f5c\u6210\u3057\u307e\u3059\u3002\n\n```bash:Dockerfile\nFROM java:openjdk-7-jdk\n\nRUN curl -s http://ftp.jaist.ac.jp/pub/apache/spark/spark-1.5.1/spark-1.5.1-bin-hadoop2.6.tgz | tar -xz -C /usr/local/\nRUN cd /usr/local && ln -s spark-1.5.1-bin-hadoop2.6 spark\n\nWORKDIR /usr/local/spark\nRUN cd conf && cp log4j.properties.template log4j.properties && \\\n    sed -i 's/log4j.rootCategory=INFO/log4j.rootCategory=WARN/' log4j.properties\n\nCMD [\"/bin/bash\"]\n```\n\n Docker\u30a4\u30e1\u30fc\u30b8\u3092\u30d3\u30eb\u30c9\u3057\u3066\u30b3\u30f3\u30c6\u30ca\u3092\u5b9f\u884c\u3057\u307e\u3059\u3002\u300clocal[N]\u300d\u306eN\u306f\u5b9f\u884c\u3059\u308b\u30b9\u30ec\u30c3\u30c9\u6570\u3067\u3059\u3002\u300c*\u300d\u3092\u6307\u5b9a\u3059\u308b\u3068\u5229\u7528\u3067\u304d\u308bCPU\u306e\u30b3\u30a2\u6570\u3092\u4f7f\u3044\u307e\u3059\u3002\n\n```bash\n$ docker build -t spark-local .\n$ docker run --rm -it spark-local\n$ ./bin/spark-shell --master local[*]\n15/11/29 16:35:07 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\nWelcome to\n      ____              __\n     / __/__  ___ _____/ /__\n    _\\ \\/ _ \\/ _ `/ __/  '_/\n   /___/ .__/\\_,_/_/ /_/\\_\\   version 1.5.2\n      /_/\n\nUsing Scala version 2.10.4 (OpenJDK 64-Bit Server VM, Java 1.7.0_91)\nType in expressions to have them evaluated.\nType :help for more information.\n15/11/29 16:35:18 WARN MetricsSystem: Using default name DAGScheduler for source because spark.app.id is not set.\nSpark context available as sc.\n15/11/29 16:35:23 WARN Connection: BoneCP specified but not present in CLASSPATH (or one of dependencies)\n15/11/29 16:35:24 WARN Connection: BoneCP specified but not present in CLASSPATH (or one of dependencies)\n (or one of dependencies)\n15/11/29 16:35:33 WARN ObjectStore: Version information not found in metastore. hive.metastore.schema.verification is not enabled so recording the schema version 1.2.0\n15/11/29 16:35:33 WARN ObjectStore: Failed to get database default, returning NoSuchObjectException\n15/11/29 16:35:37 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n15/11/29 16:35:39 WARN Connection: BoneCP specified but not present in CLASSPATH (or one of dependencies)\n15/11/29 16:35:39 WARN Connection: BoneCP specified but not present in CLASSPATH (or one of dependencies)\n15/11/29 16:35:46 WARN ObjectStore: Version information not found in metastore. hive.metastore.schema.verification is not enabled so recording the schema version 1.2.0\n15/11/29 16:35:47 WARN ObjectStore: Failed to get database default, returning NoSuchObjectException\nSQL context available as sqlContext.\n\nscala>\n```\n\u3000log4j.properties\u306erootCategory\u3092WARN\u306b\u3057\u3066\u3044\u307e\u3059\u304c\u305d\u308c\u3067\u3082\u30ed\u30b0\u304c\u305f\u304f\u3055\u3093\u8868\u793a\u3055\u308c\u307e\u3059\u3002\n\u3000spark-shell\u306e\u52d5\u4f5c\u78ba\u8a8d\u3068\u3057\u3066\u300cLISCENSE\u300d\u30d5\u30a1\u30a4\u30eb\u306e\u884c\u6570\u3092\u30ab\u30a6\u30f3\u30c8\u3059\u308b\u7c21\u5358\u306a\u30b3\u30fc\u30c9\u3092\u5b9f\u884c\u3057\u3066\u307f\u307e\u3059\u3002\u307e\u305f\u300cSpark\u300d\u3068\u3044\u3046\u6587\u5b57\u3092\u542b\u3080\u884c\u6570\u3092\u30ab\u30a6\u30f3\u30c8\u3057\u3066\u6a19\u6e96\u51fa\u529b\u3057\u307e\u3059\u3002\n\n```bash\nscala> val lines = sc.textFile(\"LICENSE\")\nlines: org.apache.spark.rdd.RDD[String] = MapPartitionsRDD[1] at textFile at <console>:21\n\nscala> val count = lines.count\ncount: Long = 294\n\nscala> val sparks = lines.filter(line => line.contains(\"Spark\"))\nsparks: org.apache.spark.rdd.RDD[String] = MapPartitionsRDD[8] at filter at <console>:23\n\nscala> sparks.count\nres7: Long = 3\n\nscala> sparks.foreach(println)\nApache Spark Subcomponents:\nThe Apache Spark project contains subcomponents with separate copyright\n        except for Main.Scala, SparkHelper.scala and ExecutorClassLoader.scala),\n```\n\n\u3000\u30d5\u30a1\u30a4\u30eb\u64cd\u4f5c\u306bHDFS\u3084S3\u3092\u4f7f\u3063\u3066\u3044\u306a\u3044\u306e\u3067\u3001\u6c17\u306b\u306a\u3063\u305f\u30b3\u30fc\u30c9\u306f\u3055\u3063\u3068Docker\u30b3\u30f3\u30c6\u30ca\u306espark-shell\u3092\u8d77\u52d5\u3057\u3066\u3059\u3050\u306b\u78ba\u8a8d\u3059\u308b\u3053\u3068\u304c\u3067\u304d\u307e\u3059\u3002\n", "tags": ["Spark1.5.2", "docker1.9.1"]}