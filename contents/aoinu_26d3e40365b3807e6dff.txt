{"tags": ["Chainer", "DeepLearning", "\u6a5f\u68b0\u5b66\u7fd2", "Python"], "context": "\n\n\u6982\u8981\n\nChainer\u3067\u30e2\u30ce\u30af\u30ed\u753b\u50cf\u306e\u30ab\u30e9\u30fc\u5316\u306e\u5b66\u7fd2\u3092\u7c21\u5358\u306b\u5b9f\u88c5\u3057\u3066\u307f\u307e\u3059\u3002\n\u6700\u8fd1\u306eChainer\u306f\u62bd\u8c61\u7684\u306b\u66f8\u3051\u308b\u3088\u3046\u306b\u306a\u3063\u3066\u308b\u306e\u3067\u3001Trainer\u7b49\u3092\u4f7f\u3063\u3066\u5b9f\u88c5\u3057\u307e\u3059\u3002\n\u5168\u7d50\u5408NN\u3068\u7573\u8fbc\u307fNN\u3001\u53ca\u3073\u6d3b\u6027\u5316\u95a2\u6570\u306e\u9055\u3044\u306b\u3088\u308b\u4ed5\u4e0a\u304c\u308a\u306e\u9055\u3044\u3092\u6bd4\u8f03\u3057\u3066\u307f\u307e\u3059\u3002\n\n\n\u30c7\u30fc\u30bf\u30bb\u30c3\u30c8\n\u30c7\u30fc\u30bf\u30bb\u30c3\u30c8\u306b\u306fCIFAR-100\u3092\u5229\u7528\u3057\u307e\u3059\u3002Chainer\u306b\u306f\u7c21\u5358\u306b\u5229\u7528\u3067\u304d\u308b\u30c7\u30fc\u30bf\u30bb\u30c3\u30c8\u304c\u5e7e\u3064\u304b\u7528\u610f\u3055\u308c\u3066\u304a\u308a\u3001MNIST\u3084CIFAR-100\u3068\u3044\u3063\u305f\u3082\u306e\u304c\u4f7f\u3048\u307e\u3059\u3002\u4eca\u56de\u306f\u624b\u3063\u53d6\u308a\u65e9\u304f\u6ca2\u5c71\u306e\u30ab\u30e9\u30fc\u753b\u50cf\u304c\u7528\u610f\u3067\u304d\u308bCIFAR-100\u306b\u3057\u307e\u3057\u305f\u304c\u3001\u672c\u6765\u306f\u3082\u3063\u3068\u3088\u308a\u591a\u304f\u306e\u7a2e\u985e\u306e\u753b\u50cf\u3092\u542b\u3080\u30c7\u30fc\u30bf\u30bb\u30c3\u30c8\u304c\u9069\u5207\u304b\u3068\u601d\u3044\u307e\u3059\u3002\nChainer\u3067\u306eCIFAR-100\u306e\u5229\u7528\u306f\u4ee5\u4e0b\u306e\u3088\u3046\u306b\u5b9f\u88c5\u3057\u307e\u3059\u3002\ntrain, test = chainer.datasets.get_cifar100(withlabel=False)\n\nChainer\u306e\u6559\u5e2b\u3042\u308a\u5b66\u7fd2\u306e\u30c7\u30fc\u30bf\u30bb\u30c3\u30c8\u306f(\u5b66\u7fd2\u30c7\u30fc\u30bf, \u6559\u5e2b\u30c7\u30fc\u30bf)\u306e\u914d\u5217\u3092iterator\u306b\u6e21\u3057\u3066\u5b9f\u88c5\u3057\u307e\u3059\u3002\u30e2\u30ce\u30af\u30ed\u753b\u50cf\u306e\u30ab\u30e9\u30fc\u5316\u3092\u5b66\u7fd2\u3059\u308b\u306b\u3042\u305f\u3063\u3066\u5fc5\u8981\u306a\u306e\u306f(\u30e2\u30ce\u30af\u30ed\u753b\u50cf, \u30ab\u30e9\u30fc\u753b\u50cf)\u306e\u914d\u5217\u3067\u3059\u3002\u4eca\u56de\u5229\u7528\u3059\u308bchainer.datasets.get_cifar100()\u304b\u3089\u306f(\u753b\u50cf, \u30e9\u30d9\u30eb)\u3068\u3044\u3046\u30bf\u30d7\u30eb\u306e\u914d\u5217\uff08\u3063\u307d\u3044\u3082\u306e\uff09\u304c\u5f97\u3089\u308c\u308b\u306e\u3067\u3059\u304c\u3001\u30e9\u30d9\u30eb\u306f\u4e0d\u8981\u306a\u306e\u3067withlabel\u3092False\u306b\u3057\u3001\u753b\u50cf\u306e\u914d\u5217\u3060\u3051\u3092\u5f97\u307e\u3059\u3002\n\u6b21\u306b\u3001\u5f97\u3089\u308c\u305f\u30ab\u30e9\u30fc\u753b\u50cf\u306e\u30c7\u30fc\u30bf\u30bb\u30c3\u30c8\u3092(\u30e2\u30ce\u30af\u30ed\u753b\u50cf, \u30ab\u30e9\u30fc\u753b\u50cf)\u306b\u6539\u9020\u3057\u307e\u3059\u3002Chainer\u3067\u30c7\u30fc\u30bf\u30bb\u30c3\u30c8\u3092\u81ea\u4f5c\u3059\u308b\u969b\u306fchainer.datasets.TupleDataset(\u5b66\u7fd2\u30c7\u30fc\u30bf\u914d\u5217, \u6559\u5e2b\u30c7\u30fc\u30bf\u914d\u5217)\u3067\u5b9f\u88c5\u3059\u308b\u3053\u3068\u304c\u591a\u3044\u3068\u601d\u3044\u307e\u3059\u3002\u304c\u3001\u30ab\u30e9\u30fc\u753b\u50cf\u304b\u3089\u306e\u30e2\u30ce\u30af\u30ed\u753b\u50cf\u751f\u6210\u306f\u7c21\u5358\u306b\u3067\u304d\u308b\u306e\u3067\u3001\u4eca\u56de\u306fchainer.dataset.DatasetMixin\u3092\u7d99\u627f\u3057\u305f\u30af\u30e9\u30b9\u3092\u4f7f\u3044\u3001\u30df\u30cb\u30d0\u30c3\u30c1\u3092\u4f5c\u6210\u3059\u308b\u76f4\u524d\u3067\u30e2\u30ce\u30af\u30ed\u753b\u50cf\u3092\u7528\u610f\u3059\u308b\u3084\u308a\u65b9\u3067\u5b9f\u88c5\u3057\u307e\u3059\u3002\u3053\u3061\u3089\u306e\u30b5\u30f3\u30d7\u30eb\u304c\u53c2\u8003\u306b\u306a\u308a\u307e\u3059\u3002\u753b\u50cf\u306e\u30af\u30ed\u30c3\u30d7\u3084\u30ce\u30a4\u30ba\u3092\u306e\u305b\u308b\u3068\u3044\u3063\u305f\u52a0\u5de5\u3082\u3053\u306e\u3084\u308a\u65b9\u3067\u884c\u3046\u306e\u304c\u697d\u304b\u3068\u601d\u308f\u308c\u307e\u3059\u3002\nclass PreprocessedDataset(chainer.dataset.DatasetMixin):\n    def __init__(self, base_image_dataset):\n        self.base = base_image_dataset\n\n    def __len__(self):\n        return len(self.base)\n\n    def get_example(self, i):\n        color_image = self.base[i]\n        gray_image = np.ndarray((32, 32), dtype=np.float32)\n        for ch in range(3):\n            gray_image = (\n                0.298912*color_image[0]\n                + 0.586611*color_image[1]\n                + 0.114478*color_image[2]\n            )\n        return gray_image, color_image\n\n\n\u30cd\u30c3\u30c8\u30ef\u30fc\u30af\u69cb\u6210\n\u4eca\u56de\u306f2\u7a2e\u985e\u306eNN\u3092\u8a66\u3057\u3066\u307f\u307e\u3059\u3002\u4e00\u3064\u306f\u5358\u7d14\u306b\u5168\u7d50\u5408\u5c64\u3092\u7e4b\u3052\u305f\u3082\u306e\u3001\u3082\u3046\u4e00\u3064\u306fConvolution\u5c64\u306e\u5f8c\u308d\u306bDeconvolution\u5c64\u3092\u7e4b\u3052\u305f\u3082\u306e\u3067\u3059\u3002\nclass AIC_FC(chainer.Chain):\n    def __init__(self, n_units):\n        initializer = chainer.initializers.HeNormal()\n        super(AIC_FC, self).__init__(\n            fc_in = L.Linear(None, n_units),\n            bn1 = L.BatchNormalization(n_units),\n            fc2 = L.Linear(None, n_units),\n            bn2 = L.BatchNormalization(n_units),\n            fc_out = L.Linear(None, 32*32*3)\n        )\n\n    def __call__(self, x, t):\n        y = self.colorize(x)\n        loss = F.mean_squared_error(y, t)\n        chainer.reporter.report({\n            'loss': loss\n        })\n        return loss\n\n    def colorize(self, x, test=False):\n        h = F.elu(self.bn1(self.fc_in(x), test=test))\n        h = F.elu(self.bn2(self.fc2(h), test=test))\n        y = F.reshape(self.fc_out(h), (h.shape[0], 3, 32, 32))\n        return y\n\nclass AIC_DC(chainer.Chain):\n    def __init__(self, n_ch):\n        initializer = chainer.initializers.HeNormal()\n        super(AIC_DC, self).__init__(\n            cv_in = L.Convolution2D(1, n_ch//4, 4, 2, 1),\n            bn1 = L.BatchNormalization(n_ch//4),\n            cv1 = L.Convolution2D(n_ch//4, n_ch//2, 4, 2, 1),\n            bn2 = L.BatchNormalization(n_ch//2),\n            cv2 = L.Convolution2D(n_ch//2, n_ch, 4, 2, 1),\n            bn3 = L.BatchNormalization(n_ch),\n            cv3 = L.Convolution2D(n_ch, n_ch, 4, 2, 1),\n            bn4 = L.BatchNormalization(n_ch),\n            dc1 = L.Deconvolution2D(n_ch, n_ch, 4, 2, 1),\n            bn5 = L.BatchNormalization(n_ch),\n            dc2 = L.Deconvolution2D(n_ch, n_ch//2, 4, 2, 1),\n            bn6 = L.BatchNormalization(n_ch//2),\n            dc3 = L.Deconvolution2D(n_ch//2, n_ch//4, 4, 2, 1),\n            bn7 = L.BatchNormalization(n_ch//4),\n            dc_out = L.Deconvolution2D(n_ch//4, 3, 4, 2, 1, outsize=(32, 32))\n        )\n\n    def __call__(self, x, t):\n        y = self.colorize(x)\n        loss = F.mean_squared_error(y, t)\n        chainer.reporter.report({\n            'loss': loss\n        })\n        return loss\n\n    def colorize(self, x, test=False):\n        h = F.reshape(x, (x.shape[0], 1, 32, 32))\n        h = F.elu(self.bn1(self.cv_in(h), test=test))\n        h = F.elu(self.bn2(self.cv1(h), test=test))\n        h = F.elu(self.bn3(self.cv2(h), test=test))\n        h = F.elu(self.bn4(self.cv3(h), test=test))\n        h = F.elu(self.bn5(self.dc1(h), test=test))\n        h = F.elu(self.bn6(self.dc2(h), test=test))\n        h = F.elu(self.bn7(self.dc3(h), test=test))\n        y = self.dc_out(h)\n        return y\n\n\u5168\u7d50\u5408NN\u3092\u6df1\u304f\u3057\u3066\u307f\u305f\u3068\u3053\u308d\u3001\u5f85\u3066\u3069\u66ae\u3089\u305b\u3069\u307c\u3084\u3051\u305f\u753b\u50cf\u3057\u304b\u751f\u6210\u3055\u308c\u306a\u3044\uff08\u53ce\u675f\u304c\u9045\u3044\uff1f\uff09\u306e\u3067\u3001\u6d45\u3081\u306b\u3057\u307e\u3057\u305f\u3002\n\u3061\u306a\u307f\u306b\u5b9f\u969b\u306e\u30ab\u30e9\u30fc\u5316NN\u306f\u3082\u3063\u3068\u8907\u96d1\u306a\u8a2d\u8a08\u306b\u306a\u3063\u3066\u3044\u308b\u3088\u3046\u3067\u3059\u3002\uff08\u53c2\u8003\uff09\n\n\u5b66\u7fd2\u306e\u5b9f\u88c5\nChainer\u306b\u304a\u3051\u308b\u5b66\u7fd2\u306e\u5b9f\u88c5\u306e\u6d41\u308c\u306f\n\n\u30e2\u30c7\u30eb\u306e\u4f5c\u6210\nOptimizer\u306e\u8a2d\u5b9a\nDataset\u306e\u7528\u610f\nDataset\u304b\u3089Iterator\u3092\u4f5c\u6210\nUpdater\u3092\u8a2d\u5b9a\nTrainer\u3092\u8a2d\u5b9a\n\n\u3068\u306a\u308a\u307e\u3059\u3002Optimizer\u306fAdam\u306e\u4ed6\u3001SGD\u3084MomentumSGD\u306e\u3088\u3046\u306a\u57fa\u672c\u7684\u306a\u3082\u306e\u3082\u7528\u610f\u3055\u308c\u3066\u304a\u308a\u3001Updater\u3082GAN\u306e\u3088\u3046\u306a\u8907\u96d1\u306a\u640d\u5931\u8a08\u7b97\u3092\u884c\u308f\u306a\u3044\u554f\u984c\u306b\u3064\u3044\u3066\u306fStandardUpdater\u3067\u5341\u5206\u304b\u3068\u601d\u308f\u308c\u307e\u3059\u3002\u5168\u90e8\u81ea\u529b\u3067\u66f8\u3044\u3066\u305f\u6642\u4ee3\u306b\u6bd4\u3079\u308b\u3068\u3001\u30c7\u30d5\u30a9\u30eb\u30c8\u3067\u3044\u3044\u611f\u3058\u306e\u3082\u306e\u304c\u7528\u610f\u3055\u308c\u3066\u3044\u308b\u306e\u3067\u5927\u5206\u697d\u3067\u304d\u307e\u3059\u3002\u6539\u9020\u3082\u5fc5\u8981\u306a\u90e8\u5206\u3060\u3051\u3067\u6e08\u3080\u306e\u3067\u3001\u4ed6\u306e\u4eba\u304c\u898b\u305f\u3068\u304d\u306e\u5206\u304b\u308a\u3084\u3059\u3055\u304c\u6539\u5584\u3057\u3066\u304a\u308a\u3001\u6709\u308a\u96e3\u307f\u3092\u611f\u3058\u307e\u3059\u3002\n\n\u30e2\u30c7\u30eb\u306e\u30c6\u30b9\u30c8\u3092\u5b9f\u88c5\n\u4eca\u56de\u306e\u3088\u3046\u306a\u554f\u984c\u306floss\u306e\u5024\u3060\u3051\u3067\u306f\u5b66\u7fd2\u306e\u69d8\u5b50\u304c\u5206\u304b\u308a\u306b\u304f\u3044\u306e\u3067\u8996\u899a\u5316\u3057\u305f\u304f\u306a\u308a\u307e\u3059\u3002\u305d\u3053\u3067Trainer Extension\u3067\u30e2\u30c7\u30eb\u306e\u30c6\u30b9\u30c8\u3092\u5b9f\u88c5\u3057\u307e\u3059\u3002Extension\u306fchainer.training.extention.Extension\u7b49\u3092\u7d99\u627f\u3059\u308b\u304b\u3001chainer.training.make_extension()\u3092\u5229\u7528\u3057\u3066\u4f5c\u6210\u3057\u307e\u3059\u3002\u30e2\u30c7\u30eb\u306e\u30c6\u30b9\u30c8\u3068\u753b\u50cf\u306e\u4fdd\u5b58\u3092chainer.training.make_extension()\u3067\u4ee5\u4e0b\u306e\u901a\u308a\u5b9f\u88c5\u3057\u307e\u3059\u3002\uff08scipy.misc\u306eimsave\u3092import\u3057\u3066\u3044\u307e\u3059\u3002\uff09\n\u8a13\u7df4\u30c7\u30fc\u30bf\u3068\u306f\u5225\u306b\u30c6\u30b9\u30c8\u7528\u753b\u50cf\u3092\u7528\u610f\u3057\u3066\u3044\u307e\u3059\u3002\n@chainer.training.make_extension(trigger=(1, 'epoch'))\ndef test_model(trainer):\n    colorized_img = chainer.cuda.to_cpu(F.clipped_relu(model.colorize(test_img, test=True), z=1.0).data)\n    imsave(\n        'test_colorized{}.png'.format(trainer.updater.epoch),\n        colorized_img\n        .transpose(0, 2, 3, 1)\n        .reshape((8, 8, 32, 32, 3))\n        .transpose(1, 2, 0, 3, 4)\n        .reshape(8*32, 8*32, 3)\n    )\ntrainer.extend(test_model)\n\n\n\u5b66\u7fd2\u7d50\u679c\n\u5b66\u7fd2\u306e\u7d50\u679c\u3092\u7d39\u4ecb\u3057\u307e\u3059\u3002\u4eca\u56de\u306f\u5168\u7d50\u5408NN\u3068\u7573\u307f\u8fbc\u307fNN\u306e2\u3064\u3092\u8a66\u3057\u305f\u306e\u3067\u300130 epoch\u5b66\u7fd2\u3055\u305b\u305f\u6642\u70b9\u3067\u306e\u5b66\u7fd2\u306e\u69d8\u5b50\u3068\u5408\u308f\u305b\u3066\u6bd4\u8f03\u3057\u3066\u3044\u304d\u307e\u3059\u3002\u5168\u7d50\u5408NN\u306en_units\u306f2048\u3001\u7573\u8fbc\u307fNN\u306en_ch\u306f512\u3067\u5b66\u7fd2\u3057\u307e\u3057\u305f\u3002\n\n\u30ab\u30e9\u30fc\u753b\u50cf\n\n\n\u30e2\u30ce\u30af\u30ed\u753b\u50cf\n\n\n30 epoch\u5f8c\n\u5168\u7d50\u5408NN\n\n\u7573\u307f\u8fbc\u307fNN\n\n\u5168\u7d50\u5408NN\u306f\u5168\u4f53\u7684\u306b\u3056\u3089\u3064\u3044\u305f\u611f\u3058\u306e\u753b\u50cf\u306b\u306a\u308a\u3084\u3059\u3044\u3088\u3046\u3067\u3059\u3002\u5358\u7d14\u306aNN\u3067\u3082\u7d50\u69cb\u8272\u304c\u4e57\u3063\u3066\u3044\u3066\u610f\u5916\u3067\u3057\u305f\u304c\u3001\u7573\u307f\u8fbc\u307fNN\u306e\u307b\u3046\u304c\u3088\u308a\u9bae\u3084\u304b\u3067\u7dba\u9e97\u306a\u753b\u50cf\u304c\u51fa\u529b\u3067\u304d\u3066\u3044\u308b\u3068\u611f\u3058\u307e\u3059\u3002\n\u4e00\u3064\u4e00\u3064\u306e\u753b\u50cf\u3092\u898b\u3066\u3044\u304f\u3068\u3001\u7a7a\u3084\u6d77\u306f\u3046\u307e\u304f\u8a8d\u8b58\u3057\u3066\u7dba\u9e97\u306b\u8272\u3092\u8f09\u305b\u3066\u304f\u308c\u308b\u50be\u5411\u306b\u3042\u308a\u305d\u3046\u3067\u3059\u3002\u3067\u3059\u304c\u9752\u7a7a\u3068\u5915\u713c\u3051\u306e\u533a\u5225\u306f\u96e3\u3057\u3044\u307f\u305f\u3044\u3067\u3059\u306d\u3002\u5c0f\u52d5\u7269\u304c\u5199\u3063\u3066\u3044\u308b\u3068\u601d\u3057\u304d\u4e00\u756a\u53f3\u4e0b\u306e\u753b\u50cf\u306b\u3064\u3044\u3066\u306f\u3001\u5730\u9762\u3092\u8a8d\u8b58\u3057\u3066\u8336\u8272\u3084\u8349\u306e\u8272\u3092\u518d\u73fe\u3057\u3066\u3044\u307e\u3059\u3002\u304c\u3001\u6b63\u89e3\u3068\u6bd4\u3079\u308b\u3068\u3061\u3087\u3063\u3068\u8349\u751f\u3084\u3057\u3059\u304e\u3067\u3059\u306d\u3002\n\n\u6d3b\u6027\u5316\u95a2\u6570\u306e\u9055\u3044\u306b\u3088\u308b\u5909\u5316\n\u4e0a\u306b\u6319\u3052\u305f\u753b\u50cf\u306f\u6d3b\u6027\u5316\u95a2\u6570\u306belu\u3092\u4f7f\u7528\u3057\u305f\u969b\u306e\u3082\u306e\u3067\u3059\u3002\u6d3b\u6027\u5316\u95a2\u6570\u306brelu\u3084leaky_relu\u3092\u4f7f\u7528\u3059\u308b\u3068\u3001\u4ed5\u4e0a\u304c\u308a\u306b\u3069\u306e\u3088\u3046\u306a\u5909\u5316\u304c\u3042\u308b\u304b\u3082\u8abf\u3079\u3066\u307f\u307e\u3057\u305f\u3002n_ch\u304c512\u306e\u7573\u307f\u8fbc\u307fNN, 30 epoch\u3067\u306e\u7d50\u679c\u306e\u307f\u7d39\u4ecb\u3057\u307e\u3059\u3002\nrelu\n\nleaky_relu\n\nelu\n\nrelu\u306f\u9bae\u3084\u304b\u306b\u4ed5\u4e0a\u304c\u3063\u3066\u3044\u307e\u3059\u304c\u82e5\u5e72\u307c\u3084\u3051\u305f\u5370\u8c61\u3067\u3059\u3002elu\u3084leaky relu\u306f\u753b\u50cf\u306e\u9bae\u660e\u3055\u3067relu\u3088\u308a\u512a\u79c0\u305d\u3046\u3067\u3059\u3002leaky relu\u306felu\u3068relu\u306e\u4e2d\u9593\u304f\u3089\u3044\u306e\u5370\u8c61\u3092\u611f\u3058\u307e\u3059\u3002\n\n\u4f7f\u7528\u3057\u305f\u30b3\u30fc\u30c9\u306e\u5168\u4f53\n#! /usr/bin/env python\n# coding : utf-8\n\nimport argparse\nimport numpy as np\nfrom scipy.misc import imsave\nimport chainer\nimport chainer.functions as F\nimport chainer.links as L\nfrom chainer.training import extensions \n\n\nclass PreprocessedDataset(chainer.dataset.DatasetMixin):\n    def __init__(self, base_image_dataset):\n        self.base = base_image_dataset\n\n    def __len__(self):\n        return len(self.base)\n\n    def get_example(self, i):\n        color_image = self.base[i]\n        gray_image = np.ndarray((32, 32), dtype=np.float32)\n        for ch in range(3):\n            # \u8f1d\u5ea6\u3092\u8a08\u7b97\u3057\u3001\u30e2\u30ce\u30af\u30ed\u753b\u50cf\u3092\u4f5c\u6210\n            gray_image = (\n                0.298912*color_image[0]\n                + 0.586611*color_image[1]\n                + 0.114478*color_image[2]\n            )\n        return gray_image, color_image\n\nclass AIC_FC(chainer.Chain):\n    def __init__(self, n_units):\n        initializer = chainer.initializers.HeNormal()\n        super(AIC_FC, self).__init__(\n            fc_in = L.Linear(None, n_units),\n            bn1 = L.BatchNormalization(n_units),\n            fc2 = L.Linear(None, n_units),\n            bn2 = L.BatchNormalization(n_units),\n            fc_out = L.Linear(None, 32*32*3)\n        )\n\n    def __call__(self, x, t):\n        y = self.colorize(x)\n        loss = F.mean_squared_error(y, t)\n        chainer.reporter.report({\n            'loss': loss\n        })\n        return loss\n\n    def colorize(self, x, test=False):\n        h = F.elu(self.bn1(self.fc_in(x), test=test))\n        h = F.elu(self.bn2(self.fc2(h), test=test))\n        y = F.reshape(self.fc_out(h), (h.shape[0], 3, 32, 32))\n        return y\n\nclass AIC_DC(chainer.Chain):\n    def __init__(self, n_ch):\n        initializer = chainer.initializers.HeNormal()\n        super(AIC_DC, self).__init__(\n            cv_in = L.Convolution2D(1, n_ch//4, 4, 2, 1),\n            bn1 = L.BatchNormalization(n_ch//4),\n            cv1 = L.Convolution2D(n_ch//4, n_ch//2, 4, 2, 1),\n            bn2 = L.BatchNormalization(n_ch//2),\n            cv2 = L.Convolution2D(n_ch//2, n_ch, 4, 2, 1),\n            bn3 = L.BatchNormalization(n_ch),\n            cv3 = L.Convolution2D(n_ch, n_ch, 4, 2, 1),\n            bn4 = L.BatchNormalization(n_ch),\n            dc1 = L.Deconvolution2D(n_ch, n_ch, 4, 2, 1),\n            bn5 = L.BatchNormalization(n_ch),\n            dc2 = L.Deconvolution2D(n_ch, n_ch//2, 4, 2, 1),\n            bn6 = L.BatchNormalization(n_ch//2),\n            dc3 = L.Deconvolution2D(n_ch//2, n_ch//4, 4, 2, 1),\n            bn7 = L.BatchNormalization(n_ch//4),\n            dc_out = L.Deconvolution2D(n_ch//4, 3, 4, 2, 1, outsize=(32, 32))\n        )\n\n    def __call__(self, x, t):\n        y = self.colorize(x)\n        loss = F.mean_squared_error(y, t)\n        chainer.reporter.report({\n            'loss': loss\n        })\n        return loss\n\n    def colorize(self, x, test=False):\n        # Convolution\u5c64\u306b\u5165\u529b\u3059\u308b\u305f\u3081\u3001ndim\u304c4\u306b\u306a\u308b\u3088\u3046\u306breshape\n        h = F.reshape(x, (x.shape[0], 1, 32, 32))\n        h = F.elu(self.bn1(self.cv_in(h), test=test))\n        h = F.elu(self.bn2(self.cv1(h), test=test))\n        h = F.elu(self.bn3(self.cv2(h), test=test))\n        h = F.elu(self.bn4(self.cv3(h), test=test))\n        h = F.elu(self.bn5(self.dc1(h), test=test))\n        h = F.elu(self.bn6(self.dc2(h), test=test))\n        h = F.elu(self.bn7(self.dc3(h), test=test))\n        y = self.dc_out(h)\n        return y\n\n\ndef main():\n    parser = argparse.ArgumentParser(description='Automatic Image Colorization')\n    parser.add_argument('--batchsize', '-b', type=int, default=64,\n                        help='Number of images in each mini-batch')\n    parser.add_argument('--epoch', '-e', type=int, default=30,\n                        help='Number of sweeps over the dataset to train')\n    parser.add_argument('--gpu', '-g', type=int, default=0,\n                        help='GPU ID (negative value indicates CPU)')\n    parser.add_argument('--resume', '-r', default='',\n                        help='Resume the training from snapshot')\n    parser.add_argument('--n_ch', '-nc', type=int, default=1024,\n                        help='Number of channels')\n    parser.add_argument('--n_units', '-nu', type=int, default=0,\n                        help='Number of units')\n    args = parser.parse_args()\n    print('# GPU: {}'.format(args.gpu))\n    print('# Minibatch-size: {}'.format(args.batchsize))\n    print('# epoch: {}'.format(args.epoch))\n\n    if args.n_units > 0:\n        print('# n_units: {}\\n'.format(args.n_units))\n        model = AIC_FC(args.n_units)\n    else:\n        print('# n_ch: {}\\n'.format(args.n_ch))\n        model = AIC_DC(args.n_ch)\n    if args.gpu >= 0:\n        chainer.cuda.get_device().use()\n        model.to_gpu()\n\n    opt = chainer.optimizers.Adam()\n    opt.setup(model)\n\n    train, test = chainer.datasets.get_cifar100(withlabel=False)\n    test_img = (\n        0.298912*test[:64,0]\n        + 0.586611*test[:64,1]\n        + 0.114478*test[:64,2]\n    )\n    # 64\u679a\u306e\u753b\u50cf\u30928x8\u306b\u4e26\u3093\u3060\u4e00\u679a\u306e\u753b\u50cf\u3068\u3057\u3066\u4fdd\u5b58\u3059\u308b\n    imsave(\n        'test.png',\n        test[:64]\n        .transpose(0, 2, 3, 1)\n        .reshape((8, 8, 32, 32, 3))\n        .transpose(1, 2, 0, 3, 4)\n        .reshape(8*32, 8*32, 3)\n    )\n    imsave(\n        'test_gray.png',\n        test_img\n        .reshape((8, 8, 32, 32))\n        .transpose(1, 2, 0, 3)\n        .reshape(8*32, 8*32)\n    )\n    if args.gpu >= 0:\n        test_img = chainer.cuda.to_gpu(test_img)\n\n\n    dataset = PreprocessedDataset(train)\n    iterator = chainer.iterators.MultiprocessIterator(dataset, args.batchsize)\n\n    updater = chainer.training.StandardUpdater(iterator, opt, device=args.gpu)\n    trainer = chainer.training.Trainer(updater, (args.epoch, 'epoch'))\n\n    trainer.extend(extensions.LogReport())\n    trainer.extend(extensions.PrintReport([\n        'epoch', 'loss', 'elapsed_time'\n    ]))\n    @chainer.training.make_extension(trigger=(10, 'epoch'))\n    def test_model(trainer):\n        # \u5024\u57df\u30920~1\u306b\u3059\u308b\u305f\u3081\u3001clipped_relu\u3092\u901a\u3059\n        colorized_img = chainer.cuda.to_cpu(F.clipped_relu(model.colorize(test_img, test=True), z=1.0).data)\n        imsave(\n            'test_colorized{}.png'.format(trainer.updater.epoch),\n            colorized_img\n            .transpose(0, 2, 3, 1)\n            .reshape((8, 8, 32, 32, 3))\n            .transpose(1, 2, 0, 3, 4)\n            .reshape(8*32, 8*32, 3)\n        )\n    trainer.extend(test_model)\n    trainer.extend(extensions.ProgressBar(update_interval=100))\n\n    trainer.run()\n\nif __name__ == '__main__':\n    main()\n\n#\u6982\u8981\n\n- Chainer\u3067\u30e2\u30ce\u30af\u30ed\u753b\u50cf\u306e\u30ab\u30e9\u30fc\u5316\u306e\u5b66\u7fd2\u3092\u7c21\u5358\u306b\u5b9f\u88c5\u3057\u3066\u307f\u307e\u3059\u3002\n- \u6700\u8fd1\u306eChainer\u306f\u62bd\u8c61\u7684\u306b\u66f8\u3051\u308b\u3088\u3046\u306b\u306a\u3063\u3066\u308b\u306e\u3067\u3001Trainer\u7b49\u3092\u4f7f\u3063\u3066\u5b9f\u88c5\u3057\u307e\u3059\u3002\n- \u5168\u7d50\u5408NN\u3068\u7573\u8fbc\u307fNN\u3001\u53ca\u3073\u6d3b\u6027\u5316\u95a2\u6570\u306e\u9055\u3044\u306b\u3088\u308b\u4ed5\u4e0a\u304c\u308a\u306e\u9055\u3044\u3092\u6bd4\u8f03\u3057\u3066\u307f\u307e\u3059\u3002\n\n#\u30c7\u30fc\u30bf\u30bb\u30c3\u30c8\n\u30c7\u30fc\u30bf\u30bb\u30c3\u30c8\u306b\u306f[CIFAR-100](https://www.cs.toronto.edu/~kriz/cifar.html)\u3092\u5229\u7528\u3057\u307e\u3059\u3002Chainer\u306b\u306f\u7c21\u5358\u306b\u5229\u7528\u3067\u304d\u308b\u30c7\u30fc\u30bf\u30bb\u30c3\u30c8\u304c\u5e7e\u3064\u304b\u7528\u610f\u3055\u308c\u3066\u304a\u308a\u3001MNIST\u3084CIFAR-100\u3068\u3044\u3063\u305f\u3082\u306e\u304c\u4f7f\u3048\u307e\u3059\u3002\u4eca\u56de\u306f\u624b\u3063\u53d6\u308a\u65e9\u304f\u6ca2\u5c71\u306e\u30ab\u30e9\u30fc\u753b\u50cf\u304c\u7528\u610f\u3067\u304d\u308bCIFAR-100\u306b\u3057\u307e\u3057\u305f\u304c\u3001\u672c\u6765\u306f\u3082\u3063\u3068\u3088\u308a\u591a\u304f\u306e\u7a2e\u985e\u306e\u753b\u50cf\u3092\u542b\u3080\u30c7\u30fc\u30bf\u30bb\u30c3\u30c8\u304c\u9069\u5207\u304b\u3068\u601d\u3044\u307e\u3059\u3002\n\nChainer\u3067\u306eCIFAR-100\u306e\u5229\u7528\u306f\u4ee5\u4e0b\u306e\u3088\u3046\u306b\u5b9f\u88c5\u3057\u307e\u3059\u3002\n\n```py3\ntrain, test = chainer.datasets.get_cifar100(withlabel=False)\n```\n\nChainer\u306e\u6559\u5e2b\u3042\u308a\u5b66\u7fd2\u306e\u30c7\u30fc\u30bf\u30bb\u30c3\u30c8\u306f`(\u5b66\u7fd2\u30c7\u30fc\u30bf, \u6559\u5e2b\u30c7\u30fc\u30bf)`\u306e\u914d\u5217\u3092iterator\u306b\u6e21\u3057\u3066\u5b9f\u88c5\u3057\u307e\u3059\u3002\u30e2\u30ce\u30af\u30ed\u753b\u50cf\u306e\u30ab\u30e9\u30fc\u5316\u3092\u5b66\u7fd2\u3059\u308b\u306b\u3042\u305f\u3063\u3066\u5fc5\u8981\u306a\u306e\u306f`(\u30e2\u30ce\u30af\u30ed\u753b\u50cf, \u30ab\u30e9\u30fc\u753b\u50cf)`\u306e\u914d\u5217\u3067\u3059\u3002\u4eca\u56de\u5229\u7528\u3059\u308b`chainer.datasets.get_cifar100()`\u304b\u3089\u306f`(\u753b\u50cf, \u30e9\u30d9\u30eb)`\u3068\u3044\u3046\u30bf\u30d7\u30eb\u306e\u914d\u5217\uff08\u3063\u307d\u3044\u3082\u306e\uff09\u304c\u5f97\u3089\u308c\u308b\u306e\u3067\u3059\u304c\u3001\u30e9\u30d9\u30eb\u306f\u4e0d\u8981\u306a\u306e\u3067withlabel\u3092False\u306b\u3057\u3001\u753b\u50cf\u306e\u914d\u5217\u3060\u3051\u3092\u5f97\u307e\u3059\u3002\n\n\u6b21\u306b\u3001\u5f97\u3089\u308c\u305f\u30ab\u30e9\u30fc\u753b\u50cf\u306e\u30c7\u30fc\u30bf\u30bb\u30c3\u30c8\u3092`(\u30e2\u30ce\u30af\u30ed\u753b\u50cf, \u30ab\u30e9\u30fc\u753b\u50cf)`\u306b\u6539\u9020\u3057\u307e\u3059\u3002Chainer\u3067\u30c7\u30fc\u30bf\u30bb\u30c3\u30c8\u3092\u81ea\u4f5c\u3059\u308b\u969b\u306f`chainer.datasets.TupleDataset(\u5b66\u7fd2\u30c7\u30fc\u30bf\u914d\u5217, \u6559\u5e2b\u30c7\u30fc\u30bf\u914d\u5217)`\u3067\u5b9f\u88c5\u3059\u308b\u3053\u3068\u304c\u591a\u3044\u3068\u601d\u3044\u307e\u3059\u3002\u304c\u3001\u30ab\u30e9\u30fc\u753b\u50cf\u304b\u3089\u306e\u30e2\u30ce\u30af\u30ed\u753b\u50cf\u751f\u6210\u306f\u7c21\u5358\u306b\u3067\u304d\u308b\u306e\u3067\u3001\u4eca\u56de\u306f`chainer.dataset.DatasetMixin`\u3092\u7d99\u627f\u3057\u305f\u30af\u30e9\u30b9\u3092\u4f7f\u3044\u3001\u30df\u30cb\u30d0\u30c3\u30c1\u3092\u4f5c\u6210\u3059\u308b\u76f4\u524d\u3067\u30e2\u30ce\u30af\u30ed\u753b\u50cf\u3092\u7528\u610f\u3059\u308b\u3084\u308a\u65b9\u3067\u5b9f\u88c5\u3057\u307e\u3059\u3002[\u3053\u3061\u3089\u306e\u30b5\u30f3\u30d7\u30eb](https://github.com/pfnet/chainer/blob/master/examples/imagenet/train_imagenet.py)\u304c\u53c2\u8003\u306b\u306a\u308a\u307e\u3059\u3002\u753b\u50cf\u306e\u30af\u30ed\u30c3\u30d7\u3084\u30ce\u30a4\u30ba\u3092\u306e\u305b\u308b\u3068\u3044\u3063\u305f\u52a0\u5de5\u3082\u3053\u306e\u3084\u308a\u65b9\u3067\u884c\u3046\u306e\u304c\u697d\u304b\u3068\u601d\u308f\u308c\u307e\u3059\u3002\n\n```py3\nclass PreprocessedDataset(chainer.dataset.DatasetMixin):\n    def __init__(self, base_image_dataset):\n        self.base = base_image_dataset\n\n    def __len__(self):\n        return len(self.base)\n\n    def get_example(self, i):\n        color_image = self.base[i]\n        gray_image = np.ndarray((32, 32), dtype=np.float32)\n        for ch in range(3):\n            gray_image = (\n                0.298912*color_image[0]\n                + 0.586611*color_image[1]\n                + 0.114478*color_image[2]\n            )\n        return gray_image, color_image\n```\n\n#\u30cd\u30c3\u30c8\u30ef\u30fc\u30af\u69cb\u6210\n\u4eca\u56de\u306f2\u7a2e\u985e\u306eNN\u3092\u8a66\u3057\u3066\u307f\u307e\u3059\u3002\u4e00\u3064\u306f\u5358\u7d14\u306b\u5168\u7d50\u5408\u5c64\u3092\u7e4b\u3052\u305f\u3082\u306e\u3001\u3082\u3046\u4e00\u3064\u306fConvolution\u5c64\u306e\u5f8c\u308d\u306bDeconvolution\u5c64\u3092\u7e4b\u3052\u305f\u3082\u306e\u3067\u3059\u3002\n\n```py3\nclass AIC_FC(chainer.Chain):\n    def __init__(self, n_units):\n        initializer = chainer.initializers.HeNormal()\n        super(AIC_FC, self).__init__(\n            fc_in = L.Linear(None, n_units),\n            bn1 = L.BatchNormalization(n_units),\n            fc2 = L.Linear(None, n_units),\n            bn2 = L.BatchNormalization(n_units),\n            fc_out = L.Linear(None, 32*32*3)\n        )\n\n    def __call__(self, x, t):\n        y = self.colorize(x)\n        loss = F.mean_squared_error(y, t)\n        chainer.reporter.report({\n            'loss': loss\n        })\n        return loss\n\n    def colorize(self, x, test=False):\n        h = F.elu(self.bn1(self.fc_in(x), test=test))\n        h = F.elu(self.bn2(self.fc2(h), test=test))\n        y = F.reshape(self.fc_out(h), (h.shape[0], 3, 32, 32))\n        return y\n\nclass AIC_DC(chainer.Chain):\n    def __init__(self, n_ch):\n        initializer = chainer.initializers.HeNormal()\n        super(AIC_DC, self).__init__(\n            cv_in = L.Convolution2D(1, n_ch//4, 4, 2, 1),\n            bn1 = L.BatchNormalization(n_ch//4),\n            cv1 = L.Convolution2D(n_ch//4, n_ch//2, 4, 2, 1),\n            bn2 = L.BatchNormalization(n_ch//2),\n            cv2 = L.Convolution2D(n_ch//2, n_ch, 4, 2, 1),\n            bn3 = L.BatchNormalization(n_ch),\n            cv3 = L.Convolution2D(n_ch, n_ch, 4, 2, 1),\n            bn4 = L.BatchNormalization(n_ch),\n            dc1 = L.Deconvolution2D(n_ch, n_ch, 4, 2, 1),\n            bn5 = L.BatchNormalization(n_ch),\n            dc2 = L.Deconvolution2D(n_ch, n_ch//2, 4, 2, 1),\n            bn6 = L.BatchNormalization(n_ch//2),\n            dc3 = L.Deconvolution2D(n_ch//2, n_ch//4, 4, 2, 1),\n            bn7 = L.BatchNormalization(n_ch//4),\n            dc_out = L.Deconvolution2D(n_ch//4, 3, 4, 2, 1, outsize=(32, 32))\n        )\n\n    def __call__(self, x, t):\n        y = self.colorize(x)\n        loss = F.mean_squared_error(y, t)\n        chainer.reporter.report({\n            'loss': loss\n        })\n        return loss\n\n    def colorize(self, x, test=False):\n        h = F.reshape(x, (x.shape[0], 1, 32, 32))\n        h = F.elu(self.bn1(self.cv_in(h), test=test))\n        h = F.elu(self.bn2(self.cv1(h), test=test))\n        h = F.elu(self.bn3(self.cv2(h), test=test))\n        h = F.elu(self.bn4(self.cv3(h), test=test))\n        h = F.elu(self.bn5(self.dc1(h), test=test))\n        h = F.elu(self.bn6(self.dc2(h), test=test))\n        h = F.elu(self.bn7(self.dc3(h), test=test))\n        y = self.dc_out(h)\n        return y\n```\n\u5168\u7d50\u5408NN\u3092\u6df1\u304f\u3057\u3066\u307f\u305f\u3068\u3053\u308d\u3001\u5f85\u3066\u3069\u66ae\u3089\u305b\u3069\u307c\u3084\u3051\u305f\u753b\u50cf\u3057\u304b\u751f\u6210\u3055\u308c\u306a\u3044\uff08\u53ce\u675f\u304c\u9045\u3044\uff1f\uff09\u306e\u3067\u3001\u6d45\u3081\u306b\u3057\u307e\u3057\u305f\u3002\n\n\u3061\u306a\u307f\u306b\u5b9f\u969b\u306e\u30ab\u30e9\u30fc\u5316NN\u306f\u3082\u3063\u3068\u8907\u96d1\u306a\u8a2d\u8a08\u306b\u306a\u3063\u3066\u3044\u308b\u3088\u3046\u3067\u3059\u3002\uff08[\u53c2\u8003](http://hi.cs.waseda.ac.jp/~iizuka/projects/colorization/ja/)\uff09\n\n#\u5b66\u7fd2\u306e\u5b9f\u88c5\nChainer\u306b\u304a\u3051\u308b\u5b66\u7fd2\u306e\u5b9f\u88c5\u306e\u6d41\u308c\u306f\n\n1. \u30e2\u30c7\u30eb\u306e\u4f5c\u6210\n2. Optimizer\u306e\u8a2d\u5b9a\n3. Dataset\u306e\u7528\u610f\n4. Dataset\u304b\u3089Iterator\u3092\u4f5c\u6210\n5. Updater\u3092\u8a2d\u5b9a\n6. Trainer\u3092\u8a2d\u5b9a\n\n\u3068\u306a\u308a\u307e\u3059\u3002Optimizer\u306fAdam\u306e\u4ed6\u3001SGD\u3084MomentumSGD\u306e\u3088\u3046\u306a\u57fa\u672c\u7684\u306a\u3082\u306e\u3082\u7528\u610f\u3055\u308c\u3066\u304a\u308a\u3001Updater\u3082GAN\u306e\u3088\u3046\u306a\u8907\u96d1\u306a\u640d\u5931\u8a08\u7b97\u3092\u884c\u308f\u306a\u3044\u554f\u984c\u306b\u3064\u3044\u3066\u306fStandardUpdater\u3067\u5341\u5206\u304b\u3068\u601d\u308f\u308c\u307e\u3059\u3002\u5168\u90e8\u81ea\u529b\u3067\u66f8\u3044\u3066\u305f\u6642\u4ee3\u306b\u6bd4\u3079\u308b\u3068\u3001\u30c7\u30d5\u30a9\u30eb\u30c8\u3067\u3044\u3044\u611f\u3058\u306e\u3082\u306e\u304c\u7528\u610f\u3055\u308c\u3066\u3044\u308b\u306e\u3067\u5927\u5206\u697d\u3067\u304d\u307e\u3059\u3002\u6539\u9020\u3082\u5fc5\u8981\u306a\u90e8\u5206\u3060\u3051\u3067\u6e08\u3080\u306e\u3067\u3001\u4ed6\u306e\u4eba\u304c\u898b\u305f\u3068\u304d\u306e\u5206\u304b\u308a\u3084\u3059\u3055\u304c\u6539\u5584\u3057\u3066\u304a\u308a\u3001\u6709\u308a\u96e3\u307f\u3092\u611f\u3058\u307e\u3059\u3002\n\n###\u30e2\u30c7\u30eb\u306e\u30c6\u30b9\u30c8\u3092\u5b9f\u88c5\n\u4eca\u56de\u306e\u3088\u3046\u306a\u554f\u984c\u306floss\u306e\u5024\u3060\u3051\u3067\u306f\u5b66\u7fd2\u306e\u69d8\u5b50\u304c\u5206\u304b\u308a\u306b\u304f\u3044\u306e\u3067\u8996\u899a\u5316\u3057\u305f\u304f\u306a\u308a\u307e\u3059\u3002\u305d\u3053\u3067Trainer Extension\u3067\u30e2\u30c7\u30eb\u306e\u30c6\u30b9\u30c8\u3092\u5b9f\u88c5\u3057\u307e\u3059\u3002Extension\u306f`chainer.training.extention.Extension`\u7b49\u3092\u7d99\u627f\u3059\u308b\u304b\u3001`chainer.training.make_extension()`\u3092\u5229\u7528\u3057\u3066\u4f5c\u6210\u3057\u307e\u3059\u3002\u30e2\u30c7\u30eb\u306e\u30c6\u30b9\u30c8\u3068\u753b\u50cf\u306e\u4fdd\u5b58\u3092`chainer.training.make_extension()`\u3067\u4ee5\u4e0b\u306e\u901a\u308a\u5b9f\u88c5\u3057\u307e\u3059\u3002\uff08scipy.misc\u306eimsave\u3092import\u3057\u3066\u3044\u307e\u3059\u3002\uff09\n\n\u8a13\u7df4\u30c7\u30fc\u30bf\u3068\u306f\u5225\u306b\u30c6\u30b9\u30c8\u7528\u753b\u50cf\u3092\u7528\u610f\u3057\u3066\u3044\u307e\u3059\u3002\n\n```py3\n@chainer.training.make_extension(trigger=(1, 'epoch'))\ndef test_model(trainer):\n    colorized_img = chainer.cuda.to_cpu(F.clipped_relu(model.colorize(test_img, test=True), z=1.0).data)\n    imsave(\n        'test_colorized{}.png'.format(trainer.updater.epoch),\n        colorized_img\n        .transpose(0, 2, 3, 1)\n        .reshape((8, 8, 32, 32, 3))\n        .transpose(1, 2, 0, 3, 4)\n        .reshape(8*32, 8*32, 3)\n    )\ntrainer.extend(test_model)\n```\n\n#\u5b66\u7fd2\u7d50\u679c\n\u5b66\u7fd2\u306e\u7d50\u679c\u3092\u7d39\u4ecb\u3057\u307e\u3059\u3002\u4eca\u56de\u306f\u5168\u7d50\u5408NN\u3068\u7573\u307f\u8fbc\u307fNN\u306e2\u3064\u3092\u8a66\u3057\u305f\u306e\u3067\u300130 epoch\u5b66\u7fd2\u3055\u305b\u305f\u6642\u70b9\u3067\u306e\u5b66\u7fd2\u306e\u69d8\u5b50\u3068\u5408\u308f\u305b\u3066\u6bd4\u8f03\u3057\u3066\u3044\u304d\u307e\u3059\u3002\u5168\u7d50\u5408NN\u306en_units\u306f2048\u3001\u7573\u8fbc\u307fNN\u306en_ch\u306f512\u3067\u5b66\u7fd2\u3057\u307e\u3057\u305f\u3002\n\n###\u30ab\u30e9\u30fc\u753b\u50cf\n![test.png](https://qiita-image-store.s3.amazonaws.com/0/69692/ecd547f5-fe27-d16b-d9e1-68ebaec96405.png)\n\n###\u30e2\u30ce\u30af\u30ed\u753b\u50cf\n![test_gray.png](https://qiita-image-store.s3.amazonaws.com/0/69692/260cc81d-5404-8b79-6bae-38dd7e613a8d.png)\n\n###30 epoch\u5f8c\n\u5168\u7d50\u5408NN\n![30epoch3L2048units.png](https://qiita-image-store.s3.amazonaws.com/0/69692/82d0ffd2-d694-81dc-c1bc-aa090dd1c67f.png)\n\n\n\u7573\u307f\u8fbc\u307fNN\n![30epochELU512ch.png](https://qiita-image-store.s3.amazonaws.com/0/69692/de1e6ff2-5217-eccb-fe5e-b6bacfb643e7.png)\n\n\n\u5168\u7d50\u5408NN\u306f\u5168\u4f53\u7684\u306b\u3056\u3089\u3064\u3044\u305f\u611f\u3058\u306e\u753b\u50cf\u306b\u306a\u308a\u3084\u3059\u3044\u3088\u3046\u3067\u3059\u3002\u5358\u7d14\u306aNN\u3067\u3082\u7d50\u69cb\u8272\u304c\u4e57\u3063\u3066\u3044\u3066\u610f\u5916\u3067\u3057\u305f\u304c\u3001\u7573\u307f\u8fbc\u307fNN\u306e\u307b\u3046\u304c\u3088\u308a\u9bae\u3084\u304b\u3067\u7dba\u9e97\u306a\u753b\u50cf\u304c\u51fa\u529b\u3067\u304d\u3066\u3044\u308b\u3068\u611f\u3058\u307e\u3059\u3002\n\n\u4e00\u3064\u4e00\u3064\u306e\u753b\u50cf\u3092\u898b\u3066\u3044\u304f\u3068\u3001\u7a7a\u3084\u6d77\u306f\u3046\u307e\u304f\u8a8d\u8b58\u3057\u3066\u7dba\u9e97\u306b\u8272\u3092\u8f09\u305b\u3066\u304f\u308c\u308b\u50be\u5411\u306b\u3042\u308a\u305d\u3046\u3067\u3059\u3002\u3067\u3059\u304c\u9752\u7a7a\u3068\u5915\u713c\u3051\u306e\u533a\u5225\u306f\u96e3\u3057\u3044\u307f\u305f\u3044\u3067\u3059\u306d\u3002\u5c0f\u52d5\u7269\u304c\u5199\u3063\u3066\u3044\u308b\u3068\u601d\u3057\u304d\u4e00\u756a\u53f3\u4e0b\u306e\u753b\u50cf\u306b\u3064\u3044\u3066\u306f\u3001\u5730\u9762\u3092\u8a8d\u8b58\u3057\u3066\u8336\u8272\u3084\u8349\u306e\u8272\u3092\u518d\u73fe\u3057\u3066\u3044\u307e\u3059\u3002\u304c\u3001\u6b63\u89e3\u3068\u6bd4\u3079\u308b\u3068\u3061\u3087\u3063\u3068\u8349\u751f\u3084\u3057\u3059\u304e\u3067\u3059\u306d\u3002\n\n##\u6d3b\u6027\u5316\u95a2\u6570\u306e\u9055\u3044\u306b\u3088\u308b\u5909\u5316\n\u4e0a\u306b\u6319\u3052\u305f\u753b\u50cf\u306f\u6d3b\u6027\u5316\u95a2\u6570\u306belu\u3092\u4f7f\u7528\u3057\u305f\u969b\u306e\u3082\u306e\u3067\u3059\u3002\u6d3b\u6027\u5316\u95a2\u6570\u306brelu\u3084leaky_relu\u3092\u4f7f\u7528\u3059\u308b\u3068\u3001\u4ed5\u4e0a\u304c\u308a\u306b\u3069\u306e\u3088\u3046\u306a\u5909\u5316\u304c\u3042\u308b\u304b\u3082\u8abf\u3079\u3066\u307f\u307e\u3057\u305f\u3002n_ch\u304c512\u306e\u7573\u307f\u8fbc\u307fNN, 30 epoch\u3067\u306e\u7d50\u679c\u306e\u307f\u7d39\u4ecb\u3057\u307e\u3059\u3002\n\nrelu\n![30epochRelu512ch.png](https://qiita-image-store.s3.amazonaws.com/0/69692/3b49cc9b-ae00-fdb8-b9f8-e40932d84f55.png)\n\nleaky_relu\n![30epoch512ch.png](https://qiita-image-store.s3.amazonaws.com/0/69692/a570a19b-a78f-c49f-1280-74affc99759e.png)\n\nelu\n![30epochELU512ch.png](https://qiita-image-store.s3.amazonaws.com/0/69692/26aca1a4-b311-a67f-ff44-634c94c557ea.png)\n\nrelu\u306f\u9bae\u3084\u304b\u306b\u4ed5\u4e0a\u304c\u3063\u3066\u3044\u307e\u3059\u304c\u82e5\u5e72\u307c\u3084\u3051\u305f\u5370\u8c61\u3067\u3059\u3002elu\u3084leaky relu\u306f\u753b\u50cf\u306e\u9bae\u660e\u3055\u3067relu\u3088\u308a\u512a\u79c0\u305d\u3046\u3067\u3059\u3002leaky relu\u306felu\u3068relu\u306e\u4e2d\u9593\u304f\u3089\u3044\u306e\u5370\u8c61\u3092\u611f\u3058\u307e\u3059\u3002\n\n#\u4f7f\u7528\u3057\u305f\u30b3\u30fc\u30c9\u306e\u5168\u4f53\n```py3\n#! /usr/bin/env python\n# coding : utf-8\n\nimport argparse\nimport numpy as np\nfrom scipy.misc import imsave\nimport chainer\nimport chainer.functions as F\nimport chainer.links as L\nfrom chainer.training import extensions \n\n\nclass PreprocessedDataset(chainer.dataset.DatasetMixin):\n    def __init__(self, base_image_dataset):\n        self.base = base_image_dataset\n\n    def __len__(self):\n        return len(self.base)\n\n    def get_example(self, i):\n        color_image = self.base[i]\n        gray_image = np.ndarray((32, 32), dtype=np.float32)\n        for ch in range(3):\n            # \u8f1d\u5ea6\u3092\u8a08\u7b97\u3057\u3001\u30e2\u30ce\u30af\u30ed\u753b\u50cf\u3092\u4f5c\u6210\n            gray_image = (\n                0.298912*color_image[0]\n                + 0.586611*color_image[1]\n                + 0.114478*color_image[2]\n            )\n        return gray_image, color_image\n\nclass AIC_FC(chainer.Chain):\n    def __init__(self, n_units):\n        initializer = chainer.initializers.HeNormal()\n        super(AIC_FC, self).__init__(\n            fc_in = L.Linear(None, n_units),\n            bn1 = L.BatchNormalization(n_units),\n            fc2 = L.Linear(None, n_units),\n            bn2 = L.BatchNormalization(n_units),\n            fc_out = L.Linear(None, 32*32*3)\n        )\n\n    def __call__(self, x, t):\n        y = self.colorize(x)\n        loss = F.mean_squared_error(y, t)\n        chainer.reporter.report({\n            'loss': loss\n        })\n        return loss\n\n    def colorize(self, x, test=False):\n        h = F.elu(self.bn1(self.fc_in(x), test=test))\n        h = F.elu(self.bn2(self.fc2(h), test=test))\n        y = F.reshape(self.fc_out(h), (h.shape[0], 3, 32, 32))\n        return y\n\nclass AIC_DC(chainer.Chain):\n    def __init__(self, n_ch):\n        initializer = chainer.initializers.HeNormal()\n        super(AIC_DC, self).__init__(\n            cv_in = L.Convolution2D(1, n_ch//4, 4, 2, 1),\n            bn1 = L.BatchNormalization(n_ch//4),\n            cv1 = L.Convolution2D(n_ch//4, n_ch//2, 4, 2, 1),\n            bn2 = L.BatchNormalization(n_ch//2),\n            cv2 = L.Convolution2D(n_ch//2, n_ch, 4, 2, 1),\n            bn3 = L.BatchNormalization(n_ch),\n            cv3 = L.Convolution2D(n_ch, n_ch, 4, 2, 1),\n            bn4 = L.BatchNormalization(n_ch),\n            dc1 = L.Deconvolution2D(n_ch, n_ch, 4, 2, 1),\n            bn5 = L.BatchNormalization(n_ch),\n            dc2 = L.Deconvolution2D(n_ch, n_ch//2, 4, 2, 1),\n            bn6 = L.BatchNormalization(n_ch//2),\n            dc3 = L.Deconvolution2D(n_ch//2, n_ch//4, 4, 2, 1),\n            bn7 = L.BatchNormalization(n_ch//4),\n            dc_out = L.Deconvolution2D(n_ch//4, 3, 4, 2, 1, outsize=(32, 32))\n        )\n\n    def __call__(self, x, t):\n        y = self.colorize(x)\n        loss = F.mean_squared_error(y, t)\n        chainer.reporter.report({\n            'loss': loss\n        })\n        return loss\n\n    def colorize(self, x, test=False):\n        # Convolution\u5c64\u306b\u5165\u529b\u3059\u308b\u305f\u3081\u3001ndim\u304c4\u306b\u306a\u308b\u3088\u3046\u306breshape\n        h = F.reshape(x, (x.shape[0], 1, 32, 32))\n        h = F.elu(self.bn1(self.cv_in(h), test=test))\n        h = F.elu(self.bn2(self.cv1(h), test=test))\n        h = F.elu(self.bn3(self.cv2(h), test=test))\n        h = F.elu(self.bn4(self.cv3(h), test=test))\n        h = F.elu(self.bn5(self.dc1(h), test=test))\n        h = F.elu(self.bn6(self.dc2(h), test=test))\n        h = F.elu(self.bn7(self.dc3(h), test=test))\n        y = self.dc_out(h)\n        return y\n\n\ndef main():\n    parser = argparse.ArgumentParser(description='Automatic Image Colorization')\n    parser.add_argument('--batchsize', '-b', type=int, default=64,\n                        help='Number of images in each mini-batch')\n    parser.add_argument('--epoch', '-e', type=int, default=30,\n                        help='Number of sweeps over the dataset to train')\n    parser.add_argument('--gpu', '-g', type=int, default=0,\n                        help='GPU ID (negative value indicates CPU)')\n    parser.add_argument('--resume', '-r', default='',\n                        help='Resume the training from snapshot')\n    parser.add_argument('--n_ch', '-nc', type=int, default=1024,\n                        help='Number of channels')\n    parser.add_argument('--n_units', '-nu', type=int, default=0,\n                        help='Number of units')\n    args = parser.parse_args()\n    print('# GPU: {}'.format(args.gpu))\n    print('# Minibatch-size: {}'.format(args.batchsize))\n    print('# epoch: {}'.format(args.epoch))\n\n    if args.n_units > 0:\n        print('# n_units: {}\\n'.format(args.n_units))\n        model = AIC_FC(args.n_units)\n    else:\n        print('# n_ch: {}\\n'.format(args.n_ch))\n        model = AIC_DC(args.n_ch)\n    if args.gpu >= 0:\n        chainer.cuda.get_device().use()\n        model.to_gpu()\n\n    opt = chainer.optimizers.Adam()\n    opt.setup(model)\n\n    train, test = chainer.datasets.get_cifar100(withlabel=False)\n    test_img = (\n        0.298912*test[:64,0]\n        + 0.586611*test[:64,1]\n        + 0.114478*test[:64,2]\n    )\n    # 64\u679a\u306e\u753b\u50cf\u30928x8\u306b\u4e26\u3093\u3060\u4e00\u679a\u306e\u753b\u50cf\u3068\u3057\u3066\u4fdd\u5b58\u3059\u308b\n    imsave(\n        'test.png',\n        test[:64]\n        .transpose(0, 2, 3, 1)\n        .reshape((8, 8, 32, 32, 3))\n        .transpose(1, 2, 0, 3, 4)\n        .reshape(8*32, 8*32, 3)\n    )\n    imsave(\n        'test_gray.png',\n        test_img\n        .reshape((8, 8, 32, 32))\n        .transpose(1, 2, 0, 3)\n        .reshape(8*32, 8*32)\n    )\n    if args.gpu >= 0:\n        test_img = chainer.cuda.to_gpu(test_img)\n\n\n    dataset = PreprocessedDataset(train)\n    iterator = chainer.iterators.MultiprocessIterator(dataset, args.batchsize)\n\n    updater = chainer.training.StandardUpdater(iterator, opt, device=args.gpu)\n    trainer = chainer.training.Trainer(updater, (args.epoch, 'epoch'))\n\n    trainer.extend(extensions.LogReport())\n    trainer.extend(extensions.PrintReport([\n        'epoch', 'loss', 'elapsed_time'\n    ]))\n    @chainer.training.make_extension(trigger=(10, 'epoch'))\n    def test_model(trainer):\n        # \u5024\u57df\u30920~1\u306b\u3059\u308b\u305f\u3081\u3001clipped_relu\u3092\u901a\u3059\n        colorized_img = chainer.cuda.to_cpu(F.clipped_relu(model.colorize(test_img, test=True), z=1.0).data)\n        imsave(\n            'test_colorized{}.png'.format(trainer.updater.epoch),\n            colorized_img\n            .transpose(0, 2, 3, 1)\n            .reshape((8, 8, 32, 32, 3))\n            .transpose(1, 2, 0, 3, 4)\n            .reshape(8*32, 8*32, 3)\n        )\n    trainer.extend(test_model)\n    trainer.extend(extensions.ProgressBar(update_interval=100))\n\n    trainer.run()\n\nif __name__ == '__main__':\n    main()\n```\n"}