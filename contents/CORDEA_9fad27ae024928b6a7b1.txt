{"context": " More than 1 year has passed since last update.\n\n\u74b0\u5883\nDocker\u3067\u65b0\u3057\u304f\u4f5c\u6210\u3057\u305fUbuntu\u30b3\u30f3\u30c6\u30ca\n\n\nCentOS release 6.6\n\nDocker version 1.3.2, build 39fa2fa/1.3.2\n\n\nUbuntu 14.04\n\n\n\n\nCaffe 3e12d49324793d4798ee10bb6ef6a1c1b7633baf (git log | head -n 1)\nPylearn2 9870dec593c71c194ebc2044973f65acc32c8675\n\n\nDocker Hub\n\u3068\u308a\u3042\u3048\u305a\u304a\u8a66\u3057\u3067\u4f7f\u3063\u3066\u307f\u305f\u3044\u3068\u3044\u3046\u65b9\u306b\u5411\u3051\u3066\u3001Caffe(python wrapper\u542b\u3080), Pylearn2\u306e\u305d\u308c\u305e\u308c\u306e\u74b0\u5883\u69cb\u7bc9\u3092\u884c\u3063\u305fDocker\u30b3\u30f3\u30c6\u30ca\u3092Docker Hub\u306b\u516c\u958b\u3057\u307e\u3057\u305f\u3002\n\u8a73\u7d30\u306f\u30ea\u30dd\u30b8\u30c8\u30ea\u306eInformation\u3092\u3054\u53c2\u7167\u4e0b\u3055\u3044\u3002\n\nCaffe\n\nbash\n# docker pull cordea/pycaffe\n\n\n\u3053\u306e\u8a18\u4e8b\u3067\u8a00\u3046\u3068\"make\"\u307e\u3067\u7d42\u4e86\u3057\u3066\u3044\u308b\u72b6\u614b\u306e\u30b3\u30f3\u30c6\u30ca\u3067\u3059\u3002\n\nPylearn2\n\nbash\n# docker pull cordea/pylearn2\n\n\n\"path\"\u307e\u3067\u7d42\u4e86\u3057\u3066\u3044\u308b\u72b6\u614b\u306e\u30b3\u30f3\u30c6\u30ca\u3067\u3059\u3002\n\n\u5171\u901a\n\nCreate user\nroot\u3067\u3082\u3044\u3044\u3063\u3066\u4eba\u306f\u98db\u3070\u3057\u3066\u4e0b\u3055\u3044\u3002\n\nbash\n# username=\"your user name\"\n# adduser --disabled-password --gecos '' $username\n# adduser $username sudo\n# echo '%sudo ALL=(ALL) NOPASSWD:ALL' >> /etc/sudoers\n# su $username\n\n\n\u57fa\u672c\u3060\u3051\u3068\u308a\u3042\u3048\u305ainstall\n\u4ed6\u306b\u3082\u5171\u901a\u306e\u30d1\u30c3\u30b1\u30fc\u30b8\u306f\u3042\u308a\u307e\u3059\u304c...\n$ sudo apt-get update\n$ sudo apt-get install python vim git wget\n\n\nCaffe\n\u4eca\u56de\u306f CPU\u30e2\u30fc\u30c9 \u3067\u52d5\u4f5c\u3055\u305b\u308b\u305f\u3081\u3001NVIDIA Graphics Driver\u306f\u30a4\u30f3\u30b9\u30c8\u30fc\u30eb\u3057\u307e\u305b\u3093\u3002\n\nInstallation\n$ sudo apt-get install make bc libprotobuf-dev libleveldb-dev libsnappy-dev libopencv-dev libboost-all-dev libhdf5-serial-dev libblas-dev libatlas-base-dev libgflags-dev libgoogle-glog-dev liblmdb-dev protobuf-compiler libsvm-dev libsvm3 libsvm-tools\n\n\nPyCaffe\nAnaconda Python\u304c\u63a8\u5968\u3055\u308c\u3066\u3044\u307e\u3059\u304cLinux\u3060\u3068\u9762\u5012\u306a\u306e\u306f\u3069\u3061\u3089\u3067\u3082\u5909\u308f\u3089\u306a\u3044\u306e\u3067\u4eca\u56de\u306f\u4f7f\u3044\u307e\u305b\u3093\u3002\n\u516c\u5f0f\u306e\u901a\u308apip\u3067\u5165\u308c\u308b\u306a\u3089 (\u304a\u305d\u3089\u304f\u8ffd\u52a0\u3067gfortran\u306einstall\u304c\u5fc5\u8981\u3067\u3059)\n$ sudo apt-get install python-pip\n$ cd ~/caffe/python/\n$ for req in $(cat requirements.txt); do sudo pip install $req; done\n\n\u51fa\u6765\u308b\u3060\u3051apt-get\u3067\u7ba1\u7406\u3057\u305f\u3044\u306a\u3089\n$ sudo apt-get install python-pip python-scipy python-matplotlib python-scikits-learn ipython python-h5py python-leveldb python-networkx python-nose python-pandas python-dateutil python-protobuf python-yaml python-gflags python-skimage cython\n\n\nCUDA\n$ cd ~\n$ cd \n$ chmod u+x cuda_6.5.14_linux_64.run \n$ ./cuda_6.5.14_linux_64.run \nDo you accept the previously read EULA? (accept/decline/quit): accept\nInstall NVIDIA Accelerated Graphics Driver for Linux-x86_64 340.29? ((y)es/(n)o/(q)uit): n\nInstall the CUDA 6.5 Toolkit? ((y)es/(n)o/(q)uit): y\nEnter Toolkit Location [ default is /usr/local/cuda-6.5 ]: \n/usr/local/cuda-6.5 is not writable.\nDo you wish to run the installation with 'sudo'? ((y)es/(n)o): y\nDo you want to install a symbolic link at /usr/local/cuda? ((y)es/(n)o/(q)uit): y\nInstall the CUDA 6.5 Samples? ((y)es/(n)o/(q)uit): n\nInstalling the CUDA Toolkit in /usr/local/cuda-6.5 ...\n\n===========\n= Summary =\n===========\n\nDriver:   Not Selected\nToolkit:  Installed in /usr/local/cuda-6.5\nSamples:  Not Selected\n\n$ sudo ldconfig /usr/local/cuda-6.5/lib64/\n$ rm cuda_6.5.14_linux_64.run\n\n\nmake\n$ git clone https://github.com/BVLC/caffe\n$ cd caffe/\n$ cp Makefile.config.example Makefile.config  \n$ echo \"CPU_ONLY := 1\" >> Makefile.config # 1/26 \u8ffd\u8a18   \n$ make all\n$ make test\n$ make runtest\n\n...\n\n[----------] Global test environment tear-down\n[==========] 457 tests from 98 test cases ran. (14811 ms total)\n[  PASSED  ] 457 tests.\n\n\nTutorial\n$ vim examples/mnist/lenet_solver.prototxt\n\n$ ./data/mnist/get_mnist.sh \n$ ./examples/mnist/create_mnist.sh\n$ ./examples/mnist/train_lenet.sh \n\n\nPyCaffe Tutorials\nCaffe\u3067\u624b\u8efd\u306b\u753b\u50cf\u5206\u985e\u306b\u5f93\u3063\u3066Tutorial\u3092\u884c\u3044\u307e\u3059\u3002\n$ cd ~/caffe/examples/imagenet/\n$ wget https://raw.githubusercontent.com/sguada/caffe-public/master/models/get_caffe_reference_imagenet_model.sh\n$ chmod u+x get_caffe_reference_imagenet_model.sh\n$ ./get_caffe_reference_imagenet_model.sh\n$ cd ~/caffe/data/ilsvrc12/\n$ ./get_ilsvrc_aux.sh\n$ cd ~/caffe/\n$ wget http://www.vision.caltech.edu/Image_Datasets/Caltech101/101_ObjectCategories.tar.gz\n$ tar xzvf 101_ObjectCategories.tar.gz\n\n$ echo \"export PYTHONPATH=$HOME/caffe/python:$PYTHONPATH\" >> ~/.bashrc\n$ source ~/.bashrc\n\n\n\u5b9f\u884c\n\n\u30ea\u30d5\u30a1\u30ec\u30f3\u30b9\u30e2\u30c7\u30eb\u3067\u306e\u5206\u985e\n$ cd ~/caffe/python/\n$ python classify.py --raw_scale 255 ../101_ObjectCategories/airplanes/image_0001.jpg ../result.npy\n\n\u4e0a\u306e\u30ea\u30f3\u30af\u306b\u5f93\u3063\u3066show_result.py\u3092\u4f5c\u6210\u3057\u3001\u5b9f\u884c\u3057\u307e\u3059\u3002\n$ cd ~/caffe/\n$ python show_result.py data/ilsvrc12/synset\nsynset_words.txt  synsets.txt       \n$ python show_result.py data/ilsvrc12/synset_words.txt result.npy \n#1 | n04552348 warplane, military plane | 84.8%\n#2 | n04008634 projectile, missile |  5.5%\n#3 | n02690373 airliner |  5.1%\n\n\nclassify.py\u3067\u30a8\u30e9\u30fc\u304c\u51fa\u305f\u5834\u5408\nnumpy\u306eio\u3068PyCaffe\u306eio.py\u304c\u7af6\u5408\u3059\u308b\u3088\u3046\u3067\u3059\u3002(Strange Issue using Python #782)\n$ python classify.py --raw_scale 255 ~/caffe/101_ObjectCategories/airplanes/image_0001.jpg ../result.npy\nTraceback (most recent call last):\n  File \"classify.py\", line 7, in <module>\n    import numpy as np\n\n...\n\n\n  File \"/usr/local/lib/python2.7/dist-packages/skimage/util/dtype.py\", line 8, in <module>\n    dtype_range = {np.bool_: (False, True),\nAttributeError: 'module' object has no attribute 'bool_'\n\n\u7121\u7406\u3084\u308a\u306a\u65b9\u6cd5\u3067\u3059\u304cio.py\u3092caffe_io.py\u306brename\u3057\u307e\u3059\u3002\n\u3053\u3053\u3067rename\u3057\u305f\u5834\u5408\u306b\u306f\u3001\u6b21\u306e\"Caffe\u3092\u7279\u5fb4\u62bd\u51fa\u5668\u3068\u3057\u3066\u4f7f\u3063\u305f\u5206\u985e\"\u306b\u4f5c\u6210\u3059\u308bfeature.py\u3067\u3082rename\u3059\u308b\u5fc5\u8981\u304c\u3042\u308a\u307e\u3059\u3002\n$ cd ~/caffe/python/\n$ aftfile=\"caffe_io\"\n$ for file in `find . -name \"*.py\"`; do; cat $file | sed -e \"s/import [\\w\\.]*io/import $aftfile/g\" | sed -e \"s/caffe\\.io/caffe\\.$aftfile/g\" > $file\".tmp\";mv $file\".tmp\" $file; done\n$ mv \"caffe/io.py\" \"caffe/\"$aftfile\".py\"\n\n\u3000\n\nCaffe\u3092\u7279\u5fb4\u62bd\u51fa\u5668\u3068\u3057\u3066\u4f7f\u3063\u305f\u5206\u985e\n\u524d\u306e\u30d6\u30e9\u30f3\u30c1\u306b\u5207\u308a\u66ff\u3048\u305f\u307e\u307e\u623b\u3059\u306e\u3092\u3059\u3063\u304b\u308a\u5fd8\u308c\u3066\u3044\u305f\u306e\u3067\u3001\u3082\u3057\u304b\u3057\u305f\u3089\u5c11\u3057\u9055\u3046\u90e8\u5206\u304c\u3042\u308b\u304b\u3082\u3057\u308c\u307e\u305b\u3093\u3002\n$ cd ~/caffe\n$ cp examples/imagenet/imagenet_deploy.prototxt examples/imagenet/imagenet_feature.prototxt\n$ vim examples/imagenet/imagenet_feature.prototxt\n\n\u6b21\u306e\u3088\u3046\u306bimagenet_feature.prototxt\u3092\u5909\u66f4\u3057\u3066\u4e0b\u3055\u3044\u3002\n\nimagenet_feature.prototxt\n...\n\n154   top: \"fc6wi\"\n\n...\n\n162   bottom: \"fc6wi\"\n\n...\n\n\n\u3000deeplearning-tutorials\nlibsvm format\u3067\u7279\u5fb4\u91cf\u3092\u4e26\u3079\u305f\u30d5\u30a1\u30a4\u30eb\u3092\u4f5c\u6210\u3057\u307e\u3059\u3002\n$ cd ~/caffe/\n$ git clone https://github.com/CORDEA/deeplearning-tutorials\n$ mv ~/caffe/deeplearning-tutorials/caffe/feature.py ~/caffe/\n$ python feature.py\n\n\u3082\u3057\u304f\u306f\n$ cd ~/caffe/\n$ wget https://raw.githubusercontent.com/CORDEA/deeplearning-tutorials/master/caffe/feature.py\n$ python feature.py\n\ntraincommand\u306fsvm-train\u306b\npredictcommand\u306fsvm-predict\u306b\n\u305d\u308c\u305e\u308c\u540d\u524d\u304c\u5909\u308f\u3063\u3066\u3044\u307e\u3059\u306e\u3067\u6ce8\u610f\u3057\u3066\u4e0b\u3055\u3044\u3002\n$ svm-scale -s scale.txt train.txt > train_scaled.txt\n$ svm-scale -r scale.txt test.txt > test_scaled.txt\n$ svm-train -c 0.03 train_scaled.txt caltech101.model\n\n\nFine tuning\n\u5fc5\u8981\u306a\u30d5\u30a1\u30a4\u30eb\u3092\u7528\u610f\u3057\u307e\u3059\u3002\n\"Caffe\u3092\u7279\u5fb4\u62bd\u51fa\u5668\u3068\u3057\u3066\u4f7f\u3063\u305f\u5206\u985e\"\u3067git clone\u3057\u305f\u5834\u5408\n$ cd ~/caffe/\n$ mv ~/caffe/deeplearning-tutorials/caffe/fine_tuning.py ~/caffe/\n$ python fine_tuning.py\n\nwget\u3059\u308b\u5834\u5408\n$ cd ~/caffe/\n$ wget https://raw.githubusercontent.com/CORDEA/deeplearning-tutorials/master/caffe/fine_tuning.py\n$ python fine_tuning.py\n\nconvert_imageset.bin\u306e\u4ed5\u69d8\u304c\u5909\u308f\u3063\u3066\u3044\u308b\u306e\u3067\u53c2\u8003\u8a18\u4e8b\u306e\u901a\u308a\u3067\u306f\u52d5\u4f5c\u3057\u307e\u305b\u3093\u3002\n\u53c2\u8003\u8a18\u4e8b\u3067\u6307\u5b9a\u3055\u308c\u3066\u3044\u308bflag\u306e1\u304c\u73fe\u5728\u306e\u3069\u308c\u306b\u5f53\u305f\u308b\u304b\u308f\u304b\u308a\u307e\u305b\u3093\u304c\u3001\u304a\u305d\u3089\u304f-gray\u3060\u308d\u3046\u3068\u5224\u65ad\u3057\u3066\u9032\u3081\u3066\u3044\u307e\u3059\u3002\n$ build/tools/convert_imageset.bin -gray -resize_width 256 -resize_height 256 101_ObjectCategories/ train.txt caltech101_train_leveldb\n$ build/tools/convert_imageset.bin -gray -resize_width 256 -resize_height 256 101_ObjectCategories/ val.txt caltech101_val_leveldb\n$ build/tools/compute_image_mean.bin caltech101_train_leveldb caltech101_mean.binaryproto\n\n\u53c2\u8003\u8a18\u4e8b\u304b\u3089\u53c2\u7167\u5148\u304c\u5909\u308f\u3063\u3066\u3044\u307e\u3059\u306e\u3067\u6c17\u3092\u3064\u3051\u3066\u4e0b\u3055\u3044\u3002\n$ cp ~/caffe/models/bvlc_reference_caffenet/*.prototxt ~/caffe/\n$ cd ~/caffe/\n$ sed -i -e 's/fc8/fc8ft/g' train_val.prototxt deploy.prototxt\n\n\u4ee5\u4e0b\u306e\u90e8\u5206\u3092\u30a8\u30c7\u30a3\u30bf(vi\u3068\u304b)\u3067\u5909\u66f4\u3057\u3066\u4e0b\u3055\u3044\u3002\n\nsolver.prototxt\n1 net: \"train_val.prototxt\"\n\n...\n\n4 base_lr: 0.001\n\n...\n\n14 solver_mode: CPU\n\n\n\ntrain_val.prototxt\n8     source: \"caltech101_train_leveldb\"\n9     backend: LEVELDB\n\n...\n\n14     mean_file: \"caltech101_mean.binaryproto\"\n\n...\n\n25     source: \"caltech101_val_leveldb\"\n26     backend: LEVELDB\n\n...\n\n31     mean_file: \"caltech101_mean.binaryproto\"\n\n...\n\n321     num_output: 102\n\n\n\ndeploy.prototxt\n5 input_dim: 256\n6 input_dim: 256\n\n...\n\n204     num_output: 102\n\n\n$ build/tools/caffe train -solver solver.prototxt\n\n\u3000\n\u3000\n\nPylearn2\n\nInstallation\n$ sudo apt-get install python-setuptools python-pip python-dev python-numpy python-scipy python-yaml python-matplotlib liblapack-dev python-nose2 cython\n\n$ sudo pip install theano\n\n$ cd ~\n$ git clone https://github.com/lisa-lab/pylearn2.git\n$ cd pylearn2\n$ sudo python setup.py develop\n\n\npath\n$ echo \"export PATH=$HOME/pylearn2/pylearn2/scripts/:$PATH\" >> ~/.bashrc\n$ echo \"export PYLEARN2_DATA_PATH=$HOME/.data/lisa/data\" >> ~/.bashrc\n$ source ~/.bashrc\n\n\nTutorials\n\nGaussian-Bernoulli RBM examples using CIFAR10\n$ cd ~/pylearn2/pylearn2/scripts/datasets/\n$ ./download_cifar10.sh\n$ cd ~/pylearn2/pylearn2/scripts/tutorials/grbm_smd/\n$ python make_dataset.py\n$ train.py cifar_grbm_smd.yaml\n$ show_weights.py cifar_grbm_smd.pkl --out weights_result.png # GUI\u304c\u3042\u308b\u5834\u5408\u306f --out \u306f\u7121\u304f\u3066\u3082\u826f\u3044\n$ plot_monitor.py cifar_grbm_smd.pkl --out monitor_result.png\nPut e, b, s or h in the list somewhere to plot epochs, batches, seconds, or hours, respectively.\nEnter a list of channels to plot (example: A, C,F-G, h, <test_err>) or q to quit or o for options: b,L,M\nset x_axis to example\nA. bias_hid_max:cifar_grbm\nB. bias_hid_mean:cifar_grbm\nC. bias_hid_min:cifar_grbm\nD. bias_vis_max:cifar_grbm\nE. bias_vis_mean:cifar_grbm\nF. bias_vis_min:cifar_grbm\nG. h_max:cifar_grbm\nH. h_mean:cifar_grbm\nI. h_min:cifar_grbm\nJ. learning_rate:cifar_grbm\nK. objective:cifar_grbm\nL. reconstruction_error:cifar_grbm\nM. total_seconds_last_epoch:cifar_grbm\nN. training_seconds_this_epoch:cifar_grbm\n\nPut e, b, s or h in the list somewhere to plot epochs, batches, seconds, or hours, respectively.\nEnter a list of channels to plot (example: A, C,F-G, h, <test_err>) or q to quit or o for options: q\n\n\nimage\u306e\u78ba\u8a8d\ndocker\u3067\u52d5\u4f5c\u3055\u305b\u3066\u3044\u308b\u5834\u5408\ndocker cp\u3067local\u306bcopy\u3057\u3066\u308b\u3060\u3051\n% container=\"pylearn2\" # Enter the container ID or name\n% for file in `echo weights_result.png monitor_result.png`;do;docker cp $container:/home/cordea/pylearn2/pylearn2/scripts/tutorials/grbm_smd/$file /host/path/to/dir/;done\n% open *.png # for Mac\n\n\nSdA examples using MNIST\n$ cd ~/pylearn2/pylearn2/scripts/datasets/\n$ python download_mnist.py\n$ cd ~/pylearn2/pylearn2/scripts/tutorials/stacked_autoencoders/tests\n$ python test_dae.py\n\n\n\u81ea\u5206\u306e\u7528\u610f\u3057\u305f\u30c7\u30fc\u30bf\u3092\u4f7f\u3046\ncsv\u3092\u305d\u306e\u307e\u307e\u4f7f\u7528\u3059\u308b\u306a\u3089\u3053\u3061\u3089\u304c\u53c2\u8003\u306b\u306a\u308a\u307e\u3059\u3002\n\u4eca\u56de\u306fcsv\u304b\u3089pkl\u3092\u4f5c\u6210\u3059\u308b\u65b9\u6cd5\u3092\u7d39\u4ecb\u3057\u307e\u3059\u3002\n\u753b\u50cf\u3092resize, gray-scale\u5316\u3057\u305f\u4e0a\u3067csv\u306b\u5909\u63db\u3057\u307e\u3059\u3002\n$ cd ~\n$ git clone https://github.com/CORDEA/deeplearning-tutorials.git\n$ cd deeplearning-tutorials/pylearn2\n$ mkdir in\n\nconvertImage.py\u306f\u4ee5\u4e0b\u306e\u69d8\u306a\u30c7\u30a3\u30ec\u30af\u30c8\u30ea\u69cb\u9020\u3092\u60f3\u5b9a\u3057\u3066\u4f5c\u6210\u3057\u3066\u3044\u307e\u3059\u3002\n\u30c7\u30a3\u30ec\u30af\u30c8\u30ea\u540d\u3092\u30e9\u30d9\u30eb\u60c5\u5831\u3068\u3057\u3066\u4e0b\u3055\u3044\u3002\n.\n\u251c\u2500\u2500 convertImage.py\n    \u251c\u2500\u2500 in\n        \u251c\u2500\u2500 hoge # label name\n        |   \u251c\u2500\u2500 hogehoge.png\n        |   ...\n        |\n        \u251c\u2500\u2500 huge\n        |   \u251c\u2500\u2500 hugehuge.png\n        |   ...\n        ...\n\n$ python convertImage.py\n\n\u4f5c\u6210\u3057\u305ftrain.csv\u3092pkl\u30d5\u30a1\u30a4\u30eb\u306b\u3057\u307e\u3059\u3002\n$ python createpkl.py\n\ntrain.pkl\u3092~/pylearn2/pylearn2/scripts/tutorials/\u306e\u30b5\u30f3\u30d7\u30eb\u3092\u53c2\u8003\u306b\u3057\u3066\u4f7f\u7528\u3059\u308c\u3070\u4f7f\u3048\u308b\u304b\u3068\u601d\u3044\u307e\u3059\u3002\n\n\u4f8b\n\u30af\u30e9\u30b9\u6570\u306f10\u3068\u3057\u3066\u4f8b\u793a\u3057\u307e\u3059\u3002\n$ cd ~/pylearn2/pylearn2/scripts/tutorials/dbm_demo/\n$ cp ~/deeplearning-tutorials/pylearn2/train.pkl ./\n\n\nrbm.yaml\n13,21c13\n<     dataset: &data !obj:pylearn2.datasets.binarizer.Binarizer {\n<         # We use the \"raw\" tag to specify the underlying dataset defining\n<         # the sampling probabilities should be MNIST.\n<         raw: &raw_train !obj:pylearn2.datasets.mnist.MNIST {\n<             which_set: \"train\",\n<             start: 0,\n<             stop: %(train_stop)i\n<         }\n<     },\n---\n>     dataset: !pkl: \"train.pkl\",\n\n\n\ntrain_dbm.py\n22     hyper_params = {'detector_layer_dim': 10,\n\n\n$ python train_dbm.py rbm.yaml\n$ show_weights.py dbm.pkl --out figure.png\n\n\n\u30a8\u30e9\u30fc\n\npylearn2/pylearn2/space/__init__.py\n794                 raise TypeError(Cannot safely cast batch dtype %s to space's dtype %s. % (batch.dtype, self.dtype))\n\n\n\u3053\u3053\u3067\u30a8\u30e9\u30fc\u304c\u51fa\u305f\u306e\u3067\u3059\u304c\u3001\u30c7\u30fc\u30bf\u306e\u65b9\u3092\u5f04\u3063\u3066\u3082\u3044\u307e\u3044\u3061\u4e0a\u624b\u304f\u884c\u304b\u306a\u304b\u3063\u305f\u306e\u3067\n\npylearn2/pylearn2/space/__init__.py\n794                 # raise TypeError(\"Cannot safely cast batch dtype %s to \"\n795                 print \"Might not be safely cast batch dtype %s to space's dtype %s.\" \\\n796                         % (batch.dtype, self.dtype)\n\n\n\npylearn2/pylearn2/format/target_format.py\n 98             try:\n 99                 print \"Run the conversion to int64 from %s\" % (targets.dtype)\n100                 targets = np.array([[int(r) for r in label] for label in targets])\n101             except:\n102                 raise TypeError(\"need an integer array for targets, %s\" % (targets.dtype))\n\n\n\u4eca\u306e\u3068\u3053\u308d\u3053\u3093\u306a\u304b\u3093\u3058\u3067\u7121\u7406\u3084\u308a\u52d5\u304b\u3057\u3066\u3044\u307e\u3059...\n\u304a\u75b2\u308c\u69d8\u3067\u3057\u305f\u3002\n\n\u53c2\u8003\n\nCaffe\n\n\nCaffe\n\nInstallation\nTraining LeNet on MNIST with Caffe\n\n\nCaffe\u3067\u624b\u8efd\u306b\u753b\u50cf\u5206\u985e - Yahoo! \u30c7\u30d9\u30ed\u30c3\u30d1\u30fc\u30cd\u30c3\u30c8\u30ef\u30fc\u30af\n\u306f\u3058\u3081\u308bDeep learning\n\n\nPylearn2\n\n\nPylearn2 dev documentation\n\nDownload and installation\nLibrary Documentation\nQuick-start example\n\n\n\nFastML\n\nPylearn2 in practice\nHow to get predictions from Pylearn2\n\n\nJSAI's AI Tool Introduction - Deep Learning and Pylearn2\npylearn2 \u5165\u9580\u3057\u305f\u3044\u7de8 - laughing\u306e\u30d6\u30ed\u30b0\nCaffe\u3067Deep Learning \u3064\u307e\u305a\u304d\u3084\u3059\u3044\u3068\u3053\u308d\u3092\u4e2d\u5fc3\u306b\nPylearn2\u3092\u4f7f\u3063\u3066\u624b\u66f8\u304d\u6587\u5b57\u8a8d\u8b58\u3092\u884c\u3046\n\u4eca\u30ca\u30a6\u3044\u30c7\u30a3\u30fc\u30d7\u30e9\u30fc\u30cb\u30f3\u30b0\u306e\u30e9\u30a4\u30d6\u30e9\u30ea\u300cPylearn2\u300d\u306e\u30a4\u30f3\u30b9\u30c8\u30fc\u30eb\u3068\u30c1\u30e5\u30fc\u30c8\u30ea\u30a2\u30eb\n\u7537\u306e\u305f\u3081\u306e\u6a5f\u68b0\u5b66\u7fd2\u301cRBM\u3067A\u25ef\u5973\u512a\u3055\u3093\u306e\u5171\u901a\u7279\u5fb4\u91cf\u3092\u5f97\u3088\u3046\u301c - \u65b0kensuke-mi\u306e\u65e5\u8a18\nPython/PIL\u306b\u3088\u308b\u753b\u50cf\u306e\u30b0\u30ec\u30a4\u30b9\u30b1\u30fc\u30eb\u5316\u3068\u30a2\u30b9\u30ad\u30fc\u30a2\u30fc\u30c8\u5316 - Soleil cou coup\u00e9\n\n\n##\u74b0\u5883\nDocker\u3067\u65b0\u3057\u304f\u4f5c\u6210\u3057\u305fUbuntu\u30b3\u30f3\u30c6\u30ca\n\n- CentOS release 6.6\n\t- Docker version 1.3.2, build 39fa2fa/1.3.2\n\t\t- Ubuntu 14.04\n\n- Caffe 3e12d49324793d4798ee10bb6ef6a1c1b7633baf (`git log | head -n 1`)\n- Pylearn2 9870dec593c71c194ebc2044973f65acc32c8675\n\n##Docker Hub\n\n\u3068\u308a\u3042\u3048\u305a\u304a\u8a66\u3057\u3067\u4f7f\u3063\u3066\u307f\u305f\u3044\u3068\u3044\u3046\u65b9\u306b\u5411\u3051\u3066\u3001Caffe(python wrapper\u542b\u3080), Pylearn2\u306e\u305d\u308c\u305e\u308c\u306e\u74b0\u5883\u69cb\u7bc9\u3092\u884c\u3063\u305fDocker\u30b3\u30f3\u30c6\u30ca\u3092[Docker Hub](https://hub.docker.com/u/cordea/)\u306b\u516c\u958b\u3057\u307e\u3057\u305f\u3002\n\u8a73\u7d30\u306f\u30ea\u30dd\u30b8\u30c8\u30ea\u306eInformation\u3092\u3054\u53c2\u7167\u4e0b\u3055\u3044\u3002\n\n### Caffe\n\n```haskell:bash\n# docker pull cordea/pycaffe\n```\n\n\u3053\u306e\u8a18\u4e8b\u3067\u8a00\u3046\u3068\"make\"\u307e\u3067\u7d42\u4e86\u3057\u3066\u3044\u308b\u72b6\u614b\u306e\u30b3\u30f3\u30c6\u30ca\u3067\u3059\u3002\n\n### Pylearn2\n\n```haskell:bash\n# docker pull cordea/pylearn2\n```\n\n\"path\"\u307e\u3067\u7d42\u4e86\u3057\u3066\u3044\u308b\u72b6\u614b\u306e\u30b3\u30f3\u30c6\u30ca\u3067\u3059\u3002\n\n#\u5171\u901a\n\n## Create user\n\nroot\u3067\u3082\u3044\u3044\u3063\u3066\u4eba\u306f\u98db\u3070\u3057\u3066\u4e0b\u3055\u3044\u3002\n\n```haskell:bash\n# username=\"your user name\"\n# adduser --disabled-password --gecos '' $username\n# adduser $username sudo\n# echo '%sudo ALL=(ALL) NOPASSWD:ALL' >> /etc/sudoers\n# su $username\n```\n\n\u57fa\u672c\u3060\u3051\u3068\u308a\u3042\u3048\u305ainstall\n\u4ed6\u306b\u3082\u5171\u901a\u306e\u30d1\u30c3\u30b1\u30fc\u30b8\u306f\u3042\u308a\u307e\u3059\u304c...\n\n```bash\n$ sudo apt-get update\n$ sudo apt-get install python vim git wget\n```\n\n#Caffe\n\n\u4eca\u56de\u306f **CPU\u30e2\u30fc\u30c9** \u3067\u52d5\u4f5c\u3055\u305b\u308b\u305f\u3081\u3001NVIDIA Graphics Driver\u306f\u30a4\u30f3\u30b9\u30c8\u30fc\u30eb\u3057\u307e\u305b\u3093\u3002\n\n## Installation\n```bash\n$ sudo apt-get install make bc libprotobuf-dev libleveldb-dev libsnappy-dev libopencv-dev libboost-all-dev libhdf5-serial-dev libblas-dev libatlas-base-dev libgflags-dev libgoogle-glog-dev liblmdb-dev protobuf-compiler libsvm-dev libsvm3 libsvm-tools\n```\n\n### PyCaffe\n[Anaconda Python](https://store.continuum.io/cshop/anaconda/)\u304c\u63a8\u5968\u3055\u308c\u3066\u3044\u307e\u3059\u304cLinux\u3060\u3068\u9762\u5012\u306a\u306e\u306f\u3069\u3061\u3089\u3067\u3082\u5909\u308f\u3089\u306a\u3044\u306e\u3067\u4eca\u56de\u306f\u4f7f\u3044\u307e\u305b\u3093\u3002\n\n\u516c\u5f0f\u306e\u901a\u308a`pip`\u3067\u5165\u308c\u308b\u306a\u3089 (\u304a\u305d\u3089\u304f\u8ffd\u52a0\u3067`gfortran`\u306einstall\u304c\u5fc5\u8981\u3067\u3059)\n\n```bash\n$ sudo apt-get install python-pip\n$ cd ~/caffe/python/\n$ for req in $(cat requirements.txt); do sudo pip install $req; done\n```\n\n\u51fa\u6765\u308b\u3060\u3051`apt-get`\u3067\u7ba1\u7406\u3057\u305f\u3044\u306a\u3089\n\n```bash\n$ sudo apt-get install python-pip python-scipy python-matplotlib python-scikits-learn ipython python-h5py python-leveldb python-networkx python-nose python-pandas python-dateutil python-protobuf python-yaml python-gflags python-skimage cython\n```\n\n### CUDA\n\n```bash\n$ cd ~\n$ cd \n$ chmod u+x cuda_6.5.14_linux_64.run \n$ ./cuda_6.5.14_linux_64.run \nDo you accept the previously read EULA? (accept/decline/quit): accept\nInstall NVIDIA Accelerated Graphics Driver for Linux-x86_64 340.29? ((y)es/(n)o/(q)uit): n\nInstall the CUDA 6.5 Toolkit? ((y)es/(n)o/(q)uit): y\nEnter Toolkit Location [ default is /usr/local/cuda-6.5 ]: \n/usr/local/cuda-6.5 is not writable.\nDo you wish to run the installation with 'sudo'? ((y)es/(n)o): y\nDo you want to install a symbolic link at /usr/local/cuda? ((y)es/(n)o/(q)uit): y\nInstall the CUDA 6.5 Samples? ((y)es/(n)o/(q)uit): n\nInstalling the CUDA Toolkit in /usr/local/cuda-6.5 ...\n\n===========\n= Summary =\n===========\n\nDriver:   Not Selected\nToolkit:  Installed in /usr/local/cuda-6.5\nSamples:  Not Selected\n\n$ sudo ldconfig /usr/local/cuda-6.5/lib64/\n$ rm cuda_6.5.14_linux_64.run\n```\n\n###make\n\n\n```bash\n$ git clone https://github.com/BVLC/caffe\n$ cd caffe/\n$ cp Makefile.config.example Makefile.config  \n$ echo \"CPU_ONLY := 1\" >> Makefile.config # 1/26 \u8ffd\u8a18   \n$ make all\n$ make test\n$ make runtest\n\n...\n\n[----------] Global test environment tear-down\n[==========] 457 tests from 98 test cases ran. (14811 ms total)\n[  PASSED  ] 457 tests.\n```\n\n##Tutorial\n\n```bash\n$ vim examples/mnist/lenet_solver.prototxt\n```\n\n```bash\n$ ./data/mnist/get_mnist.sh \n$ ./examples/mnist/create_mnist.sh\n$ ./examples/mnist/train_lenet.sh \n```\n\n##PyCaffe Tutorials\n\n[Caffe\u3067\u624b\u8efd\u306b\u753b\u50cf\u5206\u985e](http://techblog.yahoo.co.jp/programming/caffe-intro/)\u306b\u5f93\u3063\u3066Tutorial\u3092\u884c\u3044\u307e\u3059\u3002\n\n\n```bash\n$ cd ~/caffe/examples/imagenet/\n$ wget https://raw.githubusercontent.com/sguada/caffe-public/master/models/get_caffe_reference_imagenet_model.sh\n$ chmod u+x get_caffe_reference_imagenet_model.sh\n$ ./get_caffe_reference_imagenet_model.sh\n$ cd ~/caffe/data/ilsvrc12/\n$ ./get_ilsvrc_aux.sh\n$ cd ~/caffe/\n$ wget http://www.vision.caltech.edu/Image_Datasets/Caltech101/101_ObjectCategories.tar.gz\n$ tar xzvf 101_ObjectCategories.tar.gz\n```\n\n```bash\n$ echo \"export PYTHONPATH=$HOME/caffe/python:$PYTHONPATH\" >> ~/.bashrc\n$ source ~/.bashrc\n```\n\n###\u5b9f\u884c\n\n####\u30ea\u30d5\u30a1\u30ec\u30f3\u30b9\u30e2\u30c7\u30eb\u3067\u306e\u5206\u985e\n\n```bash\n$ cd ~/caffe/python/\n$ python classify.py --raw_scale 255 ../101_ObjectCategories/airplanes/image_0001.jpg ../result.npy\n```\n\u4e0a\u306e\u30ea\u30f3\u30af\u306b\u5f93\u3063\u3066`show_result.py`\u3092\u4f5c\u6210\u3057\u3001\u5b9f\u884c\u3057\u307e\u3059\u3002\n\n```bash\n$ cd ~/caffe/\n$ python show_result.py data/ilsvrc12/synset\nsynset_words.txt  synsets.txt       \n$ python show_result.py data/ilsvrc12/synset_words.txt result.npy \n#1 | n04552348 warplane, military plane | 84.8%\n#2 | n04008634 projectile, missile |  5.5%\n#3 | n02690373 airliner |  5.1%\n```\n\n#####classify.py\u3067\u30a8\u30e9\u30fc\u304c\u51fa\u305f\u5834\u5408\n\nnumpy\u306eio\u3068PyCaffe\u306eio.py\u304c\u7af6\u5408\u3059\u308b\u3088\u3046\u3067\u3059\u3002([Strange Issue using Python #782](https://github.com/BVLC/caffe/issues/782))\n\n```bash\n$ python classify.py --raw_scale 255 ~/caffe/101_ObjectCategories/airplanes/image_0001.jpg ../result.npy\nTraceback (most recent call last):\n  File \"classify.py\", line 7, in <module>\n    import numpy as np\n\n...\n\n\n  File \"/usr/local/lib/python2.7/dist-packages/skimage/util/dtype.py\", line 8, in <module>\n    dtype_range = {np.bool_: (False, True),\nAttributeError: 'module' object has no attribute 'bool_'\n```\n\n\u7121\u7406\u3084\u308a\u306a\u65b9\u6cd5\u3067\u3059\u304c`io.py`\u3092`caffe_io.py`\u306brename\u3057\u307e\u3059\u3002\n\u3053\u3053\u3067rename\u3057\u305f\u5834\u5408\u306b\u306f\u3001\u6b21\u306e\"Caffe\u3092\u7279\u5fb4\u62bd\u51fa\u5668\u3068\u3057\u3066\u4f7f\u3063\u305f\u5206\u985e\"\u306b\u4f5c\u6210\u3059\u308b`feature.py`\u3067\u3082rename\u3059\u308b\u5fc5\u8981\u304c\u3042\u308a\u307e\u3059\u3002\n\n```bash\n$ cd ~/caffe/python/\n$ aftfile=\"caffe_io\"\n$ for file in `find . -name \"*.py\"`; do; cat $file | sed -e \"s/import [\\w\\.]*io/import $aftfile/g\" | sed -e \"s/caffe\\.io/caffe\\.$aftfile/g\" > $file\".tmp\";mv $file\".tmp\" $file; done\n$ mv \"caffe/io.py\" \"caffe/\"$aftfile\".py\"\n```\n\n\n\u3000\n\n####Caffe\u3092\u7279\u5fb4\u62bd\u51fa\u5668\u3068\u3057\u3066\u4f7f\u3063\u305f\u5206\u985e\n\u524d\u306e\u30d6\u30e9\u30f3\u30c1\u306b\u5207\u308a\u66ff\u3048\u305f\u307e\u307e\u623b\u3059\u306e\u3092\u3059\u3063\u304b\u308a\u5fd8\u308c\u3066\u3044\u305f\u306e\u3067\u3001\u3082\u3057\u304b\u3057\u305f\u3089\u5c11\u3057\u9055\u3046\u90e8\u5206\u304c\u3042\u308b\u304b\u3082\u3057\u308c\u307e\u305b\u3093\u3002\n\n```bash\n$ cd ~/caffe\n$ cp examples/imagenet/imagenet_deploy.prototxt examples/imagenet/imagenet_feature.prototxt\n$ vim examples/imagenet/imagenet_feature.prototxt\n```\n\n\u6b21\u306e\u3088\u3046\u306b`imagenet_feature.prototxt`\u3092\u5909\u66f4\u3057\u3066\u4e0b\u3055\u3044\u3002\n\n```vim:imagenet_feature.prototxt\n...\n\n154   top: \"fc6wi\"\n\n...\n\n162   bottom: \"fc6wi\"\n\n...\n```\n\n\u3000deeplearning-tutorials\nlibsvm format\u3067\u7279\u5fb4\u91cf\u3092\u4e26\u3079\u305f\u30d5\u30a1\u30a4\u30eb\u3092\u4f5c\u6210\u3057\u307e\u3059\u3002\n\n```bash\n$ cd ~/caffe/\n$ git clone https://github.com/CORDEA/deeplearning-tutorials\n$ mv ~/caffe/deeplearning-tutorials/caffe/feature.py ~/caffe/\n$ python feature.py\n```\n\n\u3082\u3057\u304f\u306f\n\n```bash\n$ cd ~/caffe/\n$ wget https://raw.githubusercontent.com/CORDEA/deeplearning-tutorials/master/caffe/feature.py\n$ python feature.py\n```\n\n`train`command\u306f`svm-train`\u306b\n`predict`command\u306f`svm-predict`\u306b\n\u305d\u308c\u305e\u308c\u540d\u524d\u304c\u5909\u308f\u3063\u3066\u3044\u307e\u3059\u306e\u3067\u6ce8\u610f\u3057\u3066\u4e0b\u3055\u3044\u3002\n\n```bash\n$ svm-scale -s scale.txt train.txt > train_scaled.txt\n$ svm-scale -r scale.txt test.txt > test_scaled.txt\n$ svm-train -c 0.03 train_scaled.txt caltech101.model\n```\n\n\n####Fine tuning\n\n\u5fc5\u8981\u306a\u30d5\u30a1\u30a4\u30eb\u3092\u7528\u610f\u3057\u307e\u3059\u3002\n\n\"Caffe\u3092\u7279\u5fb4\u62bd\u51fa\u5668\u3068\u3057\u3066\u4f7f\u3063\u305f\u5206\u985e\"\u3067`git clone`\u3057\u305f\u5834\u5408\n\n```bash\n$ cd ~/caffe/\n$ mv ~/caffe/deeplearning-tutorials/caffe/fine_tuning.py ~/caffe/\n$ python fine_tuning.py\n```\n\nwget\u3059\u308b\u5834\u5408\n\n```bash\n$ cd ~/caffe/\n$ wget https://raw.githubusercontent.com/CORDEA/deeplearning-tutorials/master/caffe/fine_tuning.py\n$ python fine_tuning.py\n```\n\n`convert_imageset.bin`\u306e\u4ed5\u69d8\u304c\u5909\u308f\u3063\u3066\u3044\u308b\u306e\u3067\u53c2\u8003\u8a18\u4e8b\u306e\u901a\u308a\u3067\u306f\u52d5\u4f5c\u3057\u307e\u305b\u3093\u3002\n\u53c2\u8003\u8a18\u4e8b\u3067\u6307\u5b9a\u3055\u308c\u3066\u3044\u308bflag\u306e`1`\u304c\u73fe\u5728\u306e\u3069\u308c\u306b\u5f53\u305f\u308b\u304b\u308f\u304b\u308a\u307e\u305b\u3093\u304c\u3001\u304a\u305d\u3089\u304f`-gray`\u3060\u308d\u3046\u3068\u5224\u65ad\u3057\u3066\u9032\u3081\u3066\u3044\u307e\u3059\u3002\n\n```bash\n$ build/tools/convert_imageset.bin -gray -resize_width 256 -resize_height 256 101_ObjectCategories/ train.txt caltech101_train_leveldb\n$ build/tools/convert_imageset.bin -gray -resize_width 256 -resize_height 256 101_ObjectCategories/ val.txt caltech101_val_leveldb\n$ build/tools/compute_image_mean.bin caltech101_train_leveldb caltech101_mean.binaryproto\n```\n\n\u53c2\u8003\u8a18\u4e8b\u304b\u3089\u53c2\u7167\u5148\u304c\u5909\u308f\u3063\u3066\u3044\u307e\u3059\u306e\u3067\u6c17\u3092\u3064\u3051\u3066\u4e0b\u3055\u3044\u3002\n\n```bash\n$ cp ~/caffe/models/bvlc_reference_caffenet/*.prototxt ~/caffe/\n$ cd ~/caffe/\n$ sed -i -e 's/fc8/fc8ft/g' train_val.prototxt deploy.prototxt\n```\n\n\u4ee5\u4e0b\u306e\u90e8\u5206\u3092\u30a8\u30c7\u30a3\u30bf(vi\u3068\u304b)\u3067\u5909\u66f4\u3057\u3066\u4e0b\u3055\u3044\u3002\n\n```vim:solver.prototxt\n1 net: \"train_val.prototxt\"\n\n...\n\n4 base_lr: 0.001\n\n...\n\n14 solver_mode: CPU\n```\n\n```vim:train_val.prototxt\n8     source: \"caltech101_train_leveldb\"\n9     backend: LEVELDB\n\n...\n\n14     mean_file: \"caltech101_mean.binaryproto\"\n\n...\n\n25     source: \"caltech101_val_leveldb\"\n26     backend: LEVELDB\n\n...\n\n31     mean_file: \"caltech101_mean.binaryproto\"\n\n...\n\n321     num_output: 102\n```\n\n```vim:deploy.prototxt\n5 input_dim: 256\n6 input_dim: 256\n\n...\n\n204     num_output: 102\n```\n\n```bash\n$ build/tools/caffe train -solver solver.prototxt\n```\n\n\n\u3000\n\n\u3000\n\n\n#Pylearn2\n\n## Installation\n```bash\n$ sudo apt-get install python-setuptools python-pip python-dev python-numpy python-scipy python-yaml python-matplotlib liblapack-dev python-nose2 cython\n```\n\n```bash\n$ sudo pip install theano\n```\n\n\n```bash\n$ cd ~\n$ git clone https://github.com/lisa-lab/pylearn2.git\n$ cd pylearn2\n$ sudo python setup.py develop\n```\n\n\n### path\n\n```vim\n$ echo \"export PATH=$HOME/pylearn2/pylearn2/scripts/:$PATH\" >> ~/.bashrc\n$ echo \"export PYLEARN2_DATA_PATH=$HOME/.data/lisa/data\" >> ~/.bashrc\n$ source ~/.bashrc\n```\n\n##Tutorials\n\n### Gaussian-Bernoulli RBM examples using CIFAR10\n\n```bash\n$ cd ~/pylearn2/pylearn2/scripts/datasets/\n$ ./download_cifar10.sh\n$ cd ~/pylearn2/pylearn2/scripts/tutorials/grbm_smd/\n$ python make_dataset.py\n$ train.py cifar_grbm_smd.yaml\n$ show_weights.py cifar_grbm_smd.pkl --out weights_result.png # GUI\u304c\u3042\u308b\u5834\u5408\u306f --out \u306f\u7121\u304f\u3066\u3082\u826f\u3044\n$ plot_monitor.py cifar_grbm_smd.pkl --out monitor_result.png\nPut e, b, s or h in the list somewhere to plot epochs, batches, seconds, or hours, respectively.\nEnter a list of channels to plot (example: A, C,F-G, h, <test_err>) or q to quit or o for options: b,L,M\nset x_axis to example\nA. bias_hid_max:cifar_grbm\nB. bias_hid_mean:cifar_grbm\nC. bias_hid_min:cifar_grbm\nD. bias_vis_max:cifar_grbm\nE. bias_vis_mean:cifar_grbm\nF. bias_vis_min:cifar_grbm\nG. h_max:cifar_grbm\nH. h_mean:cifar_grbm\nI. h_min:cifar_grbm\nJ. learning_rate:cifar_grbm\nK. objective:cifar_grbm\nL. reconstruction_error:cifar_grbm\nM. total_seconds_last_epoch:cifar_grbm\nN. training_seconds_this_epoch:cifar_grbm\n\nPut e, b, s or h in the list somewhere to plot epochs, batches, seconds, or hours, respectively.\nEnter a list of channels to plot (example: A, C,F-G, h, <test_err>) or q to quit or o for options: q\n```\n\n####image\u306e\u78ba\u8a8d\ndocker\u3067\u52d5\u4f5c\u3055\u305b\u3066\u3044\u308b\u5834\u5408\n\n`docker cp`\u3067local\u306bcopy\u3057\u3066\u308b\u3060\u3051\n\n```bash\n% container=\"pylearn2\" # Enter the container ID or name\n% for file in `echo weights_result.png monitor_result.png`;do;docker cp $container:/home/cordea/pylearn2/pylearn2/scripts/tutorials/grbm_smd/$file /host/path/to/dir/;done\n% open *.png # for Mac\n```\n\n\n### SdA examples using MNIST\n\n```bash\n$ cd ~/pylearn2/pylearn2/scripts/datasets/\n$ python download_mnist.py\n$ cd ~/pylearn2/pylearn2/scripts/tutorials/stacked_autoencoders/tests\n$ python test_dae.py\n```\n\n## \u81ea\u5206\u306e\u7528\u610f\u3057\u305f\u30c7\u30fc\u30bf\u3092\u4f7f\u3046\n\n**csv\u3092\u305d\u306e\u307e\u307e\u4f7f\u7528\u3059\u308b\u306a\u3089[\u3053\u3061\u3089](http://fastml.com/pylearn2-in-practice/)\u304c\u53c2\u8003\u306b\u306a\u308a\u307e\u3059\u3002**\n\n\u4eca\u56de\u306fcsv\u304b\u3089pkl\u3092\u4f5c\u6210\u3059\u308b\u65b9\u6cd5\u3092\u7d39\u4ecb\u3057\u307e\u3059\u3002\n\n\u753b\u50cf\u3092resize, gray-scale\u5316\u3057\u305f\u4e0a\u3067csv\u306b\u5909\u63db\u3057\u307e\u3059\u3002\n\n```bash\n$ cd ~\n$ git clone https://github.com/CORDEA/deeplearning-tutorials.git\n$ cd deeplearning-tutorials/pylearn2\n$ mkdir in\n```\n`convertImage.py`\u306f\u4ee5\u4e0b\u306e\u69d8\u306a\u30c7\u30a3\u30ec\u30af\u30c8\u30ea\u69cb\u9020\u3092\u60f3\u5b9a\u3057\u3066\u4f5c\u6210\u3057\u3066\u3044\u307e\u3059\u3002\n\u30c7\u30a3\u30ec\u30af\u30c8\u30ea\u540d\u3092\u30e9\u30d9\u30eb\u60c5\u5831\u3068\u3057\u3066\u4e0b\u3055\u3044\u3002\n\n```\n.\n\u251c\u2500\u2500 convertImage.py\n    \u251c\u2500\u2500 in\n        \u251c\u2500\u2500 hoge # label name\n        |   \u251c\u2500\u2500 hogehoge.png\n        |   ...\n        |\n        \u251c\u2500\u2500 huge\n        |   \u251c\u2500\u2500 hugehuge.png\n        |   ...\n        ...\n```\n\n```bash\n$ python convertImage.py\n```\n\n\u4f5c\u6210\u3057\u305f`train.csv`\u3092pkl\u30d5\u30a1\u30a4\u30eb\u306b\u3057\u307e\u3059\u3002\n\n```bash\n$ python createpkl.py\n```\n\n`train.pkl`\u3092`~/pylearn2/pylearn2/scripts/tutorials/`\u306e\u30b5\u30f3\u30d7\u30eb\u3092\u53c2\u8003\u306b\u3057\u3066\u4f7f\u7528\u3059\u308c\u3070\u4f7f\u3048\u308b\u304b\u3068\u601d\u3044\u307e\u3059\u3002\n\n###\u4f8b\n\n\u30af\u30e9\u30b9\u6570\u306f10\u3068\u3057\u3066\u4f8b\u793a\u3057\u307e\u3059\u3002\n\n```bash\n$ cd ~/pylearn2/pylearn2/scripts/tutorials/dbm_demo/\n$ cp ~/deeplearning-tutorials/pylearn2/train.pkl ./\n```\n\n```bash:rbm.yaml\n13,21c13\n<     dataset: &data !obj:pylearn2.datasets.binarizer.Binarizer {\n<         # We use the \"raw\" tag to specify the underlying dataset defining\n<         # the sampling probabilities should be MNIST.\n<         raw: &raw_train !obj:pylearn2.datasets.mnist.MNIST {\n<             which_set: \"train\",\n<             start: 0,\n<             stop: %(train_stop)i\n<         }\n<     },\n---\n>     dataset: !pkl: \"train.pkl\",\n```\n\n```vim:train_dbm.py\n22     hyper_params = {'detector_layer_dim': 10,\n```\n\n```bash\n$ python train_dbm.py rbm.yaml\n$ show_weights.py dbm.pkl --out figure.png\n```\n\n\n####\u30a8\u30e9\u30fc\n\n```python:pylearn2/pylearn2/space/__init__.py\n794                 raise TypeError(Cannot safely cast batch dtype %s to space's dtype %s. % (batch.dtype, self.dtype))\n```\n\n\u3053\u3053\u3067\u30a8\u30e9\u30fc\u304c\u51fa\u305f\u306e\u3067\u3059\u304c\u3001\u30c7\u30fc\u30bf\u306e\u65b9\u3092\u5f04\u3063\u3066\u3082\u3044\u307e\u3044\u3061\u4e0a\u624b\u304f\u884c\u304b\u306a\u304b\u3063\u305f\u306e\u3067\n\n```python:pylearn2/pylearn2/space/__init__.py\n794                 # raise TypeError(\"Cannot safely cast batch dtype %s to \"\n795                 print \"Might not be safely cast batch dtype %s to space's dtype %s.\" \\\n796                         % (batch.dtype, self.dtype)\n```\n\n```python:pylearn2/pylearn2/format/target_format.py\n 98             try:\n 99                 print \"Run the conversion to int64 from %s\" % (targets.dtype)\n100                 targets = np.array([[int(r) for r in label] for label in targets])\n101             except:\n102                 raise TypeError(\"need an integer array for targets, %s\" % (targets.dtype))\n```\n\n\u4eca\u306e\u3068\u3053\u308d\u3053\u3093\u306a\u304b\u3093\u3058\u3067\u7121\u7406\u3084\u308a\u52d5\u304b\u3057\u3066\u3044\u307e\u3059...\n\n\n\u304a\u75b2\u308c\u69d8\u3067\u3057\u305f\u3002\n\n# \u53c2\u8003\n## Caffe\n- [Caffe](http://caffe.berkeleyvision.org/)\n\t- [Installation](http://caffe.berkeleyvision.org/installation.html)\n\t- [Training LeNet on MNIST with Caffe](http://caffe.berkeleyvision.org/gathered/examples/mnist.html)\n- [Caffe\u3067\u624b\u8efd\u306b\u753b\u50cf\u5206\u985e - Yahoo! \u30c7\u30d9\u30ed\u30c3\u30d1\u30fc\u30cd\u30c3\u30c8\u30ef\u30fc\u30af](http://techblog.yahoo.co.jp/programming/caffe-intro/)\n- [\u306f\u3058\u3081\u308bDeep learning](http://qiita.com/icoxfog417/items/65e800c3a2094457c3a0)\n\n## Pylearn2\n\n- [Pylearn2 dev documentation](http://deeplearning.net/software/pylearn2/)\n\t- [Download and installation](http://deeplearning.net/software/pylearn2/index.html#download-and-installation)\n\t- [Library Documentation](http://deeplearning.net/software/pylearn2/library/datasets.html#module-pylearn2.datasets.csv_dataset)\n\t- [Quick-start example](http://deeplearning.net/software/pylearn2/tutorial/index.html#tutorial)\n\n- [FastML](http://fastml.com/)\n\t- [Pylearn2 in practice](http://fastml.com/pylearn2-in-practice/)\n\t- [How to get predictions from Pylearn2](http://fastml.com/how-to-get-predictions-from-pylearn2/)\n\n- [JSAI's AI Tool Introduction - Deep Learning and Pylearn2](http://www.slideshare.net/ktrnkym/ai-tool-introduction-20140710b)\n\n- [pylearn2 \u5165\u9580\u3057\u305f\u3044\u7de8 - laughing\u306e\u30d6\u30ed\u30b0](http://laughing.hatenablog.com/entry/2013/11/30/pylearn2_%E5%85%A5%E9%96%80%E3%81%97%E3%81%9F%E3%81%84%E7%B7%A8)\n\n- [Caffe\u3067Deep Learning \u3064\u307e\u305a\u304d\u3084\u3059\u3044\u3068\u3053\u308d\u3092\u4e2d\u5fc3\u306b](http://qiita.com/uchihashi_k/items/8333f80529bb3498e32f)\n\n- [Pylearn2\u3092\u4f7f\u3063\u3066\u624b\u66f8\u304d\u6587\u5b57\u8a8d\u8b58\u3092\u884c\u3046](http://qiita.com/dsanno/items/a1d805a89e192c44730d)\n\n- [\u4eca\u30ca\u30a6\u3044\u30c7\u30a3\u30fc\u30d7\u30e9\u30fc\u30cb\u30f3\u30b0\u306e\u30e9\u30a4\u30d6\u30e9\u30ea\u300cPylearn2\u300d\u306e\u30a4\u30f3\u30b9\u30c8\u30fc\u30eb\u3068\u30c1\u30e5\u30fc\u30c8\u30ea\u30a2\u30eb](http://qiita.com/mizuki0420@github/items/3f9c97b32e8d6e37abad)\n\n- [\u7537\u306e\u305f\u3081\u306e\u6a5f\u68b0\u5b66\u7fd2\u301cRBM\u3067A\u25ef\u5973\u512a\u3055\u3093\u306e\u5171\u901a\u7279\u5fb4\u91cf\u3092\u5f97\u3088\u3046\u301c - \u65b0kensuke-mi\u306e\u65e5\u8a18](http://kensuke-mi.xyz/kensuke-mi_diary/2014/11/rbma.html)\n\n- [Python/PIL\u306b\u3088\u308b\u753b\u50cf\u306e\u30b0\u30ec\u30a4\u30b9\u30b1\u30fc\u30eb\u5316\u3068\u30a2\u30b9\u30ad\u30fc\u30a2\u30fc\u30c8\u5316 - Soleil cou coup\u00e9](http://d.hatena.ne.jp/xef/20120920/p1)\n\n\n", "tags": ["Caffe", "docker", "Python", "Pylearn2", "DeepLearning"]}