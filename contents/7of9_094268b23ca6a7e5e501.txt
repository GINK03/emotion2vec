{"context": "\n\nTensorFlow\n\n\u52d5\u4f5c\u74b0\u5883\nGeForce GTX 1070 (8GB)\nASRock Z170M Pro4S [Intel Z170chipset]\nUbuntu 14.04 LTS desktop amd64\nTensorFlow v0.11\ncuDNN v5.1 for Linux\nCUDA v8.0\nPython 2.7.6\nIPython 5.1.0 -- An enhanced Interactive Python.\ngcc (Ubuntu 4.8.4-2ubuntu1~14.04.3) 4.8.4\n\n\n\ncode\n\u5b9f\u88c5\u9014\u4e2d\u3002\ninput:100, output:100\u306e\u30ce\u30fc\u30c9\u6570\u3067\u306e\u5b66\u7fd2\u4e88\u5b9a\u3002\n\nlearn_in100out100.py\n#!/usr/bin/env python\n# -*- coding: utf-8 -*-\n\nimport sys\nimport tensorflow as tf\nimport tensorflow.contrib.slim as slim\nimport numpy as np\n\n'''\nv0.1 Feb. 06, 2017\n    - read [test_in.csv],[test_out.csv]\n'''\n\n'''\ncodingrule:PEP8\n'''\n\nfilename_inp = tf.train.string_input_producer([\"test_in.csv\"])\nfilename_out = tf.train.string_input_producer([\"test_out.csv\"])\nNUM_INP_NODE = 100\nNUM_OUT_NODE = 100\n\n# parse csv\n# a. input node\nreader = tf.TextLineReader()\nkey, value = reader.read(filename_inp)\ndeflist = [[0.] for idx in range(NUM_INP_NODE)]\ninput1 = tf.decode_csv(value, record_defaults=deflist)\n# b. output node\nkey, value = reader.read(filename_out)\ndeflist = [[0.] for idx in range(NUM_OUT_NODE)]\noutput1 = tf.decode_csv(value, record_defaults=deflist)\n# c. pack\ninputs = tf.pack([input1])\noutputs = tf.pack([output1])\n\nbatch_size = 4\ninputs_batch, output_batch = tf.train.shuffle_batch([inputs, outputs], batch_size, capacity=40, min_after_dequeue=batch_size)\n\ninput_ph = tf.placeholder(\"float\", [None, 1])\noutput_ph = tf.placeholder(\"float\", [None, 1])\n\n# network\nhiddens = slim.stack(input_ph, slim.fully_connected, [7,7,7],\n    activation_fn=tf.nn.sigmoid, scope=\"hidden\")\nprediction = slim.fully_connected(hiddens, 1, activation_fn=None, scope=\"output\")\nloss = tf.contrib.losses.mean_squared_error(prediction, output_ph)\n\ntrain_op = slim.learning.create_train_op(loss, tf.train.AdamOptimizer(0.001))\n\ninit_op = tf.initialize_all_variables()\n\nwith tf.Session() as sess:\n    coord = tf.train.Coordinator()\n    threads = tf.train.start_queue_runners(sess=sess, coord=coord)\n\n    try:\n        sess.run(init_op)\n        for idx in range(10):\n            inpbt, outbt = sess.run([inputs_batch, output_batch])\n            _, t_loss = sess.run([train_op, loss], feed_dict={input_ph:inpbt, output_ph:outbt})\n\n            if (idx+1) % 100 == 0:\n                print(\"%d,%f\" % (idx+1, t_loss))\n    finally:\n        coord.request_stop()\n\n\n\n\n\u30a8\u30e9\u30fc\n\u5b9f\u884c\u6642\u306b\u4ee5\u4e0b\u306e\u30a8\u30e9\u30fc\u304c\u51fa\u305f\u3002\nTraceback (most recent call last):\n  File \"learn_in100out100.py\", line 60, in <module>\n    inpbt, outbt = sess.run([inputs_batch, output_batch])\n  File \"/home/yasokada/tensorflow-GPU/local/lib/python2.7/site-packages/tensorflow/python/client/session.py\", line 717, in run\n    run_metadata_ptr)\n  File \"/home/yasokada/tensorflow-GPU/local/lib/python2.7/site-packages/tensorflow/python/client/session.py\", line 915, in _run\n    feed_dict_string, options, run_metadata)\n  File \"/home/yasokada/tensorflow-GPU/local/lib/python2.7/site-packages/tensorflow/python/client/session.py\", line 965, in _do_run\n    target_list, options, run_metadata)\n  File \"/home/yasokada/tensorflow-GPU/local/lib/python2.7/site-packages/tensorflow/python/client/session.py\", line 985, in _do_call\n    raise type(e)(node_def, op, message)\ntensorflow.python.framework.errors.OutOfRangeError: RandomShuffleQueue '_3_shuffle_batch/random_shuffle_queue' is closed and has insufficient elements (requested 4, current size 0)\n         [[Node: shuffle_batch = QueueDequeueMany[_class=[\"loc:@shuffle_batch/random_shuffle_queue\"], component_types=[DT_FLOAT, DT_FLOAT], timeout_ms=-1, _device=\"/job:localhost/replica:0/task:0/cpu:0\"](shuffle_batch/random_shuffle_queue, shuffle_batch/n)]]\n\nCaused by op u'shuffle_batch', defined at:\n  File \"learn_in100out100.py\", line 38, in <module>\n    inputs_batch, output_batch = tf.train.shuffle_batch([inputs, outputs], batch_size, capacity=40, min_after_dequeue=batch_size)\n  File \"/home/yasokada/tensorflow-GPU/local/lib/python2.7/site-packages/tensorflow/python/training/input.py\", line 819, in shuffle_batch\n    dequeued = queue.dequeue_many(batch_size, name=name)\n  File \"/home/yasokada/tensorflow-GPU/local/lib/python2.7/site-packages/tensorflow/python/ops/data_flow_ops.py\", line 458, in dequeue_many\n    self._queue_ref, n=n, component_types=self._dtypes, name=name)\n  File \"/home/yasokada/tensorflow-GPU/local/lib/python2.7/site-packages/tensorflow/python/ops/gen_data_flow_ops.py\", line 905, in _queue_dequeue_many\n    timeout_ms=timeout_ms, name=name)\n  File \"/home/yasokada/tensorflow-GPU/local/lib/python2.7/site-packages/tensorflow/python/framework/op_def_library.py\", line 749, in apply_op\n    op_def=op_def)\n  File \"/home/yasokada/tensorflow-GPU/local/lib/python2.7/site-packages/tensorflow/python/framework/ops.py\", line 2380, in create_op\n    original_op=self._default_original_op, op_def=op_def)\n  File \"/home/yasokada/tensorflow-GPU/local/lib/python2.7/site-packages/tensorflow/python/framework/ops.py\", line 1298, in __init__\n    self._traceback = _extract_stack()\n\nOutOfRangeError (see above for traceback): RandomShuffleQueue '_3_shuffle_batch/random_shuffle_queue' is closed and has insufficient elements (requested 4, current size 0)\n         [[Node: shuffle_batch = QueueDequeueMany[_class=[\"loc:@shuffle_batch/random_shuffle_queue\"], component_types=[DT_FLOAT, DT_FLOAT], timeout_ms=-1, _device=\"/job:localhost/replica:0/task:0/cpu:0\"](shuffle_batch/random_shuffle_queue, shuffle_batch/n)]]\n\n\n\u53c2\u8003\u3068\u5bfe\u51e6\n\u53c2\u8003 http://stackoverflow.com/questions/34050071/tensorflow-random-shuffle-queue-is-closed-and-has-insufficient-elements\n\nwas caused by the queue running out of data. This is often caused by thinking you have enough data for N iterations when really you only have enough for M iterations where M < N.\n\n\u4eca\u56de\u306f100\u30d1\u30bf\u30fc\u30f3\u3057\u304b\u7528\u610f\u3057\u3066\u3044\u306a\u3044\u306e\u3060\u304c\u3001\n\nbatch_size = 4\ncapacity=40\nfor idx in range(10):\n\n\u306a\u3069\u306e\u51e6\u7406\u3067\u30d1\u30bf\u30fc\u30f3\u6570100\u3092\u8d85\u3048\u305f\u306e\u304c\u539f\u56e0\u306e\u3088\u3046\u3060\u3002\n\nbatch_size = 1\ncapacity=1\n\n\u306e\u3088\u3046\u306b\u5909\u66f4\u3057\u305f\u3068\u3053\u308d\u3001\u8a72\u5f53\u30a8\u30e9\u30fc\u306f\u51fa\u306a\u304f\u306a\u3063\u305f\u3002\n$ python learn_in100out100.py \nI tensorflow/stream_executor/dso_loader.cc:111] successfully opened CUDA library libcublas.so locally\nI tensorflow/stream_executor/dso_loader.cc:111] successfully opened CUDA library libcudnn.so locally\nI tensorflow/stream_executor/dso_loader.cc:111] successfully opened CUDA library libcufft.so locally\nI tensorflow/stream_executor/dso_loader.cc:111] successfully opened CUDA library libcuda.so.1 locally\nI tensorflow/stream_executor/dso_loader.cc:111] successfully opened CUDA library libcurand.so locally\nTraceback (most recent call last):\n  File \"learn_in100out100.py\", line 38, in <module>\n    inputs_batch, output_batch = tf.train.shuffle_batch([inputs, outputs], batch_size, capacity=1, min_after_dequeue=batch_size)\n  File \"/home/yasokada/tensorflow-GPU/local/lib/python2.7/site-packages/tensorflow/python/training/input.py\", line 808, in shuffle_batch\n    (1. / (capacity - min_after_dequeue)))\nZeroDivisionError: float division by zero\n\n\u6700\u5f8c\u306e\u30a8\u30e9\u30fc\u306f\u5225\u9014\u8981\u691c\u8a0e\u3002\n\u30d0\u30c3\u30c1\u30b5\u30a4\u30ba\u3068\u5b66\u7fd2\u30d1\u30bf\u30fc\u30f3\u6570\u306a\u3069\u306f\u4eca\u5f8c\u691c\u8a0e\u3059\u308b\u3053\u3068\u306b\u306a\u308b\u3002\n### TensorFlow\n\n```txt:\u52d5\u4f5c\u74b0\u5883\nGeForce GTX 1070 (8GB)\nASRock Z170M Pro4S [Intel Z170chipset]\nUbuntu 14.04 LTS desktop amd64\nTensorFlow v0.11\ncuDNN v5.1 for Linux\nCUDA v8.0\nPython 2.7.6\nIPython 5.1.0 -- An enhanced Interactive Python.\ngcc (Ubuntu 4.8.4-2ubuntu1~14.04.3) 4.8.4\n```\n\n### code\n\n\u5b9f\u88c5\u9014\u4e2d\u3002\ninput:100, output:100\u306e\u30ce\u30fc\u30c9\u6570\u3067\u306e\u5b66\u7fd2\u4e88\u5b9a\u3002\n\n```learn_in100out100.py\n#!/usr/bin/env python\n# -*- coding: utf-8 -*-\n\nimport sys\nimport tensorflow as tf\nimport tensorflow.contrib.slim as slim\nimport numpy as np\n\n'''\nv0.1 Feb. 06, 2017\n    - read [test_in.csv],[test_out.csv]\n'''\n\n'''\ncodingrule:PEP8\n'''\n\nfilename_inp = tf.train.string_input_producer([\"test_in.csv\"])\nfilename_out = tf.train.string_input_producer([\"test_out.csv\"])\nNUM_INP_NODE = 100\nNUM_OUT_NODE = 100\n\n# parse csv\n# a. input node\nreader = tf.TextLineReader()\nkey, value = reader.read(filename_inp)\ndeflist = [[0.] for idx in range(NUM_INP_NODE)]\ninput1 = tf.decode_csv(value, record_defaults=deflist)\n# b. output node\nkey, value = reader.read(filename_out)\ndeflist = [[0.] for idx in range(NUM_OUT_NODE)]\noutput1 = tf.decode_csv(value, record_defaults=deflist)\n# c. pack\ninputs = tf.pack([input1])\noutputs = tf.pack([output1])\n\nbatch_size = 4\ninputs_batch, output_batch = tf.train.shuffle_batch([inputs, outputs], batch_size, capacity=40, min_after_dequeue=batch_size)\n\ninput_ph = tf.placeholder(\"float\", [None, 1])\noutput_ph = tf.placeholder(\"float\", [None, 1])\n\n# network\nhiddens = slim.stack(input_ph, slim.fully_connected, [7,7,7],\n    activation_fn=tf.nn.sigmoid, scope=\"hidden\")\nprediction = slim.fully_connected(hiddens, 1, activation_fn=None, scope=\"output\")\nloss = tf.contrib.losses.mean_squared_error(prediction, output_ph)\n\ntrain_op = slim.learning.create_train_op(loss, tf.train.AdamOptimizer(0.001))\n\ninit_op = tf.initialize_all_variables()\n\nwith tf.Session() as sess:\n    coord = tf.train.Coordinator()\n    threads = tf.train.start_queue_runners(sess=sess, coord=coord)\n\n    try:\n        sess.run(init_op)\n        for idx in range(10):\n            inpbt, outbt = sess.run([inputs_batch, output_batch])\n            _, t_loss = sess.run([train_op, loss], feed_dict={input_ph:inpbt, output_ph:outbt})\n\n            if (idx+1) % 100 == 0:\n            \tprint(\"%d,%f\" % (idx+1, t_loss))\n    finally:\n        coord.request_stop()\n\n```\n\n### \u30a8\u30e9\u30fc\n\n\u5b9f\u884c\u6642\u306b\u4ee5\u4e0b\u306e\u30a8\u30e9\u30fc\u304c\u51fa\u305f\u3002\n\n```\nTraceback (most recent call last):\n  File \"learn_in100out100.py\", line 60, in <module>\n    inpbt, outbt = sess.run([inputs_batch, output_batch])\n  File \"/home/yasokada/tensorflow-GPU/local/lib/python2.7/site-packages/tensorflow/python/client/session.py\", line 717, in run\n    run_metadata_ptr)\n  File \"/home/yasokada/tensorflow-GPU/local/lib/python2.7/site-packages/tensorflow/python/client/session.py\", line 915, in _run\n    feed_dict_string, options, run_metadata)\n  File \"/home/yasokada/tensorflow-GPU/local/lib/python2.7/site-packages/tensorflow/python/client/session.py\", line 965, in _do_run\n    target_list, options, run_metadata)\n  File \"/home/yasokada/tensorflow-GPU/local/lib/python2.7/site-packages/tensorflow/python/client/session.py\", line 985, in _do_call\n    raise type(e)(node_def, op, message)\ntensorflow.python.framework.errors.OutOfRangeError: RandomShuffleQueue '_3_shuffle_batch/random_shuffle_queue' is closed and has insufficient elements (requested 4, current size 0)\n         [[Node: shuffle_batch = QueueDequeueMany[_class=[\"loc:@shuffle_batch/random_shuffle_queue\"], component_types=[DT_FLOAT, DT_FLOAT], timeout_ms=-1, _device=\"/job:localhost/replica:0/task:0/cpu:0\"](shuffle_batch/random_shuffle_queue, shuffle_batch/n)]]\n\nCaused by op u'shuffle_batch', defined at:\n  File \"learn_in100out100.py\", line 38, in <module>\n    inputs_batch, output_batch = tf.train.shuffle_batch([inputs, outputs], batch_size, capacity=40, min_after_dequeue=batch_size)\n  File \"/home/yasokada/tensorflow-GPU/local/lib/python2.7/site-packages/tensorflow/python/training/input.py\", line 819, in shuffle_batch\n    dequeued = queue.dequeue_many(batch_size, name=name)\n  File \"/home/yasokada/tensorflow-GPU/local/lib/python2.7/site-packages/tensorflow/python/ops/data_flow_ops.py\", line 458, in dequeue_many\n    self._queue_ref, n=n, component_types=self._dtypes, name=name)\n  File \"/home/yasokada/tensorflow-GPU/local/lib/python2.7/site-packages/tensorflow/python/ops/gen_data_flow_ops.py\", line 905, in _queue_dequeue_many\n    timeout_ms=timeout_ms, name=name)\n  File \"/home/yasokada/tensorflow-GPU/local/lib/python2.7/site-packages/tensorflow/python/framework/op_def_library.py\", line 749, in apply_op\n    op_def=op_def)\n  File \"/home/yasokada/tensorflow-GPU/local/lib/python2.7/site-packages/tensorflow/python/framework/ops.py\", line 2380, in create_op\n    original_op=self._default_original_op, op_def=op_def)\n  File \"/home/yasokada/tensorflow-GPU/local/lib/python2.7/site-packages/tensorflow/python/framework/ops.py\", line 1298, in __init__\n    self._traceback = _extract_stack()\n\nOutOfRangeError (see above for traceback): RandomShuffleQueue '_3_shuffle_batch/random_shuffle_queue' is closed and has insufficient elements (requested 4, current size 0)\n         [[Node: shuffle_batch = QueueDequeueMany[_class=[\"loc:@shuffle_batch/random_shuffle_queue\"], component_types=[DT_FLOAT, DT_FLOAT], timeout_ms=-1, _device=\"/job:localhost/replica:0/task:0/cpu:0\"](shuffle_batch/random_shuffle_queue, shuffle_batch/n)]]\n```\n\n\n### \u53c2\u8003\u3068\u5bfe\u51e6\n\n\u53c2\u8003 http://stackoverflow.com/questions/34050071/tensorflow-random-shuffle-queue-is-closed-and-has-insufficient-elements\n\n> was caused by the queue running out of data. This is often caused by thinking you have enough data for N iterations when really you only have enough for M iterations where M < N.\n\n\u4eca\u56de\u306f100\u30d1\u30bf\u30fc\u30f3\u3057\u304b\u7528\u610f\u3057\u3066\u3044\u306a\u3044\u306e\u3060\u304c\u3001\n\n- batch_size = 4\n- capacity=40\n- for idx in range(10):\n\n\u306a\u3069\u306e\u51e6\u7406\u3067\u30d1\u30bf\u30fc\u30f3\u6570100\u3092\u8d85\u3048\u305f\u306e\u304c\u539f\u56e0\u306e\u3088\u3046\u3060\u3002\n\n- batch_size = 1\n- capacity=1\n\n\u306e\u3088\u3046\u306b\u5909\u66f4\u3057\u305f\u3068\u3053\u308d\u3001\u8a72\u5f53\u30a8\u30e9\u30fc\u306f\u51fa\u306a\u304f\u306a\u3063\u305f\u3002\n\n```\n$ python learn_in100out100.py \nI tensorflow/stream_executor/dso_loader.cc:111] successfully opened CUDA library libcublas.so locally\nI tensorflow/stream_executor/dso_loader.cc:111] successfully opened CUDA library libcudnn.so locally\nI tensorflow/stream_executor/dso_loader.cc:111] successfully opened CUDA library libcufft.so locally\nI tensorflow/stream_executor/dso_loader.cc:111] successfully opened CUDA library libcuda.so.1 locally\nI tensorflow/stream_executor/dso_loader.cc:111] successfully opened CUDA library libcurand.so locally\nTraceback (most recent call last):\n  File \"learn_in100out100.py\", line 38, in <module>\n    inputs_batch, output_batch = tf.train.shuffle_batch([inputs, outputs], batch_size, capacity=1, min_after_dequeue=batch_size)\n  File \"/home/yasokada/tensorflow-GPU/local/lib/python2.7/site-packages/tensorflow/python/training/input.py\", line 808, in shuffle_batch\n    (1. / (capacity - min_after_dequeue)))\nZeroDivisionError: float division by zero\n```\n\n\u6700\u5f8c\u306e\u30a8\u30e9\u30fc\u306f\u5225\u9014\u8981\u691c\u8a0e\u3002\n\n\u30d0\u30c3\u30c1\u30b5\u30a4\u30ba\u3068\u5b66\u7fd2\u30d1\u30bf\u30fc\u30f3\u6570\u306a\u3069\u306f\u4eca\u5f8c\u691c\u8a0e\u3059\u308b\u3053\u3068\u306b\u306a\u308b\u3002\n\n", "tags": ["borgWarp", "TensorFlow"]}