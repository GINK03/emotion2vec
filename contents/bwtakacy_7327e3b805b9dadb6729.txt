{"context": "HDFS\u4e0a\u306e\u30c7\u30fc\u30bf\u3092\u6697\u53f7\u5316\u3059\u308bTransparent Encryption in HDFS\u3092\u8a66\u3057\u3066\u307f\u307e\u3057\u305f\u3002\n\u74b0\u5883\u306f\n* CentOS 7.2\n* Oracle Java 1.8.0_65\n* Apache Hadoop 2.7.2\nTransparent Encryption in HDFS \u306e\u8aac\u660e\u306f\u30c9\u30ad\u30e5\u30e1\u30f3\u30c8\u53c2\u7167\u3067\u3059\u3002\n\u96d1\u306b\u307e\u3068\u3081\u308b\u3068\u3001\u65b0\u3057\u3044\u30b3\u30f3\u30dd\u30fc\u30cd\u30f3\u30c8Key Management Server(KMS)\u3092\u8ffd\u52a0\u3059\u308b\u4ee3\u308f\u308a\u306b\u3001\u6697\u53f7\u5316\u30ad\u30fc\u306e\u7ba1\u7406\u3092\u900f\u904e\u7684\u306b\u3084\u3063\u3066\u304f\u308c\u307e\u3059\u3002\n\u6f02\u3046SPOF\u611f\u30fb\u30fb\u30fb\n\nHDFS\u30af\u30e9\u30b9\u30bf\u306e\u521d\u671f\u5316\n\u4ee5\u524d\u66f8\u3044\u305f\u624b\u9806\u3067\u5b9f\u65bd\u30022.7.2\u3067\u3082\u540c\u3058\u3067\u3059\u3002\nhttp://qiita.com/bwtakacy/items/6491b3d11754492f9702\n\nKMS\u306e\u8a2d\u5b9a\nkms-site.xml\u306e\u4ee5\u4e0b\u306e\u30d1\u30e9\u30e1\u30fc\u30bf\u304c\u6700\u4f4e\u9650\u5fc5\u8981\u306a\u3088\u3046\u3067\u3059\u3002\u30c7\u30d5\u30a9\u30eb\u30c8\u3067\u5165\u3063\u3066\u3044\u308b\u5024\u3092\u4eca\u56de\u306f\u4f7f\u3044\u307e\u3059\u3002\n  <!-- KMS Backend KeyProvider -->\n\n  <property>\n    <name>hadoop.kms.key.provider.uri</name>\n    <value>jceks://file@/${user.home}/kms.keystore</value>\n    <description>\n      URI of the backing KeyProvider for the KMS.\n    </description>\n  </property>\n\n  <property>\n    <name>hadoop.security.keystore.java-keystore-provider.password-file</name>\n    <value>kms.keystore.password</value>\n    <description>\n      If using the JavaKeyStoreProvider, the password for the keystore file.\n    </description>\n  </property>\n\nKeyProvider\u3068\u3057\u3066Java\u4ed8\u5c5e\u306eKeyStore\u3092\u5229\u7528\u3059\u308b\u5b9f\u88c5\u306b\u306a\u3063\u3066\u3044\u308b\u3088\u3046\u3067\u3059\u3002\nKMS\u521d\u56de\u8d77\u52d5\u6642\u306b\u3001\u6307\u5b9a\u3057\u305f\u30d1\u30b9\u306b\u6307\u5b9a\u3057\u305f\u30d1\u30b9\u30ef\u30fc\u30c9\u3067KeyStore\u304c\u4f5c\u6210\u3055\u308c\u307e\u3059\u3002\n\nKMS\u306e\u8d77\u52d5\n$ sbin/kms.sh start\n\n\n\u30cf\u30de\u308a\u3069\u3053\u308d1\n\u30c9\u30ad\u30e5\u30e1\u30f3\u30c8\u3092\u898b\u308b\u3068\u3001\n\nThe password file is looked up in the Hadoop\u2019s configuration directory via the class path.\n\nhttp://hadoop.apache.org/docs/r2.7.2/hadoop-kms/index.html\n\u3068\u3042\u308b\u306e\u3067\u3001Hadoop\u306e\u8a2d\u5b9a\u30d5\u30a1\u30a4\u30eb\u304c\u7f6e\u3044\u3066\u3042\u308b\u5834\u6240\uff08\u3053\u306e\u74b0\u5883\u3067\u306f$HADOOP_PREFIX/etc/hadoop\uff09\u306b\u7f6e\u3044\u3066\u3044\u305f\u306e\u3067\u3059\u304c\u3001\u30d1\u30b9\u30ef\u30fc\u30c9\u30d5\u30a1\u30a4\u30eb\u3092KMS\u304c\u3046\u307e\u304f\u8a8d\u8b58\u3057\u3066\u304f\u308c\u305a\u8d77\u52d5\u3057\u307e\u305b\u3093\u3067\u3057\u305f\u3002\n\u3044\u308d\u3044\u308d\u8a66\u884c\u932f\u8aa4\u3057\u305f\u306e\u3067\u3059\u304c\u3001\u4e0a\u306e\u8aac\u660e\u3092\u3088\u304f\u8aad\u3080\u3068\u5206\u304b\u308b\u3088\u3046\u306b\u3001CLASSPATH\u7d4c\u7531\u3067\u898b\u3048\u3066\u3044\u308b\u5fc5\u8981\u304c\u3042\u308b\u3088\u3046\u3067\u3059\u3002\nKMS\u306fTomcat\u306b\u30ed\u30fc\u30c9\u3055\u308c\u3066\u8d77\u52d5\u3059\u308b\u306e\u3067\u3059\u304c\u3001\u305d\u306e\u8d77\u52d5\u306e\u969b\u306bTomcat\u306eCLASSPATH\u306bHadoop\u306e\u8a2d\u5b9a\u30d5\u30a1\u30a4\u30eb\u306e\u30d1\u30b9\u304c\u6e21\u3055\u308c\u3066\u3044\u306a\u3044\u3088\u3046\u3067\u3059\u3002\nkms-site.xml\u3068\u540c\u3058\u3068\u3053\u308d\u306b\u3042\u308bkms-env.sh\u306b\u4ee5\u4e0b\u306e\uff11\u884c\u3092\u8ffd\u52a0\u3059\u308b\u3068\u3001\u3046\u307e\u304f\u8a8d\u8b58\u3067\u304d\u308b\u3088\u3046\u306b\u306a\u308a\u307e\u3057\u305f\u3002\nexport CLASSPATH=$CLASSPATH:/usr/local/hadoop/etc/hadoop/kms.keystore.password\n\n2016/2/7 11:20\u3000\u8ffd\u8a18\n\u3084\u308a\u76f4\u3057\u3066\u307f\u305f\u3068\u3053\u308d\u3001\u4e0a\u8a18\u3067\u3082\u30c0\u30e1\u3067\u3057\u305f\u3002\u3002\u3002\n\u3069\u3046\u3084\u3089Tomcat\u306e\u30af\u30e9\u30b9\u30d1\u30b9\u304c\u5dee\u3057\u3066\u3044\u308b\u3068\u3053\u308d\u306b\u30d1\u30b9\u30ef\u30fc\u30c9\u30d5\u30a1\u30a4\u30eb\u3092\u7f6e\u304f\u304f\u3089\u3044\u3057\u304b\u898b\u51fa\u305b\u307e\u305b\u3093\u3067\u3057\u305f\u3002\n\u5834\u6240\u306f$HADOOP_PREFIX/share/hadoop/kms/tomcat/webapps/kms/WEB-INF/classes/\u3067\u3059\u3002\n2016/2/7 11:40\u3000\u8ffd\u8a18\n\u3082\u3046\u4e00\u3064\u3084\u308a\u65b9\u3092\u898b\u3064\u3051\u307e\u3057\u305f\u3002\n\u3069\u3046\u3084\u3089\u3001keystore\u30d1\u30b9\u30ef\u30fc\u30c9\u306f\u30d5\u30a1\u30a4\u30eb\u306b\u66f8\u3044\u3066\u8aad\u307f\u8fbc\u307e\u305b\u308b\u4ed6\u306b\u3001\u74b0\u5883\u5909\u6570HADOOP_KEYSTORE_PASSWORD\u3067\u4e0e\u3048\u308b\u65b9\u6cd5\u3082\u3042\u308b\u3088\u3046\u3067\u3059\u3002\u3053\u306e\u5834\u5408\u3001kms-env.sh\u306b\nexport HADOOP_KEYSTORE_PASSWORD=password\n\n\u3068\u3084\u3063\u3066\u30d1\u30b9\u30ef\u30fc\u30c9\u3092\u4e0e\u3048\u308c\u3070OK\u3067\u3059\u3002\n\nHadoop\u5074\u3067\u306eKMS\u5229\u7528\u8a2d\u5b9a\nhfs-site.xml\u306b\u4ee5\u4e0b\u3092\u8ffd\u8a18\u3057\u307e\u3059\u3002\n<property>\n  <name>dfs.encryption.key.provider.uri</name>\n  <value>kms://http@localhost:16000/kms</value>\n  <description>\n    The KeyProvider to use when interacting with encryption keys used \n    when reading and writing to an encryption zone.\n  </description>\n</property>\n\n\n\u30cf\u30de\u30ea\u3069\u3053\u308d2\n\u4e0a\u8a18\u306e\u30d1\u30e9\u30e1\u30fc\u30bf\u3060\u3051\u3060\u3068Encryption Zone\u3092\u4f5c\u6210\u3057\u3088\u3046\u3068\u3057\u305f\u969b\u306b\u6b21\u306e\u30a8\u30e9\u30fc\u304c\u51fa\u307e\u3057\u305f\u3002\n\nThere are no valid KeyProviders configured. No key\n was created. You can use the -provider option to specify\n a provider to use.\n\n\u306a\u3093\u30fb\u30fb\u30fb\u3060\u3068\u30fb\u30fb\u30fb\uff1f\n\u3053\u308c\u307e\u305f\u30cd\u30c3\u30c8\u4e0a\u53ca\u3073\u30bd\u30fc\u30b9\u30b3\u30fc\u30c9\u3092\u8abf\u67fb\u3057\u307e\u3057\u305f\u3002\n\u4f55\u6545\u304b\u30c9\u30ad\u30e5\u30e1\u30f3\u30c8\u306b\u8a18\u8f09\u304c\u306a\u304f\u3001core-default.xml\u306b\u3059\u3089\u8a18\u8f09\u304c\u306a\u3044\u306e\u3067\u3059\u304c\u3001\u4ee5\u4e0b\u306e\u30d1\u30e9\u30e1\u30fc\u30bf\u3092core-site.xml\u306b\u8a2d\u5b9a\u3059\u308b\u5fc5\u8981\u304c\u3042\u308b\u3088\u3046\u3067\u3059\u3002\n    <property>\n        <name>hadoop.security.key.provider.path</name>\n        <value>kms://http@localhost:16000/kms</value>\n    </property>\n\n\u8a2d\u5b9a\u3059\u308b\u5024\u306fdfs.encryption.key.provider.uri\u3068\u540c\u3058\u3067\u826f\u3044\u307f\u305f\u3044\u3067\u3059\u3002\n\nHDFS\u30af\u30e9\u30b9\u30bf\u306e\u518d\u8d77\u52d5\n$ stop-dfs.sh\n$ start-dfs.sh\n\n\n\u4f7f\u3063\u3066\u307f\u308b\n\nEncryption key\u306e\u4f5c\u6210\n$ hadoop key create mykey\nmykey has been successfully created with options Options{cipher='AES/CTR/NoPadding', bitLength=128, description='null', attributes=null}.\nKMSClientProvider[http://localhost:16000/kms/v1/] has been updated.\n$ hadoop key list\nListing keys for KeyProvider: KMSClientProvider[http://localhost:16000/kms/v1/]\nmykey\n\nkeytool\u30b3\u30de\u30f3\u30c9\u3067\u3082\u78ba\u8a8d\u3002\n$ keytool -list -storetype jceks -keystore kms.keystore \n\u30ad\u30fc\u30b9\u30c8\u30a2\u306e\u30d1\u30b9\u30ef\u30fc\u30c9\u3092\u5165\u529b\u3057\u3066\u304f\u3060\u3055\u3044:  \n\n\u30ad\u30fc\u30b9\u30c8\u30a2\u306e\u30bf\u30a4\u30d7: JCEKS\n\u30ad\u30fc\u30b9\u30c8\u30a2\u30fb\u30d7\u30ed\u30d0\u30a4\u30c0: SunJCE\n\n\u30ad\u30fc\u30b9\u30c8\u30a2\u306b\u306f2\u30a8\u30f3\u30c8\u30ea\u304c\u542b\u307e\u308c\u307e\u3059\n\nmykey@0,2016/04/14, SecretKeyEntry, \nmykey,2016/04/14, SecretKeyEntry, \n\n\n\u30cf\u30de\u30ea\u3069\u3053\u308d3\n\u30c9\u30ad\u30e5\u30e1\u30f3\u30c8\u306b\u66f8\u3044\u3066\u3042\u308b\u30b3\u30de\u30f3\u30c9\u4f8b\u306f\u5931\u6557\u3057\u307e\u3059\u3002\n$ hadoop key create myKey\njava.lang.IllegalArgumentException: Uppercase key names are unsupported: myKey\n    at sun.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)\n    at sun.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62)\n    at sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)\n    at java.lang.reflect.Constructor.newInstance(Constructor.java:422)\n    at org.apache.hadoop.util.HttpExceptionUtils.validateResponse(HttpExceptionUtils.java:157)\n    at org.apache.hadoop.crypto.key.kms.KMSClientProvider.call(KMSClientProvider.java:546)\n    at org.apache.hadoop.crypto.key.kms.KMSClientProvider.call(KMSClientProvider.java:504)\n    at org.apache.hadoop.crypto.key.kms.KMSClientProvider.createKeyInternal(KMSClientProvider.java:677)\n    at org.apache.hadoop.crypto.key.kms.KMSClientProvider.createKey(KMSClientProvider.java:685)\n    at org.apache.hadoop.crypto.key.KeyShell$CreateCommand.execute(KeyShell.java:483)\n    at org.apache.hadoop.crypto.key.KeyShell.run(KeyShell.java:79)\n    at org.apache.hadoop.util.ToolRunner.run(ToolRunner.java:70)\n    at org.apache.hadoop.crypto.key.KeyShell.main(KeyShell.java:515)\n\n\u307b\u3093\u307e\u304b\uff1f\u5de5\u85e4\u30fb\u30fb\u30fb\n\u3068\u306b\u304b\u304f\u3001key\u540d\u306f\u5c0f\u6587\u5b57\u306e\u307f\u306b\u3057\u307e\u3057\u3087\u3046\u3002\n2016/2/10 \u8ffd\u8a18\n\u30c9\u30ad\u30e5\u30e1\u30f3\u30c8\u4fee\u6b63\u30d1\u30c3\u30c1\u304c\u30de\u30fc\u30b8\u3055\u308c\u307e\u3057\u305f\u3002\nhttps://issues.apache.org/jira/browse/HDFS-9784\n\n\u30cf\u30de\u308a\u3069\u3053\u308d4\nkeytool\u30b3\u30de\u30f3\u30c9\u3067\u78ba\u8a8d\u3059\u308b\u5834\u5408\u3001storetype\u3092\u6307\u5b9a\u3059\u308b\u5fc5\u8981\u304c\u3042\u308b\u304b\u3069\u3046\u304b\u6ce8\u610f\u3057\u307e\u3057\u3087\u3046\u3002\nkms-site.xml\u306e\u30c7\u30d5\u30a9\u30eb\u30c8\u3060\u3068JCEKS\u306b\u306a\u3063\u3066\u3044\u308b\u306e\u3067\u3001list\u3059\u308b\u969b\u306b\u660e\u793a\u7684\u306b\u6307\u5b9a\u3057\u306a\u3044\u3068\u4ee5\u4e0b\u306e\u3088\u3046\u306a\u610f\u5473\u4e0d\u660e\u306e\u30a8\u30e9\u30fc\u304c\u51fa\u307e\u3059\u3002\n$ keytool -list -keystore kms.keystore \nkeytool\u30a8\u30e9\u30fc: java.io.IOException: Invalid keystone format\n\n\nEncryption Zone\u306e\u4f5c\u6210\n$ hdfs dfs -mkdir /securezone\n$ hdfs crypto -createZone -keyName mykey -path /securezone\nAdded encryption zone /securezone\n$ hdfs crypto -listZones\n/securezone  mykey \n\n\n\u30c7\u30fc\u30bf\u3092\u7f6e\u3044\u3066\u307f\u308b\n$ hdfs dfs -put README.txt /securezone/\n$ hdfs dfs -ls /securezone\nFound 1 items\n-rw-r--r--   1 hadoop supergroup       1366 2016-02-07 14:31 /securezone/README.txt\n\n\u901a\u5e38\u306eHDFS\u30a2\u30af\u30bb\u30b9\u3068\u65b9\u6cd5\u306f\u4f55\u3082\u5909\u308f\u308a\u307e\u305b\u3093\u3002\n\n\u4e2d\u8eab\u304c\u6697\u53f7\u5316\u3055\u308c\u3066\u3044\u308b\u304b\u78ba\u8a8d\n\u5b9f\u969b\u306e\u30d6\u30ed\u30c3\u30af\u5185\u5bb9\u3092\u8997\u3044\u3066\u307f\u307e\u3059\u3002\n\u305d\u306e\u524d\u306b\u3001\u6bd4\u8f03\u306e\u305f\u3081\u306bEncryption Zone\u306e\u5916\u306b\u540c\u3058\u30d5\u30a1\u30a4\u30eb\u3092\u7f6e\u3044\u3066\u304a\u304d\u307e\u3059\u3002\n$ hdfs dfs -put README.txt /\n$ hdfs dfs -ls -R /\n-rw-r--r--   1 hadoop supergroup       1366 2016-02-07 14:32 /README.txt\ndrwxr-xr-x   - hadoop supergroup          0 2016-02-07 14:31 /securezone\n-rw-r--r--   1 hadoop supergroup       1366 2016-02-07 14:31 /securezone/README.txt\n\nDataNode\u306eDFS\u30c7\u30a3\u30ec\u30af\u30c8\u30ea\u3092\u4e0b\u3063\u3066\u30d6\u30ed\u30c3\u30af\u30d5\u30a1\u30a4\u30eb\u3092\u63a2\u3057\u307e\u3059\u3002\n$ pwd\n/tmp/hadoop-hadoop/dfs/data/current/BP-1497679019-127.0.0.1-1454819646630/current/finalized/subdir0/subdir0\n$ ll\n\u5408\u8a08 16\n-rw-rw-r--. 1 hadoop hadoop 1366  2\u6708  7 14:31 blk_1073741825\n-rw-rw-r--. 1 hadoop hadoop   19  2\u6708  7 14:31 blk_1073741825_1001.meta\n-rw-rw-r--. 1 hadoop hadoop 1366  2\u6708  7 14:32 blk_1073741826\n-rw-rw-r--. 1 hadoop hadoop   19  2\u6708  7 14:32 lk_1073741826_1002.meta\n\n\u30d5\u30a1\u30a4\u30eb\u306e\u4e2d\u3092\u8997\u3044\u3066\u307f\u308b\u3068\u3001\u3001\u3001\n$ cat blk_1073741825\n??e7]\u07ed?\n??z\njt\u05d7\u0378??????>zP!X)?\u0148?W?0 ?]sqj?IBD????4????_?r?W?B1? ?#Y$+??/by?c?\ue682N??\u048d????-? ??DmE?8}yJA??8t??cyx??&??CDnY\u07e4?1???? ?KO?W?????\n??\u07e4?p\n?^|x?R=_?w??D?? L\u03a7?mE?s?\u035es??})Agn??wc????????9R:(?[x??    ???T??E?S?1??^?*R??\n??I5??r??&??.?yQHz;,?a????s??Z??0?qHEr\u047e??#??cT7&\u64b3&HI3???@????1M??IL?????8???:dV}?&bP???i???\u0476/?U?m??5?w?d?`mK??O9\n?[??\u01f4??F];=\u04ff%Q??Uc?k?z'????~???8???V%???O%a?\n                                            ??}????P?z\u0599\n?bE?j????Dso??h)\u056a\u0260??<\u073b???d?.G????z\u06fax?}e?a?U\u5233M?\n                                              ??09E?,??Vz?h?    \u05a5????\"iAf?J#{d??????4?PF?W?g\\??`??L?????O???q???\u035fJ???'?B?P??Iy?Fd??????   (S??!S????\\P?{??7=???p?f?Gu>J??8??_2??\uef005X??\u0143?)??_!??\n8J?%,??n%<WT??w?'??[<9Fe?Yq????\u2029?8y???\nDd????v?]d@/?\n\u01c7)L\u0755??\u047a????1J\u0082>OM&?g2?-??A6?-?t??2???~s\u04a99???C\n\u01e4??*?)Y?4kj?}\u01e7?\\?G???Be\n??n:k1?%/=m???v?????????    ???yf\"?,????W   3????y?C\u07fe??i\u04e6W+?\u028d?????/BP[t??46o{8??t??n\n                                                                                        ?~??\"?o|\u0613F?+??g??U???]Zq?? ??\nVnl?Xk?u?#R8?^?NI?(Q?v?&\u021b?;?\u064e??vl??\n                     oF?V??,C?\u059a?E}5?q?w?i?i]+?Lg?Z?&?D?????E\n                                                           ???GVx?L?W????(?\u0730?!?<U???%<86U(?w???D?E\\???ESVI??hJ?1j??H?M?U;?? .J?Ce>?[3?????\u0250i????<?Aa?s??????%X??9??\"??*???\u00ef??&?$ ??I\n                 ??bx~?Mtr,?(????????d?6??????<?>m?M*\n\n\u3053\u3063\u3061\u306f\u6697\u53f7\u5316\u3055\u308c\u305f\u65b9\u307f\u305f\u3044\u3067\u3059\u306d\u3002\u3044\u3044\u611f\u3058\u306e\u30d0\u30a4\u30ca\u30ea\u30c7\u30fc\u30bf\u3067\u3059\u3002\n$ cat blk_1073741826\nFor the latest information about Hadoop, please visit our website at:\n\n   http://hadoop.apache.org/core/\n\nand our wiki, at:\n\n   http://wiki.apache.org/hadoop/\n\nThis distribution includes cryptographic software.  The country in \nwhich you currently reside may have restrictions on the import, \npossession, use, and/or re-export to another country, of \nencryption software.  BEFORE using any encryption software, please \ncheck your country's laws, regulations and policies concerning the\nimport, possession, or use, and re-export of encryption software, to \nsee if this is permitted.  See <http://www.wassenaar.org/> for more\ninformation.\n\nThe U.S. Government Department of Commerce, Bureau of Industry and\nSecurity (BIS), has classified this software as Export Commodity \nControl Number (ECCN) 5D002.C.1, which includes information security\nsoftware using or performing cryptographic functions with asymmetric\nalgorithms.  The form and manner of this Apache Software Foundation\ndistribution makes it eligible for export under the License Exception\nENC Technology Software Unrestricted (TSU) exception (see the BIS \nExport Administration Regulations, Section 740.13) for both object \ncode and source code.\n\nThe following provides more details on the included cryptographic\nsoftware:\n  Hadoop Core uses the SSL libraries from the Jetty project written \nby mortbay.org.\n\n\u3082\u3046\u4e00\u65b9\u306f\u30c6\u30ad\u30b9\u30c8\u30d5\u30a1\u30a4\u30eb\u306e\u307e\u307e\u3067\u3057\u305f\u3002\u3053\u3063\u3061\u306fEncryption Zone\u306e\u5916\u306b\u7f6e\u3044\u305f\u65b9\u3067\u3059\u306d\u3002\n\nHDFS\u30af\u30e9\u30a4\u30a2\u30f3\u30c8\u304b\u3089\u6697\u53f7\u5316\u3092\u610f\u8b58\u305b\u305a\u306b\u30a2\u30af\u30bb\u30b9\u3067\u304d\u308b\u304b\u78ba\u8a8d\n$ hdfs dfs -tail /securezone/README.txt\ntry, of \nencryption software.  BEFORE using any encryption software, please \ncheck your country's laws, regulations and policies concerning the\nimport, possession, or use, and re-export of encryption software, to \nsee if this is permitted.  See <http://www.wassenaar.org/> for more\ninformation.\n\nThe U.S. Government Department of Commerce, Bureau of Industry and\nSecurity (BIS), has classified this software as Export Commodity \nControl Number (ECCN) 5D002.C.1, which includes information security\nsoftware using or performing cryptographic functions with asymmetric\nalgorithms.  The form and manner of this Apache Software Foundation\ndistribution makes it eligible for export under the License Exception\nENC Technology Software Unrestricted (TSU) exception (see the BIS \nExport Administration Regulations, Section 740.13) for both object \ncode and source code.\n\nThe following provides more details on the included cryptographic\nsoftware:\n  Hadoop Core uses the SSL libraries from the Jetty project written \nby mortbay.org.\n\n\u5927\u4e08\u592b\u3067\u3057\u305f\u3002\n\nMapReduce\u304b\u3089\u6697\u53f7\u5316\u3092\u610f\u8b58\u305b\u305a\u306b\u30a2\u30af\u30bb\u30b9\u3067\u304d\u308b\u304b\u78ba\u8a8d\nHadoop\u3068\u3044\u3048\u3070WordCount\n$ hadoop jar share/hadoop/mapreduce/hadoop-mapreduce-examples-2.7.2.jar wordcount /securezone/README.txt /out2\n\n$ hdfs dfs -ls -R /out2\n-rw-r--r--   1 hadoop supergroup          0 2016-02-07 14:42 /out2/_SUCCESS\n-rw-r--r--   1 hadoop supergroup       1306 2016-02-07 14:42 /out2/part-r-00000\n$ hdfs dfs -cat /out2/part-r-00000\n(BIS),  1\n(ECCN)  1\n(TSU)   1\n(see    1\n5D002.C.1,  1\n740.13) 1\n<http://www.wassenaar.org/> 1\nAdministration  1\nApache  1\nBEFORE  1\nBIS 1\nBureau  1\nCommerce,   1\nCommodity   1\nControl 1\nCore    1\nDepartment  1\nENC 1\nException   1\nExport  2\nFor 1\nFoundation  1\nGovernment  1\nHadoop  1\nHadoop, 1\nIndustry    1\nJetty   1\nLicense 1\nNumber  1\nRegulations,    1\nSSL 1\nSection 1\nSecurity    1\nSee 1\nSoftware    2\nTechnology  1\nThe 4\nThis    1\nU.S.    1\nUnrestricted    1\nabout   1\nalgorithms. 1\nand 6\nand/or  1\nanother 1\nany 1\nas  1\nasymmetric  1\nat: 2\nboth    1\nby  1\ncheck   1\nclassified  1\ncode    1\ncode.   1\nconcerning  1\ncountry 1\ncountry's   1\ncountry,    1\ncryptographic   3\ncurrently   1\ndetails 1\ndistribution    2\neligible    1\nencryption  3\nexception   1\nexport  1\nfollowing   1\nfor 3\nform    1\nfrom    1\nfunctions   1\nhas 1\nhave    1\nhttp://hadoop.apache.org/core/  1\nhttp://wiki.apache.org/hadoop/  1\nif  1\nimport, 2\nin  1\nincluded    1\nincludes    2\ninformation 2\ninformation.    1\nis  1\nit  1\nlatest  1\nlaws,   1\nlibraries   1\nmakes   1\nmanner  1\nmay 1\nmore    2\nmortbay.org.    1\nobject  1\nof  5\non  2\nor  2\nour 2\nperforming  1\npermitted.  1\nplease  2\npolicies    1\npossession, 2\nproject 1\nprovides    1\nre-export   2\nregulations 1\nreside  1\nrestrictions    1\nsecurity    1\nsee 1\nsoftware    2\nsoftware,   2\nsoftware.   2\nsoftware:   1\nsource  1\nthe 8\nthis    3\nto  2\nunder   1\nuse,    2\nuses    1\nusing   2\nvisit   1\nwebsite 1\nwhich   2\nwiki,   1\nwith    1\nwritten 1\nyou 1\nyour    1\n\n\u5927\u4e08\u592b\u305d\u3046\u3067\u3059\u306d\u3002\n\u5ff5\u306e\u305f\u3081Encryption Zone\u306e\u5916\u306b\u7f6e\u3044\u305f\u540c\u3058\u30d5\u30a1\u30a4\u30eb\u306b\u5bfe\u3059\u308b\u7d50\u679c\u3092diff\u3057\u3066\u3082\u540c\u3058\u7d50\u679c\u306b\u306a\u3063\u3066\u3044\u307e\u3057\u305f\u3002\n\u4ee5\u4e0a\uff01\n\n\u304a\u307e\u3051 ~KMS\u304c\u6b7b\u306c\u6642\u3069\u3046\u306a\u308b\u306e~\n\u3082\u3057\u3082HDFS\u30af\u30e9\u30b9\u30bf\u304c\u52d5\u4f5c\u3057\u3066\u3044\u3066\u3082KMS\u304c\u6b7b\u3093\u3060\u3089\uff1f\n$ hdfs dfs -cat /securezone/README.txt\ncat: \u63a5\u7d9a\u3092\u62d2\u5426\u3055\u308c\u307e\u3057\u305f\n\n$ hadoop jar share/hadoop/mapreduce/hadoop-mapreduce-examples-3.0.0-SNAPSHOT.jar wordcount /securezone/README.txt /out\n16/02/07 23:55:57 INFO Configuration.deprecation: session.id is deprecated. Instead, use dfs.metrics.session-id\n16/02/07 23:55:57 INFO jvm.JvmMetrics: Initializing JVM Metrics with processName=JobTracker, sessionId=\n16/02/07 23:55:58 INFO input.FileInputFormat: Total input files to process : 1\n16/02/07 23:55:58 INFO mapreduce.JobSubmitter: number of splits:1\n16/02/07 23:55:58 INFO mapreduce.JobSubmitter: Submitting tokens for job: job_local471899076_0001\n16/02/07 23:55:58 INFO mapreduce.Job: The url to track the job: http://localhost:8080/\n16/02/07 23:55:58 INFO mapreduce.Job: Running job: job_local471899076_0001\n16/02/07 23:55:58 INFO mapred.LocalJobRunner: OutputCommitter set in config null\n16/02/07 23:55:58 INFO output.FileOutputCommitter: File Output Committer Algorithm version is 2\n16/02/07 23:55:58 INFO output.FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\n16/02/07 23:55:58 INFO mapred.LocalJobRunner: OutputCommitter is org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter\n16/02/07 23:55:58 INFO mapred.LocalJobRunner: Waiting for map tasks\n16/02/07 23:55:58 INFO mapred.LocalJobRunner: Starting task: attempt_local471899076_0001_m_000000_0\n16/02/07 23:55:58 INFO output.FileOutputCommitter: File Output Committer Algorithm version is 2\n16/02/07 23:55:58 INFO output.FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\n16/02/07 23:55:58 INFO mapred.Task:  Using ResourceCalculatorProcessTree : [ ]\n16/02/07 23:55:58 INFO mapred.MapTask: Processing split: hdfs://localhost:9000/securezone/README.txt:0+1366\n16/02/07 23:55:58 INFO mapred.MapTask: (EQUATOR) 0 kvi 26214396(104857584)\n16/02/07 23:55:58 INFO mapred.MapTask: mapreduce.task.io.sort.mb: 100\n16/02/07 23:55:58 INFO mapred.MapTask: soft limit at 83886080\n16/02/07 23:55:58 INFO mapred.MapTask: bufstart = 0; bufvoid = 104857600\n16/02/07 23:55:58 INFO mapred.MapTask: kvstart = 26214396; length = 6553600\n16/02/07 23:55:58 INFO mapred.MapTask: Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer\n16/02/07 23:55:58 INFO mapred.MapTask: Starting flush of map output\n16/02/07 23:55:58 INFO mapred.LocalJobRunner: map task executor complete.\n16/02/07 23:55:58 WARN mapred.LocalJobRunner: job_local471899076_0001\njava.lang.Exception: java.net.ConnectException: \u63a5\u7d9a\u3092\u62d2\u5426\u3055\u308c\u307e\u3057\u305f\n    at org.apache.hadoop.mapred.LocalJobRunner$Job.runTasks(LocalJobRunner.java:490)\n    at org.apache.hadoop.mapred.LocalJobRunner$Job.run(LocalJobRunner.java:550)\nCaused by: java.net.ConnectException: \u63a5\u7d9a\u3092\u62d2\u5426\u3055\u308c\u307e\u3057\u305f\n    at java.net.PlainSocketImpl.socketConnect(Native Method)\n    at java.net.AbstractPlainSocketImpl.doConnect(AbstractPlainSocketImpl.java:350)\n    at java.net.AbstractPlainSocketImpl.connectToAddress(AbstractPlainSocketImpl.java:206)\n    at java.net.AbstractPlainSocketImpl.connect(AbstractPlainSocketImpl.java:188)\n    at java.net.SocksSocketImpl.connect(SocksSocketImpl.java:392)\n    at java.net.Socket.connect(Socket.java:589)\n    at sun.net.NetworkClient.doConnect(NetworkClient.java:175)\n    at sun.net.www.http.HttpClient.openServer(HttpClient.java:432)\n    at sun.net.www.http.HttpClient.openServer(HttpClient.java:527)\n    at sun.net.www.http.HttpClient.<init>(HttpClient.java:211)\n    at sun.net.www.http.HttpClient.New(HttpClient.java:308)\n    at sun.net.www.http.HttpClient.New(HttpClient.java:326)\n    at sun.net.www.protocol.http.HttpURLConnection.getNewHttpClient(HttpURLConnection.java:1169)\n    at sun.net.www.protocol.http.HttpURLConnection.plainConnect0(HttpURLConnection.java:1105)\n    at sun.net.www.protocol.http.HttpURLConnection.plainConnect(HttpURLConnection.java:999)\n    at sun.net.www.protocol.http.HttpURLConnection.connect(HttpURLConnection.java:933)\n    at org.apache.hadoop.security.authentication.client.KerberosAuthenticator.authenticate(KerberosAuthenticator.java:190)\n    at org.apache.hadoop.security.token.delegation.web.DelegationTokenAuthenticator.authenticate(DelegationTokenAuthenticator.java:128)\n    at org.apache.hadoop.security.authentication.client.AuthenticatedURL.openConnection(AuthenticatedURL.java:215)\n    at org.apache.hadoop.security.token.delegation.web.DelegationTokenAuthenticatedURL.openConnection(DelegationTokenAuthenticatedURL.java:322)\n    at org.apache.hadoop.crypto.key.kms.KMSClientProvider$1.run(KMSClientProvider.java:486)\n    at org.apache.hadoop.crypto.key.kms.KMSClientProvider$1.run(KMSClientProvider.java:481)\n    at java.security.AccessController.doPrivileged(Native Method)\n    at javax.security.auth.Subject.doAs(Subject.java:422)\n    at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1729)\n    at org.apache.hadoop.crypto.key.kms.KMSClientProvider.createConnection(KMSClientProvider.java:481)\n    at org.apache.hadoop.crypto.key.kms.KMSClientProvider.decryptEncryptedKey(KMSClientProvider.java:774)\n    at org.apache.hadoop.crypto.key.KeyProviderCryptoExtension.decryptEncryptedKey(KeyProviderCryptoExtension.java:388)\n    at org.apache.hadoop.hdfs.DFSClient.decryptEncryptedDataEncryptionKey(DFSClient.java:901)\n    at org.apache.hadoop.hdfs.DFSClient.createWrappedInputStream(DFSClient.java:969)\n    at org.apache.hadoop.hdfs.DistributedFileSystem$3.doCall(DistributedFileSystem.java:273)\n    at org.apache.hadoop.hdfs.DistributedFileSystem$3.doCall(DistributedFileSystem.java:268)\n    at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)\n    at org.apache.hadoop.hdfs.DistributedFileSystem.open(DistributedFileSystem.java:280)\n    at org.apache.hadoop.fs.FileSystem.open(FileSystem.java:777)\n    at org.apache.hadoop.mapreduce.lib.input.LineRecordReader.initialize(LineRecordReader.java:85)\n    at org.apache.hadoop.mapred.MapTask$NewTrackingRecordReader.initialize(MapTask.java:548)\n    at org.apache.hadoop.mapred.MapTask.runNewMapper(MapTask.java:786)\n    at org.apache.hadoop.mapred.MapTask.run(MapTask.java:341)\n    at org.apache.hadoop.mapred.LocalJobRunner$Job$MapTaskRunnable.run(LocalJobRunner.java:271)\n    at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)\n    at java.util.concurrent.FutureTask.run(FutureTask.java:266)\n    at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)\n    at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)\n    at java.lang.Thread.run(Thread.java:745)\n16/02/07 23:55:59 INFO mapreduce.Job: Job job_local471899076_0001 running in uber mode : false\n16/02/07 23:55:59 INFO mapreduce.Job:  map 0% reduce 0%\n16/02/07 23:55:59 INFO mapreduce.Job: Job job_local471899076_0001 failed with state FAILED due to: NA\n16/02/07 23:55:59 INFO mapreduce.Job: Counters: 0\n\n\u30a2\u30ab\u30f3\u3084\u3064\u3084\u30fb\u30fb\u30fb\n\nHDFS\u4e0a\u306e\u30c7\u30fc\u30bf\u3092\u6697\u53f7\u5316\u3059\u308bTransparent Encryption in HDFS\u3092\u8a66\u3057\u3066\u307f\u307e\u3057\u305f\u3002\n\u74b0\u5883\u306f\n* CentOS 7.2\n* Oracle Java 1.8.0_65\n* Apache Hadoop 2.7.2\n\nTransparent Encryption in HDFS \u306e\u8aac\u660e\u306f[\u30c9\u30ad\u30e5\u30e1\u30f3\u30c8](http://hadoop.apache.org/docs/r2.7.2/hadoop-project-dist/hadoop-hdfs/TransparentEncryption.html)\u53c2\u7167\u3067\u3059\u3002\n\n\u96d1\u306b\u307e\u3068\u3081\u308b\u3068\u3001\u65b0\u3057\u3044\u30b3\u30f3\u30dd\u30fc\u30cd\u30f3\u30c8Key Management Server(KMS)\u3092\u8ffd\u52a0\u3059\u308b\u4ee3\u308f\u308a\u306b\u3001\u6697\u53f7\u5316\u30ad\u30fc\u306e\u7ba1\u7406\u3092\u900f\u904e\u7684\u306b\u3084\u3063\u3066\u304f\u308c\u307e\u3059\u3002\n\n\u6f02\u3046SPOF\u611f\u30fb\u30fb\u30fb\n\n\n# HDFS\u30af\u30e9\u30b9\u30bf\u306e\u521d\u671f\u5316\n\n\u4ee5\u524d\u66f8\u3044\u305f\u624b\u9806\u3067\u5b9f\u65bd\u30022.7.2\u3067\u3082\u540c\u3058\u3067\u3059\u3002\n\nhttp://qiita.com/bwtakacy/items/6491b3d11754492f9702\n\n# KMS\u306e\u8a2d\u5b9a\n\nkms-site.xml\u306e\u4ee5\u4e0b\u306e\u30d1\u30e9\u30e1\u30fc\u30bf\u304c\u6700\u4f4e\u9650\u5fc5\u8981\u306a\u3088\u3046\u3067\u3059\u3002\u30c7\u30d5\u30a9\u30eb\u30c8\u3067\u5165\u3063\u3066\u3044\u308b\u5024\u3092\u4eca\u56de\u306f\u4f7f\u3044\u307e\u3059\u3002\n\n```\n  <!-- KMS Backend KeyProvider -->\n\n  <property>\n    <name>hadoop.kms.key.provider.uri</name>\n    <value>jceks://file@/${user.home}/kms.keystore</value>\n    <description>\n      URI of the backing KeyProvider for the KMS.\n    </description>\n  </property>\n\n  <property>\n    <name>hadoop.security.keystore.java-keystore-provider.password-file</name>\n    <value>kms.keystore.password</value>\n    <description>\n      If using the JavaKeyStoreProvider, the password for the keystore file.\n    </description>\n  </property>\n```\n\nKeyProvider\u3068\u3057\u3066Java\u4ed8\u5c5e\u306eKeyStore\u3092\u5229\u7528\u3059\u308b\u5b9f\u88c5\u306b\u306a\u3063\u3066\u3044\u308b\u3088\u3046\u3067\u3059\u3002\nKMS\u521d\u56de\u8d77\u52d5\u6642\u306b\u3001\u6307\u5b9a\u3057\u305f\u30d1\u30b9\u306b\u6307\u5b9a\u3057\u305f\u30d1\u30b9\u30ef\u30fc\u30c9\u3067KeyStore\u304c\u4f5c\u6210\u3055\u308c\u307e\u3059\u3002\n\n\n# KMS\u306e\u8d77\u52d5\n\n```\n$ sbin/kms.sh start\n```\n\n\n## \u30cf\u30de\u308a\u3069\u3053\u308d1\n\n\u30c9\u30ad\u30e5\u30e1\u30f3\u30c8\u3092\u898b\u308b\u3068\u3001\n```\nThe password file is looked up in the Hadoop\u2019s configuration directory via the class path.\n```\nhttp://hadoop.apache.org/docs/r2.7.2/hadoop-kms/index.html\n\n\u3068\u3042\u308b\u306e\u3067\u3001Hadoop\u306e\u8a2d\u5b9a\u30d5\u30a1\u30a4\u30eb\u304c\u7f6e\u3044\u3066\u3042\u308b\u5834\u6240\uff08\u3053\u306e\u74b0\u5883\u3067\u306f$HADOOP_PREFIX/etc/hadoop\uff09\u306b\u7f6e\u3044\u3066\u3044\u305f\u306e\u3067\u3059\u304c\u3001\u30d1\u30b9\u30ef\u30fc\u30c9\u30d5\u30a1\u30a4\u30eb\u3092KMS\u304c\u3046\u307e\u304f\u8a8d\u8b58\u3057\u3066\u304f\u308c\u305a\u8d77\u52d5\u3057\u307e\u305b\u3093\u3067\u3057\u305f\u3002\n\n\u3044\u308d\u3044\u308d\u8a66\u884c\u932f\u8aa4\u3057\u305f\u306e\u3067\u3059\u304c\u3001\u4e0a\u306e\u8aac\u660e\u3092\u3088\u304f\u8aad\u3080\u3068\u5206\u304b\u308b\u3088\u3046\u306b\u3001CLASSPATH\u7d4c\u7531\u3067\u898b\u3048\u3066\u3044\u308b\u5fc5\u8981\u304c\u3042\u308b\u3088\u3046\u3067\u3059\u3002\n\nKMS\u306fTomcat\u306b\u30ed\u30fc\u30c9\u3055\u308c\u3066\u8d77\u52d5\u3059\u308b\u306e\u3067\u3059\u304c\u3001\u305d\u306e\u8d77\u52d5\u306e\u969b\u306bTomcat\u306eCLASSPATH\u306bHadoop\u306e\u8a2d\u5b9a\u30d5\u30a1\u30a4\u30eb\u306e\u30d1\u30b9\u304c\u6e21\u3055\u308c\u3066\u3044\u306a\u3044\u3088\u3046\u3067\u3059\u3002\n\n~~kms-site.xml\u3068\u540c\u3058\u3068\u3053\u308d\u306b\u3042\u308bkms-env.sh\u306b\u4ee5\u4e0b\u306e\uff11\u884c\u3092\u8ffd\u52a0\u3059\u308b\u3068\u3001\u3046\u307e\u304f\u8a8d\u8b58\u3067\u304d\u308b\u3088\u3046\u306b\u306a\u308a\u307e\u3057\u305f\u3002~~\n\n```\nexport CLASSPATH=$CLASSPATH:/usr/local/hadoop/etc/hadoop/kms.keystore.password\n```\n\n2016/2/7 11:20\u3000\u8ffd\u8a18\n\u3084\u308a\u76f4\u3057\u3066\u307f\u305f\u3068\u3053\u308d\u3001\u4e0a\u8a18\u3067\u3082\u30c0\u30e1\u3067\u3057\u305f\u3002\u3002\u3002\n\u3069\u3046\u3084\u3089Tomcat\u306e\u30af\u30e9\u30b9\u30d1\u30b9\u304c\u5dee\u3057\u3066\u3044\u308b\u3068\u3053\u308d\u306b\u30d1\u30b9\u30ef\u30fc\u30c9\u30d5\u30a1\u30a4\u30eb\u3092\u7f6e\u304f\u304f\u3089\u3044\u3057\u304b\u898b\u51fa\u305b\u307e\u305b\u3093\u3067\u3057\u305f\u3002\n\u5834\u6240\u306f``$HADOOP_PREFIX/share/hadoop/kms/tomcat/webapps/kms/WEB-INF/classes/``\u3067\u3059\u3002\n\n2016/2/7 11:40\u3000\u8ffd\u8a18\n\u3082\u3046\u4e00\u3064\u3084\u308a\u65b9\u3092\u898b\u3064\u3051\u307e\u3057\u305f\u3002\n\u3069\u3046\u3084\u3089\u3001keystore\u30d1\u30b9\u30ef\u30fc\u30c9\u306f\u30d5\u30a1\u30a4\u30eb\u306b\u66f8\u3044\u3066\u8aad\u307f\u8fbc\u307e\u305b\u308b\u4ed6\u306b\u3001\u74b0\u5883\u5909\u6570``HADOOP_KEYSTORE_PASSWORD``\u3067\u4e0e\u3048\u308b\u65b9\u6cd5\u3082\u3042\u308b\u3088\u3046\u3067\u3059\u3002\u3053\u306e\u5834\u5408\u3001kms-env.sh\u306b\n\n```\nexport HADOOP_KEYSTORE_PASSWORD=password\n```\n\n\u3068\u3084\u3063\u3066\u30d1\u30b9\u30ef\u30fc\u30c9\u3092\u4e0e\u3048\u308c\u3070OK\u3067\u3059\u3002\n\n\n\n\n\n###\n\n# Hadoop\u5074\u3067\u306eKMS\u5229\u7528\u8a2d\u5b9a\n\nhfs-site.xml\u306b\u4ee5\u4e0b\u3092\u8ffd\u8a18\u3057\u307e\u3059\u3002\n\n```\n<property>\n  <name>dfs.encryption.key.provider.uri</name>\n  <value>kms://http@localhost:16000/kms</value>\n  <description>\n    The KeyProvider to use when interacting with encryption keys used \n    when reading and writing to an encryption zone.\n  </description>\n</property>\n```\n\n## \u30cf\u30de\u30ea\u3069\u3053\u308d2\n\n\u4e0a\u8a18\u306e\u30d1\u30e9\u30e1\u30fc\u30bf\u3060\u3051\u3060\u3068Encryption Zone\u3092\u4f5c\u6210\u3057\u3088\u3046\u3068\u3057\u305f\u969b\u306b\u6b21\u306e\u30a8\u30e9\u30fc\u304c\u51fa\u307e\u3057\u305f\u3002\n```\nThere are no valid KeyProviders configured. No key\n was created. You can use the -provider option to specify\n a provider to use.\n```\n\n\u306a\u3093\u30fb\u30fb\u30fb\u3060\u3068\u30fb\u30fb\u30fb\uff1f\n\n\u3053\u308c\u307e\u305f\u30cd\u30c3\u30c8\u4e0a\u53ca\u3073\u30bd\u30fc\u30b9\u30b3\u30fc\u30c9\u3092\u8abf\u67fb\u3057\u307e\u3057\u305f\u3002\n\u4f55\u6545\u304b\u30c9\u30ad\u30e5\u30e1\u30f3\u30c8\u306b\u8a18\u8f09\u304c\u306a\u304f\u3001core-default.xml\u306b\u3059\u3089\u8a18\u8f09\u304c\u306a\u3044\u306e\u3067\u3059\u304c\u3001\u4ee5\u4e0b\u306e\u30d1\u30e9\u30e1\u30fc\u30bf\u3092core-site.xml\u306b\u8a2d\u5b9a\u3059\u308b\u5fc5\u8981\u304c\u3042\u308b\u3088\u3046\u3067\u3059\u3002\n\n```\n    <property>\n        <name>hadoop.security.key.provider.path</name>\n        <value>kms://http@localhost:16000/kms</value>\n    </property>\n```\n\n\u8a2d\u5b9a\u3059\u308b\u5024\u306fdfs.encryption.key.provider.uri\u3068\u540c\u3058\u3067\u826f\u3044\u307f\u305f\u3044\u3067\u3059\u3002\n\n# HDFS\u30af\u30e9\u30b9\u30bf\u306e\u518d\u8d77\u52d5\n\n```\n$ stop-dfs.sh\n$ start-dfs.sh\n```\n\n# \u4f7f\u3063\u3066\u307f\u308b\n\n## Encryption key\u306e\u4f5c\u6210\n\n```\n$ hadoop key create mykey\nmykey has been successfully created with options Options{cipher='AES/CTR/NoPadding', bitLength=128, description='null', attributes=null}.\nKMSClientProvider[http://localhost:16000/kms/v1/] has been updated.\n$ hadoop key list\nListing keys for KeyProvider: KMSClientProvider[http://localhost:16000/kms/v1/]\nmykey\n```\n\nkeytool\u30b3\u30de\u30f3\u30c9\u3067\u3082\u78ba\u8a8d\u3002\n\n```\n$ keytool -list -storetype jceks -keystore kms.keystore \n\u30ad\u30fc\u30b9\u30c8\u30a2\u306e\u30d1\u30b9\u30ef\u30fc\u30c9\u3092\u5165\u529b\u3057\u3066\u304f\u3060\u3055\u3044:  \n\n\u30ad\u30fc\u30b9\u30c8\u30a2\u306e\u30bf\u30a4\u30d7: JCEKS\n\u30ad\u30fc\u30b9\u30c8\u30a2\u30fb\u30d7\u30ed\u30d0\u30a4\u30c0: SunJCE\n\n\u30ad\u30fc\u30b9\u30c8\u30a2\u306b\u306f2\u30a8\u30f3\u30c8\u30ea\u304c\u542b\u307e\u308c\u307e\u3059\n\nmykey@0,2016/04/14, SecretKeyEntry, \nmykey,2016/04/14, SecretKeyEntry, \n```\n\n### \u30cf\u30de\u30ea\u3069\u3053\u308d3\n\n[\u30c9\u30ad\u30e5\u30e1\u30f3\u30c8](http://hadoop.apache.org/docs/r2.7.2/hadoop-project-dist/hadoop-hdfs/TransparentEncryption.html#Example_usage)\u306b\u66f8\u3044\u3066\u3042\u308b\u30b3\u30de\u30f3\u30c9\u4f8b\u306f\u5931\u6557\u3057\u307e\u3059\u3002\n\n```\n$ hadoop key create myKey\njava.lang.IllegalArgumentException: Uppercase key names are unsupported: myKey\n\tat sun.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)\n\tat sun.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62)\n\tat sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)\n\tat java.lang.reflect.Constructor.newInstance(Constructor.java:422)\n\tat org.apache.hadoop.util.HttpExceptionUtils.validateResponse(HttpExceptionUtils.java:157)\n\tat org.apache.hadoop.crypto.key.kms.KMSClientProvider.call(KMSClientProvider.java:546)\n\tat org.apache.hadoop.crypto.key.kms.KMSClientProvider.call(KMSClientProvider.java:504)\n\tat org.apache.hadoop.crypto.key.kms.KMSClientProvider.createKeyInternal(KMSClientProvider.java:677)\n\tat org.apache.hadoop.crypto.key.kms.KMSClientProvider.createKey(KMSClientProvider.java:685)\n\tat org.apache.hadoop.crypto.key.KeyShell$CreateCommand.execute(KeyShell.java:483)\n\tat org.apache.hadoop.crypto.key.KeyShell.run(KeyShell.java:79)\n\tat org.apache.hadoop.util.ToolRunner.run(ToolRunner.java:70)\n\tat org.apache.hadoop.crypto.key.KeyShell.main(KeyShell.java:515)\n```\n\n\u307b\u3093\u307e\u304b\uff1f\u5de5\u85e4\u30fb\u30fb\u30fb\n\n\u3068\u306b\u304b\u304f\u3001key\u540d\u306f\u5c0f\u6587\u5b57\u306e\u307f\u306b\u3057\u307e\u3057\u3087\u3046\u3002\n\n2016/2/10 \u8ffd\u8a18\n\u30c9\u30ad\u30e5\u30e1\u30f3\u30c8\u4fee\u6b63\u30d1\u30c3\u30c1\u304c\u30de\u30fc\u30b8\u3055\u308c\u307e\u3057\u305f\u3002\nhttps://issues.apache.org/jira/browse/HDFS-9784\n\n### \u30cf\u30de\u308a\u3069\u3053\u308d4\n\nkeytool\u30b3\u30de\u30f3\u30c9\u3067\u78ba\u8a8d\u3059\u308b\u5834\u5408\u3001storetype\u3092\u6307\u5b9a\u3059\u308b\u5fc5\u8981\u304c\u3042\u308b\u304b\u3069\u3046\u304b\u6ce8\u610f\u3057\u307e\u3057\u3087\u3046\u3002\nkms-site.xml\u306e\u30c7\u30d5\u30a9\u30eb\u30c8\u3060\u3068JCEKS\u306b\u306a\u3063\u3066\u3044\u308b\u306e\u3067\u3001list\u3059\u308b\u969b\u306b\u660e\u793a\u7684\u306b\u6307\u5b9a\u3057\u306a\u3044\u3068\u4ee5\u4e0b\u306e\u3088\u3046\u306a\u610f\u5473\u4e0d\u660e\u306e\u30a8\u30e9\u30fc\u304c\u51fa\u307e\u3059\u3002\n\n```\n$ keytool -list -keystore kms.keystore \nkeytool\u30a8\u30e9\u30fc: java.io.IOException: Invalid keystone format\n```\n\n## Encryption Zone\u306e\u4f5c\u6210\n\n```\n$ hdfs dfs -mkdir /securezone\n$ hdfs crypto -createZone -keyName mykey -path /securezone\nAdded encryption zone /securezone\n$ hdfs crypto -listZones\n/securezone  mykey \n```\n\n## \u30c7\u30fc\u30bf\u3092\u7f6e\u3044\u3066\u307f\u308b\n\n```\n$ hdfs dfs -put README.txt /securezone/\n$ hdfs dfs -ls /securezone\nFound 1 items\n-rw-r--r--   1 hadoop supergroup       1366 2016-02-07 14:31 /securezone/README.txt\n```\n\n\u901a\u5e38\u306eHDFS\u30a2\u30af\u30bb\u30b9\u3068\u65b9\u6cd5\u306f\u4f55\u3082\u5909\u308f\u308a\u307e\u305b\u3093\u3002\n\n## \u4e2d\u8eab\u304c\u6697\u53f7\u5316\u3055\u308c\u3066\u3044\u308b\u304b\u78ba\u8a8d\n\n\u5b9f\u969b\u306e\u30d6\u30ed\u30c3\u30af\u5185\u5bb9\u3092\u8997\u3044\u3066\u307f\u307e\u3059\u3002\n\u305d\u306e\u524d\u306b\u3001\u6bd4\u8f03\u306e\u305f\u3081\u306bEncryption Zone\u306e\u5916\u306b\u540c\u3058\u30d5\u30a1\u30a4\u30eb\u3092\u7f6e\u3044\u3066\u304a\u304d\u307e\u3059\u3002\n\n```\n$ hdfs dfs -put README.txt /\n$ hdfs dfs -ls -R /\n-rw-r--r--   1 hadoop supergroup       1366 2016-02-07 14:32 /README.txt\ndrwxr-xr-x   - hadoop supergroup          0 2016-02-07 14:31 /securezone\n-rw-r--r--   1 hadoop supergroup       1366 2016-02-07 14:31 /securezone/README.txt\n```\n\nDataNode\u306eDFS\u30c7\u30a3\u30ec\u30af\u30c8\u30ea\u3092\u4e0b\u3063\u3066\u30d6\u30ed\u30c3\u30af\u30d5\u30a1\u30a4\u30eb\u3092\u63a2\u3057\u307e\u3059\u3002\n\n```\n$ pwd\n/tmp/hadoop-hadoop/dfs/data/current/BP-1497679019-127.0.0.1-1454819646630/current/finalized/subdir0/subdir0\n$ ll\n\u5408\u8a08 16\n-rw-rw-r--. 1 hadoop hadoop 1366  2\u6708  7 14:31 blk_1073741825\n-rw-rw-r--. 1 hadoop hadoop   19  2\u6708  7 14:31 blk_1073741825_1001.meta\n-rw-rw-r--. 1 hadoop hadoop 1366  2\u6708  7 14:32 blk_1073741826\n-rw-rw-r--. 1 hadoop hadoop   19  2\u6708  7 14:32 lk_1073741826_1002.meta\n```\n\n\u30d5\u30a1\u30a4\u30eb\u306e\u4e2d\u3092\u8997\u3044\u3066\u307f\u308b\u3068\u3001\u3001\u3001\n\n```\n$ cat blk_1073741825\n??e7]\u07ed?\n??z\njt\u05d7\u0378??????>zP!X)?\u0148?W?0 ?]sqj?IBD????4????_?r?W?B1? ?#Y$+??/by?c?\ue682N??\u048d????-? ??DmE?8}yJA??8t??cyx??&??CDnY\u07e4?1???? ?KO?W?????\n??\u07e4?p\n?^|x?R=_?w??D?? L\u03a7?mE?s?\u035es??})Agn??wc????????9R:(?[x??\t???T??E?S?1??^?*R??\n??I5??r??&??.?yQHz;,?a????s??Z??0?qHEr\u047e??#??cT7&\u64b3&HI3???@????1M??IL?????8???:dV}?&bP???i???\u0476/?U?m??5?w?d?`mK??O9\n?[??\u01f4??F];=\u04ff%Q??Uc?k?z'????~???8???V%???O%a?\n                                            ??}????P?z\u0599\n?bE?j????Dso??h)\u056a\u0260??<\u073b???d?.G????z\u06fax?}e?a?U\u5233M?\n                                              ??09E?,??Vz?h?\t\u05a5????\"iAf?J#{d??????4?PF?W?g\\??`??L?????O???q???\u035fJ???'?B?P??Iy?Fd??????\t(S??!S????\\P?{??7=???p?f?Gu>J??8??_2??\uef005X??\u0143?)??_!??\n8J?%,??n%<WT??w?'??[<9Fe?Yq????\u2029?8y???\nDd????v?]d@/?\n\u01c7)L\u0755??\u047a????1J\u0082>OM&?g2?-??A6?-?t??2???~s\u04a99???C\n\u01e4??*?)Y?4kj?}\u01e7?\\?G???Be\n??n:k1?%/=m???v?????????\t???yf\"?,????W\t3????y?C\u07fe??i\u04e6W+?\u028d?????/BP[t??46o{8??t??n\n                                                                                        ?~??\"?o|\u0613F?+??g??U???]Zq?? ??\nVnl?Xk?u?#R8?^?NI?(Q?v?&\u021b?;?\u064e??vl??\n                     oF?V??,C?\u059a?E}5?q?w?i?i]+?Lg?Z?&?D?????E\n                                                           ???GVx?L?W????(?\u0730?!?<U???%<86U(?w???D?E\\???ESVI??hJ?1j??H?M?U;?? .J?Ce>?[3?????\u0250i????<?Aa?s??????%X??9??\"??*???\u00ef??&?$\t??I\n                 ??bx~?Mtr,?(????????d?6??????<?>m?M*\n```\n\n\u3053\u3063\u3061\u306f\u6697\u53f7\u5316\u3055\u308c\u305f\u65b9\u307f\u305f\u3044\u3067\u3059\u306d\u3002\u3044\u3044\u611f\u3058\u306e\u30d0\u30a4\u30ca\u30ea\u30c7\u30fc\u30bf\u3067\u3059\u3002\n\n```\n$ cat blk_1073741826\nFor the latest information about Hadoop, please visit our website at:\n\n   http://hadoop.apache.org/core/\n\nand our wiki, at:\n\n   http://wiki.apache.org/hadoop/\n\nThis distribution includes cryptographic software.  The country in \nwhich you currently reside may have restrictions on the import, \npossession, use, and/or re-export to another country, of \nencryption software.  BEFORE using any encryption software, please \ncheck your country's laws, regulations and policies concerning the\nimport, possession, or use, and re-export of encryption software, to \nsee if this is permitted.  See <http://www.wassenaar.org/> for more\ninformation.\n\nThe U.S. Government Department of Commerce, Bureau of Industry and\nSecurity (BIS), has classified this software as Export Commodity \nControl Number (ECCN) 5D002.C.1, which includes information security\nsoftware using or performing cryptographic functions with asymmetric\nalgorithms.  The form and manner of this Apache Software Foundation\ndistribution makes it eligible for export under the License Exception\nENC Technology Software Unrestricted (TSU) exception (see the BIS \nExport Administration Regulations, Section 740.13) for both object \ncode and source code.\n\nThe following provides more details on the included cryptographic\nsoftware:\n  Hadoop Core uses the SSL libraries from the Jetty project written \nby mortbay.org.\n```\n\n\u3082\u3046\u4e00\u65b9\u306f\u30c6\u30ad\u30b9\u30c8\u30d5\u30a1\u30a4\u30eb\u306e\u307e\u307e\u3067\u3057\u305f\u3002\u3053\u3063\u3061\u306fEncryption Zone\u306e\u5916\u306b\u7f6e\u3044\u305f\u65b9\u3067\u3059\u306d\u3002\n\n## HDFS\u30af\u30e9\u30a4\u30a2\u30f3\u30c8\u304b\u3089\u6697\u53f7\u5316\u3092\u610f\u8b58\u305b\u305a\u306b\u30a2\u30af\u30bb\u30b9\u3067\u304d\u308b\u304b\u78ba\u8a8d\n\n```\n$ hdfs dfs -tail /securezone/README.txt\ntry, of \nencryption software.  BEFORE using any encryption software, please \ncheck your country's laws, regulations and policies concerning the\nimport, possession, or use, and re-export of encryption software, to \nsee if this is permitted.  See <http://www.wassenaar.org/> for more\ninformation.\n\nThe U.S. Government Department of Commerce, Bureau of Industry and\nSecurity (BIS), has classified this software as Export Commodity \nControl Number (ECCN) 5D002.C.1, which includes information security\nsoftware using or performing cryptographic functions with asymmetric\nalgorithms.  The form and manner of this Apache Software Foundation\ndistribution makes it eligible for export under the License Exception\nENC Technology Software Unrestricted (TSU) exception (see the BIS \nExport Administration Regulations, Section 740.13) for both object \ncode and source code.\n\nThe following provides more details on the included cryptographic\nsoftware:\n  Hadoop Core uses the SSL libraries from the Jetty project written \nby mortbay.org.\n```\n\n\u5927\u4e08\u592b\u3067\u3057\u305f\u3002\n\n## MapReduce\u304b\u3089\u6697\u53f7\u5316\u3092\u610f\u8b58\u305b\u305a\u306b\u30a2\u30af\u30bb\u30b9\u3067\u304d\u308b\u304b\u78ba\u8a8d\n\nHadoop\u3068\u3044\u3048\u3070WordCount\n\n```\n$ hadoop jar share/hadoop/mapreduce/hadoop-mapreduce-examples-2.7.2.jar wordcount /securezone/README.txt /out2\n```\n\n```\n$ hdfs dfs -ls -R /out2\n-rw-r--r--   1 hadoop supergroup          0 2016-02-07 14:42 /out2/_SUCCESS\n-rw-r--r--   1 hadoop supergroup       1306 2016-02-07 14:42 /out2/part-r-00000\n$ hdfs dfs -cat /out2/part-r-00000\n(BIS),\t1\n(ECCN)\t1\n(TSU)\t1\n(see\t1\n5D002.C.1,\t1\n740.13)\t1\n<http://www.wassenaar.org/>\t1\nAdministration\t1\nApache\t1\nBEFORE\t1\nBIS\t1\nBureau\t1\nCommerce,\t1\nCommodity\t1\nControl\t1\nCore\t1\nDepartment\t1\nENC\t1\nException\t1\nExport\t2\nFor\t1\nFoundation\t1\nGovernment\t1\nHadoop\t1\nHadoop,\t1\nIndustry\t1\nJetty\t1\nLicense\t1\nNumber\t1\nRegulations,\t1\nSSL\t1\nSection\t1\nSecurity\t1\nSee\t1\nSoftware\t2\nTechnology\t1\nThe\t4\nThis\t1\nU.S.\t1\nUnrestricted\t1\nabout\t1\nalgorithms.\t1\nand\t6\nand/or\t1\nanother\t1\nany\t1\nas\t1\nasymmetric\t1\nat:\t2\nboth\t1\nby\t1\ncheck\t1\nclassified\t1\ncode\t1\ncode.\t1\nconcerning\t1\ncountry\t1\ncountry's\t1\ncountry,\t1\ncryptographic\t3\ncurrently\t1\ndetails\t1\ndistribution\t2\neligible\t1\nencryption\t3\nexception\t1\nexport\t1\nfollowing\t1\nfor\t3\nform\t1\nfrom\t1\nfunctions\t1\nhas\t1\nhave\t1\nhttp://hadoop.apache.org/core/\t1\nhttp://wiki.apache.org/hadoop/\t1\nif\t1\nimport,\t2\nin\t1\nincluded\t1\nincludes\t2\ninformation\t2\ninformation.\t1\nis\t1\nit\t1\nlatest\t1\nlaws,\t1\nlibraries\t1\nmakes\t1\nmanner\t1\nmay\t1\nmore\t2\nmortbay.org.\t1\nobject\t1\nof\t5\non\t2\nor\t2\nour\t2\nperforming\t1\npermitted.\t1\nplease\t2\npolicies\t1\npossession,\t2\nproject\t1\nprovides\t1\nre-export\t2\nregulations\t1\nreside\t1\nrestrictions\t1\nsecurity\t1\nsee\t1\nsoftware\t2\nsoftware,\t2\nsoftware.\t2\nsoftware:\t1\nsource\t1\nthe\t8\nthis\t3\nto\t2\nunder\t1\nuse,\t2\nuses\t1\nusing\t2\nvisit\t1\nwebsite\t1\nwhich\t2\nwiki,\t1\nwith\t1\nwritten\t1\nyou\t1\nyour\t1\n```\n\n\u5927\u4e08\u592b\u305d\u3046\u3067\u3059\u306d\u3002\n\u5ff5\u306e\u305f\u3081Encryption Zone\u306e\u5916\u306b\u7f6e\u3044\u305f\u540c\u3058\u30d5\u30a1\u30a4\u30eb\u306b\u5bfe\u3059\u308b\u7d50\u679c\u3092diff\u3057\u3066\u3082\u540c\u3058\u7d50\u679c\u306b\u306a\u3063\u3066\u3044\u307e\u3057\u305f\u3002\n\n\u4ee5\u4e0a\uff01\n\n# \u304a\u307e\u3051 ~KMS\u304c\u6b7b\u306c\u6642\u3069\u3046\u306a\u308b\u306e~\n\n\u3082\u3057\u3082HDFS\u30af\u30e9\u30b9\u30bf\u304c\u52d5\u4f5c\u3057\u3066\u3044\u3066\u3082KMS\u304c\u6b7b\u3093\u3060\u3089\uff1f\n\n```\n$ hdfs dfs -cat /securezone/README.txt\ncat: \u63a5\u7d9a\u3092\u62d2\u5426\u3055\u308c\u307e\u3057\u305f\n```\n\n```\n$ hadoop jar share/hadoop/mapreduce/hadoop-mapreduce-examples-3.0.0-SNAPSHOT.jar wordcount /securezone/README.txt /out\n16/02/07 23:55:57 INFO Configuration.deprecation: session.id is deprecated. Instead, use dfs.metrics.session-id\n16/02/07 23:55:57 INFO jvm.JvmMetrics: Initializing JVM Metrics with processName=JobTracker, sessionId=\n16/02/07 23:55:58 INFO input.FileInputFormat: Total input files to process : 1\n16/02/07 23:55:58 INFO mapreduce.JobSubmitter: number of splits:1\n16/02/07 23:55:58 INFO mapreduce.JobSubmitter: Submitting tokens for job: job_local471899076_0001\n16/02/07 23:55:58 INFO mapreduce.Job: The url to track the job: http://localhost:8080/\n16/02/07 23:55:58 INFO mapreduce.Job: Running job: job_local471899076_0001\n16/02/07 23:55:58 INFO mapred.LocalJobRunner: OutputCommitter set in config null\n16/02/07 23:55:58 INFO output.FileOutputCommitter: File Output Committer Algorithm version is 2\n16/02/07 23:55:58 INFO output.FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\n16/02/07 23:55:58 INFO mapred.LocalJobRunner: OutputCommitter is org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter\n16/02/07 23:55:58 INFO mapred.LocalJobRunner: Waiting for map tasks\n16/02/07 23:55:58 INFO mapred.LocalJobRunner: Starting task: attempt_local471899076_0001_m_000000_0\n16/02/07 23:55:58 INFO output.FileOutputCommitter: File Output Committer Algorithm version is 2\n16/02/07 23:55:58 INFO output.FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\n16/02/07 23:55:58 INFO mapred.Task:  Using ResourceCalculatorProcessTree : [ ]\n16/02/07 23:55:58 INFO mapred.MapTask: Processing split: hdfs://localhost:9000/securezone/README.txt:0+1366\n16/02/07 23:55:58 INFO mapred.MapTask: (EQUATOR) 0 kvi 26214396(104857584)\n16/02/07 23:55:58 INFO mapred.MapTask: mapreduce.task.io.sort.mb: 100\n16/02/07 23:55:58 INFO mapred.MapTask: soft limit at 83886080\n16/02/07 23:55:58 INFO mapred.MapTask: bufstart = 0; bufvoid = 104857600\n16/02/07 23:55:58 INFO mapred.MapTask: kvstart = 26214396; length = 6553600\n16/02/07 23:55:58 INFO mapred.MapTask: Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer\n16/02/07 23:55:58 INFO mapred.MapTask: Starting flush of map output\n16/02/07 23:55:58 INFO mapred.LocalJobRunner: map task executor complete.\n16/02/07 23:55:58 WARN mapred.LocalJobRunner: job_local471899076_0001\njava.lang.Exception: java.net.ConnectException: \u63a5\u7d9a\u3092\u62d2\u5426\u3055\u308c\u307e\u3057\u305f\n\tat org.apache.hadoop.mapred.LocalJobRunner$Job.runTasks(LocalJobRunner.java:490)\n\tat org.apache.hadoop.mapred.LocalJobRunner$Job.run(LocalJobRunner.java:550)\nCaused by: java.net.ConnectException: \u63a5\u7d9a\u3092\u62d2\u5426\u3055\u308c\u307e\u3057\u305f\n\tat java.net.PlainSocketImpl.socketConnect(Native Method)\n\tat java.net.AbstractPlainSocketImpl.doConnect(AbstractPlainSocketImpl.java:350)\n\tat java.net.AbstractPlainSocketImpl.connectToAddress(AbstractPlainSocketImpl.java:206)\n\tat java.net.AbstractPlainSocketImpl.connect(AbstractPlainSocketImpl.java:188)\n\tat java.net.SocksSocketImpl.connect(SocksSocketImpl.java:392)\n\tat java.net.Socket.connect(Socket.java:589)\n\tat sun.net.NetworkClient.doConnect(NetworkClient.java:175)\n\tat sun.net.www.http.HttpClient.openServer(HttpClient.java:432)\n\tat sun.net.www.http.HttpClient.openServer(HttpClient.java:527)\n\tat sun.net.www.http.HttpClient.<init>(HttpClient.java:211)\n\tat sun.net.www.http.HttpClient.New(HttpClient.java:308)\n\tat sun.net.www.http.HttpClient.New(HttpClient.java:326)\n\tat sun.net.www.protocol.http.HttpURLConnection.getNewHttpClient(HttpURLConnection.java:1169)\n\tat sun.net.www.protocol.http.HttpURLConnection.plainConnect0(HttpURLConnection.java:1105)\n\tat sun.net.www.protocol.http.HttpURLConnection.plainConnect(HttpURLConnection.java:999)\n\tat sun.net.www.protocol.http.HttpURLConnection.connect(HttpURLConnection.java:933)\n\tat org.apache.hadoop.security.authentication.client.KerberosAuthenticator.authenticate(KerberosAuthenticator.java:190)\n\tat org.apache.hadoop.security.token.delegation.web.DelegationTokenAuthenticator.authenticate(DelegationTokenAuthenticator.java:128)\n\tat org.apache.hadoop.security.authentication.client.AuthenticatedURL.openConnection(AuthenticatedURL.java:215)\n\tat org.apache.hadoop.security.token.delegation.web.DelegationTokenAuthenticatedURL.openConnection(DelegationTokenAuthenticatedURL.java:322)\n\tat org.apache.hadoop.crypto.key.kms.KMSClientProvider$1.run(KMSClientProvider.java:486)\n\tat org.apache.hadoop.crypto.key.kms.KMSClientProvider$1.run(KMSClientProvider.java:481)\n\tat java.security.AccessController.doPrivileged(Native Method)\n\tat javax.security.auth.Subject.doAs(Subject.java:422)\n\tat org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1729)\n\tat org.apache.hadoop.crypto.key.kms.KMSClientProvider.createConnection(KMSClientProvider.java:481)\n\tat org.apache.hadoop.crypto.key.kms.KMSClientProvider.decryptEncryptedKey(KMSClientProvider.java:774)\n\tat org.apache.hadoop.crypto.key.KeyProviderCryptoExtension.decryptEncryptedKey(KeyProviderCryptoExtension.java:388)\n\tat org.apache.hadoop.hdfs.DFSClient.decryptEncryptedDataEncryptionKey(DFSClient.java:901)\n\tat org.apache.hadoop.hdfs.DFSClient.createWrappedInputStream(DFSClient.java:969)\n\tat org.apache.hadoop.hdfs.DistributedFileSystem$3.doCall(DistributedFileSystem.java:273)\n\tat org.apache.hadoop.hdfs.DistributedFileSystem$3.doCall(DistributedFileSystem.java:268)\n\tat org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)\n\tat org.apache.hadoop.hdfs.DistributedFileSystem.open(DistributedFileSystem.java:280)\n\tat org.apache.hadoop.fs.FileSystem.open(FileSystem.java:777)\n\tat org.apache.hadoop.mapreduce.lib.input.LineRecordReader.initialize(LineRecordReader.java:85)\n\tat org.apache.hadoop.mapred.MapTask$NewTrackingRecordReader.initialize(MapTask.java:548)\n\tat org.apache.hadoop.mapred.MapTask.runNewMapper(MapTask.java:786)\n\tat org.apache.hadoop.mapred.MapTask.run(MapTask.java:341)\n\tat org.apache.hadoop.mapred.LocalJobRunner$Job$MapTaskRunnable.run(LocalJobRunner.java:271)\n\tat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)\n\tat java.util.concurrent.FutureTask.run(FutureTask.java:266)\n\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)\n\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)\n\tat java.lang.Thread.run(Thread.java:745)\n16/02/07 23:55:59 INFO mapreduce.Job: Job job_local471899076_0001 running in uber mode : false\n16/02/07 23:55:59 INFO mapreduce.Job:  map 0% reduce 0%\n16/02/07 23:55:59 INFO mapreduce.Job: Job job_local471899076_0001 failed with state FAILED due to: NA\n16/02/07 23:55:59 INFO mapreduce.Job: Counters: 0\n```\n\n\u30a2\u30ab\u30f3\u3084\u3064\u3084\u30fb\u30fb\u30fb\n", "tags": ["hadoop", "\u30bb\u30ad\u30e5\u30ea\u30c6\u30a3", "\u30c7\u30fc\u30bf\u6697\u53f7\u5316"]}