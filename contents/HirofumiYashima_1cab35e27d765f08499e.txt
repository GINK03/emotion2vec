{"tags": ["\u6df1\u5c64\u5b66\u7fd2", "DeepLearning", "\u6642\u7cfb\u5217\u89e3\u6790", "statistics", "\u4eba\u5de5\u77e5\u80fd"], "context": "\n\n\uff08 \u95a2\u9023\u8a18\u4e8b \uff09\n\n\nHirofumiYashima Qiita\u8a18\u4e8b \u300cCNN \u3067 \u6642\u7cfb\u5217\u30c7\u30fc\u30bf \u306e \u7279\u5fb4\u91cf\uff08\u7279\u5fb4\u30de\u30c3\u30d7\uff09 \u3092 \u7573\u307f\u8fbc\u307f \u3067 \u62bd\u51fa\u3057\u3066\u3001 + \u30d7\u30fc\u30ea\u30f3\u30b0 \u3067 \u60c5\u5831\u5727\u7e2e \u3059\u308b \u65b9\u6cd5 \u3044\u308d\u3044\u308d\u300d\nHirofumiYashima Qiita\u8a18\u4e8b \u300c\u3010 \u8abf\u67fb \u3011CNN\uff08Convolution Neural Net\uff09\u3092 \u7528\u3044\u305f \u6642\u7cfb\u5217\u30c7\u30fc\u30bf\u306e\u4e88\u6e2c\u30bf\u30b9\u30af\u3001\u5206\u985e\u30bf\u30b9\u30af \u5fdc\u7528\u4e8b\u4f8b\u300d\n\n\n\n\uff08 \u65b9\u6cd5\uff11 \uff09\n\n\n\u5404\u5909\u6570\u3054\u3068\u306b\u3001\u6642\u7cfb\u5217\u30d1\u30bf\u30fc\u30f3\u306e\u7279\u5fb4\u30d9\u30af\u30c8\u30eb \u3092 \u500b\u5225\u306eLSTM\u30bf\u30b9\u30af \u3067 \u62bd\u51fa\u3057\u3001\u5404\u5909\u6570\u306e\u6642\u7cfb\u5217\u7279\u5fb4\u30d9\u30af\u30c8\u30eb \u3092 \u5f8c\u304b\u3089 \u7d71\u5408\uff08\u91cd\u307f\u5171\u6709\uff09\u3057\u3066\u3001\u591a\u5909\u91cf\u5168\u4f53\u306e\u6642\u7cfb\u5217\u7279\u5fb4\u91cf \u3092 \u7372\u5f97\u3059\u308b \u30a2\u30d7\u30ed\u30fc\u30c1\n\n\u30de\u30eb\u30c1\u30e2\u30fc\u30c0\u30ebDeep Learning\u3068\u540c\u3058\u30a2\u30d7\u30ed\u30fc\u30c1\n\n\n\uff11\u3064\u306e\u8aac\u660e\u5909\u6570\u306e\u6642\u7cfb\u5217\u7279\u5fb4\u91cf \u3092 \uff11\u3064\u306eLSTM \u3067 \u72ec\u7acb\u3057\u3066 \u5b66\u7fd2\u3001\n\u4e0a\u8a18 \u3092 \u8aac\u660e\u5909\u6570\u500b\u5206\u3001\u72ec\u7acb\u3057\u305fLSTM \u3092 \u4e26\u884c\u51e6\u7406\u3055\u305b\u308b\n\u500b\u3005\u306eLSTM \u304c\u62bd\u51fa\u3057\u305f \u500b\u3005\u306e\u8aac\u660e\u5909\u6570\uff08\u6642\u7cfb\u5217\u30c7\u30fc\u30bf\uff09\u306e\u7279\u5fb4\u91cf \u3092\u3001\u591a\u5909\u91cf\u6642\u7cfb\u5217\u30c7\u30fc\u30bf\u300c\u5168\u4f53\u300d\u306e\u5305\u62ec\u30fb\u7d71\u5408 \u7279\u5fb4\u91cf \u3068\u3057\u3066 \u7d71\u5408 \u3059\u308b\n\u7d71\u5408\u7279\u5fb4\u91cf \u306e \u5f8c\u308d \u306b \u6700\u7d42\u7684 \u306a \u51fa\u529b\u5c64 \u3092 \u8a2d\u7f6e\u3057\u3066\u3001\u6052\u7b49\u95a2\u6570\uff08\u56de\u5e30\u554f\u984c\uff09\u3001\u30ed\u30b8\u30b9\u30c6\u30a3\u30c3\u30af\u95a2\u6570\uff08\uff12\u5024\u5206\u985e\u554f\u984c\uff09\u3001Softmax\u95a2\u6570\uff08\u591a\u5024\u5206\u985e\u554f\u984c\uff09 \u3067 \u30cd\u30c3\u30c8\u30ef\u30fc\u30af\u3068\u3057\u3066 \u306e \u4e88\u6e2c\u7d50\u679c \u3092 \u51fa\u529b\u3059\u308b\n\n\n\uff08 \u4e8b\u4f8b \uff09\n\n\nDong Nie et.al, FULLY CONVOLUTIONAL NETWORKS FOR MULTI-MODALITY ISOINTENSE INFANT BRAIN IMAGE SEGMENTATION\n\n\nKeras \u3067\u306f\u3001Merge\u5c64 \u3067 \u8907\u6570\u306e\u5c64 \u3092 \u5408\u6d41\uff08\u7d71\u5408\uff09\u3055\u305b\u3066 \u7d71\u5408\u7279\u5fb4\u91cf\u5c64 \u3092 \u7d44\u3080\u3053\u3068 \u304c \u3067\u304d\u308b\u3002\n\n\nKeras Documentation \u300cSequential\u30e2\u30c7\u30eb\u3067Keras\u306b\u89e6\u308c\u3066\u307f\u3088\u3046\u300d\nHirofumiYashima Qiita\u8a18\u4e8b \u300c\u3010 \u591a\u5909\u91cf\u30de\u30eb\u30c1\u30e2\u30fc\u30c0\u30eb DeepLearning \u3011Keras \u306e Merge\u5c64 \u3067\u3001\u300c\u591a\u5165\u529b\u300d\uff1d\uff1e \u300c\u5358\u4e00\u51fa\u529b\u300d or \u300c\u591a\u51fa\u529b\u300d \u306e \u30cd\u30c3\u30c8\u30ef\u30fc\u30af\u30b0\u30e9\u30d5 \u3092 \u5b9f\u88c5\u3067\u304d\u308b\u300d\n\n\n\n\u30de\u30eb\u30c1\u30e2\u30fc\u30c0\u30ebDeep Learning \u306e \u30a2\u30d7\u30ed\u30fc\u30c1\n\nGoogle\u691c\u7d22 \u3067\u3001\u300c\u30de\u30eb\u30c1\u30e2\u30fc\u30c0\u30eb\u3001\u6df1\u5c64\u5b66\u7fd2\u300d\u3068\u3059\u308b\u3068\u3001\u53c2\u8003\u4f8b \u304c \u51fa\u3066\u304f\u308b\u3002\n\nHirofumiYashima Qiita\u8a18\u4e8b\u300c\u3010 \u57fa\u790e\u8abf\u67fb \u3011\u8907\u6570\u306e\u30bb\u30f3\u30b5\u611f\u899a\u30c7\u30fc\u30bf\uff08\u7279\u5fb4\u91cf\uff09\u3092\u7d71\u5408\u3057\u3066\u3001\u300c\u30de\u30eb\u30c1\u30e2\u30fc\u30c0\u30eb\u5b66\u7fd2\u300d\uff08\u30de\u30eb\u30c1\u30e2\u30fc\u30c0\u30eb\u7279\u5fb4\u91cf\uff09\u3092\u5f97\u308b\u305f\u3081\u306e\u624b\u6cd5\u3044\u308d\u3044\u308d\u300d\n\u9234\u6728 \u96c5\u5927\u30fb\u677e\u5c3e \u8c4a\u300c\u6df1\u5c64\u751f\u6210\u30e2\u30c7\u30eb\u3092\u7528\u3044\u305f\u30de\u30eb\u30c1\u30e2\u30fc\u30c0\u30eb\u5b66\u7fd2\u300d\n\n\n\u6df1\u5c64\u30cb\u30e5\u30fc\u30e9\u30eb\u30cd\u30c3\u30c8\u30ef\u30fc\u30af\u306f\uff0c\u5b66\u7fd2\u306e\u904e\u7a0b\u306b\u304a\u3044\u3066\u6df1\u3044\u5c64\u3067\u666e\u904d\u7684\u306a\u7279\u5fb4\u8868\u73fe\u304c\u7372\u5f97\u3067\u304d\u308b\u3053\u3068\u304c\u77e5\u3089\u308c\u3066\u3044\u308b\uff0e\n\u305d\u306e\u305f\u3081\uff0c\u3053\u308c\u307e\u3067\u6df1\u5c64\u6559\u5e2b\u306a\u3057\u5b66\u7fd2\u30e2\u30c7\u30eb\u3067\u3042\u308b autoencoder\uff08AE\uff09\u3084 restricted Boltzmann machine\uff08RBM\uff09\u306b\u3088\u308b\u30de\u30eb\u30c1\u30e2\u30fc\u30c0\u30eb\u5b66\u7fd2 [Ngiam 11, Srivastava 12] \u304c\u63d0\u6848\u3055\u308c\u3066\u3044\u308b\uff0e\n\u3053\u308c\u3089\u306f\u7279\u5fb4\u62bd\u51fa\u5668\u3084\u6df1\u5c64\u30cb\u30e5\u30fc\u30e9\u30eb\u30cd\u30c3\u30c8\u30ef\u30fc\u30af\u306e\u4e8b\u524d\u5b66\u7fd2\u306a\u3069\u306b\u7528\u3044\u3089\u308c\u308b\u30e2\u30c7\u30eb\u3067\uff0c2 \u3064\u306e\u30cd\u30c3\u30c8\u30ef\u30fc\u30af\u306e\u96a0\u308c\u5c64\uff0c\u3082\u3057\u304f\u306f\u6f5c\u5728\u5909\u6570\u3092\u5171\u6709\u3059\u308b\u3053\u3068\u3067\uff0c\u7570\u306a\u308b\u30e2\u30fc\u30c0\u30eb\u60c5\u5831\u304b\u3089\u5171\u901a\u304b\u3064\u3088\u308a\u9ad8\u6b21\u306e\u7279\u5fb4\u8868\u73fe\u3092\u7372\u5f97\u3059\u308b\u3053\u3068\u3092\u76ee\u7684\u3068\u3057\u3066\u3044\u308b\uff0e\n\u8fd1\u5e74\uff0c\u6df1\u5c64\u30cb\u30e5\u30fc\u30e9\u30eb\u30cd\u30c3\u30c8\u30ef\u30fc\u30af\u306b\u3088\u308b\u751f\u6210\u30e2\u30c7\u30eb\u3068\u3057\u3066\uff0cvariational autoencoder\uff08VAE\uff09[Kingma 13] \u304c \u63d0\u6848\u3055\u308c\u305f\uff0e\nVAE \u306f\u751f\u6210\u30e2\u30c7\u30eb\u3067\u3042\u308a\u306a\u304c\u3089\uff0c\u30e2\u30c7\u30eb\u3068\u3057\u3066\u901a\u5e38\u306e\u591a\u5c64\u30cb\u30e5\u30fc\u30e9\u30eb\u30cd\u30c3\u30c8\u30ef\u30fc\u30af\u3092\u7528\u3044\u308b\u3053\u3068\u304c\u3067\u304d\uff0c\u5b66\u7fd2\u304c\u5bb9\u6613\u3067\u3042\u308b\u3053\u3068\uff0c\u3055\u3089\u306b\u7d75\u3084\u9854\u5199\u771f\u306a\u3069\u30b5\u30a4\u30ba\u306e\u5927\u304d\u306a\u753b\u50cf\u306a\u3069\u3092\u751f\u6210\u3067\u304d\u308b\u3053\u3068\u304b\u3089\uff0cRBM \u306b \u4ee3\u308f\u308b\u6df1\u5c64\u751f\u6210\u30e2\u30c7\u30eb\u3068\u3057\u3066\u6ce8\u76ee\u3055\u308c\u3066\u3044\u308b\uff0e\n\nmulti-modal AutoEncoder\u30e2\u30c7\u30eb\n\nhttps://www.slideshare.net/masa_s/ss-62920389\n\n\n\u30de\u30eb\u30c1\u30e2\u30fc\u30c0\u30ebautoencoder [Ngiam+ 11]\n\u5404\u30e2\u30fc\u30c0\u30eb\u60c5\u5831\u306b\u3064\u3044\u3066AE\u3092\u7528\u610f\u3057\u3001\u6700\u3082\u6df1\u3044\u96a0\u308c\u5c64\u3092\u5171\u6709\u3059\u308b.\n2\u3064\u306e\u30e2\u30fc\u30c0\u30eb\u60c5\u5831\u306b\u5171\u901a\u3059\u308b\u7279\u5fb4\u8868\u73fe\u3092\u7372\u5f97\u3067\u304d\u308b\u3088\u3046\u306b\u306a\u3063\u305f.\n\n\n\uff08 \u65b9\u6cd5\uff12 \uff09\n\n\n\u5f53\u521d\u304b\u3089\u3001\u591a\u5909\u91cf\u6642\u7cfb\u5217\u30c7\u30fc\u30bf \u5168\u4f53 \u306e \u5305\u62ec\u7279\u5fb4\u91cf \u3092\u3000\u5b66\u7fd2\u3059\u308b\u3000\u30a2\u30d7\u30ed\u30fc\u30c1\ngoogle \u3067\u3001\u300cmultivariate, LSTM\u300d\u3068 \u691c\u7d22\u3059\u308b \u3068 \u53c2\u8003\u4f8b \u304c \u51fa\u3066\u304f\u308b\u3002\n\n\u6797 \u653f\u884c\u307b\u304b \u300c\u6df1\u5c64\u5b66\u7fd2\u3092\u7528\u3044\u305f\u30de\u30eb\u30c1\u30e2\u30fc\u30c0\u30eb\u5b66\u7fd2\u306b\u3088\u308b\u964d\u6c34\u91cf\u4e88\u6e2c\u300d\u60c5\u5831\u51e6\u7406\u5b66\u4f1a\u7b2c78\u56de\u5168\u56fd\u5927\u4f1a\n\n\n\u964d\u6c34\u91cf\u306e\u4e88\u6e2c\u306e\u554f\u984c\u306f\uff0c\u6642\u7cfb\u5217\u6027\u3068\u7a7a\u9593\u6027\u306e\u4e21\u65b9\u3092\u6301\u3064\u6642\u7a7a\u9593\u30c7\u30fc\u30bf\u306e\u4e88\u6e2c\u3068\u6349\u3048\u308b\u3053\u3068\u304c\u3067\u304d\u308b\uff0e\n\u8fd1\u5e74\u306e\u7814\u7a76\u306b\u304a\u3044\u3066\uff0cSutskever \u3089 [1] \u306b\u3088\u308a Recurrent Neural Network (RNN) \u3092\u7528\u3044\u305f Sequence-to-Sequence (seq2seq) \u5b66\u7fd2\u30d5\u30ec\u30fc\u30e0\u30ef\u30fc\u30af\u304c\u63d0\u6848\u3055\u308c\uff0c\u6df1\u5c64\u5b66\u7fd2\u3092\u7528\u3044\u3066\u4efb\u610f\u9577\u306e\u7cfb\u5217\u30c7\u30fc\u30bf\u304b\u3089\u4efb\u610f\u9577\u306e\u7cfb\u5217\u30c7\u30fc\u30bf\u3092\u751f\u6210\u3067\u304d\u308b\u3088\u3046\u306b\u306a\u3063\u305f\uff0e\n\u3055\u3089\u306b\uff0cShi \u3089 [2] \u306b\u3088\u308aConvolutional Neural Network (CNN) \u306e\u64cd\u4f5c\u3092\u53d6\u308a\u5165\u308c\u305f Convolutional LSTM (ConvLSTM) \u5c64\u3092\u7528\u3044\u3066\u6642\u7a7a\u9593\u30c7\u30fc\u30bf\u306e\u4e88\u6e2c\u3092\u884c\u3046 seq2seq \u30e2\u30c7\u30eb\u304c\u63d0\u6848\u3055\u308c\uff0c\u964d\u6c34\u91cf\u4e88\u6e2c\u306e\u30bf\u30b9\u30af\u306b\u304a\u3044\u3066\u5b9f\u9a13\u304c\u884c\u306a\u308f\u308c\u305f\uff0e\n\u3057\u304b\u3057\uff0c\u5b9f\u969b\u306e\u964d\u6c34\u91cf\u306f\u96f2\u306e\u539a\u3055\uff0c\u5730\u5f62\uff0c\u304a\u3088\u3073\u98a8\u5411\u304d\u3068\u3044\u3063\u305f\u8907\u6570\u306e\u8981\u56e0 (\u30e2\u30c0\u30ea\u30c6\u30a3) \u306b\u4f9d\u5b58\u3057\u3066\u5909\u5316\u3059\u308b\u304c\uff0cShi \u3089\u306e\u63d0\u6848\u3057\u305f\u4e88\u6e2c\u30e2\u30c7\u30eb\u3067\u306f\u904e\u53bb\u306e\u964d\u6c34\u91cf\u306e\u307f\u304c\u4e88\u6e2c\u306b\n\u7528\u3044\u3089\u308c\u3066\u3044\u308b\uff0e\n\u305d\u3053\u3067\u672c\u7814\u7a76\u3067\u306f seq2seq \u30e2\u30c7\u30eb\u306b\u3088\u308b\u6642\u7a7a\u9593\u30c7\u30fc\u30bf\u306e\u4e88\u6e2c\u306b\u304a\u3044\u3066\u8907\u6570\u30e2\u30c0\u30ea\u30c6\u30a3\u3092\u4e88\n\u6e2c\u306b\u7528\u3044\u308b\u30de\u30eb\u30c1\u30e2\u30fc\u30c0\u30eb\u5b66\u7fd2\u3092\u884c\u3046\uff0e\n\u672c\u7814\u7a76\u306e\u76ee\u7684\u306f\uff0c\u964d\u6c34\u91cf\u306e\u4e88\u6e2c\u306b\u304a\u3044\u3066\u904e\u53bb\u306e\u964d\u6c34\u91cf\u306e\u30c7\u30fc\u30bf\u306b\u52a0\u3048\uff0c\u96f2\u306e\u539a\u3055\u3084\u5730\u5f62\u3068\u3044\u3063\u305f\u8907\u6570\u306e\u8981\u56e0\u3092\u5165\u529b\u30c7\u30fc\u30bf\u306b\u52a0\u3048\u308b\u3053\u3068\u3067\uff0c\u3088\u308a\u7cbe\u5ea6\u306e\u9ad8\u3044\u964d\u6c34\u91cf\u4e88\u6e2c\u3092\u884c\u3046\u3053\u3068\u3067\u3042\u308b\uff0e\n\u672c\u7a3f\u3067\u306f\uff0c2 \u7ae0\u3067 ConvLSTM \u3092\u7528\u3044\u305f\u6642\u7a7a\u9593\u30c7\u30fc\u30bf\u306e\u4e88\u6e2c\u30e2\u30c7\u30eb\u306b\u3064\u3044\u3066\u8ff0\u3079\uff0c3 \u7ae0\u3067\u63d0\u6848\u3059\u308b\u30de\u30eb\u30c1\u30e2\u30fc\u30c0\u30eb\u5b66\u7fd2\u306e\u624b\u6cd5\u3092\u8ff0\u3079\u308b\uff0e\n4 \u7ae0\u3067\u5b9f\u30c7\u30fc\u30bf\u3092\u6301\u3061\u305f\u8a55\u4fa1\u5b9f\u9a13\u306b\u3064\u3044\u3066\u8ff0\u3079\uff0c5 \u7ae0\u3067\u672c\u7814\u7a76\u306e\u307e\u3068\u3081\u3092\u884c\u3046\uff0e\n\uff08 \u4e2d\u7565 \uff09\n3 \u6642\u7a7a\u9593\u30c7\u30fc\u30bf\u306e\u30de\u30eb\u30c1\u30e2\u30fc\u30c0\u30eb\u5b66\u7fd2\u30e2\u30c7\u30eb\n\u672c\u7ae0\u3067\u306f\uff0cShi \u3089 [2] \u306e\u63d0\u6848\u3057\u305f ConvLSTM \u3092\u7528\u3044\u305f\u6642\u7a7a\u9593\u30c7\u30fc\u30bf\u306e\u4e88\u6e2c\u30e2\u30c7\u30eb\u306b\u304a\u3044\u3066\uff0cConvLSTM \u3092\u62e1\u5f35\u3057\uff0c\u30de\u30eb\u30c1\u30e2\u30fc\u30c0\u30eb\u5b66\u7fd2\u3092\u884c\u3046\u624b\u6cd5\u306b\u3064\u3044\u3066\u8ff0\u3079\u308b\uff0e\n\u6642\u7a7a\u9593\u30c7\u30fc\u30bf\u306f\u6642\u7cfb\u5217\u6027\u3068\u7a7a\u9593\u6027\u3092\u6301\u3064\u30c7\u30fc\u30bf\u3067\u3042\u308b\uff0e\n\u5404\u30bf\u30a4\u30e0\u30b9\u30c6\u30c3\u30d7\u306b\u304a\u3044\u3066\uff0c\u7a7a\u9593\u6027\u3092\u6301\u3064 1 \u3064\u306e\u30c7\u30fc\u30bf\u306f\u753b\u50cf\u3068\u3057\u3066\u6271\u3046\u3053\u3068\u304c\u3067\u304d\u308b\uff0e\n\u753b\u50cf\u3092\u6271\u3046\u4e0a\u3067\u8907\u6570\u306e\u30e2\u30c0\u30ea\u30c6\u30a3\u3092\u30cb\u30e5\u30fc\u30e9\u30eb\u30cd\u30c3\u30c8\u3067\u7528\u3044\u308b\u624b\u6cd5\u3068\u3057\u3066\uff0c\u30e2\u30c0\u30ea\u30c6\u30a3\u3092\u5168\u3066\u7d50\u5408\u3057\uff0c\u8907\u6570\u306e\u30e2\u30c0\u30ea\u30c6\u30a3\u304b\u3089\u306a\u308b\u591a\u30c1\u30e3\u30f3\u30cd\u30eb\u753b\u50cf\u3068\u3057\u3066\u6271\u3046\u65b9\u6cd5\u304c\u3042\u308b [3]\uff0e\n\u63d0\u6848\u3059\u308b\u30e2\u30c7\u30eb\u306f\u56f3 1 \u306b\u793a\u3059 Encoding-Forecasting \u30cd\u30c3\u30c8\u30ef\u30fc\u30af\u304b\u3089\u6210\u308b seq2seq \u30e2\u30c7\u30eb\u306b\uff0c\u8907\u6570\u306e\u30e2\u30c0\u30ea\u30c6\u30a3\u304b\u3089\u306a\u308b\u591a\u30c1\u30e3\u30f3\u30cd\u30eb\u753b\u50cf\u3092\u5165\u529b\u3059\u308b\u3053\u3068\u3067\u30de\u30eb\u30c1\u30e2\u30fc\u30c0\u30eb\u5b66\u7fd2\u3092\u884c\u3046\u3082\u306e\u3067\u3042\u308b\uff0e\nConvLSTM \u3067\u306f\uff0cLSTM \u306e\u5165\u529b\u30e6\u30cb\u30c3\u30c8\u304b\u3089\u306e\u5165\u529b\u3068\u96a0\u308c\u30e6\u30cb\u30c3\u30c8\u304b\u3089\u306e\u5165\u529b\u306e\u4e21\u65b9\u306b\u7573\u307f\u8fbc\u307f\u6f14\u7b97\u304c\u7528\u3044\u3089\u308c\u3066\u3044\u308b\uff0e\nCNN \u3067\u306f\u7573\u307f\u8fbc\u307f\u5c64\u306e\u76f4\u5f8c\u306b\u5c40\u6240\u6b63\u898f\u5316\u306e\u64cd\u4f5c\u304c\u53d6\u308a\u5165\u308c\u3089\u308c\u308b\u3053\u3068\u304c\u591a\u3005\u3042\u308b [3]\uff0e\n\u5f93\u3063\u3066\u63d0\u6848\u3059\u308b\u30e2\u30c7\u30eb\u3067\u306f\uff0c\u56f3 2 \u306b\u793a\u3059\u3088\u3046\u306b\uff0c\u96a0\u308c\u30e6\u30cb\u30c3\u30c8\u304b\u3089\u306e\u5165\u529b\u3092\u6b63\u898f\u5316\u3059\u308b\u64cd\u4f5c (\u56f3 2 \u306e\u20dd1 )\uff0c\u5165\u529b\u5c64\u304b\u3089\n\u306e\u5165\u529b\u3092\u6b63\u898f\u5316\u3059\u308b\u64cd\u4f5c (\u56f3 2 \u306e\u20dd2 )\uff0c\u304a\u3088\u3073\u51fa\u529b\u3092\u6b63\u898f\u5316\u3059\u308b\u64cd\u4f5c (\u56f3 2 \u306e\u20dd3 ) \u3092\u53d6\u308a\u5165\u308c\u305f\u3082\u306e\u3092\u691c\u8a0e\u3059\u308b\uff0e\n\n\n\nConvolutionalLSTM\n\n\u4ee5\u4e0b \u304c \u308f\u304b\u308a\u3084\u3059\u3044\n\nmasataka46\u3055\u3093 Qiita\u8a18\u4e8b \u300cLSTM\u3092\u6539\u826f\u3057\u3066convLSTM\u306b\u3059\u308b\u300d\n\n\u539f\u8ad6\u6587 \u306f \u4ee5\u4e0b\u3002\n\nXingjian Shi Zhourong Chen Hao Wang Dit-Yan Yeung, Convolutional LSTM Network: A Machine Learning Approach for Precipitation Nowcasting\n\n\u3053\u306e\u8ad6\u6587 \u304c \u53d6\u308a\u7d44\u3093\u3067\u3044\u308b \u4e3b\u984c \u3082\u3001\u300c\u964d\u6c34\u91cf\u4e88\u5831\u300d\uff08 precipitation nowcasting \uff09\u3067 \u3042\u308b\u3002\n\nAbstract\nThe goal of precipitation nowcasting is to predict the future rainfall intensity in a local region over a relatively short period of time. \nVery few previous studies have examined this crucial and challenging weather forecasting problem from the machine learning perspective. In this paper, we formulate precipitation nowcasting as a spatiotemporal sequence forecasting problem in which both the input and the prediction target are spatiotemporal sequences.\nBy extending the fully connected LSTM (FC-LSTM) to have convolutional structures in both the input-to-state and state-to-state transitions, we propose the convolutional LSTM (ConvLSTM) and use it to build an end-to-end trainable model for the precipitation nowcasting problem.\nExperiments show that our ConvLSTM network captures spatiotemporal\ncorrelations better and consistently outperforms FC-LSTM and the state-of-theart\noperational ROVER algorithm for precipitation nowcasting.\n\n\n\uff08 GitHub\uff09fchollet/keras Convolutional LSTM #1773\n\uff08 GitHub\uff09loliverhennigh/Convolutional-LSTM-in-Tensorflow\n\n\n\nPankaj Malhotra1, Lovekesh Vig, Gautam Shroff, Puneet Agarwal, Long Short Term Memory Networks for Anomaly Detection in Time Series, ESANN 2015 proceedings, European Symposium on Artificial Neural Networks, Computational Intelligence and Machine Learning. Bruges (Belgium), 22-24 April 2015\n\n\n2 LSTM-AD: LSTM-based Anomaly Detection\nConsider a time series X = {x(1), x(2), ..., x(n)}, where each point x(t) \u2208 Rm in the time series is an m-dimensionavector\n{x(t)1 , x(t)2 , ..., x(t)m },\nwhose elements correspond to the input variables.\nA prediction model learns to predict the next l values for d of the input variables s.t. 1 \u2264 d \u2264 m\n\n\nReitmann, Stefan and Nachtigall, Karl and Schultz, Michael, Pattern Recognition and Prediction of Multivariate Time Series with LSTM\nPavel Filonov, Andrey Lavrentyev and Artem Vorontsov, Multivariate Industrial Time Series with Cyber-Attack Simulation: Fault Detection Using an LSTM-based Predictive Data Model\n\n\n3. LSTM-based Fault Detection\nInput data can be described as multivariate time series\nX = {x(1), x(2), . . . , x(n)}, __\n__where x(t) belongs to m dimensional space Rm, n \u2014 number of time points.\nThe proposed fault detection algorithm consists of two parts: forecasting and detection.\nAt first we split the whole time series into equalsized batches of length w denoted as \nX(i) = {x(j), x(j+1), . . . , x(j+w\u22121)}. \nHere i is the batch number and j = w(i \u2212 1) + 1 is the number of first time point in the batch. \nIn the forecasting part we predict values for the next batch X\u02dc(i+1) using already observed measurements X(1), X(2), . . . , X(i).\nThe detection part is based on finding time points where the mean square error (MSE) between the\nmeasured X(i+1) and predicted X\u02dc(i+1) values becomes higher then the precomputed threshold.\n\uff08 \u4e2d\u7565 \uff09\n3.2 Neural Network Architecture\nThe choise of optimal network architecture is based on several observations.\nAt first, the most industrial technological processes generate strongly correlated multivariate time series.\nFurthermore we frequently deal with multiscale processes (see Figure 2) having fast (long-term) and slow (short-term) sub-processes.\nIn these conditions conventional feed-forward neural networks usually demonstrate a poor results.\nAn accurate data-driven predictive model can be developed using stateful LSTM neural network [Hochreiter and Schmidhuber, 1997, Malhotra et al., 2015, Nanduri et al., 2016].\nThe proposed network architecture includes two stacked LSTM layers with linear output layer (Figure3).\nIn addition we use a sequence-to-sequence architecture of LSTM network for the forecasting model (Figure 4)\n\n\n\nWenlu Zhang et.al, Deep convolutional neural networks for multi-modality isointense infant brain image segmentation\n\n\n\nhttps://sourceforge.net/p/currennt/discussion/general/thread/eaaaa315/\n\n\nHarlei Uhrahn - 2014-12-01\nIs there any way of using this library with mutlivariate time-series?\nMore precise: I have time-series-data where each time point T is a vector of N scalar values.\nI would like to predict a single scalar value at each time point T.\nWith N=3 this could be a simple model of RGB colors evolving over time.\nOf course it would be possible to split the series up into N different univariate time series, and train seperate networks.\nBut this would prevent to learn correlations between the vectors components.\n--> Side effects which I would like to prevent.\nWhat would be a good network topology?\nLast edit: Harlei Uhrahn 2014-12-01\nThis library is all about multivariate regression and classification.\nYou can look at** the speech recognition and speech autoencoding examples**\n- the first one maps a 39-dimensional feature vector (per time step) to one of 51 discrete classes (per time step). \nThe second one maps a 39-dimensional feature vector to another 39-dimensional vector (real-valued).\nIt is especially helpful to look at the .nc files (using ncdump), which contain the data (as arrays of input features and training targets), and the .jsn files, which contain the network topology definitions.\nIf you have N features and 1 output, you can just try a (B)LSTM with one hidden layer of N units and a visible output layer:\n{\n   \"layers\": [\n       {\n           \"size\": N,\n           \"name\": \"input\",\n           \"type\": \"input\"\n       },\n       {\n           \"size\": N,\n           \"name\": \"lstm_layer\",\n           \"bias\": 1.0,\n           \"type\": \"lstm\"\n       },\n       {\n           \"size\": 1,\n           \"name\": \"output\",\n           \"bias\": 1.0,\n           \"type\": \"feedforward_identity\"\n       },\n       {\n           \"size\": 1,\n           \"name\": \"postoutput\",\n           \"type\": \"sse\"\n       }\n   ]\n}\n\nwhere you replace N by your feature vector dimension. Of course, you should try more than one LSTM layer, larger LSTM layers, etc.\nTo use bidirectional LSTM layers, just replace lstm by blstm in the above.\nThe sse \"post output layer\" implements the calculation of the sum of squared errors cost function, and the backpropagation of its derivatives to train the network weights.\nIf your targets are in the range 0-1, you can also use feedforward_sigmoid as output layer type.\nIf your targets are in the range -1 to 1, you can also use feedforward_tanh. This only changes the output layer activation function so that your network outputs are automatically constrained to the correct range.\nHope that helps,\nFelix\n\n\n\n\uff08 \u4ee5\u4e0b \u306f \u8aad\u89e3\u4e2d \uff09\n\n\nhttp://catsr.ite.gmu.edu/pubs/ICNS_2016_AnomalyDetectionRNN_01042015.pdf\nhttps://arxiv.org/pdf/1610.04834.pdf\nhttp://www.ijcaonline.org/archives/volume143/number11/zaytar-2016-ijca-910497.pdf\n\n###__\uff08 \u95a2\u9023\u8a18\u4e8b \uff09__\n\n* [HirofumiYashima Qiita\u8a18\u4e8b \u300cCNN \u3067 \u6642\u7cfb\u5217\u30c7\u30fc\u30bf \u306e \u7279\u5fb4\u91cf\uff08\u7279\u5fb4\u30de\u30c3\u30d7\uff09 \u3092 \u7573\u307f\u8fbc\u307f \u3067 \u62bd\u51fa\u3057\u3066\u3001 + \u30d7\u30fc\u30ea\u30f3\u30b0 \u3067 \u60c5\u5831\u5727\u7e2e \u3059\u308b \u65b9\u6cd5 \u3044\u308d\u3044\u308d\u300d](http://qiita.com/HirofumiYashima/items/91b3aade0d7c5b2d403b)\n\n* [HirofumiYashima Qiita\u8a18\u4e8b \u300c\u3010 \u8abf\u67fb \u3011CNN\uff08Convolution Neural Net\uff09\u3092 \u7528\u3044\u305f \u6642\u7cfb\u5217\u30c7\u30fc\u30bf\u306e\u4e88\u6e2c\u30bf\u30b9\u30af\u3001\u5206\u985e\u30bf\u30b9\u30af \u5fdc\u7528\u4e8b\u4f8b\u300d](http://qiita.com/HirofumiYashima/items/9b5cca736172161aae2a)\n\n___\n\n\n\n#__\uff08 \u65b9\u6cd5\uff11 \uff09__\n\n###\u5404\u5909\u6570\u3054\u3068\u306b\u3001\u6642\u7cfb\u5217\u30d1\u30bf\u30fc\u30f3\u306e\u7279\u5fb4\u30d9\u30af\u30c8\u30eb \u3092 \u500b\u5225\u306eLSTM\u30bf\u30b9\u30af \u3067 \u62bd\u51fa\u3057\u3001\u5404\u5909\u6570\u306e\u6642\u7cfb\u5217\u7279\u5fb4\u30d9\u30af\u30c8\u30eb \u3092 \u5f8c\u304b\u3089 \u7d71\u5408\uff08\u91cd\u307f\u5171\u6709\uff09\u3057\u3066\u3001\u591a\u5909\u91cf\u5168\u4f53\u306e\u6642\u7cfb\u5217\u7279\u5fb4\u91cf \u3092 \u7372\u5f97\u3059\u308b \u30a2\u30d7\u30ed\u30fc\u30c1\n \n####__\u30de\u30eb\u30c1\u30e2\u30fc\u30c0\u30ebDeep Learning\u3068\u540c\u3058\u30a2\u30d7\u30ed\u30fc\u30c1__\n\n* \uff11\u3064\u306e\u8aac\u660e\u5909\u6570\u306e\u6642\u7cfb\u5217\u7279\u5fb4\u91cf \u3092 \uff11\u3064\u306eLSTM \u3067 \u72ec\u7acb\u3057\u3066 \u5b66\u7fd2\u3001\n* \u4e0a\u8a18 \u3092 \u8aac\u660e\u5909\u6570\u500b\u5206\u3001\u72ec\u7acb\u3057\u305fLSTM \u3092 \u4e26\u884c\u51e6\u7406\u3055\u305b\u308b\n* \u500b\u3005\u306eLSTM \u304c\u62bd\u51fa\u3057\u305f \u500b\u3005\u306e\u8aac\u660e\u5909\u6570\uff08\u6642\u7cfb\u5217\u30c7\u30fc\u30bf\uff09\u306e\u7279\u5fb4\u91cf \u3092\u3001\u591a\u5909\u91cf\u6642\u7cfb\u5217\u30c7\u30fc\u30bf\u300c\u5168\u4f53\u300d\u306e\u5305\u62ec\u30fb\u7d71\u5408 \u7279\u5fb4\u91cf \u3068\u3057\u3066 \u7d71\u5408 \u3059\u308b\n* \u7d71\u5408\u7279\u5fb4\u91cf \u306e \u5f8c\u308d \u306b \u6700\u7d42\u7684 \u306a \u51fa\u529b\u5c64 \u3092 \u8a2d\u7f6e\u3057\u3066\u3001\u6052\u7b49\u95a2\u6570\uff08\u56de\u5e30\u554f\u984c\uff09\u3001\u30ed\u30b8\u30b9\u30c6\u30a3\u30c3\u30af\u95a2\u6570\uff08\uff12\u5024\u5206\u985e\u554f\u984c\uff09\u3001Softmax\u95a2\u6570\uff08\u591a\u5024\u5206\u985e\u554f\u984c\uff09 \u3067 \u30cd\u30c3\u30c8\u30ef\u30fc\u30af\u3068\u3057\u3066 \u306e \u4e88\u6e2c\u7d50\u679c \u3092 \u51fa\u529b\u3059\u308b\n\n\n####__\uff08 \u4e8b\u4f8b \uff09__\n\n* [Dong Nie _et.al, FULLY CONVOLUTIONAL NETWORKS FOR MULTI-MODALITY ISOINTENSE INFANT BRAIN IMAGE SEGMENTATION_](https://www.ncbi.nlm.nih.gov/pmc/articles/PMC5031138/)\n\n###__Keras \u3067\u306f\u3001Merge\u5c64 \u3067 \u8907\u6570\u306e\u5c64 \u3092 \u5408\u6d41\uff08\u7d71\u5408\uff09\u3055\u305b\u3066 \u7d71\u5408\u7279\u5fb4\u91cf\u5c64 \u3092 \u7d44\u3080\u3053\u3068 \u304c \u3067\u304d\u308b\u3002__\n\n* [Keras Documentation \u300cSequential\u30e2\u30c7\u30eb\u3067Keras\u306b\u89e6\u308c\u3066\u307f\u3088\u3046\u300d](https://keras.io/ja/getting-started/sequential-model-guide/)\n\n* [HirofumiYashima Qiita\u8a18\u4e8b \u300c\u3010 \u591a\u5909\u91cf\u30de\u30eb\u30c1\u30e2\u30fc\u30c0\u30eb DeepLearning \u3011Keras \u306e Merge\u5c64 \u3067\u3001\u300c\u591a\u5165\u529b\u300d\uff1d\uff1e \u300c\u5358\u4e00\u51fa\u529b\u300d or \u300c\u591a\u51fa\u529b\u300d \u306e \u30cd\u30c3\u30c8\u30ef\u30fc\u30af\u30b0\u30e9\u30d5 \u3092 \u5b9f\u88c5\u3067\u304d\u308b\u300d](http://qiita.com/HirofumiYashima/items/5b5d50446974f262904e)\n\n<img width=\"1240\" alt=\"\u30b9\u30af\u30ea\u30fc\u30f3\u30b7\u30e7\u30c3\u30c8 2017-03-05 20.57.20.png\" src=\"https://qiita-image-store.s3.amazonaws.com/0/43487/7bd61a3d-87b4-e8be-445e-fe1c31205ed4.png\">\n\n\n####__\u30de\u30eb\u30c1\u30e2\u30fc\u30c0\u30ebDeep Learning \u306e \u30a2\u30d7\u30ed\u30fc\u30c1__\n\n__Google\u691c\u7d22 \u3067\u3001\u300c\u30de\u30eb\u30c1\u30e2\u30fc\u30c0\u30eb\u3001\u6df1\u5c64\u5b66\u7fd2\u300d\u3068\u3059\u308b\u3068\u3001\u53c2\u8003\u4f8b \u304c \u51fa\u3066\u304f\u308b\u3002__\n\n* [HirofumiYashima Qiita\u8a18\u4e8b\u300c\u3010 \u57fa\u790e\u8abf\u67fb \u3011\u8907\u6570\u306e\u30bb\u30f3\u30b5\u611f\u899a\u30c7\u30fc\u30bf\uff08\u7279\u5fb4\u91cf\uff09\u3092\u7d71\u5408\u3057\u3066\u3001\u300c\u30de\u30eb\u30c1\u30e2\u30fc\u30c0\u30eb\u5b66\u7fd2\u300d\uff08\u30de\u30eb\u30c1\u30e2\u30fc\u30c0\u30eb\u7279\u5fb4\u91cf\uff09\u3092\u5f97\u308b\u305f\u3081\u306e\u624b\u6cd5\u3044\u308d\u3044\u308d\u300d](http://qiita.com/HirofumiYashima/items/c756ac8ab4b937231a11)\n\n* [\u9234\u6728 \u96c5\u5927\u30fb\u677e\u5c3e \u8c4a\u300c\u6df1\u5c64\u751f\u6210\u30e2\u30c7\u30eb\u3092\u7528\u3044\u305f\u30de\u30eb\u30c1\u30e2\u30fc\u30c0\u30eb\u5b66\u7fd2\u300d](https://kaigi.org/jsai/webprogram/2016/pdf/727.pdf)\n\n> \u6df1\u5c64\u30cb\u30e5\u30fc\u30e9\u30eb\u30cd\u30c3\u30c8\u30ef\u30fc\u30af\u306f\uff0c\u5b66\u7fd2\u306e\u904e\u7a0b\u306b\u304a\u3044\u3066\u6df1\u3044\u5c64\u3067\u666e\u904d\u7684\u306a\u7279\u5fb4\u8868\u73fe\u304c\u7372\u5f97\u3067\u304d\u308b\u3053\u3068\u304c\u77e5\u3089\u308c\u3066\u3044\u308b\uff0e\n>\n> \u305d\u306e\u305f\u3081\uff0c\u3053\u308c\u307e\u3067\u6df1\u5c64\u6559\u5e2b\u306a\u3057\u5b66\u7fd2\u30e2\u30c7\u30eb\u3067\u3042\u308b autoencoder\uff08AE\uff09\u3084 restricted Boltzmann machine\uff08RBM\uff09\u306b\u3088\u308b\u30de\u30eb\u30c1\u30e2\u30fc\u30c0\u30eb\u5b66\u7fd2 [Ngiam 11, Srivastava 12] \u304c\u63d0\u6848\u3055\u308c\u3066\u3044\u308b\uff0e\n>\n> __\u3053\u308c\u3089\u306f\u7279\u5fb4\u62bd\u51fa\u5668\u3084\u6df1\u5c64\u30cb\u30e5\u30fc\u30e9\u30eb\u30cd\u30c3\u30c8\u30ef\u30fc\u30af\u306e\u4e8b\u524d\u5b66\u7fd2\u306a\u3069\u306b\u7528\u3044\u3089\u308c\u308b\u30e2\u30c7\u30eb\u3067\uff0c2 \u3064\u306e\u30cd\u30c3\u30c8\u30ef\u30fc\u30af\u306e\u96a0\u308c\u5c64\uff0c\u3082\u3057\u304f\u306f\u6f5c\u5728\u5909\u6570\u3092\u5171\u6709\u3059\u308b\u3053\u3068\u3067\uff0c\u7570\u306a\u308b\u30e2\u30fc\u30c0\u30eb\u60c5\u5831\u304b\u3089\u5171\u901a\u304b\u3064\u3088\u308a\u9ad8\u6b21\u306e\u7279\u5fb4\u8868\u73fe\u3092\u7372\u5f97\u3059\u308b\u3053\u3068\u3092\u76ee\u7684\u3068\u3057\u3066\u3044\u308b\uff0e__\n>\n> \u8fd1\u5e74\uff0c\u6df1\u5c64\u30cb\u30e5\u30fc\u30e9\u30eb\u30cd\u30c3\u30c8\u30ef\u30fc\u30af\u306b\u3088\u308b\u751f\u6210\u30e2\u30c7\u30eb\u3068\u3057\u3066\uff0c__*variational autoencoder\uff08VAE\uff09*__[Kingma 13] \u304c \u63d0\u6848\u3055\u308c\u305f\uff0e\n>\n> __*VAE*__ \u306f\u751f\u6210\u30e2\u30c7\u30eb\u3067\u3042\u308a\u306a\u304c\u3089\uff0c\u30e2\u30c7\u30eb\u3068\u3057\u3066\u901a\u5e38\u306e\u591a\u5c64\u30cb\u30e5\u30fc\u30e9\u30eb\u30cd\u30c3\u30c8\u30ef\u30fc\u30af\u3092\u7528\u3044\u308b\u3053\u3068\u304c\u3067\u304d\uff0c\u5b66\u7fd2\u304c\u5bb9\u6613\u3067\u3042\u308b\u3053\u3068\uff0c\u3055\u3089\u306b\u7d75\u3084\u9854\u5199\u771f\u306a\u3069\u30b5\u30a4\u30ba\u306e\u5927\u304d\u306a\u753b\u50cf\u306a\u3069\u3092\u751f\u6210\u3067\u304d\u308b\u3053\u3068\u304b\u3089\uff0c__*RBM*__ \u306b \u4ee3\u308f\u308b\u6df1\u5c64\u751f\u6210\u30e2\u30c7\u30eb\u3068\u3057\u3066\u6ce8\u76ee\u3055\u308c\u3066\u3044\u308b\uff0e\n\n\n__multi-modal AutoEncoder\u30e2\u30c7\u30eb__\n\n* https://www.slideshare.net/masa_s/ss-62920389\n\n> \u30de\u30eb\u30c1\u30e2\u30fc\u30c0\u30ebautoencoder [Ngiam+ 11]\n>\n> \u5404\u30e2\u30fc\u30c0\u30eb\u60c5\u5831\u306b\u3064\u3044\u3066AE\u3092\u7528\u610f\u3057\u3001\u6700\u3082\u6df1\u3044\u96a0\u308c\u5c64\u3092\u5171\u6709\u3059\u308b.\n> 2\u3064\u306e\u30e2\u30fc\u30c0\u30eb\u60c5\u5831\u306b\u5171\u901a\u3059\u308b\u7279\u5fb4\u8868\u73fe\u3092\u7372\u5f97\u3067\u304d\u308b\u3088\u3046\u306b\u306a\u3063\u305f.\n\n#__\uff08 \u65b9\u6cd5\uff12 \uff09__\n\n###\u5f53\u521d\u304b\u3089\u3001\u591a\u5909\u91cf\u6642\u7cfb\u5217\u30c7\u30fc\u30bf \u5168\u4f53 \u306e \u5305\u62ec\u7279\u5fb4\u91cf \u3092\u3000\u5b66\u7fd2\u3059\u308b\u3000\u30a2\u30d7\u30ed\u30fc\u30c1\n\n__google \u3067\u3001\u300cmultivariate, LSTM\u300d\u3068 \u691c\u7d22\u3059\u308b \u3068 \u53c2\u8003\u4f8b \u304c \u51fa\u3066\u304f\u308b\u3002__\n\n* [\u6797 \u653f\u884c\u307b\u304b \u300c\u6df1\u5c64\u5b66\u7fd2\u3092\u7528\u3044\u305f\u30de\u30eb\u30c1\u30e2\u30fc\u30c0\u30eb\u5b66\u7fd2\u306b\u3088\u308b\u964d\u6c34\u91cf\u4e88\u6e2c\u300d\u60c5\u5831\u51e6\u7406\u5b66\u4f1a\u7b2c78\u56de\u5168\u56fd\u5927\u4f1a](https://www.ipsj.or.jp/award/9faeag0000004emc-att/4P-03.pdf)\n\n> \u964d\u6c34\u91cf\u306e\u4e88\u6e2c\u306e\u554f\u984c\u306f\uff0c\u6642\u7cfb\u5217\u6027\u3068\u7a7a\u9593\u6027\u306e\u4e21\u65b9\u3092\u6301\u3064\u6642\u7a7a\u9593\u30c7\u30fc\u30bf\u306e\u4e88\u6e2c\u3068\u6349\u3048\u308b\u3053\u3068\u304c\u3067\u304d\u308b\uff0e\n>\n> \u8fd1\u5e74\u306e\u7814\u7a76\u306b\u304a\u3044\u3066\uff0cSutskever \u3089 [1] \u306b\u3088\u308a Recurrent Neural Network (RNN) \u3092\u7528\u3044\u305f Sequence-to-Sequence (seq2seq) \u5b66\u7fd2\u30d5\u30ec\u30fc\u30e0\u30ef\u30fc\u30af\u304c\u63d0\u6848\u3055\u308c\uff0c\u6df1\u5c64\u5b66\u7fd2\u3092\u7528\u3044\u3066\u4efb\u610f\u9577\u306e\u7cfb\u5217\u30c7\u30fc\u30bf\u304b\u3089\u4efb\u610f\u9577\u306e\u7cfb\u5217\u30c7\u30fc\u30bf\u3092\u751f\u6210\u3067\u304d\u308b\u3088\u3046\u306b\u306a\u3063\u305f\uff0e\n>\n> \u3055\u3089\u306b\uff0cShi \u3089 [2] \u306b\u3088\u308a__*Convolutional Neural Network (CNN)*__ \u306e\u64cd\u4f5c\u3092\u53d6\u308a\u5165\u308c\u305f __*Convolutional LSTM (ConvLSTM)*__ \u5c64\u3092\u7528\u3044\u3066\u6642\u7a7a\u9593\u30c7\u30fc\u30bf\u306e\u4e88\u6e2c\u3092\u884c\u3046 __*seq2seq*__ \u30e2\u30c7\u30eb\u304c\u63d0\u6848\u3055\u308c\uff0c\u964d\u6c34\u91cf\u4e88\u6e2c\u306e\u30bf\u30b9\u30af\u306b\u304a\u3044\u3066\u5b9f\u9a13\u304c\u884c\u306a\u308f\u308c\u305f\uff0e\n>\n> __\u3057\u304b\u3057\uff0c\u5b9f\u969b\u306e\u964d\u6c34\u91cf\u306f\u96f2\u306e\u539a\u3055\uff0c\u5730\u5f62\uff0c\u304a\u3088\u3073\u98a8\u5411\u304d\u3068\u3044\u3063\u305f\u8907\u6570\u306e\u8981\u56e0 (\u30e2\u30c0\u30ea\u30c6\u30a3) \u306b\u4f9d\u5b58\u3057\u3066\u5909\u5316\u3059\u308b\u304c\uff0cShi \u3089\u306e\u63d0\u6848\u3057\u305f\u4e88\u6e2c\u30e2\u30c7\u30eb\u3067\u306f\u904e\u53bb\u306e\u964d\u6c34\u91cf\u306e\u307f\u304c\u4e88\u6e2c\u306b\n\u7528\u3044\u3089\u308c\u3066\u3044\u308b\uff0e__\n>\n> __\u305d\u3053\u3067\u672c\u7814\u7a76\u3067\u306f seq2seq \u30e2\u30c7\u30eb\u306b\u3088\u308b\u6642\u7a7a\u9593\u30c7\u30fc\u30bf\u306e\u4e88\u6e2c\u306b\u304a\u3044\u3066\u8907\u6570\u30e2\u30c0\u30ea\u30c6\u30a3\u3092\u4e88\n\u6e2c\u306b\u7528\u3044\u308b\u30de\u30eb\u30c1\u30e2\u30fc\u30c0\u30eb\u5b66\u7fd2\u3092\u884c\u3046\uff0e__\n>\n> \u672c\u7814\u7a76\u306e\u76ee\u7684\u306f\uff0c__\u964d\u6c34\u91cf\u306e\u4e88\u6e2c\u306b\u304a\u3044\u3066\u904e\u53bb\u306e\u964d\u6c34\u91cf\u306e\u30c7\u30fc\u30bf\u306b\u52a0\u3048\uff0c\u96f2\u306e\u539a\u3055\u3084\u5730\u5f62\u3068\u3044\u3063\u305f\u8907\u6570\u306e\u8981\u56e0\u3092\u5165\u529b\u30c7\u30fc\u30bf\u306b\u52a0\u3048\u308b__\u3053\u3068\u3067\uff0c\u3088\u308a\u7cbe\u5ea6\u306e\u9ad8\u3044\u964d\u6c34\u91cf\u4e88\u6e2c\u3092\u884c\u3046\u3053\u3068\u3067\u3042\u308b\uff0e\n>\n> \u672c\u7a3f\u3067\u306f\uff0c2 \u7ae0\u3067 __*ConvLSTM*__ \u3092\u7528\u3044\u305f\u6642\u7a7a\u9593\u30c7\u30fc\u30bf\u306e\u4e88\u6e2c\u30e2\u30c7\u30eb\u306b\u3064\u3044\u3066\u8ff0\u3079\uff0c3 \u7ae0\u3067\u63d0\u6848\u3059\u308b\u30de\u30eb\u30c1\u30e2\u30fc\u30c0\u30eb\u5b66\u7fd2\u306e\u624b\u6cd5\u3092\u8ff0\u3079\u308b\uff0e\n> 4 \u7ae0\u3067\u5b9f\u30c7\u30fc\u30bf\u3092\u6301\u3061\u305f\u8a55\u4fa1\u5b9f\u9a13\u306b\u3064\u3044\u3066\u8ff0\u3079\uff0c5 \u7ae0\u3067\u672c\u7814\u7a76\u306e\u307e\u3068\u3081\u3092\u884c\u3046\uff0e\n>\n> \uff08 \u4e2d\u7565 \uff09\n>\n\n\n> __3 \u6642\u7a7a\u9593\u30c7\u30fc\u30bf\u306e\u30de\u30eb\u30c1\u30e2\u30fc\u30c0\u30eb\u5b66\u7fd2\u30e2\u30c7\u30eb__\n>\n> \u672c\u7ae0\u3067\u306f\uff0cShi \u3089 [2] \u306e\u63d0\u6848\u3057\u305f ConvLSTM \u3092\u7528\u3044\u305f\u6642\u7a7a\u9593\u30c7\u30fc\u30bf\u306e\u4e88\u6e2c\u30e2\u30c7\u30eb\u306b\u304a\u3044\u3066\uff0c__ConvLSTM \u3092\u62e1\u5f35\u3057\uff0c\u30de\u30eb\u30c1\u30e2\u30fc\u30c0\u30eb\u5b66\u7fd2\u3092\u884c\u3046\u624b\u6cd5__\u306b\u3064\u3044\u3066\u8ff0\u3079\u308b\uff0e\n>\n> __\u6642\u7a7a\u9593\u30c7\u30fc\u30bf\u306f\u6642\u7cfb\u5217\u6027\u3068\u7a7a\u9593\u6027\u3092\u6301\u3064\u30c7\u30fc\u30bf\u3067\u3042\u308b\uff0e__\n>\n> __\u5404\u30bf\u30a4\u30e0\u30b9\u30c6\u30c3\u30d7\u306b\u304a\u3044\u3066\uff0c\u7a7a\u9593\u6027\u3092\u6301\u3064 1 \u3064\u306e\u30c7\u30fc\u30bf\u306f\u753b\u50cf\u3068\u3057\u3066\u6271\u3046\u3053\u3068\u304c\u3067\u304d\u308b\uff0e__\n>\n> __\u753b\u50cf\u3092\u6271\u3046\u4e0a\u3067\u8907\u6570\u306e\u30e2\u30c0\u30ea\u30c6\u30a3\u3092\u30cb\u30e5\u30fc\u30e9\u30eb\u30cd\u30c3\u30c8\u3067\u7528\u3044\u308b\u624b\u6cd5\u3068\u3057\u3066\uff0c\u30e2\u30c0\u30ea\u30c6\u30a3\u3092\u5168\u3066\u7d50\u5408\u3057\uff0c\u8907\u6570\u306e\u30e2\u30c0\u30ea\u30c6\u30a3\u304b\u3089\u306a\u308b\u591a\u30c1\u30e3\u30f3\u30cd\u30eb\u753b\u50cf\u3068\u3057\u3066\u6271\u3046\u65b9\u6cd5\u304c\u3042\u308b [3]__\uff0e\n>\n>\u63d0\u6848\u3059\u308b\u30e2\u30c7\u30eb\u306f\u56f3 1 \u306b\u793a\u3059 Encoding-Forecasting \u30cd\u30c3\u30c8\u30ef\u30fc\u30af\u304b\u3089\u6210\u308b seq2seq \u30e2\u30c7\u30eb\u306b\uff0c__\u8907\u6570\u306e\u30e2\u30c0\u30ea\u30c6\u30a3\u304b\u3089\u306a\u308b\u591a\u30c1\u30e3\u30f3\u30cd\u30eb\u753b\u50cf\u3092\u5165\u529b__\u3059\u308b\u3053\u3068\u3067\u30de\u30eb\u30c1\u30e2\u30fc\u30c0\u30eb\u5b66\u7fd2\u3092\u884c\u3046\u3082\u306e\u3067\u3042\u308b\uff0e\n>\n> ConvLSTM \u3067\u306f\uff0c__LSTM \u306e\u5165\u529b\u30e6\u30cb\u30c3\u30c8\u304b\u3089\u306e\u5165\u529b\u3068\u96a0\u308c\u30e6\u30cb\u30c3\u30c8\u304b\u3089\u306e\u5165\u529b\u306e\u4e21\u65b9\u306b\u7573\u307f\u8fbc\u307f\u6f14\u7b97\u304c\u7528\u3044\u3089\u308c\u3066\u3044\u308b\uff0e__\n>\n> CNN \u3067\u306f\u7573\u307f\u8fbc\u307f\u5c64\u306e\u76f4\u5f8c\u306b\u5c40\u6240\u6b63\u898f\u5316\u306e\u64cd\u4f5c\u304c\u53d6\u308a\u5165\u308c\u3089\u308c\u308b\u3053\u3068\u304c\u591a\u3005\u3042\u308b [3]\uff0e\n>\n> \u5f93\u3063\u3066\u63d0\u6848\u3059\u308b\u30e2\u30c7\u30eb\u3067\u306f\uff0c\u56f3 2 \u306b\u793a\u3059\u3088\u3046\u306b\uff0c\u96a0\u308c\u30e6\u30cb\u30c3\u30c8\u304b\u3089\u306e\u5165\u529b\u3092\u6b63\u898f\u5316\u3059\u308b\u64cd\u4f5c (\u56f3 2 \u306e\u20dd1 )\uff0c\u5165\u529b\u5c64\u304b\u3089\n\u306e\u5165\u529b\u3092\u6b63\u898f\u5316\u3059\u308b\u64cd\u4f5c (\u56f3 2 \u306e\u20dd2 )\uff0c\u304a\u3088\u3073\u51fa\u529b\u3092\u6b63\u898f\u5316\u3059\u308b\u64cd\u4f5c (\u56f3 2 \u306e\u20dd3 ) \u3092\u53d6\u308a\u5165\u308c\u305f\u3082\u306e\u3092\u691c\u8a0e\u3059\u308b\uff0e\n\n___\n\n###__*ConvolutionalLSTM*__\n\n\u4ee5\u4e0b \u304c \u308f\u304b\u308a\u3084\u3059\u3044\n\n* [masataka46\u3055\u3093 Qiita\u8a18\u4e8b \u300cLSTM\u3092\u6539\u826f\u3057\u3066convLSTM\u306b\u3059\u308b\u300d](http://qiita.com/masataka46/items/0c77fef1e48446c7d329)\n\n\u539f\u8ad6\u6587 \u306f \u4ee5\u4e0b\u3002\n\n* [Xingjian Shi Zhourong Chen Hao Wang Dit-Yan Yeung, _Convolutional LSTM Network: A Machine Learning Approach for Precipitation Nowcasting_](https://arxiv.org/pdf/1506.04214.pdf)\n\n\u3053\u306e\u8ad6\u6587 \u304c \u53d6\u308a\u7d44\u3093\u3067\u3044\u308b \u4e3b\u984c \u3082\u3001\u300c\u964d\u6c34\u91cf\u4e88\u5831\u300d\uff08 *precipitation nowcasting* \uff09\u3067 \u3042\u308b\u3002\n\n> __Abstract__\n>\n> The goal of precipitation nowcasting is to predict the future rainfall intensity in a local region over a relatively short period of time. \n>\n> Very few previous studies have examined this crucial and challenging weather forecasting problem from the machine learning perspective. In this paper, we formulate precipitation nowcasting as __a spatiotemporal sequence forecasting problem in which both the input and the prediction target are spatiotemporal sequences.__\n>\n> __By extending the fully connected LSTM (FC-LSTM) to have convolutional structures in both the input-to-state and state-to-state transitions__, we propose __the convolutional LSTM (ConvLSTM)__ and use it to build an end-to-end trainable model for the precipitation nowcasting problem.\n>\n> Experiments __show that our ConvLSTM network captures spatiotemporal\ncorrelations better and consistently outperforms FC-LSTM and the state-of-theart\noperational ROVER algorithm for precipitation nowcasting.__\n\n\n* [\uff08 GitHub\uff09fchollet/keras _Convolutional LSTM #1773_](https://github.com/fchollet/keras/issues/1773)\n\n*  [\uff08 GitHub\uff09loliverhennigh/Convolutional-LSTM-in-Tensorflow](https://github.com/loliverhennigh/Convolutional-LSTM-in-Tensorflow)\n\n___\n\n* [Pankaj Malhotra1, Lovekesh Vig, Gautam Shroff, Puneet Agarwal, _Long Short Term Memory Networks for Anomaly Detection in Time Series_, ESANN 2015 proceedings, European Symposium on Artificial Neural Networks, Computational Intelligence and Machine Learning. Bruges (Belgium), 22-24 April 2015](https://www.elen.ucl.ac.be/Proceedings/esann/esannpdf/es2015-56.pdf)\n\n> __2 LSTM-AD: LSTM-based Anomaly Detection__\n>\n> Consider a time series X = {x(1), x(2), ..., x(n)}, where each point x(t) \u2208 Rm in the time series is an m-dimensionavector\n> {x(t)1 , x(t)2 , ..., x(t)m },\n> whose elements correspond to the input variables.\n>\n> A prediction model learns to predict the next l values for d of the input variables s.t. 1 \u2264 d \u2264 m\n\n* [Reitmann, Stefan and Nachtigall, Karl and Schultz, Michael, _Pattern Recognition and Prediction of Multivariate Time Series with LSTM_](http://elib.dlr.de/110041/)\n\n\n* [Pavel Filonov, Andrey Lavrentyev and Artem Vorontsov, _Multivariate Industrial Time Series with Cyber-Attack Simulation: Fault Detection Using an LSTM-based Predictive Data Model_](https://arxiv.org/pdf/1612.06676.pdf)\n\n> __3. LSTM-based Fault Detection__\n>\n> __Input data can be described as multivariate time series__\n> __X = {x(1), x(2), . . . , x(n)}, __\n>__where x(t) belongs to m dimensional space Rm, n \u2014 number of time points__.\n>\n> The proposed fault detection algorithm consists of two parts: forecasting and detection.\n>\n> At first we split the whole time series into equalsized batches of length w denoted as \n> X(i) = {x(j), x(j+1), . . . , x(j+w\u22121)}. \n>\n> Here i is the batch number and j = w(i \u2212 1) + 1 is the number of first time point in the batch. \n>\n> In the forecasting part we predict values for the next batch X\u02dc(i+1) using already observed measurements X(1), X(2), . . . , X(i).\n>\n> The detection part is based on finding time points where the mean square error (MSE) between the\nmeasured X(i+1) and predicted X\u02dc(i+1) values becomes higher then the precomputed threshold.\n\n> \n> \uff08 \u4e2d\u7565 \uff09\n>\n>  __3.2 Neural Network Architecture__\n>\n> The choise of optimal network architecture is based on several observations.\n>\n>  At first, the most industrial technological processes __generate strongly correlated multivariate time series__.\n>\n> Furthermore we frequently __deal with multiscale processes (see Figure 2) having fast (long-term) and slow (short-term) sub-processes__.\n>\n> In these conditions conventional feed-forward neural networks usually demonstrate a poor results.\n>\n> An accurate data-driven predictive model can be developed using __stateful LSTM neural network [Hochreiter and Schmidhuber, 1997, Malhotra et al., 2015, Nanduri et al., 2016]__.\n>\n> __The proposed network architecture includes two stacked LSTM layers with linear output layer (Figure3)__.\n>\n> In addition we use __a sequence-to-sequence architecture of LSTM network__ for the forecasting model (Figure 4)\n\n![picpoc.PNG](https://qiita-image-store.s3.amazonaws.com/0/43487/1e3d6236-4208-71fe-9383-32c9a297e982.png)\n\n\n* [Wenlu Zhang _et.al, Deep convolutional neural networks for multi-modality isointense infant brain image segmentation_](http://www.sciencedirect.com/science/article/pii/S1053811914010660)\n\n\n___\n\n* https://sourceforge.net/p/currennt/discussion/general/thread/eaaaa315/\n\n> __Harlei Uhrahn - 2014-12-01__\n>\n> Is there any way of using this library with __mutlivariate time-series__?\n>\n>More precise: I have time-series-data where each __time point T is a vector of N scalar values__.\n>\n> I would like to predict a single scalar value at each time point T.\n> _With **N=3 this could be a simple model of RGB colors evolving over time**_.\n>\n> __Of course it would be possible to split the series up into N different univariate time series, and train seperate networks__.\n>\n> __But this would prevent to learn correlations between the vectors components__.\n>--> Side effects which I would like to prevent.\n>\n>What would be a good network topology?\n> \n> __Last edit: Harlei Uhrahn 2014-12-01__\n>\n> This library is all about **multivariate regression and classification**.\n>\n> You can look at** the speech recognition and speech autoencoding examples**\n> - the first one **maps a 39-dimensional feature vector (per time step) to one of 51 discrete classes (per time step)**. \n>\n> The second one **maps a 39-dimensional feature vector to another 39-dimensional vector (real-valued)**.\n>\n> It is especially helpful to look at the .nc files (using ncdump), which contain the data (as arrays of input features and training targets), and the .jsn files, which contain the network topology definitions.\n>\n> If you have N features and 1 output, you can just try a (B)LSTM with one hidden layer of N units and a visible output layer:\n>\n>```{python:}\n>{\n>    \"layers\": [\n>        {\n>            \"size\": N,\n>            \"name\": \"input\",\n>            \"type\": \"input\"\n>        },\n>        {\n>            \"size\": N,\n>            \"name\": \"lstm_layer\",\n>            \"bias\": 1.0,\n>            \"type\": \"lstm\"\n>        },\n>        {\n>            \"size\": 1,\n>            \"name\": \"output\",\n>            \"bias\": 1.0,\n>            \"type\": \"feedforward_identity\"\n>        },\n>        {\n>            \"size\": 1,\n>            \"name\": \"postoutput\",\n>            \"type\": \"sse\"\n>        }\n>    ]\n>}\n>```\n>\n> where you replace N by your feature vector dimension. Of course, you should try more than one LSTM layer, larger LSTM layers, etc.\n>\n> To use bidirectional LSTM layers, just replace lstm by blstm in the above.\nThe sse \"post output layer\" implements the calculation of the sum of squared errors cost function, and the backpropagation of its derivatives to train the network weights.\n>\n> If your targets are in the range 0-1, you can also use feedforward_sigmoid as output layer type.\n>\n> If your targets are in the range -1 to 1, you can also use feedforward_tanh. This only changes the output layer activation function so that your network outputs are automatically constrained to the correct range.\n>\n> Hope that helps,\n> Felix\n\n___\n\n##__\uff08 \u4ee5\u4e0b \u306f \u8aad\u89e3\u4e2d \uff09__\n\n\n* http://catsr.ite.gmu.edu/pubs/ICNS_2016_AnomalyDetectionRNN_01042015.pdf\n\n* https://arxiv.org/pdf/1610.04834.pdf\n\n* http://www.ijcaonline.org/archives/volume143/number11/zaytar-2016-ijca-910497.pdf\n"}