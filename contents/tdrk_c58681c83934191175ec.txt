{"context": " More than 1 year has passed since last update.\u7b2c6\u7ae0\u306e\u524d\u534a\u306e\u554f\u984c\u3092\u89e3\u3044\u305f\u8a18\u9332\u3002\n\u5bfe\u8c61\u3068\u3059\u308b\u30d5\u30a1\u30a4\u30eb\u306fweb\u30da\u30fc\u30b8\u306b\u3082\u3042\u308b\u901a\u308a\u3001nlp.txt\u3068\u3059\u308b\u3002\n\n\u82f1\u8a9e\u306e\u30c6\u30ad\u30b9\u30c8\uff08nlp.txt\uff09\u306b\u5bfe\u3057\u3066\uff0c\u4ee5\u4e0b\u306e\u51e6\u7406\u3092\u5b9f\u884c\u305b\u3088\uff0e\n\n\n 50. \u6587\u533a\u5207\u308a\n\n(. or ; or : or ? or !) \u2192 \u7a7a\u767d\u6587\u5b57 \u2192 \u82f1\u5927\u6587\u5b57\u3068\u3044\u3046\u30d1\u30bf\u30fc\u30f3\u3092\u6587\u306e\u533a\u5207\u308a\u3068\u898b\u306a\u3057\uff0c\u5165\u529b\u3055\u308c\u305f\u6587\u66f8\u30921\u884c1\u6587\u306e\u5f62\u5f0f\u3067\u51fa\u529b\u305b\u3088\uff0e\n\n# -*- coding: utf-8 -*-\n__author__ = 'todoroki'\n\nimport re\n\npunt = re.compile(r\"(?P<punt>[\\.:;!\\?]) (?P<head>[A-Z])\")\n\nif __name__ == \"__main__\":\n    f = open('nlp.txt', 'r')\n    for line in f:\n        l = line.strip()\n        # if punt.search(l):\n            # print punt.sub(r\"\\g<punt>\\n\\g<head>\", l)\n        print punt.sub(r\"\\g<punt>\\n\\g<head>\", l)\n    f.close()\n\n\n 51. \u5358\u8a9e\u306e\u5207\u308a\u51fa\u3057\n\n\u7a7a\u767d\u3092\u5358\u8a9e\u306e\u533a\u5207\u308a\u3068\u307f\u306a\u3057\uff0c50\u306e\u51fa\u529b\u3092\u5165\u529b\u3068\u3057\u3066\u53d7\u3051\u53d6\u308a\uff0c1\u884c1\u5358\u8a9e\u306e\u5f62\u5f0f\u3067\u51fa\u529b\u305b\u3088\uff0e\u305f\u3060\u3057\uff0c\u6587\u306e\u7d42\u7aef\u3067\u306f\u7a7a\u884c\u3092\u51fa\u529b\u305b\u3088\uff0e\n\n# -*- coding: utf-8 -*-\n__author__ = 'todoroki'\n\nimport re\n\nif __name__ == \"__main__\":\n    f = open('nlp_line.txt', 'r')\n    for line in f:\n        l = line.strip()\n        for word in l.split():\n            print re.sub(r\"\\W\", \"\", word)\n        print \"\"\n    f.close()\n\n\n 52. \u30b9\u30c6\u30df\u30f3\u30b0\n\n51\u306e\u51fa\u529b\u3092\u5165\u529b\u3068\u3057\u3066\u53d7\u3051\u53d6\u308a\uff0cPorter\u306e\u30b9\u30c6\u30df\u30f3\u30b0\u30a2\u30eb\u30b4\u30ea\u30ba\u30e0\u3092\u9069\u7528\u3057\uff0c\u5358\u8a9e\u3068\u8a9e\u5e79\u3092\u30bf\u30d6\u533a\u5207\u308a\u5f62\u5f0f\u3067\u51fa\u529b\u305b\u3088\uff0e Python\u3067\u306f\uff0cPorter\u306e\u30b9\u30c6\u30df\u30f3\u30b0\u30a2\u30eb\u30b4\u30ea\u30ba\u30e0\u306e\u5b9f\u88c5\u3068\u3057\u3066stemming\u30e2\u30b8\u30e5\u30fc\u30eb\u3092\u5229\u7528\u3059\u308b\u3068\u3088\u3044\uff0e\n\n# -*- coding: utf-8 -*-\n__author__ = 'todoroki'\n\nfrom nltk.stem.porter import PorterStemmer\n\nif __name__ == \"__main__\":\n    f = open('nlp_word.txt')\n    for line in f:\n        stemmer = PorterStemmer()\n        l = line.strip()\n        if len(l) > 0:\n            print \"%s\\t%s\" % (l, stemmer.stem(l))\n        else:\n            print \"\"\n    f.close()\n\n\n 53. Tokenization\n\nStanford Core NLP\u3092\u7528\u3044\uff0c\u5165\u529b\u30c6\u30ad\u30b9\u30c8\u306e\u89e3\u6790\u7d50\u679c\u3092XML\u5f62\u5f0f\u3067\u5f97\u3088\uff0e\u307e\u305f\uff0c\u3053\u306eXML\u30d5\u30a1\u30a4\u30eb\u3092\u8aad\u307f\u8fbc\u307f\uff0c\u5165\u529b\u30c6\u30ad\u30b9\u30c8\u30921\u884c1\u5358\u8a9e\u306e\u5f62\u5f0f\u3067\u51fa\u529b\u305b\u3088\uff0e\n\n# -*- coding: utf-8 -*-\n__author__ = 'todoroki'\n\nimport re\n\nWORD = re.compile(r\"<word>(\\w+)</word>\")\n\nf = open('nlp.txt.xml', 'r')\nfor line in f:\n    word = WORD.search(line.strip())\n    if word:\n        print word.group(1)\nf.close()\n\n\nXML\u30d5\u30a1\u30a4\u30eb\u306e\u4f5c\u6210\u30b3\u30de\u30f3\u30c9\nStanford Core NLP\u3092\u30c0\u30a6\u30f3\u30ed\u30fc\u30c9\u3057\u3001\u305d\u306e\u30d5\u30a9\u30eb\u30c0\u307e\u3067\u79fb\u52d5\u3002\n\u6b21\u306e\u30b3\u30de\u30f3\u30c9\u3092\u5b9f\u884c\u3002\njava -Xmx5g -cp stanford-corenlp-3.6.0.jar:stanford-corenlp-models-3.6.0.jar:* edu.stanford.nlp.pipeline.StanfordCoreNLP -annotators tokenize,ssplit,pos,lemma,ner,parse,mention,coref -file nlp_line.txt -outputFormat xml\n\n\u306a\u305c\u3060\u304bzsh\u4e0a\u3067\u306f\u30a8\u30e9\u30fc\u3092\u5410\u3044\u3066\u52d5\u304b\u306a\u304b\u3063\u305f\u306e\u3067\u3001bash\u4e0a\u3067\u5b9f\u884c\u3002\n\n 54. \u54c1\u8a5e\u30bf\u30b0\u4ed8\u3051\n\nStanford Core NLP\u306e\u89e3\u6790\u7d50\u679cXML\u3092\u8aad\u307f\u8fbc\u307f\uff0c\u5358\u8a9e\uff0c\u30ec\u30f3\u30de\uff0c\u54c1\u8a5e\u3092\u30bf\u30d6\u533a\u5207\u308a\u5f62\u5f0f\u3067\u51fa\u529b\u305b\u3088\uff0e\n\n# -*- coding: utf-8 -*-\n__author__ = 'todoroki'\n\nimport re\n\nWORD = re.compile(r\"<word>(\\w+)</word>\")\nLEMMA = re.compile(r\"<lemma>(\\w+)</lemma>\")\nPOS = re.compile(r\"<POS>(\\w+)</POS>\")\n\nf = open(\"nlp.txt.xml\", \"r\")\nwords = []\nfor line in f:\n    if len(words) == 3:\n        print \"\\t\".join(words)\n        words = []\n    else:\n        line = line.strip()\n        word = WORD.search(line)\n        if len(words) == 0 and word:\n            words.append(word.group(1))\n            continue\n        lemma = LEMMA.search(line)\n        if len(words) == 1 and lemma:\n            words.append(lemma.group(1))\n            continue\n        pos = POS.search(line)\n        if len(words) == 2 and pos:\n            words.append(pos.group(1))\nf.close()\n\n\n\n\u7b2c6\u7ae0\u306e\u524d\u534a\u306e\u554f\u984c\u3092\u89e3\u3044\u305f\u8a18\u9332\u3002\n\u5bfe\u8c61\u3068\u3059\u308b\u30d5\u30a1\u30a4\u30eb\u306fweb\u30da\u30fc\u30b8\u306b\u3082\u3042\u308b\u901a\u308a\u3001nlp.txt\u3068\u3059\u308b\u3002\n> \u82f1\u8a9e\u306e\u30c6\u30ad\u30b9\u30c8\uff08nlp.txt\uff09\u306b\u5bfe\u3057\u3066\uff0c\u4ee5\u4e0b\u306e\u51e6\u7406\u3092\u5b9f\u884c\u305b\u3088\uff0e\n\n\n## <i class=\"fa fa-leaf\"></i> 50. \u6587\u533a\u5207\u308a\n> (. or ; or : or ? or !) \u2192 \u7a7a\u767d\u6587\u5b57 \u2192 \u82f1\u5927\u6587\u5b57\u3068\u3044\u3046\u30d1\u30bf\u30fc\u30f3\u3092\u6587\u306e\u533a\u5207\u308a\u3068\u898b\u306a\u3057\uff0c\u5165\u529b\u3055\u308c\u305f\u6587\u66f8\u30921\u884c1\u6587\u306e\u5f62\u5f0f\u3067\u51fa\u529b\u305b\u3088\uff0e\n\n```python\n# -*- coding: utf-8 -*-\n__author__ = 'todoroki'\n\nimport re\n\npunt = re.compile(r\"(?P<punt>[\\.:;!\\?]) (?P<head>[A-Z])\")\n\nif __name__ == \"__main__\":\n    f = open('nlp.txt', 'r')\n    for line in f:\n        l = line.strip()\n        # if punt.search(l):\n            # print punt.sub(r\"\\g<punt>\\n\\g<head>\", l)\n        print punt.sub(r\"\\g<punt>\\n\\g<head>\", l)\n    f.close()\n```\n\n## <i class=\"fa fa-leaf\"></i> 51. \u5358\u8a9e\u306e\u5207\u308a\u51fa\u3057\n> \u7a7a\u767d\u3092\u5358\u8a9e\u306e\u533a\u5207\u308a\u3068\u307f\u306a\u3057\uff0c50\u306e\u51fa\u529b\u3092\u5165\u529b\u3068\u3057\u3066\u53d7\u3051\u53d6\u308a\uff0c1\u884c1\u5358\u8a9e\u306e\u5f62\u5f0f\u3067\u51fa\u529b\u305b\u3088\uff0e\u305f\u3060\u3057\uff0c\u6587\u306e\u7d42\u7aef\u3067\u306f\u7a7a\u884c\u3092\u51fa\u529b\u305b\u3088\uff0e\n\n```python\n# -*- coding: utf-8 -*-\n__author__ = 'todoroki'\n\nimport re\n\nif __name__ == \"__main__\":\n    f = open('nlp_line.txt', 'r')\n    for line in f:\n        l = line.strip()\n        for word in l.split():\n            print re.sub(r\"\\W\", \"\", word)\n        print \"\"\n    f.close()\n```\n\n## <i class=\"fa fa-leaf\"></i> 52. \u30b9\u30c6\u30df\u30f3\u30b0\n> 51\u306e\u51fa\u529b\u3092\u5165\u529b\u3068\u3057\u3066\u53d7\u3051\u53d6\u308a\uff0cPorter\u306e\u30b9\u30c6\u30df\u30f3\u30b0\u30a2\u30eb\u30b4\u30ea\u30ba\u30e0\u3092\u9069\u7528\u3057\uff0c\u5358\u8a9e\u3068\u8a9e\u5e79\u3092\u30bf\u30d6\u533a\u5207\u308a\u5f62\u5f0f\u3067\u51fa\u529b\u305b\u3088\uff0e Python\u3067\u306f\uff0cPorter\u306e\u30b9\u30c6\u30df\u30f3\u30b0\u30a2\u30eb\u30b4\u30ea\u30ba\u30e0\u306e\u5b9f\u88c5\u3068\u3057\u3066stemming\u30e2\u30b8\u30e5\u30fc\u30eb\u3092\u5229\u7528\u3059\u308b\u3068\u3088\u3044\uff0e\n\n```python\n# -*- coding: utf-8 -*-\n__author__ = 'todoroki'\n\nfrom nltk.stem.porter import PorterStemmer\n\nif __name__ == \"__main__\":\n    f = open('nlp_word.txt')\n    for line in f:\n        stemmer = PorterStemmer()\n        l = line.strip()\n        if len(l) > 0:\n            print \"%s\\t%s\" % (l, stemmer.stem(l))\n        else:\n            print \"\"\n    f.close()\n```\n\n## <i class=\"fa fa-leaf\"></i> 53. Tokenization\n> Stanford Core NLP\u3092\u7528\u3044\uff0c\u5165\u529b\u30c6\u30ad\u30b9\u30c8\u306e\u89e3\u6790\u7d50\u679c\u3092XML\u5f62\u5f0f\u3067\u5f97\u3088\uff0e\u307e\u305f\uff0c\u3053\u306eXML\u30d5\u30a1\u30a4\u30eb\u3092\u8aad\u307f\u8fbc\u307f\uff0c\u5165\u529b\u30c6\u30ad\u30b9\u30c8\u30921\u884c1\u5358\u8a9e\u306e\u5f62\u5f0f\u3067\u51fa\u529b\u305b\u3088\uff0e\n\n```python\n# -*- coding: utf-8 -*-\n__author__ = 'todoroki'\n\nimport re\n\nWORD = re.compile(r\"<word>(\\w+)</word>\")\n\nf = open('nlp.txt.xml', 'r')\nfor line in f:\n    word = WORD.search(line.strip())\n    if word:\n        print word.group(1)\nf.close()\n```\n\n#### XML\u30d5\u30a1\u30a4\u30eb\u306e\u4f5c\u6210\u30b3\u30de\u30f3\u30c9\nStanford Core NLP\u3092\u30c0\u30a6\u30f3\u30ed\u30fc\u30c9\u3057\u3001\u305d\u306e\u30d5\u30a9\u30eb\u30c0\u307e\u3067\u79fb\u52d5\u3002\n\u6b21\u306e\u30b3\u30de\u30f3\u30c9\u3092\u5b9f\u884c\u3002\n\n```bash\njava -Xmx5g -cp stanford-corenlp-3.6.0.jar:stanford-corenlp-models-3.6.0.jar:* edu.stanford.nlp.pipeline.StanfordCoreNLP -annotators tokenize,ssplit,pos,lemma,ner,parse,mention,coref -file nlp_line.txt -outputFormat xml\n```\n\u306a\u305c\u3060\u304bzsh\u4e0a\u3067\u306f\u30a8\u30e9\u30fc\u3092\u5410\u3044\u3066\u52d5\u304b\u306a\u304b\u3063\u305f\u306e\u3067\u3001bash\u4e0a\u3067\u5b9f\u884c\u3002\n\n\n## <i class=\"fa fa-leaf\"></i> 54. \u54c1\u8a5e\u30bf\u30b0\u4ed8\u3051\n> Stanford Core NLP\u306e\u89e3\u6790\u7d50\u679cXML\u3092\u8aad\u307f\u8fbc\u307f\uff0c\u5358\u8a9e\uff0c\u30ec\u30f3\u30de\uff0c\u54c1\u8a5e\u3092\u30bf\u30d6\u533a\u5207\u308a\u5f62\u5f0f\u3067\u51fa\u529b\u305b\u3088\uff0e\n\n```python\n# -*- coding: utf-8 -*-\n__author__ = 'todoroki'\n\nimport re\n\nWORD = re.compile(r\"<word>(\\w+)</word>\")\nLEMMA = re.compile(r\"<lemma>(\\w+)</lemma>\")\nPOS = re.compile(r\"<POS>(\\w+)</POS>\")\n\nf = open(\"nlp.txt.xml\", \"r\")\nwords = []\nfor line in f:\n    if len(words) == 3:\n        print \"\\t\".join(words)\n        words = []\n    else:\n        line = line.strip()\n        word = WORD.search(line)\n        if len(words) == 0 and word:\n            words.append(word.group(1))\n            continue\n        lemma = LEMMA.search(line)\n        if len(words) == 1 and lemma:\n            words.append(lemma.group(1))\n            continue\n        pos = POS.search(line)\n        if len(words) == 2 and pos:\n            words.append(pos.group(1))\nf.close()\n```\n\n\n<link rel=\"stylesheet\" href=\"https://maxcdn.bootstrapcdn.com/font-awesome/4.4.0/css/font-awesome.min.css\">\n", "tags": ["\u81ea\u7136\u8a00\u8a9e\u51e6\u7406", "Python", "NLP"]}