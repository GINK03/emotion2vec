{"context": " More than 1 year has passed since last update.SQL\u306eWindow\u95a2\u6570\u306e row_number \u4fbf\u5229\u3067\u3059\u3088\u306d\u3002\nApache Spark\u306e DataFrame \u3067\u3082 1.4.0 \u4ee5\u964d\u306a\u3089 row_number \u4f7f\u3048\u307e\u3059  \n\nDataFrame\u306e\u30b5\u30f3\u30d7\u30eb\n\n\n\nversion\nname\n\n\n\n\n1.0\nApple Pie\n\n\n1.1\nBanana Bread\n\n\n1.5\nCupcake\n\n\n1.6\nDonut\n\n\n2.0\nEclair\n\n\n2.1\nFroyo\n\n\n2.3\nGingerbread\n\n\n3\nHoneycomb\n\n\n4.0\nIce Cream Sandwich\n\n\n4.3\nJelly Bean\n\n\n4.4\nKitKat\n\n\n\n\nrow_number\norg.apache.spark.sql.expressions.Window \u3092import\u3057\u3066 rowNumber().over() \u306b\u6e21\u3057\u307e\u3059\u3002\nimport org.apache.spark.sql.expressions.Window\nimport org.apache.spark.sql.functions._\n\nval identified = df.select(\n    rowNumber().over( Window.partitionBy().orderBy() ) as \"id\",\n    $\"version\",\n    $\"name\",\n)\n\n\u2191\u307f\u305f\u3044\u306b partitionBy \u306b\u5f15\u6570\u3092\u6e21\u3055\u306a\u3044\u3068\u5168\u30c7\u30fc\u30bf\u306b\u5bfe\u3057\u3066\u901a\u756a\u304c\u3075\u3089\u308c\u307e\u3059\u3002\nidentified.take(5)\nres1: Array[org.apache.spark.sql.Row] = Array([1,\"1.0\",\"Apple Pie\"], [2,\"1.1\",\"Banana Bread\"], [3,\"1.5\",\"Cupcake\"], [4,\"1.6\",\"Donut\"], [5,\"2.0\",\"Eclair\"])\n\nSQL\u306eWindow\u95a2\u6570\u306e `row_number` \u4fbf\u5229\u3067\u3059\u3088\u306d\u3002\nApache Spark\u306e `DataFrame` \u3067\u3082 `1.4.0` \u4ee5\u964d\u306a\u3089 `row_number` \u4f7f\u3048\u307e\u3059 :smiley: \n\n### DataFrame\u306e\u30b5\u30f3\u30d7\u30eb\n\n|version|name|\n|-------|----|\n|1.0| Apple Pie |\n|1.1| Banana Bread |\n|1.5| Cupcake |\n|1.6| Donut |\n|2.0| Eclair |\n|2.1| Froyo |\n|2.3| Gingerbread |\n|3| Honeycomb |\n|4.0| Ice Cream Sandwich |\n|4.3| Jelly Bean |\n|4.4| KitKat |\n\n### row_number\n`org.apache.spark.sql.expressions.Window` \u3092import\u3057\u3066 `rowNumber().over()` \u306b\u6e21\u3057\u307e\u3059\u3002\n\n```scala\nimport org.apache.spark.sql.expressions.Window\nimport org.apache.spark.sql.functions._\n\nval identified = df.select(\n    rowNumber().over( Window.partitionBy().orderBy() ) as \"id\",\n    $\"version\",\n    $\"name\",\n)\n```\n\n\u2191\u307f\u305f\u3044\u306b `partitionBy` \u306b\u5f15\u6570\u3092\u6e21\u3055\u306a\u3044\u3068\u5168\u30c7\u30fc\u30bf\u306b\u5bfe\u3057\u3066\u901a\u756a\u304c\u3075\u3089\u308c\u307e\u3059\u3002\n\n```js\nidentified.take(5)\nres1: Array[org.apache.spark.sql.Row] = Array([1,\"1.0\",\"Apple Pie\"], [2,\"1.1\",\"Banana Bread\"], [3,\"1.5\",\"Cupcake\"], [4,\"1.6\",\"Donut\"], [5,\"2.0\",\"Eclair\"])\n```\n", "tags": ["Apache", "Spark"]}