{"context": "\n\n\u6982\u8981\n\u3000\u3059\u3050\u306b\u4f7f\u3048\u308bKNBC\u30b3\u30fc\u30d1\u30b9\u3092\u5bfe\u8c61\u306b\u3001\u30e2\u30c0\u30f3\u306aR\u306e\u66f8\u304d\u65b9\u3067\u30c6\u30ad\u30b9\u30c8\u89e3\u6790\u3057\u305f\u3068\u304d\u306e\u30e1\u30e2\u3067\u3059\u3002TF-IDF\u3084\u5171\u8d77\u983b\u5ea6\uff08\u30cd\u30c3\u30c8\u30ef\u30fc\u30af\u4f5c\u6210\uff09\u3001LDA\u3084GloVe\u307e\u3067\u3092\u30d1\u30c3\u30b1\u30fc\u30b8\u3067\u5b9f\u884c\u3057\u307e\u3057\u305f\u3002\n - \u89e3\u6790\u6e08\u307f\u30d6\u30ed\u30b0\u30b3\u30fc\u30d1\u30b9\n\n\u5b9a\u7fa9\u30fb\u8a2d\u5b9a\n\u3000\u6700\u521d\u306b\u51e6\u7406\u3067\u5229\u7528\u3059\u308b\u30e9\u30a4\u30d6\u30e9\u30ea\u306e\u8aad\u307f\u8fbc\u307f\u3084\u5b9a\u6570\u30fb\u95a2\u6570\u306e\u5b9a\u7fa9\u3002\n\n\u5b9a\u6570\u5b9a\u7fa9\u90e8\nlibrary(pacman)\nlibrary(widyr)\n\n# \u8aad\u307f\u8fbc\u3080\u30d1\u30c3\u30b1\u30fc\u30b8\nSET_LOAD_PACKAGE <- c(\"tidyverse\", \"Rcpp\", \"chunked\", \"tidytext\", \"visNetwork\", \"textmineR\", \"Matrix\", \"topicmodels\", \"LDAvis\", \"text2vec\")\n\n# \u30b3\u30fc\u30d1\u30b9\u30d5\u30a1\u30a4\u30eb\u306e\u8a2d\u5b9a\nSET_CORPUS_FILE <- list(\n  DOWNLOAD_URL = \"http://nlp.ist.i.kyoto-u.ac.jp/kuntt/KNBC_v1.0_090925.tar.bz2\",\n  DIST_FILE = \"KNBC.tar.bz2\"\n)\nSET_TARGET_DIR <- list(\n  EXTRACT_DIR = \"knbc_corpus\",\n  READ_DIR = \"knbc_corpus/KNBC_v1.0_090925/corpus2/\"\n)\nSET_STAGING_FILE = \"knbc.csv\"\n\n# \u30b9\u30c8\u30c3\u30d7\u30ef\u30fc\u30c9\u8a2d\u5b9a\nSET_STOP_WORD <- c(\"\u3053\u3068\", \"\u3082\u306e\", \"\u79c1\", \"\u3088\u3046\", \"\u3053\u308c\", \"\u306e\")\n\n\n\n\u95a2\u6570\u5b9a\u7fa9\u90e8\n# MeCab\u306e{Rcpp}\u30e9\u30c3\u30d1\u30fc\u5b9a\u7fa9\nSys.setenv(\"PKG_LIBS\" = \"-lmecab\")\ncallCppMeCab <- Rcpp::cppFunction(\n  code = 'DataFrame callCppMeCab(SEXP str) {\n  std::string input = Rcpp::as<std::string>(str);\n  std::vector<std::string> surface, feature;\n\n  // MeCab\u30bf\u30ac\u30fc\u3092\u751f\u6210\u3057\u3066\u3001\u5165\u529b\u6587\u306e\u5f62\u614b\u7d20\u89e3\u6790\u7d50\u679c\u3092\u53d7\u3051\u53d6\u308b\n  MeCab::Tagger *tagger = MeCab::createTagger(\"-l 2\");\n  const MeCab::Node* node = tagger->parseToNode(input.c_str());\n\n  std::vector<std::string> strs;\n  for (; node; node = node->next) {\n    if (node->stat == MECAB_NOR_NODE || node->stat == MECAB_UNK_NODE) {\n      surface.push_back(std::string(node->surface, node->length));\n      feature.push_back(std::string(node->feature));\n    }\n  }  \n\n  return Rcpp::wrap(\n    Rcpp::DataFrame::create(\n      Rcpp::Named(\"surface\") = surface,\n      Rcpp::Named(\"feature\") = feature\n    )\n  );\n  }',\n  includes = c(\"#include <mecab.h>\")\n)\n\n# \u5f62\u614b\u7d20\u89e3\u6790\u7d50\u679c\u306e\u3046\u3061\u3001\u6307\u5b9a\u3057\u305f\u54c1\u8a5e\u306e\u8868\u5c64\u306e\u307f\u3092\u62bd\u51fa\n# @param text \u5f62\u614b\u7d20\u89e3\u6790\u306b\u304b\u3051\u308b\u5165\u529b\u6587\n# @param extract_pattern \u62bd\u51fa\u3059\u308b\u30d1\u30bf\u30fc\u30f3\uff08\u6b63\u898f\u8868\u73fe\uff09\nextractContent <- function (text, extract_pattern) {\n  ex_surface <- callCppMeCab(str = text) %>% \n    tidyr::separate(\n      col = feature, \n      into = c(\"pos\", \"pos1\", \"pos2\", \"pos3\", \"ctype\", \"cform\", \"baseform\", \"orth\", \"pron\"),\n      sep = \",\", fill = \"right\"\n    ) %>% \n    dplyr::filter(stringr::str_detect(string = .$pos, pattern = extract_pattern)) %>% \n    dplyr::mutate_if(.tbl = ., .predicate = is.factor, .funs = as.character) %>% \n    dplyr::select(surface)\n\n  if (nrow(x = ex_surface) < 1) {\n    return(\"\")\n  }\n\n  return (\n    dplyr::summarize(ex_surface, sentence = stringr::str_c(surface, collapse = \"\\t\")) %>% \n      .$sentence\n  )\n}\n\n\n\n\u6e96\u5099\n\u3000\u5fc5\u8981\u306a\u30c7\u30fc\u30bf\u306e\u53d6\u5f97\u3068\u6574\u5f62\u3092\u884c\u3044\u3001\u30c6\u30ad\u30b9\u30c8\u306e\u7d71\u8a08\u5024\u3092\u53ef\u8996\u5316\u3002\n\n\u30b3\u30fc\u30d1\u30b9\u306e\u6574\u5f62\n# \u4eca\u56de\u4f7f\u7528\u3059\u308b\u30d1\u30c3\u30b1\u30fc\u30b8\u3092\u8aad\u307f\u8fbc\u307f\npacman::p_load(char = SET_LOAD_PACKAGE, install = FALSE, character.only = TRUE)\n\n# \u30b3\u30fc\u30d1\u30b9\u6e96\u5099\ndownload.file(url = SET_CORPUS_FILE$DOWNLOAD_URL, destfile = SET_CORPUS_FILE$DIST_FILE)\nuntar(\n  tarfile = SET_CORPUS_FILE$DIST_FILE, exdir = SET_TARGET_DIR$EXTRACT_DIR,\n  list = FALSE, compressed = \"bzip2\"\n)\n\n# document_id, sentence_id, text\u306e\u5f62\u306b\u5909\u63db\nknbc_raw <- dplyr::bind_rows(\n  lapply(\n    X = list.files(path = SET_TARGET_DIR$READ_DIR, pattern = \".tsv$\", full.names = TRUE),\n    FUN = readr::read_tsv,\n    locale = locale(encoding = \"EUC-JP\"),\n    col_types = \"cc----\", col_names = c(\"id\", \"text\")\n  )\n) %>%  \n  tidyr::separate(col = id, into = c(\"gid\", \"domain\", \"did\", \"dummy\", \"sid_1\", \"sid_2\"), sep = \"_|-\") %>% \n  # \u30bf\u30a4\u30c8\u30eb\u9664\u53bb\n  dplyr::filter(.$sid_1 != 1) %>% \n  tidyr::unite_(col = \"gids\", from = c(\"gid\", \"did\", \"domain\"), sep = \"-\") %>% \n  dplyr::mutate(did = as.integer(x = as.factor(x = gids))) %>% \n  dplyr::group_by(gids) %>% \n  dplyr::mutate(sid = dplyr::row_number(x = gids)) %>% \n  dplyr::ungroup() %>% \n  dplyr::select(gids, did, sid, text) %>% \n  dplyr::arrange(did, sid)\n\n# \u30c6\u30ad\u30b9\u30c8\u6bce\u306e\u30c9\u30e1\u30a4\u30f3\nknbc_domain <- knbc_raw %>% \n  dplyr::select(gids, did) %>% \n  tidyr::separate(col = gids, into = c(\"id\", \"v\", \"domain\"), sep = \"-\") %>% \n  dplyr::group_by(domain, did) %>% \n  dplyr::summarize(scount = n()) %>% \n  dplyr::select(did, domain) %>% \n  dplyr::arrange(did)\n\n# \u30c6\u30ad\u30b9\u30c8\u306e\u30c9\u30e1\u30a4\u30f3\u983b\u5ea6\n> table(knbc_domain$domain)\n\nGourmet  Keitai   Kyoto  Sports \n     57      79      91      22 \n\n# \u884c\u6570\n> nrow(x = knbc_raw)\n[1] 3934\n\n# \u6587\u66f8\u6570\n> max(knbc_raw$did)\n[1] 249\n\n# \u6587\u66f8\u6bce\u306e\u6587\u6570\nknbc_raw %>% \n  dplyr::group_by(did) %>% \n  dplyr::summarize(sent_count = max(sid)) %>% \n  ggplot2::ggplot(data =., ggplot2::aes(x = sent_count)) + ggplot2::geom_histogram()\n\n# \u3072\u3068\u3064\u306e\u6587\u306e\u9577\u3055\nknbc_raw %>% \n  dplyr::mutate(sent_len = stringr::str_length(string = .$text)) %>% \n  ggplot2::ggplot(data =., ggplot2::aes(x = sent_len)) + ggplot2::geom_histogram()\n\n\n\n\n\n\u30d5\u30a1\u30a4\u30eb\u306b\u30d0\u30c3\u30af\u30a2\u30c3\u30d7\n# \u5404\u6587\u304b\u3089\u540d\u8a5e\u3068\u5f62\u5bb9\u8a5e\u3092\u62bd\u51fa\u3057\u3066\u3001\u30d5\u30a1\u30a4\u30eb\u306b\u66f8\u304d\u51fa\u3057\nknbc_raw %>% \n  dplyr::select(-gids) %>% \n  dplyr::rowwise(data = .) %>% \n  dplyr::mutate(text = extractContent(text = text, extract_pattern = \"\u540d\u8a5e|\u5f62\u5bb9\u8a5e\")) %>%\n  readr::write_csv(path = SET_STAGING_FILE)\n\n\n\n\n\u5bc4\u308a\u9053\n\u3000\u30b3\u30fc\u30d1\u30b9\u30d5\u30a1\u30a4\u30eb\u306e\u8aad\u307f\u8fbc\u307f\u306b{chunked}\u3092\u8a66\u3057\u305f\u304b\u3063\u305f\u304c\uff08\u5927\u898f\u6a21\u30c6\u30ad\u30b9\u30c8\u30c7\u30fc\u30bf\u3092\u4e00\u90e8\u5206\u305a\u3064\u8aad\u307f\u8fbc\u3093\u3067\u51e6\u7406\u3059\u308b\u30d1\u30c3\u30b1\u30fc\u30b8\uff09\u3001EUC-JP\u304c\u5bfe\u5fdc\u3067\u304d\u306a\u304b\u3063\u305f\u305f\u3081\u3001\u4e0a\u8a18\u3067\u5404\u6587\u304b\u3089\u540d\u8a5e\u3068\u5f62\u5bb9\u8a5e\u3092\u62bd\u51fa\u3057\u305f\u30d5\u30a1\u30a4\u30eb\u3092\u8aad\u307f\u8fbc\u3080\u5b9f\u9a13\u3002\n- Chunkwise Text-file Processing for 'dplyr'\n\n{chunked}\u306e\u5b9f\u9a13\n# \u5358\u8a9e\u983b\u5ea6\u3092\u96c6\u8a08\u306b{chunked}\u3092\u8a66\u3059\nknbc_chunked_corpus <- chunked::read_table_chunkwise(\n  file = SET_STAGING_FILE, sep = \",\", chunk_size = 500,\n  header = TRUE\n)\n\n# while\u6587\u3092\u56de\u3059\u65b9\u6cd5\u3057\u304b\u601d\u3044\u5f53\u305f\u3089\u306a\u304b\u3063\u305f\u306e\u3067\u3001\u3044\u3044\u611f\u3058\u306b\u5bfe\u51e6\u3059\u308b\u65b9\u6cd5\u3092\u8981\u8abf\u67fb\nknbc <- list()\nknbc_chunk <- \"NULL\"\nwhile (!is.null(x = knbc_chunk)) {\n  knbc_chunk <- knbc_chunked_corpus$next_chunk(cmds = NULL)\n  if (!is.null(x = knbc_chunk)) {\n    knbc <- dplyr::bind_rows(\n      knbc, knbc_chunk %>% \n        tidytext::unnest_tokens_(output_col = \"word\", input_col = \"text\") %>% \n        dplyr::count(word, sort = TRUE)\n    )\n  }\n}\n\n> knbc %>% \n  dplyr::group_by(word) %>% \n  dplyr::summarize(n = sum(n)) %>% \n  dplyr::arrange(dplyr::desc(x = n))\n# A tibble: 5,124 \u00d7 2\n    word     n\n   <chr> <int>\n1     \u306e   713\n2   \u3053\u3068   475\n3     \u4eba   321\n4   \u643a\u5e2f   317\n5   \u4eac\u90fd   289\n6     \u79c1   237\n7   \u96fb\u8a71   224\n8   \u3088\u3046   216\n9   \u3082\u306e   198\n10  \u89b3\u5149   158\n\n\n\u3000\u30c6\u30ad\u30b9\u30c8\u3092\u8aad\u307f\u8fbc\u307f\u66f8\u304d\u51fa\u3059\u307e\u3067\u3092\u4e00\u9023\u306e\u6d41\u308c\u3067\u3084\u308b\u3068\u304d\u306b\u306f\u3044\u3044\u304b\u3082\u308c\u306a\u3044\u304c\u3001iterators::ireadLines\u3068\u4f7f\u3044\u5206\u3051\u304c\u3088\u304f\u308f\u304b\u3089\u306a\u3044\u3002\n\n\n\u5171\u8d77\u30cd\u30c3\u30c8\u30ef\u30fc\u30af\n\u3000{tidytext}\u3068{widyr}\u3067\u63d0\u4f9b\u3055\u308c\u3066\u3044\u308b\u95a2\u6570\u3092\u7d44\u307f\u5408\u308f\u305b\u3066\u5171\u8d77\u983b\u5ea6\u3092\u96c6\u8a08\u3057\u3001{visNetwork}\u3067\u5171\u8d77\u30cd\u30c3\u30c8\u30ef\u30fc\u30af\u3092\u4f5c\u6210\u3002\nknbc_corpus <- readr::read_csv(\n  file = SET_STAGING_FILE,\n  col_types = list(\n    did = readr::col_integer(), sid = readr::col_integer(), text = readr::col_character()\n  )\n) %>% \n  tidyr::drop_na()\n\n> knbc_corpus %>% \n  dplyr::filter(did == 1 & sid == 1)\n# A tibble: 1 \u00d7 3\n    did   sid                                                 text\n  <int> <int>                                                <chr>\n1     1     1 \u4eca\u3055\u3089\\t\u63a5\u982d\\t\u53e5\\t\u306a\u3044\\t\u4eca\u3055\u3089\\t\u79c1\\t\u30d7\u30ea\u30da\u30a4\u30c9\\t\u643a\u5e2f\n\n# tri-gram\n> knbc_corpus %>% \n  tidytext::unnest_tokens_(output_col = \"ngram\", input_col = \"text\", token = \"ngrams\", n = 3) %>% \n  dplyr::filter(did == 1 & sid == 1)\n# A tibble: 6 \u00d7 3\n    did   sid                ngram\n  <int> <int>                <chr>\n1     1     1       \u4eca\u3055\u3089 \u63a5\u982d \u53e5\n2     1     1         \u63a5\u982d \u53e5 \u306a\u3044\n3     1     1       \u53e5 \u306a\u3044 \u4eca\u3055\u3089\n4     1     1       \u306a\u3044 \u4eca\u3055\u3089 \u79c1\n5     1     1 \u4eca\u3055\u3089 \u79c1 \u30d7\u30ea\u30da\u30a4\u30c9\n6     1     1   \u79c1 \u30d7\u30ea\u30da\u30a4\u30c9 \u643a\u5e2f\n\n# skip-gram\n> knbc_corpus %>% \n  tidytext::unnest_tokens_(output_col = \"ngram\", input_col = \"text\", token = \"skip_ngrams\", n = 3, k = 2) %>% \n  dplyr::filter(did == 1 & sid == 1)\n# A tibble: 12 \u00d7 3\n     did   sid                  ngram\n   <int> <int>                  <chr>\n1      1     1 \u4eca\u3055\u3089 \u306a\u3044 \u30d7\u30ea\u30da\u30a4\u30c9\n2      1     1       \u63a5\u982d \u4eca\u3055\u3089 \u643a\u5e2f\n3      1     1       \u4eca\u3055\u3089 \u53e5 \u4eca\u3055\u3089\n4      1     1           \u63a5\u982d \u306a\u3044 \u79c1\n5      1     1   \u53e5 \u4eca\u3055\u3089 \u30d7\u30ea\u30da\u30a4\u30c9\n6      1     1           \u306a\u3044 \u79c1 \u643a\u5e2f\n7      1     1         \u4eca\u3055\u3089 \u63a5\u982d \u53e5\n8      1     1           \u63a5\u982d \u53e5 \u306a\u3044\n9      1     1         \u53e5 \u306a\u3044 \u4eca\u3055\u3089\n10     1     1         \u306a\u3044 \u4eca\u3055\u3089 \u79c1\n11     1     1   \u4eca\u3055\u3089 \u79c1 \u30d7\u30ea\u30da\u30a4\u30c9\n12     1     1     \u79c1 \u30d7\u30ea\u30da\u30a4\u30c9 \u643a\u5e2f\n\n\n# \u6587\u30ec\u30d9\u30eb\u3067\u306e\u5171\u8d77\u983b\u5ea6\nknbc_co <- knbc_corpus %>% \n  tidytext::unnest_tokens_(output_col = \"word\", input_col = \"text\", token = \"words\") %>% \n  dplyr::anti_join(y = dplyr::data_frame(word = SET_STOP_WORD), by = \"word\") %>% \n  widyr::pairwise_count(item = word, feature = sid, diag = FALSE, upper = FALSE) %>% \n  dplyr::arrange(dplyr::desc(n))\n\n# \u5171\u8d77\u983b\u5ea6\u306e\u983b\u5ea6\n> co_freq <- table(knbc_co$n) %>% \n  print\n\n      1       2       3       4       5       6       7       8       9      10      11      12 \n2547815  425269  150040   69181   37289   22272   14126    9336    6042    4215    2986    2165 \n     13      14      15      16      17      18      19      20      21      22      23      24 \n   1448    1050     780     561     357     266     206     141     112      66      60      36 \n     25      26      27      28      29      30      33 \n     29      18      14       4       5       2       1 \n\n\n# \u5171\u8d77\u30cd\u30c3\u30c8\u30ef\u30fc\u30af\u3092\u53ef\u8996\u5316(\u983b\u5ea6\u306e\u7d2f\u7a4d\u76f8\u5bfe\u5ea6\u6570\uff08\u4e0b\u4f4d30%\uff09\u3092\u5207\u308a\u6368\u3066)\nknbc_co_net <- visNetwork::toVisNetworkData(\n  igraph = igraph::graph.data.frame(\n    d = knbc_co %>% \n      dplyr::filter(n > which.max(x = dplyr::cume_dist(x = co_freq) < 0.70)) %>% \n      dplyr::rename(from = item1, to = item2, value = n)\n  ),\n  idToLabel = TRUE\n)\nvisNetwork::visNetwork(\n  nodes = knbc_co_net$nodes, edges = knbc_co_net$edges,\n  width = 900, height = 1200\n) %>% \n  visNetwork::visOptions(\n    highlightNearest = TRUE, nodesIdSelection = TRUE\n  ) %>% \n  visNetwork::visIgraphLayout(layout = \"layout_nicely\") %>% \n  visNetwork::visPhysics(stabilization = TRUE)\n\n\n\u30a4\u30f3\u30bf\u30e9\u30af\u30c6\u30a3\u30d6\u306b\u89e6\u308c\u308b\u7d50\u679c\u306f\u3053\u3061\u3089\n\n\u6587\u66f8\u9593\u306e\u8ddd\u96e2\n\u3000{tidytext}\u3068{widyr}\u3067\u63d0\u4f9b\u3055\u308c\u3066\u3044\u308b\u95a2\u6570\u3092\u7d44\u307f\u5408\u308f\u305b\u3066\u3001TF-IDF\u3092\u7d20\u6027\u306b\u30c6\u30ad\u30b9\u30c8\u9593\u306e\u8ddd\u96e2\u3092\u7b97\u51fa\u3002\u3053\u3053\u3067\u306f\u30c9\u30ad\u30e5\u30e1\u30f3\u30c8\u30ec\u30d9\u30eb\u3067\u8ddd\u96e2\u3092\u51fa\u3057\u3066\u3044\u308b\u304c\u3001\u6587\u30ec\u30d9\u30eb\u3067\u8ddd\u96e2\u306e\u7b97\u51fa\u3082\u5f15\u6570\u3092\u5909\u3048\u308b\u3053\u3068\u3067\u53ef\u80fd\u3002\n\ndocument_distance\n# \u6587\u66f8\u6bce\u306e\u5358\u8a9e\u983b\u5ea6\uff08\u30b9\u30c8\u30c3\u30d7\u30ef\u30fc\u30c9\u9664\u53bb\uff09\nknbc_doc_word_cnt <- knbc_corpus %>% \n  tidytext::unnest_tokens_(output_col = \"word\", input_col = \"text\", token = \"words\") %>% \n  dplyr::anti_join(y = dplyr::data_frame(word = SET_STOP_WORD), by = \"word\") %>% \n  dplyr::group_by(did, word) %>%\n  dplyr::summarize(freq = n()) %>% \n  dplyr::ungroup()\n\n# \u4e0a\u4f4d10\u5358\u8a9e\u3092\u8868\u793a\n> knbc_doc_word_cnt %>% \n  dplyr::arrange(dplyr::desc(x = freq)) %>% \n  dplyr::top_n(n = 10, wt = freq)\n# A tibble: 10 \u00d7 3\n     did   word  freq\n   <int>  <chr> <int>\n1     56   \u795e\u793e    25\n2     69   \u96fb\u8a71    20\n3    200 \u3046\u3069\u3093    20\n4     69   \u643a\u5e2f    19\n5    110   \u96e2\u5bae    18\n6      1   \u643a\u5e2f    16\n7     70     \u5c40    16\n8     70   \u4ea4\u901a    16\n9     70     \u5e02    16\n10   197   \u9903\u5b50    16\n\n# TF-IDF\n> knbc_doc_tfidf <- knbc_doc_word_cnt %>% \n  tidytext::bind_tf_idf_(term_col = \"word\", document_col = \"did\", n_col = \"freq\")\n\n# IDF\u4e0a\u4f4d10\u5358\u8a9e\u3092\u8868\u793a\n> knbc_doc_tfidf %>% \n  dplyr::arrange(dplyr::desc(x = tf_idf)) %>% \n  dplyr::top_n(n = 10, wt = idf)\n# A tibble: 2,962 \u00d7 6\n     did       word  freq         tf      idf    tf_idf\n   <int>      <chr> <int>      <dbl>    <dbl>     <dbl>\n1    231 \u3055\u3064\u307e\u3044\u3082     3 0.10000000 5.517453 0.5517453\n2    141   \u306a\u304e\u306a\u305f     3 0.08823529 5.517453 0.4868341\n3    100     \u771f\u5982\u5802     4 0.08333333 5.517453 0.4597877\n4     97       \u30b1\u30a4     5 0.07692308 5.517453 0.4244195\n5    154     \u30ec\u30bf\u30b9    11 0.07534247 5.517453 0.4156985\n6    172         \u50b7     3 0.07317073 5.517453 0.4037161\n7    215         \u4e5d     5 0.06944444 5.517453 0.3831565\n8     70         \u5c40    16 0.06400000 5.517453 0.3531170\n9    238       \u52d5\u7269     4 0.06349206 5.517453 0.3503145\n10   220       \u5473\u564c     7 0.06194690 5.517453 0.3417891\n# ... with 2,952 more rows\n\n# TF-IDF\u4e0a\u4f4d10\u5358\u8a9e\u3092\u8868\u793a\n> knbc_doc_tfidf %>% \n  dplyr::arrange(dplyr::desc(x = tf_idf)) %>% \n  dplyr::top_n(n = 20, wt = tf_idf)\n# A tibble: 20 \u00d7 6\n     did         word  freq         tf      idf    tf_idf\n   <int>        <chr> <int>      <dbl>    <dbl>     <dbl>\n1    189         \u713c\u8089     5 0.15625000 4.824306 0.7537978\n2    110         \u96e2\u5bae    18 0.14285714 4.824306 0.6891865\n3    238           \u3043    11 0.17460317 3.725693 0.6505179\n4    103         \u5e83\u544a     7 0.14000000 4.418841 0.6186377\n5    232       \u30ab\u30d5\u30a7    12 0.16666667 3.571543 0.5952571\n6    200       \u3046\u3069\u3093    20 0.12820513 4.418841 0.5665180\n7    231   \u3055\u3064\u307e\u3044\u3082     3 0.10000000 5.517453 0.5517453\n8    219 \u30c1\u30e3\u30fc\u30b7\u30e5\u30fc     4 0.10810811 4.824306 0.5215466\n9    132         \u5165\u529b    12 0.13333333 3.908015 0.5210687\n10   218         \u5f01\u5f53     6 0.10714286 4.824306 0.5168899\n11   178         \u5145\u96fb     5 0.12500000 4.131159 0.5163948\n12    44       \u30dc\u30bf\u30f3     4 0.11428571 4.418841 0.5050104\n13   141     \u306a\u304e\u306a\u305f     3 0.08823529 5.517453 0.4868341\n14   220       \u304a\u3067\u3093    11 0.09734513 4.824306 0.4696227\n15   169       \u30d1\u30d5\u30a7     5 0.12500000 3.725693 0.4657117\n16   100       \u771f\u5982\u5802     4 0.08333333 5.517453 0.4597877\n17   197         \u9903\u5b50    16 0.09467456 4.824306 0.4567390\n18   112         \u8fd4\u4fe1     7 0.12727273 3.571543 0.4545600\n19   237           \u3043     6 0.12000000 3.725693 0.4470832\n20    97         \u30b1\u30a4     5 0.07692308 5.517453 0.4244195\n\n\n# \u6587\u66f8\u9593\u306e\u8ddd\u96e2(\u6587\u66f8\u6bce\u306bTF-IDF\u304c\u4e0a\u4f4d\u306e10\u8a9e\u306b\u9650\u5b9a)\nknbc_doc_dist <- knbc_doc_tfidf %>% \n  dplyr::group_by(did) %>% \n  dplyr::top_n(n = 10, wt = tf_idf) %>% \n  dplyr::ungroup() %>% \n  widyr::pairwise_dist(item = did, feature = word, value = tf_idf, method = \"euclidean\", upper = FALSE) %>% \n  dplyr::arrange(distance)\n\n# \u4e00\u756a\u8fd1\u3044\u6587\u66f8\u540c\u58eb\u3067\u5171\u901a\u3057\u3066\u51fa\u73fe\u3059\u308b\u5358\u8a9e\u3092\u8868\u793a\ndplyr::inner_join(\n  x = knbc_doc_tfidf %>% \n    dplyr::filter(did == knbc_doc_dist$item1[1]) %>% \n    dplyr::select(word, did, tf_idf) %>% \n    dplyr::arrange(dplyr::desc(x = tf_idf)),\n  y = knbc_doc_dist %>% \n    dplyr::filter(item1 == knbc_doc_dist$item1[1]) %>% \n    dplyr::top_n(n = 1, wt = -distance) %>%\n    dplyr::select(did = item2) %>% \n    dplyr::left_join(y = knbc_doc_tfidf) %>% \n    dplyr::select(word, did, tf_idf) %>% \n    dplyr::arrange(dplyr::desc(x = tf_idf)),\n  by = c(\"word\")\n) %>% \n  as.data.frame()\nJoining, by = \"did\"\n     word did.x    tf_idf.x did.y    tf_idf.y\n1    \u5352\u696d    52 0.021661008   115 0.018174114\n2    \u3042\u3068    52 0.021160556   115 0.011836149\n3    \u662f\u975e    52 0.020764783   115 0.017422160\n4    \u591a\u3044    52 0.016394187   115 0.009170082\n5      \u3093    52 0.013348896   115 0.005600025\n6      \u6614    52 0.008367429   115 0.014040954\n7      \u524d    52 0.007990222   115 0.006703991\n8    \u4eca\u65e5    52 0.006800579   115 0.011411703\n9      \u7b11    52 0.006352466   115 0.010659748\n10   \u3069\u3053    52 0.005874841   115 0.019716540\n11     \u76ee    52 0.005874841   115 0.009858270\n12     \u5e74    52 0.004666947   115 0.015662731\n13   \u6642\u9593    52 0.004443223   115 0.037279728\n14 \u3068\u3053\u308d    52 0.004389883   115 0.007366438\n15     \u4eba    52 0.003914336   115 0.022989564\n16     \u4e00    52 0.003488270   115 0.011706973\n17   \u3044\u3044    52 0.002894373   115 0.004856899\n18   \u306a\u3044    52 0.002862946   115 0.004804163\n\n\n\u3000\u62bd\u51fa\u3055\u308c\u305f\u30ef\u30fc\u30c9\u304c\u671b\u307e\u3057\u3044\u3082\u306e\u304c\u5c11\u306a\u305d\u3046\u306a\u306e\u3067\u3001\u30b9\u30c8\u30c3\u30d7\u30ef\u30fc\u30c9\u3092\u3082\u3063\u3068\u5b9a\u7fa9\u3057\u305f\u308a\u3001\u5f62\u614b\u7d20\u89e3\u6790\u306b\u7528\u3044\u308b\u8f9e\u66f8\u3092Neologd\u306b\u5909\u3048\u305f\u65b9\u304c\u9069\u3057\u305f\u7d50\u679c\u306b\u306a\u308a\u305d\u3046\u3002\u307e\u305f\u3001widyr::pairwise_dist\u306e\u8ddd\u96e2\u5c3a\u5ea6\u306fstat::dist\u3057\u304b\u4f7f\u3048\u306a\u3044\u306e\u3067\u3001proxy::dist\u304c\u4f7f\u3048\u308b\u3088\u3046\u306b\u306a\u308b\u3068\u5b09\u3057\u3044\u3002\n\nLatent Dirichlet Allocation(LDA)\n\u3000\u6587\u66f8\u6bce\u306e\u5358\u8a9e\u983b\u5ea6\u306e\u30aa\u30d6\u30b8\u30a7\u30af\u30c8\u3092{tm}\u306eDTM(Document-Term-Matrix)\u3084TDM(Term-Document-Matrix)\u306b\u5909\u63db\u3057\u3066\u3001topicmodels::LDA\u3092\u5b9f\u884c\u3057\u3066\u7d50\u679c\u3092{LDAvis}\u3067\u53ef\u8996\u5316\u3002\n\ncast2tm\n# CAST Document-Term-Matrix\n> knbc_dtm <- knbc_doc_word_cnt %>% \n  tidytext::cast_dtm_(term_col = \"word\", document_col = \"did\", value_col = \"freq\") %>% \n  print\n<<DocumentTermMatrix (documents: 249, terms: 5118)>>\nNon-/sparse entries: 15776/1258606\nSparsity           : 99%\nMaximal term length: 13\nWeighting          : term frequency (tf)\n\n> tidytext::tidy(x = knbc_dtm)\n# A tibble: 15,776 \u00d7 3\n   document     term count\n      <chr>    <chr> <dbl>\n1         1   \uff43\uff4f\uff4d     1\n2         2   \uff43\uff4f\uff4d     1\n3        46   \uff43\uff4f\uff4d     1\n4        69   \uff43\uff4f\uff4d     1\n5         1 \uff48\uff54\uff54\uff50     1\n6         2 \uff48\uff54\uff54\uff50     2\n7        35 \uff48\uff54\uff54\uff50     1\n8        46 \uff48\uff54\uff54\uff50     1\n9        69 \uff48\uff54\uff54\uff50     3\n10       92 \uff48\uff54\uff54\uff50     1\n# ... with 15,766 more rows\n\n\n# CAST Term-Document-Matrix\n> knbc_tdm <- knbc_doc_word_cnt %>% \n  tidytext::cast_tdm_(term_col = \"word\", document_col = \"did\", value_col = \"freq\") %>% \n  print\n<<TermDocumentMatrix (terms: 5118, documents: 249)>>\nNon-/sparse entries: 15776/1258606\nSparsity           : 99%\nMaximal term length: 13\nWeighting          : term frequency (tf)\n\n> tidytext::tidy(x = knbc_tdm)\n# A tibble: 15,776 \u00d7 3\n                   term document count\n                  <chr>    <chr> <dbl>\n1                \uff43\uff4f\uff4d        1     1\n2              \uff48\uff54\uff54\uff50        1     1\n3              \uff4d\uff49\uff58\uff49        1     1\n4  \uff50\uff52\uff45\uff50\uff41\uff49\uff44\uff46\uff41\uff4e        1     1\n5                  \uff53\uff41        1     1\n6      \uff53\uff4f\uff46\uff54\uff42\uff41\uff4e\uff4b        1     1\n7      \uff56\uff4f\uff44\uff41\uff46\uff4f\uff4e\uff45        1     1\n8                \uff57\uff45\uff42        1     1\n9                \uff57\uff57\uff57        1     1\n10               \u3044\u304f\u3064        1     1\n# ... with 15,766 more rows\n\n\n\nLDA\n# KNBC\u30b3\u30fc\u30d1\u30b9\u306fGourmet, Keitai, Kyoto, Sports\u306b\u3064\u3044\u3066\u66f8\u304b\u308c\u305f\u30b3\u30fc\u30d1\u30b9\u306a\u306e\u3067\u3001\u30c8\u30d4\u30c3\u30af\u6570\u30924\u306b\u6307\u5b9a\u3057\u3066\u5b9f\u884c\nknbc_dtm_lda <- topicmodels::LDA(x = knbc_dtm, k = 4, method = \"Gibbs\")\n\n# \u5358\u8a9e\u306e\u751f\u6210\u78ba\u7387\u304c\u4e00\u756a\u9ad8\u3044\u30c8\u30d4\u30c3\u30af\ntopic_term <- tidytext::tidy(knbc_dtm_lda, matrix = \"beta\") %>%\n  dplyr::group_by(term) %>%\n  dplyr::top_n(n = 1, wt = beta) %>%\n  dplyr::arrange(topic) %>% \n  ungroup()\n\n# \u5404\u30c8\u30d4\u30c3\u30af\u6bce\u306b\u751f\u6210\u78ba\u7387\u304c\u9ad8\u3044\u4e0a\u4f4d10\u5358\u8a9e\u3092\u8868\u793a\n> topic_term %>% \n  dplyr::group_by(topic) %>%\n  dplyr::top_n(n = 10, wt = beta) %>%\n  as.data.frame()\n   topic     term        beta\n1      1       \u4e00 0.014223022\n2      1       \u4eba 0.035533876\n3      1       \u5e74 0.006961546\n4      1       \u3055 0.010592284\n5      1     \u89b3\u5149 0.024799520\n6      1     \u4eac\u90fd 0.045636800\n7      1     \u6642\u9593 0.011539433\n8      1       \u5bfa 0.009645135\n9      1     \u795e\u793e 0.009171560\n10     1     \u6e05\u6c34 0.007592978\n11     2     \u6a5f\u80fd 0.009552115\n12     2     \u643a\u5e2f 0.050398932\n13     2       \u4eca 0.010823612\n14     2     \u81ea\u5206 0.009869990\n15     2       \u7684 0.009711052\n16     2     \u96fb\u8a71 0.035617788\n17     2     \u3044\u3044 0.010982549\n18     2       \u6c17 0.008916367\n19     2     \u3068\u304d 0.011777234\n20     2   \u30e1\u30fc\u30eb 0.022743889\n21     3     \u305d\u308c 0.011788188\n22     3     \u306a\u3044 0.017929646\n23     3       \u4f55 0.010252823\n24     3       \u524d 0.011105804\n25     3       \u4e2d 0.010082227\n26     3       \u3063 0.015029513\n27     3       \u3093 0.025435873\n28     3     \u597d\u304d 0.013494149\n29     3     \u3057\u304f 0.009741035\n30     3     \u5927\u5b66 0.010082227\n31     4       \u5186 0.013884887\n32     4       \u65b9 0.006861403\n33     4       \u304f 0.010283100\n34     4       \u4eac 0.009202564\n35     4       \u65e5 0.011543726\n36     4     \u3055\u3093 0.007581761\n37     4 \u304a\u3044\u3057\u3044 0.007941939\n38     4       \u5e97 0.014425155\n39     4     \u6599\u7406 0.011363636\n40     4       \u5473 0.007581761\n\n# \u5404\u30c8\u30d4\u30c3\u30af\u6bce\u306b\u751f\u6210\u78ba\u7387\u304c\u9ad8\u3044\u5358\u8a9e\u3092\u53ef\u8996\u5316\nggplot2::ggplot(\n  tidytext::tidy(knbc_dtm_lda) %>%\n    dplyr::filter(beta > 0.010) %>%\n    dplyr::mutate(term = reorder(term, beta)),\n  ggplot2::aes(term, beta)\n) + ggplot2::geom_bar(stat = \"identity\") + ggplot2::facet_wrap(~ topic, scales = \"free\") +\n  ggplot2::theme(axis.text.x = ggplot2::element_text(angle = 90, size = 15)) + \n  # Mac\u3067\u306e\u65e5\u672c\u8a9e\u6587\u5b57\u5217\u8868\u793a\u7528\n  ggplot2::theme_bw(base_family = \"HiraKakuProN-W3\")\n\n\n\n# \u5404\u30c6\u30ad\u30b9\u30c8\u3067\u3072\u3068\u3064\u306e\u30c8\u30d4\u30c3\u30af\u3092\u9078\u3076\n> dplyr::left_join(\n  x = tidytext::tidy(knbc_dtm_lda, matrix = \"gamma\") %>%\n    dplyr::group_by(document) %>%\n    dplyr::arrange(gamma) %>% \n    dplyr::top_n(n = 1, wt = gamma) %>%\n    ungroup() %>% \n    dplyr::mutate(document = as.integer(x = document)) %>% \n    dplyr::select(-gamma),\n  y = knbc_domain,\n  by = c(\"document\" = \"did\")\n) %>% \n  dplyr::select(topic, domain) %>% \n  table %>% \n  print\n     domain\ntopic Gourmet Keitai Kyoto Sports\n    1       3      1    72      1\n    2       0     70     1      1\n    3       8      7     9     20\n    4      48      1    13      0\n\n\n# tidytext::augment\u3067\u3082\u540c\u3058\u7d50\u679c\u306b\u306a\u308b\u3068\u601d\u3063\u305f\u304c\u3001\u5fae\u5999\u306b\u7570\u306a\u308b\uff08\u8981\u78ba\u8a8d\uff09\ndplyr::left_join(\n  x = tidytext::augment(x = knbc_dtm_lda) %>% \n    dplyr::mutate(document = as.integer(x = .$document)) %>% \n    dplyr::group_by(document, .topic) %>%\n    dplyr::summarize(cnt = n()) %>% \n    dplyr::arrange(document, cnt) %>% \n    dplyr::top_n(n = 1, wt = cnt) %>%\n    dplyr::select(document, .topic),\n  y = knbc_domain,\n  by = c(\"document\" = \"did\")\n) %>% \n  dplyr::ungroup() %>% \n  dplyr::select(.topic, domain) %>% \n  table\n      domain\n.topic Gourmet Keitai Kyoto Sports\n     1       4      1    66      1\n     2       0     70     3      2\n     3       8      7    12     20\n     4      45      1    14      0\n\n\n# {LDAvis}\u3067\u53ef\u8996\u5316\nlda_posterior <- topicmodels::posterior(object = knbc_dtm_lda)\nmost_probable_topic_word <- knbc_dtm_lda @ wordassignments\nlda_json <- LDAvis::createJSON(\n  phi = lda_posterior$terms, \n  theta = lda_posterior$topics,\n  vocab = colnames(x = lda_posterior$terms),\n  doc.length = slam::row_sums(x = most_probable_topic_word, na.rm = TRUE),\n  term.frequency = slam::col_sums(x = most_probable_topic_word, na.rm = TRUE)\n)\nLDAvis::serVis(json = lda_json, out.dir = \"knbc_lda\", open.browser = TRUE)\n\n\uff08\u30c8\u30d4\u30c3\u30af\u6bce\u306e\u30b9\u30af\u30ea\u30fc\u30f3\u30b7\u30e7\u30c3\u30c8\uff09\n\n\n\n\n\u3000\u53ef\u8996\u5316\u7d50\u679c\u3068\u30e2\u30c7\u30eb\u306b\u3088\u308b\u30c8\u30d4\u30c3\u30af\u306e\u5bfe\u5fdc\u304c\u53d6\u308c\u3066\u3044\u306a\u3044\u3088\u3046\u306b\u898b\u3048\u308b\u306e\u3067\uff08\u30e2\u30c7\u30eb\u306b\u3088\u308b\u7d50\u679c\u306f\u300c\u4eac\u90fd\u3001\u643a\u5e2f\u3001\u30b9\u30dd\u30fc\u30c4\u3001\u30b0\u30eb\u30e1\u300d\u306e\u9806\u306e\u3088\u3046\u3060\u304c\u3001\u53ef\u8996\u5316\u7d50\u679c\u306f\u300c\u30b0\u30eb\u30e1\u3001\u30b9\u30dd\u30fc\u30c4\u3001\u643a\u5e2f\u3001\u4eac\u90fd\u300d\u306b\u898b\u3048\u308b\uff09\u3001\u8981\u78ba\u8a8d\u3002\n\nGloVe\n\u3000{Matrix}\u30af\u30e9\u30b9\u306e\u30aa\u30d6\u30b8\u30a7\u30af\u30c8\u306b\u5909\u63db\u3057\u3066\u304b\u3089{text2vec}\u3092\u5b9f\u884c\uff08\u76f4\u63a5\u3060\u3068\u30a8\u30e9\u30fc\u304c\u51fa\u308b\uff09\u3002\u4f5c\u6210\u3055\u308c\u305f\u30d9\u30af\u30c8\u30eb\u3092\u7528\u3044\u3066\u30a2\u30ca\u30ed\u30b8\u30fc\uff08\u985e\u63a8\uff09\u3092\u8a66\u3059\u3002\n\nglove\n# no method or default for coercing \u201cDocumentTermMatrix\u201d to \u201cdgCMatrix\u201d\n# knbc_tcm <- textmineR::Dtm2Tcm(dtm = as(object = knbc_dtm, Class = \"dgCMatrix\"))\nknbc_tcm <- textmineR::Dtm2Tcm(dtm = as(object = knbc_dtm, Class = \"Matrix\"))\nknbc_glove_fit <- text2vec::glove(\n  tcm = knbc_tcm, word_vectors_size = 50,\n  num_iters = 50, x_max = 10, convergence_threshold = 0.005, \n  verbose = FALSE\n)\nword_vectors <- knbc_glove_fit$word_vectors[[1]] + knbc_glove_fit$word_vectors[[2]]\nrownames(x = word_vectors) <- rownames(x = knbc_tcm)\nword_vectors_norm <- sqrt(x = rowSums(x = word_vectors ^ 2))\n\n# \u30a2\u30ca\u30ed\u30b8\u30fc\nquery <- word_vectors[\"\u30e9\u30fc\u30e1\u30f3\", , drop = FALSE] + word_vectors[\"\u9903\u5b50\", , drop = FALSE]\n\ncos_dist <- text2vec:::cosine(\n  m_query = query, m_source = word_vectors, m_source_norm = word_vectors_norm\n)\n> head(sort(x = cos_dist[1, ], decreasing = TRUE), n = 10)\n      \u9903\u5b50   \u30e9\u30fc\u30e1\u30f3       \u76f4\u4f1d         \u5177         \u6bcd       \u4e5d\u5dde         \u68d2 \u30a4\u30f3\u30d1\u30af\u30c8     \u6211\u304c\u5bb6 \n 0.7830368  0.6812339  0.6218219  0.5890876  0.5718114  0.5650479  0.5609208  0.5578002  0.5537876 \n  \u3057\u3087\u3046\u3086 \n 0.5481026\n\n\n\u3000\u4f7f\u7528\u3057\u305f\u30b3\u30fc\u30d1\u30b9\u91cf\u3082\u591a\u304f\u306a\u3044\u306e\u3067\u3001\u3042\u307e\u308a\u3044\u3044\u7d50\u679c\u306b\u306f\u306a\u3063\u3066\u3044\u306a\u3044\u3002Wikipedia\u30b3\u30fc\u30d1\u30b9\u306a\u3069\u3067\u771f\u9762\u76ee\u306b\u8a66\u3057\u305f\u3044\u3002\n\n\n\u307e\u3068\u3081\n\u3000KNBC\u30b3\u30fc\u30d1\u30b9\u3092\u5bfe\u8c61\u306b\u3001\u30e2\u30c0\u30f3\u306aR\u306e\u66f8\u304d\u65b9\u3067\u30c6\u30ad\u30b9\u30c8\u89e3\u6790\u3092\u884c\u3044\u307e\u3057\u305f\u3002\u65e2\u5b58\u306e\u30d1\u30c3\u30b1\u30fc\u30b8\u3092\u7d44\u307f\u5408\u308f\u305b\u308b\u3053\u3068\u3067\u3001\u30c6\u30ad\u30b9\u30c8\u51e6\u7406\u304b\u3089TF-IDF\u3084\u5171\u8d77\u983b\u5ea6\uff08\u30cd\u30c3\u30c8\u30ef\u30fc\u30af\u4f5c\u6210\uff09\u3001LDA\u3084GloVe\u307e\u3067\u3092\u624b\u8efd\u306b\u5b9f\u884c\u3067\u304d\u307e\u3057\u305f\u304c\u3001\u30b9\u30c8\u30c3\u30d7\u30ef\u30fc\u30c9\u306e\u8ffd\u52a0\u3084\u5f62\u614b\u7d20\u89e3\u6790\u8f9e\u66f8\u306e\u5909\u66f4\u3001\u30b3\u30fc\u30d1\u30b9\u5897\u5f37\u306a\u3069\u3001\u3082\u3046\u5c11\u3057\u8a00\u8a9e\u51e6\u7406\u7684\u306a\u5de5\u592b\u304c\u5fc5\u8981\u3067\u3059\u3002\u3053\u306e\u3042\u305f\u308a\u306f\u307e\u3060\u307e\u3060\u8ab2\u984c\u3068\u8a00\u3048\u307e\u3059\u3002\n\u3000\u3057\u304b\u3057\u306a\u304c\u3089\u3001R\u3067\u306e\u30c6\u30ad\u30b9\u30c8\u51e6\u7406\u3082\u3057\u3084\u3059\u3044\u74b0\u5883\u306b\u306a\u3063\u3066\u304d\u3066\u3044\u308b\u3068\u601d\u3044\u307e\u3059\u306e\u3067\u3001\u8208\u5473\u3092\u3082\u3063\u305f\u65b9\u306f\u305c\u3072\u6311\u6226\u3057\u3066\u3044\u305f\u3060\u304d\u305f\u3044\u3067\u3059\u3002\n\u3000GloVe\u306e\u5b9f\u884c\u3067\u4eca\u56de\u7528\u3044\u305f{text2vec}\u306f\u4ee5\u524d\u306bword2vec\u306e\u5b9f\u884c\u3067\u4f7f\u7528\u3057\u305f{wordVectors}\u3088\u308a\u3082\u5b9f\u88c5\u304c\u826f\u3055\u3052\u3067\uff08\u65e5\u672c\u8a9e\u30c6\u30ad\u30b9\u30c8\u306b\u3082\u5bfe\u5fdc\u3057\u3066\u3044\u308b\uff09\u3001\u5927\u898f\u6a21\u306a\u30c6\u30ad\u30b9\u30c8\u51e6\u7406\u306b\u3082\u6d3b\u7528\u3067\u304d\u305d\u3046\u306a\u306e\u3067\u500b\u4eba\u7684\u306b\u306f\u3053\u3061\u3089\u3092\u4f7f\u3063\u3066\u3044\u304d\u305f\u3044\u3067\u3059\u3002\n\n\u53c2\u8003\n\nR\u3067\u59cb\u3081\u308b\u6587\u5b57\u5217\u51e6\u7406\n{stringr}/{stringi}\u3068base\u306e\u6587\u5b57\u5217\u51e6\u7406\u306b\u3064\u3044\u3066\nIntroduction to tidytext\nWiden, process, and re-tidy a dataset\n\u30c8\u30d4\u30c3\u30af\u30e2\u30c7\u30eb\u3053\u3068\u306f\u3058\u3081\nA topic model for movie reviews\n[\u7ffb\u8a33] text2vec vignette: text2vec\u30d1\u30c3\u30b1\u30fc\u30b8\u306b\u3088\u308b\u30c6\u30ad\u30b9\u30c8\u5206\u6790\n\n\n\u5b9f\u884c\u74b0\u5883\n\n\u5b9f\u884c\u74b0\u5883\n> devtools::session_info()\nSession info ----------------------------------------------------------------------------------------\n setting  value                       \n version  R version 3.3.1 (2016-06-21)\n system   x86_64, darwin13.4.0        \n ui       RStudio (0.99.903)          \n language (EN)                        \n collate  ja_JP.UTF-8                 \n tz       Asia/Tokyo                  \n date     2016-09-12                  \n\nPackages --------------------------------------------------------------------------------------------\n package      * version    date       source                            \n assertthat     0.1        2013-12-06 CRAN (R 3.3.1)                    \n broom          0.4.1      2016-06-24 CRAN (R 3.3.0)                    \n chron          2.3-47     2015-06-24 CRAN (R 3.3.1)                    \n chunked      * 0.3        2016-06-24 CRAN (R 3.3.0)                    \n codetools      0.2-14     2015-07-15 CRAN (R 3.3.1)                    \n colorspace     1.2-6      2015-03-11 CRAN (R 3.3.1)                    \n data.table     1.9.6      2015-09-19 CRAN (R 3.3.1)                    \n DBI            0.5        2016-08-11 cran (@0.5)                       \n devtools       1.12.0     2016-06-24 CRAN (R 3.3.0)                    \n digest         0.6.9      2016-01-08 CRAN (R 3.3.0)                    \n dplyr        * 0.5.0      2016-06-24 CRAN (R 3.3.1)                    \n foreach        1.4.3      2015-10-13 CRAN (R 3.3.1)                    \n ggplot2      * 2.1.0      2016-03-01 CRAN (R 3.3.1)                    \n gtable         0.2.0      2016-02-26 CRAN (R 3.3.1)                    \n htmltools      0.3.5      2016-03-21 CRAN (R 3.3.1)                    \n htmlwidgets    0.6        2016-02-25 CRAN (R 3.3.1)                    \n iterators      1.0.8      2015-10-13 CRAN (R 3.3.1)                    \n janeaustenr    0.1.1      2016-06-20 CRAN (R 3.3.0)                    \n jsonlite       1.0        2016-07-01 CRAN (R 3.3.0)                    \n lattice        0.20-33    2015-07-14 CRAN (R 3.3.1)                    \n LDAvis       * 0.3.2      2015-10-24 CRAN (R 3.3.0)                    \n magrittr       1.5        2014-11-22 CRAN (R 3.3.1)                    \n Matrix       * 1.2-6      2016-05-02 CRAN (R 3.3.1)                    \n memoise        1.0.0      2016-01-29 CRAN (R 3.3.0)                    \n mnormt         1.5-4      2016-03-09 CRAN (R 3.3.0)                    \n modeltools     0.2-21     2013-09-02 CRAN (R 3.3.1)                    \n munsell        0.4.3      2016-02-13 CRAN (R 3.3.1)                    \n nlme           3.1-128    2016-05-10 CRAN (R 3.3.1)                    \n NLP            0.1-9      2016-02-18 CRAN (R 3.3.1)                    \n pacman       * 0.4.1      2016-03-30 CRAN (R 3.3.0)                    \n plyr           1.8.4      2016-06-08 CRAN (R 3.3.1)                    \n psych          1.6.6      2016-06-28 CRAN (R 3.3.0)                    \n purrr        * 0.2.2      2016-06-18 CRAN (R 3.3.1)                    \n R6             2.1.3      2016-08-19 cran (@2.1.3)                     \n Rcpp         * 0.12.7     2016-09-05 cran (@0.12.7)                    \n RcppParallel   4.3.19     2016-05-05 CRAN (R 3.3.1)                    \n RcppProgress   0.2.1      2015-01-09 CRAN (R 3.3.0)                    \n readr        * 1.0.0      2016-08-03 cran (@1.0.0)                     \n reshape2       1.4.1      2014-12-06 CRAN (R 3.3.1)                    \n rsconnect      0.4.3      2016-08-13 Github (rstudio/rsconnect@1665cb8)\n scales         0.4.0      2016-02-26 CRAN (R 3.3.1)                    \n slam           0.1-37     2016-08-05 cran (@0.1-37)                    \n SnowballC      0.5.1      2014-08-09 CRAN (R 3.3.1)                    \n stringi        1.1.1      2016-05-27 CRAN (R 3.3.1)                    \n stringr        1.1.0      2016-08-19 cran (@1.1.0)                     \n text2vec     * 0.3.0      2016-03-31 CRAN (R 3.3.0)                    \n textmineR    * 2.0.2      2016-06-06 CRAN (R 3.3.0)                    \n tibble       * 1.2        2016-08-26 cran (@1.2)                       \n tidyr        * 0.6.0      2016-08-12 cran (@0.6.0)                     \n tidytext     * 0.1.1      2016-06-25 CRAN (R 3.3.0)                    \n tidyverse    * 0.0.0.9000 2016-09-07 Github (hadley/tidyverse@7149f49) \n tm             0.6-2      2015-07-03 CRAN (R 3.3.0)                    \n tokenizers     0.1.2      2016-04-14 CRAN (R 3.3.0)                    \n topicmodels  * 0.2-4      2016-05-23 CRAN (R 3.3.0)                    \n visNetwork   * 1.0.1      2016-06-20 CRAN (R 3.3.0)                    \n widyr        * 0.0.0.9000 2016-09-07 Github (dgrtwo/widyr@46c508a)     \n withr          1.0.2      2016-06-20 CRAN (R 3.3.0)         \n\n\n# \u6982\u8981\n\u3000\u3059\u3050\u306b\u4f7f\u3048\u308bKNBC\u30b3\u30fc\u30d1\u30b9\u3092\u5bfe\u8c61\u306b\u3001\u30e2\u30c0\u30f3\u306aR\u306e\u66f8\u304d\u65b9\u3067\u30c6\u30ad\u30b9\u30c8\u89e3\u6790\u3057\u305f\u3068\u304d\u306e\u30e1\u30e2\u3067\u3059\u3002TF-IDF\u3084\u5171\u8d77\u983b\u5ea6\uff08\u30cd\u30c3\u30c8\u30ef\u30fc\u30af\u4f5c\u6210\uff09\u3001LDA\u3084GloVe\u307e\u3067\u3092\u30d1\u30c3\u30b1\u30fc\u30b8\u3067\u5b9f\u884c\u3057\u307e\u3057\u305f\u3002\n - [\u89e3\u6790\u6e08\u307f\u30d6\u30ed\u30b0\u30b3\u30fc\u30d1\u30b9](http://nlp.ist.i.kyoto-u.ac.jp/kuntt/)\n\n\n# \u5b9a\u7fa9\u30fb\u8a2d\u5b9a\n\u3000\u6700\u521d\u306b\u51e6\u7406\u3067\u5229\u7528\u3059\u308b\u30e9\u30a4\u30d6\u30e9\u30ea\u306e\u8aad\u307f\u8fbc\u307f\u3084\u5b9a\u6570\u30fb\u95a2\u6570\u306e\u5b9a\u7fa9\u3002\n\n```r:\u5b9a\u6570\u5b9a\u7fa9\u90e8\nlibrary(pacman)\nlibrary(widyr)\n\n# \u8aad\u307f\u8fbc\u3080\u30d1\u30c3\u30b1\u30fc\u30b8\nSET_LOAD_PACKAGE <- c(\"tidyverse\", \"Rcpp\", \"chunked\", \"tidytext\", \"visNetwork\", \"textmineR\", \"Matrix\", \"topicmodels\", \"LDAvis\", \"text2vec\")\n\n# \u30b3\u30fc\u30d1\u30b9\u30d5\u30a1\u30a4\u30eb\u306e\u8a2d\u5b9a\nSET_CORPUS_FILE <- list(\n  DOWNLOAD_URL = \"http://nlp.ist.i.kyoto-u.ac.jp/kuntt/KNBC_v1.0_090925.tar.bz2\",\n  DIST_FILE = \"KNBC.tar.bz2\"\n)\nSET_TARGET_DIR <- list(\n  EXTRACT_DIR = \"knbc_corpus\",\n  READ_DIR = \"knbc_corpus/KNBC_v1.0_090925/corpus2/\"\n)\nSET_STAGING_FILE = \"knbc.csv\"\n\n# \u30b9\u30c8\u30c3\u30d7\u30ef\u30fc\u30c9\u8a2d\u5b9a\nSET_STOP_WORD <- c(\"\u3053\u3068\", \"\u3082\u306e\", \"\u79c1\", \"\u3088\u3046\", \"\u3053\u308c\", \"\u306e\")\n```\n\n```r:\u95a2\u6570\u5b9a\u7fa9\u90e8\n# MeCab\u306e{Rcpp}\u30e9\u30c3\u30d1\u30fc\u5b9a\u7fa9\nSys.setenv(\"PKG_LIBS\" = \"-lmecab\")\ncallCppMeCab <- Rcpp::cppFunction(\n  code = 'DataFrame callCppMeCab(SEXP str) {\n  std::string input = Rcpp::as<std::string>(str);\n  std::vector<std::string> surface, feature;\n\n  // MeCab\u30bf\u30ac\u30fc\u3092\u751f\u6210\u3057\u3066\u3001\u5165\u529b\u6587\u306e\u5f62\u614b\u7d20\u89e3\u6790\u7d50\u679c\u3092\u53d7\u3051\u53d6\u308b\n  MeCab::Tagger *tagger = MeCab::createTagger(\"-l 2\");\n  const MeCab::Node* node = tagger->parseToNode(input.c_str());\n  \n  std::vector<std::string> strs;\n  for (; node; node = node->next) {\n    if (node->stat == MECAB_NOR_NODE || node->stat == MECAB_UNK_NODE) {\n      surface.push_back(std::string(node->surface, node->length));\n      feature.push_back(std::string(node->feature));\n    }\n  }  \n  \n  return Rcpp::wrap(\n    Rcpp::DataFrame::create(\n      Rcpp::Named(\"surface\") = surface,\n      Rcpp::Named(\"feature\") = feature\n    )\n  );\n  }',\n  includes = c(\"#include <mecab.h>\")\n)\n\n# \u5f62\u614b\u7d20\u89e3\u6790\u7d50\u679c\u306e\u3046\u3061\u3001\u6307\u5b9a\u3057\u305f\u54c1\u8a5e\u306e\u8868\u5c64\u306e\u307f\u3092\u62bd\u51fa\n# @param text \u5f62\u614b\u7d20\u89e3\u6790\u306b\u304b\u3051\u308b\u5165\u529b\u6587\n# @param extract_pattern \u62bd\u51fa\u3059\u308b\u30d1\u30bf\u30fc\u30f3\uff08\u6b63\u898f\u8868\u73fe\uff09\nextractContent <- function (text, extract_pattern) {\n  ex_surface <- callCppMeCab(str = text) %>% \n    tidyr::separate(\n      col = feature, \n      into = c(\"pos\", \"pos1\", \"pos2\", \"pos3\", \"ctype\", \"cform\", \"baseform\", \"orth\", \"pron\"),\n      sep = \",\", fill = \"right\"\n    ) %>% \n    dplyr::filter(stringr::str_detect(string = .$pos, pattern = extract_pattern)) %>% \n    dplyr::mutate_if(.tbl = ., .predicate = is.factor, .funs = as.character) %>% \n    dplyr::select(surface)\n  \n  if (nrow(x = ex_surface) < 1) {\n    return(\"\")\n  }\n  \n  return (\n    dplyr::summarize(ex_surface, sentence = stringr::str_c(surface, collapse = \"\\t\")) %>% \n      .$sentence\n  )\n}\n```\n\n# \u6e96\u5099\n\u3000\u5fc5\u8981\u306a\u30c7\u30fc\u30bf\u306e\u53d6\u5f97\u3068\u6574\u5f62\u3092\u884c\u3044\u3001\u30c6\u30ad\u30b9\u30c8\u306e\u7d71\u8a08\u5024\u3092\u53ef\u8996\u5316\u3002\n\n```r:\u30b3\u30fc\u30d1\u30b9\u306e\u6574\u5f62\n# \u4eca\u56de\u4f7f\u7528\u3059\u308b\u30d1\u30c3\u30b1\u30fc\u30b8\u3092\u8aad\u307f\u8fbc\u307f\npacman::p_load(char = SET_LOAD_PACKAGE, install = FALSE, character.only = TRUE)\n\n# \u30b3\u30fc\u30d1\u30b9\u6e96\u5099\ndownload.file(url = SET_CORPUS_FILE$DOWNLOAD_URL, destfile = SET_CORPUS_FILE$DIST_FILE)\nuntar(\n  tarfile = SET_CORPUS_FILE$DIST_FILE, exdir = SET_TARGET_DIR$EXTRACT_DIR,\n  list = FALSE, compressed = \"bzip2\"\n)\n\n# document_id, sentence_id, text\u306e\u5f62\u306b\u5909\u63db\nknbc_raw <- dplyr::bind_rows(\n  lapply(\n    X = list.files(path = SET_TARGET_DIR$READ_DIR, pattern = \".tsv$\", full.names = TRUE),\n    FUN = readr::read_tsv,\n    locale = locale(encoding = \"EUC-JP\"),\n    col_types = \"cc----\", col_names = c(\"id\", \"text\")\n  )\n) %>%  \n  tidyr::separate(col = id, into = c(\"gid\", \"domain\", \"did\", \"dummy\", \"sid_1\", \"sid_2\"), sep = \"_|-\") %>% \n  # \u30bf\u30a4\u30c8\u30eb\u9664\u53bb\n  dplyr::filter(.$sid_1 != 1) %>% \n  tidyr::unite_(col = \"gids\", from = c(\"gid\", \"did\", \"domain\"), sep = \"-\") %>% \n  dplyr::mutate(did = as.integer(x = as.factor(x = gids))) %>% \n  dplyr::group_by(gids) %>% \n  dplyr::mutate(sid = dplyr::row_number(x = gids)) %>% \n  dplyr::ungroup() %>% \n  dplyr::select(gids, did, sid, text) %>% \n  dplyr::arrange(did, sid)\n\n# \u30c6\u30ad\u30b9\u30c8\u6bce\u306e\u30c9\u30e1\u30a4\u30f3\nknbc_domain <- knbc_raw %>% \n  dplyr::select(gids, did) %>% \n  tidyr::separate(col = gids, into = c(\"id\", \"v\", \"domain\"), sep = \"-\") %>% \n  dplyr::group_by(domain, did) %>% \n  dplyr::summarize(scount = n()) %>% \n  dplyr::select(did, domain) %>% \n  dplyr::arrange(did)\n\n# \u30c6\u30ad\u30b9\u30c8\u306e\u30c9\u30e1\u30a4\u30f3\u983b\u5ea6\n> table(knbc_domain$domain)\n\nGourmet  Keitai   Kyoto  Sports \n     57      79      91      22 \n\n# \u884c\u6570\n> nrow(x = knbc_raw)\n[1] 3934\n\n# \u6587\u66f8\u6570\n> max(knbc_raw$did)\n[1] 249\n\n# \u6587\u66f8\u6bce\u306e\u6587\u6570\nknbc_raw %>% \n  dplyr::group_by(did) %>% \n  dplyr::summarize(sent_count = max(sid)) %>% \n  ggplot2::ggplot(data =., ggplot2::aes(x = sent_count)) + ggplot2::geom_histogram()\n\n# \u3072\u3068\u3064\u306e\u6587\u306e\u9577\u3055\nknbc_raw %>% \n  dplyr::mutate(sent_len = stringr::str_length(string = .$text)) %>% \n  ggplot2::ggplot(data =., ggplot2::aes(x = sent_len)) + ggplot2::geom_histogram()\n```\n\n![document_sentence.png](https://qiita-image-store.s3.amazonaws.com/0/99957/217e5a18-eb7f-dbd3-f889-d6bc09c99ddd.png)\n\n![sentence_length.png](https://qiita-image-store.s3.amazonaws.com/0/99957/f24f1fed-58b3-4e7b-354d-95792bf98bee.png)\n\n\n```r:\u30d5\u30a1\u30a4\u30eb\u306b\u30d0\u30c3\u30af\u30a2\u30c3\u30d7\n# \u5404\u6587\u304b\u3089\u540d\u8a5e\u3068\u5f62\u5bb9\u8a5e\u3092\u62bd\u51fa\u3057\u3066\u3001\u30d5\u30a1\u30a4\u30eb\u306b\u66f8\u304d\u51fa\u3057\nknbc_raw %>% \n  dplyr::select(-gids) %>% \n  dplyr::rowwise(data = .) %>% \n  dplyr::mutate(text = extractContent(text = text, extract_pattern = \"\u540d\u8a5e|\u5f62\u5bb9\u8a5e\")) %>%\n  readr::write_csv(path = SET_STAGING_FILE)\n```\n\n---\n\n# \u5bc4\u308a\u9053\n\u3000\u30b3\u30fc\u30d1\u30b9\u30d5\u30a1\u30a4\u30eb\u306e\u8aad\u307f\u8fbc\u307f\u306b{chunked}\u3092\u8a66\u3057\u305f\u304b\u3063\u305f\u304c\uff08\u5927\u898f\u6a21\u30c6\u30ad\u30b9\u30c8\u30c7\u30fc\u30bf\u3092\u4e00\u90e8\u5206\u305a\u3064\u8aad\u307f\u8fbc\u3093\u3067\u51e6\u7406\u3059\u308b\u30d1\u30c3\u30b1\u30fc\u30b8\uff09\u3001EUC-JP\u304c\u5bfe\u5fdc\u3067\u304d\u306a\u304b\u3063\u305f\u305f\u3081\u3001\u4e0a\u8a18\u3067\u5404\u6587\u304b\u3089\u540d\u8a5e\u3068\u5f62\u5bb9\u8a5e\u3092\u62bd\u51fa\u3057\u305f\u30d5\u30a1\u30a4\u30eb\u3092\u8aad\u307f\u8fbc\u3080\u5b9f\u9a13\u3002\n- [Chunkwise Text-file Processing for 'dplyr'](https://github.com/edwindj/chunked)\n\n```r:{chunked}\u306e\u5b9f\u9a13\n# \u5358\u8a9e\u983b\u5ea6\u3092\u96c6\u8a08\u306b{chunked}\u3092\u8a66\u3059\nknbc_chunked_corpus <- chunked::read_table_chunkwise(\n  file = SET_STAGING_FILE, sep = \",\", chunk_size = 500,\n  header = TRUE\n)\n\n# while\u6587\u3092\u56de\u3059\u65b9\u6cd5\u3057\u304b\u601d\u3044\u5f53\u305f\u3089\u306a\u304b\u3063\u305f\u306e\u3067\u3001\u3044\u3044\u611f\u3058\u306b\u5bfe\u51e6\u3059\u308b\u65b9\u6cd5\u3092\u8981\u8abf\u67fb\nknbc <- list()\nknbc_chunk <- \"NULL\"\nwhile (!is.null(x = knbc_chunk)) {\n  knbc_chunk <- knbc_chunked_corpus$next_chunk(cmds = NULL)\n  if (!is.null(x = knbc_chunk)) {\n    knbc <- dplyr::bind_rows(\n      knbc, knbc_chunk %>% \n        tidytext::unnest_tokens_(output_col = \"word\", input_col = \"text\") %>% \n        dplyr::count(word, sort = TRUE)\n    )\n  }\n}\n\n> knbc %>% \n  dplyr::group_by(word) %>% \n  dplyr::summarize(n = sum(n)) %>% \n  dplyr::arrange(dplyr::desc(x = n))\n# A tibble: 5,124 \u00d7 2\n    word     n\n   <chr> <int>\n1     \u306e   713\n2   \u3053\u3068   475\n3     \u4eba   321\n4   \u643a\u5e2f   317\n5   \u4eac\u90fd   289\n6     \u79c1   237\n7   \u96fb\u8a71   224\n8   \u3088\u3046   216\n9   \u3082\u306e   198\n10  \u89b3\u5149   158\n```\n\n\u3000\u30c6\u30ad\u30b9\u30c8\u3092\u8aad\u307f\u8fbc\u307f\u66f8\u304d\u51fa\u3059\u307e\u3067\u3092\u4e00\u9023\u306e\u6d41\u308c\u3067\u3084\u308b\u3068\u304d\u306b\u306f\u3044\u3044\u304b\u3082\u308c\u306a\u3044\u304c\u3001`iterators::ireadLines`\u3068\u4f7f\u3044\u5206\u3051\u304c\u3088\u304f\u308f\u304b\u3089\u306a\u3044\u3002\n\n---\n\n# \u5171\u8d77\u30cd\u30c3\u30c8\u30ef\u30fc\u30af\n\u3000{tidytext}\u3068{widyr}\u3067\u63d0\u4f9b\u3055\u308c\u3066\u3044\u308b\u95a2\u6570\u3092\u7d44\u307f\u5408\u308f\u305b\u3066\u5171\u8d77\u983b\u5ea6\u3092\u96c6\u8a08\u3057\u3001{visNetwork}\u3067\u5171\u8d77\u30cd\u30c3\u30c8\u30ef\u30fc\u30af\u3092\u4f5c\u6210\u3002\n\n```r:\nknbc_corpus <- readr::read_csv(\n  file = SET_STAGING_FILE,\n  col_types = list(\n    did = readr::col_integer(), sid = readr::col_integer(), text = readr::col_character()\n  )\n) %>% \n  tidyr::drop_na()\n\n> knbc_corpus %>% \n  dplyr::filter(did == 1 & sid == 1)\n# A tibble: 1 \u00d7 3\n    did   sid                                                 text\n  <int> <int>                                                <chr>\n1     1     1 \u4eca\u3055\u3089\\t\u63a5\u982d\\t\u53e5\\t\u306a\u3044\\t\u4eca\u3055\u3089\\t\u79c1\\t\u30d7\u30ea\u30da\u30a4\u30c9\\t\u643a\u5e2f\n\n# tri-gram\n> knbc_corpus %>% \n  tidytext::unnest_tokens_(output_col = \"ngram\", input_col = \"text\", token = \"ngrams\", n = 3) %>% \n  dplyr::filter(did == 1 & sid == 1)\n# A tibble: 6 \u00d7 3\n    did   sid                ngram\n  <int> <int>                <chr>\n1     1     1       \u4eca\u3055\u3089 \u63a5\u982d \u53e5\n2     1     1         \u63a5\u982d \u53e5 \u306a\u3044\n3     1     1       \u53e5 \u306a\u3044 \u4eca\u3055\u3089\n4     1     1       \u306a\u3044 \u4eca\u3055\u3089 \u79c1\n5     1     1 \u4eca\u3055\u3089 \u79c1 \u30d7\u30ea\u30da\u30a4\u30c9\n6     1     1   \u79c1 \u30d7\u30ea\u30da\u30a4\u30c9 \u643a\u5e2f\n\n# skip-gram\n> knbc_corpus %>% \n  tidytext::unnest_tokens_(output_col = \"ngram\", input_col = \"text\", token = \"skip_ngrams\", n = 3, k = 2) %>% \n  dplyr::filter(did == 1 & sid == 1)\n# A tibble: 12 \u00d7 3\n     did   sid                  ngram\n   <int> <int>                  <chr>\n1      1     1 \u4eca\u3055\u3089 \u306a\u3044 \u30d7\u30ea\u30da\u30a4\u30c9\n2      1     1       \u63a5\u982d \u4eca\u3055\u3089 \u643a\u5e2f\n3      1     1       \u4eca\u3055\u3089 \u53e5 \u4eca\u3055\u3089\n4      1     1           \u63a5\u982d \u306a\u3044 \u79c1\n5      1     1   \u53e5 \u4eca\u3055\u3089 \u30d7\u30ea\u30da\u30a4\u30c9\n6      1     1           \u306a\u3044 \u79c1 \u643a\u5e2f\n7      1     1         \u4eca\u3055\u3089 \u63a5\u982d \u53e5\n8      1     1           \u63a5\u982d \u53e5 \u306a\u3044\n9      1     1         \u53e5 \u306a\u3044 \u4eca\u3055\u3089\n10     1     1         \u306a\u3044 \u4eca\u3055\u3089 \u79c1\n11     1     1   \u4eca\u3055\u3089 \u79c1 \u30d7\u30ea\u30da\u30a4\u30c9\n12     1     1     \u79c1 \u30d7\u30ea\u30da\u30a4\u30c9 \u643a\u5e2f\n\n\n# \u6587\u30ec\u30d9\u30eb\u3067\u306e\u5171\u8d77\u983b\u5ea6\nknbc_co <- knbc_corpus %>% \n  tidytext::unnest_tokens_(output_col = \"word\", input_col = \"text\", token = \"words\") %>% \n  dplyr::anti_join(y = dplyr::data_frame(word = SET_STOP_WORD), by = \"word\") %>% \n  widyr::pairwise_count(item = word, feature = sid, diag = FALSE, upper = FALSE) %>% \n  dplyr::arrange(dplyr::desc(n))\n\n# \u5171\u8d77\u983b\u5ea6\u306e\u983b\u5ea6\n> co_freq <- table(knbc_co$n) %>% \n  print\n\n      1       2       3       4       5       6       7       8       9      10      11      12 \n2547815  425269  150040   69181   37289   22272   14126    9336    6042    4215    2986    2165 \n     13      14      15      16      17      18      19      20      21      22      23      24 \n   1448    1050     780     561     357     266     206     141     112      66      60      36 \n     25      26      27      28      29      30      33 \n     29      18      14       4       5       2       1 \n\n\n# \u5171\u8d77\u30cd\u30c3\u30c8\u30ef\u30fc\u30af\u3092\u53ef\u8996\u5316(\u983b\u5ea6\u306e\u7d2f\u7a4d\u76f8\u5bfe\u5ea6\u6570\uff08\u4e0b\u4f4d30%\uff09\u3092\u5207\u308a\u6368\u3066)\nknbc_co_net <- visNetwork::toVisNetworkData(\n  igraph = igraph::graph.data.frame(\n    d = knbc_co %>% \n      dplyr::filter(n > which.max(x = dplyr::cume_dist(x = co_freq) < 0.70)) %>% \n      dplyr::rename(from = item1, to = item2, value = n)\n  ),\n  idToLabel = TRUE\n)\nvisNetwork::visNetwork(\n  nodes = knbc_co_net$nodes, edges = knbc_co_net$edges,\n  width = 900, height = 1200\n) %>% \n  visNetwork::visOptions(\n    highlightNearest = TRUE, nodesIdSelection = TRUE\n  ) %>% \n  visNetwork::visIgraphLayout(layout = \"layout_nicely\") %>% \n  visNetwork::visPhysics(stabilization = TRUE)\n```\n![co_occurrence_network.png](https://qiita-image-store.s3.amazonaws.com/0/99957/09182ce7-f6a7-1b46-689f-0874e58836fe.png)\n\n[\u30a4\u30f3\u30bf\u30e9\u30af\u30c6\u30a3\u30d6\u306b\u89e6\u308c\u308b\u7d50\u679c\u306f\u3053\u3061\u3089](http://rpubs.com/yamano357/208381)\n\n\n# \u6587\u66f8\u9593\u306e\u8ddd\u96e2\n\u3000{tidytext}\u3068{widyr}\u3067\u63d0\u4f9b\u3055\u308c\u3066\u3044\u308b\u95a2\u6570\u3092\u7d44\u307f\u5408\u308f\u305b\u3066\u3001TF-IDF\u3092\u7d20\u6027\u306b\u30c6\u30ad\u30b9\u30c8\u9593\u306e\u8ddd\u96e2\u3092\u7b97\u51fa\u3002\u3053\u3053\u3067\u306f\u30c9\u30ad\u30e5\u30e1\u30f3\u30c8\u30ec\u30d9\u30eb\u3067\u8ddd\u96e2\u3092\u51fa\u3057\u3066\u3044\u308b\u304c\u3001\u6587\u30ec\u30d9\u30eb\u3067\u8ddd\u96e2\u306e\u7b97\u51fa\u3082\u5f15\u6570\u3092\u5909\u3048\u308b\u3053\u3068\u3067\u53ef\u80fd\u3002\n\n```r:document_distance\n# \u6587\u66f8\u6bce\u306e\u5358\u8a9e\u983b\u5ea6\uff08\u30b9\u30c8\u30c3\u30d7\u30ef\u30fc\u30c9\u9664\u53bb\uff09\nknbc_doc_word_cnt <- knbc_corpus %>% \n  tidytext::unnest_tokens_(output_col = \"word\", input_col = \"text\", token = \"words\") %>% \n  dplyr::anti_join(y = dplyr::data_frame(word = SET_STOP_WORD), by = \"word\") %>% \n  dplyr::group_by(did, word) %>%\n  dplyr::summarize(freq = n()) %>% \n  dplyr::ungroup()\n\n# \u4e0a\u4f4d10\u5358\u8a9e\u3092\u8868\u793a\n> knbc_doc_word_cnt %>% \n  dplyr::arrange(dplyr::desc(x = freq)) %>% \n  dplyr::top_n(n = 10, wt = freq)\n# A tibble: 10 \u00d7 3\n     did   word  freq\n   <int>  <chr> <int>\n1     56   \u795e\u793e    25\n2     69   \u96fb\u8a71    20\n3    200 \u3046\u3069\u3093    20\n4     69   \u643a\u5e2f    19\n5    110   \u96e2\u5bae    18\n6      1   \u643a\u5e2f    16\n7     70     \u5c40    16\n8     70   \u4ea4\u901a    16\n9     70     \u5e02    16\n10   197   \u9903\u5b50    16\n\n# TF-IDF\n> knbc_doc_tfidf <- knbc_doc_word_cnt %>% \n  tidytext::bind_tf_idf_(term_col = \"word\", document_col = \"did\", n_col = \"freq\")\n\n# IDF\u4e0a\u4f4d10\u5358\u8a9e\u3092\u8868\u793a\n> knbc_doc_tfidf %>% \n  dplyr::arrange(dplyr::desc(x = tf_idf)) %>% \n  dplyr::top_n(n = 10, wt = idf)\n# A tibble: 2,962 \u00d7 6\n     did       word  freq         tf      idf    tf_idf\n   <int>      <chr> <int>      <dbl>    <dbl>     <dbl>\n1    231 \u3055\u3064\u307e\u3044\u3082     3 0.10000000 5.517453 0.5517453\n2    141   \u306a\u304e\u306a\u305f     3 0.08823529 5.517453 0.4868341\n3    100     \u771f\u5982\u5802     4 0.08333333 5.517453 0.4597877\n4     97       \u30b1\u30a4     5 0.07692308 5.517453 0.4244195\n5    154     \u30ec\u30bf\u30b9    11 0.07534247 5.517453 0.4156985\n6    172         \u50b7     3 0.07317073 5.517453 0.4037161\n7    215         \u4e5d     5 0.06944444 5.517453 0.3831565\n8     70         \u5c40    16 0.06400000 5.517453 0.3531170\n9    238       \u52d5\u7269     4 0.06349206 5.517453 0.3503145\n10   220       \u5473\u564c     7 0.06194690 5.517453 0.3417891\n# ... with 2,952 more rows\n\n# TF-IDF\u4e0a\u4f4d10\u5358\u8a9e\u3092\u8868\u793a\n> knbc_doc_tfidf %>% \n  dplyr::arrange(dplyr::desc(x = tf_idf)) %>% \n  dplyr::top_n(n = 20, wt = tf_idf)\n# A tibble: 20 \u00d7 6\n     did         word  freq         tf      idf    tf_idf\n   <int>        <chr> <int>      <dbl>    <dbl>     <dbl>\n1    189         \u713c\u8089     5 0.15625000 4.824306 0.7537978\n2    110         \u96e2\u5bae    18 0.14285714 4.824306 0.6891865\n3    238           \u3043    11 0.17460317 3.725693 0.6505179\n4    103         \u5e83\u544a     7 0.14000000 4.418841 0.6186377\n5    232       \u30ab\u30d5\u30a7    12 0.16666667 3.571543 0.5952571\n6    200       \u3046\u3069\u3093    20 0.12820513 4.418841 0.5665180\n7    231   \u3055\u3064\u307e\u3044\u3082     3 0.10000000 5.517453 0.5517453\n8    219 \u30c1\u30e3\u30fc\u30b7\u30e5\u30fc     4 0.10810811 4.824306 0.5215466\n9    132         \u5165\u529b    12 0.13333333 3.908015 0.5210687\n10   218         \u5f01\u5f53     6 0.10714286 4.824306 0.5168899\n11   178         \u5145\u96fb     5 0.12500000 4.131159 0.5163948\n12    44       \u30dc\u30bf\u30f3     4 0.11428571 4.418841 0.5050104\n13   141     \u306a\u304e\u306a\u305f     3 0.08823529 5.517453 0.4868341\n14   220       \u304a\u3067\u3093    11 0.09734513 4.824306 0.4696227\n15   169       \u30d1\u30d5\u30a7     5 0.12500000 3.725693 0.4657117\n16   100       \u771f\u5982\u5802     4 0.08333333 5.517453 0.4597877\n17   197         \u9903\u5b50    16 0.09467456 4.824306 0.4567390\n18   112         \u8fd4\u4fe1     7 0.12727273 3.571543 0.4545600\n19   237           \u3043     6 0.12000000 3.725693 0.4470832\n20    97         \u30b1\u30a4     5 0.07692308 5.517453 0.4244195\n\n\n# \u6587\u66f8\u9593\u306e\u8ddd\u96e2(\u6587\u66f8\u6bce\u306bTF-IDF\u304c\u4e0a\u4f4d\u306e10\u8a9e\u306b\u9650\u5b9a)\nknbc_doc_dist <- knbc_doc_tfidf %>% \n  dplyr::group_by(did) %>% \n  dplyr::top_n(n = 10, wt = tf_idf) %>% \n  dplyr::ungroup() %>% \n  widyr::pairwise_dist(item = did, feature = word, value = tf_idf, method = \"euclidean\", upper = FALSE) %>% \n  dplyr::arrange(distance)\n\n# \u4e00\u756a\u8fd1\u3044\u6587\u66f8\u540c\u58eb\u3067\u5171\u901a\u3057\u3066\u51fa\u73fe\u3059\u308b\u5358\u8a9e\u3092\u8868\u793a\ndplyr::inner_join(\n  x = knbc_doc_tfidf %>% \n    dplyr::filter(did == knbc_doc_dist$item1[1]) %>% \n    dplyr::select(word, did, tf_idf) %>% \n    dplyr::arrange(dplyr::desc(x = tf_idf)),\n  y = knbc_doc_dist %>% \n    dplyr::filter(item1 == knbc_doc_dist$item1[1]) %>% \n    dplyr::top_n(n = 1, wt = -distance) %>%\n    dplyr::select(did = item2) %>% \n    dplyr::left_join(y = knbc_doc_tfidf) %>% \n    dplyr::select(word, did, tf_idf) %>% \n    dplyr::arrange(dplyr::desc(x = tf_idf)),\n  by = c(\"word\")\n) %>% \n  as.data.frame()\nJoining, by = \"did\"\n     word did.x    tf_idf.x did.y    tf_idf.y\n1    \u5352\u696d    52 0.021661008   115 0.018174114\n2    \u3042\u3068    52 0.021160556   115 0.011836149\n3    \u662f\u975e    52 0.020764783   115 0.017422160\n4    \u591a\u3044    52 0.016394187   115 0.009170082\n5      \u3093    52 0.013348896   115 0.005600025\n6      \u6614    52 0.008367429   115 0.014040954\n7      \u524d    52 0.007990222   115 0.006703991\n8    \u4eca\u65e5    52 0.006800579   115 0.011411703\n9      \u7b11    52 0.006352466   115 0.010659748\n10   \u3069\u3053    52 0.005874841   115 0.019716540\n11     \u76ee    52 0.005874841   115 0.009858270\n12     \u5e74    52 0.004666947   115 0.015662731\n13   \u6642\u9593    52 0.004443223   115 0.037279728\n14 \u3068\u3053\u308d    52 0.004389883   115 0.007366438\n15     \u4eba    52 0.003914336   115 0.022989564\n16     \u4e00    52 0.003488270   115 0.011706973\n17   \u3044\u3044    52 0.002894373   115 0.004856899\n18   \u306a\u3044    52 0.002862946   115 0.004804163\n```\n\n\u3000\u62bd\u51fa\u3055\u308c\u305f\u30ef\u30fc\u30c9\u304c\u671b\u307e\u3057\u3044\u3082\u306e\u304c\u5c11\u306a\u305d\u3046\u306a\u306e\u3067\u3001\u30b9\u30c8\u30c3\u30d7\u30ef\u30fc\u30c9\u3092\u3082\u3063\u3068\u5b9a\u7fa9\u3057\u305f\u308a\u3001\u5f62\u614b\u7d20\u89e3\u6790\u306b\u7528\u3044\u308b\u8f9e\u66f8\u3092Neologd\u306b\u5909\u3048\u305f\u65b9\u304c\u9069\u3057\u305f\u7d50\u679c\u306b\u306a\u308a\u305d\u3046\u3002\u307e\u305f\u3001`widyr::pairwise_dist`\u306e\u8ddd\u96e2\u5c3a\u5ea6\u306f`stat::dist`\u3057\u304b\u4f7f\u3048\u306a\u3044\u306e\u3067\u3001`proxy::dist`\u304c\u4f7f\u3048\u308b\u3088\u3046\u306b\u306a\u308b\u3068\u5b09\u3057\u3044\u3002\n\n# Latent Dirichlet Allocation(LDA)\n\u3000\u6587\u66f8\u6bce\u306e\u5358\u8a9e\u983b\u5ea6\u306e\u30aa\u30d6\u30b8\u30a7\u30af\u30c8\u3092{tm}\u306eDTM(Document-Term-Matrix)\u3084TDM(Term-Document-Matrix)\u306b\u5909\u63db\u3057\u3066\u3001`topicmodels::LDA`\u3092\u5b9f\u884c\u3057\u3066\u7d50\u679c\u3092{LDAvis}\u3067\u53ef\u8996\u5316\u3002\n\n```r:cast2tm\n# CAST Document-Term-Matrix\n> knbc_dtm <- knbc_doc_word_cnt %>% \n  tidytext::cast_dtm_(term_col = \"word\", document_col = \"did\", value_col = \"freq\") %>% \n  print\n<<DocumentTermMatrix (documents: 249, terms: 5118)>>\nNon-/sparse entries: 15776/1258606\nSparsity           : 99%\nMaximal term length: 13\nWeighting          : term frequency (tf)\n\n> tidytext::tidy(x = knbc_dtm)\n# A tibble: 15,776 \u00d7 3\n   document     term count\n      <chr>    <chr> <dbl>\n1         1   \uff43\uff4f\uff4d     1\n2         2   \uff43\uff4f\uff4d     1\n3        46   \uff43\uff4f\uff4d     1\n4        69   \uff43\uff4f\uff4d     1\n5         1 \uff48\uff54\uff54\uff50     1\n6         2 \uff48\uff54\uff54\uff50     2\n7        35 \uff48\uff54\uff54\uff50     1\n8        46 \uff48\uff54\uff54\uff50     1\n9        69 \uff48\uff54\uff54\uff50     3\n10       92 \uff48\uff54\uff54\uff50     1\n# ... with 15,766 more rows\n\n\n# CAST Term-Document-Matrix\n> knbc_tdm <- knbc_doc_word_cnt %>% \n  tidytext::cast_tdm_(term_col = \"word\", document_col = \"did\", value_col = \"freq\") %>% \n  print\n<<TermDocumentMatrix (terms: 5118, documents: 249)>>\nNon-/sparse entries: 15776/1258606\nSparsity           : 99%\nMaximal term length: 13\nWeighting          : term frequency (tf)\n\n> tidytext::tidy(x = knbc_tdm)\n# A tibble: 15,776 \u00d7 3\n                   term document count\n                  <chr>    <chr> <dbl>\n1                \uff43\uff4f\uff4d        1     1\n2              \uff48\uff54\uff54\uff50        1     1\n3              \uff4d\uff49\uff58\uff49        1     1\n4  \uff50\uff52\uff45\uff50\uff41\uff49\uff44\uff46\uff41\uff4e        1     1\n5                  \uff53\uff41        1     1\n6      \uff53\uff4f\uff46\uff54\uff42\uff41\uff4e\uff4b        1     1\n7      \uff56\uff4f\uff44\uff41\uff46\uff4f\uff4e\uff45        1     1\n8                \uff57\uff45\uff42        1     1\n9                \uff57\uff57\uff57        1     1\n10               \u3044\u304f\u3064        1     1\n# ... with 15,766 more rows\n```\n\n```r:LDA\n# KNBC\u30b3\u30fc\u30d1\u30b9\u306fGourmet, Keitai, Kyoto, Sports\u306b\u3064\u3044\u3066\u66f8\u304b\u308c\u305f\u30b3\u30fc\u30d1\u30b9\u306a\u306e\u3067\u3001\u30c8\u30d4\u30c3\u30af\u6570\u30924\u306b\u6307\u5b9a\u3057\u3066\u5b9f\u884c\nknbc_dtm_lda <- topicmodels::LDA(x = knbc_dtm, k = 4, method = \"Gibbs\")\n\n# \u5358\u8a9e\u306e\u751f\u6210\u78ba\u7387\u304c\u4e00\u756a\u9ad8\u3044\u30c8\u30d4\u30c3\u30af\ntopic_term <- tidytext::tidy(knbc_dtm_lda, matrix = \"beta\") %>%\n  dplyr::group_by(term) %>%\n  dplyr::top_n(n = 1, wt = beta) %>%\n  dplyr::arrange(topic) %>% \n  ungroup()\n\n# \u5404\u30c8\u30d4\u30c3\u30af\u6bce\u306b\u751f\u6210\u78ba\u7387\u304c\u9ad8\u3044\u4e0a\u4f4d10\u5358\u8a9e\u3092\u8868\u793a\n> topic_term %>% \n  dplyr::group_by(topic) %>%\n  dplyr::top_n(n = 10, wt = beta) %>%\n  as.data.frame()\n   topic     term        beta\n1      1       \u4e00 0.014223022\n2      1       \u4eba 0.035533876\n3      1       \u5e74 0.006961546\n4      1       \u3055 0.010592284\n5      1     \u89b3\u5149 0.024799520\n6      1     \u4eac\u90fd 0.045636800\n7      1     \u6642\u9593 0.011539433\n8      1       \u5bfa 0.009645135\n9      1     \u795e\u793e 0.009171560\n10     1     \u6e05\u6c34 0.007592978\n11     2     \u6a5f\u80fd 0.009552115\n12     2     \u643a\u5e2f 0.050398932\n13     2       \u4eca 0.010823612\n14     2     \u81ea\u5206 0.009869990\n15     2       \u7684 0.009711052\n16     2     \u96fb\u8a71 0.035617788\n17     2     \u3044\u3044 0.010982549\n18     2       \u6c17 0.008916367\n19     2     \u3068\u304d 0.011777234\n20     2   \u30e1\u30fc\u30eb 0.022743889\n21     3     \u305d\u308c 0.011788188\n22     3     \u306a\u3044 0.017929646\n23     3       \u4f55 0.010252823\n24     3       \u524d 0.011105804\n25     3       \u4e2d 0.010082227\n26     3       \u3063 0.015029513\n27     3       \u3093 0.025435873\n28     3     \u597d\u304d 0.013494149\n29     3     \u3057\u304f 0.009741035\n30     3     \u5927\u5b66 0.010082227\n31     4       \u5186 0.013884887\n32     4       \u65b9 0.006861403\n33     4       \u304f 0.010283100\n34     4       \u4eac 0.009202564\n35     4       \u65e5 0.011543726\n36     4     \u3055\u3093 0.007581761\n37     4 \u304a\u3044\u3057\u3044 0.007941939\n38     4       \u5e97 0.014425155\n39     4     \u6599\u7406 0.011363636\n40     4       \u5473 0.007581761\n\n# \u5404\u30c8\u30d4\u30c3\u30af\u6bce\u306b\u751f\u6210\u78ba\u7387\u304c\u9ad8\u3044\u5358\u8a9e\u3092\u53ef\u8996\u5316\nggplot2::ggplot(\n  tidytext::tidy(knbc_dtm_lda) %>%\n    dplyr::filter(beta > 0.010) %>%\n    dplyr::mutate(term = reorder(term, beta)),\n  ggplot2::aes(term, beta)\n) + ggplot2::geom_bar(stat = \"identity\") + ggplot2::facet_wrap(~ topic, scales = \"free\") +\n  ggplot2::theme(axis.text.x = ggplot2::element_text(angle = 90, size = 15)) + \n  # Mac\u3067\u306e\u65e5\u672c\u8a9e\u6587\u5b57\u5217\u8868\u793a\u7528\n  ggplot2::theme_bw(base_family = \"HiraKakuProN-W3\")\n```\n![topic_nth_word.png](https://qiita-image-store.s3.amazonaws.com/0/99957/2e682093-1255-2073-c3f9-451184ad598a.png)\n\n```r\n# \u5404\u30c6\u30ad\u30b9\u30c8\u3067\u3072\u3068\u3064\u306e\u30c8\u30d4\u30c3\u30af\u3092\u9078\u3076\n> dplyr::left_join(\n  x = tidytext::tidy(knbc_dtm_lda, matrix = \"gamma\") %>%\n    dplyr::group_by(document) %>%\n    dplyr::arrange(gamma) %>% \n    dplyr::top_n(n = 1, wt = gamma) %>%\n    ungroup() %>% \n    dplyr::mutate(document = as.integer(x = document)) %>% \n    dplyr::select(-gamma),\n  y = knbc_domain,\n  by = c(\"document\" = \"did\")\n) %>% \n  dplyr::select(topic, domain) %>% \n  table %>% \n  print\n     domain\ntopic Gourmet Keitai Kyoto Sports\n    1       3      1    72      1\n    2       0     70     1      1\n    3       8      7     9     20\n    4      48      1    13      0\n\n\n# tidytext::augment\u3067\u3082\u540c\u3058\u7d50\u679c\u306b\u306a\u308b\u3068\u601d\u3063\u305f\u304c\u3001\u5fae\u5999\u306b\u7570\u306a\u308b\uff08\u8981\u78ba\u8a8d\uff09\ndplyr::left_join(\n  x = tidytext::augment(x = knbc_dtm_lda) %>% \n    dplyr::mutate(document = as.integer(x = .$document)) %>% \n    dplyr::group_by(document, .topic) %>%\n    dplyr::summarize(cnt = n()) %>% \n    dplyr::arrange(document, cnt) %>% \n    dplyr::top_n(n = 1, wt = cnt) %>%\n    dplyr::select(document, .topic),\n  y = knbc_domain,\n  by = c(\"document\" = \"did\")\n) %>% \n  dplyr::ungroup() %>% \n  dplyr::select(.topic, domain) %>% \n  table\n      domain\n.topic Gourmet Keitai Kyoto Sports\n     1       4      1    66      1\n     2       0     70     3      2\n     3       8      7    12     20\n     4      45      1    14      0\n\n\n# {LDAvis}\u3067\u53ef\u8996\u5316\nlda_posterior <- topicmodels::posterior(object = knbc_dtm_lda)\nmost_probable_topic_word <- knbc_dtm_lda @ wordassignments\nlda_json <- LDAvis::createJSON(\n  phi = lda_posterior$terms, \n  theta = lda_posterior$topics,\n  vocab = colnames(x = lda_posterior$terms),\n  doc.length = slam::row_sums(x = most_probable_topic_word, na.rm = TRUE),\n  term.frequency = slam::col_sums(x = most_probable_topic_word, na.rm = TRUE)\n)\nLDAvis::serVis(json = lda_json, out.dir = \"knbc_lda\", open.browser = TRUE)\n```\n\n\uff08\u30c8\u30d4\u30c3\u30af\u6bce\u306e\u30b9\u30af\u30ea\u30fc\u30f3\u30b7\u30e7\u30c3\u30c8\uff09\n\n<img width=\"999\" alt=\"ldavis_topic1.png\" src=\"https://qiita-image-store.s3.amazonaws.com/0/99957/7e770786-9d63-ac01-f0b5-27c001baebe9.png\">\n\n<img width=\"1009\" alt=\"ldavis_topic2.png\" src=\"https://qiita-image-store.s3.amazonaws.com/0/99957/b17afce1-60f1-b841-8260-436784e78c47.png\">\n\n<img width=\"1000\" alt=\"ldavis_topic3.png\" src=\"https://qiita-image-store.s3.amazonaws.com/0/99957/c0d431ee-30cc-152d-ff27-630feadd50cf.png\">\n\n<img width=\"1000\" alt=\"ldavis_topic4.png\" src=\"https://qiita-image-store.s3.amazonaws.com/0/99957/8d028f3b-adce-c272-fa93-8edbc576bf7f.png\">\n\n\u3000\u53ef\u8996\u5316\u7d50\u679c\u3068\u30e2\u30c7\u30eb\u306b\u3088\u308b\u30c8\u30d4\u30c3\u30af\u306e\u5bfe\u5fdc\u304c\u53d6\u308c\u3066\u3044\u306a\u3044\u3088\u3046\u306b\u898b\u3048\u308b\u306e\u3067\uff08\u30e2\u30c7\u30eb\u306b\u3088\u308b\u7d50\u679c\u306f\u300c\u4eac\u90fd\u3001\u643a\u5e2f\u3001\u30b9\u30dd\u30fc\u30c4\u3001\u30b0\u30eb\u30e1\u300d\u306e\u9806\u306e\u3088\u3046\u3060\u304c\u3001\u53ef\u8996\u5316\u7d50\u679c\u306f\u300c\u30b0\u30eb\u30e1\u3001\u30b9\u30dd\u30fc\u30c4\u3001\u643a\u5e2f\u3001\u4eac\u90fd\u300d\u306b\u898b\u3048\u308b\uff09\u3001\u8981\u78ba\u8a8d\u3002\n\n\n# GloVe\n\u3000{Matrix}\u30af\u30e9\u30b9\u306e\u30aa\u30d6\u30b8\u30a7\u30af\u30c8\u306b\u5909\u63db\u3057\u3066\u304b\u3089{text2vec}\u3092\u5b9f\u884c\uff08\u76f4\u63a5\u3060\u3068\u30a8\u30e9\u30fc\u304c\u51fa\u308b\uff09\u3002\u4f5c\u6210\u3055\u308c\u305f\u30d9\u30af\u30c8\u30eb\u3092\u7528\u3044\u3066\u30a2\u30ca\u30ed\u30b8\u30fc\uff08\u985e\u63a8\uff09\u3092\u8a66\u3059\u3002\n\n```r:glove\n# no method or default for coercing \u201cDocumentTermMatrix\u201d to \u201cdgCMatrix\u201d\n# knbc_tcm <- textmineR::Dtm2Tcm(dtm = as(object = knbc_dtm, Class = \"dgCMatrix\"))\nknbc_tcm <- textmineR::Dtm2Tcm(dtm = as(object = knbc_dtm, Class = \"Matrix\"))\nknbc_glove_fit <- text2vec::glove(\n  tcm = knbc_tcm, word_vectors_size = 50,\n  num_iters = 50, x_max = 10, convergence_threshold = 0.005, \n  verbose = FALSE\n)\nword_vectors <- knbc_glove_fit$word_vectors[[1]] + knbc_glove_fit$word_vectors[[2]]\nrownames(x = word_vectors) <- rownames(x = knbc_tcm)\nword_vectors_norm <- sqrt(x = rowSums(x = word_vectors ^ 2))\n\n# \u30a2\u30ca\u30ed\u30b8\u30fc\nquery <- word_vectors[\"\u30e9\u30fc\u30e1\u30f3\", , drop = FALSE] + word_vectors[\"\u9903\u5b50\", , drop = FALSE]\n\ncos_dist <- text2vec:::cosine(\n  m_query = query, m_source = word_vectors, m_source_norm = word_vectors_norm\n)\n> head(sort(x = cos_dist[1, ], decreasing = TRUE), n = 10)\n      \u9903\u5b50   \u30e9\u30fc\u30e1\u30f3       \u76f4\u4f1d         \u5177         \u6bcd       \u4e5d\u5dde         \u68d2 \u30a4\u30f3\u30d1\u30af\u30c8     \u6211\u304c\u5bb6 \n 0.7830368  0.6812339  0.6218219  0.5890876  0.5718114  0.5650479  0.5609208  0.5578002  0.5537876 \n  \u3057\u3087\u3046\u3086 \n 0.5481026\n```\n\n\u3000\u4f7f\u7528\u3057\u305f\u30b3\u30fc\u30d1\u30b9\u91cf\u3082\u591a\u304f\u306a\u3044\u306e\u3067\u3001\u3042\u307e\u308a\u3044\u3044\u7d50\u679c\u306b\u306f\u306a\u3063\u3066\u3044\u306a\u3044\u3002Wikipedia\u30b3\u30fc\u30d1\u30b9\u306a\u3069\u3067\u771f\u9762\u76ee\u306b\u8a66\u3057\u305f\u3044\u3002\n\n--- \n\n# \u307e\u3068\u3081\n\u3000KNBC\u30b3\u30fc\u30d1\u30b9\u3092\u5bfe\u8c61\u306b\u3001\u30e2\u30c0\u30f3\u306aR\u306e\u66f8\u304d\u65b9\u3067\u30c6\u30ad\u30b9\u30c8\u89e3\u6790\u3092\u884c\u3044\u307e\u3057\u305f\u3002\u65e2\u5b58\u306e\u30d1\u30c3\u30b1\u30fc\u30b8\u3092\u7d44\u307f\u5408\u308f\u305b\u308b\u3053\u3068\u3067\u3001\u30c6\u30ad\u30b9\u30c8\u51e6\u7406\u304b\u3089TF-IDF\u3084\u5171\u8d77\u983b\u5ea6\uff08\u30cd\u30c3\u30c8\u30ef\u30fc\u30af\u4f5c\u6210\uff09\u3001LDA\u3084GloVe\u307e\u3067\u3092\u624b\u8efd\u306b\u5b9f\u884c\u3067\u304d\u307e\u3057\u305f\u304c\u3001\u30b9\u30c8\u30c3\u30d7\u30ef\u30fc\u30c9\u306e\u8ffd\u52a0\u3084\u5f62\u614b\u7d20\u89e3\u6790\u8f9e\u66f8\u306e\u5909\u66f4\u3001\u30b3\u30fc\u30d1\u30b9\u5897\u5f37\u306a\u3069\u3001\u3082\u3046\u5c11\u3057\u8a00\u8a9e\u51e6\u7406\u7684\u306a\u5de5\u592b\u304c\u5fc5\u8981\u3067\u3059\u3002\u3053\u306e\u3042\u305f\u308a\u306f\u307e\u3060\u307e\u3060\u8ab2\u984c\u3068\u8a00\u3048\u307e\u3059\u3002\n\u3000\u3057\u304b\u3057\u306a\u304c\u3089\u3001R\u3067\u306e\u30c6\u30ad\u30b9\u30c8\u51e6\u7406\u3082\u3057\u3084\u3059\u3044\u74b0\u5883\u306b\u306a\u3063\u3066\u304d\u3066\u3044\u308b\u3068\u601d\u3044\u307e\u3059\u306e\u3067\u3001\u8208\u5473\u3092\u3082\u3063\u305f\u65b9\u306f\u305c\u3072\u6311\u6226\u3057\u3066\u3044\u305f\u3060\u304d\u305f\u3044\u3067\u3059\u3002\n\n\u3000GloVe\u306e\u5b9f\u884c\u3067\u4eca\u56de\u7528\u3044\u305f{text2vec}\u306f\u4ee5\u524d\u306bword2vec\u306e\u5b9f\u884c\u3067\u4f7f\u7528\u3057\u305f{wordVectors}\u3088\u308a\u3082\u5b9f\u88c5\u304c\u826f\u3055\u3052\u3067\uff08\u65e5\u672c\u8a9e\u30c6\u30ad\u30b9\u30c8\u306b\u3082\u5bfe\u5fdc\u3057\u3066\u3044\u308b\uff09\u3001\u5927\u898f\u6a21\u306a\u30c6\u30ad\u30b9\u30c8\u51e6\u7406\u306b\u3082\u6d3b\u7528\u3067\u304d\u305d\u3046\u306a\u306e\u3067\u500b\u4eba\u7684\u306b\u306f\u3053\u3061\u3089\u3092\u4f7f\u3063\u3066\u3044\u304d\u305f\u3044\u3067\u3059\u3002\n\n## \u53c2\u8003\n- [R\u3067\u59cb\u3081\u308b\u6587\u5b57\u5217\u51e6\u7406](https://speakerdeck.com/yamano357/tokyor49-stringr-stringi)\n- [{stringr}/{stringi}\u3068base\u306e\u6587\u5b57\u5217\u51e6\u7406\u306b\u3064\u3044\u3066](http://rpubs.com/yamano357/92478)\n- [Introduction to tidytext](https://cran.r-project.org/web/packages/tidytext/vignettes/tidytext.html)\n- [Widen, process, and re-tidy a dataset](https://github.com/dgrtwo/widyr)\n- [\u30c8\u30d4\u30c3\u30af\u30e2\u30c7\u30eb\u3053\u3068\u306f\u3058\u3081](https://speakerdeck.com/yamano357/tokyowebmining46th)\n- [A topic model for movie reviews](http://cpsievert.github.io/LDAvis/reviews/reviews.html)\n- [[\u7ffb\u8a33] text2vec vignette: text2vec\u30d1\u30c3\u30b1\u30fc\u30b8\u306b\u3088\u308b\u30c6\u30ad\u30b9\u30c8\u5206\u6790](http://qiita.com/nakamichi/items/1bf2ee393cb407d9fb74)\n\n## \u5b9f\u884c\u74b0\u5883\n```r:\u5b9f\u884c\u74b0\u5883\n> devtools::session_info()\nSession info ----------------------------------------------------------------------------------------\n setting  value                       \n version  R version 3.3.1 (2016-06-21)\n system   x86_64, darwin13.4.0        \n ui       RStudio (0.99.903)          \n language (EN)                        \n collate  ja_JP.UTF-8                 \n tz       Asia/Tokyo                  \n date     2016-09-12                  \n\nPackages --------------------------------------------------------------------------------------------\n package      * version    date       source                            \n assertthat     0.1        2013-12-06 CRAN (R 3.3.1)                    \n broom          0.4.1      2016-06-24 CRAN (R 3.3.0)                    \n chron          2.3-47     2015-06-24 CRAN (R 3.3.1)                    \n chunked      * 0.3        2016-06-24 CRAN (R 3.3.0)                    \n codetools      0.2-14     2015-07-15 CRAN (R 3.3.1)                    \n colorspace     1.2-6      2015-03-11 CRAN (R 3.3.1)                    \n data.table     1.9.6      2015-09-19 CRAN (R 3.3.1)                    \n DBI            0.5        2016-08-11 cran (@0.5)                       \n devtools       1.12.0     2016-06-24 CRAN (R 3.3.0)                    \n digest         0.6.9      2016-01-08 CRAN (R 3.3.0)                    \n dplyr        * 0.5.0      2016-06-24 CRAN (R 3.3.1)                    \n foreach        1.4.3      2015-10-13 CRAN (R 3.3.1)                    \n ggplot2      * 2.1.0      2016-03-01 CRAN (R 3.3.1)                    \n gtable         0.2.0      2016-02-26 CRAN (R 3.3.1)                    \n htmltools      0.3.5      2016-03-21 CRAN (R 3.3.1)                    \n htmlwidgets    0.6        2016-02-25 CRAN (R 3.3.1)                    \n iterators      1.0.8      2015-10-13 CRAN (R 3.3.1)                    \n janeaustenr    0.1.1      2016-06-20 CRAN (R 3.3.0)                    \n jsonlite       1.0        2016-07-01 CRAN (R 3.3.0)                    \n lattice        0.20-33    2015-07-14 CRAN (R 3.3.1)                    \n LDAvis       * 0.3.2      2015-10-24 CRAN (R 3.3.0)                    \n magrittr       1.5        2014-11-22 CRAN (R 3.3.1)                    \n Matrix       * 1.2-6      2016-05-02 CRAN (R 3.3.1)                    \n memoise        1.0.0      2016-01-29 CRAN (R 3.3.0)                    \n mnormt         1.5-4      2016-03-09 CRAN (R 3.3.0)                    \n modeltools     0.2-21     2013-09-02 CRAN (R 3.3.1)                    \n munsell        0.4.3      2016-02-13 CRAN (R 3.3.1)                    \n nlme           3.1-128    2016-05-10 CRAN (R 3.3.1)                    \n NLP            0.1-9      2016-02-18 CRAN (R 3.3.1)                    \n pacman       * 0.4.1      2016-03-30 CRAN (R 3.3.0)                    \n plyr           1.8.4      2016-06-08 CRAN (R 3.3.1)                    \n psych          1.6.6      2016-06-28 CRAN (R 3.3.0)                    \n purrr        * 0.2.2      2016-06-18 CRAN (R 3.3.1)                    \n R6             2.1.3      2016-08-19 cran (@2.1.3)                     \n Rcpp         * 0.12.7     2016-09-05 cran (@0.12.7)                    \n RcppParallel   4.3.19     2016-05-05 CRAN (R 3.3.1)                    \n RcppProgress   0.2.1      2015-01-09 CRAN (R 3.3.0)                    \n readr        * 1.0.0      2016-08-03 cran (@1.0.0)                     \n reshape2       1.4.1      2014-12-06 CRAN (R 3.3.1)                    \n rsconnect      0.4.3      2016-08-13 Github (rstudio/rsconnect@1665cb8)\n scales         0.4.0      2016-02-26 CRAN (R 3.3.1)                    \n slam           0.1-37     2016-08-05 cran (@0.1-37)                    \n SnowballC      0.5.1      2014-08-09 CRAN (R 3.3.1)                    \n stringi        1.1.1      2016-05-27 CRAN (R 3.3.1)                    \n stringr        1.1.0      2016-08-19 cran (@1.1.0)                     \n text2vec     * 0.3.0      2016-03-31 CRAN (R 3.3.0)                    \n textmineR    * 2.0.2      2016-06-06 CRAN (R 3.3.0)                    \n tibble       * 1.2        2016-08-26 cran (@1.2)                       \n tidyr        * 0.6.0      2016-08-12 cran (@0.6.0)                     \n tidytext     * 0.1.1      2016-06-25 CRAN (R 3.3.0)                    \n tidyverse    * 0.0.0.9000 2016-09-07 Github (hadley/tidyverse@7149f49) \n tm             0.6-2      2015-07-03 CRAN (R 3.3.0)                    \n tokenizers     0.1.2      2016-04-14 CRAN (R 3.3.0)                    \n topicmodels  * 0.2-4      2016-05-23 CRAN (R 3.3.0)                    \n visNetwork   * 1.0.1      2016-06-20 CRAN (R 3.3.0)                    \n widyr        * 0.0.0.9000 2016-09-07 Github (dgrtwo/widyr@46c508a)     \n withr          1.0.2      2016-06-20 CRAN (R 3.3.0)         \n```\n", "tags": ["R", "\u81ea\u7136\u8a00\u8a9e\u51e6\u7406"]}