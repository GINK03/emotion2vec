{"tags": ["processing3", "NyARToolkit", "3DCG", "obj", "AR"], "context": "\n\n\u52d5\u6a5f\n\u9577\u3089\u304f\u3001Processing 1.5.1 \u3068 NyARToolkit \u3067 AR \u3092\u697d\u3057\u3093\u3067\u304d\u307e\u3057\u305f\u3002\n\u5c11\u3057\u81ea\u7531\u306a\u6642\u9593\u304c\u3067\u304d\u305f\u306e\u3067\u2026 \u3055\u3059\u304c\u306b\u3082\u3046\u3001\u6700\u65b0\u306e\u74b0\u5883\u306b\u4e57\u308a\u79fb\u308d\u3046\u3068\u6c7a\u5fc3\u3057\u307e\u3057\u305f\u3002\u6700\u65b0\u306e NyARToolkit \u306f 3.0.2 \u4ee5\u964d\u3001\u5f93\u6765\u306e\u30de\u30fc\u30ab\u306b\u52a0\u3048\u3066\u3001NFT\uff08Natural Feature Tracking; \u81ea\u7136\u7279\u5fb4\u70b9\u8ffd\u8de1\uff09\u3082\u3067\u304d\u308b\u306e\u3067\u3001\u305d\u306e\u3042\u305f\u308a\u3082\u7df4\u7fd2\u3057\u3066\u307f\u307e\u3057\u305f\u3002\n\n\u74b0\u5883\n\nWindows 10\n\nProcessing 3.3\n\nNyARToolkit for Processing 5.0.5\n\n\n\u3084\u3063\u305f\u3053\u3068\n\n\u30d3\u30c7\u30aa\u30ad\u30e3\u30d7\u30c1\u30e3\u306e\u30c6\u30b9\u30c8\n\u6700\u3082\u30b7\u30f3\u30d7\u30eb\u306a AR\nOBJ \u5f62\u5f0f\u306e 3DCG \u30e2\u30c7\u30eb\u3067 AR\n\u30de\u30eb\u30c1 NFT\uff08\u81ea\u7136\u7279\u5fb4\u70b9\u8ffd\u8de1\uff09\u306b\u3088\u308b AR\n\n\n\u30b3\u30fc\u30c9\n\u89e3\u8aac\u306f\u4e3b\u306b\u30b3\u30fc\u30c9\u4e2d\u306e\u30b3\u30e1\u30f3\u30c8\u306e\u307f\u3067\u6050\u7e2e\u3067\u3059\u3002\n\n\u30d3\u30c7\u30aa\u30ad\u30e3\u30d7\u30c1\u30e3\u306e\u30c6\u30b9\u30c8\n\u307e\u305a\u306f\u3001Processing \u6a19\u6e96\u306e video \u30e9\u30a4\u30d6\u30e9\u30ea\u3067\u30d3\u30c7\u30aa\u30ad\u30e3\u30d7\u30c1\u30e3\u306e\u30c6\u30b9\u30c8\u3067\u3059\u3002\nProcessing 3 \u3067\u306f\u3001video \u30e9\u30a4\u30d6\u30e9\u30ea\u306f\u81ea\u5206\u3067\u30a4\u30f3\u30b9\u30c8\u30fc\u30eb\u3059\u308b\u3088\u3046\u3067\u3059\u3002Processing IDE \u306e\u300c\u30e9\u30a4\u30d6\u30e9\u30ea\u306e\u8ffd\u52a0...\u300d\u3067 The Processing Foundation \u306e video \u30e9\u30a4\u30d6\u30e9\u30ea\u3092\u30a4\u30f3\u30b9\u30c8\u30fc\u30eb\u3057\u307e\u3057\u305f\u3002\nProcessing 1.5.1 \u6642\u4ee3\u306b\u6bd4\u3079\u3066\uff08\u7279\u306b Windows \u74b0\u5883\u3067\u306f\uff09\u3068\u3066\u3082\u5bb9\u6613\u306b\u306a\u308a\u307e\u3057\u305f\u3002\n\ncam_test.pde\n// cam_test.pde\n// Install \"video\" library via \"Add Library\" tool of Processing IDE.\n// Connect a Web camera to your PC.\n// Run this sketch once.\n// Find a camera device number with \"size=640x480,fps=30\" from the list.\n// * Rewrite \"x\" with the device number you use.\n// Run this sketch again, and confirm the video is shown.\n// Coded by Mitsuteru Kokubun, 2017/02/20\n\nimport processing.video.*;               // using \"video\" library\n\nCapture cam;                             // declaration of Capture object\n\n// setup() function is executed once\nvoid setup() {\n  size(640, 480);                        // setting size of window\n  String[] cameras = Capture.list();     // getting available camera devices\n  printArray(cameras);                   // listing available camera devices\n  cam = new Capture(this, cameras[12]);  // * Rewrite [x] with the device number you use.\n  cam.start();                           // starting capture\n}\n\n// draw() function is exectuted repeatedly\nvoid draw() {\n  if(cam.available() == false) {         // if camera is not available\n    return;                              // do nothing and return\n  }\n  cam.read();                            // capturing image\n  image(cam, 0, 0);                      // displaying captured image\n}\n\n\n\n\u6700\u3082\u30b7\u30f3\u30d7\u30eb\u306a AR\nNyARToolkit for Processing \u306e GitHub \u30ea\u30dd\u30b8\u30c8\u30ea\u306e\u6307\u793a\u901a\u308a\u306b\u3001nyar4psg \u30e9\u30a4\u30d6\u30e9\u30ea\u3092\u30a4\u30f3\u30b9\u30c8\u30fc\u30eb\u3057\u307e\u3057\u305f\u3002\n\u30ab\u30e1\u30e9\u306e\u30ad\u30e3\u30ea\u30d6\u30ec\u30fc\u30b7\u30e7\u30f3\u30d1\u30e9\u30e1\u30fc\u30bf\u3082\u30c7\u30d5\u30a9\u30eb\u30c8\u306e \"camera_para.dat\" \u3092\u4f7f\u3044\u307e\u3057\u305f\u3002\n\u307e\u305f\u3001NyID \u30de\u30fc\u30ab\u3092\u4f7f\u3063\u3066\u3044\u307e\u3059\uff08\u3053\u3061\u3089\u306e\u30b5\u30a4\u30c8\u3067\u4f5c\u6210\uff09\u3002\n\u5b9f\u8cea20\u884c\u304f\u3089\u3044\u3067\u3067\u304d\u307e\u3057\u305f\u3002\n\n\nar_box.pde\n// ar_box.pde\n// A simple AR demo using NyARToolkit and Proceccing 3.\n// Install \"video\" library via \"Add Library\" tool of Processing IDE.\n// Install \"nyar4psg\" library according to the URL below.\n//   -> https://github.com/nyatla/NyARToolkit-for-Processing/\n// Connect a Web camera to your PC.\n// * Rewrite \"x\" with the camera device number you use.\n// Place \"camera_para.dat\" in \"data\" folder of this sketch.\n//   - \"camera_para.dat\" is included within ./libraries/nyar4psg/data\n// Print NyID markers on paper. (\"NyId_000-005.pdf\")\n// Run this sketch, and check that an orange transparent box is superimposed on the marker.\n// Coded by Mitsuteru Kokubun, 2017/02/20\n\nimport processing.video.*;               // using \"video\" library\nimport jp.nyatla.nyar4psg.*;             // using \"nyar4psg\" library\n\nCapture cam;                             // declaration of Capture object\nMultiMarker mm;                          // declaration of MultiMarker object\n\nvoid setup() {\n  // window and camera settings\n  size(640, 480, P3D);                   // setting size of window with P3D mode\n  String[] cameras = Capture.list();     // getting available camera devices\n  printArray(cameras);                   // listing available camera devices\n  cam = new Capture(this, cameras[12]);  // * Rewrite [x] with the device number you use.\n  cam.start();                           // starting capture\n  // NyARToolkit settings\n  mm = new MultiMarker(this,             // initial settings of NyARToolkit\n             width,                      // width of the input image\n             height,                     // height of the input image\n             \"camera_para.dat\",          // camera calibration parameter file\n             NyAR4PsgConfig.CONFIG_PSG); // configuration for Processing\n  mm.addNyIdMarker(0, 80);               // adding NyId marker(ID, marker_width[mm])\n}\n\nvoid draw() {\n  // video capture\n  if(cam.available() == false) {         // if camera is not available\n    return;                              // do nothing and return\n  }\n  cam.read();                            // capturing image\n  // Start of AR process\n  mm.detect(cam);                        // detecting marker within captured image\n  mm.drawBackground(cam);                // drawing captured image on background\n  if(mm.isExist(0) == false) {           // if marker[0] is not exist within the image\n    return;                              // do nothing and return\n  }\n  mm.beginTransform(0);                  // starting coordinate projection based on marker[0]\n    translate(0, 0, 40);                 // move the origin 40 mm in the Z axis direction\n    fill(255, 165, 0, 127);              // fill color(R, G, B, opacity)\n    box(80);                             // draw a 80 mm square box\n  mm.endTransform();                     // ending coordinate projection\n  // End of AR process\n}\n\n\n\nOBJ \u5f62\u5f0f\u306e 3DCG \u30e2\u30c7\u30eb\u3067 AR\n3DCG \u306e\u30e2\u30c7\u30eb\u3092\u8aad\u3080\u306b\u306f\u3001Processing 1.5.1 \u6642\u4ee3\u306f\u3001saitoobjloader \u3084 MQOLoader \u306a\u3069\u3092\u4f7f\u308f\u305b\u3066\u3044\u305f\u3060\u3044\u3066\u304d\u307e\u3057\u305f\u3002\n\u4eca\u56de\u3001saitoobjloader \u3092\u8a66\u3057\u305f\u3068\u3053\u308d\u3001Processing 3.3 \u3067\u306f\u52d5\u304d\u307e\u305b\u3093\u3067\u3057\u305f\u3002\n\u5c11\u3057\u8abf\u3079\u305f\u3089\u3001Processing \u6a19\u6e96\u306e PShape \u3067 OBJ \u5f62\u5f0f\u306e\u30e2\u30c7\u30eb\u304c\u8aad\u3081\u308b\u3053\u3068\u304c\u5206\u304b\u3063\u305f\u306e\u3067\u3001\u8a66\u3057\u305f\u3089\u3001\u7c21\u5358\u306b\u3067\u304d\u307e\u3057\u305f\u3002\u5b9f\u8cea30\u884c\u304f\u3089\u3044\u3067\u3059\u3002\nOBJ \u5f62\u5f0f\u306e 3DCG \u30e2\u30c7\u30eb\uff08rocket.obj, rocket.mtl, rocket.png\uff09\u306f\u3001Processing \u306e\u30b5\u30f3\u30d7\u30eb\u300cLoadDisplayObj.pde\u300d\u3067\u4f7f\u308f\u308c\u3066\u3044\u308b\u3082\u306e\u3092\u4f7f\u3044\u307e\u3057\u305f\u3002Processing \u672c\u4f53\u306e\u30d5\u30a9\u30eb\u30c0\u5185\u306e\u3001modes\\java\\examples\\Basics\\Shape\\LoadDisplayOBJ\\data \u306e\u4e2d\u306b\u3042\u308a\u307e\u3059\u3002\n\n\nar_obj.pde\n// ar_obj.pde\n// A 3DCG (*.obj) AR demo using NyARToolkit and Proceccing 3.\n// Install \"video\" library via \"Add Library\" tool of the Processing IDE.\n// Install \"nyar4psg\" library according to the URL below.\n// Connect a Web camera to your PC.\n// * Rewrite \"x\" with the camera device number you use.\n// Place \"camera_para.dat\" in \"data\" folder of this sketch.\n//   - \"camera_para.dat\" is included within ./libraries/nyar4psg/data\n// Place \"rocket.obj\", \"rocket.mtl\", and \"rocket.png\" in \"data\" folder of this sketch.\n//   - \"rocket.*\" are included within ./Processing_3.x.x/\n//       modes/java/exmples/Basics/Shape/LoadDisplayOBJ/data\n// Print NyID markers on paper. (\"NyId_000-005.pdf\")\n// Run this sketch, and check that a rocket of 3DCG is superimposed on the marker.\n// Coded by Mitsuteru Kokubun, 2017/02/20\n\nimport processing.video.*;               // using \"video\" library\nimport jp.nyatla.nyar4psg.*;             // using \"nyar4psg\" library\n\nCapture cam;                             // declaration of Capture object\nMultiMarker mm;                          // declaration of MultiMarker object\nPShape obj;                              // declaration of PShape object\nfloat ry;                                // variable for rotation of 3DCG model\n\nvoid setup() {\n  // window and camera settings\n  size(640, 480, P3D);                   // setting size of window with P3D mode\n  String[] cameras = Capture.list();     // getting available camera devices\n  printArray(cameras);                   // listing available camera devices\n  cam = new Capture(this, cameras[12]);  // * Rewrite [x] with the device number you use.\n  cam.start();                           // starting capture\n  // NyARToolkit settings\n  mm = new MultiMarker(this,             // initial settings of NyARToolkit\n             width,                      // width of the input image\n             height,                     // height of the input image\n             \"camera_para.dat\",          // camera calibration parameter file\n             NyAR4PsgConfig.CONFIG_PSG); // configuration for Processing\n  mm.addNyIdMarker(0, 80);               // adding NyId marker(ID, marker_width[mm])\n  // PShape setting\n  obj = loadShape(\"rocket.obj\");         // loading a 3DCG model named \"rocket.obj\"\n}\n\nvoid draw() {\n  // video capture\n  if(cam.available() == false) {         // if camera is not available\n    return;                              // do nothing and return\n  }\n  cam.read();                            // capturing image\n  // Start of AR process\n  mm.detect(cam);                        // detecting marker within captured image\n  mm.drawBackground(cam);                // drawing captured image on background\n  if(mm.isExist(0) == false) {           // if marker[0] is not exist within the image\n    return;                              // do nothing and return\n  }\n  mm.beginTransform(0);                  // starting coordinate projection based on marker[0]\n    lights();                            // adding lights in the 3D scene\n    scale(0.3);                          // adjusting the size of the 3DCG model\n    translate(0, 0, 80);                 // adjusting the position of the 3DCG model\n    rotateX(PI/2);                       // rotating the 3DCG model 90 degrees around the X axis\n    rotateY(ry);                         // rotating the 3DCG model ry radians around the Y axis\n    shape(obj);                          // displaying the 3DCG model\n  mm.endTransform();                     // ending coordinate projection\n  // End of AR process\n  ry += 0.1;                             // changing rotation angle\n}\n\n\n\n\u30de\u30eb\u30c1 NFT\uff08\u81ea\u7136\u7279\u5fb4\u70b9\u8ffd\u8de1\uff09\u306b\u3088\u308b AR\n\u6700\u5f8c\u306b NFT \u3082\u7df4\u7fd2\u3057\u3066\u307f\u307e\u3057\u3057\u305f\u3002\u305b\u3063\u304b\u304f\u306a\u306e\u3067\u3001\u9069\u5f53\u306b\u5199\u771f\u3092\u64ae\u3063\u3066\u305d\u308c\u3092 NFT \u306e\u30bf\u30fc\u30b2\u30c3\u30c8\u306b\u3001\u91cd\u7573\u8868\u793a\u3055\u305b\u308b CG \u30e2\u30c7\u30eb\u3082 Blender \u3092\u4f7f\u3063\u3066\u81ea\u4f5c\u3057\u307e\u3057\u305f\u3002\n\u4ee5\u4e0b\u306f\u30bf\u30fc\u30b2\u30c3\u30c8\u7528\u306b\u64ae\u5f71\u3057\u305f\u5199\u771f\u3067\u3059\u3002\n\nNyARToolkit \u306e\u30b5\u30f3\u30d7\u30eb\u3068\u3057\u3066\u4ed8\u5c5e\u3059\u308b NftFileGenerator \u3092\u4f7f\u3063\u3066\u753b\u50cf\u304b\u3089\u7279\u5fb4\u70b9\u3092\u62bd\u51fa\u3057\u3001\u7279\u5fb4\u70b9\u30d5\u30a1\u30a4\u30eb\uff08*.fset, *.fset3, *.iset \u306e\u4e09\u3064\u306e\u30d5\u30a1\u30a4\u30eb\uff09\u3092\u51fa\u529b\u3057\u307e\u3059\u3002\n\nBlender \u3067\u9069\u5f53\u306b CG \u3092\u4f5c\u308a\u307e\u3057\u305f\u3002\n\n\u5b8c\u6210\u3067\u3059\u3002\n\n\nar_nft.pde\n// ar_nft.pde\n// An NFT(Natural Feature Tracking) AR demo using NyARToolkit and Proceccing 3.\n// Install \"video\" library via \"Add Library\" tool of the Processing IDE.\n// Install \"nyar4psg\" library according to the URL below.\n// Connect a Web camera to your PC.\n// * Rewrite \"x\" with the device number you use.\n// Place \"camera_para.dat\" in \"data\" folder of this sketch.\n//   - \"camera_para.dat\" is included within ./libraries/nyar4psg/data\n// Place \"drop.{obj, mtl}\" and \"time.{obj, mtl}\" in \"data\" folder of this sketch.\n//   - These obj models are made by using some modeling software, e.g. Blender.\n// Place \"faucet.{fset,fset3, iset}\" and \"time.{fset,fset3, iset}\" in \"data\" folder of this sketch.\n// Print \"faucet.jpg\" and \"clock.jpg\" on paper.\n// Run this sketch, and check that the 3DCGs are superimposed on the marker.\n// Coded by Mitsuteru Kokubun, 2017/02/20\n\nimport processing.video.*;               // using \"video\" library\nimport jp.nyatla.nyar4psg.*;             // using \"nyar4psg\" library\n\nCapture cam;                             // declaration of Capture object\nMultiNft nft;                            // declaration of MultiNft object\nPShape[] obj;                            // declaration of PShape array object\n\nvoid setup() {\n  // window and camera settings\n  size(640, 480, P3D);                   // setting size of window with P3D mode\n  String[] cameras = Capture.list();     // getting available camera devices\n  printArray(cameras);                   // listing available camera devices\n  cam = new Capture(this, cameras[0]);   // * Rewrite [x] with the device number you use.\n  cam.start();                           // starting capture\n  // NyARToolkit settings\n  nft = new MultiNft(this,               // initial settings of NyARToolkit\n             width,                      // width of the input image\n             height,                     // height of the input image\n             \"camera_para.dat\",          // camera calibration parameter file\n             NyAR4PsgConfig.CONFIG_PSG); // configuration for Processing\n  nft.addNftTarget(\"faucet\", 160);       // adding NFT target[0] (name, target_width[mm])\n  nft.addNftTarget(\"clock\", 160);        // adding NFT target[1] (name, target_width[mm])\n  // PShape setting\n  obj = new PShape[2];\n  obj[0] = loadShape(\"drop.obj\");        // loading a 3DCG model named \"drop.obj\"\n  obj[1] = loadShape(\"time.obj\");        // loading a 3DCG model named \"time.obj\"\n}\n\nvoid draw() {\n  // video capture\n  if(cam.available() == false) {         // if camera is not available\n    return;                              // do nothing and return\n  }\n  cam.read();                            // capturing image\n  // Start of AR process\n  nft.detect(cam);                       // detecting marker within captured image\n  nft.drawBackground(cam);               // drawing captured image on background\n  for (int i=0; i<2; i++) {              // repeating for two NFT targets\n    if(nft.isExist(i) == false) {        // if target[i] is not exist within the image\n      continue;                          // do nothing and find next target\n    }\n    nft.beginTransform(i);               // starting coordinate projection based on target[i]\n      lights();                          // adding lights in the 3D scene\n      translate(-80, 40, 0);             // adjusting the position of the 3DCG model\n      rotateY(PI);                       // rotating the 3DCG model 180 degrees around the Y axis \n      shape(obj[i]);                     // displaying the 3DCG model\n    nft.endTransform();                  // ending coordinate projection\n  }\n  // End of AR process\n}\n\n\n\n\u6240\u611f\u3068\u4eca\u5f8c\n\u79fb\u884c\u3057\u3066\u5927\u6b63\u89e3\u3067\u3057\u305f\u3002\n\u305f\u3044\u3066\u3044\u306e\u79c1\u306e\u7528\u9014\u306f\u521d\u671f\u306e\u30d7\u30ed\u30c8\u30bf\u30a4\u30d4\u30f3\u30b0\u306e\u305f\u3081\u3001\u901a\u5e38\u306e\u30de\u30fc\u30ab\u30fc\u3092\u4f7f\u3063\u3066\u3044\u3066\u3082\u306a\u3093\u306e\u554f\u984c\u3082\u306a\u3044\u306e\u3067\u3059\u304c\u3001NFT \u306e\u307b\u3046\u304c\u3084\u3063\u3071\u308a\u697d\u3057\u3044\u3067\u3059\u306d\u3002\n\u5f15\u304d\u7d9a\u304d\u3044\u308d\u3044\u308d\u904a\u3093\u3067\u307f\u305f\u3044\u3068\u601d\u3044\u307e\u3059\u3002\n# \u52d5\u6a5f\n\u9577\u3089\u304f\u3001Processing 1.5.1 \u3068 NyARToolkit \u3067 AR \u3092\u697d\u3057\u3093\u3067\u304d\u307e\u3057\u305f\u3002\n\u5c11\u3057\u81ea\u7531\u306a\u6642\u9593\u304c\u3067\u304d\u305f\u306e\u3067\u2026 \u3055\u3059\u304c\u306b\u3082\u3046\u3001\u6700\u65b0\u306e\u74b0\u5883\u306b\u4e57\u308a\u79fb\u308d\u3046\u3068\u6c7a\u5fc3\u3057\u307e\u3057\u305f\u3002\u6700\u65b0\u306e NyARToolkit \u306f 3.0.2 \u4ee5\u964d\u3001\u5f93\u6765\u306e\u30de\u30fc\u30ab\u306b\u52a0\u3048\u3066\u3001NFT\uff08Natural Feature Tracking; \u81ea\u7136\u7279\u5fb4\u70b9\u8ffd\u8de1\uff09\u3082\u3067\u304d\u308b\u306e\u3067\u3001\u305d\u306e\u3042\u305f\u308a\u3082\u7df4\u7fd2\u3057\u3066\u307f\u307e\u3057\u305f\u3002\n\n# \u74b0\u5883\n* Windows 10\n* [Processing](https://processing.org/) 3.3\n* [NyARToolkit for Processing](https://github.com/nyatla/NyARToolkit-for-Processing/) 5.0.5\n\n# \u3084\u3063\u305f\u3053\u3068\n* \u30d3\u30c7\u30aa\u30ad\u30e3\u30d7\u30c1\u30e3\u306e\u30c6\u30b9\u30c8\n* \u6700\u3082\u30b7\u30f3\u30d7\u30eb\u306a AR\n* OBJ \u5f62\u5f0f\u306e 3DCG \u30e2\u30c7\u30eb\u3067 AR\n* \u30de\u30eb\u30c1 NFT\uff08\u81ea\u7136\u7279\u5fb4\u70b9\u8ffd\u8de1\uff09\u306b\u3088\u308b AR\n\n# \u30b3\u30fc\u30c9\n\n\u89e3\u8aac\u306f\u4e3b\u306b\u30b3\u30fc\u30c9\u4e2d\u306e\u30b3\u30e1\u30f3\u30c8\u306e\u307f\u3067\u6050\u7e2e\u3067\u3059\u3002\n\n## \u30d3\u30c7\u30aa\u30ad\u30e3\u30d7\u30c1\u30e3\u306e\u30c6\u30b9\u30c8\n\n\u307e\u305a\u306f\u3001Processing \u6a19\u6e96\u306e video \u30e9\u30a4\u30d6\u30e9\u30ea\u3067\u30d3\u30c7\u30aa\u30ad\u30e3\u30d7\u30c1\u30e3\u306e\u30c6\u30b9\u30c8\u3067\u3059\u3002\nProcessing 3 \u3067\u306f\u3001video \u30e9\u30a4\u30d6\u30e9\u30ea\u306f\u81ea\u5206\u3067\u30a4\u30f3\u30b9\u30c8\u30fc\u30eb\u3059\u308b\u3088\u3046\u3067\u3059\u3002Processing IDE \u306e\u300c\u30e9\u30a4\u30d6\u30e9\u30ea\u306e\u8ffd\u52a0...\u300d\u3067 The Processing Foundation \u306e video \u30e9\u30a4\u30d6\u30e9\u30ea\u3092\u30a4\u30f3\u30b9\u30c8\u30fc\u30eb\u3057\u307e\u3057\u305f\u3002\n\nProcessing 1.5.1 \u6642\u4ee3\u306b\u6bd4\u3079\u3066\uff08\u7279\u306b Windows \u74b0\u5883\u3067\u306f\uff09\u3068\u3066\u3082\u5bb9\u6613\u306b\u306a\u308a\u307e\u3057\u305f\u3002\n\n```java:cam_test.pde\n// cam_test.pde\n// Install \"video\" library via \"Add Library\" tool of Processing IDE.\n// Connect a Web camera to your PC.\n// Run this sketch once.\n// Find a camera device number with \"size=640x480,fps=30\" from the list.\n// * Rewrite \"x\" with the device number you use.\n// Run this sketch again, and confirm the video is shown.\n// Coded by Mitsuteru Kokubun, 2017/02/20\n\nimport processing.video.*;               // using \"video\" library\n\nCapture cam;                             // declaration of Capture object\n\n// setup() function is executed once\nvoid setup() {\n  size(640, 480);                        // setting size of window\n  String[] cameras = Capture.list();     // getting available camera devices\n  printArray(cameras);                   // listing available camera devices\n  cam = new Capture(this, cameras[12]);  // * Rewrite [x] with the device number you use.\n  cam.start();                           // starting capture\n}\n\n// draw() function is exectuted repeatedly\nvoid draw() {\n  if(cam.available() == false) {         // if camera is not available\n    return;                              // do nothing and return\n  }\n  cam.read();                            // capturing image\n  image(cam, 0, 0);                      // displaying captured image\n}\n```\n\n## \u6700\u3082\u30b7\u30f3\u30d7\u30eb\u306a AR\n\n[NyARToolkit for Processing \u306e GitHub \u30ea\u30dd\u30b8\u30c8\u30ea](https://github.com/nyatla/NyARToolkit-for-Processing/)\u306e\u6307\u793a\u901a\u308a\u306b\u3001nyar4psg \u30e9\u30a4\u30d6\u30e9\u30ea\u3092\u30a4\u30f3\u30b9\u30c8\u30fc\u30eb\u3057\u307e\u3057\u305f\u3002\n\u30ab\u30e1\u30e9\u306e\u30ad\u30e3\u30ea\u30d6\u30ec\u30fc\u30b7\u30e7\u30f3\u30d1\u30e9\u30e1\u30fc\u30bf\u3082\u30c7\u30d5\u30a9\u30eb\u30c8\u306e \"camera_para.dat\" \u3092\u4f7f\u3044\u307e\u3057\u305f\u3002\n\u307e\u305f\u3001NyID \u30de\u30fc\u30ab\u3092\u4f7f\u3063\u3066\u3044\u307e\u3059\uff08[\u3053\u3061\u3089\u306e\u30b5\u30a4\u30c8](http://sixwish.jp/AR/Marker/idMarker/)\u3067\u4f5c\u6210\uff09\u3002\n\u5b9f\u8cea20\u884c\u304f\u3089\u3044\u3067\u3067\u304d\u307e\u3057\u305f\u3002\n\n![ar_box.JPG](https://qiita-image-store.s3.amazonaws.com/0/157570/38aed228-049d-7098-8e85-fca82e740919.jpeg)\n\n\n```java:ar_box.pde\n// ar_box.pde\n// A simple AR demo using NyARToolkit and Proceccing 3.\n// Install \"video\" library via \"Add Library\" tool of Processing IDE.\n// Install \"nyar4psg\" library according to the URL below.\n//   -> https://github.com/nyatla/NyARToolkit-for-Processing/\n// Connect a Web camera to your PC.\n// * Rewrite \"x\" with the camera device number you use.\n// Place \"camera_para.dat\" in \"data\" folder of this sketch.\n//   - \"camera_para.dat\" is included within ./libraries/nyar4psg/data\n// Print NyID markers on paper. (\"NyId_000-005.pdf\")\n// Run this sketch, and check that an orange transparent box is superimposed on the marker.\n// Coded by Mitsuteru Kokubun, 2017/02/20\n\nimport processing.video.*;               // using \"video\" library\nimport jp.nyatla.nyar4psg.*;             // using \"nyar4psg\" library\n\nCapture cam;                             // declaration of Capture object\nMultiMarker mm;                          // declaration of MultiMarker object\n\nvoid setup() {\n  // window and camera settings\n  size(640, 480, P3D);                   // setting size of window with P3D mode\n  String[] cameras = Capture.list();     // getting available camera devices\n  printArray(cameras);                   // listing available camera devices\n  cam = new Capture(this, cameras[12]);  // * Rewrite [x] with the device number you use.\n  cam.start();                           // starting capture\n  // NyARToolkit settings\n  mm = new MultiMarker(this,             // initial settings of NyARToolkit\n             width,                      // width of the input image\n             height,                     // height of the input image\n             \"camera_para.dat\",          // camera calibration parameter file\n             NyAR4PsgConfig.CONFIG_PSG); // configuration for Processing\n  mm.addNyIdMarker(0, 80);               // adding NyId marker(ID, marker_width[mm])\n}\n\nvoid draw() {\n  // video capture\n  if(cam.available() == false) {         // if camera is not available\n    return;                              // do nothing and return\n  }\n  cam.read();                            // capturing image\n  // Start of AR process\n  mm.detect(cam);                        // detecting marker within captured image\n  mm.drawBackground(cam);                // drawing captured image on background\n  if(mm.isExist(0) == false) {           // if marker[0] is not exist within the image\n    return;                              // do nothing and return\n  }\n  mm.beginTransform(0);                  // starting coordinate projection based on marker[0]\n    translate(0, 0, 40);                 // move the origin 40 mm in the Z axis direction\n    fill(255, 165, 0, 127);              // fill color(R, G, B, opacity)\n    box(80);                             // draw a 80 mm square box\n  mm.endTransform();                     // ending coordinate projection\n  // End of AR process\n}\n```\n\n\n## OBJ \u5f62\u5f0f\u306e 3DCG \u30e2\u30c7\u30eb\u3067 AR\n\n3DCG \u306e\u30e2\u30c7\u30eb\u3092\u8aad\u3080\u306b\u306f\u3001Processing 1.5.1 \u6642\u4ee3\u306f\u3001[saitoobjloader](https://code.google.com/archive/p/saitoobjloader/downloads) \u3084 [MQOLoader](http://www.hyde-ysd.com/reco-memo/mqoview.html) \u306a\u3069\u3092\u4f7f\u308f\u305b\u3066\u3044\u305f\u3060\u3044\u3066\u304d\u307e\u3057\u305f\u3002\n\u4eca\u56de\u3001saitoobjloader \u3092\u8a66\u3057\u305f\u3068\u3053\u308d\u3001Processing 3.3 \u3067\u306f\u52d5\u304d\u307e\u305b\u3093\u3067\u3057\u305f\u3002\n\u5c11\u3057\u8abf\u3079\u305f\u3089\u3001Processing \u6a19\u6e96\u306e PShape \u3067 OBJ \u5f62\u5f0f\u306e\u30e2\u30c7\u30eb\u304c\u8aad\u3081\u308b\u3053\u3068\u304c\u5206\u304b\u3063\u305f\u306e\u3067\u3001\u8a66\u3057\u305f\u3089\u3001\u7c21\u5358\u306b\u3067\u304d\u307e\u3057\u305f\u3002\u5b9f\u8cea30\u884c\u304f\u3089\u3044\u3067\u3059\u3002\nOBJ \u5f62\u5f0f\u306e 3DCG \u30e2\u30c7\u30eb\uff08rocket.obj, rocket.mtl, rocket.png\uff09\u306f\u3001Processing \u306e\u30b5\u30f3\u30d7\u30eb\u300cLoadDisplayObj.pde\u300d\u3067\u4f7f\u308f\u308c\u3066\u3044\u308b\u3082\u306e\u3092\u4f7f\u3044\u307e\u3057\u305f\u3002Processing \u672c\u4f53\u306e\u30d5\u30a9\u30eb\u30c0\u5185\u306e\u3001modes\\java\\examples\\Basics\\Shape\\LoadDisplayOBJ\\data \u306e\u4e2d\u306b\u3042\u308a\u307e\u3059\u3002\n\n![ar_obj.JPG](https://qiita-image-store.s3.amazonaws.com/0/157570/bc361cf5-f728-8470-ed72-e833e86d22f0.jpeg)\n\n\n```java:ar_obj.pde\n// ar_obj.pde\n// A 3DCG (*.obj) AR demo using NyARToolkit and Proceccing 3.\n// Install \"video\" library via \"Add Library\" tool of the Processing IDE.\n// Install \"nyar4psg\" library according to the URL below.\n// Connect a Web camera to your PC.\n// * Rewrite \"x\" with the camera device number you use.\n// Place \"camera_para.dat\" in \"data\" folder of this sketch.\n//   - \"camera_para.dat\" is included within ./libraries/nyar4psg/data\n// Place \"rocket.obj\", \"rocket.mtl\", and \"rocket.png\" in \"data\" folder of this sketch.\n//   - \"rocket.*\" are included within ./Processing_3.x.x/\n//       modes/java/exmples/Basics/Shape/LoadDisplayOBJ/data\n// Print NyID markers on paper. (\"NyId_000-005.pdf\")\n// Run this sketch, and check that a rocket of 3DCG is superimposed on the marker.\n// Coded by Mitsuteru Kokubun, 2017/02/20\n\nimport processing.video.*;               // using \"video\" library\nimport jp.nyatla.nyar4psg.*;             // using \"nyar4psg\" library\n\nCapture cam;                             // declaration of Capture object\nMultiMarker mm;                          // declaration of MultiMarker object\nPShape obj;                              // declaration of PShape object\nfloat ry;                                // variable for rotation of 3DCG model\n\nvoid setup() {\n  // window and camera settings\n  size(640, 480, P3D);                   // setting size of window with P3D mode\n  String[] cameras = Capture.list();     // getting available camera devices\n  printArray(cameras);                   // listing available camera devices\n  cam = new Capture(this, cameras[12]);  // * Rewrite [x] with the device number you use.\n  cam.start();                           // starting capture\n  // NyARToolkit settings\n  mm = new MultiMarker(this,             // initial settings of NyARToolkit\n             width,                      // width of the input image\n             height,                     // height of the input image\n             \"camera_para.dat\",          // camera calibration parameter file\n             NyAR4PsgConfig.CONFIG_PSG); // configuration for Processing\n  mm.addNyIdMarker(0, 80);               // adding NyId marker(ID, marker_width[mm])\n  // PShape setting\n  obj = loadShape(\"rocket.obj\");         // loading a 3DCG model named \"rocket.obj\"\n}\n\nvoid draw() {\n  // video capture\n  if(cam.available() == false) {         // if camera is not available\n    return;                              // do nothing and return\n  }\n  cam.read();                            // capturing image\n  // Start of AR process\n  mm.detect(cam);                        // detecting marker within captured image\n  mm.drawBackground(cam);                // drawing captured image on background\n  if(mm.isExist(0) == false) {           // if marker[0] is not exist within the image\n    return;                              // do nothing and return\n  }\n  mm.beginTransform(0);                  // starting coordinate projection based on marker[0]\n    lights();                            // adding lights in the 3D scene\n    scale(0.3);                          // adjusting the size of the 3DCG model\n    translate(0, 0, 80);                 // adjusting the position of the 3DCG model\n    rotateX(PI/2);                       // rotating the 3DCG model 90 degrees around the X axis\n    rotateY(ry);                         // rotating the 3DCG model ry radians around the Y axis\n    shape(obj);                          // displaying the 3DCG model\n  mm.endTransform();                     // ending coordinate projection\n  // End of AR process\n  ry += 0.1;                             // changing rotation angle\n}\n```\n\n## \u30de\u30eb\u30c1 NFT\uff08\u81ea\u7136\u7279\u5fb4\u70b9\u8ffd\u8de1\uff09\u306b\u3088\u308b AR\n\n\u6700\u5f8c\u306b NFT \u3082\u7df4\u7fd2\u3057\u3066\u307f\u307e\u3057\u3057\u305f\u3002\u305b\u3063\u304b\u304f\u306a\u306e\u3067\u3001\u9069\u5f53\u306b\u5199\u771f\u3092\u64ae\u3063\u3066\u305d\u308c\u3092 NFT \u306e\u30bf\u30fc\u30b2\u30c3\u30c8\u306b\u3001\u91cd\u7573\u8868\u793a\u3055\u305b\u308b CG \u30e2\u30c7\u30eb\u3082 Blender \u3092\u4f7f\u3063\u3066\u81ea\u4f5c\u3057\u307e\u3057\u305f\u3002\n\n\u4ee5\u4e0b\u306f\u30bf\u30fc\u30b2\u30c3\u30c8\u7528\u306b\u64ae\u5f71\u3057\u305f\u5199\u771f\u3067\u3059\u3002\n![IMG_0177.JPG](https://qiita-image-store.s3.amazonaws.com/0/157570/44138b22-5579-bf6b-5e56-507b5eaae328.jpeg)\n\nNyARToolkit \u306e\u30b5\u30f3\u30d7\u30eb\u3068\u3057\u3066\u4ed8\u5c5e\u3059\u308b NftFileGenerator \u3092\u4f7f\u3063\u3066\u753b\u50cf\u304b\u3089\u7279\u5fb4\u70b9\u3092\u62bd\u51fa\u3057\u3001\u7279\u5fb4\u70b9\u30d5\u30a1\u30a4\u30eb\uff08*.fset, *.fset3, *.iset \u306e\u4e09\u3064\u306e\u30d5\u30a1\u30a4\u30eb\uff09\u3092\u51fa\u529b\u3057\u307e\u3059\u3002\n![nftgen_savefeatureset.PNG](https://qiita-image-store.s3.amazonaws.com/0/157570/fffad013-bcb4-88cf-18bb-f71043962f15.png)\n\nBlender \u3067\u9069\u5f53\u306b CG \u3092\u4f5c\u308a\u307e\u3057\u305f\u3002\n![blender_time.PNG](https://qiita-image-store.s3.amazonaws.com/0/157570/8806cc28-2802-f4b8-c683-0780b1b90aa2.png)\n\n\u5b8c\u6210\u3067\u3059\u3002\n![nft_clock.JPG](https://qiita-image-store.s3.amazonaws.com/0/157570/a959aa92-8657-8cd6-afd4-c440a2f1e70d.jpeg)\n\n\n```java:ar_nft.pde\n// ar_nft.pde\n// An NFT(Natural Feature Tracking) AR demo using NyARToolkit and Proceccing 3.\n// Install \"video\" library via \"Add Library\" tool of the Processing IDE.\n// Install \"nyar4psg\" library according to the URL below.\n// Connect a Web camera to your PC.\n// * Rewrite \"x\" with the device number you use.\n// Place \"camera_para.dat\" in \"data\" folder of this sketch.\n//   - \"camera_para.dat\" is included within ./libraries/nyar4psg/data\n// Place \"drop.{obj, mtl}\" and \"time.{obj, mtl}\" in \"data\" folder of this sketch.\n//   - These obj models are made by using some modeling software, e.g. Blender.\n// Place \"faucet.{fset,fset3, iset}\" and \"time.{fset,fset3, iset}\" in \"data\" folder of this sketch.\n// Print \"faucet.jpg\" and \"clock.jpg\" on paper.\n// Run this sketch, and check that the 3DCGs are superimposed on the marker.\n// Coded by Mitsuteru Kokubun, 2017/02/20\n\nimport processing.video.*;               // using \"video\" library\nimport jp.nyatla.nyar4psg.*;             // using \"nyar4psg\" library\n\nCapture cam;                             // declaration of Capture object\nMultiNft nft;                            // declaration of MultiNft object\nPShape[] obj;                            // declaration of PShape array object\n\nvoid setup() {\n  // window and camera settings\n  size(640, 480, P3D);                   // setting size of window with P3D mode\n  String[] cameras = Capture.list();     // getting available camera devices\n  printArray(cameras);                   // listing available camera devices\n  cam = new Capture(this, cameras[0]);   // * Rewrite [x] with the device number you use.\n  cam.start();                           // starting capture\n  // NyARToolkit settings\n  nft = new MultiNft(this,               // initial settings of NyARToolkit\n             width,                      // width of the input image\n             height,                     // height of the input image\n             \"camera_para.dat\",          // camera calibration parameter file\n             NyAR4PsgConfig.CONFIG_PSG); // configuration for Processing\n  nft.addNftTarget(\"faucet\", 160);       // adding NFT target[0] (name, target_width[mm])\n  nft.addNftTarget(\"clock\", 160);        // adding NFT target[1] (name, target_width[mm])\n  // PShape setting\n  obj = new PShape[2];\n  obj[0] = loadShape(\"drop.obj\");        // loading a 3DCG model named \"drop.obj\"\n  obj[1] = loadShape(\"time.obj\");        // loading a 3DCG model named \"time.obj\"\n}\n\nvoid draw() {\n  // video capture\n  if(cam.available() == false) {         // if camera is not available\n    return;                              // do nothing and return\n  }\n  cam.read();                            // capturing image\n  // Start of AR process\n  nft.detect(cam);                       // detecting marker within captured image\n  nft.drawBackground(cam);               // drawing captured image on background\n  for (int i=0; i<2; i++) {              // repeating for two NFT targets\n    if(nft.isExist(i) == false) {        // if target[i] is not exist within the image\n      continue;                          // do nothing and find next target\n    }\n    nft.beginTransform(i);               // starting coordinate projection based on target[i]\n      lights();                          // adding lights in the 3D scene\n      translate(-80, 40, 0);             // adjusting the position of the 3DCG model\n      rotateY(PI);                       // rotating the 3DCG model 180 degrees around the Y axis \n      shape(obj[i]);                     // displaying the 3DCG model\n    nft.endTransform();                  // ending coordinate projection\n  }\n  // End of AR process\n}\n```\n\n\n# \u6240\u611f\u3068\u4eca\u5f8c\n\n\u79fb\u884c\u3057\u3066\u5927\u6b63\u89e3\u3067\u3057\u305f\u3002\n\u305f\u3044\u3066\u3044\u306e\u79c1\u306e\u7528\u9014\u306f\u521d\u671f\u306e\u30d7\u30ed\u30c8\u30bf\u30a4\u30d4\u30f3\u30b0\u306e\u305f\u3081\u3001\u901a\u5e38\u306e\u30de\u30fc\u30ab\u30fc\u3092\u4f7f\u3063\u3066\u3044\u3066\u3082\u306a\u3093\u306e\u554f\u984c\u3082\u306a\u3044\u306e\u3067\u3059\u304c\u3001NFT \u306e\u307b\u3046\u304c\u3084\u3063\u3071\u308a\u697d\u3057\u3044\u3067\u3059\u306d\u3002\n\u5f15\u304d\u7d9a\u304d\u3044\u308d\u3044\u308d\u904a\u3093\u3067\u307f\u305f\u3044\u3068\u601d\u3044\u307e\u3059\u3002\n"}