{"context": "\n\n\u306f\u3058\u3081\u306b\nWeb API\u306e\u30de\u30fc\u30b1\u30c3\u30c8\u30d7\u30ec\u30a4\u30b9\u3067\u3042\u308bApitore\u306b\u3001Word2Vec\u3092\u8ffd\u52a0\u3057\u3088\u3046\u3068\u601d\u3044\u307e\u3059\u3002Word2Vec\u304c\u3042\u308c\u3070\u81ea\u7136\u8a00\u8a9e\u51e6\u7406\u7cfb\u306e\u30a2\u30d7\u30ea\u30b1\u30fc\u30b7\u30e7\u30f3\u3067\u8272\u3005\u306a\u62e1\u304c\u308a\u304c\u51fa\u3066\u304d\u307e\u3059\u3002\u305d\u306e\u8a71\u306fAPI\u3092\u516c\u958b\u3057\u305f\u3068\u304d\u306b\u3059\u308b\u3068\u3057\u3066\u3001\u4eca\u56de\u306fJava\u3067Word2Vec\u3092\u5b9f\u88c5\u3059\u308b\u30ce\u30a6\u30cf\u30a6\u3092\u516c\u958b\u3057\u307e\u3059\u3002Java\u3067Word2Vec\u3092\u4f5c\u308b\u306a\u3089\u3001\u672c\u5bb6\u306eGoogle\u3067\u3082\u30aa\u30b9\u30b9\u30e1\u3057\u3066\u3044\u308bdeeplearning4j\u3092\u4f7f\u3046\u3068\u7c21\u5358\u3067\u3059\u3002\u5185\u8535\u3057\u3066\u3044\u308b\u5f62\u614b\u7d20\u89e3\u6790\u6a5f\u80fd\u306f\u30b9\u30da\u30fc\u30b9\u533a\u5207\u308a\u306a\u306e\u3067\u3001\u65e5\u672c\u8a9e\u5f62\u614b\u7d20\u89e3\u6790\u5668\u306eKuromoji\u3092\u4f7f\u3044\u307e\u3059\u3002\n\u30bd\u30fc\u30b9\u30b3\u30fc\u30c9\u7b49\u306f\u3053\u3061\u3089\u3067\u516c\u958b\u3057\u3066\u3044\u307e\u3059\u3002\n\n\ndeeplearning4j\u306b\u3088\u308bword2vec\nJava\u3092\u3069\u3046\u3057\u3066\u3082\u4f7f\u3044\u305f\u3044\u306e\u3067\u3001deeplearning4j\u3092\u5229\u7528\u3057\u307e\u3059\u3002\u5f62\u614b\u7d20\u89e3\u6790\u5668\u306fKuromoji\u3067\u3059\u3002\u4eca\u56de\u306fMaven\u3092\u4f7f\u3044\u307e\u3059\u3002\n<dependency>\n  <groupId>com.atilika.kuromoji</groupId>\n  <artifactId>kuromoji-ipadic</artifactId>\n  <version>0.9.0</version>\n</dependency>\n\n<dependency>\n  <groupId>org.deeplearning4j</groupId>\n  <artifactId>deeplearning4j-ui</artifactId>\n  <version>0.5.0</version>\n</dependency>\n\n<dependency>\n  <groupId>org.deeplearning4j</groupId>\n  <artifactId>deeplearning4j-nlp</artifactId>\n  <version>0.5.0</version>\n</dependency>\n\n<dependency>\n  <groupId>org.nd4j</groupId>\n  <artifactId>nd4j-native</artifactId>\n  <version>0.5.0</version>\n</dependency>\n\ndeeplearning4j\u306eword2vec\u3067kuromoji\u3092\u5229\u7528\u3059\u308b\u305f\u3081\u306b\u3001\u62e1\u5f35\u30af\u30e9\u30b9\u3092\u5b9f\u88c5\u3057\u307e\u3059\u3002Tokenizer\u3068TokenizerFactory\u306e\u62e1\u5f35\u30af\u30e9\u30b9\u3067\u3059\u3002\u65e2\u306bScala\u3067\u540c\u69d8\u306e\u3053\u3068\u3092\u3084\u3089\u308c\u305f\u65b9\u304c\u3044\u305f\u306e\u3067\u3001\u305d\u3061\u3089\u3092\u53c2\u8003\u306b\u3057\u307e\u3057\u305f\u3002\npublic class KuromojiIpadicTokenizer implements Tokenizer {\n\n  private List<Token> tokens;\n  private int index;\n  private TokenPreProcess preProcess;\n\n  public KuromojiIpadicTokenizer (String toTokenize) {\n    com.atilika.kuromoji.ipadic.Tokenizer tokenizer = new com.atilika.kuromoji.ipadic.Tokenizer();\n    tokens = tokenizer.tokenize(toTokenize);\n    index = (tokens.isEmpty()) ? -1:0;\n  }\n\n\n  @Override\n  public int countTokens() {\n    return tokens.size();\n  }\n\n  @Override\n  public List<String> getTokens() {\n    List<String> ret = new ArrayList<String>();\n    while (hasMoreTokens()) {\n      ret.add(nextToken());\n    }\n    return ret;\n  }\n\n  @Override\n  public boolean hasMoreTokens() {\n    if (index < 0)\n      return false;\n    else\n      return index < tokens.size();\n  }\n\n  @Override\n  public String nextToken() {\n    if (index < 0)\n      return null;\n\n    Token tok = tokens.get(index);\n    index++;\n    if (preProcess != null)\n      return preProcess.preProcess(tok.getSurface());\n    else\n      return tok.getSurface();\n  }\n\n  @Override\n  public void setTokenPreProcessor(TokenPreProcess preProcess) {\n    this.preProcess = preProcess;\n  }\n\n}\n\npublic class KuromojiIpadicTokenizerFactory implements TokenizerFactory {\n\n  private TokenPreProcess preProcess;\n\n\n  @Override\n  public Tokenizer create(String toTokenize) {\n    if (toTokenize == null || toTokenize.isEmpty()) {\n      throw new IllegalArgumentException(\"Unable to proceed; no sentence to tokenize\");\n    }\n\n    KuromojiIpadicTokenizer ret = new KuromojiIpadicTokenizer(toTokenize);\n    ret.setTokenPreProcessor(preProcess);\n    return ret;\n  }\n\n  @Override\n  public Tokenizer create(InputStream paramInputStream) {\n    throw new UnsupportedOperationException();\n  }\n\n  @Override\n  public void setTokenPreProcessor(TokenPreProcess preProcess) {\n    this.preProcess = preProcess;\n  }\n\n  @Override\n  public TokenPreProcess getTokenPreProcessor() {\n    return this.preProcess;\n  }\n\n}\n\n\u3055\u3066\u3001\u5b9f\u969b\u306b\u5b66\u7fd2\u3057\u3066\u307f\u307e\u3059\u3002\u5b66\u7fd2\u30c7\u30fc\u30bf\u306e\u8aad\u307f\u8fbc\u307f\u306f\u4ee5\u4e0b\u306e\u3088\u3046\u306b\u3057\u307e\u3059\u3002\nSentenceIterator iter = new BasicLineIterator(new File(\"corpus.txt\"));\n\n\u5f62\u614b\u7d20\u89e3\u6790\u306e\u5b9f\u884c\u306f\u4ee5\u4e0b\u306e\u3088\u3046\u306b\u3057\u307e\u3059\u3002\u5f62\u614b\u7d20\u89e3\u6790\u5b9f\u884c\u5f8c\u306b\u82f1\u5358\u8a9e\u306e\u6d3b\u7528\u5f62\u90e8\u5206\uff08e.g. -ed,-ing\uff09\u306e\u9664\u53bb\u3001\u82f1\u5b57\u5c0f\u6587\u5b57\u5316\u3001\u6570\u5b57\u306e\u8a18\u53f7\u5316\u3092\u3057\u3066\u304a\u304d\u307e\u3059\u3002\nfinal EndingPreProcessor preProcessor    = new EndingPreProcessor();\nKuromojiIpadicTokenizerFactory tokenizer = new KuromojiIpadicTokenizerFactory();\ntokenizer.setTokenPreProcessor( new TokenPreProcess()\n{\n  @Override\n  public String preProcess( String token )\n  {\n    token       = token.toLowerCase();\n    String base = preProcessor.preProcess( token );\n    base        = base.replaceAll( \"\\\\d\" , \"__NUMBER__\" );\n    return base;\n  }\n});\n\n\u5b66\u7fd2\u3092\u5b9f\u884c\u3057\u307e\u3059\u3002\u30d1\u30e9\u30e1\u30fc\u30bf\u306f\u30cd\u30c3\u30c8\u3067\u8abf\u3079\u3066\u3088\u304f\u4f7f\u308f\u308c\u3066\u3044\u305d\u3046\u306a\u3082\u306e\u3092\u63a1\u7528\u3057\u3066\u3044\u307e\u3059\u306e\u3067\u3001\u9069\u5f53\u3067\u3059\u3002\u30b3\u30a2\u306f6\u500b\u4f7f\u3046\u3088\u3046\u306b\u3057\u307e\u3057\u305f\u304c\u3001\u30bf\u30b9\u30af\u30de\u30cd\u30fc\u30b8\u30e3\u3092\u898b\u308b\u30686\u500b\u306f\u4f7f\u3063\u3066\u306a\u3044\u6c17\u304c\u3057\u307e\u3059\u3002\nint batchSize   = 1000;\nint iterations  = 5;\nint layerSize   = 150;\n\nWord2Vec vec = new Word2Vec.Builder()\n    .batchSize(batchSize)\n    .minWordFrequency(5)\n    .useAdaGrad(false)\n    .layerSize(layerSize)\n    .iterations(iterations)\n    .seed(1)\n    .windowSize(5)\n    .learningRate(0.025)\n    .minLearningRate(1e-3)\n    .negativeSample(10)\n    .iterate(iter)\n    .tokenizerFactory(tokenizer)\n    .workers(6)\n    .build();\nvec.fit();\n\n\u5b66\u7fd2\u30e2\u30c7\u30eb\u3092\u4fdd\u5b58\u3057\u307e\u3059\u3002\u3053\u308c\u3092\u5fd8\u308c\u308b\u3068\u5730\u7344\u3067\u3059\u3002\nWordVectorSerializer.writeWordVectors(vec, \"model-wordvectors.txt\");\n\n\u5b66\u7fd2\u304c\u5b8c\u4e86\u3057\u305f\u5f8c\u306f\u3001\u4f5c\u3063\u305f\u30e2\u30c7\u30eb\u3092\u4f7f\u3063\u3066\u30a2\u30ec\u30b3\u30ec\u3067\u304d\u307e\u3059\u3002\nWordVectors vec = WordVectorSerializer.loadTxtVectors(new File(\"model-wordvectors.txt\"));\nCollection<String> lst = vec.wordsNearest(\"day\", 10);\nSystem.out.println(lst);\ndouble cosSim = vec.similarity(\"day\", \"night\");\nSystem.out.println(cosSim);\ndouble[] wordVector = wordVectors.getWordVector(\"day\");\nSystem.out.println(wordVector);\n\n\n\u304a\u308f\u308a\u306b\ndeeplearning4j\u3092\u4f7f\u3063\u3066Word2Vec\u304c\u7c21\u5358\u306b\u5b9f\u88c5\u3067\u304d\u307e\u3057\u305f\u3002\u809d\u5fc3\u306e\u30c7\u30e2\u306b\u3064\u3044\u3066\u306f\u6e96\u5099\u4e2d\u3067\u3059\u3002API\u3092\u516c\u958b\u3059\u308b\u3068\u304d\u306b\u30c7\u30e2\u7d50\u679c\u3092\u542b\u3081\u3066\u8a18\u4e8b\u306b\u3057\u307e\u3059\u3002\u3061\u306a\u307f\u306b\u5c0f\u3055\u3044\u30c7\u30fc\u30bf\u3067\u52d5\u4f5c\u78ba\u8a8d\u306f\u3057\u3066\u3044\u308b\u306e\u3067\u3001\u4e0a\u8a18\u306e\u8a18\u4e8b\u306f\u6b63\u78ba\u3067\u3059\u3002\u73fe\u5728\u3001Windows10 64bit corei7\u3001\u30e1\u30e2\u30ea10GB\u3092\u4f7f\u3063\u3066\u5b66\u7fd2\u4e2d\u3067\u3059\u3002\u4e382\u65e5\u7d4c\u3063\u3066\u3082\u7d42\u308f\u3063\u3066\u3044\u307e\u305b\u3093\u3002\u30e1\u30e2\u30ea\u306f10GB\u6307\u5b9a\u3057\u307e\u3057\u305f\u304c\u3001\u3060\u3044\u305f\u30443GB\uff5e5GB\u304f\u3089\u3044\u3057\u304b\u4f7f\u3063\u3066\u306a\u3055\u305d\u3046\u3067\u3059\u3002\n## \u306f\u3058\u3081\u306b\nWeb API\u306e\u30de\u30fc\u30b1\u30c3\u30c8\u30d7\u30ec\u30a4\u30b9\u3067\u3042\u308b[Apitore](https://apitore.com/)\u306b\u3001Word2Vec\u3092\u8ffd\u52a0\u3057\u3088\u3046\u3068\u601d\u3044\u307e\u3059\u3002Word2Vec\u304c\u3042\u308c\u3070\u81ea\u7136\u8a00\u8a9e\u51e6\u7406\u7cfb\u306e\u30a2\u30d7\u30ea\u30b1\u30fc\u30b7\u30e7\u30f3\u3067\u8272\u3005\u306a\u62e1\u304c\u308a\u304c\u51fa\u3066\u304d\u307e\u3059\u3002\u305d\u306e\u8a71\u306fAPI\u3092\u516c\u958b\u3057\u305f\u3068\u304d\u306b\u3059\u308b\u3068\u3057\u3066\u3001\u4eca\u56de\u306fJava\u3067Word2Vec\u3092\u5b9f\u88c5\u3059\u308b\u30ce\u30a6\u30cf\u30a6\u3092\u516c\u958b\u3057\u307e\u3059\u3002Java\u3067Word2Vec\u3092\u4f5c\u308b\u306a\u3089\u3001\u672c\u5bb6\u306eGoogle\u3067\u3082\u30aa\u30b9\u30b9\u30e1\u3057\u3066\u3044\u308b[deeplearning4j](http://deeplearning4j.org/word2vec.html)\u3092\u4f7f\u3046\u3068\u7c21\u5358\u3067\u3059\u3002\u5185\u8535\u3057\u3066\u3044\u308b\u5f62\u614b\u7d20\u89e3\u6790\u6a5f\u80fd\u306f\u30b9\u30da\u30fc\u30b9\u533a\u5207\u308a\u306a\u306e\u3067\u3001\u65e5\u672c\u8a9e\u5f62\u614b\u7d20\u89e3\u6790\u5668\u306eKuromoji\u3092\u4f7f\u3044\u307e\u3059\u3002\n\u30bd\u30fc\u30b9\u30b3\u30fc\u30c9\u7b49\u306f[\u3053\u3061\u3089](http://blog.apitore.com/2016/09/19/deeplearning4j-jwikipedia-word2vec/)\u3067\u516c\u958b\u3057\u3066\u3044\u307e\u3059\u3002\n\n<img src=\"http://blog.apitore.com/wp-content/uploads/2016/09/amarec-20160919-095417.png\" alt=\"amarec (20160919-095417)\" width=\"960\" height=\"640\" class=\"alignnone size-full wp-image-413\" />\n\n\n## deeplearning4j\u306b\u3088\u308bword2vec\nJava\u3092\u3069\u3046\u3057\u3066\u3082\u4f7f\u3044\u305f\u3044\u306e\u3067\u3001[deeplearning4j](http://deeplearning4j.org/word2vec.html)\u3092\u5229\u7528\u3057\u307e\u3059\u3002\u5f62\u614b\u7d20\u89e3\u6790\u5668\u306fKuromoji\u3067\u3059\u3002\u4eca\u56de\u306fMaven\u3092\u4f7f\u3044\u307e\u3059\u3002\n\n```\n<dependency>\n  <groupId>com.atilika.kuromoji</groupId>\n  <artifactId>kuromoji-ipadic</artifactId>\n  <version>0.9.0</version>\n</dependency>\n\n<dependency>\n  <groupId>org.deeplearning4j</groupId>\n  <artifactId>deeplearning4j-ui</artifactId>\n  <version>0.5.0</version>\n</dependency>\n\n<dependency>\n  <groupId>org.deeplearning4j</groupId>\n  <artifactId>deeplearning4j-nlp</artifactId>\n  <version>0.5.0</version>\n</dependency>\n\n<dependency>\n  <groupId>org.nd4j</groupId>\n  <artifactId>nd4j-native</artifactId>\n  <version>0.5.0</version>\n</dependency>\n```\n\ndeeplearning4j\u306eword2vec\u3067kuromoji\u3092\u5229\u7528\u3059\u308b\u305f\u3081\u306b\u3001\u62e1\u5f35\u30af\u30e9\u30b9\u3092\u5b9f\u88c5\u3057\u307e\u3059\u3002Tokenizer\u3068TokenizerFactory\u306e\u62e1\u5f35\u30af\u30e9\u30b9\u3067\u3059\u3002\u65e2\u306bScala\u3067\u540c\u69d8\u306e\u3053\u3068\u3092\u3084\u3089\u308c\u305f\u65b9\u304c\u3044\u305f\u306e\u3067\u3001[\u305d\u3061\u3089](https://github.com/wmeddie/dl4j-jp)\u3092\u53c2\u8003\u306b\u3057\u307e\u3057\u305f\u3002\n\n```\npublic class KuromojiIpadicTokenizer implements Tokenizer {\n\n  private List<Token> tokens;\n  private int index;\n  private TokenPreProcess preProcess;\n\n  public KuromojiIpadicTokenizer (String toTokenize) {\n    com.atilika.kuromoji.ipadic.Tokenizer tokenizer = new com.atilika.kuromoji.ipadic.Tokenizer();\n    tokens = tokenizer.tokenize(toTokenize);\n    index = (tokens.isEmpty()) ? -1:0;\n  }\n\n\n  @Override\n  public int countTokens() {\n    return tokens.size();\n  }\n\n  @Override\n  public List<String> getTokens() {\n    List<String> ret = new ArrayList<String>();\n    while (hasMoreTokens()) {\n      ret.add(nextToken());\n    }\n    return ret;\n  }\n\n  @Override\n  public boolean hasMoreTokens() {\n    if (index < 0)\n      return false;\n    else\n      return index < tokens.size();\n  }\n\n  @Override\n  public String nextToken() {\n    if (index < 0)\n      return null;\n\n    Token tok = tokens.get(index);\n    index++;\n    if (preProcess != null)\n      return preProcess.preProcess(tok.getSurface());\n    else\n      return tok.getSurface();\n  }\n\n  @Override\n  public void setTokenPreProcessor(TokenPreProcess preProcess) {\n    this.preProcess = preProcess;\n  }\n\n}\n```\n\n```\npublic class KuromojiIpadicTokenizerFactory implements TokenizerFactory {\n\n  private TokenPreProcess preProcess;\n\n\n  @Override\n  public Tokenizer create(String toTokenize) {\n    if (toTokenize == null || toTokenize.isEmpty()) {\n      throw new IllegalArgumentException(\"Unable to proceed; no sentence to tokenize\");\n    }\n\n    KuromojiIpadicTokenizer ret = new KuromojiIpadicTokenizer(toTokenize);\n    ret.setTokenPreProcessor(preProcess);\n    return ret;\n  }\n\n  @Override\n  public Tokenizer create(InputStream paramInputStream) {\n    throw new UnsupportedOperationException();\n  }\n\n  @Override\n  public void setTokenPreProcessor(TokenPreProcess preProcess) {\n    this.preProcess = preProcess;\n  }\n\n  @Override\n  public TokenPreProcess getTokenPreProcessor() {\n    return this.preProcess;\n  }\n\n}\n```\n\n\u3055\u3066\u3001\u5b9f\u969b\u306b\u5b66\u7fd2\u3057\u3066\u307f\u307e\u3059\u3002\u5b66\u7fd2\u30c7\u30fc\u30bf\u306e\u8aad\u307f\u8fbc\u307f\u306f\u4ee5\u4e0b\u306e\u3088\u3046\u306b\u3057\u307e\u3059\u3002\n\n```\nSentenceIterator iter = new BasicLineIterator(new File(\"corpus.txt\"));\n```\n\n\u5f62\u614b\u7d20\u89e3\u6790\u306e\u5b9f\u884c\u306f\u4ee5\u4e0b\u306e\u3088\u3046\u306b\u3057\u307e\u3059\u3002\u5f62\u614b\u7d20\u89e3\u6790\u5b9f\u884c\u5f8c\u306b\u82f1\u5358\u8a9e\u306e\u6d3b\u7528\u5f62\u90e8\u5206\uff08e.g. -ed,-ing\uff09\u306e\u9664\u53bb\u3001\u82f1\u5b57\u5c0f\u6587\u5b57\u5316\u3001\u6570\u5b57\u306e\u8a18\u53f7\u5316\u3092\u3057\u3066\u304a\u304d\u307e\u3059\u3002\n\n```\nfinal EndingPreProcessor preProcessor    = new EndingPreProcessor();\nKuromojiIpadicTokenizerFactory tokenizer = new KuromojiIpadicTokenizerFactory();\ntokenizer.setTokenPreProcessor( new TokenPreProcess()\n{\n  @Override\n  public String preProcess( String token )\n  {\n    token       = token.toLowerCase();\n    String base = preProcessor.preProcess( token );\n    base        = base.replaceAll( \"\\\\d\" , \"__NUMBER__\" );\n    return base;\n  }\n});\n```\n\n\u5b66\u7fd2\u3092\u5b9f\u884c\u3057\u307e\u3059\u3002\u30d1\u30e9\u30e1\u30fc\u30bf\u306f\u30cd\u30c3\u30c8\u3067\u8abf\u3079\u3066\u3088\u304f\u4f7f\u308f\u308c\u3066\u3044\u305d\u3046\u306a\u3082\u306e\u3092\u63a1\u7528\u3057\u3066\u3044\u307e\u3059\u306e\u3067\u3001\u9069\u5f53\u3067\u3059\u3002\u30b3\u30a2\u306f6\u500b\u4f7f\u3046\u3088\u3046\u306b\u3057\u307e\u3057\u305f\u304c\u3001\u30bf\u30b9\u30af\u30de\u30cd\u30fc\u30b8\u30e3\u3092\u898b\u308b\u30686\u500b\u306f\u4f7f\u3063\u3066\u306a\u3044\u6c17\u304c\u3057\u307e\u3059\u3002\n\n```\nint batchSize   = 1000;\nint iterations  = 5;\nint layerSize   = 150;\n\nWord2Vec vec = new Word2Vec.Builder()\n    .batchSize(batchSize)\n    .minWordFrequency(5)\n    .useAdaGrad(false)\n    .layerSize(layerSize)\n    .iterations(iterations)\n    .seed(1)\n    .windowSize(5)\n    .learningRate(0.025)\n    .minLearningRate(1e-3)\n    .negativeSample(10)\n    .iterate(iter)\n    .tokenizerFactory(tokenizer)\n    .workers(6)\n    .build();\nvec.fit();\n```\n\n\u5b66\u7fd2\u30e2\u30c7\u30eb\u3092\u4fdd\u5b58\u3057\u307e\u3059\u3002\u3053\u308c\u3092\u5fd8\u308c\u308b\u3068\u5730\u7344\u3067\u3059\u3002\n\n```\nWordVectorSerializer.writeWordVectors(vec, \"model-wordvectors.txt\");\n```\n\n\u5b66\u7fd2\u304c\u5b8c\u4e86\u3057\u305f\u5f8c\u306f\u3001\u4f5c\u3063\u305f\u30e2\u30c7\u30eb\u3092\u4f7f\u3063\u3066\u30a2\u30ec\u30b3\u30ec\u3067\u304d\u307e\u3059\u3002\n\n```\nWordVectors vec = WordVectorSerializer.loadTxtVectors(new File(\"model-wordvectors.txt\"));\nCollection<String> lst = vec.wordsNearest(\"day\", 10);\nSystem.out.println(lst);\ndouble cosSim = vec.similarity(\"day\", \"night\");\nSystem.out.println(cosSim);\ndouble[] wordVector = wordVectors.getWordVector(\"day\");\nSystem.out.println(wordVector);\n```\n\n## \u304a\u308f\u308a\u306b\ndeeplearning4j\u3092\u4f7f\u3063\u3066Word2Vec\u304c\u7c21\u5358\u306b\u5b9f\u88c5\u3067\u304d\u307e\u3057\u305f\u3002\u809d\u5fc3\u306e\u30c7\u30e2\u306b\u3064\u3044\u3066\u306f\u6e96\u5099\u4e2d\u3067\u3059\u3002API\u3092\u516c\u958b\u3059\u308b\u3068\u304d\u306b\u30c7\u30e2\u7d50\u679c\u3092\u542b\u3081\u3066\u8a18\u4e8b\u306b\u3057\u307e\u3059\u3002\u3061\u306a\u307f\u306b\u5c0f\u3055\u3044\u30c7\u30fc\u30bf\u3067\u52d5\u4f5c\u78ba\u8a8d\u306f\u3057\u3066\u3044\u308b\u306e\u3067\u3001\u4e0a\u8a18\u306e\u8a18\u4e8b\u306f\u6b63\u78ba\u3067\u3059\u3002\u73fe\u5728\u3001Windows10 64bit corei7\u3001\u30e1\u30e2\u30ea10GB\u3092\u4f7f\u3063\u3066\u5b66\u7fd2\u4e2d\u3067\u3059\u3002\u4e382\u65e5\u7d4c\u3063\u3066\u3082\u7d42\u308f\u3063\u3066\u3044\u307e\u305b\u3093\u3002\u30e1\u30e2\u30ea\u306f10GB\u6307\u5b9a\u3057\u307e\u3057\u305f\u304c\u3001\u3060\u3044\u305f\u30443GB\uff5e5GB\u304f\u3089\u3044\u3057\u304b\u4f7f\u3063\u3066\u306a\u3055\u305d\u3046\u3067\u3059\u3002\n", "tags": ["deeplearning4j", "word2vec", "Java", "DeepLearning", "\u81ea\u7136\u8a00\u8a9e\u51e6\u7406"]}