{"context": "\n\u52d5\u4f5c\u74b0\u5883\nGeForce GTX 1070 (8GB)\nASRock Z170M Pro4S [Intel Z170chipset]\nUbuntu 14.04 LTS desktop amd64\nTensorFlow v0.11\ncuDNN v5.1 for Linux\nCUDA v8.0\nPython 2.7.6\nIPython 5.1.0 -- An enhanced Interactive Python.\n\n\nv0.1 http://qiita.com/7of9/items/b364d897b95476a30754\nAdamOptimizer\u306e\u5b66\u7fd2\u4fc2\u6570\u3092\u5909\u66f4\u3057\u3066\u307f\u305f\u3002\n\n\u4f7f\u7528\u3059\u308binput.csv\nQiita\u8a18\u4e8b\n\nNetwork\n\n\ncode\n\nlinreg2.py\n#!/usr/bin/env python\n# -*- coding: utf-8 -*-\n\nimport tensorflow as tf\nimport tensorflow.contrib.slim as slim\n\n# \u30d5\u30a1\u30a4\u30eb\u540d\u306e Queue \u3092\u4f5c\u6210\nfilename_queue = tf.train.string_input_producer([\"input.csv\"])\n\n# CSV \u3092 parse\nreader = tf.TextLineReader()\nkey, value = reader.read(filename_queue)\ninput1, output = tf.decode_csv(value, record_defaults=[[0.], [0.]])\ninputs = tf.pack([input1])\noutput = tf.pack([output])\n\ninputs_batch, output_batch = tf.train.shuffle_batch([inputs, output], 4, capacity=40, min_after_dequeue=4)\n\n## NN \u306e\u30b0\u30e9\u30d5\u751f\u6210\nhiddens = slim.stack(inputs_batch, slim.fully_connected, [1,7,7,7], \n  activation_fn=tf.nn.sigmoid, scope=\"hidden\")\nprediction = slim.fully_connected(hiddens, 1, activation_fn=tf.nn.sigmoid, scope=\"output\")\n\nloss = tf.contrib.losses.mean_squared_error(prediction, output_batch)\n#train_op = slim.learning.create_train_op(loss, tf.train.AdamOptimizer(0.01))\ntrain_op = slim.learning.create_train_op(loss, tf.train.AdamOptimizer(0.001))\n\ninit_op = tf.initialize_all_variables()\n\nwith tf.Session() as sess:\n  coord = tf.train.Coordinator()\n  threads = tf.train.start_queue_runners(sess=sess, coord=coord)\n\n  try:\n    sess.run(init_op)\n    for i in range(20000):\n      _, t_loss = sess.run([train_op, loss])\n      if (i+1) % 100 == 0:\n        print(\"%d,%f\" % (i+1, t_loss))\n#        print(\"%d,%f,#step, loss\" % (i+1, t_loss))\n  finally:\n    coord.request_stop()\n\n  coord.join(threads)\n\n\n\n\u7d50\u679c\ntrain_op = slim.learning.create_train_op(loss, tf.train.AdamOptimizer(0.001))\n\n\u306e\u884c\u306e\u4fc2\u6570\u30920.01\u30680.001\u3068\u3067\u305d\u308c\u305e\u308c\u5b9f\u884c\u3057\u3001\u4ee5\u4e0b\u306e\u30d5\u30a1\u30a4\u30eb\u3092\u4f5c\u6210\u3057\u305f\u3002\n\nlog.learn0p01\nlog.learn0p001\n\n\u4e0a\u8a18\u306e\u30d5\u30a1\u30a4\u30eb\u3092\u8aad\u3080Jupyter\u7528\u30b3\u30fc\u30c9\u306f\u4ee5\u4e0b\u3002\n%matplotlib inline\n\nimport numpy as np\nimport matplotlib.pyplot as plt\n\ndata = np.loadtxt('log.learn0p01', delimiter=',')\ninput1 = data[:,0]\noutput1 = data[:,1]\ndata = np.loadtxt('log.learn0p001', delimiter=',')\ninput2 = data[:,0]\noutput2 = data[:,1]\n\nfig = plt.figure()\nax = fig.add_subplot(1,1,1)\n\nax.plot(input1, output1, color='black', linestyle='solid', label='rate=0.01')\nax.plot(input2, output2, color='red', linestyle='solid', label='rate=0.001')\n\nax.set_title('loss')\nax.set_xlabel('step')\nax.set_ylabel('loss')\nax.grid(True)\nax.legend()\nfig.show()\n\n\n\u5b66\u7fd2\u4fc2\u6570\u3092\u5909\u66f4\u3057\u3066\u3082step20000\u8fd1\u8fba\u306eloss\u306e\u5024\u306f20%\u7a0b\u5ea6\u306f\u3042\u308b\u3002\n\u81ea\u5206\u304c\u5fc5\u8981\u3068\u3057\u3066\u3044\u308bloss\u306e\u4e0a\u9650\u306f\u3044\u304f\u3089\u306a\u306e\u304b\u5225\u9014\u8abf\u67fb\u3059\u308b\u5fc5\u8981\u3042\u308a\u3002loss\u304c20%\u3067\u3082\u4fc2\u6570\u306e\u521d\u671f\u5024\u3068\u3057\u3066\u8a08\u7b97\u304c\u65e9\u304f\u306a\u308b\u306e\u3067\u3042\u308c\u3070\u3001\u3053\u3053\u3067\u6642\u9593\u3092\u4f7f\u3046\u3053\u3068\u3082\u306a\u3044\u304b\u3082\u3057\u308c\u306a\u3044\u3002\n\n\u8ffd\u52a0\u8abf\u67fb\n\nQMC\u3092\u7528\u3044\u3066\u5165\u529b\u30c7\u30fc\u30bf\u3092\u4f5c\u6210\u3057\u3066\u307f\u305f\n\n\nloss\u5024\u306e\u6539\u5584\u306a\u3057\n\n\nprep_data.py\u5185\u306ey_data = np.sin(2*np.pi*x_data) + 0.3 * np.random.rand()\u306e0.3\u30920.03\u306b\u3057\u3066\u307f\u305f\n\n\nloss\u5024\u306e\u6539\u5584\u306a\u3057\n\n\n\u30cd\u30c3\u30c8\u306e\u5f62\u614b\u3092\u9069\u5f53\u306b\u5909\u66f4\u3057\u3066\u307f\u305f\n\n\nloss\u5024\u306e\u6539\u5584\u306a\u3057\n\n\n\n\nRNN\u3084\u305d\u306e\u4e00\u5f62\u614b\u306eLSTM\u306a\u3069\u306b\u9032\u3080\u304b\u3001\u5b9f\u969b\u306e\u5b66\u7fd2\u5bfe\u8c61\u306e\u30c7\u30fc\u30bf\u51e6\u7406\u306b\u9032\u3080\u304b\u3002\ntf.train.shuffle_batch()\u3092\u4f7f\u3063\u3066\u3044\u308b\u90e8\u5206\u306f\u30c7\u30fc\u30bf\u30bb\u30c3\u30c8\u304b\u3089\u9806\u756a\u306b\u53d6\u308a\u51fa\u3059\u3088\u3046\u306b\u5909\u66f4\u3059\u308b\u65b9\u304c\u3044\u3044\u304b\u3082\u3057\u308c\u306a\u3044\u3002\u305d\u3046\u3057\u306a\u3044\u3068QMC\u306e\u52b9\u679c\u304c\u671f\u5f85\u3067\u304d\u306a\u3044\u3002\n```txt:\u52d5\u4f5c\u74b0\u5883\nGeForce GTX 1070 (8GB)\nASRock Z170M Pro4S [Intel Z170chipset]\nUbuntu 14.04 LTS desktop amd64\nTensorFlow v0.11\ncuDNN v5.1 for Linux\nCUDA v8.0\nPython 2.7.6\nIPython 5.1.0 -- An enhanced Interactive Python.\n```\n\nv0.1 http://qiita.com/7of9/items/b364d897b95476a30754\n\nAdamOptimizer\u306e\u5b66\u7fd2\u4fc2\u6570\u3092\u5909\u66f4\u3057\u3066\u307f\u305f\u3002\n\n\n### \u4f7f\u7528\u3059\u308binput.csv \n\n[Qiita\u8a18\u4e8b](http://qiita.com/7of9/items/b364d897b95476a30754#%E3%83%87%E3%83%BC%E3%82%BF%E7%94%9F%E6%88%90%E9%83%A8)\n\n### Network\n\n![](http://yuml.me/diagram/class/ [x]-->[a], [x]-->[b], [x]-->[c], [x]-->[d], [x]-->[0], [x]-->[1], [x]-->[2], [a]-->[e], [a]-->[f], [a]-->[g], [a]-->[h], [a]-->[3], [a]-->[4], [a]-->[5], [b]-->[e], [b]-->[f], [b]-->[g], [b]-->[h], [b]-->[3], [b]-->[4], [b]-->[5], [c]-->[e], [c]-->[f], [c]-->[g], [c]-->[h], [c]-->[3], [c]-->[4], [c]-->[5], [d]-->[e], [d]-->[f], [d]-->[g], [d]-->[h], [d]-->[3], [d]-->[4], [d]-->[5], [0]-->[e], [0]-->[f], [0]-->[g], [0]-->[h], [0]-->[3], [0]-->[4], [0]-->[5], [1]-->[e], [1]-->[f], [1]-->[g], [1]-->[h], [1]-->[3], [1]-->[4], [1]-->[5], [2]-->[e], [2]-->[f], [2]-->[g], [2]-->[h], [2]-->[3], [2]-->[4], [2]-->[5], [e]-->[i], [e]-->[j], [e]-->[k], [e]-->[l], [e]-->[6], [e]-->[7], [e]-->[8], [f]-->[i], [f]-->[j], [f]-->[k], [f]-->[l], [f]-->[6], [f]-->[7], [f]-->[8], [g]-->[i], [g]-->[j], [g]-->[k], [g]-->[l], [g]-->[6], [g]-->[7], [g]-->[8], [h]-->[i], [h]-->[j], [h]-->[k], [h]-->[l], [h]-->[6], [h]-->[7], [h]-->[8], [3]-->[i], [3]-->[j], [3]-->[k], [3]-->[l], [3]-->[6], [3]-->[7], [3]-->[8], [4]-->[i], [4]-->[j], [4]-->[k], [4]-->[l], [4]-->[6], [4]-->[7], [4]-->[8], [5]-->[i], [5]-->[j], [5]-->[k], [5]-->[l], [5]-->[6], [5]-->[7], [5]-->[8], [i]-->[z], [j]-->[z], [k]-->[z], [l]-->[z], [6]-->[z], [7]-->[z], [8]-->[z], )\n\n\n### code\n\n```linreg2.py\n#!/usr/bin/env python\n# -*- coding: utf-8 -*-\n\nimport tensorflow as tf\nimport tensorflow.contrib.slim as slim\n\n# \u30d5\u30a1\u30a4\u30eb\u540d\u306e Queue \u3092\u4f5c\u6210\nfilename_queue = tf.train.string_input_producer([\"input.csv\"])\n\n# CSV \u3092 parse\nreader = tf.TextLineReader()\nkey, value = reader.read(filename_queue)\ninput1, output = tf.decode_csv(value, record_defaults=[[0.], [0.]])\ninputs = tf.pack([input1])\noutput = tf.pack([output])\n\ninputs_batch, output_batch = tf.train.shuffle_batch([inputs, output], 4, capacity=40, min_after_dequeue=4)\n\n## NN \u306e\u30b0\u30e9\u30d5\u751f\u6210\nhiddens = slim.stack(inputs_batch, slim.fully_connected, [1,7,7,7], \n  activation_fn=tf.nn.sigmoid, scope=\"hidden\")\nprediction = slim.fully_connected(hiddens, 1, activation_fn=tf.nn.sigmoid, scope=\"output\")\n\nloss = tf.contrib.losses.mean_squared_error(prediction, output_batch)\n#train_op = slim.learning.create_train_op(loss, tf.train.AdamOptimizer(0.01))\ntrain_op = slim.learning.create_train_op(loss, tf.train.AdamOptimizer(0.001))\n\ninit_op = tf.initialize_all_variables()\n\nwith tf.Session() as sess:\n  coord = tf.train.Coordinator()\n  threads = tf.train.start_queue_runners(sess=sess, coord=coord)\n\n  try:\n    sess.run(init_op)\n    for i in range(20000):\n      _, t_loss = sess.run([train_op, loss])\n      if (i+1) % 100 == 0:\n        print(\"%d,%f\" % (i+1, t_loss))\n#        print(\"%d,%f,#step, loss\" % (i+1, t_loss))\n  finally:\n    coord.request_stop()\n\n  coord.join(threads)\n```\n\n### \u7d50\u679c\n\n`train_op = slim.learning.create_train_op(loss, tf.train.AdamOptimizer(0.001))\n`\n\u306e\u884c\u306e\u4fc2\u6570\u30920.01\u30680.001\u3068\u3067\u305d\u308c\u305e\u308c\u5b9f\u884c\u3057\u3001\u4ee5\u4e0b\u306e\u30d5\u30a1\u30a4\u30eb\u3092\u4f5c\u6210\u3057\u305f\u3002\n\n- log.learn0p01\n- log.learn0p001\n\n\u4e0a\u8a18\u306e\u30d5\u30a1\u30a4\u30eb\u3092\u8aad\u3080Jupyter\u7528\u30b3\u30fc\u30c9\u306f\u4ee5\u4e0b\u3002\n\n```py\n%matplotlib inline\n\nimport numpy as np\nimport matplotlib.pyplot as plt\n\ndata = np.loadtxt('log.learn0p01', delimiter=',')\ninput1 = data[:,0]\noutput1 = data[:,1]\ndata = np.loadtxt('log.learn0p001', delimiter=',')\ninput2 = data[:,0]\noutput2 = data[:,1]\n\nfig = plt.figure()\nax = fig.add_subplot(1,1,1)\n\nax.plot(input1, output1, color='black', linestyle='solid', label='rate=0.01')\nax.plot(input2, output2, color='red', linestyle='solid', label='rate=0.001')\n\nax.set_title('loss')\nax.set_xlabel('step')\nax.set_ylabel('loss')\nax.grid(True)\nax.legend()\nfig.show()\n```\n\n\n![qiita.png](https://qiita-image-store.s3.amazonaws.com/0/32870/5e96ee37-74c5-3ae0-9a6c-0b2c6b0d2401.png)\n\n\u5b66\u7fd2\u4fc2\u6570\u3092\u5909\u66f4\u3057\u3066\u3082step20000\u8fd1\u8fba\u306eloss\u306e\u5024\u306f20%\u7a0b\u5ea6\u306f\u3042\u308b\u3002\n\n\u81ea\u5206\u304c\u5fc5\u8981\u3068\u3057\u3066\u3044\u308bloss\u306e\u4e0a\u9650\u306f\u3044\u304f\u3089\u306a\u306e\u304b\u5225\u9014\u8abf\u67fb\u3059\u308b\u5fc5\u8981\u3042\u308a\u3002loss\u304c20%\u3067\u3082\u4fc2\u6570\u306e\u521d\u671f\u5024\u3068\u3057\u3066\u8a08\u7b97\u304c\u65e9\u304f\u306a\u308b\u306e\u3067\u3042\u308c\u3070\u3001\u3053\u3053\u3067\u6642\u9593\u3092\u4f7f\u3046\u3053\u3068\u3082\u306a\u3044\u304b\u3082\u3057\u308c\u306a\u3044\u3002\n\n### \u8ffd\u52a0\u8abf\u67fb\n\n\n- QMC\u3092\u7528\u3044\u3066\u5165\u529b\u30c7\u30fc\u30bf\u3092\u4f5c\u6210\u3057\u3066\u307f\u305f\n   + loss\u5024\u306e\u6539\u5584\u306a\u3057\n- prep_data.py\u5185\u306e`y_data = np.sin(2*np.pi*x_data) + 0.3 * np.random.rand()`\u306e0.3\u30920.03\u306b\u3057\u3066\u307f\u305f\n   + loss\u5024\u306e\u6539\u5584\u306a\u3057\n- \u30cd\u30c3\u30c8\u306e\u5f62\u614b\u3092\u9069\u5f53\u306b\u5909\u66f4\u3057\u3066\u307f\u305f\n   + loss\u5024\u306e\u6539\u5584\u306a\u3057\n\n![qiita.png](https://qiita-image-store.s3.amazonaws.com/0/32870/733f8962-e04f-e778-4fcc-97e8323d52e4.png)\n\nRNN\u3084\u305d\u306e\u4e00\u5f62\u614b\u306eLSTM\u306a\u3069\u306b\u9032\u3080\u304b\u3001\u5b9f\u969b\u306e\u5b66\u7fd2\u5bfe\u8c61\u306e\u30c7\u30fc\u30bf\u51e6\u7406\u306b\u9032\u3080\u304b\u3002\n\ntf.train.shuffle_batch()\u3092\u4f7f\u3063\u3066\u3044\u308b\u90e8\u5206\u306f\u30c7\u30fc\u30bf\u30bb\u30c3\u30c8\u304b\u3089\u9806\u756a\u306b\u53d6\u308a\u51fa\u3059\u3088\u3046\u306b\u5909\u66f4\u3059\u308b\u65b9\u304c\u3044\u3044\u304b\u3082\u3057\u308c\u306a\u3044\u3002\u305d\u3046\u3057\u306a\u3044\u3068QMC\u306e\u52b9\u679c\u304c\u671f\u5f85\u3067\u304d\u306a\u3044\u3002\n", "tags": ["borgWarp"]}