{"tags": ["Python", "lxml", "scipy"], "context": " More than 1 year has passed since last update.\n\n\u4f55\u3092\u3059\u308b\u306e\u304b\nTOPIX \u306e\u6642\u7cfb\u5217\u3092\u8868\u793a\u3059\u308b\u306e\u306f\u524d\u306e\u6295\u7a3f\u3067\u3084\u3063\u305f\u306e\u3067\u3001\n\u5f8c\u3067\u52a0\u5de5\u3057\u3084\u3059\u3044\u3088\u3046\u306b\u3044\u308d\u3093\u306a\u5f62\u5f0f\u3067\u4fdd\u5b58\u3059\u308b\u3002\n\nYahoo \u30d5\u30a1\u30a4\u30ca\u30f3\u30b9\u306e html \u3092\u89e3\u6790\u3059\u308b\u30b3\u30fc\u30c9\n\u524d\u306e\u3068\u540c\u3058\u3002 \u305f\u3060\u3057\u3001 savedataAs\u306a\u3093\u3068\u304b(filename, data) \u3068\u3044\u3046\u95a2\u6570\u547c\u3073\u51fa\u3057\u3092\u5165\u308c\u3066\u3044\u308b\u3002\n#!/usr/bin/env python\n#-*- coding: utf-8 -*-\nimport pylab\nimport urllib2\nimport lxml\nimport lxml.html\nimport re\n\ndateFr = {\"year\": 2000, \"month\":1, \"day\":1}\ndateTo = {\"year\": 2013, \"month\":11, \"day\": 1}\n\ndata = []\nfor page in range(1, 30):\n    print page\n    url = \"http://info.finance.yahoo.co.jp/history/?code=998405.T&sy=%d&sm=%d&sd=%d&ey=%d&em=%d&ed=%d&tm=d&p=%d\"\n    url = url % (dateFr[\"year\"], dateFr[\"month\"], dateFr[\"day\"], dateTo[\"year\"], dateFr[\"month\"], dateFr[\"day\"], page)\n\n    html = urllib2.urlopen(url).read()\n    root = lxml.html.fromstring(html)\n    table = root.xpath(' //*[contains(concat(\" \",normalize-space(@class),\" \"), \" boardFin \")]')[0]\n\n    for tr in table.xpath(\"descendant::tr\"):\n        tmp = [td.text for td in tr.xpath(\"descendant::td\")]\n        if len(tmp) != 5:\n            continue\n        begin = float(tmp[1].replace(\",\", \"\"))\n        high  = float(tmp[2].replace(\",\", \"\"))\n        low   = float(tmp[3].replace(\",\", \"\"))\n        end   = float(tmp[4].replace(\",\", \"\"))\n        data.append([low, high, low, high])\nsavedataAsPickle('topix.pickle', data)\nsavedataAsCSV('topix.csv', data)\nsavedataAsExcel('topix.xlsx', data)\n\n\n\u4fdd\u5b58\u3059\u308b\u30b3\u30fc\u30c9\n\npickle\npython \u306e\u6a19\u6e96\u30e9\u30a4\u30d6\u30e9\u30ea\u306b\u3042\u308b\u5f62\u5f0f\ndef savedata(filename, data):\n    pickle.dump(data, open(filename, \"w\"))\n\n\ncsv\nComma Separated Values \u306e\u7565\u3002\u30c6\u30ad\u30b9\u30c8\u5f62\u5f0f\u3002\ndef savedata(filename, data):\n    import csv\n    csvobj = csv.writer(open(filename, \"w\"))\n    csvobj.writerows(data)\n\n\n\nExcel \u5f62\u5f0f\nExcel \u3067\u8aad\u3081\u308b\u5f62\u5f0f\u306b\u4fdd\u5b58\ndef savedata(filename, data):\n    import openpyxl.workbook\n    import openpyxl.cell\n\n    wb = openpyxl.workbook.Workbook()\n    ws = wb.worksheets[0]\n    ws.title = \"TOPIX\"\n    for idat, dat in enumerate(data):\n        col = openpyxl.cell.get_column_letter(idat + 1) # from 1, 2, ... to A, B, ...\n        for irow, d in enumerate(dat):\n            ws.cell('%s%s'%(col, irow + 1)).value = d\n    wb.save(filename)\n\n# \u4f55\u3092\u3059\u308b\u306e\u304b\n\nTOPIX \u306e\u6642\u7cfb\u5217\u3092\u8868\u793a\u3059\u308b\u306e\u306f\u524d\u306e\u6295\u7a3f\u3067\u3084\u3063\u305f\u306e\u3067\u3001\n\u5f8c\u3067\u52a0\u5de5\u3057\u3084\u3059\u3044\u3088\u3046\u306b\u3044\u308d\u3093\u306a\u5f62\u5f0f\u3067\u4fdd\u5b58\u3059\u308b\u3002\n\n# Yahoo \u30d5\u30a1\u30a4\u30ca\u30f3\u30b9\u306e html \u3092\u89e3\u6790\u3059\u308b\u30b3\u30fc\u30c9\n\u524d\u306e\u3068\u540c\u3058\u3002 \u305f\u3060\u3057\u3001 `savedataAs\u306a\u3093\u3068\u304b(filename, data)` \u3068\u3044\u3046\u95a2\u6570\u547c\u3073\u51fa\u3057\u3092\u5165\u308c\u3066\u3044\u308b\u3002\n\n```py\n#!/usr/bin/env python\n#-*- coding: utf-8 -*-\nimport pylab\nimport urllib2\nimport lxml\nimport lxml.html\nimport re\n\ndateFr = {\"year\": 2000, \"month\":1, \"day\":1}\ndateTo = {\"year\": 2013, \"month\":11, \"day\": 1}\n\ndata = []\nfor page in range(1, 30):\n    print page\n    url = \"http://info.finance.yahoo.co.jp/history/?code=998405.T&sy=%d&sm=%d&sd=%d&ey=%d&em=%d&ed=%d&tm=d&p=%d\"\n    url = url % (dateFr[\"year\"], dateFr[\"month\"], dateFr[\"day\"], dateTo[\"year\"], dateFr[\"month\"], dateFr[\"day\"], page)\n\n    html = urllib2.urlopen(url).read()\n    root = lxml.html.fromstring(html)\n    table = root.xpath(' //*[contains(concat(\" \",normalize-space(@class),\" \"), \" boardFin \")]')[0]\n\n    for tr in table.xpath(\"descendant::tr\"):\n        tmp = [td.text for td in tr.xpath(\"descendant::td\")]\n        if len(tmp) != 5:\n            continue\n        begin = float(tmp[1].replace(\",\", \"\"))\n        high  = float(tmp[2].replace(\",\", \"\"))\n        low   = float(tmp[3].replace(\",\", \"\"))\n        end   = float(tmp[4].replace(\",\", \"\"))\n        data.append([low, high, low, high])\nsavedataAsPickle('topix.pickle', data)\nsavedataAsCSV('topix.csv', data)\nsavedataAsExcel('topix.xlsx', data)\n```\n\n# \u4fdd\u5b58\u3059\u308b\u30b3\u30fc\u30c9\n\n## pickle\npython \u306e\u6a19\u6e96\u30e9\u30a4\u30d6\u30e9\u30ea\u306b\u3042\u308b\u5f62\u5f0f\n\n```py\ndef savedata(filename, data):\n    pickle.dump(data, open(filename, \"w\"))\n```\n\n## csv\nComma Separated Values \u306e\u7565\u3002\u30c6\u30ad\u30b9\u30c8\u5f62\u5f0f\u3002\n\n```py\ndef savedata(filename, data):\n    import csv\n    csvobj = csv.writer(open(filename, \"w\"))\n    csvobj.writerows(data)\n\n```\n\n## Excel \u5f62\u5f0f\nExcel \u3067\u8aad\u3081\u308b\u5f62\u5f0f\u306b\u4fdd\u5b58\n\n```py\ndef savedata(filename, data):\n    import openpyxl.workbook\n    import openpyxl.cell\n \n    wb = openpyxl.workbook.Workbook()\n    ws = wb.worksheets[0]\n    ws.title = \"TOPIX\"\n    for idat, dat in enumerate(data):\n        col = openpyxl.cell.get_column_letter(idat + 1) # from 1, 2, ... to A, B, ...\n        for irow, d in enumerate(dat):\n            ws.cell('%s%s'%(col, irow + 1)).value = d\n    wb.save(filename)\n```\n"}