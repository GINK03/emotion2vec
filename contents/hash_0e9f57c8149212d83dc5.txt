{"context": " More than 1 year has passed since last update.\n\n\u8ab2\u984c\nReplicaSet\u3067read_secondary => ture\u306b\u3057\u3066\u3044\u308b\u6642\u3001\u8aad\u307f\u306b\u884c\u304fmongo\u306f\u30e9\u30f3\u30c0\u30e0\u306b\u6c7a\u5b9a\u3055\u308c\u308b\u3002\n\u3053\u308c\u304c\u5931\u6557\u3059\u308b\u3068Mongo::ConnectionFailure\u304c\u767a\u751f\u3059\u308b\u306e\u3060\u304c\u3001\u30c7\u30d5\u30a9\u30eb\u30c8\u3060\u3068\u305d\u306e\u307e\u307e\u30ea\u30c8\u30e9\u30a4\u305b\u305a\u306b\u30a8\u30e9\u30fc\u3068\u306a\u308b\u3002\nfailover\u5fa9\u65e7\u6642\u3084index\u4f5c\u6210\u6642\u306a\u3069secondary\u304cblock\u72b6\u614b\u306e\u6642\u306b\u3082\u3001\u4f55\u5ea6\u304b\u30ea\u30c8\u30e9\u30a4\u3059\u308b\u3088\u3046\u306b\u3057\u305f\u3044\u3002\n\u203b\u6ce8: background => true\u3067\u5b9f\u884c\u3057\u305f\u3068\u304dprimary\u306f\u78ba\u304b\u306bbackground\u5b9f\u884c\u306b\u306a\u3063\u3066\u3044\u308b\u304c\u3001secondary\u306fblock\u3055\u308c\u308b\n\n\u89e3\u6c7a\nmongoid.yml\u306bmax_retries_on_connection_failure\u30aa\u30d7\u30b7\u30e7\u30f3\u3092\u8ffd\u52a0\u3059\u308b\u3002\n\nmongoid.yml\nproduction:\n  database: myapp\n  hosts: [[100.100.100.100, 27017],\n          [200.200.200.200, 27017],\n          [300.300.300.300, 27017]]\n  pool_size: 99\n  read_secondary: true\n  max_retries_on_connection_failure: 5\n\n\n\n\u53c2\u8003\n\n\nConnection Failures\nImagine that either the master node or one of the read nodes goes offline. How will the driver respond?\nIf any read operation fails, the driver will raise a ConnectionFailure exception. It then becomes the client's responsibility to decide how to handle this.\nIf the client decides to retry, it's not guaranteed that another member of the replica set will have been promoted to master right away, so it's still possible that the driver will raise another ConnectionFailure. However, once a member has been promoted to master, typically within a few seconds, subsequent operations will succeed. Note that this does not prevent exception in the event of a primary failover.\nThe driver will essentially cycle through all known seed addresses until a node identifies itself as master.\nRuby Mongo drive\n\n\n\nIf you would also like Mongoid to retry operations if a Mongo::ConnectionFailure occurs you may specify this option in your config. Mongoid will retry the operation every half second up to the limit that is set. This defaults to 0.\nmax_retries_on_connection_failure: 3\n\nNote that Mongoid does not handle reconnection at the time of this documentation, so you'll have to catch the connection errors and retry yourself in the meantime.\nMongoid\u516c\u5f0f\u30c9\u30ad\u30e5\u30e1\u30f3\u30c8\n\n\n\u305d\u306e\u4ed6\u30bd\u30fc\u30b9\nhttp://groups.google.com/group/mongoid/browse_thread/thread/700b5e0c5249baed?pli=1\nhttp://stackoverflow.com/questions/10221198/mongooperationfailure-repeatedly-happening-in-ec2-what-to-do\n\n## \u8ab2\u984c\n\nReplicaSet\u3067read_secondary => ture\u306b\u3057\u3066\u3044\u308b\u6642\u3001\u8aad\u307f\u306b\u884c\u304fmongo\u306f\u30e9\u30f3\u30c0\u30e0\u306b\u6c7a\u5b9a\u3055\u308c\u308b\u3002\n\u3053\u308c\u304c\u5931\u6557\u3059\u308b\u3068`Mongo::ConnectionFailure`\u304c\u767a\u751f\u3059\u308b\u306e\u3060\u304c\u3001\u30c7\u30d5\u30a9\u30eb\u30c8\u3060\u3068\u305d\u306e\u307e\u307e\u30ea\u30c8\u30e9\u30a4\u305b\u305a\u306b\u30a8\u30e9\u30fc\u3068\u306a\u308b\u3002\n\nfailover\u5fa9\u65e7\u6642\u3084index\u4f5c\u6210\u6642\u306a\u3069secondary\u304cblock\u72b6\u614b\u306e\u6642\u306b\u3082\u3001\u4f55\u5ea6\u304b\u30ea\u30c8\u30e9\u30a4\u3059\u308b\u3088\u3046\u306b\u3057\u305f\u3044\u3002\n\n<small>\u203b\u6ce8: background => true\u3067\u5b9f\u884c\u3057\u305f\u3068\u304dprimary\u306f\u78ba\u304b\u306bbackground\u5b9f\u884c\u306b\u306a\u3063\u3066\u3044\u308b\u304c\u3001secondary\u306fblock\u3055\u308c\u308b</small>\n\n\n## \u89e3\u6c7a\n\nmongoid.yml\u306b`max_retries_on_connection_failure`\u30aa\u30d7\u30b7\u30e7\u30f3\u3092\u8ffd\u52a0\u3059\u308b\u3002\n\n~~~~ruby:mongoid.yml\nproduction:\n  database: myapp\n  hosts: [[100.100.100.100, 27017],\n          [200.200.200.200, 27017],\n          [300.300.300.300, 27017]]\n  pool_size: 99\n  read_secondary: true\n  max_retries_on_connection_failure: 5\n~~~~\n\n\n## \u53c2\u8003\n\n> ### Connection Failures\n>\n> Imagine that either the master node or one of the read nodes goes offline. How will the driver respond?\n>\n> If any read operation fails, the driver will raise a `ConnectionFailure` exception. It then becomes the client's responsibility to decide how to handle this.\n>\n> If the client decides to retry, it's not guaranteed that another member of the replica set will have been promoted to master right away, so it's still possible that the driver will raise another `ConnectionFailure`. However, once a member has been promoted to master, typically within a few seconds, subsequent operations will succeed. Note that this does not prevent exception in the event of a primary failover.\n>\n> The driver will essentially cycle through all known seed addresses until a node identifies itself as master.\n>\n> <cite>[Ruby Mongo drive](http://api.mongodb.org/ruby/current/file.REPLICA_SETS.html)</cite>\n\n---\n\n> If you would also like Mongoid to retry operations if a Mongo::ConnectionFailure occurs you may specify this option in your config. Mongoid will retry the operation every half second up to the limit that is set. This defaults to 0.\n>\n> ~~~~~~~~~~\n> max_retries_on_connection_failure: 3\n> ~~~~~~~~~~\n>\n> Note that Mongoid does not handle reconnection at the time of this documentation, so you'll have to catch the connection errors and retry yourself in the meantime.\n> \n> <cite>[Mongoid\u516c\u5f0f\u30c9\u30ad\u30e5\u30e1\u30f3\u30c8](http://mongoid.org/docs/installation/replication.html)</cite>\n\n\n### \u305d\u306e\u4ed6\u30bd\u30fc\u30b9\n\nhttp://groups.google.com/group/mongoid/browse_thread/thread/700b5e0c5249baed?pli=1\nhttp://stackoverflow.com/questions/10221198/mongooperationfailure-repeatedly-happening-in-ec2-what-to-do", "tags": ["MongoDB", "Ruby", "mongoid"]}