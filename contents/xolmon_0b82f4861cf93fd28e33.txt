{"context": "\n\n\u74b0\u5883\nPC: MacBook Air\nCPU: 1.4 GHz Intel Core i5\n\u30e1\u30e2\u30ea: 4GB\n\u3075\u3064\u3046\u306eMacBook Air\u3067\u3084\u3063\u305f\u306e\u3067\u3059\u304c\u3001\u5b66\u7fd2\u9045\u3044\u3057\u3001\u30e1\u30e2\u30ea\u4e0d\u8db3\u3067\u843d\u3061\u308b\u3057\u3067\u3084\u3063\u3071\u308a\u8f9b\u304b\u3063\u305f\u3067\u3059\u3002\n\n\u304a\u304a\u307e\u304b\u306a\u6d41\u308c\n\n\u5404\u5973\u512a\u306e\u753b\u50cf\u3092\u53ce\u96c6\u3059\u308b\u3002\ndlib\u3067\u9854\u753b\u50cf\u3092\u5207\u308a\u53d6\u3063\u306696\u00d796\u306e\u5927\u304d\u3055\u306b\u30ea\u30b5\u30a4\u30ba\u3059\u308b\u3002\n1\u4eba\u306b\u3064\u304d1000\u679a\u306e\u753b\u50cf\u306b\u306a\u308b\u3088\u3046\u30c7\u30fc\u30bf\u62e1\u5f35\u3059\u308b\u3002\n\u30c7\u30fc\u30bf\u3092numpy\u30d5\u30a1\u30a4\u30eb\u306b\u5909\u63db\u3059\u308b\u3002\nchainer\u3067\u9854\u753b\u50cf\u3092\u5b66\u7fd2\u3059\u308b\u3002\n\u5b66\u7fd2\u3057\u305f\u30e2\u30c7\u30eb\u304b\u3089\u4efb\u610f\u306e\u753b\u50cf\u306e\u4e88\u6e2c\u3092\u3059\u308b\u3002\n\n\n1. \u753b\u50cf\u3092\u53ce\u96c6\u3059\u308b\n\u3053\u3053\u306f\u8a73\u3057\u304f\u306f\u66f8\u3051\u306a\u3044\u306e\u3067\u4ee5\u4e0b\u306e\u8a18\u4e8b\u3092\u53c2\u8003\u306b\u3057\u3066\u304f\u3060\u3055\u3044\u3002\nPython: BeautifulSoup4 \u3092\u4f7f\u3063\u3066 Web \u30b5\u30a4\u30c8\u3092\u30b9\u30af\u30ec\u30a4\u30d4\u30f3\u30b0\u3059\u308b\nPython\u3068Beautiful Soup\u3067\u30b9\u30af\u30ec\u30a4\u30d4\u30f3\u30b0\n\u53d6\u5f97\u3057\u305f\u753b\u50cf\u306f\u5973\u512a\u3054\u3068\u306b\u30c7\u30a3\u30ec\u30af\u30c8\u30ea\u3092\u5206\u3051\u3066\u4fdd\u5b58\u3057\u307e\u3059\u3002\n./folder\n    |--- /actress1\n    |        |--- image1.jpg\n    |        |--- image2.jpg\n    |        |--- image3.jpg\n    |\n    |--- /actress2\n    |        .\n    |        .\n    |--- /actress3\n    .\n    .\n    .\n\n\n\n2. dlib\u3067\u9854\u753b\u50cf\u3092\u5207\u308a\u629c\u304f\n\u753b\u50cf\u8a8d\u8b58\u3068\u3044\u3048\u3070OpenCV\u304c\u6709\u540d\u3060\u3068\u601d\u3044\u307e\u3059\u304cdlib vs OpenCV face detection\u3092\u898b\u308b\u3068\u3001\u9854\u62bd\u51fa\u306b\u95a2\u3057\u3066\u306fdlib\u3068\u3044\u3046\u30e9\u30a4\u30d6\u30e9\u30ea\u306e\u307b\u3046\u304c\u8aa4\u691c\u51fa\u304c\u5c11\u306a\u304f\u3088\u3055\u305d\u3046\u306a\u306e\u3067\u3001dlib\u3092\u4f7f\u3044\u307e\u3057\u305f\u3002\nimport os\nimport sys\nimport glob\nimport cv2\nfrom PIL import Image\nimport dlib\n\n\"\"\"\nINPUT_DIR\u306f(1.\u753b\u50cf\u3092\u53ce\u96c6\u3059\u308b)\u3067\u53d6\u5f97\u3057\u305f\u753b\u50cf\u306e\u30c7\u30a3\u30ec\u30af\u30c8\u30ea\u540d\nOUTPUT_DIR\u306f\u51fa\u529b\u30c7\u30a3\u30ec\u30af\u30c8\u30ea\u540d(\u30d5\u30a9\u30eb\u30c0\u69cb\u6210\u306fINPUT_DIR\u3068\u540c\u3058\u306b\u306a\u308b)\n\"\"\"\n\ndetector = dlib.get_frontal_face_detector()\n\n# \u5404\u5973\u512a\u306e\u30c7\u30a3\u30ec\u30af\u30c8\u30ea\u306e\u30ea\u30b9\u30c8\u3092\u53d6\u5f97\ndir_list = os.listdir(INPUT_DIR)\n\nfor i, dir_name in enumerate(dir_list):\n    if not os.path.exists(os.path.join(OUTPUT_DIR, dir_name)):\n        os.mkdir(os.path.join(OUTPUT_DIR, dir_name))\n    image_files = glob.glob(os.path.join(INPUT_DIR, dir_name, \"*.jpg\"))\n\n    for j, image_file in enumerate(image_files):\n        img = cv2.imread(image_file)\n        dets = detector(img, 1)\n        open_img = Image.open(image_file)\n\n        for k, d in enumerate(dets):\n            # \u30b5\u30a4\u30ba\u304c80\u4ee5\u4e0b\u306e\u753b\u50cf\u306f\u30b9\u30ad\u30c3\u30d7\u3059\u308b\n            if d.right()-d.left() < 80 or d.bottom()-d.top() < 80:\n                continue\n\n            image_file = image_file.replace(INPUT_DIR, OUTPUT_DIR)\n            # \uff11\u3064\u306e\u753b\u50cf\u306b\u5fa9\u6570\u306e\u9854\u304c\u3042\u308b\u3068\u51fa\u529b\u306e\u30d5\u30a1\u30a4\u30eb\u540d\u304c\u304b\u3076\u308b\u306e\u3067\u5909\u66f4\n            output_file = image_file.replace('.jpg', '_'+str(k)+'.jpg')\n\n            cropped_img = open_img.crop((d.left(), d.top(), d.right(), d.bottom()))\n            cropped_img.resize((96,96)).save(output_file, 'JPEG', quality=100, optimize=True)\n\ndlib\u306f\u9854\u62bd\u51fa\u3060\u3051\u3067\u306a\u304f\u3001\u9854\u306e\u76ee\u3001\u9f3b\u3001\u8f2a\u90ed\u306a\u3069\u306e\u5668\u5b98\u3092\u691c\u51fa\u3059\u308b\u6a5f\u80fd\u3082\u3042\u308a\u307e\u3059\u3002\n\n\u53c2\u8003\u8cc7\u6599\ndlib.net face_detect.py\n\n3. \u30c7\u30fc\u30bf\u62e1\u5f35 (Data augmentation)\nimport os\nimport math\nimport random\nimport glob\nimport numpy as np\nfrom scipy import misc\nfrom PIL import Image\nimport cv2\n\n#\u3000\u5de6\u53f3\u53cd\u8ee2\ndef flip_left_right(image):\n    return image[:, -1::-1]\n\n# \u8f1d\u5ea6\u306e\u5909\u66f4\ndef random_brightness(image, max_delta=63, seed=None):\n    img = np.array(image)\n    delta = np.random.uniform(-max_delta, max_delta)\n    image = Image.fromarray(np.uint8(img + delta))\n    return image\n\n# \u30b3\u30f3\u30c8\u30e9\u30b9\u30c8\u5909\u66f4\ndef random_contrast(image, lower, upper, seed=None):\n    factor = np.random.uniform(-lower, upper)\n    mean = (image[0] + image[1] + image[2]).astype(np.float32) / 3\n    img = np.zeros(image.shape, np.float32)\n    for i in range(0, 3):\n        img[i] = (img[i] - mean) * factor + mean\n    return img\n\n# \u753b\u50cf\u5207\u308a\u629c\u304d\ndef crop(image, name, crop_size, padding_size):\n    (width, height) = image.shape\n    cropped_images = []\n    for i in xrange(0, width, padding_size):\n        for j in xrange(0, height, padding_size):\n            box = (i, j, i+crop_size, j+crop_size) #left, upper, right, lower\n            cropped_name = name + '_' + str(i) + '_' + str(j) + '.jpg'\n            cropped_image = image[i:i+crop_size, j:j+crop_size]\n            resized_image = cv2.resize(cropped_image, (IMAGE_SIZE, IMAGE_SIZE))\n            cropped_images.append(resized_image)\n\n    return cropped_images\n\n# \u30c7\u30fc\u30bf\u62e1\u5f35\n# data_num\u306b\u6307\u5b9a\u3057\u305f\u5024\u306b\u306a\u308b\u307e\u3067\u300c\u5de6\u53f3\u53cd\u8ee2\u300d\u300c\u8f1d\u5ea6\u306e\u5909\u66f4\u300d\u300c\u30b3\u30f3\u30c8\u30e9\u30b9\u30c8\u306e\u5909\u66f4\u300d\u300c\u5207\u308a\u629c\u304d\u300d\u3059\u308b\ndef data_augmentation(image_files, data_num):\n    image_list = []\n    file_num = len(image_files)\n\n    for image_file in image_files:\n        image_list.append(misc.imread(image_file))\n\n    if file_num >= data_num:\n        return image_list\n\n    # flip left right\n    random.shuffle(image_list)\n    for image in image_list:\n        flipped_image = flip_left_right(image)\n        image_list.append(flipped_image)\n        if len(image_list) == data_num:\n            return image_list\n\n    # random brightness\n    random.shuffle(image_list)\n    for image in image_list:\n        brightness_image = random_brightness(image)\n        image_list.append(brightness_image)\n        if len(image_list) == data_num:\n            return image_list\n\n    # random contrast\n    random.shuffle(image_list)\n    for image in image_list:\n        contrast_image = random_contrast(image)\n        image_list.append(contrast_image)\n        if len(image_list) == data_num:\n            return image_list\n\n    # cropping\n    random.shuffle(image_list)\n    image_list.clear()\n    cropped_size = int(IMAGE_SIZE * 0.75)\n    padding_size = IMAGE_SIZE - cropped_size\n    for image in image_list:\n        cropped_image_list = crop(image, 'image', cropped_size, padding_size)\n        for cropped_image in cropped_image_list:\n            image_list.append(cropped_image)\n            if len(image_list) == data_num:\n                return image_list\n\n    return image_list\n\n\ndir_list = os.listdir(INPUT_DIR)\n\nfor dir in dir_list:\n    image_files = glob.glob(os.path.join(input_dir, dir, \"*.jpg\"))\n    if len(image_files) == 0:\n        continue\n\n\n    image_list = data_augmentation(image_files, 1000)\n\n    for i, image in enumerate(image_list):\n        image = whitening(image)\n        misc.imsave(os.path.join(OUTPUT_DIR, dir, str(i) + '.jpg'), image)\n\n\n\n\u53c2\u8003\u8cc7\u6599\nChainer\u306eimagenet\u30b5\u30f3\u30d7\u30eb\u3067\u5b66\u7fd2\u30c7\u30fc\u30bf\u306e\u62e1\u5f35/whitening\n\n4. \u30c7\u30fc\u30bf\u3092numpy\u5f62\u5f0f\u306b\u5909\u63db\u3059\u308b\nimport os\nimport sys\nimport glob\nimport random\nimport numpy as np\nfrom scipy import misc\n\n\"\"\" Get files from specified directory \"\"\"\ndef load_data_from_dir(input_dir_name, input_dir_list, start_index, test_freq):\n    train_list = []\n    test_list = []\n\n    for dir_index, dir_name in enumerate(input_dir_list):\n        image_files = glob.glob(os.path.join(input_dir_name, dir_name, \"*.jpg\"))\n        train_count = 0\n        test_count = 0\n        print('directory:{} index:{}'.format(dir_name, dir_index + start_index))\n\n        for file_index, file_name in enumerate(image_files):\n            image = misc.imread(file_name)\n            label = np.int32(dir_index + start_index)\n            if not file_index % test_freq == 0: # set train datq\n                train_list.append((dir_name, image, label))\n                train_count += 1\n            else:\n                test_list.append((dir_name, image, label))\n                test_count += 1\n\n        print(\"directory:{} total:{} train:{} test:{}\".format(\n               dir_name, train_count + test_count, train_count, test_count))\n\n    return train_list, test_list\n\n\"\"\" Save data in a numpy format \"\"\"\ndef save_dataset_numpy(data_list, image_path, label_path):\n    image_list = []\n    label_list = []\n    for _, image, label in data_list:\n        image_list.append(image)\n        label_list.append(label)\n\n    image_data = np.array(image_list, dtype=np.float32)\n    label_data = np.array(label_list, dtype=np.int32)\n\n    np.save(image_path, image_data)\n    np.save(label_path, label_data)\n\nfor i in xrange(0, len(DIR_LIST), 10):\n    # 10\u30af\u30e9\u30b9\u3054\u3068\u306b\u30d5\u30a1\u30a4\u30eb\u3092\u4f5c\u6210\u3059\u308b\n    train_list, test_list = load_data_from_dir(INPUT_DIR, dir_list[i:i+args.interval], i, 10)\n\n    train_data_path = os.path.join(OUTPUT_DIR, 'train', 'data-{}.npy'.format(i+args.interval))\n    train_label_path = os.path.join(OUTPUT_DIR, 'train', 'label-{}.npy'.format(i+args.interval))\n    test_data_path = os.path.join(OUTPUT_DIR, 'test', 'data-{}.npy'.format(i+args.interval))\n    test_label_path = os.path.join(OUTPUT_DIR, 'test', 'label-{}.npy'.format(i+args.interval))\n\n    save_dataset_numpy(train_list, train_data_path, train_label_path)\n    save_dataset_numpy(test_list, test_data_path, test_label_path)\n\n\n\n5. chainer\u3067\u9854\u753b\u50cf\u3092\u5b66\u7fd2\u3059\u308b\n\u6700\u521d\u306fTensorflow\u3067\u4f5c\u3063\u3066\u307f\u305f\u306e\u3067\u3059\u304c\u3001\u500b\u4eba\u7684\u306b\u306f\u4f59\u8a08\u306a\u6a5f\u80fd\u304c\u591a\u304b\u3063\u305f\u306e\u3067Chainer\u306b\u5207\u308a\u66ff\u3048\u307e\u3057\u305f\u3002\n\u5b66\u7fd2\u306f\u6700\u521d\u306bCIFAR-10(\u4e00\u822c\u7269\u4f53\u306e10\u30af\u30e9\u30b9\u5206\u985e)\u3067\u3061\u3083\u3093\u3068\u5b66\u7fd2\u3059\u308b\u3082\u306e\u3092\u3064\u304f\u3063\u3066\u304b\u3089\u3001\u5b9f\u969b\u306e\u30c7\u30fc\u30bf\u3092\u5b66\u7fd2\u3059\u308b\u3088\u3046\u306b\u3057\u307e\u3057\u305f\u3002\n\u30cd\u30c3\u30c8\u30ef\u30fc\u30af\u306fAlexNet\u306bBatch Normalization\u3092\u5165\u308c\u305f\u3082\u306e\u3092\u5c11\u3057\u5909\u3048\u3066\u4f7f\u7528\u3057\u307e\u3057\u305f\u3002\n\n\u5931\u6557\u3057\u305f\u3053\u3068\n\n\u6700\u521d\u304b\u3089multiprocessing\u3092\u4f7f\u3063\u3066(\u3053\u3093\u306a\u304b\u3093\u3058)\u3067\u4f5c\u6210\u3057\u305f\u306e\u3067\u3059\u304c\u3001\u30c7\u30d0\u30c3\u30b0\u304c\u7d50\u69cb\u5927\u5909\u3060\u3063\u305f\u306e\u3067\u3001\u6700\u521d\u306f\u672c\u5f53\u306b\u30b7\u30f3\u30d7\u30eb\u306a\u30d7\u30ed\u30b0\u30e9\u30e0\u3092\u4f5c\u3063\u305f\u307b\u3046\u304c\u3044\u3044\u3068\u601d\u3044\u307e\u3059\u3002\n\u753b\u50cf\u3092\u4e00\u6c17\u306b\u8aad\u307f\u8fbc\u3080\u3068\u30a4\u30f3\u30d7\u30c3\u30c8\u753b\u50cf\u3060\u3051\u30671.7GB\u7a0b\u5ea6\u3042\u308b\u306e\u3067\u30e1\u30e2\u30ea\u304c\u6b7b\u306b\u307e\u3059\u3002\u305d\u306e\u305f\u3081\u3001\u30bd\u30fc\u30b9\u306f\u6c5a\u304f\u306a\u308a\u307e\u3059\u304c\u3001\u30d0\u30c3\u30c1\u6bce\u306b\u30c7\u30fc\u30bf\u3092delete\u3057\u3066\u30e1\u30e2\u30ea\u3092\u89e3\u653e\u3059\u308b\u3088\u3046\u306bBatchIterator\u30af\u30e9\u30b9\u3092\u4f5c\u6210\u3057\u307e\u3057\u305f\u3002\n\n// 1\u679a\u5f53\u305f\u308a\u306e\u5927\u304d\u3055  \n96\u00d796\u00d73 = 27648(byte)\n\n// 1\u30af\u30e9\u30b9\u3042\u305f\u308a  \n27648\u00d71000 = 27648000(byte) = 26.4(MB)\n\n// \u5168\u4f53 (66\u30af\u30e9\u30b9) ... \u8a08\u7b97\u3042\u3063\u3066\u308b\uff1f \n26.4\u00d766 = 1742.4(MB) = 1.7(GB)\n\n\n\"\"\"\nBatch iterator class\n\nUsage:\nbatch_iter = BatchIter(DATA_DIR, 100)\n\nfor batch_data, batch_label in batch_iter:\n    batch_start_time = time.time()\n    x = np.asarray(batch_data, dtype=np.float32).transpose((0, 3, 1, 2))\n    t = np.asarray(train_batch_label, dtype=np.int32)\n    x = Variable(xp.asarray(x))\n    t = Variable(xp.asarray(t))\n\n    optimizer.update(model, x, t)\n\"\"\"\nclass BatchIter(object):\n    def __init__(self, data_dir, batch_size):\n        self.index = 0\n        self.batch_size = batch_size\n        self.data_files = glob.glob(os.path.join(data_dir, 'data-*.npy'))\n        self.label_files = glob.glob(os.path.join(data_dir, 'label-*.npy'))\n        data_size = 0\n        for data in self.data_files:\n            loaded_data = np.load(data)\n            data_size += loaded_data.shape[0]\n            del loaded_data\n        self.data_size = data_size\n\n        assert len(self.data_files) == len(self.label_files), \"Invalid data size.\"\n\n    def __iter__(self):\n        return self\n\n    def next(self):\n        if self.index >= self.data_size:\n            raise StopIteration()\n\n        data = np.zeros((self.batch_size, IMAGE_SIZE, IMAGE_SIZE, 3))\n        label = np.zeros((self.batch_size))\n        incremental_value = int(self.batch_size / len(self.data_files))\n\n        count = 0\n        for i in range(len(self.data_files)):\n            loaded_data = np.load(self.data_files[i])\n            loaded_label = np.load(self.label_files[i])\n            assert loaded_data.shape[0] == loaded_label.shape[0], \"Loaded data size is invalid.\"\n\n            perm = np.random.permutation(loaded_data.shape[0])\n            if i + 1 == len(self.data_files): # last item\n                incremental_value = self.batch_size - count\n                idx = perm[0:incremental_value]\n            else:\n                idx = perm[0:incremental_value]\n\n            data[count:count+incremental_value] = loaded_data[idx]\n            label[count:count+incremental_value] = loaded_label[idx]\n\n            count += incremental_value\n            del loaded_data\n            del loaded_label\n\n        self.index += self.batch_size\n        return data, label\n\n\n\u53c2\u8003\u8cc7\u6599\n\nCNN\n\u753b\u50cf\u8a8d\u8b58\u5206\u91ce\u3067\u306e\u30c7\u30a3\u30fc\u30d7\u30e9\u30fc\u30cb\u30f3\u30b0\u306e\u7814\u7a76\u52d5\u5411\n\u6df1\u5c64\u7573\u307f\u8fbc\u307f\u30cb\u30e5\u30fc\u30e9\u30eb\u30cd\u30c3\u30c8\u30ef\u30fc\u30af\u3092\u7528\u3044\u305f\u753b\u50cf\u30b9\u30b1\u30fc\u30ea\u30f3\u30b0\nCNN\u306e\u30c1\u30e5\u30fc\u30c8\u30ea\u30a2\u30eb\nTensorflow\nTensorFlow\u3067\u30a2\u30cb\u30e1\u3086\u308b\u3086\u308a\u306e\u5236\u4f5c\u4f1a\u793e\u3092\u8b58\u5225\u3059\u308b\nTensorFlow\u306b\u3088\u308b\u30c7\u30a3\u30fc\u30d7\u30e9\u30fc\u30cb\u30f3\u30b0\u3067\u3001\u30a2\u30a4\u30c9\u30eb\u306e\u9854\u3092\u8b58\u5225\u3059\u308b\nTensor Flow: How To\nChainer\nGitHub - chainer/examples/imagenet/\nGitHub - mitmul/chainer-cifar10\n\u306f\u3058\u3081\u3066\u306e\u30a2\u30cb\u30e1\u9854\u8a8d\u8b58 with Chainer\n\n\n6. \u5b66\u7fd2\u3057\u305f\u30e2\u30c7\u30eb\u304b\u3089\u4efb\u610f\u306e\u753b\u50cf\u306e\u4e88\u6e2c\u3092\u3059\u308b\ndef set_model(model_name, model_path):\n    model_fn = os.path.basename('models/' + model_name + '.py')\n    model = imp.load_source(model_fn.split('.')[0],\n                            'models/' + model_name + '.py').model\n\n    print('Load model from ', model_path)\n    serializers.load_hdf5(model_path, model)\n\n    return model\n\ndef set_optimizer(opt_name, opt_path, model):\n    if opt_name == 'MomentumSGD':\n        optimizer = optimizers.MomentumSGD(momentum=0.9)\n    elif opt_name == 'Adam':\n        optimizer = optimizers.Adam()\n    elif opt_name == 'AdaGrad':\n        optimizer = optimizers.AdaGrad()\n    else:\n        raise ValueError('Invalid architecture name')\n\n    optimizer.setup(model)\n\n    print('Load optimizer state from ', opt_path)\n    serializers.load_hdf5(opt_path, optimizer)\n\n    return optimizer\n\ndef detect_face(image_file):\n    detector = dlib.get_frontal_face_detector()\n    #img = cv2.imread(image_file)\n    image = misc.imread(image_file)\n    dets = detector(image, 1)\n    d = dets[0]\n    cropped_image = image[d.top():d.bottom(), d.left():d.right()]\n    resized_image = misc.imresize(cropped_image, (96, 96))\n    return resized_image\n\n\n# \u30e2\u30c7\u30eb\u8aad\u307f\u8fbc\u307f\nmodel = set_model(model_name, model_path)\noptimizer = set_optimizer(opt_name, opt_path, model)\ndetected_face_image = detect_face(input_image)\n\n# \u8aad\u307f\u8fbc\u3093\u3060\u30e2\u30c7\u30eb\u304b\u3089\u4e88\u6e2c\u3059\u308b\nx = np.asarray(detected_face_image, dtype=np.float32).transpose((0, 3, 1, 2))\nx = Variable(np.asarray(x), volatile='on') \npred = model.predict(x).data\n\n# \u30e9\u30d9\u30eb\u8aad\u307f\u8fbc\u307f (\u30e9\u30d9\u30eb\u7528\u306e\u30d5\u30a1\u30a4\u30eb\u306fnumpy\u5f62\u5f0f\u306e\u30d5\u30a1\u30a4\u30eb\u3092\u4f5c\u6210\u6642\u306b\u3064\u304f\u308b)\ncategories = np.loadtxt(label_path, str, delimiter=\"\\n\")\n\n# \u30b9\u30b3\u30a2\u306e\u9ad8\u3044\u9806\u306b\u4e26\u3073\u66ff\u3048\u308b\nscore = pred.reshape((pred.size,))\nresult = zip(score, categories)\nresult = sorted(result, reverse=True)\n\nresults = []\nfor i, (score, label) in enumerate(result[:10]):\n    if i == 5: break\n    print('num:{} score:{:.5f} label:{}'.format(i + 1, score * 100, label))\n    results.append({\n        'label': label,\n        'score': str(round(score * 100, 2))\n    })\n\n\n\u904b\u7528\u30b5\u30fc\u30d0\u30fc\n\u5168\u7136\u30c7\u30a3\u30fc\u30d7\u30e9\u30fc\u30cb\u30f3\u30b0\u3068\u95a2\u4fc2\u306a\u3044\u3067\u3059\u304c\u3001Web\u30b5\u30a4\u30c8\u69cb\u7bc9\u6642\u306b\u6700\u521d\u306fHeroku\u3068\u304b\u8a66\u3057\u305f\u3093\u3067\u3059\u304c\u3001\u6700\u7d42\u7684\u306bConoha\u306b\u3057\u307e\u3057\u305f\u3002\ndlib\u3068\u304bchainer\u3092\u4f7f\u3046\u3068\u304d\u306fHeroku\u3060\u3068\u30a4\u30f3\u30b9\u30c8\u30fc\u30eb\u3067\u7d50\u69cb\u82e6\u52b4\u3057\u307e\u3057\u305f\u3002Conoha\u306f\u5c11\u3057\u524d\u306f\u7a3c\u50cd\u7387\u306b\u554f\u984c\u304c\u3042\u3063\u305f\u3088\u3046\u3067\u3059\u304c\u3001\u30ea\u30cb\u30e5\u30fc\u30a2\u30eb\u3057\u3066\u3044\u3044\u304b\u3093\u3058\u306e\u3088\u3046\u3067\u3059\u3002\n\u3055\u304f\u3089VPS\u3068\u3082\u8ff7\u3063\u305f\u306e\u3067\u3059\u304c\u3001\u3055\u304f\u3089VPS\u306f\u521d\u671f\u8cbb\u7528\u304c\u304b\u304b\u308b\u306e\u306b\u5bfe\u3057\u3066Conoha\u306f\u521d\u671f\u8cbb\u7528\u7121\u6599\u306a\u306e\u304c\u6c7a\u3081\u624b\u3067\u3057\u305f\u3002\u3000\u3000\n\u5b66\u7fd2\u90e8\u5206\u306e\u30b3\u30fc\u30c9\u304c\u62bd\u8c61\u5316\u3055\u308c\u305fChainer Trainer\u3092\u4f7f\u3063\u3066\u307f\u305f\u8a18\u4e8b\u3082\u66f8\u3044\u3066\u307f\u305f\u306e\u3067\u3088\u304b\u3063\u305f\u3089\u53c2\u8003\u306b\u3057\u3066\u304f\u3060\u3055\u3044\u3002\nChainer Trainer\u3092\u4f7f\u3063\u3066\u72ec\u81ea\u30c7\u30fc\u30bf\u30bb\u30c3\u30c8\u306e\u5b66\u7fd2\u3092\u3057\u3066\u307f\u305f\n\u6700\u5f8c\u306b\u5ba3\u4f1d\u306b\u306a\u308a\u307e\u3059\u304c\u3001CNN\u3092\u4f7f\u3063\u3066AV\u5973\u512a\u306e\u985e\u4f3c\u753b\u50cf\u691c\u7d22\u3092\u3057\u305f\u30b5\u30a4\u30c8\u3092\u4f5c\u3063\u3066\u3044\u308b\u306e\u3067\u3001\u3088\u304b\u3063\u305f\u3089\u898b\u3066\u307f\u3066\u304f\u3060\u3055\u3044\u3002\nBabelink - \u985e\u4f3cAV\u5973\u512a\u691c\u7d22\u30b5\u30fc\u30d3\u30b9\n\u203b\u30a2\u30c0\u30eb\u30c8\u30b5\u30a4\u30c8\u306e\u305f\u3081\u3001\u95b2\u89a7\u306b\u306f\u5341\u5206\u6ce8\u610f\u3092\u3057\u3066\u304f\u3060\u3055\u3044\u3002\n## \u74b0\u5883\n\nPC: MacBook Air\nCPU: 1.4 GHz Intel Core i5\n\u30e1\u30e2\u30ea: 4GB\n\n\u3075\u3064\u3046\u306eMacBook Air\u3067\u3084\u3063\u305f\u306e\u3067\u3059\u304c\u3001\u5b66\u7fd2\u9045\u3044\u3057\u3001\u30e1\u30e2\u30ea\u4e0d\u8db3\u3067\u843d\u3061\u308b\u3057\u3067\u3084\u3063\u3071\u308a\u8f9b\u304b\u3063\u305f\u3067\u3059\u3002\n\n## \u304a\u304a\u307e\u304b\u306a\u6d41\u308c\n\n1. \u5404\u5973\u512a\u306e\u753b\u50cf\u3092\u53ce\u96c6\u3059\u308b\u3002\n2. dlib\u3067\u9854\u753b\u50cf\u3092\u5207\u308a\u53d6\u3063\u306696\u00d796\u306e\u5927\u304d\u3055\u306b\u30ea\u30b5\u30a4\u30ba\u3059\u308b\u3002\n3. 1\u4eba\u306b\u3064\u304d1000\u679a\u306e\u753b\u50cf\u306b\u306a\u308b\u3088\u3046\u30c7\u30fc\u30bf\u62e1\u5f35\u3059\u308b\u3002\n4. \u30c7\u30fc\u30bf\u3092numpy\u30d5\u30a1\u30a4\u30eb\u306b\u5909\u63db\u3059\u308b\u3002\n5. chainer\u3067\u9854\u753b\u50cf\u3092\u5b66\u7fd2\u3059\u308b\u3002\n6. \u5b66\u7fd2\u3057\u305f\u30e2\u30c7\u30eb\u304b\u3089\u4efb\u610f\u306e\u753b\u50cf\u306e\u4e88\u6e2c\u3092\u3059\u308b\u3002\n\n## 1. \u753b\u50cf\u3092\u53ce\u96c6\u3059\u308b\n\n\u3053\u3053\u306f\u8a73\u3057\u304f\u306f\u66f8\u3051\u306a\u3044\u306e\u3067\u4ee5\u4e0b\u306e\u8a18\u4e8b\u3092\u53c2\u8003\u306b\u3057\u3066\u304f\u3060\u3055\u3044\u3002\n\n[Python: BeautifulSoup4 \u3092\u4f7f\u3063\u3066 Web \u30b5\u30a4\u30c8\u3092\u30b9\u30af\u30ec\u30a4\u30d4\u30f3\u30b0\u3059\u308b](http://momijiame.tumblr.com/post/114227737756/python-beautifulsoup4-%E3%82%92%E4%BD%BF%E3%81%A3%E3%81%A6-web-%E3%82%B5%E3%82%A4%E3%83%88%E3%82%92%E3%82%B9%E3%82%AF%E3%83%AC%E3%82%A4%E3%83%94%E3%83%B3%E3%82%B0%E3%81%99%E3%82%8B)\n[Python\u3068Beautiful Soup\u3067\u30b9\u30af\u30ec\u30a4\u30d4\u30f3\u30b0](http://qiita.com/itkr/items/513318a9b5b92bd56185)\n\n\u53d6\u5f97\u3057\u305f\u753b\u50cf\u306f\u5973\u512a\u3054\u3068\u306b\u30c7\u30a3\u30ec\u30af\u30c8\u30ea\u3092\u5206\u3051\u3066\u4fdd\u5b58\u3057\u307e\u3059\u3002\n\n```\n./folder\n    |--- /actress1\n    |        |--- image1.jpg\n    |        |--- image2.jpg\n    |        |--- image3.jpg\n    |\n    |--- /actress2\n    |        .\n    |        .\n    |--- /actress3\n    .\n    .\n    .\n    \n```\n\n## 2. dlib\u3067\u9854\u753b\u50cf\u3092\u5207\u308a\u629c\u304f\n\n\u753b\u50cf\u8a8d\u8b58\u3068\u3044\u3048\u3070OpenCV\u304c\u6709\u540d\u3060\u3068\u601d\u3044\u307e\u3059\u304c[dlib vs OpenCV face detection](https://www.youtube.com/watch?v=LsK0hzcEyHI)\u3092\u898b\u308b\u3068\u3001\u9854\u62bd\u51fa\u306b\u95a2\u3057\u3066\u306fdlib\u3068\u3044\u3046\u30e9\u30a4\u30d6\u30e9\u30ea\u306e\u307b\u3046\u304c\u8aa4\u691c\u51fa\u304c\u5c11\u306a\u304f\u3088\u3055\u305d\u3046\u306a\u306e\u3067\u3001dlib\u3092\u4f7f\u3044\u307e\u3057\u305f\u3002\n\n```py\nimport os\nimport sys\nimport glob\nimport cv2\nfrom PIL import Image\nimport dlib\n\n\"\"\"\nINPUT_DIR\u306f(1.\u753b\u50cf\u3092\u53ce\u96c6\u3059\u308b)\u3067\u53d6\u5f97\u3057\u305f\u753b\u50cf\u306e\u30c7\u30a3\u30ec\u30af\u30c8\u30ea\u540d\nOUTPUT_DIR\u306f\u51fa\u529b\u30c7\u30a3\u30ec\u30af\u30c8\u30ea\u540d(\u30d5\u30a9\u30eb\u30c0\u69cb\u6210\u306fINPUT_DIR\u3068\u540c\u3058\u306b\u306a\u308b)\n\"\"\"\n\ndetector = dlib.get_frontal_face_detector()\n\n# \u5404\u5973\u512a\u306e\u30c7\u30a3\u30ec\u30af\u30c8\u30ea\u306e\u30ea\u30b9\u30c8\u3092\u53d6\u5f97\ndir_list = os.listdir(INPUT_DIR)\n\nfor i, dir_name in enumerate(dir_list):\n    if not os.path.exists(os.path.join(OUTPUT_DIR, dir_name)):\n        os.mkdir(os.path.join(OUTPUT_DIR, dir_name))\n    image_files = glob.glob(os.path.join(INPUT_DIR, dir_name, \"*.jpg\"))\n\n    for j, image_file in enumerate(image_files):\n        img = cv2.imread(image_file)\n        dets = detector(img, 1)\n        open_img = Image.open(image_file)\n\n        for k, d in enumerate(dets):\n            # \u30b5\u30a4\u30ba\u304c80\u4ee5\u4e0b\u306e\u753b\u50cf\u306f\u30b9\u30ad\u30c3\u30d7\u3059\u308b\n            if d.right()-d.left() < 80 or d.bottom()-d.top() < 80:\n                continue\n\n            image_file = image_file.replace(INPUT_DIR, OUTPUT_DIR)\n            # \uff11\u3064\u306e\u753b\u50cf\u306b\u5fa9\u6570\u306e\u9854\u304c\u3042\u308b\u3068\u51fa\u529b\u306e\u30d5\u30a1\u30a4\u30eb\u540d\u304c\u304b\u3076\u308b\u306e\u3067\u5909\u66f4\n            output_file = image_file.replace('.jpg', '_'+str(k)+'.jpg')\n\n            cropped_img = open_img.crop((d.left(), d.top(), d.right(), d.bottom()))\n            cropped_img.resize((96,96)).save(output_file, 'JPEG', quality=100, optimize=True)\n```\n\ndlib\u306f\u9854\u62bd\u51fa\u3060\u3051\u3067\u306a\u304f\u3001\u9854\u306e\u76ee\u3001\u9f3b\u3001\u8f2a\u90ed\u306a\u3069\u306e\u5668\u5b98\u3092\u691c\u51fa\u3059\u308b\u6a5f\u80fd\u3082\u3042\u308a\u307e\u3059\u3002\n\n#### \u53c2\u8003\u8cc7\u6599\n\n[dlib.net face_detect.py](http://dlib.net/face_detector.py.html)\n\n## 3. \u30c7\u30fc\u30bf\u62e1\u5f35 (Data augmentation)\n\n```py\nimport os\nimport math\nimport random\nimport glob\nimport numpy as np\nfrom scipy import misc\nfrom PIL import Image\nimport cv2\n\n#\u3000\u5de6\u53f3\u53cd\u8ee2\ndef flip_left_right(image):\n    return image[:, -1::-1]\n\n# \u8f1d\u5ea6\u306e\u5909\u66f4\ndef random_brightness(image, max_delta=63, seed=None):\n    img = np.array(image)\n    delta = np.random.uniform(-max_delta, max_delta)\n    image = Image.fromarray(np.uint8(img + delta))\n    return image\n\n# \u30b3\u30f3\u30c8\u30e9\u30b9\u30c8\u5909\u66f4\ndef random_contrast(image, lower, upper, seed=None):\n    factor = np.random.uniform(-lower, upper)\n    mean = (image[0] + image[1] + image[2]).astype(np.float32) / 3\n    img = np.zeros(image.shape, np.float32)\n    for i in range(0, 3):\n        img[i] = (img[i] - mean) * factor + mean\n    return img\n\n# \u753b\u50cf\u5207\u308a\u629c\u304d\ndef crop(image, name, crop_size, padding_size):\n    (width, height) = image.shape\n    cropped_images = []\n    for i in xrange(0, width, padding_size):\n        for j in xrange(0, height, padding_size):\n            box = (i, j, i+crop_size, j+crop_size) #left, upper, right, lower\n            cropped_name = name + '_' + str(i) + '_' + str(j) + '.jpg'\n            cropped_image = image[i:i+crop_size, j:j+crop_size]\n            resized_image = cv2.resize(cropped_image, (IMAGE_SIZE, IMAGE_SIZE))\n            cropped_images.append(resized_image)\n\n    return cropped_images\n\n# \u30c7\u30fc\u30bf\u62e1\u5f35\n# data_num\u306b\u6307\u5b9a\u3057\u305f\u5024\u306b\u306a\u308b\u307e\u3067\u300c\u5de6\u53f3\u53cd\u8ee2\u300d\u300c\u8f1d\u5ea6\u306e\u5909\u66f4\u300d\u300c\u30b3\u30f3\u30c8\u30e9\u30b9\u30c8\u306e\u5909\u66f4\u300d\u300c\u5207\u308a\u629c\u304d\u300d\u3059\u308b\ndef data_augmentation(image_files, data_num):\n    image_list = []\n    file_num = len(image_files)\n        \n    for image_file in image_files:\n        image_list.append(misc.imread(image_file))\n\n    if file_num >= data_num:\n        return image_list\n\n    # flip left right\n    random.shuffle(image_list)\n    for image in image_list:\n        flipped_image = flip_left_right(image)\n        image_list.append(flipped_image)\n        if len(image_list) == data_num:\n            return image_list\n\n    # random brightness\n    random.shuffle(image_list)\n    for image in image_list:\n        brightness_image = random_brightness(image)\n        image_list.append(brightness_image)\n        if len(image_list) == data_num:\n            return image_list\n\n    # random contrast\n    random.shuffle(image_list)\n    for image in image_list:\n        contrast_image = random_contrast(image)\n        image_list.append(contrast_image)\n        if len(image_list) == data_num:\n            return image_list\n\n    # cropping\n    random.shuffle(image_list)\n    image_list.clear()\n    cropped_size = int(IMAGE_SIZE * 0.75)\n    padding_size = IMAGE_SIZE - cropped_size\n    for image in image_list:\n        cropped_image_list = crop(image, 'image', cropped_size, padding_size)\n        for cropped_image in cropped_image_list:\n            image_list.append(cropped_image)\n            if len(image_list) == data_num:\n                return image_list\n\n    return image_list\n\n\ndir_list = os.listdir(INPUT_DIR)\n\nfor dir in dir_list:\n    image_files = glob.glob(os.path.join(input_dir, dir, \"*.jpg\"))\n    if len(image_files) == 0:\n        continue\n\n     \n    image_list = data_augmentation(image_files, 1000)\n\n    for i, image in enumerate(image_list):\n        image = whitening(image)\n        misc.imsave(os.path.join(OUTPUT_DIR, dir, str(i) + '.jpg'), image)\n\n```\n\n#### \u53c2\u8003\u8cc7\u6599\n[Chainer\u306eimagenet\u30b5\u30f3\u30d7\u30eb\u3067\u5b66\u7fd2\u30c7\u30fc\u30bf\u306e\u62e1\u5f35/whitening](http://qiita.com/knok/items/a07d5fc4c254c7da7ea2)\n\n\n## 4. \u30c7\u30fc\u30bf\u3092numpy\u5f62\u5f0f\u306b\u5909\u63db\u3059\u308b\n\n```py\nimport os\nimport sys\nimport glob\nimport random\nimport numpy as np\nfrom scipy import misc\n\n\"\"\" Get files from specified directory \"\"\"\ndef load_data_from_dir(input_dir_name, input_dir_list, start_index, test_freq):\n    train_list = []\n    test_list = []\n\n    for dir_index, dir_name in enumerate(input_dir_list):\n        image_files = glob.glob(os.path.join(input_dir_name, dir_name, \"*.jpg\"))\n        train_count = 0\n        test_count = 0\n        print('directory:{} index:{}'.format(dir_name, dir_index + start_index))\n\n        for file_index, file_name in enumerate(image_files):\n            image = misc.imread(file_name)\n            label = np.int32(dir_index + start_index)\n            if not file_index % test_freq == 0: # set train datq\n                train_list.append((dir_name, image, label))\n                train_count += 1\n            else:\n                test_list.append((dir_name, image, label))\n                test_count += 1\n\n        print(\"directory:{} total:{} train:{} test:{}\".format(\n               dir_name, train_count + test_count, train_count, test_count))\n\n    return train_list, test_list\n\n\"\"\" Save data in a numpy format \"\"\"\ndef save_dataset_numpy(data_list, image_path, label_path):\n    image_list = []\n    label_list = []\n    for _, image, label in data_list:\n        image_list.append(image)\n        label_list.append(label)\n\n    image_data = np.array(image_list, dtype=np.float32)\n    label_data = np.array(label_list, dtype=np.int32)\n\n    np.save(image_path, image_data)\n    np.save(label_path, label_data)\n\nfor i in xrange(0, len(DIR_LIST), 10):\n    # 10\u30af\u30e9\u30b9\u3054\u3068\u306b\u30d5\u30a1\u30a4\u30eb\u3092\u4f5c\u6210\u3059\u308b\n    train_list, test_list = load_data_from_dir(INPUT_DIR, dir_list[i:i+args.interval], i, 10)\n\n    train_data_path = os.path.join(OUTPUT_DIR, 'train', 'data-{}.npy'.format(i+args.interval))\n    train_label_path = os.path.join(OUTPUT_DIR, 'train', 'label-{}.npy'.format(i+args.interval))\n    test_data_path = os.path.join(OUTPUT_DIR, 'test', 'data-{}.npy'.format(i+args.interval))\n    test_label_path = os.path.join(OUTPUT_DIR, 'test', 'label-{}.npy'.format(i+args.interval))\n\n    save_dataset_numpy(train_list, train_data_path, train_label_path)\n    save_dataset_numpy(test_list, test_data_path, test_label_path)\n\n```\n\n## 5. chainer\u3067\u9854\u753b\u50cf\u3092\u5b66\u7fd2\u3059\u308b\n\n\u6700\u521d\u306fTensorflow\u3067\u4f5c\u3063\u3066\u307f\u305f\u306e\u3067\u3059\u304c\u3001\u500b\u4eba\u7684\u306b\u306f\u4f59\u8a08\u306a\u6a5f\u80fd\u304c\u591a\u304b\u3063\u305f\u306e\u3067Chainer\u306b\u5207\u308a\u66ff\u3048\u307e\u3057\u305f\u3002\n\n\u5b66\u7fd2\u306f\u6700\u521d\u306b[CIFAR-10](http://aidiary.hatenablog.com/entry/20151014/1444827123)(\u4e00\u822c\u7269\u4f53\u306e10\u30af\u30e9\u30b9\u5206\u985e)\u3067\u3061\u3083\u3093\u3068\u5b66\u7fd2\u3059\u308b\u3082\u306e\u3092\u3064\u304f\u3063\u3066\u304b\u3089\u3001\u5b9f\u969b\u306e\u30c7\u30fc\u30bf\u3092\u5b66\u7fd2\u3059\u308b\u3088\u3046\u306b\u3057\u307e\u3057\u305f\u3002\n\n\u30cd\u30c3\u30c8\u30ef\u30fc\u30af\u306f[AlexNet\u306bBatch Normalization\u3092\u5165\u308c\u305f\u3082\u306e](https://github.com/pfnet/chainer/blob/master/examples/imagenet/alexbn.py)\u3092\u5c11\u3057\u5909\u3048\u3066\u4f7f\u7528\u3057\u307e\u3057\u305f\u3002\n\n\n#### \u5931\u6557\u3057\u305f\u3053\u3068\n\n+ \u6700\u521d\u304b\u3089multiprocessing\u3092\u4f7f\u3063\u3066([\u3053\u3093\u306a\u304b\u3093\u3058](https://github.com/mitmul/chainer-cifar10/blob/master/train.py))\u3067\u4f5c\u6210\u3057\u305f\u306e\u3067\u3059\u304c\u3001\u30c7\u30d0\u30c3\u30b0\u304c\u7d50\u69cb\u5927\u5909\u3060\u3063\u305f\u306e\u3067\u3001\u6700\u521d\u306f\u672c\u5f53\u306b\u30b7\u30f3\u30d7\u30eb\u306a\u30d7\u30ed\u30b0\u30e9\u30e0\u3092\u4f5c\u3063\u305f\u307b\u3046\u304c\u3044\u3044\u3068\u601d\u3044\u307e\u3059\u3002\n\n+ \u753b\u50cf\u3092\u4e00\u6c17\u306b\u8aad\u307f\u8fbc\u3080\u3068\u30a4\u30f3\u30d7\u30c3\u30c8\u753b\u50cf\u3060\u3051\u30671.7GB\u7a0b\u5ea6\u3042\u308b\u306e\u3067\u30e1\u30e2\u30ea\u304c\u6b7b\u306b\u307e\u3059\u3002\u305d\u306e\u305f\u3081\u3001\u30bd\u30fc\u30b9\u306f\u6c5a\u304f\u306a\u308a\u307e\u3059\u304c\u3001\u30d0\u30c3\u30c1\u6bce\u306b\u30c7\u30fc\u30bf\u3092`delete`\u3057\u3066\u30e1\u30e2\u30ea\u3092\u89e3\u653e\u3059\u308b\u3088\u3046\u306b`BatchIterator`\u30af\u30e9\u30b9\u3092\u4f5c\u6210\u3057\u307e\u3057\u305f\u3002\n\n```\n// 1\u679a\u5f53\u305f\u308a\u306e\u5927\u304d\u3055  \n96\u00d796\u00d73 = 27648(byte)\n\n// 1\u30af\u30e9\u30b9\u3042\u305f\u308a  \n27648\u00d71000 = 27648000(byte) = 26.4(MB)\n\n// \u5168\u4f53 (66\u30af\u30e9\u30b9) ... \u8a08\u7b97\u3042\u3063\u3066\u308b\uff1f \n26.4\u00d766 = 1742.4(MB) = 1.7(GB)\n```\n\n```py\n\n\"\"\"\nBatch iterator class\n\nUsage:\nbatch_iter = BatchIter(DATA_DIR, 100)\n\nfor batch_data, batch_label in batch_iter:\n    batch_start_time = time.time()\n    x = np.asarray(batch_data, dtype=np.float32).transpose((0, 3, 1, 2))\n    t = np.asarray(train_batch_label, dtype=np.int32)\n    x = Variable(xp.asarray(x))\n    t = Variable(xp.asarray(t))\n\n    optimizer.update(model, x, t)\n\"\"\"\nclass BatchIter(object):\n    def __init__(self, data_dir, batch_size):\n        self.index = 0\n        self.batch_size = batch_size\n        self.data_files = glob.glob(os.path.join(data_dir, 'data-*.npy'))\n        self.label_files = glob.glob(os.path.join(data_dir, 'label-*.npy'))\n        data_size = 0\n        for data in self.data_files:\n            loaded_data = np.load(data)\n            data_size += loaded_data.shape[0]\n            del loaded_data\n        self.data_size = data_size\n\n        assert len(self.data_files) == len(self.label_files), \"Invalid data size.\"\n\n    def __iter__(self):\n        return self\n\n    def next(self):\n        if self.index >= self.data_size:\n            raise StopIteration()\n\n        data = np.zeros((self.batch_size, IMAGE_SIZE, IMAGE_SIZE, 3))\n        label = np.zeros((self.batch_size))\n        incremental_value = int(self.batch_size / len(self.data_files))\n\n        count = 0\n        for i in range(len(self.data_files)):\n            loaded_data = np.load(self.data_files[i])\n            loaded_label = np.load(self.label_files[i])\n            assert loaded_data.shape[0] == loaded_label.shape[0], \"Loaded data size is invalid.\"\n\n            perm = np.random.permutation(loaded_data.shape[0])\n            if i + 1 == len(self.data_files): # last item\n                incremental_value = self.batch_size - count\n                idx = perm[0:incremental_value]\n            else:\n                idx = perm[0:incremental_value]\n\n            data[count:count+incremental_value] = loaded_data[idx]\n            label[count:count+incremental_value] = loaded_label[idx]\n\n            count += incremental_value\n            del loaded_data\n            del loaded_label\n\n        self.index += self.batch_size\n        return data, label\n```\n\n#### \u53c2\u8003\u8cc7\u6599  \n\n* CNN\n[\u753b\u50cf\u8a8d\u8b58\u5206\u91ce\u3067\u306e\u30c7\u30a3\u30fc\u30d7\u30e9\u30fc\u30cb\u30f3\u30b0\u306e\u7814\u7a76\u52d5\u5411](http://ibisml.org/archive/ibis2013/pdfs/ibis2013-okatani.pdf)\n[\u6df1\u5c64\u7573\u307f\u8fbc\u307f\u30cb\u30e5\u30fc\u30e9\u30eb\u30cd\u30c3\u30c8\u30ef\u30fc\u30af\u3092\u7528\u3044\u305f\u753b\u50cf\u30b9\u30b1\u30fc\u30ea\u30f3\u30b0](http://postd.cc/image-scaling-using-deep-convolutional-neural-networks-part1/)\n[CNN\u306e\u30c1\u30e5\u30fc\u30c8\u30ea\u30a2\u30eb](https://tech.d-itlab.co.jp/ml/666/)\n\n* Tensorflow\n[TensorFlow\u3067\u30a2\u30cb\u30e1\u3086\u308b\u3086\u308a\u306e\u5236\u4f5c\u4f1a\u793e\u3092\u8b58\u5225\u3059\u308b](http://kivantium.hateblo.jp/entry/2015/11/18/233834)\n[TensorFlow\u306b\u3088\u308b\u30c7\u30a3\u30fc\u30d7\u30e9\u30fc\u30cb\u30f3\u30b0\u3067\u3001\u30a2\u30a4\u30c9\u30eb\u306e\u9854\u3092\u8b58\u5225\u3059\u308b](http://d.hatena.ne.jp/sugyan/20160112/1452558576)\n[Tensor Flow: How To](http://kzky.hatenablog.com/entry/2015/12/24/Tensor_Flow%3A_How_To)\n\n* Chainer\n[GitHub - chainer/examples/imagenet/](https://github.com/pfnet/chainer/tree/master/examples/imagenet)\n[GitHub - mitmul/chainer-cifar10](https://github.com/mitmul/chainer-cifar10)\n[\u306f\u3058\u3081\u3066\u306e\u30a2\u30cb\u30e1\u9854\u8a8d\u8b58 with Chainer](http://qiita.com/homulerdora/items/9a9af1481bf63470731a)\n\n## 6. \u5b66\u7fd2\u3057\u305f\u30e2\u30c7\u30eb\u304b\u3089\u4efb\u610f\u306e\u753b\u50cf\u306e\u4e88\u6e2c\u3092\u3059\u308b\n\n```py\ndef set_model(model_name, model_path):\n    model_fn = os.path.basename('models/' + model_name + '.py')\n    model = imp.load_source(model_fn.split('.')[0],\n                            'models/' + model_name + '.py').model\n\n    print('Load model from ', model_path)\n    serializers.load_hdf5(model_path, model)\n\n    return model\n\ndef set_optimizer(opt_name, opt_path, model):\n    if opt_name == 'MomentumSGD':\n        optimizer = optimizers.MomentumSGD(momentum=0.9)\n    elif opt_name == 'Adam':\n        optimizer = optimizers.Adam()\n    elif opt_name == 'AdaGrad':\n        optimizer = optimizers.AdaGrad()\n    else:\n        raise ValueError('Invalid architecture name')\n\n    optimizer.setup(model)\n\n    print('Load optimizer state from ', opt_path)\n    serializers.load_hdf5(opt_path, optimizer)\n\n    return optimizer\n\ndef detect_face(image_file):\n    detector = dlib.get_frontal_face_detector()\n    #img = cv2.imread(image_file)\n    image = misc.imread(image_file)\n    dets = detector(image, 1)\n    d = dets[0]\n    cropped_image = image[d.top():d.bottom(), d.left():d.right()]\n    resized_image = misc.imresize(cropped_image, (96, 96))\n    return resized_image\n\n\n# \u30e2\u30c7\u30eb\u8aad\u307f\u8fbc\u307f\nmodel = set_model(model_name, model_path)\noptimizer = set_optimizer(opt_name, opt_path, model)\ndetected_face_image = detect_face(input_image)\n\n# \u8aad\u307f\u8fbc\u3093\u3060\u30e2\u30c7\u30eb\u304b\u3089\u4e88\u6e2c\u3059\u308b\nx = np.asarray(detected_face_image, dtype=np.float32).transpose((0, 3, 1, 2))\nx = Variable(np.asarray(x), volatile='on') \npred = model.predict(x).data\n\n# \u30e9\u30d9\u30eb\u8aad\u307f\u8fbc\u307f (\u30e9\u30d9\u30eb\u7528\u306e\u30d5\u30a1\u30a4\u30eb\u306fnumpy\u5f62\u5f0f\u306e\u30d5\u30a1\u30a4\u30eb\u3092\u4f5c\u6210\u6642\u306b\u3064\u304f\u308b)\ncategories = np.loadtxt(label_path, str, delimiter=\"\\n\")\n\n# \u30b9\u30b3\u30a2\u306e\u9ad8\u3044\u9806\u306b\u4e26\u3073\u66ff\u3048\u308b\nscore = pred.reshape((pred.size,))\nresult = zip(score, categories)\nresult = sorted(result, reverse=True)\n\nresults = []\nfor i, (score, label) in enumerate(result[:10]):\n    if i == 5: break\n    print('num:{} score:{:.5f} label:{}'.format(i + 1, score * 100, label))\n    results.append({\n        'label': label,\n        'score': str(round(score * 100, 2))\n    })\n```\n\n## \u904b\u7528\u30b5\u30fc\u30d0\u30fc\n\n\u5168\u7136\u30c7\u30a3\u30fc\u30d7\u30e9\u30fc\u30cb\u30f3\u30b0\u3068\u95a2\u4fc2\u306a\u3044\u3067\u3059\u304c\u3001Web\u30b5\u30a4\u30c8\u69cb\u7bc9\u6642\u306b\u6700\u521d\u306fHeroku\u3068\u304b\u8a66\u3057\u305f\u3093\u3067\u3059\u304c\u3001\u6700\u7d42\u7684\u306bConoha\u306b\u3057\u307e\u3057\u305f\u3002\ndlib\u3068\u304bchainer\u3092\u4f7f\u3046\u3068\u304d\u306fHeroku\u3060\u3068\u30a4\u30f3\u30b9\u30c8\u30fc\u30eb\u3067\u7d50\u69cb\u82e6\u52b4\u3057\u307e\u3057\u305f\u3002Conoha\u306f\u5c11\u3057\u524d\u306f\u7a3c\u50cd\u7387\u306b\u554f\u984c\u304c\u3042\u3063\u305f\u3088\u3046\u3067\u3059\u304c\u3001\u30ea\u30cb\u30e5\u30fc\u30a2\u30eb\u3057\u3066\u3044\u3044\u304b\u3093\u3058\u306e\u3088\u3046\u3067\u3059\u3002\n\u3055\u304f\u3089VPS\u3068\u3082\u8ff7\u3063\u305f\u306e\u3067\u3059\u304c\u3001\u3055\u304f\u3089VPS\u306f\u521d\u671f\u8cbb\u7528\u304c\u304b\u304b\u308b\u306e\u306b\u5bfe\u3057\u3066Conoha\u306f\u521d\u671f\u8cbb\u7528\u7121\u6599\u306a\u306e\u304c\u6c7a\u3081\u624b\u3067\u3057\u305f\u3002\u3000\u3000\n\n\u5b66\u7fd2\u90e8\u5206\u306e\u30b3\u30fc\u30c9\u304c\u62bd\u8c61\u5316\u3055\u308c\u305fChainer Trainer\u3092\u4f7f\u3063\u3066\u307f\u305f\u8a18\u4e8b\u3082\u66f8\u3044\u3066\u307f\u305f\u306e\u3067\u3088\u304b\u3063\u305f\u3089\u53c2\u8003\u306b\u3057\u3066\u304f\u3060\u3055\u3044\u3002\n[Chainer Trainer\u3092\u4f7f\u3063\u3066\u72ec\u81ea\u30c7\u30fc\u30bf\u30bb\u30c3\u30c8\u306e\u5b66\u7fd2\u3092\u3057\u3066\u307f\u305f](http://qiita.com/xolmon/items/6d1f0d38bc00b3b828b6)\n\n\u6700\u5f8c\u306b\u5ba3\u4f1d\u306b\u306a\u308a\u307e\u3059\u304c\u3001CNN\u3092\u4f7f\u3063\u3066AV\u5973\u512a\u306e\u985e\u4f3c\u753b\u50cf\u691c\u7d22\u3092\u3057\u305f\u30b5\u30a4\u30c8\u3092\u4f5c\u3063\u3066\u3044\u308b\u306e\u3067\u3001\u3088\u304b\u3063\u305f\u3089\u898b\u3066\u307f\u3066\u304f\u3060\u3055\u3044\u3002\n[Babelink - \u985e\u4f3cAV\u5973\u512a\u691c\u7d22\u30b5\u30fc\u30d3\u30b9](http://www.babelink.net/)\n\u203b\u30a2\u30c0\u30eb\u30c8\u30b5\u30a4\u30c8\u306e\u305f\u3081\u3001\u95b2\u89a7\u306b\u306f\u5341\u5206\u6ce8\u610f\u3092\u3057\u3066\u304f\u3060\u3055\u3044\u3002\n", "tags": ["Python", "DeepLearning", "Chainer", "OpenCV", "dlib"]}