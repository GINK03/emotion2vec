{"context": "\n\n\u53d6\u308a\u6271\u3046\u30c7\u30fc\u30bf\u30aa\u30d6\u30b8\u30a7\u30af\u30c8\n\n\n\u8ad6\u6587\u30bf\u30a4\u30c8\u30eb \u3068 \u8ad6\u6587\u6982\u8981\uff08Abstract\uff09\u30c6\u30ad\u30b9\u30c8\u30c7\u30fc\u30bf \u3092\u683c\u7d0d\u3057\u305f csv\u3000\u3092 \u53d6\u308a\u8fbc\u3093\u3060 DataFrame\u578b\u30aa\u30d6\u30b8\u30a7\u30af\u30c8\n\n\n\u884c\u3046\u3053\u3068\n\n-1) \u5404\u8ad6\u6587\u306e\u5185\u5bb9 \u3092 \u8868\u3059 \u7279\u5fb4\u30d9\u30af\u30c8\u30eb \u3092 \u7d44\u6210\u3059\u308b\u3002\n-2) \u7d44\u6210\u3057\u305f\u7279\u5fb4\u30d9\u30af\u30c8\u30eb\u306f\u3001str\u578b\u3067\u3001DataFrame \u306e\u65b0\u8a2d\u5217\u306b\u683c\u7d0d\u3059\u308b\u3002\n-3) \u7279\u5fb4\u30d9\u30af\u30c8\u30eb\u306f\u3001\u4ee5\u4e0b\u306e\uff12\u3064\u3092\u7528\u610f\n  3-1) \u5404\u8ad6\u6587 \u306e \u6982\u8981\uff08Abstract\uff09 \u6587\u7ae0 \u306e \u51fa\u73fe\u30c8\u30fc\u30af\u30f3\u30fb\u30ea\u30b9\u30c8\uff08\uff11\u56de\u4ee5\u4e0a\u51fa\u73fe\uff1a\u300c\uff11\u300d\u3001\uff10\u56de\u51fa\u73fe\uff1a\u300c\uff10\u300d\uff09\n  3-2) \u5404\u8ad6\u6587 \u306e \u6982\u8981\uff08Abstract\uff09 \u6587\u7ae0 \u306e \u30c8\u30fc\u30af\u30f3\u51fa\u73fe\u56de\u6570\u30ea\u30b9\u30c8 \uff08\u203b \u5404\u8ad6\u6587\u306e\u6982\u8981\u5358\u8a9e\u6570\u3067\u9664\u7b97\u3059\u308b\u306a\u3069\u306e\u6b63\u898f\u5316\u51e6\u7406\u306f\u672a\u5b9f\u65bd\uff09  \n\n\nSQL \u306b\u3088\u308b \u30c7\u30fc\u30bf\u53d6\u5f97\n\n\n\u4ee5\u4e0b\u306eSQL\u3067\u53d6\u5f97\u3057\u305f\u30c7\u30fc\u30bf\u30bb\u30c3\u30c8\u3092\u3001paper_info.csv \u3067\u30d5\u30a1\u30a4\u30eb\u4fdd\u5b58\n\n\nSQL\nselect paper.paper_id,\n       author.name,\n       author.organization, \n       paper.paper_title, \n       paper.abstract\nfrom paper\njoin author\non paper.paper_id = author.paper_id\norder by paper_id desc\n\n\n\nPandas DataFrame \u3078\u306e \u30c7\u30fc\u30bf\u53d6\u308a\u8fbc\u307f\n\n\nPython3\nimport pandas as pd\npaper_df = pd.read_csv('paper_info.csv ')\n\n#paper_df.shape\n#paper_df.head()\n\n\n\n\u8ad6\u6587\u6982\u8981\u5217 \u3092 \u5f62\u614b\u7d20\u89e3\u6790\uff08MeCab \u3067 \u540d\u8a5e\u306e\u307f \u62bd\u51fa\uff09\n\n\nPython3\ndef get_token_list(text, hinshi):\n    import MeCab\n    token_list = []\n    mt = MeCab.Tagger(\"-Ochasen -d /usr/local/lib/mecab/dic/mecab-ipadic-neologd\")\n    mt.parse('') \n    node = mt.parseToNode(text)\n    while node:\n        feats = node.feature.split(',')\n        if feats[0] in hinshi :\n            try:\n                token_list.append(node.surface)\n            except:\n                print(\"err: \" + str(node.surface))\n\n        node = node.next\n\n    return token_list\n\n#hinshi = [\"\u540d\u8a5e\"]\n#res = get_token_list(\"\u65e5\u672c\u306f\u3001\u307e\u3060\u307e\u3060\u7d4c\u6e08\u6210\u9577\u3067\u304d\u308b\u56fd\u3060\u3068\u601d\u3046\u3002\", hinshi)\n#print(res)\n## ['\u65e5\u672c', '\u7d4c\u6e08\u6210\u9577', '\u56fd']\n\n\n\n\u5404\u8ad6\u6587\u306e\u6982\u8981\uff08Abstract\uff09\u6587\u7ae0 \u3092\u3001\u540d\u8a5e\u30ea\u30b9\u30c8 \u306b \u5909\u63db\n\n\nPython3\nabstract_token_list = [get_token_list(paper_abstract,  [\"\u540d\u8a5e\"]) for paper_abstract in list(paper_df['paper_abstract'])]\n\n\n\n\u7d50\u679c \u3092 DataFrame \u306e \u65b0\u898f\u30ab\u30e9\u30e0 \u306b \u683c\u7d0d\n\n\nPython3\npaper_df[\"tokens_in_paper_abstract\"] = None\n#len(list(paper_df[\"tokens_in_paper_abstract\"])) == paper_df.shape[0]\n# True\n\n# \u4ee5\u4e0b\u3001str()\u3067\u6587\u5b57\u5217\u578b\u306b\u578b\u5909\u63db\u3057\u306a\u3044\u3068\u3001\u30a8\u30e9\u30fc\u306b\u306a\u308b\nfor i in range(len(abstract_token_list)):\n    paper_df.ix[i, 'tokens_in_paper_abstract'] = str(abstract_token_list[i])\n\n#'tokens_in_paper_abstract' in paper_df.columns\n#print(paper_df.ix[0:3, ['paper_abstract', 'tokens_in_paper_abstract']])\n\n\n\n\u5404\u8ad6\u6587\u306e\u7279\u5fb4\u30d9\u30af\u30c8\u30eb\u2460\uff08\u5404\u30c8\u30fc\u30af\u30f3\u306e\u51fa\u73fe\u6709\u7121\uff09\u3092\u7d44\u6210\n\n\nPython3\n## \u3044\u305a\u308c\u304b\uff11\u4ef6\u4ee5\u4e0a\u306e\u8ad6\u6587\u306b\u51fa\u73fe\u3059\u308b\u30c8\u30fc\u30af\u30f3\u306e\u5168\u30ea\u30b9\u30c8\uff08\u91cd\u8907\u6392\u9664\uff09\u3092\u7528\u610f\n## http://d.hatena.ne.jp/xef/20121027/p2\n## http://stackoverflow.com/questions/8689184/nameerror-name-reduce-is-not-defined-in-python\n\n# \u4e8c\u91cd\u30ea\u30b9\u30c8\u3092\u30cd\u30b9\u30c8\u3055\u308c\u3066\u3044\u306a\u3044\u30ea\u30b9\u30c8\u306b\u5909\u63db\uff08flatten\u51e6\u7406\uff09\nfrom functools import reduce\nfrom operator import add\ntmp_list = reduce(add, abstract_token_list)\n# print(len(tmp_list))\n\n# \u91cd\u8907\u6392\u9664\u3057\u3001token\u306e\u30e6\u30cb\u30fc\u30af\u30fb\u30ea\u30b9\u30c8\u3092\u7528\u610f\npaper_abstract_uniq_token_list = list(set(tmp_list))\n# print(len(paper_abstract_uniq_token_list))\n# print(paper_abstract_uniq_token_list[0:10])\n\n# \u96f6\u884c\u5217\u3092\u7528\u610f\n## \uff08\u884c\u6570\uff09 \u8ad6\u6587\u672c\u6570\uff08\uff1dDataFrame \u306e \u884c\u6570\uff09\n## \uff08\u5217\u6570\uff09 paper_abstract_uniq_token_list \u306e \u8981\u7d20\u6570\nshape = (len(paper_df.index), len(paper_abstract_uniq_token_list))\n# print(shape)\n\nimport numpy as np\nR = np.zeros(shape) \n\n# \u8ad6\u6587\uff11\u4ef6\u3054\u3068\u306b\u3001\u6982\u8981\u30c6\u30ad\u30b9\u30c8\u4e2d\u3001\u30e6\u30cb\u30fc\u30af\u30fb\u30c8\u30fc\u30af\u30f3\u30ea\u30b9\u30c8\u306b\u683c\u7d0d\u3055\u308c\u305f\u5404token\u304c\u51fa\u73fe\u3059\u308b\u304b\u3069\u3046\u304b\u3092\u30c1\u30a7\u30c3\u30af\u3059\u308b\u3002\n# \u5b58\u5728\u3059\u308b\u5834\u5408\u306f\u3001\u5f53\u8a72\u8ad6\u6587\u30c7\u30fc\u30bf\u756a\u53f7\uff08\u884c\u756a\u53f7\uff09\u306e\u5f53\u8a72\u30c8\u30fc\u30af\u30f3\u756a\u53f7\uff08\u5217\u756a\u53f7\uff09\u306b\u3001\u300c\uff11\u300d\u3092\u683c\u7d0d\u3059\u308b\u3002\n# \u5b58\u5728\u3057\u306a\u3044\u5834\u5408\u306f\u3001\u306a\u306b\u3082\u3057\u306a\u3044\u3002\uff08\u7d50\u679c\u3001ndarray\u578b\u30aa\u30d6\u30b8\u30a7\u30af\u30c8\u300cR\u300d\u306b\u683c\u7d0d\u3055\u308c\u3066\u3044\u308b\u300c\uff10\u300d\u304c\u305d\u306e\u307e\u307e\u7dad\u6301\u3055\u308c\u308b\nfor i in paper_df.index:  # i \u306f\u3001DataFrame\u306e\u5404\u884c\uff08\uff1d\u5404\u8ad6\u6587\u30c7\u30fc\u30bf\uff09 \u306e Index\u756a\u53f7\n    token_list_of_this_doc = paper_df.ix[i, 'tokens_in_paper_abstract']\n    for (n, token) in enumerate(paper_abstract_uniq_token_list): # \u5168token\u30ea\u30b9\u30c8\u304b\u3089\u3001token\u3092\uff11\u3064\u305a\u3064\u53d6\u308a\u51fa\u3059\n        if token in token_list_of_this_doc: # token \u304c\u3001\u3042\u308b\u8ad6\u6587\u306e\u6982\u8981\u6b04\u306b\u51fa\u73fe\u3059\u308b\u304b\u3069\u3046\u304b\u3092\u30c1\u30a7\u30c3\u30af\n            R[i , n] = 1 # \u51fa\u73fe\u3059\u308b\u306a\u3089\u3001\u305d\u306e\u8ad6\u6587Index\u756a\u53f7\u306e\u884c\u306e\u3001\u3044\u307e\u30c1\u30a7\u30c3\u30af\u3092\u7d42\u3048\u305ftoken\u306eIndex\u756a\u53f7\u884c\u306b\u3001\u300c\uff11\u300d\u3092\u683c\u7d0d\n        else:\n            pass # \u51fa\u73fe\u3057\u306a\u3044\u5834\u5408\u306f\u3001\u306a\u306b\u3082\u3057\u306a\u3044\uff08\u203b ndarray\u578b\u30aa\u30d6\u30b8\u30a7\u30af\u30c8\u300cR\u300d\u306b\u683c\u7d0d\u6e08\u307f\u306e\u300c\uff10\u300d\u304c\u3001\u6539\u5909\u3055\u308c\u305a\u306b\u6b8b\u308b\uff09\n\n#import types\n#type(R)\n## numpy.ndarray\n\n#1 in R[0]\n#1 in R[10]\n\n# R \u306e\u884c\u6570\u306f\u3001\u8ad6\u6587DataFrame\u306e\u884c\u6570\uff08\u8ad6\u6587\u672c\u6570\uff09\u306b\u4e00\u81f4\u3059\u308b\n# len(R[: , 1]) == paper_df.shape[0]\n## TRUE\n\n\n\nDatFrame \u306b\u5217\u3092\u65b0\u8a2d\u3057\u3066\u3001\u5404\u8ad6\u6587\u306e\u7279\u5fb4\u30d9\u30af\u30c8\u30eb \u3092 \u683c\u7d0d\n\n\nPython3\n# None \u3067\u521d\u671f\u5316\u3057\u305f\u5217\u3092\u7528\u610f\uff08\u5217\u540d\uff1a\"token_exisits_or_not_feature_vector\"\uff09\npaper_df[\"token_exisits_or_not_feature_vector\"] = None\n\n# \u5217\u306b\u3001\u7279\u5fb4\u30d9\u30af\u30c8\u30eb \u3092 \u683c\u7d0d\nfor i in range(len(abstract_token_list)):\n    paper_df.ix[i, \"token_exisits_or_not_feature_vector\"] = str(R[i])\n\n\n# \u4e0a\u306f\u3001\u4ee5\u4e0b\u3068\u540c\u3058\n#for i in range(paper_df.shape[0]):\n#    paper_df.ix[i, \"token_exisits_or_not_feature_vector\"] = str(R[i])\n\n# print(paper_df.ix[0, \"token_exisits_or_not_feature_vector\"])\n# print(paper_df.ix[10, \"token_exisits_or_not_feature_vector\"])\n# print(paper_df.ix[10, [\"tokens_in_paper_abstract\", \"token_exisits_or_not_feature_vector\"]])\n\n\n\n\n\u5404\u8ad6\u6587\u306e\u7279\u5fb4\u30d9\u30af\u30c8\u30eb\u2461\uff08\u5404\u30c8\u30fc\u30af\u30f3\u306e\u51fa\u73fe\u56de\u6570\uff09\u3092\u7d44\u6210\n\n\n\u51fa\u73fe\u6709\u7121\uff080 or 1\uff09 \u3067\u306f\u306a\u304f\u3001 \u51fa\u73fe\u56de\u6570 \u306e \u7279\u5fb4\u30d9\u30af\u30c8\u30eb \u3092 \u751f\u6210\u3057\u3001DataFrame \u306e \u65b0\u898f\u5217 \u306b \u683c\u7d0d\u3059\u308b\n\n\uff08\u53c2\u8003\uff09\n* \u300cPython\u3067\u5358\u8a9e\u306e\u6570\u3048\u4e0a\u3052\u3068\u304b\u3059\u308b\u306a\u3089Counter\u3092\u4f7f\u3046\u3068\u4fbf\u5229\u306a\u306f\u306a\u3057\u300d\n\nPython3\nR2 = np.zeros(shape) \n\nfrom collections import Counter\n\nfor i in paper_df.index:\n    token_list_of_this_doc = paper_df.ix[i, 'tokens_in_paper_abstract'].replace(\"[\",\"\").replace(\"]\",\"\").replace(\"'\",\"\").replace(\" \",\"\")\\\n                                                                      .split(\",\")\n\n    counter = Counter(token_list_of_this_doc)\n    token_count_dict = {}\n\n    for (word, cnt) in counter.most_common():\n        token_count_dict.update({word : cnt})\n\n    for (n, token) in enumerate(paper_abstract_uniq_token_list):\n        if token in token_count_dict.keys():\n            R2[i , n] = token_count_dict[token]\n        else:\n            pass    \n\n# print(R2)\n# print(R2[0])\n# R2.shape\n# len(R2[0]) == len(paper_abstract_uniq_token_list)\n## TRUE\n\n# R2.shape[0] == paper_df.shape[0]\n## TRUE\n\n# R2.shape[1] == len(paper_abstract_uniq_token_list)\n## TRUE\n\n# 3 in R2[13]\n# TRUE\n\n# R2[13]\n\n\n\nDatFrame \u306b\u5217\u3092\u65b0\u8a2d\u3057\u3066\u3001\u3053\u306e\u7279\u5fb4\u30d9\u30af\u30c8\u30eb \u3092 \u683c\u7d0d\n\npaper_df[\"token_count_feature_vector\"] = None\n\nfor i in range(paper_df.shape[0]):\n    paper_df.ix[i, \"token_count_feature_vector\"] = str(R2[i])\n\n# print(paper_df.ix[0, \"token_count_feature_vector\"])\n# print(paper_df.ix[13, \"token_count_feature_vector\"])\n\n\n\u5404\u8ad6\u6587\u884c\u3054\u3068\u306e\u7279\u5fb4\u30d9\u30af\u30c8\u30eb\u306f\u3001str\u578b\u3067\u683c\u7d0d\u3055\u308c\u3066\u3044\u308b\u3002\u53d6\u308a\u51fa\u3059\u6642\u306f\u3001list\u578b\u306b\u5909\u63db\u3059\u308b\u3002\n\n\nPython3\n## \u4ee5\u4e0b\u300113\u756a\u76ee\u306e\u8ad6\u6587\u306e\u7279\u5fb4\u30d9\u30af\u30c8\u30eb\u3092\u53d6\u308a\u51fa\u3059\u3002\n##\uff08\u5168\u8ad6\u6587\u306e\u7279\u5fb4\u30d9\u30af\u30c8\u30eb\u3092\u53d6\u308a\u51fa\u3059\u969b\u306f\u3001\u4ee5\u4e0b\u3092\u30e1\u30bd\u30c3\u30c9\u5316\u3057\u3066\u3001\u30ea\u30b9\u30c8\u5185\u5305\u8868\u8a18\u3067\u5b9f\u884c\u3059\u308b\u306a\u3069\u3059\u308b\uff09\ntoken_count_feature_vector_list_row13 = list(paper_df.ix[13, \"token_count_feature_vector\"]\\\n                                             .replace(\"[\", \"\").replace(\"]\", \"\").replace(\" \", \"\")\\\n                                             .replace(\"\\n\", \"\").replace(\"\", \"\").split(\".\"))\n# print(token_count_feature_vector_list_row13)\n\n\n\n\n\u3010 \u767a\u5c55 \u3011\n\n\nBoW\u60c5\u5831\u304b\u3089\u751f\u6210\u3057\u305f\u7279\u5fb4\u30d9\u30af\u30c8\u30eb\u3068\u3001\u8ad6\u6587\u5c5e\u6027\u60c5\u5831\uff08\u57f7\u7b46\u8005\u306e\u6240\u5c5e\u5927\u5b66\u3001\u7814\u7a76\u79d1\u30fb\u5c02\u9580\u9818\u57df\u3001\u8ad6\u6587\u63b2\u8f09\u5b66\u4f1a\u8a8c\u306a\u3069\uff09\u306e\u7279\u5fb4\u30d9\u30af\u30c8\u30eb\uff08DB\u4e0a\u306e\u30b3\u30fc\u30c9\u5024\u3092\u6570\u5024\u4e26\u3079\u305f\u6570\u5024\u30d9\u30af\u30c8\u30eb\u306e\u30a4\u30e1\u30fc\u30b8\uff09\u3092\u9023\u7d50\u3055\u305b\u305f\u7d71\u5408\u7279\u5fb4\u30d9\u30af\u30c8\u30eb\u306a\u3069\u3082\u3001\u8003\u3048\u3089\u308c\u308b\u3002\n\u4ee5\u4e0b\u3067\u306f\u3001\u6587\u66f8\u4e2d\u306e\u30c8\u30fc\u30af\u30f3\u306e\u51fa\u73fe\u7b87\u6240\u3054\u3068\u306b\u91cd\u307f\u4ed8\u3051\u3092\u4e0e\u3048\u305f\u4e0a\u3067\u3001\u30c8\u30fc\u30af\u30f3\u51fa\u73fe\u30ab\u30a6\u30f3\u30c8\u3092\u884c\u3063\u3066\u6587\u66f8\u7279\u5fb4\u30d9\u30af\u30c8\u30eb\u3092\u751f\u6210\u3057\u3066\u3044\u308b\n\n\u6749\u6d66 \u5e83\u548c \uff08\u540d\u53e4\u5c4b\u5927\u5b66\u5de5\u5b66\u90e8\uff09 \u300c\u8b70\u4e8b\u9332\u96c6\u5408\u304b\u3089\u306e\u7279\u5fb4\u8a9e\u62bd\u51fa\u3068\u305d\u306e\u5fdc\u7528\u306b\u95a2\u3059\u308b\u7814\u7a76\u300d\n\n\n\u3010 \u95a2\u9023\u8a18\u4e8b \u3011\n\n\nHirofumiYashima Qiita\u8a18\u4e8b\uff082016/04/22\uff09\u300cRedshift \u306a\u3069\u306eRDBMS \u4e0a \u306e \u5546\u54c1\u58f2\u308a\u4e0a\u3052\u30c6\u30fc\u30d6\u30eb \u3092 csv\u7d4c\u7531 \u3067 Python Pandas & Numpy \u306b\u53d6\u308a\u8fbc\u3093\u3067\u3001\u6a5f\u68b0\u5b66\u7fd2 \u3068 DeepLearning \u3067 \u5229\u7528\u53ef\u80fd \u306a \u9867\u5ba2\u5225\u5546\u54c1\u8cfc\u8cb7\u884c\u52d5 \u7279\u5fb4\u30d9\u30af\u30c8\u30eb & \u5354\u8abf\u30d5\u30a3\u30eb\u30bf\u30ea\u30f3\u30b0 \u3067 \u305d\u306e\u307e\u307e\u4f7f\u3048\u308b \u30e6\u30fc\u30b6\u30fb\u30a2\u30a4\u30c6\u30e0\u9023\u95a2 2\u6b21\u5143 \u884c\u5217 \u306b \u30c7\u30fc\u30bf\u5f62\u5f0f\u5909\u63db\u3059\u308b \u96db\u5f62\u30b3\u30fc\u30c9\u4f8b\u300d\nHirofumiYashima Qiita\u8a18\u4e8b\uff082016/02/09\uff09\u300cPython \u3067\u300c\u30c8\u30fc\u30af\u30f3\u540d, \u6587\u66f8\u540d, tfidf\u5024, Okapi 25\u5024\u300d\u306e\u5217\u3067\u69cb\u6210\u3055\u308c\u308b DataFrame\u30aa\u30d6\u30b8\u30a7\u30af\u30c8 \u3092 \u751f\u6210\u3059\u308b\u300d\nHirofumiYashima Qiita\u8a18\u4e8b\uff082016/01/06\uff09\u300cPython \u3067 MeCab \u3092\u4f7f\u3063\u3066\u3001\u6307\u5b9a\u3057\u305f\u54c1\u8a5e\u306e\u30c8\u30fc\u30af\u30f3\u3060\u3051\u3092\u30ea\u30b9\u30c8\u306b\u683c\u7d0d\u3057\u3066\u8fd4\u3059\u30e1\u30bd\u30c3\u30c9\u5b9a\u7fa9\u5f0f\u300d\n\n\n\n##__\u53d6\u308a\u6271\u3046\u30c7\u30fc\u30bf\u30aa\u30d6\u30b8\u30a7\u30af\u30c8__\n\n* \u8ad6\u6587\u30bf\u30a4\u30c8\u30eb \u3068 \u8ad6\u6587\u6982\u8981\uff08Abstract\uff09\u30c6\u30ad\u30b9\u30c8\u30c7\u30fc\u30bf \u3092\u683c\u7d0d\u3057\u305f csv\u3000\u3092 \u53d6\u308a\u8fbc\u3093\u3060 DataFrame\u578b\u30aa\u30d6\u30b8\u30a7\u30af\u30c8\n\n##__\u884c\u3046\u3053\u3068__\n\n-1) \u5404\u8ad6\u6587\u306e\u5185\u5bb9 \u3092 \u8868\u3059 \u7279\u5fb4\u30d9\u30af\u30c8\u30eb \u3092 \u7d44\u6210\u3059\u308b\u3002\n-2) \u7d44\u6210\u3057\u305f\u7279\u5fb4\u30d9\u30af\u30c8\u30eb\u306f\u3001str\u578b\u3067\u3001DataFrame \u306e\u65b0\u8a2d\u5217\u306b\u683c\u7d0d\u3059\u308b\u3002\n-3) \u7279\u5fb4\u30d9\u30af\u30c8\u30eb\u306f\u3001\u4ee5\u4e0b\u306e\uff12\u3064\u3092\u7528\u610f\n  3-1) \u5404\u8ad6\u6587 \u306e \u6982\u8981\uff08Abstract\uff09 \u6587\u7ae0 \u306e \u51fa\u73fe\u30c8\u30fc\u30af\u30f3\u30fb\u30ea\u30b9\u30c8\uff08\uff11\u56de\u4ee5\u4e0a\u51fa\u73fe\uff1a\u300c\uff11\u300d\u3001\uff10\u56de\u51fa\u73fe\uff1a\u300c\uff10\u300d\uff09\n  3-2) \u5404\u8ad6\u6587 \u306e \u6982\u8981\uff08Abstract\uff09 \u6587\u7ae0 \u306e \u30c8\u30fc\u30af\u30f3\u51fa\u73fe\u56de\u6570\u30ea\u30b9\u30c8 \uff08\u203b \u5404\u8ad6\u6587\u306e\u6982\u8981\u5358\u8a9e\u6570\u3067\u9664\u7b97\u3059\u308b\u306a\u3069\u306e\u6b63\u898f\u5316\u51e6\u7406\u306f\u672a\u5b9f\u65bd\uff09  \n\n___\n\n###__SQL \u306b\u3088\u308b \u30c7\u30fc\u30bf\u53d6\u5f97__\n\n* __\u4ee5\u4e0b\u306eSQL\u3067\u53d6\u5f97\u3057\u305f\u30c7\u30fc\u30bf\u30bb\u30c3\u30c8\u3092\u3001paper_info.csv \u3067\u30d5\u30a1\u30a4\u30eb\u4fdd\u5b58__\n\n\n```{SQL:SQL}\nselect paper.paper_id,\n       author.name,\n       author.organization, \n       paper.paper_title, \n       paper.abstract\nfrom paper\njoin author\non paper.paper_id = author.paper_id\norder by paper_id desc\n```\n\n###__Pandas DataFrame \u3078\u306e \u30c7\u30fc\u30bf\u53d6\u308a\u8fbc\u307f__\n\n```{Python:Python3}\nimport pandas as pd\npaper_df = pd.read_csv('paper_info.csv ')\n\n#paper_df.shape\n#paper_df.head()\n```\n\n###__\u8ad6\u6587\u6982\u8981\u5217 \u3092 \u5f62\u614b\u7d20\u89e3\u6790\uff08MeCab \u3067 \u540d\u8a5e\u306e\u307f \u62bd\u51fa\uff09__\n\n```{Python:Python3}\ndef get_token_list(text, hinshi):\n    import MeCab\n    token_list = []\n    mt = MeCab.Tagger(\"-Ochasen -d /usr/local/lib/mecab/dic/mecab-ipadic-neologd\")\n    mt.parse('') \n    node = mt.parseToNode(text)\n    while node:\n        feats = node.feature.split(',')\n        if feats[0] in hinshi :\n            try:\n                token_list.append(node.surface)\n            except:\n                print(\"err: \" + str(node.surface))\n\n        node = node.next\n\n    return token_list\n\n#hinshi = [\"\u540d\u8a5e\"]\n#res = get_token_list(\"\u65e5\u672c\u306f\u3001\u307e\u3060\u307e\u3060\u7d4c\u6e08\u6210\u9577\u3067\u304d\u308b\u56fd\u3060\u3068\u601d\u3046\u3002\", hinshi)\n#print(res)\n## ['\u65e5\u672c', '\u7d4c\u6e08\u6210\u9577', '\u56fd']\n```\n\n###__\u5404\u8ad6\u6587\u306e\u6982\u8981\uff08Abstract\uff09\u6587\u7ae0 \u3092\u3001\u540d\u8a5e\u30ea\u30b9\u30c8 \u306b \u5909\u63db__\n\n```{Python:Python3}\nabstract_token_list = [get_token_list(paper_abstract,  [\"\u540d\u8a5e\"]) for paper_abstract in list(paper_df['paper_abstract'])]\n```\n\n###__\u7d50\u679c \u3092 DataFrame \u306e \u65b0\u898f\u30ab\u30e9\u30e0 \u306b \u683c\u7d0d__\n\n```{Python:Python3}\npaper_df[\"tokens_in_paper_abstract\"] = None\n#len(list(paper_df[\"tokens_in_paper_abstract\"])) == paper_df.shape[0]\n# True\n\n# \u4ee5\u4e0b\u3001str()\u3067\u6587\u5b57\u5217\u578b\u306b\u578b\u5909\u63db\u3057\u306a\u3044\u3068\u3001\u30a8\u30e9\u30fc\u306b\u306a\u308b\nfor i in range(len(abstract_token_list)):\n    paper_df.ix[i, 'tokens_in_paper_abstract'] = str(abstract_token_list[i])\n\n#'tokens_in_paper_abstract' in paper_df.columns\n#print(paper_df.ix[0:3, ['paper_abstract', 'tokens_in_paper_abstract']])\n```\n\n###__\u5404\u8ad6\u6587\u306e\u7279\u5fb4\u30d9\u30af\u30c8\u30eb\u2460\uff08\u5404\u30c8\u30fc\u30af\u30f3\u306e\u51fa\u73fe\u6709\u7121\uff09\u3092\u7d44\u6210__\n\n```{Python:Python3}\n## \u3044\u305a\u308c\u304b\uff11\u4ef6\u4ee5\u4e0a\u306e\u8ad6\u6587\u306b\u51fa\u73fe\u3059\u308b\u30c8\u30fc\u30af\u30f3\u306e\u5168\u30ea\u30b9\u30c8\uff08\u91cd\u8907\u6392\u9664\uff09\u3092\u7528\u610f\n## http://d.hatena.ne.jp/xef/20121027/p2\n## http://stackoverflow.com/questions/8689184/nameerror-name-reduce-is-not-defined-in-python\n\n# \u4e8c\u91cd\u30ea\u30b9\u30c8\u3092\u30cd\u30b9\u30c8\u3055\u308c\u3066\u3044\u306a\u3044\u30ea\u30b9\u30c8\u306b\u5909\u63db\uff08flatten\u51e6\u7406\uff09\nfrom functools import reduce\nfrom operator import add\ntmp_list = reduce(add, abstract_token_list)\n# print(len(tmp_list))\n\n# \u91cd\u8907\u6392\u9664\u3057\u3001token\u306e\u30e6\u30cb\u30fc\u30af\u30fb\u30ea\u30b9\u30c8\u3092\u7528\u610f\npaper_abstract_uniq_token_list = list(set(tmp_list))\n# print(len(paper_abstract_uniq_token_list))\n# print(paper_abstract_uniq_token_list[0:10])\n\n# \u96f6\u884c\u5217\u3092\u7528\u610f\n## \uff08\u884c\u6570\uff09 \u8ad6\u6587\u672c\u6570\uff08\uff1dDataFrame \u306e \u884c\u6570\uff09\n## \uff08\u5217\u6570\uff09 paper_abstract_uniq_token_list \u306e \u8981\u7d20\u6570\nshape = (len(paper_df.index), len(paper_abstract_uniq_token_list))\n# print(shape)\n\nimport numpy as np\nR = np.zeros(shape) \n\n# \u8ad6\u6587\uff11\u4ef6\u3054\u3068\u306b\u3001\u6982\u8981\u30c6\u30ad\u30b9\u30c8\u4e2d\u3001\u30e6\u30cb\u30fc\u30af\u30fb\u30c8\u30fc\u30af\u30f3\u30ea\u30b9\u30c8\u306b\u683c\u7d0d\u3055\u308c\u305f\u5404token\u304c\u51fa\u73fe\u3059\u308b\u304b\u3069\u3046\u304b\u3092\u30c1\u30a7\u30c3\u30af\u3059\u308b\u3002\n# \u5b58\u5728\u3059\u308b\u5834\u5408\u306f\u3001\u5f53\u8a72\u8ad6\u6587\u30c7\u30fc\u30bf\u756a\u53f7\uff08\u884c\u756a\u53f7\uff09\u306e\u5f53\u8a72\u30c8\u30fc\u30af\u30f3\u756a\u53f7\uff08\u5217\u756a\u53f7\uff09\u306b\u3001\u300c\uff11\u300d\u3092\u683c\u7d0d\u3059\u308b\u3002\n# \u5b58\u5728\u3057\u306a\u3044\u5834\u5408\u306f\u3001\u306a\u306b\u3082\u3057\u306a\u3044\u3002\uff08\u7d50\u679c\u3001ndarray\u578b\u30aa\u30d6\u30b8\u30a7\u30af\u30c8\u300cR\u300d\u306b\u683c\u7d0d\u3055\u308c\u3066\u3044\u308b\u300c\uff10\u300d\u304c\u305d\u306e\u307e\u307e\u7dad\u6301\u3055\u308c\u308b\nfor i in paper_df.index:  # i \u306f\u3001DataFrame\u306e\u5404\u884c\uff08\uff1d\u5404\u8ad6\u6587\u30c7\u30fc\u30bf\uff09 \u306e Index\u756a\u53f7\n    token_list_of_this_doc = paper_df.ix[i, 'tokens_in_paper_abstract']\n    for (n, token) in enumerate(paper_abstract_uniq_token_list): # \u5168token\u30ea\u30b9\u30c8\u304b\u3089\u3001token\u3092\uff11\u3064\u305a\u3064\u53d6\u308a\u51fa\u3059\n        if token in token_list_of_this_doc: # token \u304c\u3001\u3042\u308b\u8ad6\u6587\u306e\u6982\u8981\u6b04\u306b\u51fa\u73fe\u3059\u308b\u304b\u3069\u3046\u304b\u3092\u30c1\u30a7\u30c3\u30af\n            R[i , n] = 1 # \u51fa\u73fe\u3059\u308b\u306a\u3089\u3001\u305d\u306e\u8ad6\u6587Index\u756a\u53f7\u306e\u884c\u306e\u3001\u3044\u307e\u30c1\u30a7\u30c3\u30af\u3092\u7d42\u3048\u305ftoken\u306eIndex\u756a\u53f7\u884c\u306b\u3001\u300c\uff11\u300d\u3092\u683c\u7d0d\n        else:\n            pass # \u51fa\u73fe\u3057\u306a\u3044\u5834\u5408\u306f\u3001\u306a\u306b\u3082\u3057\u306a\u3044\uff08\u203b ndarray\u578b\u30aa\u30d6\u30b8\u30a7\u30af\u30c8\u300cR\u300d\u306b\u683c\u7d0d\u6e08\u307f\u306e\u300c\uff10\u300d\u304c\u3001\u6539\u5909\u3055\u308c\u305a\u306b\u6b8b\u308b\uff09\n\n#import types\n#type(R)\n## numpy.ndarray\n\n#1 in R[0]\n#1 in R[10]\n\n# R \u306e\u884c\u6570\u306f\u3001\u8ad6\u6587DataFrame\u306e\u884c\u6570\uff08\u8ad6\u6587\u672c\u6570\uff09\u306b\u4e00\u81f4\u3059\u308b\n# len(R[: , 1]) == paper_df.shape[0]\n## TRUE\n```\n\n###__DatFrame \u306b\u5217\u3092\u65b0\u8a2d\u3057\u3066\u3001\u5404\u8ad6\u6587\u306e\u7279\u5fb4\u30d9\u30af\u30c8\u30eb \u3092 \u683c\u7d0d__\n\n```{Python:Python3}\n# None \u3067\u521d\u671f\u5316\u3057\u305f\u5217\u3092\u7528\u610f\uff08\u5217\u540d\uff1a\"token_exisits_or_not_feature_vector\"\uff09\npaper_df[\"token_exisits_or_not_feature_vector\"] = None\n\n# \u5217\u306b\u3001\u7279\u5fb4\u30d9\u30af\u30c8\u30eb \u3092 \u683c\u7d0d\nfor i in range(len(abstract_token_list)):\n    paper_df.ix[i, \"token_exisits_or_not_feature_vector\"] = str(R[i])\n\n\t\n# \u4e0a\u306f\u3001\u4ee5\u4e0b\u3068\u540c\u3058\n#for i in range(paper_df.shape[0]):\n#    paper_df.ix[i, \"token_exisits_or_not_feature_vector\"] = str(R[i])\n\n# print(paper_df.ix[0, \"token_exisits_or_not_feature_vector\"])\n# print(paper_df.ix[10, \"token_exisits_or_not_feature_vector\"])\n# print(paper_df.ix[10, [\"tokens_in_paper_abstract\", \"token_exisits_or_not_feature_vector\"]])\n```\n\n___\n\n###__\u5404\u8ad6\u6587\u306e\u7279\u5fb4\u30d9\u30af\u30c8\u30eb\u2461\uff08\u5404\u30c8\u30fc\u30af\u30f3\u306e\u51fa\u73fe\u56de\u6570\uff09\u3092\u7d44\u6210__\n\n* \u51fa\u73fe\u6709\u7121\uff080 or 1\uff09 \u3067\u306f\u306a\u304f\u3001 \u51fa\u73fe\u56de\u6570 \u306e \u7279\u5fb4\u30d9\u30af\u30c8\u30eb \u3092 \u751f\u6210\u3057\u3001DataFrame \u306e \u65b0\u898f\u5217 \u306b \u683c\u7d0d\u3059\u308b\n\n \uff08\u53c2\u8003\uff09\n* [\u300cPython\u3067\u5358\u8a9e\u306e\u6570\u3048\u4e0a\u3052\u3068\u304b\u3059\u308b\u306a\u3089Counter\u3092\u4f7f\u3046\u3068\u4fbf\u5229\u306a\u306f\u306a\u3057\u300d](http://qiita.com/hatchinee/items/a904c1f8d732a4686c9d)\n\n```{Python:Python3}\nR2 = np.zeros(shape) \n\nfrom collections import Counter\n\nfor i in paper_df.index:\n    token_list_of_this_doc = paper_df.ix[i, 'tokens_in_paper_abstract'].replace(\"[\",\"\").replace(\"]\",\"\").replace(\"'\",\"\").replace(\" \",\"\")\\\n                                                                      .split(\",\")\n        \n    counter = Counter(token_list_of_this_doc)\n    token_count_dict = {}\n    \n    for (word, cnt) in counter.most_common():\n        token_count_dict.update({word : cnt})\n\n    for (n, token) in enumerate(paper_abstract_uniq_token_list):\n        if token in token_count_dict.keys():\n            R2[i , n] = token_count_dict[token]\n        else:\n            pass    \n\n# print(R2)\n# print(R2[0])\n# R2.shape\n# len(R2[0]) == len(paper_abstract_uniq_token_list)\n## TRUE\n\n# R2.shape[0] == paper_df.shape[0]\n## TRUE\n\n# R2.shape[1] == len(paper_abstract_uniq_token_list)\n## TRUE\n\n# 3 in R2[13]\n# TRUE\n\n# R2[13]\n```\n\n###__DatFrame \u306b\u5217\u3092\u65b0\u8a2d\u3057\u3066\u3001\u3053\u306e\u7279\u5fb4\u30d9\u30af\u30c8\u30eb \u3092 \u683c\u7d0d__\n\n```\npaper_df[\"token_count_feature_vector\"] = None\n\nfor i in range(paper_df.shape[0]):\n    paper_df.ix[i, \"token_count_feature_vector\"] = str(R2[i])\n\n# print(paper_df.ix[0, \"token_count_feature_vector\"])\n# print(paper_df.ix[13, \"token_count_feature_vector\"])\n```\n\n####__\u5404\u8ad6\u6587\u884c\u3054\u3068\u306e\u7279\u5fb4\u30d9\u30af\u30c8\u30eb\u306f\u3001str\u578b\u3067\u683c\u7d0d\u3055\u308c\u3066\u3044\u308b\u3002\u53d6\u308a\u51fa\u3059\u6642\u306f\u3001list\u578b\u306b\u5909\u63db\u3059\u308b\u3002__\n\n```{Python:Python3}\n## \u4ee5\u4e0b\u300113\u756a\u76ee\u306e\u8ad6\u6587\u306e\u7279\u5fb4\u30d9\u30af\u30c8\u30eb\u3092\u53d6\u308a\u51fa\u3059\u3002\n##\uff08\u5168\u8ad6\u6587\u306e\u7279\u5fb4\u30d9\u30af\u30c8\u30eb\u3092\u53d6\u308a\u51fa\u3059\u969b\u306f\u3001\u4ee5\u4e0b\u3092\u30e1\u30bd\u30c3\u30c9\u5316\u3057\u3066\u3001\u30ea\u30b9\u30c8\u5185\u5305\u8868\u8a18\u3067\u5b9f\u884c\u3059\u308b\u306a\u3069\u3059\u308b\uff09\ntoken_count_feature_vector_list_row13 = list(paper_df.ix[13, \"token_count_feature_vector\"]\\\n                                             .replace(\"[\", \"\").replace(\"]\", \"\").replace(\" \", \"\")\\\n                                             .replace(\"\\n\", \"\").replace(\"\", \"\").split(\".\"))\n# print(token_count_feature_vector_list_row13)\n```\n\n___\n\n##__\u3010 \u767a\u5c55 \u3011__\n\n* BoW\u60c5\u5831\u304b\u3089\u751f\u6210\u3057\u305f\u7279\u5fb4\u30d9\u30af\u30c8\u30eb\u3068\u3001\u8ad6\u6587\u5c5e\u6027\u60c5\u5831\uff08\u57f7\u7b46\u8005\u306e\u6240\u5c5e\u5927\u5b66\u3001\u7814\u7a76\u79d1\u30fb\u5c02\u9580\u9818\u57df\u3001\u8ad6\u6587\u63b2\u8f09\u5b66\u4f1a\u8a8c\u306a\u3069\uff09\u306e\u7279\u5fb4\u30d9\u30af\u30c8\u30eb\uff08DB\u4e0a\u306e\u30b3\u30fc\u30c9\u5024\u3092\u6570\u5024\u4e26\u3079\u305f\u6570\u5024\u30d9\u30af\u30c8\u30eb\u306e\u30a4\u30e1\u30fc\u30b8\uff09\u3092\u9023\u7d50\u3055\u305b\u305f\u7d71\u5408\u7279\u5fb4\u30d9\u30af\u30c8\u30eb\u306a\u3069\u3082\u3001\u8003\u3048\u3089\u308c\u308b\u3002\n\n* \u4ee5\u4e0b\u3067\u306f\u3001\u6587\u66f8\u4e2d\u306e\u30c8\u30fc\u30af\u30f3\u306e\u51fa\u73fe\u7b87\u6240\u3054\u3068\u306b\u91cd\u307f\u4ed8\u3051\u3092\u4e0e\u3048\u305f\u4e0a\u3067\u3001\u30c8\u30fc\u30af\u30f3\u51fa\u73fe\u30ab\u30a6\u30f3\u30c8\u3092\u884c\u3063\u3066\u6587\u66f8\u7279\u5fb4\u30d9\u30af\u30c8\u30eb\u3092\u751f\u6210\u3057\u3066\u3044\u308b\n\n[\u6749\u6d66 \u5e83\u548c \uff08\u540d\u53e4\u5c4b\u5927\u5b66\u5de5\u5b66\u90e8\uff09 \u300c\u8b70\u4e8b\u9332\u96c6\u5408\u304b\u3089\u306e\u7279\u5fb4\u8a9e\u62bd\u51fa\u3068\u305d\u306e\u5fdc\u7528\u306b\u95a2\u3059\u308b\u7814\u7a76\u300d](http://www.nagao.nuie.nagoya-u.ac.jp/paper/11253.html)\n\n___\n\n##__\u3010 \u95a2\u9023\u8a18\u4e8b \u3011__\n\n* [HirofumiYashima Qiita\u8a18\u4e8b\uff082016/04/22\uff09\u300cRedshift \u306a\u3069\u306eRDBMS \u4e0a \u306e \u5546\u54c1\u58f2\u308a\u4e0a\u3052\u30c6\u30fc\u30d6\u30eb \u3092 csv\u7d4c\u7531 \u3067 Python Pandas & Numpy \u306b\u53d6\u308a\u8fbc\u3093\u3067\u3001\u6a5f\u68b0\u5b66\u7fd2 \u3068 DeepLearning \u3067 \u5229\u7528\u53ef\u80fd \u306a \u9867\u5ba2\u5225\u5546\u54c1\u8cfc\u8cb7\u884c\u52d5 \u7279\u5fb4\u30d9\u30af\u30c8\u30eb & \u5354\u8abf\u30d5\u30a3\u30eb\u30bf\u30ea\u30f3\u30b0 \u3067 \u305d\u306e\u307e\u307e\u4f7f\u3048\u308b \u30e6\u30fc\u30b6\u30fb\u30a2\u30a4\u30c6\u30e0\u9023\u95a2 2\u6b21\u5143 \u884c\u5217 \u306b \u30c7\u30fc\u30bf\u5f62\u5f0f\u5909\u63db\u3059\u308b \u96db\u5f62\u30b3\u30fc\u30c9\u4f8b\u300d](http://qiita.com/HirofumiYashima/items/a78f723d81b973709a93)\n* [HirofumiYashima Qiita\u8a18\u4e8b\uff082016/02/09\uff09\u300cPython \u3067\u300c\u30c8\u30fc\u30af\u30f3\u540d, \u6587\u66f8\u540d, tfidf\u5024, Okapi 25\u5024\u300d\u306e\u5217\u3067\u69cb\u6210\u3055\u308c\u308b DataFrame\u30aa\u30d6\u30b8\u30a7\u30af\u30c8 \u3092 \u751f\u6210\u3059\u308b\u300d](http://qiita.com/HirofumiYashima/items/49316894edf59ad025b5)\n* [HirofumiYashima Qiita\u8a18\u4e8b\uff082016/01/06\uff09\u300cPython \u3067 MeCab \u3092\u4f7f\u3063\u3066\u3001\u6307\u5b9a\u3057\u305f\u54c1\u8a5e\u306e\u30c8\u30fc\u30af\u30f3\u3060\u3051\u3092\u30ea\u30b9\u30c8\u306b\u683c\u7d0d\u3057\u3066\u8fd4\u3059\u30e1\u30bd\u30c3\u30c9\u5b9a\u7fa9\u5f0f\u300d](http://qiita.com/HirofumiYashima/items/bb326bc1ca62e337857e)\n", "tags": ["Python", "\u6a5f\u68b0\u5b66\u7fd2", "MachineLearning", "pandas", "\u81ea\u7136\u8a00\u8a9e\u51e6\u7406"]}