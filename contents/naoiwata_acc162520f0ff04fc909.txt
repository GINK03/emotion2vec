{"context": " More than 1 year has passed since last update.\n\n\u203b 2015-01-07 \u8ffd\u8a18\nboto \u3067\u306a\u304f awscli \u3092\u4f7f\u3048\u3070\u4e0b\u8a18\u306e\u3088\u3046\u306b\u3001s3 bucket \u30a2\u30c3\u30d7\u30ed\u30fc\u30c9\u30b9\u30af\u30ea\u30d7\u30c8\u3092\u66f8\u304b\u305a\u306b\u6e08\u3080\u3053\u3068\u3092\u6559\u3048\u3066\u3082\u3089\u3044\u307e\u3057\u305f\u3002awscli \u4fbf\u5229\u305d\u3046\u306a\u306e\u3067\u3053\u3061\u3089\u3092\u662f\u975e\u4f7f\u3044\u307e\u3057\u3087\u3046\u3002\n\u30a4\u30f3\u30b9\u30c8\u30fc\u30eb\n$ pip install awscli\nS3 \u60c5\u5831\u3092\u767b\u9332 (~/.aws/ \u306b\u8a2d\u5b9a\u30d5\u30a1\u30a4\u30eb\u304c\u751f\u6210\u3055\u308c\u308b\u3002)\n$ aws configure\n\u6307\u5b9a\u30d5\u30a9\u30eb\u30c0\u3092\u30a2\u30c3\u30d7\u30ed\u30fc\u30c9\n$ aws s3 sync <\u30d5\u30a9\u30eb\u30c0\u306e\u30d1\u30b9> s3://<bucket \u540d>\n\u30a2\u30c3\u30d7\u30ed\u30fc\u30c9\u3092\u78ba\u8a8d\n$ aws s3 ls <bucket \u540d>\n\u30c0\u30a6\u30f3\u30ed\u30fc\u30c9\u3082\u3067\u304d\u308b\n$ aws s3 sync s3://<bucket \u540d> <\u30c0\u30a6\u30f3\u30ed\u30fc\u30c9\u5148\u306e\u30d1\u30b9>\n\nAmason S3 \u306b\u6307\u5b9a\u306e\u30d5\u30a9\u30eb\u30c0\u3092\u30a2\u30c3\u30d7\u30ed\u30fc\u30c9\u3059\u308b\u30b9\u30af\u30ea\u30d7\u30c8\nGist \u306b\u8cbc\u3063\u3066\u3044\u305f\u306e\u3092 Qiita \u306b\u66f8\u3044\u3066\u307f\u307e\u3057\u305f.\nboto \u3092\u4f7f\u3063\u3066 Amason S3 \u306e bucket \u306b\u6307\u5b9a\u306e\u30d5\u30a9\u30eb\u30c0(\u4e2d\u306e\u30d5\u30a1\u30a4\u30eb\u5168\u3066)\u3092\u30a2\u30c3\u30d7\u30ed\u30fc\u30c9\u3057\u307e\u3059.\npip install boto \u306a\u3069\u3067 boto \u3092\u30a4\u30f3\u30b9\u30c8\u30fc\u30eb\u3057\u3066\u304a\u304d\u307e\u3057\u3087\u3046.\nACCESS_KEY_ID, SECRET_ACCESS_KEY, BUCKET_NAME \u3092\u8ffd\u8a18\u3057\u3066\u304a\u304d\u307e\u3059. \u4f8b\u3067\u306f 'Cache-Control: max-age=10' \u3068\u30d8\u30c3\u30c0\u3092\u66f8\u3044\u3066\u3044\u307e\u3059\u304c\u304a\u597d\u307f\u3067\u30d8\u30c3\u30c0\u3082\u8ffd\u8a18\u3057\u307e\u3059. \n\ndeploys3.py\n# -*- coding: utf-8 -*-\n\"\"\"deploy script to upload the files to AWS S3 bucket\n\nUsage:\n    $ python deploy_s3.py <folder name for deploy>\n\"\"\"\n\nimport os\nimport sys\nfrom boto.s3.connection import S3Connection\nfrom boto.s3.key import Key\n\n\nACCESS_KEY_ID = 'xxx'\nSECRET_ACCESS_KEY = 'xxx'\nBUCKET_NAME = 'xxx'\n\n\ndef main():\n    # check arguments\n    if len(sys.argv) is not 2:\n        print '[ERROR] wrong number of arguments. (required 1, got %s)' % len(sys.argv)\n        sys.exit(1)\n    _file_name = str(sys.argv[1])\n\n    # upload to S3\n    try:\n        upload_to_s3(_file_name)\n    except Exception, e:\n        raise e\n        print '[ERROR] upload to S3 has been failed.'\n    print '[OK] upload to S3 bucket has successfully completed. :)'\n\n\ndef upload_to_s3(file_name):\n    # connect to S3\n    s3 = S3Connection(ACCESS_KEY_ID, SECRET_ACCESS_KEY)\n    bucket = s3.get_bucket(BUCKET_NAME)\n    # upload with metadata and publish\n    fc = 0\n    for abspath, relpath in upload_files(file_name):\n        k = Key(bucket)\n        k.key = relpath\n        k.set_metadata('Cache-Control', 'max-age=10')\n        k.set_contents_from_filename(abspath)\n        k.make_public()\n        fc += 1\n    print '[OK] %s files are uploaded.' % fc\n\n\ndef upload_files(basedir):\n    parent_dir = os.path.dirname(os.path.realpath(basedir))\n    for (path, dirs, files) in os.walk(basedir):\n        for fn in files:\n            if fn.startswith('.'):\n                continue\n            abspath = os.path.join(path, fn)\n            yield (\n                abspath,\n                os.path.relpath(abspath, parent_dir).split(''.join([basedir, '/']))[1]\n            )\n\n\nif __name__ == '__main__':\n    main()\n\n\n\n\u3053\u306e\u30b9\u30af\u30ea\u30d7\u30c8\u3092\u4ee5\u4e0b\u306e\u3088\u3046\u306b\u5b9f\u884c\u3059\u308b\u3068 hoge \u30d5\u30a9\u30eb\u30c0\u5185\u306e\u4e0d\u53ef\u8996\u30d5\u30a1\u30a4\u30eb(. \u304b\u3089\u59cb\u307e\u308b\u30d5\u30a1\u30a4\u30eb)\u4ee5\u5916\u304c\u3059\u3079\u3066 S3 \u306e\u30eb\u30fc\u30c8\u30c7\u30a3\u30ec\u30af\u30c8\u30ea\u306b\u6307\u5b9a\u306e\u30d8\u30c3\u30c0\u3092\u4ed8\u3051\u3066\u30a2\u30c3\u30d7\u30ed\u30fc\u30c9\u3057 publish \u3055\u308c\u307e\u3059.\n$ python deploys3.py hoge\n\nQiita \u306e\u6295\u7a3f\u306e\u4f7f\u3044\u65b9\u3088\u304f\u308f\u304b\u3089\u306a\u3044... \nboto \u306e\u3088\u3046\u306a\u6a5f\u80fd\u306e gem \u3084 npm \u304c\u3082\u3057\u3042\u3063\u305f\u3089\u8ab0\u304b\u6559\u3048\u3066\u304f\u3060\u3055\u3044m()m\n## \u203b 2015-01-07 \u8ffd\u8a18\n\n`boto` \u3067\u306a\u304f [`awscli`](https://pypi.python.org/pypi/awscli) \u3092\u4f7f\u3048\u3070\u4e0b\u8a18\u306e\u3088\u3046\u306b\u3001s3 bucket \u30a2\u30c3\u30d7\u30ed\u30fc\u30c9\u30b9\u30af\u30ea\u30d7\u30c8\u3092\u66f8\u304b\u305a\u306b\u6e08\u3080\u3053\u3068\u3092\u6559\u3048\u3066\u3082\u3089\u3044\u307e\u3057\u305f\u3002`awscli` \u4fbf\u5229\u305d\u3046\u306a\u306e\u3067\u3053\u3061\u3089\u3092\u662f\u975e\u4f7f\u3044\u307e\u3057\u3087\u3046\u3002\n\n\u30a4\u30f3\u30b9\u30c8\u30fc\u30eb\n`$ pip install awscli`\n\nS3 \u60c5\u5831\u3092\u767b\u9332 (`~/.aws/` \u306b\u8a2d\u5b9a\u30d5\u30a1\u30a4\u30eb\u304c\u751f\u6210\u3055\u308c\u308b\u3002)\n`$ aws configure`\n\n\u6307\u5b9a\u30d5\u30a9\u30eb\u30c0\u3092\u30a2\u30c3\u30d7\u30ed\u30fc\u30c9\n`$ aws s3 sync <\u30d5\u30a9\u30eb\u30c0\u306e\u30d1\u30b9> s3://<bucket \u540d>`\n\n\u30a2\u30c3\u30d7\u30ed\u30fc\u30c9\u3092\u78ba\u8a8d\n`$ aws s3 ls <bucket \u540d>`\n\n\u30c0\u30a6\u30f3\u30ed\u30fc\u30c9\u3082\u3067\u304d\u308b\n`$ aws s3 sync s3://<bucket \u540d> <\u30c0\u30a6\u30f3\u30ed\u30fc\u30c9\u5148\u306e\u30d1\u30b9> `\n\n# Amason S3 \u306b\u6307\u5b9a\u306e\u30d5\u30a9\u30eb\u30c0\u3092\u30a2\u30c3\u30d7\u30ed\u30fc\u30c9\u3059\u308b\u30b9\u30af\u30ea\u30d7\u30c8\n\n[Gist](https://gist.github.com/naoiwata/8111246) \u306b\u8cbc\u3063\u3066\u3044\u305f\u306e\u3092 Qiita \u306b\u66f8\u3044\u3066\u307f\u307e\u3057\u305f.\n\n[boto](http://docs.pythonboto.org/en/latest/) \u3092\u4f7f\u3063\u3066 Amason S3 \u306e bucket \u306b\u6307\u5b9a\u306e\u30d5\u30a9\u30eb\u30c0(\u4e2d\u306e\u30d5\u30a1\u30a4\u30eb\u5168\u3066)\u3092\u30a2\u30c3\u30d7\u30ed\u30fc\u30c9\u3057\u307e\u3059.\n\n`pip install boto` \u306a\u3069\u3067 `boto` \u3092\u30a4\u30f3\u30b9\u30c8\u30fc\u30eb\u3057\u3066\u304a\u304d\u307e\u3057\u3087\u3046.\nACCESS_KEY_ID, SECRET_ACCESS_KEY, BUCKET_NAME \u3092\u8ffd\u8a18\u3057\u3066\u304a\u304d\u307e\u3059. \u4f8b\u3067\u306f 'Cache-Control: max-age=10' \u3068\u30d8\u30c3\u30c0\u3092\u66f8\u3044\u3066\u3044\u307e\u3059\u304c\u304a\u597d\u307f\u3067\u30d8\u30c3\u30c0\u3082\u8ffd\u8a18\u3057\u307e\u3059. \n\n```deploys3.py\n# -*- coding: utf-8 -*-\n\"\"\"deploy script to upload the files to AWS S3 bucket\n \nUsage:\n    $ python deploy_s3.py <folder name for deploy>\n\"\"\"\n \nimport os\nimport sys\nfrom boto.s3.connection import S3Connection\nfrom boto.s3.key import Key\n \n \nACCESS_KEY_ID = 'xxx'\nSECRET_ACCESS_KEY = 'xxx'\nBUCKET_NAME = 'xxx'\n\n\ndef main():\n    # check arguments\n    if len(sys.argv) is not 2:\n        print '[ERROR] wrong number of arguments. (required 1, got %s)' % len(sys.argv)\n        sys.exit(1)\n    _file_name = str(sys.argv[1])\n\n    # upload to S3\n    try:\n        upload_to_s3(_file_name)\n    except Exception, e:\n        raise e\n        print '[ERROR] upload to S3 has been failed.'\n    print '[OK] upload to S3 bucket has successfully completed. :)'\n \n \ndef upload_to_s3(file_name):\n    # connect to S3\n    s3 = S3Connection(ACCESS_KEY_ID, SECRET_ACCESS_KEY)\n    bucket = s3.get_bucket(BUCKET_NAME)\n    # upload with metadata and publish\n    fc = 0\n    for abspath, relpath in upload_files(file_name):\n        k = Key(bucket)\n        k.key = relpath\n        k.set_metadata('Cache-Control', 'max-age=10')\n        k.set_contents_from_filename(abspath)\n        k.make_public()\n        fc += 1\n    print '[OK] %s files are uploaded.' % fc\n \n \ndef upload_files(basedir):\n    parent_dir = os.path.dirname(os.path.realpath(basedir))\n    for (path, dirs, files) in os.walk(basedir):\n        for fn in files:\n            if fn.startswith('.'):\n                continue\n            abspath = os.path.join(path, fn)\n            yield (\n                abspath,\n                os.path.relpath(abspath, parent_dir).split(''.join([basedir, '/']))[1]\n            )\n \n \nif __name__ == '__main__':\n    main()\n\n```\n\n\u3053\u306e\u30b9\u30af\u30ea\u30d7\u30c8\u3092\u4ee5\u4e0b\u306e\u3088\u3046\u306b\u5b9f\u884c\u3059\u308b\u3068 hoge \u30d5\u30a9\u30eb\u30c0\u5185\u306e\u4e0d\u53ef\u8996\u30d5\u30a1\u30a4\u30eb(. \u304b\u3089\u59cb\u307e\u308b\u30d5\u30a1\u30a4\u30eb)\u4ee5\u5916\u304c\u3059\u3079\u3066 S3 \u306e\u30eb\u30fc\u30c8\u30c7\u30a3\u30ec\u30af\u30c8\u30ea\u306b\u6307\u5b9a\u306e\u30d8\u30c3\u30c0\u3092\u4ed8\u3051\u3066\u30a2\u30c3\u30d7\u30ed\u30fc\u30c9\u3057 publish \u3055\u308c\u307e\u3059.\n\n```\n$ python deploys3.py hoge\n```\n\n\nQiita \u306e\u6295\u7a3f\u306e\u4f7f\u3044\u65b9\u3088\u304f\u308f\u304b\u3089\u306a\u3044... \n`boto` \u306e\u3088\u3046\u306a\u6a5f\u80fd\u306e gem \u3084 npm \u304c\u3082\u3057\u3042\u3063\u305f\u3089\u8ab0\u304b\u6559\u3048\u3066\u304f\u3060\u3055\u3044m()m\n", "tags": ["Python2.7.5", "boto", "AWS"]}