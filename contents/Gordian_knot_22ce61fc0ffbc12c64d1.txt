{"context": "PRML\u7b2c\uff19\u7ae0\u3067\u306fEM\u30a2\u30eb\u30b4\u30ea\u30ba\u30e0\u304c\u7d39\u4ecb\u3055\u308c\u3066\u3044\u307e\u3059\u3002EM\u30a2\u30eb\u30b4\u30ea\u30ba\u30e0\u81ea\u4f53\u306f\u69d8\u3005\u306a\u3068\u3053\u308d\u3067\u4f7f\u3048\u308b\u624b\u6cd5\u3067\u3001\u79c1\u81ea\u8eab\u306fEM\u30a2\u30eb\u30b4\u30ea\u30ba\u30e0\u3068\u3042\u308b\u5206\u985e\u5668\u3092\u7d44\u307f\u5408\u308f\u305b\u3066\u3088\u308a\u30ce\u30a4\u30ba\u306b\u9811\u5065\u306a\u30af\u30e9\u30b9\u5206\u985e\u3092\u884c\u3063\u305f\u308a\u3057\u305f\u3053\u3068\u304c\u3042\u308a\u307e\u3059\u3002\u3057\u304b\u3057\u3001EM\u30a2\u30eb\u30b4\u30ea\u30ba\u30e0\u3092\u9069\u7528\u3059\u308b\u5fdc\u7528\u4f8b\u3068\u3057\u3066\u4e00\u756a\u6709\u540d\u306a\u6df7\u5408\u30ac\u30a6\u30b9\u5206\u5e03\u306b\u3088\u308b\u30af\u30e9\u30b9\u30bf\u30ea\u30f3\u30b0\u3092\u3057\u305f\u3053\u3068\u304c\u306a\u304b\u3063\u305f\u306e\u3067\u3001\u4eca\u56de\u306fEM\u30a2\u30eb\u30b4\u30ea\u30ba\u30e0\u306b\u3088\u308b\u6df7\u5408\u30ac\u30a6\u30b9\u5206\u5e03\u306e\u6700\u5c24\u63a8\u5b9a\u3092\u5b9f\u88c5\u3057\u307e\u3057\u305f\u3002\n\n\u6df7\u5408\u30ac\u30a6\u30b9\u5206\u5e03\u306e\u6700\u5c24\u63a8\u5b9a\n\n\u4f8b\u3048\u3070\u3001\u4e0a\u306e\u56f3\u306e\u9752\u70b9\u306e\u3088\u3046\u306a\u30c7\u30fc\u30bf\u70b9\u3092\u666e\u901a\u306e\u30ac\u30a6\u30b9\u5206\u5e03\np({\\bf x}) = \\mathcal{N}({\\bf x}|{\\bf\\mu},{\\bf\\Sigma})\np(x)=N(x|\u03bc,\u03a3)p(x)=N(x|\u03bc,\u03a3){p({\\bf x}) = \\mathcal{N}({\\bf x}|{\\bf\\mu},{\\bf\\Sigma})\n}\n\u3067\u30d5\u30a3\u30c3\u30c6\u30a3\u30f3\u30b0\u3059\u308b\u3068\u3001\n\n\u3053\u306e\u3088\u3046\u306b\u306a\u3063\u3066\u3057\u307e\u3044\u3001\u3053\u306e\u30b1\u30fc\u30b9\u3067\u306f\u5358\u5cf0\u306e\u30ac\u30a6\u30b9\u5206\u5e03\u306f\u9069\u5207\u306a\u30e2\u30c7\u30eb\u3067\u306f\u3042\u308a\u307e\u305b\u3093\u3002\u30c7\u30fc\u30bf\u70b9\u304c\uff13\u3064\u306e\u7fa4\u306b\u5206\u304b\u308c\u3066\u3044\u308b\u3053\u3068\u306b\u7740\u76ee\u3059\u308b\u3068\u3001\u4eca\u56de\u306e\u5834\u5408\u306f\uff13\u3064\u306e\u30ac\u30a6\u30b9\u5206\u5e03\u3092\u7528\u3044\u305f\u6df7\u5408\u30ac\u30a6\u30b9\u5206\u5e03\np({\\bf x}) = \\sum_{k=1}^3 \\pi_k\\mathcal{N}({\\bf x}|{\\bf\\mu}_k,{\\bf\\Sigma}_k)\np(x)=3\u2211k=1\u03c0kN(x|\u03bck,\u03a3k){p({\\bf x}) = \\sum_{k=1}^3 \\pi_k\\mathcal{N}({\\bf x}|{\\bf\\mu}_k,{\\bf\\Sigma}_k)\n}\n\u304c\u9069\u5207\u306a\u30e2\u30c7\u30eb\u3067\u3042\u308b\u3068\u8003\u3048\u3089\u308c\u307e\u3059\u3002\u305f\u3060\u3057\u3001\u2211k\u03c0k=1\\sum_k\\pi_k=1\u3068\u3057\u307e\u3059\u3002\u305d\u308c\u305e\u308c\u03bc1{\\bf\\mu}_1\u304c\u4e0a\u3001\u03bc2{\\bf\\mu}_2\u304c\u53f3\u4e0b\u3001\u03bc3{\\bf\\mu}_3\u304c\u5de6\u4e0b\u306e\u30c7\u30fc\u30bf\u70b9\u306e\u584a\u306e\u5e73\u5747\u306e\u3088\u3046\u306b\u3057\u307e\u3059\u3002\u3088\u3063\u3066\u584a\u3054\u3068\u306b\u30ac\u30a6\u30b9\u5206\u5e03\u3067\u30d5\u30a3\u30c3\u30c6\u30a3\u30f3\u30b0\u3059\u308c\u3070\u3044\u3044\u306e\u3067\u3059\u304c\u3001\u3069\u306e\u30c7\u30fc\u30bf\u70b9\u304c\u3069\u306e\u584a\u306b\u5c5e\u3059\u308b\u306e\u304b\u306f\u79c1\u305f\u3061\u4eba\u9593\u306b\u306f\u4e00\u76ee\u77ad\u7136\u3067\u3059\u304c\u3001\u6a5f\u68b0\u306b\u306f\u305d\u3093\u306a\u3053\u3068\u306f\u5206\u304b\u308a\u307e\u305b\u3093\u3002\nN\u500b\u306e\u30c7\u30fc\u30bf\u70b9\u306e\u5ea7\u6a19{xn}Nn=1\\{{\\bf x}_n\\}_{n=1}^N\u3092\u89b3\u6e2c\u5909\u6570\u3068\u3057\u3066\u3001\u3069\u306e\u30c7\u30fc\u30bf\u70b9\u304cK\u500b\u306e\u584a\u306e\u3046\u3061\u3069\u308c\u306b\u5c5e\u3059\u308b\u304b\u30921-of-k\u7b26\u53f7\u5316\u3067\u8868\u3059\u6f5c\u5728\u5909\u6570{zn}Nn=1\\{{\\bf z}_n\\}_{n=1}^N\u3068\u30d1\u30e9\u30e1\u30fc\u30bf{\u03c0k,\u03bck,\u03a3k}Kk=1\\{{\\bf\\pi}_k,{\\bf\\mu}_k,{\\bf\\Sigma}_k\\}_{k=1}^K\u3092\u540c\u6642\u306b\u63a8\u5b9a\u3057\u307e\u3059\u3002\u3053\u306e\u3088\u3046\u306b\u6f5c\u5728\u5909\u6570\u304c\u3042\u308b\u5834\u5408\u306fEM\u30a2\u30eb\u30b4\u30ea\u30ba\u30e0\u3092\u7528\u3044\u308b\u306e\u304c\u4e00\u822c\u7684\u3067\u3059\u3002\n\nEM\u30a2\u30eb\u30b4\u30ea\u30ba\u30e0\nPRML\u306e\u7b2c9.2.2\u9805\u306b\u6df7\u5408\u30ac\u30a6\u30b9\u5206\u5e03\u3092EM\u30a2\u30eb\u30b4\u30ea\u30ba\u30e0\u3067\u6700\u5c24\u63a8\u5b9a\u3059\u308b\u624b\u9806\uff08PRML\u5f0f(9.23)~(9.27)\uff09\u304c\u307e\u3068\u3081\u3089\u308c\u3066\u3044\u308b\u306e\u3067\u5272\u611b\u3057\u307e\u3059\u3002\n\n\u30b3\u30fc\u30c9\n\n\u30e9\u30a4\u30d6\u30e9\u30ea\n\u3044\u3064\u3082\u3069\u304a\u308a\u306bNumpy\u3068matplotlib\u3092\u4f7f\u3044\u307e\u3059\u3002\nimport matplotlib.pyplot as plt\nimport numpy as np\n\n\n\u6df7\u5408\u30ac\u30a6\u30b9\u5206\u5e03\nclass GaussianMixture(object):\n\n    def __init__(self, n_component):\n        # \u30ac\u30a6\u30b9\u5206\u5e03\u306e\u500b\u6570\n        self.n_component = n_component\n\n    # EM\u30a2\u30eb\u30b4\u30ea\u30ba\u30e0\u3092\u7528\u3044\u305f\u6700\u5c24\u63a8\u5b9a\n    def fit(self, X, iter_max=10):\n        # \u30c7\u30fc\u30bf\u306e\u6b21\u5143\n        self.ndim = np.size(X, 1)\n        # \u6df7\u5408\u4fc2\u6570\u306e\u521d\u671f\u5316\n        self.weights = np.ones(self.n_component) / self.n_component\n        # \u5e73\u5747\u306e\u521d\u671f\u5316\n        self.means = np.random.uniform(X.min(), X.max(), (self.ndim, self.n_component))\n        # \u5171\u5206\u6563\u884c\u5217\u306e\u521d\u671f\u5316\n        self.covs = np.repeat(10 * np.eye(self.ndim), self.n_component).reshape(self.ndim, self.ndim, self.n_component)\n\n        # E\u30b9\u30c6\u30c3\u30d7\u3068M\u30b9\u30c6\u30c3\u30d7\u3092\u7e70\u308a\u8fd4\u3059\n        for i in xrange(iter_max):\n            params = np.hstack((self.weights.ravel(), self.means.ravel(), self.covs.ravel()))\n            # E\u30b9\u30c6\u30c3\u30d7\u3001\u8ca0\u62c5\u7387\u3092\u8a08\u7b97\n            resps = self.expectation(X)\n            # M\u30b9\u30c6\u30c3\u30d7\u3001\u30d1\u30e9\u30e1\u30fc\u30bf\u3092\u66f4\u65b0\n            self.maximization(X, resps)\n            # \u30d1\u30e9\u30e1\u30fc\u30bf\u304c\u53ce\u675f\u3057\u305f\u304b\u3092\u78ba\u8a8d\n            if np.allclose(params, np.hstack((self.weights.ravel(), self.means.ravel(), self.covs.ravel()))):\n                break\n        else:\n            print(\"parameters may not have converged\")\n\n    # \u30ac\u30a6\u30b9\u95a2\u6570\n    def gauss(self, X):\n        precisions = np.linalg.inv(self.covs.T).T\n        diffs = X[:, :, None] - self.means\n        assert diffs.shape == (len(X), self.ndim, self.n_component)\n        exponents = np.sum(np.einsum('nik,ijk->njk', diffs, precisions) * diffs, axis=1)\n        assert exponents.shape == (len(X), self.n_component)\n        return np.exp(-0.5 * exponents) / np.sqrt(np.linalg.det(self.covs.T).T * (2 * np.pi) ** self.ndim)\n\n    # E\u30b9\u30c6\u30c3\u30d7\n    def expectation(self, X):\n        # PRML\u5f0f(9.23)\n        resps = self.weights * self.gauss(X)\n        resps /= resps.sum(axis=-1, keepdims=True)\n        return resps\n\n    # M\u30b9\u30c6\u30c3\u30d7\n    def maximization(self, X, resps):\n        # PRML\u5f0f(9.27)\n        Nk = np.sum(resps, axis=0)\n\n        # PRML\u5f0f(9.26)\n        self.weights = Nk / len(X)\n\n        # PRML\u5f0f(9.24)\n        self.means = X.T.dot(resps) / Nk\n\n        diffs = X[:, :, None] - self.means\n        # PRML\u5f0f(9.25)\n        self.covs = np.einsum('nik,njk->ijk', diffs, diffs * np.expand_dims(resps, 1)) / Nk\n\n    # \u78ba\u7387\u5206\u5e03p(x)\u3092\u8a08\u7b97\n    def predict_proba(self, X):\n        # PRML\u5f0f(9.7)\n        gauss = self.weights * self.gauss(X)\n        return np.sum(gauss, axis=-1)\n\n    # \u30af\u30e9\u30b9\u30bf\u30ea\u30f3\u30b0\n    def classify(self, X):\n        joint_prob = self.weights * self.gauss(X)\n        return np.argmax(joint_prob, axis=1)\n\n\n\u5168\u4f53\u306e\u30b3\u30fc\u30c9\n\ngaussian_mixture.py\nimport matplotlib.pyplot as plt\nimport numpy as np\n\n\nclass GaussianMixture(object):\n\n    def __init__(self, n_component):\n        self.n_component = n_component\n\n    def fit(self, X, iter_max=10):\n        self.ndim = np.size(X, 1)\n        self.weights = np.ones(self.n_component) / self.n_component\n        self.means = np.random.uniform(X.min(), X.max(), (self.ndim, self.n_component))\n        self.covs = np.repeat(10 * np.eye(self.ndim), self.n_component).reshape(self.ndim, self.ndim, self.n_component)\n        for i in xrange(iter_max):\n            params = np.hstack((self.weights.ravel(), self.means.ravel(), self.covs.ravel()))\n            resps = self.expectation(X)\n            self.maximization(X, resps)\n            if np.allclose(params, np.hstack((self.weights.ravel(), self.means.ravel(), self.covs.ravel()))):\n                break\n        else:\n            print(\"parameters may not have converged\")\n\n    def gauss(self, X):\n        precisions = np.linalg.inv(self.covs.T).T\n        diffs = X[:, :, None] - self.means\n        assert diffs.shape == (len(X), self.ndim, self.n_component)\n        exponents = np.sum(np.einsum('nik,ijk->njk', diffs, precisions) * diffs, axis=1)\n        assert exponents.shape == (len(X), self.n_component)\n        return np.exp(-0.5 * exponents) / np.sqrt(np.linalg.det(self.covs.T).T * (2 * np.pi) ** self.ndim)\n\n    def expectation(self, X):\n        resps = self.weights * self.gauss(X)\n        resps /= resps.sum(axis=-1, keepdims=True)\n        return resps\n\n    def maximization(self, X, resps):\n        Nk = np.sum(resps, axis=0)\n        self.weights = Nk / len(X)\n        self.means = X.T.dot(resps) / Nk\n        diffs = X[:, :, None] - self.means\n        self.covs = np.einsum('nik,njk->ijk', diffs, diffs * np.expand_dims(resps, 1)) / Nk\n\n    def predict_proba(self, X):\n        gauss = self.weights * self.gauss(X)\n        return np.sum(gauss, axis=-1)\n\n    def classify(self, X):\n        joint_prob = self.weights * self.gauss(X)\n        return np.argmax(joint_prob, axis=1)\n\n\ndef create_toy_data():\n    x1 = np.random.normal(size=(100, 2))\n    x1 += np.array([-5, -5])\n    x2 = np.random.normal(size=(100, 2))\n    x2 += np.array([5, -5])\n    x3 = np.random.normal(size=(100, 2))\n    x3 += np.array([0, 5])\n    return np.vstack((x1, x2, x3))\n\n\ndef main():\n    X = create_toy_data()\n\n    model = GaussianMixture(3)\n    model.fit(X, iter_max=100)\n    labels = model.classify(X)\n\n    x_test, y_test = np.meshgrid(np.linspace(-10, 10, 100), np.linspace(-10, 10, 100))\n    X_test = np.array([x_test, y_test]).reshape(2, -1).transpose()\n    probs = model.predict_proba(X_test)\n    Probs = probs.reshape(100, 100)\n    colors = [\"red\", \"blue\", \"green\"]\n    plt.scatter(X[:, 0], X[:, 1], c=[colors[int(label)] for label in labels])\n    plt.contour(x_test, y_test, Probs)\n    plt.xlim(-10, 10)\n    plt.ylim(-10, 10)\n    plt.show()\n\n\nif __name__ == '__main__':\n    main()\n\n\n\n\u7d50\u679c\n\u70b9\u3092\u5b66\u7fd2\u30c7\u30fc\u30bf\u3068\u3057\u3066\u6df7\u5408\u30ac\u30a6\u30b9\u5206\u5e03\u306e\u30d1\u30e9\u30e1\u30fc\u30bf\u3092\u6700\u5c24\u63a8\u5b9a\u3057\u3066\u3001\u305d\u306e\u78ba\u7387\u5206\u5e03\u3092\u7b49\u9ad8\u7dda\u3067\u56f3\u793a\u3057\u305f\u3082\u306e\u3067\u3059\u3002\u307e\u305f\u3001\u70b9\u306e\u8272\u306f\u3069\u306e\u30af\u30e9\u30b9\u30bf\u306b\u5c5e\u3059\u308b\u304b\u3092\u8868\u3057\u3066\u3044\u307e\u3059\u3002\n\n\u3053\u308c\u306f\u6210\u529f\u3057\u305f\u3068\u304d\u306e\u7d50\u679c\u3067\u3059\u304c\u3001\u305f\u307e\u306b\u5931\u6557\u3057\u307e\u3059\u3002PRML\u306b\u3082\u8a18\u8f09\u3055\u308c\u3066\u3044\u307e\u3059\u304c\u3001\u4eca\u56de\u306e\u5bfe\u6570\u5c24\u5ea6\u95a2\u6570\u306e\u6700\u5927\u5316\u306f\u4e0d\u826f\u8a2d\u5b9a\u554f\u984c\u306b\u306a\u3063\u3066\u3044\u3066\u826f\u3044\u89e3\u306b\u306a\u3089\u306a\u3044\u3053\u3068\u304c\u3042\u308a\u307e\u3059\u3002\u305d\u308c\u3092\u56de\u907f\u3059\u308b\u30d2\u30e5\u30fc\u30ea\u30b9\u30c6\u30a3\u30c3\u30af\u30b9\u3082\u3042\u308a\u307e\u3059\u304c\u3001\u4eca\u56de\u306f\u305d\u306e\u56de\u907f\u65b9\u6cd5\u3092\u5b9f\u88c5\u3057\u3066\u3044\u306a\u3044\u306e\u3067\u305f\u307e\u306b\u5931\u6557\u3057\u307e\u3059\u3002\u3068\u3044\u3063\u3066\u3082\u3042\u307e\u308a\u5931\u6557\u3057\u306a\u3044\u306f\u305a\u3067\u3059\u3002\n\n\u7d42\u308f\u308a\u306b\n\u6df7\u5408\u30ac\u30a6\u30b9\u5206\u5e03\u306b\u3088\u308b\u30d5\u30a3\u30c3\u30c6\u30a3\u30f3\u30b0\u3092\u884c\u3046\u3053\u3068\u3067\u3001\u6559\u5e2b\u306a\u3057\u306e\u30af\u30e9\u30b9\u30bf\u30ea\u30f3\u30b0\u3092\u884c\u3044\u307e\u3057\u305f\u3002\u305d\u306e\u969b\u306b\u7528\u3044\u308b\u30ac\u30a6\u30b9\u5206\u5e03\u306e\u500b\u6570\u3092\u3053\u3061\u3089\u3067\u6307\u5b9a\u3057\u307e\u3057\u305f\u3002\u6b21\u306e\u7b2c\uff11\uff10\u7ae0\u3067\u306f\u9069\u5207\u306a\u6df7\u5408\u30ac\u30a6\u30b9\u5206\u5e03\u306e\u8981\u7d20\u6570\u3082\u81ea\u52d5\u7684\u306b\u63a8\u5b9a\u3059\u308b\u624b\u6cd5\u304c\u7d39\u4ecb\u3055\u308c\u3066\u3044\u308b\u306e\u3067\u3001\u6b21\u56de\u306f\u305d\u3053\u3067\u7528\u3044\u3089\u308c\u3066\u3044\u308b\u5909\u5206\u30d9\u30a4\u30ba\u3092\u5b9f\u88c5\u3057\u307e\u3059\u3002\nPRML\u7b2c\uff19\u7ae0\u3067\u306fEM\u30a2\u30eb\u30b4\u30ea\u30ba\u30e0\u304c\u7d39\u4ecb\u3055\u308c\u3066\u3044\u307e\u3059\u3002EM\u30a2\u30eb\u30b4\u30ea\u30ba\u30e0\u81ea\u4f53\u306f\u69d8\u3005\u306a\u3068\u3053\u308d\u3067\u4f7f\u3048\u308b\u624b\u6cd5\u3067\u3001\u79c1\u81ea\u8eab\u306fEM\u30a2\u30eb\u30b4\u30ea\u30ba\u30e0\u3068\u3042\u308b\u5206\u985e\u5668\u3092\u7d44\u307f\u5408\u308f\u305b\u3066\u3088\u308a\u30ce\u30a4\u30ba\u306b\u9811\u5065\u306a\u30af\u30e9\u30b9\u5206\u985e\u3092\u884c\u3063\u305f\u308a\u3057\u305f\u3053\u3068\u304c\u3042\u308a\u307e\u3059\u3002\u3057\u304b\u3057\u3001EM\u30a2\u30eb\u30b4\u30ea\u30ba\u30e0\u3092\u9069\u7528\u3059\u308b\u5fdc\u7528\u4f8b\u3068\u3057\u3066\u4e00\u756a\u6709\u540d\u306a\u6df7\u5408\u30ac\u30a6\u30b9\u5206\u5e03\u306b\u3088\u308b\u30af\u30e9\u30b9\u30bf\u30ea\u30f3\u30b0\u3092\u3057\u305f\u3053\u3068\u304c\u306a\u304b\u3063\u305f\u306e\u3067\u3001\u4eca\u56de\u306f**EM\u30a2\u30eb\u30b4\u30ea\u30ba\u30e0\u306b\u3088\u308b\u6df7\u5408\u30ac\u30a6\u30b9\u5206\u5e03\u306e\u6700\u5c24\u63a8\u5b9a\u3092\u5b9f\u88c5**\u3057\u307e\u3057\u305f\u3002\n\n# \u6df7\u5408\u30ac\u30a6\u30b9\u5206\u5e03\u306e\u6700\u5c24\u63a8\u5b9a\n![blobs.png](https://qiita-image-store.s3.amazonaws.com/0/148017/88f68e74-dd32-3c98-6336-651bef00998a.png)\n\u4f8b\u3048\u3070\u3001\u4e0a\u306e\u56f3\u306e\u9752\u70b9\u306e\u3088\u3046\u306a\u30c7\u30fc\u30bf\u70b9\u3092\u666e\u901a\u306e\u30ac\u30a6\u30b9\u5206\u5e03\n\n```math\np({\\bf x}) = \\mathcal{N}({\\bf x}|{\\bf\\mu},{\\bf\\Sigma})\n```\n\u3067\u30d5\u30a3\u30c3\u30c6\u30a3\u30f3\u30b0\u3059\u308b\u3068\u3001\n![gauss_fitting.png](https://qiita-image-store.s3.amazonaws.com/0/148017/37430ba8-acd5-fb9b-28b5-3740174bc313.png)\n\u3053\u306e\u3088\u3046\u306b\u306a\u3063\u3066\u3057\u307e\u3044\u3001\u3053\u306e\u30b1\u30fc\u30b9\u3067\u306f\u5358\u5cf0\u306e\u30ac\u30a6\u30b9\u5206\u5e03\u306f\u9069\u5207\u306a\u30e2\u30c7\u30eb\u3067\u306f\u3042\u308a\u307e\u305b\u3093\u3002\u30c7\u30fc\u30bf\u70b9\u304c\uff13\u3064\u306e\u7fa4\u306b\u5206\u304b\u308c\u3066\u3044\u308b\u3053\u3068\u306b\u7740\u76ee\u3059\u308b\u3068\u3001\u4eca\u56de\u306e\u5834\u5408\u306f\uff13\u3064\u306e\u30ac\u30a6\u30b9\u5206\u5e03\u3092\u7528\u3044\u305f\u6df7\u5408\u30ac\u30a6\u30b9\u5206\u5e03\n\n```math\np({\\bf x}) = \\sum_{k=1}^3 \\pi_k\\mathcal{N}({\\bf x}|{\\bf\\mu}_k,{\\bf\\Sigma}_k)\n```\n\u304c\u9069\u5207\u306a\u30e2\u30c7\u30eb\u3067\u3042\u308b\u3068\u8003\u3048\u3089\u308c\u307e\u3059\u3002\u305f\u3060\u3057\u3001$\\sum_k\\pi_k=1$\u3068\u3057\u307e\u3059\u3002\u305d\u308c\u305e\u308c${\\bf\\mu}\\_1$\u304c\u4e0a\u3001${\\bf\\mu}\\_2$\u304c\u53f3\u4e0b\u3001${\\bf\\mu}\\_3$\u304c\u5de6\u4e0b\u306e\u30c7\u30fc\u30bf\u70b9\u306e\u584a\u306e\u5e73\u5747\u306e\u3088\u3046\u306b\u3057\u307e\u3059\u3002\u3088\u3063\u3066**\u584a\u3054\u3068\u306b\u30ac\u30a6\u30b9\u5206\u5e03\u3067\u30d5\u30a3\u30c3\u30c6\u30a3\u30f3\u30b0\u3059\u308c\u3070\u3044\u3044\u306e\u3067\u3059\u304c\u3001\u3069\u306e\u30c7\u30fc\u30bf\u70b9\u304c\u3069\u306e\u584a\u306b\u5c5e\u3059\u308b\u306e\u304b\u306f\u79c1\u305f\u3061\u4eba\u9593\u306b\u306f\u4e00\u76ee\u77ad\u7136\u3067\u3059\u304c\u3001\u6a5f\u68b0\u306b\u306f\u305d\u3093\u306a\u3053\u3068\u306f\u5206\u304b\u308a\u307e\u305b\u3093**\u3002\n\nN\u500b\u306e\u30c7\u30fc\u30bf\u70b9\u306e\u5ea7\u6a19$\\\\{{\\bf x}\\_n\\\\}\\_{n=1}^N$\u3092\u89b3\u6e2c\u5909\u6570\u3068\u3057\u3066\u3001\u3069\u306e\u30c7\u30fc\u30bf\u70b9\u304cK\u500b\u306e\u584a\u306e\u3046\u3061\u3069\u308c\u306b\u5c5e\u3059\u308b\u304b\u30921-of-k\u7b26\u53f7\u5316\u3067\u8868\u3059\u6f5c\u5728\u5909\u6570$\\\\{{\\bf z}\\_n\\\\}\\_{n=1}^N$\u3068\u30d1\u30e9\u30e1\u30fc\u30bf$\\\\{{\\bf\\pi}\\_k,{\\bf\\mu}\\_k,{\\bf\\Sigma}\\_k\\\\}\\_{k=1}^K$\u3092\u540c\u6642\u306b\u63a8\u5b9a\u3057\u307e\u3059\u3002\u3053\u306e\u3088\u3046\u306b\u6f5c\u5728\u5909\u6570\u304c\u3042\u308b\u5834\u5408\u306fEM\u30a2\u30eb\u30b4\u30ea\u30ba\u30e0\u3092\u7528\u3044\u308b\u306e\u304c\u4e00\u822c\u7684\u3067\u3059\u3002\n\n\n# EM\u30a2\u30eb\u30b4\u30ea\u30ba\u30e0\nPRML\u306e\u7b2c9.2.2\u9805\u306b\u6df7\u5408\u30ac\u30a6\u30b9\u5206\u5e03\u3092EM\u30a2\u30eb\u30b4\u30ea\u30ba\u30e0\u3067\u6700\u5c24\u63a8\u5b9a\u3059\u308b\u624b\u9806\uff08PRML\u5f0f(9.23)~(9.27)\uff09\u304c\u307e\u3068\u3081\u3089\u308c\u3066\u3044\u308b\u306e\u3067\u5272\u611b\u3057\u307e\u3059\u3002\n\n# \u30b3\u30fc\u30c9\n\n## \u30e9\u30a4\u30d6\u30e9\u30ea\n\u3044\u3064\u3082\u3069\u304a\u308a\u306bNumpy\u3068matplotlib\u3092\u4f7f\u3044\u307e\u3059\u3002\n\n```python\nimport matplotlib.pyplot as plt\nimport numpy as np\n```\n\n## \u6df7\u5408\u30ac\u30a6\u30b9\u5206\u5e03\n\n```python\nclass GaussianMixture(object):\n\n    def __init__(self, n_component):\n        # \u30ac\u30a6\u30b9\u5206\u5e03\u306e\u500b\u6570\n        self.n_component = n_component\n\n    # EM\u30a2\u30eb\u30b4\u30ea\u30ba\u30e0\u3092\u7528\u3044\u305f\u6700\u5c24\u63a8\u5b9a\n    def fit(self, X, iter_max=10):\n        # \u30c7\u30fc\u30bf\u306e\u6b21\u5143\n        self.ndim = np.size(X, 1)\n        # \u6df7\u5408\u4fc2\u6570\u306e\u521d\u671f\u5316\n        self.weights = np.ones(self.n_component) / self.n_component\n        # \u5e73\u5747\u306e\u521d\u671f\u5316\n        self.means = np.random.uniform(X.min(), X.max(), (self.ndim, self.n_component))\n        # \u5171\u5206\u6563\u884c\u5217\u306e\u521d\u671f\u5316\n        self.covs = np.repeat(10 * np.eye(self.ndim), self.n_component).reshape(self.ndim, self.ndim, self.n_component)\n\n        # E\u30b9\u30c6\u30c3\u30d7\u3068M\u30b9\u30c6\u30c3\u30d7\u3092\u7e70\u308a\u8fd4\u3059\n        for i in xrange(iter_max):\n            params = np.hstack((self.weights.ravel(), self.means.ravel(), self.covs.ravel()))\n            # E\u30b9\u30c6\u30c3\u30d7\u3001\u8ca0\u62c5\u7387\u3092\u8a08\u7b97\n            resps = self.expectation(X)\n            # M\u30b9\u30c6\u30c3\u30d7\u3001\u30d1\u30e9\u30e1\u30fc\u30bf\u3092\u66f4\u65b0\n            self.maximization(X, resps)\n            # \u30d1\u30e9\u30e1\u30fc\u30bf\u304c\u53ce\u675f\u3057\u305f\u304b\u3092\u78ba\u8a8d\n            if np.allclose(params, np.hstack((self.weights.ravel(), self.means.ravel(), self.covs.ravel()))):\n                break\n        else:\n            print(\"parameters may not have converged\")\n\n    # \u30ac\u30a6\u30b9\u95a2\u6570\n    def gauss(self, X):\n        precisions = np.linalg.inv(self.covs.T).T\n        diffs = X[:, :, None] - self.means\n        assert diffs.shape == (len(X), self.ndim, self.n_component)\n        exponents = np.sum(np.einsum('nik,ijk->njk', diffs, precisions) * diffs, axis=1)\n        assert exponents.shape == (len(X), self.n_component)\n        return np.exp(-0.5 * exponents) / np.sqrt(np.linalg.det(self.covs.T).T * (2 * np.pi) ** self.ndim)\n\n    # E\u30b9\u30c6\u30c3\u30d7\n    def expectation(self, X):\n        # PRML\u5f0f(9.23)\n        resps = self.weights * self.gauss(X)\n        resps /= resps.sum(axis=-1, keepdims=True)\n        return resps\n\n    # M\u30b9\u30c6\u30c3\u30d7\n    def maximization(self, X, resps):\n        # PRML\u5f0f(9.27)\n        Nk = np.sum(resps, axis=0)\n\n        # PRML\u5f0f(9.26)\n        self.weights = Nk / len(X)\n\n        # PRML\u5f0f(9.24)\n        self.means = X.T.dot(resps) / Nk\n\n        diffs = X[:, :, None] - self.means\n        # PRML\u5f0f(9.25)\n        self.covs = np.einsum('nik,njk->ijk', diffs, diffs * np.expand_dims(resps, 1)) / Nk\n\n    # \u78ba\u7387\u5206\u5e03p(x)\u3092\u8a08\u7b97\n    def predict_proba(self, X):\n        # PRML\u5f0f(9.7)\n        gauss = self.weights * self.gauss(X)\n        return np.sum(gauss, axis=-1)\n\n    # \u30af\u30e9\u30b9\u30bf\u30ea\u30f3\u30b0\n    def classify(self, X):\n        joint_prob = self.weights * self.gauss(X)\n        return np.argmax(joint_prob, axis=1)\n```\n\n## \u5168\u4f53\u306e\u30b3\u30fc\u30c9\n\n```python:gaussian_mixture.py\nimport matplotlib.pyplot as plt\nimport numpy as np\n\n\nclass GaussianMixture(object):\n\n    def __init__(self, n_component):\n        self.n_component = n_component\n\n    def fit(self, X, iter_max=10):\n        self.ndim = np.size(X, 1)\n        self.weights = np.ones(self.n_component) / self.n_component\n        self.means = np.random.uniform(X.min(), X.max(), (self.ndim, self.n_component))\n        self.covs = np.repeat(10 * np.eye(self.ndim), self.n_component).reshape(self.ndim, self.ndim, self.n_component)\n        for i in xrange(iter_max):\n            params = np.hstack((self.weights.ravel(), self.means.ravel(), self.covs.ravel()))\n            resps = self.expectation(X)\n            self.maximization(X, resps)\n            if np.allclose(params, np.hstack((self.weights.ravel(), self.means.ravel(), self.covs.ravel()))):\n                break\n        else:\n            print(\"parameters may not have converged\")\n\n    def gauss(self, X):\n        precisions = np.linalg.inv(self.covs.T).T\n        diffs = X[:, :, None] - self.means\n        assert diffs.shape == (len(X), self.ndim, self.n_component)\n        exponents = np.sum(np.einsum('nik,ijk->njk', diffs, precisions) * diffs, axis=1)\n        assert exponents.shape == (len(X), self.n_component)\n        return np.exp(-0.5 * exponents) / np.sqrt(np.linalg.det(self.covs.T).T * (2 * np.pi) ** self.ndim)\n\n    def expectation(self, X):\n        resps = self.weights * self.gauss(X)\n        resps /= resps.sum(axis=-1, keepdims=True)\n        return resps\n\n    def maximization(self, X, resps):\n        Nk = np.sum(resps, axis=0)\n        self.weights = Nk / len(X)\n        self.means = X.T.dot(resps) / Nk\n        diffs = X[:, :, None] - self.means\n        self.covs = np.einsum('nik,njk->ijk', diffs, diffs * np.expand_dims(resps, 1)) / Nk\n\n    def predict_proba(self, X):\n        gauss = self.weights * self.gauss(X)\n        return np.sum(gauss, axis=-1)\n\n    def classify(self, X):\n        joint_prob = self.weights * self.gauss(X)\n        return np.argmax(joint_prob, axis=1)\n\n\ndef create_toy_data():\n    x1 = np.random.normal(size=(100, 2))\n    x1 += np.array([-5, -5])\n    x2 = np.random.normal(size=(100, 2))\n    x2 += np.array([5, -5])\n    x3 = np.random.normal(size=(100, 2))\n    x3 += np.array([0, 5])\n    return np.vstack((x1, x2, x3))\n\n\ndef main():\n    X = create_toy_data()\n\n    model = GaussianMixture(3)\n    model.fit(X, iter_max=100)\n    labels = model.classify(X)\n\n    x_test, y_test = np.meshgrid(np.linspace(-10, 10, 100), np.linspace(-10, 10, 100))\n    X_test = np.array([x_test, y_test]).reshape(2, -1).transpose()\n    probs = model.predict_proba(X_test)\n    Probs = probs.reshape(100, 100)\n    colors = [\"red\", \"blue\", \"green\"]\n    plt.scatter(X[:, 0], X[:, 1], c=[colors[int(label)] for label in labels])\n    plt.contour(x_test, y_test, Probs)\n    plt.xlim(-10, 10)\n    plt.ylim(-10, 10)\n    plt.show()\n\n\nif __name__ == '__main__':\n    main()\n```\n\n# \u7d50\u679c\n\u70b9\u3092\u5b66\u7fd2\u30c7\u30fc\u30bf\u3068\u3057\u3066\u6df7\u5408\u30ac\u30a6\u30b9\u5206\u5e03\u306e\u30d1\u30e9\u30e1\u30fc\u30bf\u3092\u6700\u5c24\u63a8\u5b9a\u3057\u3066\u3001\u305d\u306e\u78ba\u7387\u5206\u5e03\u3092\u7b49\u9ad8\u7dda\u3067\u56f3\u793a\u3057\u305f\u3082\u306e\u3067\u3059\u3002\u307e\u305f\u3001\u70b9\u306e\u8272\u306f\u3069\u306e\u30af\u30e9\u30b9\u30bf\u306b\u5c5e\u3059\u308b\u304b\u3092\u8868\u3057\u3066\u3044\u307e\u3059\u3002\n![result.png](https://qiita-image-store.s3.amazonaws.com/0/148017/8f9c552e-04fe-8bf5-497c-e7d3e52e5a2e.png)\n\u3053\u308c\u306f\u6210\u529f\u3057\u305f\u3068\u304d\u306e\u7d50\u679c\u3067\u3059\u304c\u3001**\u305f\u307e\u306b\u5931\u6557\u3057\u307e\u3059**\u3002PRML\u306b\u3082\u8a18\u8f09\u3055\u308c\u3066\u3044\u307e\u3059\u304c\u3001\u4eca\u56de\u306e\u5bfe\u6570\u5c24\u5ea6\u95a2\u6570\u306e\u6700\u5927\u5316\u306f\u4e0d\u826f\u8a2d\u5b9a\u554f\u984c\u306b\u306a\u3063\u3066\u3044\u3066\u826f\u3044\u89e3\u306b\u306a\u3089\u306a\u3044\u3053\u3068\u304c\u3042\u308a\u307e\u3059\u3002\u305d\u308c\u3092\u56de\u907f\u3059\u308b\u30d2\u30e5\u30fc\u30ea\u30b9\u30c6\u30a3\u30c3\u30af\u30b9\u3082\u3042\u308a\u307e\u3059\u304c\u3001\u4eca\u56de\u306f\u305d\u306e\u56de\u907f\u65b9\u6cd5\u3092\u5b9f\u88c5\u3057\u3066\u3044\u306a\u3044\u306e\u3067\u305f\u307e\u306b\u5931\u6557\u3057\u307e\u3059\u3002\u3068\u3044\u3063\u3066\u3082\u3042\u307e\u308a\u5931\u6557\u3057\u306a\u3044\u306f\u305a\u3067\u3059\u3002\n\n# \u7d42\u308f\u308a\u306b\n\u6df7\u5408\u30ac\u30a6\u30b9\u5206\u5e03\u306b\u3088\u308b\u30d5\u30a3\u30c3\u30c6\u30a3\u30f3\u30b0\u3092\u884c\u3046\u3053\u3068\u3067\u3001\u6559\u5e2b\u306a\u3057\u306e\u30af\u30e9\u30b9\u30bf\u30ea\u30f3\u30b0\u3092\u884c\u3044\u307e\u3057\u305f\u3002\u305d\u306e\u969b\u306b\u7528\u3044\u308b\u30ac\u30a6\u30b9\u5206\u5e03\u306e\u500b\u6570\u3092\u3053\u3061\u3089\u3067\u6307\u5b9a\u3057\u307e\u3057\u305f\u3002\u6b21\u306e\u7b2c\uff11\uff10\u7ae0\u3067\u306f\u9069\u5207\u306a\u6df7\u5408\u30ac\u30a6\u30b9\u5206\u5e03\u306e\u8981\u7d20\u6570\u3082\u81ea\u52d5\u7684\u306b\u63a8\u5b9a\u3059\u308b\u624b\u6cd5\u304c\u7d39\u4ecb\u3055\u308c\u3066\u3044\u308b\u306e\u3067\u3001\u6b21\u56de\u306f\u305d\u3053\u3067\u7528\u3044\u3089\u308c\u3066\u3044\u308b\u5909\u5206\u30d9\u30a4\u30ba\u3092\u5b9f\u88c5\u3057\u307e\u3059\u3002\n", "tags": ["PRML", "\u6a5f\u68b0\u5b66\u7fd2", "Python"]}