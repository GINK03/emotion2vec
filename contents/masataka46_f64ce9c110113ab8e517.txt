{"context": "\u74b0\u5883\uff1a\nCPU:Corei7 6700K\nGPU:GTX1070\nSSD:240GB\nHDD:1TB\n\u30de\u30b6\u30fc\u30dc\u30fc\u30c9:ASUS H170-pro\nOS:Ubuntu14.04 LTS\npython:2.7.6\nCUDA:8.0 RC\ncuDNN:5.1\nTensorFlow:0.10.0\n\u306a\u3069\n\u904e\u53bb\uff14\u56de\u3067\u3001Ubuntu14.04\u3001CUDA\u3001chainer\u3001dqn\u3001LIS\u3001Tensorflow\u3092\u9806\u6b21\u30a4\u30f3\u30b9\u30c8\u30fc\u30eb\u3057\u305f\u3002\nhttp://qiita.com/masataka46/items/94417a5974dba810e7b8\nhttp://qiita.com/masataka46/items/fddef236cb211ef3f145\nhttp://qiita.com/masataka46/items/125c7900ec8ca83f6eb2\nhttp://qiita.com/masataka46/items/12fb01f3417bd0791703\n\u305f\u3060\u3057\u3001Unity\u304c\u3046\u307e\u304f\u7acb\u3061\u4e0a\u304c\u3089\u306a\u3044\u305f\u3081\u3001\u6700\u5f8c\u306eLIS\u74b0\u5883\u69cb\u7bc9\u306f\u5b8c\u4e86\u3057\u3066\u3044\u306a\u3044\u3002\n\u4eca\u56de\u306fOpen AI Gym\u3092\u30a4\u30f3\u30b9\u30c8\u30fc\u30eb\u3059\u308b\u3002\u307e\u305a\u306f\u3053\u3053\u306e\u6307\u793a\nhttps://gym.openai.com/docs\n\u306b\u5f93\u3063\u3066\u9032\u3081\u308b\u3002\n\nOpen AI Gym\u3092\u30a4\u30f3\u30b9\u30c8\u30fc\u30eb\n\u307e\u305aGitHub\u304b\u3089clone\u3059\u308b\u3002\ngit clone https://github.com/openai/gym\ncd gym\n\nfull\u30a4\u30f3\u30b9\u30c8\u30fc\u30eb\u3059\u308b\u65b9\u6cd5\u3082\u3042\u308b\u304c\u3001\u3068\u308a\u3042\u3048\u305aminimum\u3067\u30a4\u30f3\u30b9\u30c8\u30fc\u30eb\u3059\u308b\u3002\npip install -e .\n\n\n\u30b5\u30f3\u30d7\u30eb\u3092\u8d70\u3089\u305b\u308b\nHP\u306e\u6307\u793a\u306b\u5f93\u3063\u3066\u3001\u7c21\u5358\u306a\u30b5\u30f3\u30d7\u30eb\u3092\u8d70\u3089\u305b\u308b\u3002\nimport gym\nenv = gym.make('CartPole-v0')\nenv.reset()\nfor _ in range(1000):\n    env.render()\n    env.step(env.action_space.sample()) # take a random action\n\n\u3068\u3044\u3046\u30b3\u30fc\u30c9\u306btest01.py\u306a\u3069\u9069\u5f53\u306a\u540d\u524d\u3092\u4ed8\u3051\u3001\npython test01.py\n\n\u3067\u8d70\u3089\u305b\u308b\u3002\u3059\u308b\u3068\u4ee5\u4e0b\u306e\u3088\u3046\u306a\u30a8\u30e9\u30fc\u304c\u8868\u793a\u3055\u308c\u305f\u3002\n[2016-09-05 18:09:35,235] Making new env: CartPole-v0\n[2016-09-05 18:09:35,690] You are calling 'step()' even though this environment has already returned done = True. You should always call 'reset()' once you receive 'done = True' -- any further steps are undefined behavior.\nTraceback (most recent call last):\n  File \"test01.py\", line 5, in <module>\n    env.render()\n  File \"/home/ohmasa/openAIGym/gym/gym/core.py\", line 189, in render\n    return self._render(mode=mode, close=close)\n  File \"/home/ohmasa/openAIGym/gym/gym/envs/classic_control/cartpole.py\", line 149, in _render\n    return self.viewer.render(return_rgb_array = mode=='rgb_array')\n  File \"/home/ohmasa/openAIGym/gym/gym/envs/classic_control/rendering.py\", line 84, in render\n    self.window.dispatch_events()\n  File \"/usr/local/lib/python2.7/dist-packages/pyglet/window/xlib/__init__.py\", line 853, in dispatch_events\n    0x1ffffff, byref(e)):\nctypes.ArgumentError: argument 2: <type 'exceptions.TypeError'>: wrong type\n\n\u3057\u304b\u3057\u3001\u6b21\u306e\u30b5\u30f3\u30d7\u30eb\nimport gym\nenv = gym.make('CartPole-v0')\nfor i_episode in range(20):\n    observation = env.reset()\n    for t in range(100):\n        env.render()\n        print(observation)\n        action = env.action_space.sample()\n        observation, reward, done, info = env.step(action)\n        if done:\n            print(\"Episode finished after {} timesteps\".format(t+1))\n            break\n\n\u306fepisode\u3092\u6700\u5f8c\u307e\u3067\u5b9f\u884c\u3057\u7d42\u4e86\u3057\u305f\u3002\u5834\u5408\u306b\u3088\u3063\u3066\u306f\u3046\u307e\u304f\u3044\u304f\u306e\u304b\uff1f\n\u74b0\u5883\uff1a\nCPU:Corei7 6700K\nGPU:GTX1070\nSSD:240GB\nHDD:1TB\n\u30de\u30b6\u30fc\u30dc\u30fc\u30c9:ASUS H170-pro\nOS:Ubuntu14.04 LTS\npython:2.7.6\nCUDA:8.0 RC\ncuDNN:5.1\nTensorFlow:0.10.0\n\u306a\u3069\n\n\u904e\u53bb\uff14\u56de\u3067\u3001Ubuntu14.04\u3001CUDA\u3001chainer\u3001dqn\u3001LIS\u3001Tensorflow\u3092\u9806\u6b21\u30a4\u30f3\u30b9\u30c8\u30fc\u30eb\u3057\u305f\u3002\nhttp://qiita.com/masataka46/items/94417a5974dba810e7b8\nhttp://qiita.com/masataka46/items/fddef236cb211ef3f145\nhttp://qiita.com/masataka46/items/125c7900ec8ca83f6eb2\nhttp://qiita.com/masataka46/items/12fb01f3417bd0791703\n~~\u305f\u3060\u3057\u3001Unity\u304c\u3046\u307e\u304f\u7acb\u3061\u4e0a\u304c\u3089\u306a\u3044\u305f\u3081\u3001\u6700\u5f8c\u306eLIS\u74b0\u5883\u69cb\u7bc9\u306f\u5b8c\u4e86\u3057\u3066\u3044\u306a\u3044\u3002~~\n\n\u4eca\u56de\u306fOpen AI Gym\u3092\u30a4\u30f3\u30b9\u30c8\u30fc\u30eb\u3059\u308b\u3002\u307e\u305a\u306f\u3053\u3053\u306e\u6307\u793a\nhttps://gym.openai.com/docs\n\u306b\u5f93\u3063\u3066\u9032\u3081\u308b\u3002\n##Open AI Gym\u3092\u30a4\u30f3\u30b9\u30c8\u30fc\u30eb\n\u307e\u305aGitHub\u304b\u3089clone\u3059\u308b\u3002\n\n```\ngit clone https://github.com/openai/gym\ncd gym\n```\nfull\u30a4\u30f3\u30b9\u30c8\u30fc\u30eb\u3059\u308b\u65b9\u6cd5\u3082\u3042\u308b\u304c\u3001\u3068\u308a\u3042\u3048\u305aminimum\u3067\u30a4\u30f3\u30b9\u30c8\u30fc\u30eb\u3059\u308b\u3002\n\n```\npip install -e .\n```\n\n##\u30b5\u30f3\u30d7\u30eb\u3092\u8d70\u3089\u305b\u308b\nHP\u306e\u6307\u793a\u306b\u5f93\u3063\u3066\u3001\u7c21\u5358\u306a\u30b5\u30f3\u30d7\u30eb\u3092\u8d70\u3089\u305b\u308b\u3002\n\n```\nimport gym\nenv = gym.make('CartPole-v0')\nenv.reset()\nfor _ in range(1000):\n    env.render()\n    env.step(env.action_space.sample()) # take a random action\n```\n\n\u3068\u3044\u3046\u30b3\u30fc\u30c9\u306btest01.py\u306a\u3069\u9069\u5f53\u306a\u540d\u524d\u3092\u4ed8\u3051\u3001\n\n```\npython test01.py\n```\n\n\u3067\u8d70\u3089\u305b\u308b\u3002\u3059\u308b\u3068\u4ee5\u4e0b\u306e\u3088\u3046\u306a\u30a8\u30e9\u30fc\u304c\u8868\u793a\u3055\u308c\u305f\u3002\n\n```\n[2016-09-05 18:09:35,235] Making new env: CartPole-v0\n[2016-09-05 18:09:35,690] You are calling 'step()' even though this environment has already returned done = True. You should always call 'reset()' once you receive 'done = True' -- any further steps are undefined behavior.\nTraceback (most recent call last):\n  File \"test01.py\", line 5, in <module>\n    env.render()\n  File \"/home/ohmasa/openAIGym/gym/gym/core.py\", line 189, in render\n    return self._render(mode=mode, close=close)\n  File \"/home/ohmasa/openAIGym/gym/gym/envs/classic_control/cartpole.py\", line 149, in _render\n    return self.viewer.render(return_rgb_array = mode=='rgb_array')\n  File \"/home/ohmasa/openAIGym/gym/gym/envs/classic_control/rendering.py\", line 84, in render\n    self.window.dispatch_events()\n  File \"/usr/local/lib/python2.7/dist-packages/pyglet/window/xlib/__init__.py\", line 853, in dispatch_events\n    0x1ffffff, byref(e)):\nctypes.ArgumentError: argument 2: <type 'exceptions.TypeError'>: wrong type\n```\n\n\u3057\u304b\u3057\u3001\u6b21\u306e\u30b5\u30f3\u30d7\u30eb\n\n```\nimport gym\nenv = gym.make('CartPole-v0')\nfor i_episode in range(20):\n    observation = env.reset()\n    for t in range(100):\n        env.render()\n        print(observation)\n        action = env.action_space.sample()\n        observation, reward, done, info = env.step(action)\n        if done:\n            print(\"Episode finished after {} timesteps\".format(t+1))\n            break\n```\n\n\u306fepisode\u3092\u6700\u5f8c\u307e\u3067\u5b9f\u884c\u3057\u7d42\u4e86\u3057\u305f\u3002\u5834\u5408\u306b\u3088\u3063\u3066\u306f\u3046\u307e\u304f\u3044\u304f\u306e\u304b\uff1f\n", "tags": ["TensorFlow", "Ubuntu14.04", "OpenAI", "DeepLearning", "DQN"]}