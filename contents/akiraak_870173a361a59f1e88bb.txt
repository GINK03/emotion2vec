{"context": "\u753b\u50cf\u8a8d\u8b58\u306b\u4f7f\u308f\u308c\u308b\u7573\u307f\u8fbc\u307f\u30cb\u30e5\u30fc\u30e9\u30eb\u30cd\u30c3\u30c8\u30ef\u30fc\u30af\uff08\u4ee5\u4e0bCNN\u3068\u547c\u3076\uff09\u3068\u3044\u3046\u3082\u306e\u304c\u3042\u308a\u307e\u3059\u3002Tensorflow \u306e\u30c1\u30e5\u30fc\u30c8\u30ea\u30a2\u30eb\uff08Deep MNIST for Experts\uff09\u306b\u3082\u51fa\u3066\u304d\u307e\u3059\u304c\u3001\u30cd\u30c3\u30c8\u30ef\u30fc\u30af\u304c\u8907\u96d1\u3067\u7406\u89e3\u3059\u308b\u306e\u306b\u82e6\u52b4\u3057\u307e\u3059\u3002\u305d\u3053\u3067\u3001\u7573\u307f\u8fbc\u307f\u5c64\u3068\u30d7\u30fc\u30ea\u30f3\u30b0\u5c64\u306e\u4e2d\u8eab\u3092\u753b\u50cf\u5316\u3057\u3066\u3001\u4f55\u304c\u884c\u308f\u308c\u3066\u3044\u308b\u306e\u304b\u306a\u3093\u3068\u306a\u304f\u4f53\u611f\u3057\u305f\u3044\u3068\u601d\u3044\u307e\u3059\u3002\n\n\u30d9\u30fc\u30b9\u3068\u306a\u308b Deep MNIST for Experts \u306e\u30b3\u30fc\u30c9\n\u4eca\u56de\u4f7f\u7528\u3059\u308b\u30b3\u30fc\u30c9\u306f github(tf-cnn-image) \u306b\u4e0a\u3052\u3066\u3042\u308a\u307e\u3059\u3002\n\u307e\u305a\u306fCNN\u306e\u30b3\u30fc\u30c9\u3092\u7528\u610f\u3057\u307e\u3059\u3002Deep MNIST for Experts\u306e\u30b3\u30fc\u30c9\u304b\u3089\u4e0d\u8981\u306a\u7b87\u6240\u3092\u524a\u9664\u3057\u305f\u3082\u306e\u3092\u7528\u610f\u3057\u307e\u3057\u305f\u3002\u30b3\u30e1\u30f3\u30c8\u306f\u6700\u5c0f\u9650\u306b\u3057\u3066\u3042\u308b\u306e\u3067\u3001\u8a73\u3057\u3044\u52d5\u4f5c\u3092\u77e5\u308a\u305f\u3044\u5834\u5408\u306f\u3053\u3061\u3089\u306a\u3069\u3092\u53c2\u8003\u306b\u3057\u3066\u304f\u3060\u3055\u3044\u3002\n\n0.py\n# -*- coding: utf-8 -*-\nimport sys\nsys.path.append('tensorflow/tensorflow/examples/tutorials/mnist')\nimport input_data\nimport tensorflow as tf\n\n\ndef weight_variable(shape):\n    initial = tf.truncated_normal(shape, stddev=0.1)\n    return tf.Variable(initial)\n\n\ndef bias_variable(shape):\n    initial = tf.constant(0.1, shape=shape)\n    return tf.Variable(initial)\n\n\ndef conv2d(x, W):\n    return tf.nn.conv2d(x, W, strides=[1, 1, 1, 1], padding='SAME')\n\n\ndef max_pool_2x2(x):\n    return tf.nn.max_pool(x, ksize=[1, 2, 2, 1],\n                          strides=[1, 2, 2, 1], padding='SAME')\n\n\nmnist = input_data.read_data_sets(\"MNIST_data/\", one_hot=True)\nx = tf.placeholder(\"float\", shape=[None, 784])\ny_ = tf.placeholder(\"float\", shape=[None, 10])\n\n\"\"\"\n\u7b2c1\u5c64\n\"\"\"\nW_conv1 = weight_variable([5, 5, 1, 32])\nb_conv1 = bias_variable([32])\nx_image = tf.reshape(x, [-1, 28, 28, 1])\nh_conv1 = tf.nn.relu(conv2d(x_image, W_conv1) + b_conv1)\nh_pool1 = max_pool_2x2(h_conv1)\n\n\"\"\"\n\u7b2c2\u5c64\n\"\"\"\nW_conv2 = weight_variable([5, 5, 32, 64])\nb_conv2 = bias_variable([64])\nh_conv2 = tf.nn.relu(conv2d(h_pool1, W_conv2) + b_conv2)\nh_pool2 = max_pool_2x2(h_conv2)\n\n\"\"\"\n\u5168\u7d50\u5408\u5c64\u3078\u306e\u5909\u63db\n\"\"\"\nW_fc1 = weight_variable([7 * 7 * 64, 1024])\nb_fc1 = bias_variable([1024])\nh_pool2_flat = tf.reshape(h_pool2, [-1, 7 * 7 * 64])\nh_fc1 = tf.nn.relu(tf.matmul(h_pool2_flat, W_fc1) + b_fc1)\n\n\"\"\"\nDropout\n\"\"\"\nkeep_prob = tf.placeholder(\"float\")\nh_fc1_drop = tf.nn.dropout(h_fc1, keep_prob)\n\n\"\"\"\n\u8aad\u307f\u51fa\u3057\u5c64\n\"\"\"\nW_fc2 = weight_variable([1024, 10])\nb_fc2 = bias_variable([10])\ny_conv = tf.nn.softmax(tf.matmul(h_fc1_drop, W_fc2) + b_fc2)\n\n\"\"\"\n\u30e2\u30c7\u30eb\u306e\u5b66\u7fd2\n\"\"\"\ncross_entropy = -tf.reduce_sum(y_ * tf.log(y_conv))\ntrain_step = tf.train.AdamOptimizer(1e-4).minimize(cross_entropy)\n\n\"\"\"\n\u30e2\u30c7\u30eb\u306e\u8a55\u4fa1\n\"\"\"\ncorrect_prediction = tf.equal(tf.argmax(y_conv, 1), tf.argmax(y_, 1))\naccuracy = tf.reduce_mean(tf.cast(correct_prediction, \"float\"))\n\nwith tf.Session() as sess:\n    sess.run(tf.global_variables_initializer())\n    for i in range(20000):\n        batch = mnist.train.next_batch(50)\n        if i % 100 == 0:\n            train_accuracy = accuracy.eval(feed_dict={\n                x: batch[0], y_: batch[1], keep_prob: 1.0})\n            print(\"step %d, training accuracy %g\" % (i, train_accuracy))\n        train_step.run(feed_dict={x: batch[0], y_: batch[1], keep_prob: 0.5})\n\n    print(\"test accuracy %g\" % accuracy.eval(feed_dict={\n        x: mnist.test.images, y_: mnist.test.labels, keep_prob: 1.0}))\n\n\n\n\u30cd\u30c3\u30c8\u30ef\u30fc\u30af\u5404\u5c64\u306e\u51fa\u529b\u5f62\u5f0f\u3092\u8868\u793a\u3057\u3066\u307f\u308b\nCNN\u306b\u306f\u7b2c\u4e00\u5c64\u306e\u7573\u307f\u8fbc\u307f\u5c64\u3068\u30d7\u30fc\u30ea\u30f3\u30b0\u5c64\u3001\u305d\u3057\u3066\u7b2c\u4e8c\u5c64\u3068\u7d50\u5408\u5c64\u3068\u7d9a\u304d\u307e\u3059\u3002\u5404\u5c64\u304c\u3069\u306e\u3088\u3046\u306a\u5f62\u5f0f\u306b\u306a\u3063\u3066\u3044\u308b\u306e\u304b\u78ba\u8a8d\u3057\u3066\u307f\u307e\u3059\u3002\n1.py\n\n1.py\nwith tf.Session() as sess:\n    sess.run(tf.global_variables_initializer())\n    batch = mnist.train.next_batch(50)\n    feed_dict = {x: batch[0], y_: batch[1], keep_prob: 1.0}\n\n    print(\"W_conv1: \", W_conv1.eval().shape)\n    print(\"b_conv1: \", b_conv1.eval().shape)\n    print(\"x_image: \", x_image.eval(feed_dict=feed_dict).shape)\n    print(\"h_conv1: \", h_conv1.eval(feed_dict=feed_dict).shape)\n    print(\"h_pool1: \", h_pool1.eval(feed_dict=feed_dict).shape)\n\n    print(\"W_conv2: \", W_conv2.eval().shape)\n    print(\"b_conv2: \", b_conv2.eval().shape)\n    print(\"h_conv2: \", h_conv2.eval(feed_dict=feed_dict).shape)\n    print(\"h_pool2: \", h_pool2.eval(feed_dict=feed_dict).shape)\n\n    print(\"W_fc1: \", W_fc1.eval().shape)\n    print(\"b_fc1: \", b_fc1.eval().shape)\n    print(\"h_pool2_flat: \", h_pool2_flat.eval(feed_dict=feed_dict).shape)\n    print(\"h_fc1: \", h_fc1.eval(feed_dict=feed_dict).shape)\n\n    print(\"h_fc1_drop: \", h_fc1_drop.eval(feed_dict=feed_dict).shape)\n\n    print(\"W_fc2: \", W_fc2.eval().shape)\n    print(\"b_fc2: \", b_fc2.eval().shape)\n    print(\"y_conv: \", y_conv.eval(feed_dict=feed_dict).shape)\n\n# W_conv1:  (5, 5, 1, 32)\n# b_conv1:  (32,)\n# x_image:  (50, 28, 28, 1)\n# h_conv1:  (50, 28, 28, 32)\n# h_pool1:  (50, 14, 14, 32)\n# W_conv2:  (5, 5, 32, 64)\n# b_conv2:  (64,)\n# h_conv2:  (50, 14, 14, 64)\n# h_pool2:  (50, 7, 7, 64)\n# W_fc1:  (3136, 1024)\n# b_fc1:  (1024,)\n# h_pool2_flat:  (50, 3136)\n# h_fc1:  (50, 1024)\n# h_fc1_drop:  (50, 1024)\n# W_fc2:  (1024, 10)\n# b_fc2:  (10,)\n# y_conv:  (50, 10)\n\n\n\u305d\u308c\u305e\u308c\u306e\u5c64\u306e\u8a08\u7b97\u7d50\u679c\u306f W_conv1.eval() \u306e\u3088\u3046\u306b eval() \u30e1\u30bd\u30c3\u30c9\u3092\u547c\u3073\u51fa\u3059\u3053\u3068\u3067\u53d6\u5f97\u3067\u304d\u307e\u3059\u3002print(\"W_conv1: \", W_conv1.eval().shape) \u3068\u3059\u308b\u3068\u7d50\u679c\uff08\u884c\u5217\uff09\u306e\u578b\u304c\u53d6\u5f97\u3067\u304d\u307e\u3059\u3002\nprint(\"W_conv1: \", W_conv1.eval().shape)\n# W_conv1:  (5, 5, 1, 32)\n\n\u3053\u308c\u306f 5 x 5 x 1 x 32 \u306e\u914d\u5217\uff08\u884c\u5217\uff09\u304c\u8a08\u7b97\u7d50\u679c\u3068\u3057\u3066\u8fd4\u3063\u3066\u304d\u305f\u3053\u3068\u306b\u306a\u308a\u307e\u3059\u3002\nshape \u3092\u4ed8\u3051\u305a\u306bprint\u3059\u308c\u3070\u4e2d\u8eab\u306e\u78ba\u8a8d\u3082\u3067\u304d\u307e\u3059\u3002\nprint(\"W_conv1: \", W_conv1.eval())\n\"\"\"\nW_conv1:  [[[[ -1.23130225e-01  -1.35876462e-02   4.32779454e-03   7.67905191e-02\n      9.60119516e-02  -1.52146637e-01  -1.95266187e-01  -3.94680016e-02\n      7.22171217e-02  -8.30523148e-02   1.21835567e-01  -1.77600980e-01\n      2.14710459e-02  -8.71937573e-02  -1.44006601e-02  -8.36562514e-02\n     -1.46166608e-01  -4.43873368e-03   9.04049501e-02   1.72778830e-01\n     -1.87566504e-01   1.45240754e-01   4.66598086e-02  -5.61284199e-02\n     -9.03827175e-02   2.92096492e-02   4.94740643e-02  -2.18347758e-02\n      1.74995847e-02  -6.22901395e-02   6.10287003e-02   1.21927358e-01]]\n-- \u7701\u7565 --\n\"\"\"\n\n\u753b\u50cf\u5316\u3059\u308b\u306e\u306f\u7573\u307f\u8fbc\u307f\u5c64\u3068\u30d7\u30fc\u30ea\u30f3\u30b0\u5c64\u306a\u306e\u3067\u4ee5\u4e0b\u306e\u8a08\u7b97\u7d50\u679c\u3092\u4f7f\u3046\u3053\u3068\u306b\u306a\u308a\u307e\u3059\u3002\n# h_conv1:  (50, 28, 28, 32)\n# h_pool1:  (50, 14, 14, 32)\n# h_conv2:  (50, 14, 14, 64)\n# h_pool2:  (50, 7, 7, 64)\n\n\u3061\u306a\u307f\u306b\u3001\u3069\u308c\u3082\u5148\u982d\u306e\u6b21\u5143\u304c50\u3067\u3059\u304c\u3001\u3053\u308c\u306f\u30df\u30cb\u30d0\u30c3\u30c1\u51e6\u7406\u3068\u3057\u3066\u753b\u50cf\u309250\u679a\u3065\u3064\u4e0e\u3048\u3066\u8a08\u7b97\u3057\u3066\u3044\u308b\u304b\u3089\u3067\u3059\u3002\u305d\u3057\u3066 h_conv1 \u3067\u306f 28 x 28 \u306e\u30b5\u30a4\u30ba\u306e\u753b\u50cf\u3092\u4f5c\u308a\u3001h_pool1 \u3068 h_conv2 \u3067\u306f 14 x 14 \u306e\u753b\u50cf\u3092\u4f5c\u308a\u3001h_pool2 \u3067\u306f 7 x 7 \u306e\u753b\u50cf\u3092\u4f5c\u308a\u307e\u3059\u3002\n\n\u753b\u50cf\u306e\u4f5c\u308a\u65b9\nPython3.5\u3067\u5b9f\u88c5\u3057\u3066\u3044\u308b\u306e\u3067\u753b\u50cf\u306e\u4f5c\u6210\u30c4\u30fc\u30eb\u3068\u3057\u3066Pillow\u3092\u4f7f\u7528\u3057\u307e\u3059\u3002Tensorflow\u306e\u8a08\u7b97\u7d50\u679c\u306fnumpy.array\u3067\u3059\u304c\u3001\u305d\u3053\u304b\u3089Pillow\u3067\u753b\u50cf\u3092\u4f5c\u308b\u306e\u306f\u3068\u3066\u3082\u7c21\u5358\u306a\u306e\u3067\u3059\u304c\u591a\u5c11\u4fee\u6b63\u3057\u3066\u3042\u3052\u308b\u5fc5\u8981\u304c\u3042\u308a\u307e\u3059\u3002\u307e\u305a\u306f\u5165\u529b\u30c7\u30fc\u30bf\u3067\u3042\u308b\u5143\u30c7\u30fc\u30bf\u3092\u753b\u50cf\u5316\u3057\u3066\u307f\u3088\u3046\u3068\u601d\u3044\u307e\u3059\u3002\n2.py\n\n2.py\nwith tf.Session() as sess:\n    sess.run(tf.global_variables_initializer())\n    batch = mnist.train.next_batch(50)\n    images = x_image.eval(feed_dict={x: batch[0], y_: batch[1], keep_prob: 1.0})\n    #print(images)\n    #print(images.shape)\n    images = images.reshape((-1, 28, 28)) * 255\n    save_image(\"2.png\", images)\n\n\ntools.py\n\ntools.py\ndef save_image(file_name, image_ndarray, cols=8):\n    # \u753b\u50cf\u6570, \u5e45, \u9ad8\u3055\n    count, w, h = image_ndarray.shape\n    # \u7e26\u306b\u753b\u50cf\u3092\u914d\u7f6e\u3059\u308b\u6570\n    rows = int((count - 1) / cols) + 1\n    # \u5fa9\u6570\u306e\u753b\u50cf\u3092\u5927\u304d\u306a\u753b\u50cf\u306b\u914d\u7f6e\u3057\u76f4\u3059\n    canvas = Image.new(\"RGB\", (w * cols + (cols - 1), h * rows + (rows - 1)), (0x80, 0x80, 0x80))\n    for i, image in enumerate(image_ndarray):\n        # \u6a2a\u306e\u914d\u7f6e\u5ea7\u6a19\n        x_i = int(i % cols)\n        x = int(x_i * w + x_i * 1)\n        # \u7e26\u306e\u914d\u7f6e\u5ea7\u6a19\n        y_i = int(i / cols)\n        y = int(y_i * h + y_i * 1)\n        out_image = Image.fromarray(np.uint8(image))\n        canvas.paste(out_image, (x, y))\n    canvas.save('images/' + file_name, \"PNG\")\n\n\n\u307e\u305a\u5143\u753b\u50cf\u306e\u5c64\u306f x_image \u306a\u306e\u3067\u3001\u305d\u306e\u30c7\u30fc\u30bf\u3092\u53d6\u5f97\u3057\u307e\u3059\u3002\nimages = x_image.eval(feed_dict={x: batch[0], y_: batch[1], keep_prob: 1.0})\n\n\u3053\u306e\u30c7\u30fc\u30bf\u306e\u578b\u306f (50, 28, 28, 1) \u306b\u306a\u308a\u307e\u3059\u3002\u3053\u308c\u3092 (50, 28, 28) \u306b\u5909\u3048\u3001\u304b\u3064\u30c7\u30fc\u30bf\u306f0\u301c1.0\u306e\u5024\u3067\u5165\u3063\u3066\u3044\u308b\u306e\u3067\u3001\u3053\u308c\u30920\u301c255\u306b\u5909\u63db\u3057\u307e\u3059\u3002\nimages = images.reshape((-1, 28, 28)) * 255\n\nsave_image() \u3067\u306f\u3001\u307e\u305a50\u679a\u5168\u3066\u306e\u753b\u50cf\u3092\u6577\u304d\u8a70\u3081\u308b\u7a7a\u306e\u753b\u50cf\u3092 Image.new() \u3067\u4f5c\u6210\u3057\u307e\u3059\u3002\u305d\u306e\u5f8c Image.fromarray() \u3067numpy.array\u304b\u3089\u500b\u5225\u306e\u753b\u50cf\u3092\u4f5c\u6210\u3057\u3001 canvas.paste() \u3067\u753b\u50cf\u3092\u6577\u304d\u8a70\u3081\u3066\u3044\u304d\u307e\u3059\u3002\u3053\u306e\u3088\u3046\u306a\u753b\u50cf\u304c\u4f5c\u6210\u3055\u308c\u307e\u3059\u3002\n\n\n\u7573\u307f\u8fbc\u307f\u5c64\u3068\u30d7\u30fc\u30ea\u30f3\u30b0\u5c64\u306e\u753b\u50cf\u3092\u4f5c\u6210\n\u305d\u308c\u3067\u306f\u7573\u307f\u8fbc\u307f\u5c64\u3068\u30d7\u30fc\u30ea\u30f3\u30b0\u5c64\u306e\u753b\u50cf\u3092\u4f5c\u6210\u3057\u3066\u304d\u305f\u3044\u3068\u601d\u3044\u307e\u3059\u304c\u3001\u30c7\u30a3\u30fc\u30d7\u30e9\u30fc\u30cb\u30f3\u30b0\u3067\u306f\u5b66\u7fd2\u3092\u7d9a\u3051\u308b\u3068\u5404\u5c64\u306e\u30a6\u30a7\u30a4\u30c8\u5024\u3068\u30d0\u30a4\u30a2\u30b9\u5024\u304c\u6700\u9069\u306a\u5024\u306b\u8abf\u6574\u3055\u308c\u3066\u3044\u304d\u8ce2\u3044AI\u304c\u4f5c\u3089\u308c\u307e\u3059\u3002\u7573\u307f\u8fbc\u307f\u5c64\u3068\u30d7\u30fc\u30ea\u30f3\u30b0\u5c64\u3082\u30a6\u30a7\u30a4\u30c8\u5024\u3068\u30d0\u30a4\u30a2\u30b9\u5024\u306b\u3088\u3063\u3066\u7570\u306a\u308b\u3082\u306e\u304c\u3067\u304d\u308b\u306e\u3067\u3001\u672a\u5b66\u7fd2\u306a\u72b6\u614b\u3067\u4f5c\u3089\u308c\u308b\u753b\u50cf\u3068\u3001\u5b66\u7fd2\u5f8c\u306e\u72b6\u614b\u3067\u4f5c\u3089\u308c\u308b\u753b\u50cf\u3092\u4f5c\u6210\u3057\u6bd4\u8f03\u3057\u3066\u307f\u3088\u3046\u3068\u601d\u3044\u307e\u3059\u3002\n3.py\n\n3.py\ndef train():\n    for i in range(20000):\n        batch = mnist.train.next_batch(50)\n        if i % 100 == 0:\n            train_accuracy = accuracy.eval(feed_dict={\n                x: batch[0], y_: batch[1], keep_prob: 1.0})\n            print(\"step %d, training accuracy %g\" % (i, train_accuracy))\n        train_step.run(feed_dict={x: batch[0], y_: batch[1], keep_prob: 0.5})\n\n    print(\"test accuracy %g\" % accuracy.eval(feed_dict={\n        x: mnist.test.images, y_: mnist.test.labels, keep_prob: 1.0}))\n\n\ndef create_images(tag):\n    batch = mnist.train.next_batch(10)\n    feed_dict = {x: batch[0], keep_prob: 1.0}\n\n    # \u7573\u307f\u8fbc\u307f\uff11\u5c64\n    h_conv1_result = h_conv1.eval(feed_dict=feed_dict)\n    for i, result in enumerate(h_conv1_result):\n        images = channels_to_images(result)\n        save_image(\"3_%s_h_conv1_%02d.png\" % (tag, i), images)\n\n    # \u30d7\u30fc\u30ea\u30f3\u30b0\uff11\u5c64\n    h_pool1_result = h_pool1.eval(feed_dict=feed_dict)\n    for i, result in enumerate(h_pool1_result):\n        images = channels_to_images(result)\n        save_image(\"3_%s_h_pool1_%02d.png\" % (tag, i), images)\n\n    # \u7573\u307f\u8fbc\u307f\uff12\u5c64\n    h_conv2_result = h_conv2.eval(feed_dict=feed_dict)\n    for i, result in enumerate(h_conv2_result):\n        images = channels_to_images(result)\n        save_image(\"3_%s_h_conv2_%02d.png\" % (tag, i), images)\n\n    # \u30d7\u30fc\u30ea\u30f3\u30b0\uff12\u5c64\n    h_pool2_result = h_pool2.eval(feed_dict=feed_dict)\n    for i, result in enumerate(h_pool2_result):\n        images = channels_to_images(result)\n        save_image(\"3_%s_h_pool2_%02d.png\" % (tag, i), images)\n\n    print(\"Created images. tag =\", tag)\n    print(\"Number: \", [v.argmax() for v in batch[1]])\n\n\nwith tf.Session() as sess:\n    sess.run(tf.global_variables_initializer())\n    # \u753b\u50cf\u4f5c\u6210\n    create_images(\"before\")\n    # \u30c8\u30ec\u30fc\u30cb\u30f3\u30b0\n    train()\n    # \u753b\u50cf\u4f5c\u6210\n    create_images(\"after\")\n\n\n\u5b66\u7fd2\u524d\u3068\u5f8c\u3067\u753b\u50cf\u3092\u4f5c\u308a\u307e\u3059\u3002\n    # \u753b\u50cf\u4f5c\u6210\n    create_images(\"before\")\n    # \u30c8\u30ec\u30fc\u30cb\u30f3\u30b0\n    train()\n    # \u753b\u50cf\u4f5c\u6210\n    create_images(\"after\")\n\ncreate_images() \u3067\u306f\u5404\u5c64\u306e h_conv1 h_pool1 h_conv2 h_pool2 \u3068\u3001\u5165\u529b\u306e\u753b\u50cf\u6bce\u306b\u51fa\u529b\u306e\u753b\u50cf\u3092\u4f5c\u6210\u3057\u307e\u3059\u3002\ndef create_images(tag):\n    batch = mnist.train.next_batch(10)\n    feed_dict = {x: batch[0], keep_prob: 1.0}\n\n    # \u7573\u307f\u8fbc\u307f\uff11\u5c64\n    h_conv1_result = h_conv1.eval(feed_dict=feed_dict)\n    for i, result in enumerate(h_conv1_result):\n        images = channels_to_images(result)\n        save_image(\"3_%s_h_conv1_%02d.png\" % (tag, i), images)\n\n\u5165\u529b\u753b\u50cf\u306f\u3042\u307e\u308a\u591a\u304f\u3066\u3082\u610f\u5473\u304c\u306a\u3044\u306e\u306710\u679a mnist.train.next_batch(10) \u306b\u3057\u307e\u3059\u3002h_conv1_result \u306b\u306f (10, 28, 28, 32) \u3068\u3044\u3046\u5f62\u5f0f\u3067\u7d50\u679c\u304c\u8fd4\u308a\u307e\u3059\u3002\u3053\u308c\u306f10\u679a\u306e\u5165\u529b\u753b\u50cf\u306b\u5bfe\u3057\u3066 28 x 28 \u306e\u30c7\u30fc\u30bf\u304c32\u7a2e\u985e\uff08\u30c1\u30e3\u30f3\u30cd\u30eb\uff09\u3068\u3044\u3046\u610f\u5473\u306b\u306a\u308a\u307e\u3059\u3002\u3053\u306e\u578b\u3067\u306f\u753b\u50cf\u306b\u3067\u304d\u306a\u3044\u306e\u3067 channels_to_images() \u3067\u5404\u5165\u529b\u753b\u50cf\u3054\u3068\u306b (32, 28, 28) \u3068\u3044\u3046\u578b\u306b\u5909\u63db\u3057\u307e\u3059\u3002\ntools.py\n\ntools.py\ndef channels_to_images(channels):\n    count = channels.shape[2]\n    images = []\n    for i in range(count):\n        image = []\n        for line in channels:\n            out_line = [pix[i] for pix in line]\n            image.append(out_line)\n        images.append(image)\n    return np.array(images) * 255\n\n\n\u3053\u308c\u3067\u3001\u3053\u306e\u3088\u3046\u306b28x28\u306e\u30b5\u30a4\u30ba\u306e\u753b\u50cf32\u679a\u3092\u6577\u304d\u8a70\u3081\u305f\u753b\u50cf\u304c10\u679a\uff08\u5165\u529b\u753b\u50cf\u6570\u5206\uff09\u4f5c\u6210\u3055\u308c\u307e\u3059\u3002\n\nh_pool2 \u306e\u30d7\u30fc\u30ea\u30f3\u30b0\u7b2c\u4e8c\u5c64\u3060\u30687x7\u306e\u30b5\u30a4\u30ba\u306e\u753b\u50cf\u304c64\u679a\u306a\u306e\u3067\u3001\u3053\u3093\u306a\u5c0f\u3055\u3044\u3082\u306e\u306b\u306a\u308a\u307e\u3059\u3002\n\n\n\u6bd4\u8f03\u3057\u3066\u307f\u308b\n\u5165\u529b\u304c\uff19\u306e\u753b\u50cf\u3060\u3063\u305f\u5834\u5408\u306e\u7d50\u679c\u3092\u6bd4\u8f03\u3057\u3066\u307f\u307e\u3059\u3002\u898b\u3084\u3059\u3044\u3088\u3046\u306b\u30aa\u30ea\u30b8\u30ca\u30eb\u753b\u50cf\u3092\u62e1\u5927\u3057\u3066\u3042\u308a\u307e\u3059\u3002\n\n\u7b2c\u4e00\u7573\u307f\u8fbc\u307f\u5c64\n\u5b66\u7fd2\u524d\n\n\u5b66\u7fd2\u5f8c\n\n\n\u7b2c\u4e00\u30d7\u30fc\u30ea\u30f3\u30b0\u5c64\n\u5b66\u7fd2\u524d\n\n\u5b66\u7fd2\u5f8c\n\n\n\u7b2c\u4e8c\u7573\u307f\u8fbc\u307f\u5c64\n\u5b66\u7fd2\u524d\n\n\u5b66\u7fd2\u5f8c\n\n\n\u7b2c\u4e8c\u30d7\u30fc\u30ea\u30f3\u30b0\u5c64\n\u5b66\u7fd2\u524d\n\n\u5b66\u7fd2\u5f8c\n\n\n\u611f\u60f3\n\u306a\u3093\u3068\u306a\u304f\u3001\u3001\u5b66\u7fd2\u3057\u3066\u3044\u308b\u3088\u3046\u306a\u6c17\u304c\u3059\u308b\u3002\u3002\u3002\u305f\u3076\u3093\u3002\u3002\u3002\u306a\u3093\u304b\u5927\u304d\u304f\u30ce\u30a4\u30ba\u3063\u307d\u3044\u584a\u3060\u3063\u305f\u306e\u304c\u3001\u305d\u308c\u3068\u306a\u304f\u3069\u3053\u304b\u306e\u7279\u5fb4\u3092\u898b\u51fa\u3057\u3066\u3044\u308b\u3088\u3046\u306a\u3001\u3001\u3001\u3088\u304f\u308f\u304b\u3089\u306a\u3044\u3051\u3069\u3002\u3002\u3002\u305d\u308c\u304c\u30c7\u30a3\u30fc\u30d7\u30e9\u30fc\u30cb\u30f3\u30b0\u306a\u3093\u3060\u308d\u3046\u304d\u3063\u3068\n\n\u7c21\u5358\u5b9f\u884c\ntf-cnn-image \u3092\u843d\u3068\u3057\u305f\u3089\u4ee5\u4e0b\u306e\u3088\u3046\u306b\u5b9f\u884c\u3067\u304d\u307e\u3059\u3002\n$ python 0.py\n$ python 1.py\n$ python 2.py\n$ python 3.py\n\n\u753b\u50cf\u8a8d\u8b58\u306b\u4f7f\u308f\u308c\u308b\u7573\u307f\u8fbc\u307f\u30cb\u30e5\u30fc\u30e9\u30eb\u30cd\u30c3\u30c8\u30ef\u30fc\u30af\uff08\u4ee5\u4e0bCNN\u3068\u547c\u3076\uff09\u3068\u3044\u3046\u3082\u306e\u304c\u3042\u308a\u307e\u3059\u3002Tensorflow \u306e\u30c1\u30e5\u30fc\u30c8\u30ea\u30a2\u30eb\uff08[Deep MNIST for Experts](https://www.tensorflow.org/tutorials/mnist/pros/)\uff09\u306b\u3082\u51fa\u3066\u304d\u307e\u3059\u304c\u3001\u30cd\u30c3\u30c8\u30ef\u30fc\u30af\u304c\u8907\u96d1\u3067\u7406\u89e3\u3059\u308b\u306e\u306b\u82e6\u52b4\u3057\u307e\u3059\u3002\u305d\u3053\u3067\u3001\u7573\u307f\u8fbc\u307f\u5c64\u3068\u30d7\u30fc\u30ea\u30f3\u30b0\u5c64\u306e\u4e2d\u8eab\u3092\u753b\u50cf\u5316\u3057\u3066\u3001\u4f55\u304c\u884c\u308f\u308c\u3066\u3044\u308b\u306e\u304b\u306a\u3093\u3068\u306a\u304f\u4f53\u611f\u3057\u305f\u3044\u3068\u601d\u3044\u307e\u3059\u3002\n\n#\u30d9\u30fc\u30b9\u3068\u306a\u308b Deep MNIST for Experts \u306e\u30b3\u30fc\u30c9\n\n\u4eca\u56de\u4f7f\u7528\u3059\u308b\u30b3\u30fc\u30c9\u306f github([tf-cnn-image](https://github.com/akiraak/tf-cnn-image)) \u306b\u4e0a\u3052\u3066\u3042\u308a\u307e\u3059\u3002\n\n\u307e\u305a\u306fCNN\u306e\u30b3\u30fc\u30c9\u3092\u7528\u610f\u3057\u307e\u3059\u3002[Deep MNIST for Experts](https://www.tensorflow.org/tutorials/mnist/pros/)\u306e\u30b3\u30fc\u30c9\u304b\u3089\u4e0d\u8981\u306a\u7b87\u6240\u3092\u524a\u9664\u3057\u305f\u3082\u306e\u3092\u7528\u610f\u3057\u307e\u3057\u305f\u3002\u30b3\u30e1\u30f3\u30c8\u306f\u6700\u5c0f\u9650\u306b\u3057\u3066\u3042\u308b\u306e\u3067\u3001\u8a73\u3057\u3044\u52d5\u4f5c\u3092\u77e5\u308a\u305f\u3044\u5834\u5408\u306f[\u3053\u3061\u3089](https://gist.github.com/uramonk/422bb33419df91b253d8728fe794f8b4)\u306a\u3069\u3092\u53c2\u8003\u306b\u3057\u3066\u304f\u3060\u3055\u3044\u3002\n\n```0.py\n# -*- coding: utf-8 -*-\nimport sys\nsys.path.append('tensorflow/tensorflow/examples/tutorials/mnist')\nimport input_data\nimport tensorflow as tf\n\n\ndef weight_variable(shape):\n    initial = tf.truncated_normal(shape, stddev=0.1)\n    return tf.Variable(initial)\n\n\ndef bias_variable(shape):\n    initial = tf.constant(0.1, shape=shape)\n    return tf.Variable(initial)\n\n\ndef conv2d(x, W):\n    return tf.nn.conv2d(x, W, strides=[1, 1, 1, 1], padding='SAME')\n\n\ndef max_pool_2x2(x):\n    return tf.nn.max_pool(x, ksize=[1, 2, 2, 1],\n                          strides=[1, 2, 2, 1], padding='SAME')\n\n\nmnist = input_data.read_data_sets(\"MNIST_data/\", one_hot=True)\nx = tf.placeholder(\"float\", shape=[None, 784])\ny_ = tf.placeholder(\"float\", shape=[None, 10])\n\n\"\"\"\n\u7b2c1\u5c64\n\"\"\"\nW_conv1 = weight_variable([5, 5, 1, 32])\nb_conv1 = bias_variable([32])\nx_image = tf.reshape(x, [-1, 28, 28, 1])\nh_conv1 = tf.nn.relu(conv2d(x_image, W_conv1) + b_conv1)\nh_pool1 = max_pool_2x2(h_conv1)\n\n\"\"\"\n\u7b2c2\u5c64\n\"\"\"\nW_conv2 = weight_variable([5, 5, 32, 64])\nb_conv2 = bias_variable([64])\nh_conv2 = tf.nn.relu(conv2d(h_pool1, W_conv2) + b_conv2)\nh_pool2 = max_pool_2x2(h_conv2)\n\n\"\"\"\n\u5168\u7d50\u5408\u5c64\u3078\u306e\u5909\u63db\n\"\"\"\nW_fc1 = weight_variable([7 * 7 * 64, 1024])\nb_fc1 = bias_variable([1024])\nh_pool2_flat = tf.reshape(h_pool2, [-1, 7 * 7 * 64])\nh_fc1 = tf.nn.relu(tf.matmul(h_pool2_flat, W_fc1) + b_fc1)\n\n\"\"\"\nDropout\n\"\"\"\nkeep_prob = tf.placeholder(\"float\")\nh_fc1_drop = tf.nn.dropout(h_fc1, keep_prob)\n\n\"\"\"\n\u8aad\u307f\u51fa\u3057\u5c64\n\"\"\"\nW_fc2 = weight_variable([1024, 10])\nb_fc2 = bias_variable([10])\ny_conv = tf.nn.softmax(tf.matmul(h_fc1_drop, W_fc2) + b_fc2)\n\n\"\"\"\n\u30e2\u30c7\u30eb\u306e\u5b66\u7fd2\n\"\"\"\ncross_entropy = -tf.reduce_sum(y_ * tf.log(y_conv))\ntrain_step = tf.train.AdamOptimizer(1e-4).minimize(cross_entropy)\n\n\"\"\"\n\u30e2\u30c7\u30eb\u306e\u8a55\u4fa1\n\"\"\"\ncorrect_prediction = tf.equal(tf.argmax(y_conv, 1), tf.argmax(y_, 1))\naccuracy = tf.reduce_mean(tf.cast(correct_prediction, \"float\"))\n\nwith tf.Session() as sess:\n    sess.run(tf.global_variables_initializer())\n    for i in range(20000):\n        batch = mnist.train.next_batch(50)\n        if i % 100 == 0:\n            train_accuracy = accuracy.eval(feed_dict={\n                x: batch[0], y_: batch[1], keep_prob: 1.0})\n            print(\"step %d, training accuracy %g\" % (i, train_accuracy))\n        train_step.run(feed_dict={x: batch[0], y_: batch[1], keep_prob: 0.5})\n\n    print(\"test accuracy %g\" % accuracy.eval(feed_dict={\n        x: mnist.test.images, y_: mnist.test.labels, keep_prob: 1.0}))\n```\n\n#\u30cd\u30c3\u30c8\u30ef\u30fc\u30af\u5404\u5c64\u306e\u51fa\u529b\u5f62\u5f0f\u3092\u8868\u793a\u3057\u3066\u307f\u308b\n\nCNN\u306b\u306f\u7b2c\u4e00\u5c64\u306e\u7573\u307f\u8fbc\u307f\u5c64\u3068\u30d7\u30fc\u30ea\u30f3\u30b0\u5c64\u3001\u305d\u3057\u3066\u7b2c\u4e8c\u5c64\u3068\u7d50\u5408\u5c64\u3068\u7d9a\u304d\u307e\u3059\u3002\u5404\u5c64\u304c\u3069\u306e\u3088\u3046\u306a\u5f62\u5f0f\u306b\u306a\u3063\u3066\u3044\u308b\u306e\u304b\u78ba\u8a8d\u3057\u3066\u307f\u307e\u3059\u3002\n\n[1.py](https://github.com/akiraak/tf-cnn-image/blob/master/1.py)\n\n```1.py\nwith tf.Session() as sess:\n    sess.run(tf.global_variables_initializer())\n    batch = mnist.train.next_batch(50)\n    feed_dict = {x: batch[0], y_: batch[1], keep_prob: 1.0}\n\n    print(\"W_conv1: \", W_conv1.eval().shape)\n    print(\"b_conv1: \", b_conv1.eval().shape)\n    print(\"x_image: \", x_image.eval(feed_dict=feed_dict).shape)\n    print(\"h_conv1: \", h_conv1.eval(feed_dict=feed_dict).shape)\n    print(\"h_pool1: \", h_pool1.eval(feed_dict=feed_dict).shape)\n\n    print(\"W_conv2: \", W_conv2.eval().shape)\n    print(\"b_conv2: \", b_conv2.eval().shape)\n    print(\"h_conv2: \", h_conv2.eval(feed_dict=feed_dict).shape)\n    print(\"h_pool2: \", h_pool2.eval(feed_dict=feed_dict).shape)\n\n    print(\"W_fc1: \", W_fc1.eval().shape)\n    print(\"b_fc1: \", b_fc1.eval().shape)\n    print(\"h_pool2_flat: \", h_pool2_flat.eval(feed_dict=feed_dict).shape)\n    print(\"h_fc1: \", h_fc1.eval(feed_dict=feed_dict).shape)\n\n    print(\"h_fc1_drop: \", h_fc1_drop.eval(feed_dict=feed_dict).shape)\n\n    print(\"W_fc2: \", W_fc2.eval().shape)\n    print(\"b_fc2: \", b_fc2.eval().shape)\n    print(\"y_conv: \", y_conv.eval(feed_dict=feed_dict).shape)\n\n# W_conv1:  (5, 5, 1, 32)\n# b_conv1:  (32,)\n# x_image:  (50, 28, 28, 1)\n# h_conv1:  (50, 28, 28, 32)\n# h_pool1:  (50, 14, 14, 32)\n# W_conv2:  (5, 5, 32, 64)\n# b_conv2:  (64,)\n# h_conv2:  (50, 14, 14, 64)\n# h_pool2:  (50, 7, 7, 64)\n# W_fc1:  (3136, 1024)\n# b_fc1:  (1024,)\n# h_pool2_flat:  (50, 3136)\n# h_fc1:  (50, 1024)\n# h_fc1_drop:  (50, 1024)\n# W_fc2:  (1024, 10)\n# b_fc2:  (10,)\n# y_conv:  (50, 10)\n```\n\n\u305d\u308c\u305e\u308c\u306e\u5c64\u306e\u8a08\u7b97\u7d50\u679c\u306f `W_conv1.eval()` \u306e\u3088\u3046\u306b `eval()` \u30e1\u30bd\u30c3\u30c9\u3092\u547c\u3073\u51fa\u3059\u3053\u3068\u3067\u53d6\u5f97\u3067\u304d\u307e\u3059\u3002`print(\"W_conv1: \", W_conv1.eval().shape)` \u3068\u3059\u308b\u3068\u7d50\u679c\uff08\u884c\u5217\uff09\u306e\u578b\u304c\u53d6\u5f97\u3067\u304d\u307e\u3059\u3002\n\n```\nprint(\"W_conv1: \", W_conv1.eval().shape)\n# W_conv1:  (5, 5, 1, 32)\n```\n\n\u3053\u308c\u306f 5 x 5 x 1 x 32 \u306e\u914d\u5217\uff08\u884c\u5217\uff09\u304c\u8a08\u7b97\u7d50\u679c\u3068\u3057\u3066\u8fd4\u3063\u3066\u304d\u305f\u3053\u3068\u306b\u306a\u308a\u307e\u3059\u3002\n\n\n`shape` \u3092\u4ed8\u3051\u305a\u306bprint\u3059\u308c\u3070\u4e2d\u8eab\u306e\u78ba\u8a8d\u3082\u3067\u304d\u307e\u3059\u3002\n\n```py\nprint(\"W_conv1: \", W_conv1.eval())\n\"\"\"\nW_conv1:  [[[[ -1.23130225e-01  -1.35876462e-02   4.32779454e-03   7.67905191e-02\n      9.60119516e-02  -1.52146637e-01  -1.95266187e-01  -3.94680016e-02\n      7.22171217e-02  -8.30523148e-02   1.21835567e-01  -1.77600980e-01\n      2.14710459e-02  -8.71937573e-02  -1.44006601e-02  -8.36562514e-02\n     -1.46166608e-01  -4.43873368e-03   9.04049501e-02   1.72778830e-01\n     -1.87566504e-01   1.45240754e-01   4.66598086e-02  -5.61284199e-02\n     -9.03827175e-02   2.92096492e-02   4.94740643e-02  -2.18347758e-02\n      1.74995847e-02  -6.22901395e-02   6.10287003e-02   1.21927358e-01]]\n-- \u7701\u7565 --\n\"\"\"\n```\n\n\u753b\u50cf\u5316\u3059\u308b\u306e\u306f\u7573\u307f\u8fbc\u307f\u5c64\u3068\u30d7\u30fc\u30ea\u30f3\u30b0\u5c64\u306a\u306e\u3067\u4ee5\u4e0b\u306e\u8a08\u7b97\u7d50\u679c\u3092\u4f7f\u3046\u3053\u3068\u306b\u306a\u308a\u307e\u3059\u3002\n\n```\n# h_conv1:  (50, 28, 28, 32)\n# h_pool1:  (50, 14, 14, 32)\n# h_conv2:  (50, 14, 14, 64)\n# h_pool2:  (50, 7, 7, 64)\n```\n\n\u3061\u306a\u307f\u306b\u3001\u3069\u308c\u3082\u5148\u982d\u306e\u6b21\u5143\u304c50\u3067\u3059\u304c\u3001\u3053\u308c\u306f\u30df\u30cb\u30d0\u30c3\u30c1\u51e6\u7406\u3068\u3057\u3066\u753b\u50cf\u309250\u679a\u3065\u3064\u4e0e\u3048\u3066\u8a08\u7b97\u3057\u3066\u3044\u308b\u304b\u3089\u3067\u3059\u3002\u305d\u3057\u3066 h_conv1 \u3067\u306f 28 x 28 \u306e\u30b5\u30a4\u30ba\u306e\u753b\u50cf\u3092\u4f5c\u308a\u3001h_pool1 \u3068 h_conv2 \u3067\u306f 14 x 14 \u306e\u753b\u50cf\u3092\u4f5c\u308a\u3001h_pool2 \u3067\u306f 7 x 7 \u306e\u753b\u50cf\u3092\u4f5c\u308a\u307e\u3059\u3002\n\n#\u753b\u50cf\u306e\u4f5c\u308a\u65b9\n\nPython3.5\u3067\u5b9f\u88c5\u3057\u3066\u3044\u308b\u306e\u3067\u753b\u50cf\u306e\u4f5c\u6210\u30c4\u30fc\u30eb\u3068\u3057\u3066Pillow\u3092\u4f7f\u7528\u3057\u307e\u3059\u3002Tensorflow\u306e\u8a08\u7b97\u7d50\u679c\u306fnumpy.array\u3067\u3059\u304c\u3001\u305d\u3053\u304b\u3089Pillow\u3067\u753b\u50cf\u3092\u4f5c\u308b\u306e\u306f\u3068\u3066\u3082\u7c21\u5358\u306a\u306e\u3067\u3059\u304c\u591a\u5c11\u4fee\u6b63\u3057\u3066\u3042\u3052\u308b\u5fc5\u8981\u304c\u3042\u308a\u307e\u3059\u3002\u307e\u305a\u306f\u5165\u529b\u30c7\u30fc\u30bf\u3067\u3042\u308b\u5143\u30c7\u30fc\u30bf\u3092\u753b\u50cf\u5316\u3057\u3066\u307f\u3088\u3046\u3068\u601d\u3044\u307e\u3059\u3002\n\n[2.py](https://github.com/akiraak/tf-cnn-image/blob/master/2.py)\n\n```2.py\nwith tf.Session() as sess:\n    sess.run(tf.global_variables_initializer())\n    batch = mnist.train.next_batch(50)\n    images = x_image.eval(feed_dict={x: batch[0], y_: batch[1], keep_prob: 1.0})\n    #print(images)\n    #print(images.shape)\n    images = images.reshape((-1, 28, 28)) * 255\n    save_image(\"2.png\", images)\n```\n\n[tools.py](https://github.com/akiraak/tf-cnn-image/blob/master/tools.py)\n\n```tools.py\ndef save_image(file_name, image_ndarray, cols=8):\n    # \u753b\u50cf\u6570, \u5e45, \u9ad8\u3055\n    count, w, h = image_ndarray.shape\n    # \u7e26\u306b\u753b\u50cf\u3092\u914d\u7f6e\u3059\u308b\u6570\n    rows = int((count - 1) / cols) + 1\n    # \u5fa9\u6570\u306e\u753b\u50cf\u3092\u5927\u304d\u306a\u753b\u50cf\u306b\u914d\u7f6e\u3057\u76f4\u3059\n    canvas = Image.new(\"RGB\", (w * cols + (cols - 1), h * rows + (rows - 1)), (0x80, 0x80, 0x80))\n    for i, image in enumerate(image_ndarray):\n        # \u6a2a\u306e\u914d\u7f6e\u5ea7\u6a19\n        x_i = int(i % cols)\n        x = int(x_i * w + x_i * 1)\n        # \u7e26\u306e\u914d\u7f6e\u5ea7\u6a19\n        y_i = int(i / cols)\n        y = int(y_i * h + y_i * 1)\n        out_image = Image.fromarray(np.uint8(image))\n        canvas.paste(out_image, (x, y))\n    canvas.save('images/' + file_name, \"PNG\")\n```\n\n\u307e\u305a\u5143\u753b\u50cf\u306e\u5c64\u306f x_image \u306a\u306e\u3067\u3001\u305d\u306e\u30c7\u30fc\u30bf\u3092\u53d6\u5f97\u3057\u307e\u3059\u3002\n\n```\nimages = x_image.eval(feed_dict={x: batch[0], y_: batch[1], keep_prob: 1.0})\n```\n\n\u3053\u306e\u30c7\u30fc\u30bf\u306e\u578b\u306f (50, 28, 28, 1) \u306b\u306a\u308a\u307e\u3059\u3002\u3053\u308c\u3092 (50, 28, 28) \u306b\u5909\u3048\u3001\u304b\u3064\u30c7\u30fc\u30bf\u306f0\u301c1.0\u306e\u5024\u3067\u5165\u3063\u3066\u3044\u308b\u306e\u3067\u3001\u3053\u308c\u30920\u301c255\u306b\u5909\u63db\u3057\u307e\u3059\u3002\n\n```\nimages = images.reshape((-1, 28, 28)) * 255\n```\n\n`save_image()` \u3067\u306f\u3001\u307e\u305a50\u679a\u5168\u3066\u306e\u753b\u50cf\u3092\u6577\u304d\u8a70\u3081\u308b\u7a7a\u306e\u753b\u50cf\u3092 `Image.new()` \u3067\u4f5c\u6210\u3057\u307e\u3059\u3002\u305d\u306e\u5f8c `Image.fromarray() ` \u3067numpy.array\u304b\u3089\u500b\u5225\u306e\u753b\u50cf\u3092\u4f5c\u6210\u3057\u3001 `canvas.paste()` \u3067\u753b\u50cf\u3092\u6577\u304d\u8a70\u3081\u3066\u3044\u304d\u307e\u3059\u3002\u3053\u306e\u3088\u3046\u306a\u753b\u50cf\u304c\u4f5c\u6210\u3055\u308c\u307e\u3059\u3002\n\n![2.png](https://qiita-image-store.s3.amazonaws.com/0/33704/13c238cc-2623-bd01-8a31-8111981a4ccc.png)\n\n#\u7573\u307f\u8fbc\u307f\u5c64\u3068\u30d7\u30fc\u30ea\u30f3\u30b0\u5c64\u306e\u753b\u50cf\u3092\u4f5c\u6210\n\n\u305d\u308c\u3067\u306f\u7573\u307f\u8fbc\u307f\u5c64\u3068\u30d7\u30fc\u30ea\u30f3\u30b0\u5c64\u306e\u753b\u50cf\u3092\u4f5c\u6210\u3057\u3066\u304d\u305f\u3044\u3068\u601d\u3044\u307e\u3059\u304c\u3001\u30c7\u30a3\u30fc\u30d7\u30e9\u30fc\u30cb\u30f3\u30b0\u3067\u306f\u5b66\u7fd2\u3092\u7d9a\u3051\u308b\u3068\u5404\u5c64\u306e\u30a6\u30a7\u30a4\u30c8\u5024\u3068\u30d0\u30a4\u30a2\u30b9\u5024\u304c\u6700\u9069\u306a\u5024\u306b\u8abf\u6574\u3055\u308c\u3066\u3044\u304d\u8ce2\u3044AI\u304c\u4f5c\u3089\u308c\u307e\u3059\u3002\u7573\u307f\u8fbc\u307f\u5c64\u3068\u30d7\u30fc\u30ea\u30f3\u30b0\u5c64\u3082\u30a6\u30a7\u30a4\u30c8\u5024\u3068\u30d0\u30a4\u30a2\u30b9\u5024\u306b\u3088\u3063\u3066\u7570\u306a\u308b\u3082\u306e\u304c\u3067\u304d\u308b\u306e\u3067\u3001\u672a\u5b66\u7fd2\u306a\u72b6\u614b\u3067\u4f5c\u3089\u308c\u308b\u753b\u50cf\u3068\u3001\u5b66\u7fd2\u5f8c\u306e\u72b6\u614b\u3067\u4f5c\u3089\u308c\u308b\u753b\u50cf\u3092\u4f5c\u6210\u3057\u6bd4\u8f03\u3057\u3066\u307f\u3088\u3046\u3068\u601d\u3044\u307e\u3059\u3002\n\n[3.py](https://github.com/akiraak/tf-cnn-image/blob/master/3.py)\n\n```3.py\ndef train():\n    for i in range(20000):\n        batch = mnist.train.next_batch(50)\n        if i % 100 == 0:\n            train_accuracy = accuracy.eval(feed_dict={\n                x: batch[0], y_: batch[1], keep_prob: 1.0})\n            print(\"step %d, training accuracy %g\" % (i, train_accuracy))\n        train_step.run(feed_dict={x: batch[0], y_: batch[1], keep_prob: 0.5})\n\n    print(\"test accuracy %g\" % accuracy.eval(feed_dict={\n        x: mnist.test.images, y_: mnist.test.labels, keep_prob: 1.0}))\n\n\ndef create_images(tag):\n    batch = mnist.train.next_batch(10)\n    feed_dict = {x: batch[0], keep_prob: 1.0}\n\n    # \u7573\u307f\u8fbc\u307f\uff11\u5c64\n    h_conv1_result = h_conv1.eval(feed_dict=feed_dict)\n    for i, result in enumerate(h_conv1_result):\n        images = channels_to_images(result)\n        save_image(\"3_%s_h_conv1_%02d.png\" % (tag, i), images)\n\n    # \u30d7\u30fc\u30ea\u30f3\u30b0\uff11\u5c64\n    h_pool1_result = h_pool1.eval(feed_dict=feed_dict)\n    for i, result in enumerate(h_pool1_result):\n        images = channels_to_images(result)\n        save_image(\"3_%s_h_pool1_%02d.png\" % (tag, i), images)\n\n    # \u7573\u307f\u8fbc\u307f\uff12\u5c64\n    h_conv2_result = h_conv2.eval(feed_dict=feed_dict)\n    for i, result in enumerate(h_conv2_result):\n        images = channels_to_images(result)\n        save_image(\"3_%s_h_conv2_%02d.png\" % (tag, i), images)\n\n    # \u30d7\u30fc\u30ea\u30f3\u30b0\uff12\u5c64\n    h_pool2_result = h_pool2.eval(feed_dict=feed_dict)\n    for i, result in enumerate(h_pool2_result):\n        images = channels_to_images(result)\n        save_image(\"3_%s_h_pool2_%02d.png\" % (tag, i), images)\n\n    print(\"Created images. tag =\", tag)\n    print(\"Number: \", [v.argmax() for v in batch[1]])\n\n\nwith tf.Session() as sess:\n    sess.run(tf.global_variables_initializer())\n    # \u753b\u50cf\u4f5c\u6210\n    create_images(\"before\")\n    # \u30c8\u30ec\u30fc\u30cb\u30f3\u30b0\n    train()\n    # \u753b\u50cf\u4f5c\u6210\n    create_images(\"after\")\n```\n\n\u5b66\u7fd2\u524d\u3068\u5f8c\u3067\u753b\u50cf\u3092\u4f5c\u308a\u307e\u3059\u3002\n\n```py\n    # \u753b\u50cf\u4f5c\u6210\n    create_images(\"before\")\n    # \u30c8\u30ec\u30fc\u30cb\u30f3\u30b0\n    train()\n    # \u753b\u50cf\u4f5c\u6210\n    create_images(\"after\")\n```\n\n`create_images()` \u3067\u306f\u5404\u5c64\u306e `h_conv1` `h_pool1` `h_conv2` `h_pool2` \u3068\u3001\u5165\u529b\u306e\u753b\u50cf\u6bce\u306b\u51fa\u529b\u306e\u753b\u50cf\u3092\u4f5c\u6210\u3057\u307e\u3059\u3002\n\n```py\ndef create_images(tag):\n    batch = mnist.train.next_batch(10)\n    feed_dict = {x: batch[0], keep_prob: 1.0}\n\n    # \u7573\u307f\u8fbc\u307f\uff11\u5c64\n    h_conv1_result = h_conv1.eval(feed_dict=feed_dict)\n    for i, result in enumerate(h_conv1_result):\n        images = channels_to_images(result)\n        save_image(\"3_%s_h_conv1_%02d.png\" % (tag, i), images)\n```\n\n\u5165\u529b\u753b\u50cf\u306f\u3042\u307e\u308a\u591a\u304f\u3066\u3082\u610f\u5473\u304c\u306a\u3044\u306e\u306710\u679a `mnist.train.next_batch(10)` \u306b\u3057\u307e\u3059\u3002`h_conv1_result` \u306b\u306f (10, 28, 28, 32) \u3068\u3044\u3046\u5f62\u5f0f\u3067\u7d50\u679c\u304c\u8fd4\u308a\u307e\u3059\u3002\u3053\u308c\u306f10\u679a\u306e\u5165\u529b\u753b\u50cf\u306b\u5bfe\u3057\u3066 28 x 28 \u306e\u30c7\u30fc\u30bf\u304c32\u7a2e\u985e\uff08\u30c1\u30e3\u30f3\u30cd\u30eb\uff09\u3068\u3044\u3046\u610f\u5473\u306b\u306a\u308a\u307e\u3059\u3002\u3053\u306e\u578b\u3067\u306f\u753b\u50cf\u306b\u3067\u304d\u306a\u3044\u306e\u3067 `channels_to_images()` \u3067\u5404\u5165\u529b\u753b\u50cf\u3054\u3068\u306b (32, 28, 28) \u3068\u3044\u3046\u578b\u306b\u5909\u63db\u3057\u307e\u3059\u3002\n\n[tools.py](https://github.com/akiraak/tf-cnn-image/blob/master/tools.py)\n\n```tools.py\ndef channels_to_images(channels):\n    count = channels.shape[2]\n    images = []\n    for i in range(count):\n        image = []\n        for line in channels:\n            out_line = [pix[i] for pix in line]\n            image.append(out_line)\n        images.append(image)\n    return np.array(images) * 255\n```\n\n\u3053\u308c\u3067\u3001\u3053\u306e\u3088\u3046\u306b28x28\u306e\u30b5\u30a4\u30ba\u306e\u753b\u50cf32\u679a\u3092\u6577\u304d\u8a70\u3081\u305f\u753b\u50cf\u304c10\u679a\uff08\u5165\u529b\u753b\u50cf\u6570\u5206\uff09\u4f5c\u6210\u3055\u308c\u307e\u3059\u3002\n\n![3_before_h_conv1_00.png](https://qiita-image-store.s3.amazonaws.com/0/33704/d5dd8052-3da0-bbe8-1670-d0a7ce02ae9e.png)\n\nh_pool2 \u306e\u30d7\u30fc\u30ea\u30f3\u30b0\u7b2c\u4e8c\u5c64\u3060\u30687x7\u306e\u30b5\u30a4\u30ba\u306e\u753b\u50cf\u304c64\u679a\u306a\u306e\u3067\u3001\u3053\u3093\u306a\u5c0f\u3055\u3044\u3082\u306e\u306b\u306a\u308a\u307e\u3059\u3002\n\n![3_before_h_pool2_00.png](https://qiita-image-store.s3.amazonaws.com/0/33704/b87e1cc9-1a44-7866-47be-89f738d7c1b2.png)\n\n\n#\u6bd4\u8f03\u3057\u3066\u307f\u308b\n\n\u5165\u529b\u304c\uff19\u306e\u753b\u50cf\u3060\u3063\u305f\u5834\u5408\u306e\u7d50\u679c\u3092\u6bd4\u8f03\u3057\u3066\u307f\u307e\u3059\u3002\u898b\u3084\u3059\u3044\u3088\u3046\u306b\u30aa\u30ea\u30b8\u30ca\u30eb\u753b\u50cf\u3092\u62e1\u5927\u3057\u3066\u3042\u308a\u307e\u3059\u3002\n\n##\u7b2c\u4e00\u7573\u307f\u8fbc\u307f\u5c64\n\n\u5b66\u7fd2\u524d\n![3_before_h_conv1.png](https://qiita-image-store.s3.amazonaws.com/0/33704/1d7cf708-63ba-d480-f9b8-5bf77a77914b.png)\n\n\u5b66\u7fd2\u5f8c\n![3_after_h_conv1.png](https://qiita-image-store.s3.amazonaws.com/0/33704/1ab9826c-c09d-09b1-ea6a-4d060b7f5e10.png)\n\n##\u7b2c\u4e00\u30d7\u30fc\u30ea\u30f3\u30b0\u5c64\n\n\u5b66\u7fd2\u524d\n![3_before_h_pool1.png](https://qiita-image-store.s3.amazonaws.com/0/33704/9ab69176-7695-f41e-6a14-ad8beb6b2068.png)\n\n\u5b66\u7fd2\u5f8c\n![3_after_h_pool1.png](https://qiita-image-store.s3.amazonaws.com/0/33704/c9460448-1102-4f81-283f-0a28b995ff55.png)\n\n##\u7b2c\u4e8c\u7573\u307f\u8fbc\u307f\u5c64\n\n\u5b66\u7fd2\u524d\n![3_before_h_conv2.png](https://qiita-image-store.s3.amazonaws.com/0/33704/9aa0dfa3-bd4d-2e9c-3f4e-5661cb198c64.png)\n\n\u5b66\u7fd2\u5f8c\n![3_after_h_conv2.png](https://qiita-image-store.s3.amazonaws.com/0/33704/160001b0-1bbe-d841-e2a2-c10e402cc30a.png)\n\n##\u7b2c\u4e8c\u30d7\u30fc\u30ea\u30f3\u30b0\u5c64\n\n\u5b66\u7fd2\u524d\n![3_before_h_pool2.png](https://qiita-image-store.s3.amazonaws.com/0/33704/832cf106-ccad-e614-2a27-b7f3dbef39af.png)\n\n\u5b66\u7fd2\u5f8c\n![3_after_h_pool2.png](https://qiita-image-store.s3.amazonaws.com/0/33704/a5993b4b-cad4-cb96-c7c8-9edab4e6b174.png)\n\n#\u611f\u60f3\n\u306a\u3093\u3068\u306a\u304f\u3001\u3001\u5b66\u7fd2\u3057\u3066\u3044\u308b\u3088\u3046\u306a\u6c17\u304c\u3059\u308b\u3002\u3002\u3002\u305f\u3076\u3093\u3002\u3002\u3002\u306a\u3093\u304b\u5927\u304d\u304f\u30ce\u30a4\u30ba\u3063\u307d\u3044\u584a\u3060\u3063\u305f\u306e\u304c\u3001\u305d\u308c\u3068\u306a\u304f\u3069\u3053\u304b\u306e\u7279\u5fb4\u3092\u898b\u51fa\u3057\u3066\u3044\u308b\u3088\u3046\u306a\u3001\u3001\u3001\u3088\u304f\u308f\u304b\u3089\u306a\u3044\u3051\u3069\u3002\u3002\u3002\u305d\u308c\u304c\u30c7\u30a3\u30fc\u30d7\u30e9\u30fc\u30cb\u30f3\u30b0\u306a\u3093\u3060\u308d\u3046\u304d\u3063\u3068\n\n#\u7c21\u5358\u5b9f\u884c\n\n[tf-cnn-image](https://github.com/akiraak/tf-cnn-image/) \u3092\u843d\u3068\u3057\u305f\u3089\u4ee5\u4e0b\u306e\u3088\u3046\u306b\u5b9f\u884c\u3067\u304d\u307e\u3059\u3002\n\n```\n$ python 0.py\n$ python 1.py\n$ python 2.py\n$ python 3.py\n```\n", "tags": ["TensorFlow", "DeepLearning", "CNN", "\u53ef\u8996\u5316"]}