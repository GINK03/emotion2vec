{"context": " More than 1 year has passed since last update.\n\n\u74b0\u5883\nmac osx 10.9.5\nscala 2.10.4\n\nspark-csv\u306e\u3056\u3063\u304f\u308a\u3068\u3057\u305f\u7d39\u4ecb\n\u30fbApache spark\u3067CSV\u30c7\u30fc\u30bf\u3092\u30d1\u30fc\u30b9\u3067\u304d\u308b\u3088\u3046\u306b\u3059\u308b\n\u30fb\u30d1\u30fc\u30b9\u3057\u305f\u3082\u306e\u306fSpark SQL\u3084DataFrame\u3067\u4f7f\u3048\u308b\u3088\u3046\u306b\u306a\u308b\n\ngithub\nhttps://github.com/databricks/spark-csv\n\n\u5fc5\u8981\u306a\u3082\u306e\u3068\u4eca\u56de\u4f7f\u7528\u3057\u305f\u30d0\u30fc\u30b8\u30e7\u30f3\nspark-core 1.4.0\nspark-sql 1.4.0\nspark-csv 1.0.3\n\nbuild.sbt\u306e\u629c\u7c8b\nlibraryDependencies ++= Seq(\n  \"org.apache.spark\" %% \"spark-core\" % \"1.4.0\",\n  \"org.apache.spark\" %% \"spark-sql\" % \"1.4.0\",\n  \"com.databricks\" %% \"spark-csv\" % \"1.0.3\"\n)\n\n\n\u5b9f\u969b\u306e\u30b3\u30fc\u30c9\n\n// initialize spark\nval conf: SparkConf = new SparkConf().setMaster(\"local\").setAppName(\"test\")\nval sc: SparkContext = new SparkContext(conf)\nval sqlContext: SQLContext = new SQLContext(sc)\n\n// \u8aad\u307f\u8fbc\u307f\u305f\u3044\u30d5\u30a1\u30a4\u30eb\u306e\u30d1\u30b9\u3092load()\u306e\u5f15\u6570\u306b\u8a2d\u5b9a\u3059\u308b\nval df = sqlContext.read.format(\"com.databricks.spark.csv\").option(\"header\", \"true\").load(\"xxxx/yyyy/zzzz.csv\")\n\n\n\u3053\u308c\u3067\u6307\u5b9a\u3057\u305f\u30d5\u30a1\u30a4\u30eb\u306eCSV\u30c7\u30fc\u30bf\u3092\u89e3\u6790\u3002\noption\u306e\u5f15\u6570\u306fCSV\u30c7\u30fc\u30bf\u306e\u30d8\u30c3\u30c0(\u30c7\u30fc\u30bf\u306e1\u884c\u76ee\u306b\u3042\u308b\u9805\u76ee\u540d)\u3092\u542b\u3081\u308b\u304b\u3069\u3046\u304b\u3002\n\n\u89e3\u6790\u3057\u305fCSV\u3092\u5b9f\u969b\u306b\u53d6\u5f97\n\u203b\u300cname\u300d\u300caddress\u300d\u306e2\u9805\u76ee\u3092\u6301\u3064CSV\u304c\u3042\u3063\u305f\u3068\u3057\u3066\n\n// RDD\u53d6\u5f97\nval rdd = df.select(\"name\", \"address\")\n\n// \u4e2d\u8eab\u3092\u898b\u3066\u307f\u308b\nrdd.foreach(pritnln)\n\n\n\u7c21\u5358\u306a\u4f7f\u3044\u65b9\u306f\u4ee5\u4e0a\u306b\u306a\u308a\u307e\u3059\u3002\n\u3053\u308c\u304c\u4fbf\u5229\u3067\u5b9f\u969b\u306bmysql\u306b\u6295\u3052\u308b\u3088\u3046\u306aSQL\u304c\u5b9f\u884c\u3067\u304d\u3001\nGROUP BY\u3067\u304d\u305f\u308a\u3001JOIN\u3067\u304d\u305f\u308a\u3082\u3057\u307e\u3059\u3002\n\u6642\u9593\u3042\u308b\u3068\u304d\u306b\u30b5\u30f3\u30d7\u30eb\u8f09\u305b\u305f\u3044\u3068\u601d\u3044\u307e\u3059\u3002\n\u52d5\u304b\u306a\u3044\u7b49\u3042\u308a\u307e\u3057\u305f\u3089\u3054\u6307\u6458\u4e0b\u3055\u3044m(__)m\n# \u74b0\u5883\nmac osx 10.9.5\nscala 2.10.4\n\n\n# spark-csv\u306e\u3056\u3063\u304f\u308a\u3068\u3057\u305f\u7d39\u4ecb\n\u30fbApache spark\u3067CSV\u30c7\u30fc\u30bf\u3092\u30d1\u30fc\u30b9\u3067\u304d\u308b\u3088\u3046\u306b\u3059\u308b\n\u30fb\u30d1\u30fc\u30b9\u3057\u305f\u3082\u306e\u306fSpark SQL\u3084DataFrame\u3067\u4f7f\u3048\u308b\u3088\u3046\u306b\u306a\u308b\n\n\n# github\nhttps://github.com/databricks/spark-csv\n\n\n# \u5fc5\u8981\u306a\u3082\u306e\u3068\u4eca\u56de\u4f7f\u7528\u3057\u305f\u30d0\u30fc\u30b8\u30e7\u30f3\nspark-core 1.4.0\nspark-sql 1.4.0\nspark-csv 1.0.3\n\n\n# build.sbt\u306e\u629c\u7c8b\n```scala\nlibraryDependencies ++= Seq(\n  \"org.apache.spark\" %% \"spark-core\" % \"1.4.0\",\n  \"org.apache.spark\" %% \"spark-sql\" % \"1.4.0\",\n  \"com.databricks\" %% \"spark-csv\" % \"1.0.3\"\n)\n```\n\n# \u5b9f\u969b\u306e\u30b3\u30fc\u30c9\n```scala\n\n// initialize spark\nval conf: SparkConf = new SparkConf().setMaster(\"local\").setAppName(\"test\")\nval sc: SparkContext = new SparkContext(conf)\nval sqlContext: SQLContext = new SQLContext(sc)\n\n// \u8aad\u307f\u8fbc\u307f\u305f\u3044\u30d5\u30a1\u30a4\u30eb\u306e\u30d1\u30b9\u3092load()\u306e\u5f15\u6570\u306b\u8a2d\u5b9a\u3059\u308b\nval df = sqlContext.read.format(\"com.databricks.spark.csv\").option(\"header\", \"true\").load(\"xxxx/yyyy/zzzz.csv\")\n\n```\n\n\u3053\u308c\u3067\u6307\u5b9a\u3057\u305f\u30d5\u30a1\u30a4\u30eb\u306eCSV\u30c7\u30fc\u30bf\u3092\u89e3\u6790\u3002\noption\u306e\u5f15\u6570\u306fCSV\u30c7\u30fc\u30bf\u306e\u30d8\u30c3\u30c0(\u30c7\u30fc\u30bf\u306e1\u884c\u76ee\u306b\u3042\u308b\u9805\u76ee\u540d)\u3092\u542b\u3081\u308b\u304b\u3069\u3046\u304b\u3002\n\n\n# \u89e3\u6790\u3057\u305fCSV\u3092\u5b9f\u969b\u306b\u53d6\u5f97\n\u203b\u300cname\u300d\u300caddress\u300d\u306e2\u9805\u76ee\u3092\u6301\u3064CSV\u304c\u3042\u3063\u305f\u3068\u3057\u3066\n\n```scala\n\n// RDD\u53d6\u5f97\nval rdd = df.select(\"name\", \"address\")\n\n// \u4e2d\u8eab\u3092\u898b\u3066\u307f\u308b\nrdd.foreach(pritnln)\n\n```\n\n\n\u7c21\u5358\u306a\u4f7f\u3044\u65b9\u306f\u4ee5\u4e0a\u306b\u306a\u308a\u307e\u3059\u3002\n\u3053\u308c\u304c\u4fbf\u5229\u3067\u5b9f\u969b\u306bmysql\u306b\u6295\u3052\u308b\u3088\u3046\u306aSQL\u304c\u5b9f\u884c\u3067\u304d\u3001\nGROUP BY\u3067\u304d\u305f\u308a\u3001JOIN\u3067\u304d\u305f\u308a\u3082\u3057\u307e\u3059\u3002\n\u6642\u9593\u3042\u308b\u3068\u304d\u306b\u30b5\u30f3\u30d7\u30eb\u8f09\u305b\u305f\u3044\u3068\u601d\u3044\u307e\u3059\u3002\n\n\n\u52d5\u304b\u306a\u3044\u7b49\u3042\u308a\u307e\u3057\u305f\u3089\u3054\u6307\u6458\u4e0b\u3055\u3044m(__)m\n", "tags": ["Spark", "Scala", "Mac"]}