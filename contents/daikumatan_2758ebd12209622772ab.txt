{"context": "Chrome\u3067\u898b\u308b\u3068\u753b\u50cf\u306e\u8272\u5408\u3044\u304c\u5909\u306a\u306e\u3067Safari\u3084Firefox\u3067\u898b\u3066\u304f\u3060\u3055\u3044\u3002\n\n\u5168\u4f53\u306e\u6d41\u308c\n\n\nGPU REST Engine\u306e\u30a4\u30f3\u30b9\u30c8\u30fc\u30eb\n\nGPU REST Engine\u306e\u52d5\u4f5c\u78ba\u8a8d\n\n\n0. \u524d\u63d0\u6761\u4ef6\n\ng2.2xlarge\u306e\u30a4\u30f3\u30b9\u30bf\u30f3\u30b9\u306b\u30ed\u30b0\u30a4\u30f3\u3057\u3066\u3044\u308b\u3053\u3068\u3002\u30ea\u30fc\u30b8\u30e7\u30f3\u306f\u3069\u3053\u3067\u3082OK\nK520 \u7528\u306e NVIDIA Driver\u3068CUDA\u304c\u30a4\u30f3\u30b9\u30c8\u30fc\u30eb\u3055\u308c\u3066\u3044\u308b\u3053\u3068\nnvidia docker \u304c\u30a4\u30f3\u30b9\u30c8\u30fc\u30eb\u3055\u308c\u3066\u3044\u308b\u3053\u3068\n\n\n1. Download GRE (GPU REST Engine)\n\nDownload\ngit clone https://github.com/NVIDIA/gpu-rest-engine ${HOME}\n\n\n\n2. \u63a8\u8ad6\u30b5\u30fc\u30d0\u306e\u69cb\u7bc9/\u8d77\u52d5\n\n2.1 \u63a8\u8ad6\u30b5\u30fc\u30d0\u306e\u69cb\u7bc9\nbuild\u306b15\u5206\u7a0b\u5ea6\u5fc5\u8981\u3067\u3059\u3002\n\n\u30c0\u30a6\u30f3\u30ed\u30fc\u30c9\u3057\u305f\u30c7\u30a3\u30ec\u30af\u30c8\u30ea\u30fc\u3078\u79fb\u52d5\ncd ${HOME}/gpu-rest-engine\n\n\n\n\u63a8\u8ad6\u30b5\u30fc\u30d0\u306e\u69cb\u7bc9\nsudo docker build -t inference_server -f Dockerfile.inference_server .\n\n\n\n2.2 \u63a8\u8ad6\u30b5\u30fc\u30d0\u306e\u8d77\u52d5\n\n\u63a8\u8ad6\u30b5\u30fc\u30d0\u306e\u8d77\u52d5\nsudo nvidia-docker run --name=server --net=host --rm inference_server\n\n\n\nresult-example\n2016/05/06 04:30:51 Initializing Caffe classifiers\n2016/05/06 04:30:54 Adding REST endpoint /api/classify\n2016/05/06 04:30:54 Starting server listening on :8000\n\n\n\n3. \u52d5\u4f5c\u78ba\u8a8d\n\u3053\u3053\u3067\u306e\u52d5\u4f5c\u78ba\u8a8d\u306f\u63a8\u8ad6\u30b5\u30fc\u30d0\u3068\u540c\u3058\u30de\u30b7\u30f3\u304b\u3089\u3001\u753b\u50cf\u3092\u30a2\u30c3\u30d7\u30ed\u30fc\u30c9\u3057\u3066\u3001\u305d\u306e\u753b\u50cf\u306b\u5199\u3063\u3066\u3044\u308b\n\u52d5\u7269\u3092\u63a8\u6e2c\u3057\u307e\u3059\u3002\n\n\u30b5\u30f3\u30d7\u30eb\u30a4\u30e1\u30fc\u30b8 images/1.jpg \u306e\u52d5\u7269\u3092\u63a8\u8ad6\u3059\u308b\n\n\n\u30a4\u30e1\u30fc\u30b8\u753b\u50cf\u306ePATH\u3092\u6c7a\u5b9a\nIMAGE=\"${HOME}/gpu-rest-engine/images/1.jpg\"\n\n\n\nendpoint\u306e\u6307\u5b9a\nENDPOINT=\"http://127.0.0.1:8000/api/classify\"\n\n\n\n\u5909\u6570\u306e\u78ba\u8a8d\ncat << ETX\n\nIMAGE_NAME : ${IMAGE} \nEND_POINT : ${ENDPOINT}\n\nETX\n\n\n\n\u63a8\u8ad6\u30b5\u30fc\u30d0\u306eAPI\u3092\u30ad\u30c3\u30af\ncurl -XPOST --data-binary @${IMAGE} ${ENDPOINT} | jq .\n\n\n\nresult\n[\n  {\n    \"label\": \"n02328150 Angora, Angora rabbit\",\n    \"confidence\": 0.9998\n  },\n  {\n    \"label\": \"n02325366 wood rabbit, cottontail, cottontail rabbit\",\n    \"confidence\": 0.0001\n  },\n  {\n    \"label\": \"n02326432 hare\",\n    \"confidence\": 0.0001\n  },\n  {\n    \"label\": \"n02085936 Maltese dog, Maltese terrier, Maltese\",\n    \"confidence\": 0\n  },\n  {\n    \"label\": \"n02342885 hamster\",\n    \"confidence\": 0\n  }\n]\n\n\n\n\u30a4\u30f3\u30bf\u30fc\u30cd\u30c3\u30c8\u4e0a\u306e\u753b\u50cf\u3092\u63a8\u8ad6\u3059\u308b\n\n\n\u753b\u50cf\u306eDownload\nwget http://sozaing.com/wp-content/uploads/IMG_29451-540x360.jpg -P ${HOME}/gpu-rest-engine/images\n\n\n\n\u30a4\u30e1\u30fc\u30b8\u753b\u50cf\u306ePATH\u3092\u6c7a\u5b9a\nIMAGE=\"${HOME}/gpu-rest-engine/images/IMG_29451-540x360.jpg\"\n\n\n\n\u5909\u6570\u306e\u78ba\u8a8d\ncat << ETX\n\nIMAGE_NAME : ${IMAGE} \nEND_POINT : ${ENDPOINT}\n\nETX\n\n\n\n\u63a8\u8ad6\u30b5\u30fc\u30d0\u306eAPI\u3092\u30ad\u30c3\u30af\ncurl -XPOST --data-binary @${IMAGE} ${ENDPOINT} | jq .\n\n\n\nresult\n[\n  {\n    \"label\": \"n02325366 wood rabbit, cottontail, cottontail rabbit\",\n    \"confidence\": 0.6424\n  },\n  {\n    \"label\": \"n02326432 hare\",\n    \"confidence\": 0.1461\n  },\n  {\n    \"label\": \"n02095889 Sealyham terrier, Sealyham\",\n    \"confidence\": 0.0929\n  },\n  {\n    \"label\": \"n02437616 llama\",\n    \"confidence\": 0.0161\n  },\n  {\n    \"label\": \"n02328150 Angora, Angora rabbit\",\n    \"confidence\": 0.0149\n  }\n]\n\n\n\n4. Benchmarking\n\n4.1 \u30c6\u30b9\u30c8\u7528 docker container \u306e\u69cb\u7bc9\n\n\u30c0\u30a6\u30f3\u30ed\u30fc\u30c9\u3057\u305f\u30c7\u30a3\u30ec\u30af\u30c8\u30ea\u30fc\u3078\u79fb\u52d5\ncd ${HOME}/gpu-rest-engine\n\n\n\ncommand\nsudo docker build -t inference_client -f Dockerfile.inference_client .\n\n\n\n4.2 \u30c6\u30b9\u30c8\u306e\u5b9f\u884c\n\nbenchmark-test\nsudo docker run -e CONCURRENCY=8 -e REQUESTS=20000 --net=host inference_client\n\n\n\nresult-example\nSummary:\n  Total:    153.6530 secs\n  Slowest:  0.0992 secs\n  Fastest:  0.0198 secs\n  Average:  0.0614 secs\n  Requests/sec: 130.1634\n  Total data:   6880000 bytes\n  Size/request: 344 bytes\n\nStatus code distribution:\n  [200] 20000 responses\n\nResponse time histogram:\n  0.020 [1]     |\n  0.028 [0]     |\n  0.036 [2]     |\n  0.044 [5]     |\n  0.052 [2]     |\n  0.060 [548]   |\u220e\n  0.067 [19139] |\u220e\u220e\u220e\u220e\u220e\u220e\u220e\u220e\u220e\u220e\u220e\u220e\u220e\u220e\u220e\u220e\u220e\u220e\u220e\u220e\u220e\u220e\u220e\u220e\u220e\u220e\u220e\u220e\u220e\u220e\u220e\u220e\u220e\u220e\u220e\u220e\u220e\u220e\u220e\u220e\n  0.075 [297]   |\n  0.083 [3]     |\n  0.091 [2]     |\n  0.099 [1]     |\n\nLatency distribution:\n  10% in 0.0610 secs\n  25% in 0.0612 secs\n  50% in 0.0614 secs\n  75% in 0.0616 secs\n  90% in 0.0619 secs\n  95% in 0.0623 secs\n  99% in 0.0691 secs\n\n\n\n\u3053\u306eQiita\u306e\u60c5\u5831\u306f\u3001\u304a\u3044\u3089\u304c\u30d7\u30e9\u30a4\u30d9\u30fc\u30c8\u3067\u4f5c\u3063\u3066\u3044\u308b\u3082\u306e\u3067\u3001NVIDIA\u3068\u306f\u7121\u95a2\u4fc2\u3067\u3059\u3002\u500b\u4eba\u8cac\u4efb\u3067\u304a\u8a66\u3057\u304f\u3060\u3055\u3044\u3002\u30a4\u30f3\u30b9\u30bf\u30f3\u30b9\u7b49\u306e\u6d88\u3057\u5fd8\u308c\u7b49\u3054\u6ce8\u610f\u304f\u3060\u3055\u3044\u3002\n\nChrome\u3067\u898b\u308b\u3068\u753b\u50cf\u306e\u8272\u5408\u3044\u304c\u5909\u306a\u306e\u3067Safari\u3084Firefox\u3067\u898b\u3066\u304f\u3060\u3055\u3044\u3002\n\n\u5168\u4f53\u306e\u6d41\u308c\n=============\n\n- [GPU REST Engine]\u306e\u30a4\u30f3\u30b9\u30c8\u30fc\u30eb\n- [GPU REST Engine]\u306e\u52d5\u4f5c\u78ba\u8a8d\n\n0. \u524d\u63d0\u6761\u4ef6\n=================\n\n- [g2.2xlarge\u306e\u30a4\u30f3\u30b9\u30bf\u30f3\u30b9\u306b\u30ed\u30b0\u30a4\u30f3\u3057\u3066\u3044\u308b\u3053\u3068\u3002\u30ea\u30fc\u30b8\u30e7\u30f3\u306f\u3069\u3053\u3067\u3082OK](http://qiita.com/daikumatan/items/58daff99250d4698d659)\n- [K520 \u7528\u306e NVIDIA Driver\u3068CUDA\u304c\u30a4\u30f3\u30b9\u30c8\u30fc\u30eb\u3055\u308c\u3066\u3044\u308b\u3053\u3068](http://qiita.com/daikumatan/items/26039fc23edabf76a9c4)\n- [nvidia docker \u304c\u30a4\u30f3\u30b9\u30c8\u30fc\u30eb\u3055\u308c\u3066\u3044\u308b\u3053\u3068](http://qiita.com/daikumatan/items/c0951a02e70fd2449b8f)\n\n\n\n1. Download GRE (GPU REST Engine)\n===================================\n\n```bash:Download\ngit clone https://github.com/NVIDIA/gpu-rest-engine ${HOME}\n```\n\n2. \u63a8\u8ad6\u30b5\u30fc\u30d0\u306e\u69cb\u7bc9/\u8d77\u52d5\n=====================\n\n2.1 \u63a8\u8ad6\u30b5\u30fc\u30d0\u306e\u69cb\u7bc9\n-----------------------------\n\nbuild\u306b15\u5206\u7a0b\u5ea6\u5fc5\u8981\u3067\u3059\u3002\n\n```bash:\u30c0\u30a6\u30f3\u30ed\u30fc\u30c9\u3057\u305f\u30c7\u30a3\u30ec\u30af\u30c8\u30ea\u30fc\u3078\u79fb\u52d5\ncd ${HOME}/gpu-rest-engine\n```\n\n```bash:\u63a8\u8ad6\u30b5\u30fc\u30d0\u306e\u69cb\u7bc9\nsudo docker build -t inference_server -f Dockerfile.inference_server .\n```\n\n\n2.2 \u63a8\u8ad6\u30b5\u30fc\u30d0\u306e\u8d77\u52d5\n-----------------------------\n\n```bash:\u63a8\u8ad6\u30b5\u30fc\u30d0\u306e\u8d77\u52d5\nsudo nvidia-docker run --name=server --net=host --rm inference_server\n```\n\n```bash:result-example\n2016/05/06 04:30:51 Initializing Caffe classifiers\n2016/05/06 04:30:54 Adding REST endpoint /api/classify\n2016/05/06 04:30:54 Starting server listening on :8000\n```\n\n\n3. \u52d5\u4f5c\u78ba\u8a8d\n==============\n\n\u3053\u3053\u3067\u306e\u52d5\u4f5c\u78ba\u8a8d\u306f\u63a8\u8ad6\u30b5\u30fc\u30d0\u3068\u540c\u3058\u30de\u30b7\u30f3\u304b\u3089\u3001\u753b\u50cf\u3092\u30a2\u30c3\u30d7\u30ed\u30fc\u30c9\u3057\u3066\u3001\u305d\u306e\u753b\u50cf\u306b\u5199\u3063\u3066\u3044\u308b\n\u52d5\u7269\u3092\u63a8\u6e2c\u3057\u307e\u3059\u3002\n\n\u30b5\u30f3\u30d7\u30eb\u30a4\u30e1\u30fc\u30b8 images/1.jpg \u306e\u52d5\u7269\u3092\u63a8\u8ad6\u3059\u308b\n------------------------------------------\n\n\n![Kobito.G6nOer.png](https://qiita-image-store.s3.amazonaws.com/0/73207/311cfb8c-92b5-7cd9-6a4a-3ac915fabb85.png \"Kobito.G6nOer.png\")\n\n\n```bash:\u30a4\u30e1\u30fc\u30b8\u753b\u50cf\u306ePATH\u3092\u6c7a\u5b9a\nIMAGE=\"${HOME}/gpu-rest-engine/images/1.jpg\"\n```\n\n```bash:endpoint\u306e\u6307\u5b9a\nENDPOINT=\"http://127.0.0.1:8000/api/classify\"\n```\n\n```bash:\u5909\u6570\u306e\u78ba\u8a8d\ncat << ETX\n\nIMAGE_NAME : ${IMAGE} \nEND_POINT : ${ENDPOINT}\n\nETX\n```\n\n```bash:\u63a8\u8ad6\u30b5\u30fc\u30d0\u306eAPI\u3092\u30ad\u30c3\u30af\ncurl -XPOST --data-binary @${IMAGE} ${ENDPOINT} | jq .\n```\n\n```json:result\n[\n  {\n    \"label\": \"n02328150 Angora, Angora rabbit\",\n    \"confidence\": 0.9998\n  },\n  {\n    \"label\": \"n02325366 wood rabbit, cottontail, cottontail rabbit\",\n    \"confidence\": 0.0001\n  },\n  {\n    \"label\": \"n02326432 hare\",\n    \"confidence\": 0.0001\n  },\n  {\n    \"label\": \"n02085936 Maltese dog, Maltese terrier, Maltese\",\n    \"confidence\": 0\n  },\n  {\n    \"label\": \"n02342885 hamster\",\n    \"confidence\": 0\n  }\n]\n```\n\n\u30a4\u30f3\u30bf\u30fc\u30cd\u30c3\u30c8\u4e0a\u306e\u753b\u50cf\u3092\u63a8\u8ad6\u3059\u308b\n----------------------------------\n\n![\u3046\u3055\u304e](http://sozaing.com/wp-content/uploads/IMG_29451-540x360.jpg)\n\n```bash:\u753b\u50cf\u306eDownload\nwget http://sozaing.com/wp-content/uploads/IMG_29451-540x360.jpg -P ${HOME}/gpu-rest-engine/images\n```\n\n```bash:\u30a4\u30e1\u30fc\u30b8\u753b\u50cf\u306ePATH\u3092\u6c7a\u5b9a\nIMAGE=\"${HOME}/gpu-rest-engine/images/IMG_29451-540x360.jpg\"\n```\n\n```bash:\u5909\u6570\u306e\u78ba\u8a8d\ncat << ETX\n\nIMAGE_NAME : ${IMAGE} \nEND_POINT : ${ENDPOINT}\n\nETX\n```\n\n```bash:\u63a8\u8ad6\u30b5\u30fc\u30d0\u306eAPI\u3092\u30ad\u30c3\u30af\ncurl -XPOST --data-binary @${IMAGE} ${ENDPOINT} | jq .\n```\n\n\n```json:result\n[\n  {\n    \"label\": \"n02325366 wood rabbit, cottontail, cottontail rabbit\",\n    \"confidence\": 0.6424\n  },\n  {\n    \"label\": \"n02326432 hare\",\n    \"confidence\": 0.1461\n  },\n  {\n    \"label\": \"n02095889 Sealyham terrier, Sealyham\",\n    \"confidence\": 0.0929\n  },\n  {\n    \"label\": \"n02437616 llama\",\n    \"confidence\": 0.0161\n  },\n  {\n    \"label\": \"n02328150 Angora, Angora rabbit\",\n    \"confidence\": 0.0149\n  }\n]\n```\n\n4. Benchmarking\n==========================\n\n4.1 \u30c6\u30b9\u30c8\u7528 docker container \u306e\u69cb\u7bc9\n-------------------------------\n\n```bash:\u30c0\u30a6\u30f3\u30ed\u30fc\u30c9\u3057\u305f\u30c7\u30a3\u30ec\u30af\u30c8\u30ea\u30fc\u3078\u79fb\u52d5\ncd ${HOME}/gpu-rest-engine\n```\n\n```bash:command\nsudo docker build -t inference_client -f Dockerfile.inference_client .\n```\n\n4.2 \u30c6\u30b9\u30c8\u306e\u5b9f\u884c\n-----------------------------------\n\n```bash:benchmark-test\nsudo docker run -e CONCURRENCY=8 -e REQUESTS=20000 --net=host inference_client\n```\n\n```bash:result-example\nSummary:\n  Total:\t153.6530 secs\n  Slowest:\t0.0992 secs\n  Fastest:\t0.0198 secs\n  Average:\t0.0614 secs\n  Requests/sec:\t130.1634\n  Total data:\t6880000 bytes\n  Size/request:\t344 bytes\n\nStatus code distribution:\n  [200]\t20000 responses\n\nResponse time histogram:\n  0.020 [1]\t\t|\n  0.028 [0]\t\t|\n  0.036 [2]\t\t|\n  0.044 [5]\t\t|\n  0.052 [2]\t\t|\n  0.060 [548]\t|\u220e\n  0.067 [19139]\t|\u220e\u220e\u220e\u220e\u220e\u220e\u220e\u220e\u220e\u220e\u220e\u220e\u220e\u220e\u220e\u220e\u220e\u220e\u220e\u220e\u220e\u220e\u220e\u220e\u220e\u220e\u220e\u220e\u220e\u220e\u220e\u220e\u220e\u220e\u220e\u220e\u220e\u220e\u220e\u220e\n  0.075 [297]\t|\n  0.083 [3]\t\t|\n  0.091 [2]\t\t|\n  0.099 [1]\t\t|\n\nLatency distribution:\n  10% in 0.0610 secs\n  25% in 0.0612 secs\n  50% in 0.0614 secs\n  75% in 0.0616 secs\n  90% in 0.0619 secs\n  95% in 0.0623 secs\n  99% in 0.0691 secs\n```\n\n\n[GPU REST Engine]:https://github.com/NVIDIA/gpu-rest-engine\n\n\n------\n\n__\u3053\u306eQiita\u306e\u60c5\u5831\u306f\u3001\u304a\u3044\u3089\u304c\u30d7\u30e9\u30a4\u30d9\u30fc\u30c8\u3067\u4f5c\u3063\u3066\u3044\u308b\u3082\u306e\u3067\u3001NVIDIA\u3068\u306f\u7121\u95a2\u4fc2\u3067\u3059\u3002\u500b\u4eba\u8cac\u4efb\u3067\u304a\u8a66\u3057\u304f\u3060\u3055\u3044\u3002\u30a4\u30f3\u30b9\u30bf\u30f3\u30b9\u7b49\u306e\u6d88\u3057\u5fd8\u308c\u7b49\u3054\u6ce8\u610f\u304f\u3060\u3055\u3044\u3002__\n", "tags": ["GRE", "CUDA", "GPU", "AWS", "NVIDIA"]}