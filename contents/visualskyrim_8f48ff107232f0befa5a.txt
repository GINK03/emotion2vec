{"context": "This is a for-beginner tutorial for those who already understand how Kafka works and the basic functionality of Kerberos.\n\nPurpose\n\nSetup a simple pipeline for stream processing within the VMs.\nIntegrate Kafka with Kerberos' SASL authentication.\nConsole pipeline to check if our setup works.\n\nThe versions of components in this post will be:\n\nUbuntu: 16.04.1\nKafka: 0.10.1.0 with scala 2.11\nKerberos: 5\n\n\nPrepare the Servers\nWe are going to have 3 Ubuntu servers in the VirtualBox:\nserver-kerberos A server for Kerberos.\nserver-kafka A server for both Zookeeper and Kafka Broker.\nserver-kafka-client A server for Kafka clients(producer and consumer).\nYou can also make server-kafka-client into two different servers, but the setups for these two servers will be exactly the same.\nTo make things simple and clean, this post will only use one server to host both producer and consumer.\nFor the same reason, server-kafka can also be splited into two servers.\n\nInstallation of Kerberos and Kafka\nUse VirtualBox to create all these 3 servers with Ubuntu.\nGo to your VirtualBox manager, and make sure all your boxes' network adapters are set to NAT.\nFor server-kerberos:\nTo install kerberos, enter:\napt-get install krb5-admin-server krb5-kdc\n\nDuring the installation, you will be asked for several settings. Enter the settings like below:\n\nDefault Kerberos version 5 realm? [VISUALSKYRIM]\nKerberos servers for your realm? [kerberos.com]\nAdministrative server for your realm? [kerberos.com]\n\nFor server-kafka, server-kafka-client:\nInstall krb5-user for SASL authentication:\nsudo apt-get install krb5-user\n\nDuring this installation, you will be asked the same questions. Just answer them with the same answer:\n\nDefault Kerberos version 5 realm? [VISUALSKYRIM]\nKerberos servers for your realm? [kerberos.com]\nAdministrative server for your realm? [kerberos.com]\n\nThese question will generate a Kerberos config file under you /etc/krb5.config.\nInstall kafka:\nwget http://ftp.meisei-u.ac.jp/mirror/apache/dist/kafka/0.10.1.0/kafka_2.10-0.10.1.0.tgz\ntar -xzf kafka_2.11-0.10.1.0.tgz\ncd kafka_2.11-0.10.1.0\n\nLater in this post, you will need to transfer authentication files(keytabs) between servers.\nFor that purpose, this post will use scp, and openssh-server will be installed.\nIf you are going to use other methods to transfer files from server-kerberos, feel free to skip this installation.\napt-get install openssh-server\n\n\nSetting up servers\nBefore starting to set up servers, we need to change our VMs' network adapters to Host-Only and reboot to get an individual IP address for each VM.\nAfter that, go to each server to get their IP address by\nifconfig\n\nThen input those IP address and the hostnames into /etc/hosts. Something like this:\n192.168.56.104  kerberos.com\n192.168.56.106  kafka.com\n192.168.56.107  kafka-client.com\n\nThen make sure all these 3 servers can ping each other by using the hostname.\nAfter that, we start to set up our servers one by one:\n\nKerberos Server\nCreate the new realm.\nsudo krb5_newrealm\n\n\nThis might stuck at the place where command-line prompts Loading random data.\nIf this happens, run the following code first: cat /dev/sda > /dev/urandom\n\nThen edit /etc/krb5.conf.\nThe updated content should be like:\n[libdefaults]\n    default_realm = VISUALSKYRIM\n\n...\n\n[realms]\n    VISUALSKYRIM = {\n        kdc = kerberos.com\n        admin_server = kerberos.com\n    }\n\n...\n\n[domain_realm]\n    kerberos.com = VISUALSKYRIM\n\nNext, add principals for each of your roles:\n- zookeeper\n- kafka\n- kafka-client\n\nEnter:\n$ sudo kadmin.local\n\n> addprinc zookeeper\n> ktadd -k /tmp/zookeeper.keytab zookeeper\n> addprinc kafka\n> ktadd -k /tmp/kafka.keytab kafka\n> addprinc kafka-client\n> ktadd -k /tmp/kafka-client.keytab kafka-client\n\nMove /tmp/zookeeper.keytab and /tmp/kafka.keytab to your server-kafka, and move /tmp/kafka-client.keytab to your server-kafka-client.\n\nKafka Server\nJust like real world, every individual(program) in the distributed system must tell the authority(Kerberos) two things to identify itself:\nThe first thing is the accepted way for this role to be identified.\nIt's like in America, people usually use drive license, and in China people use ID card, while in Japan, people use so called MyNumber card.\nThe second thing is the file or document that identifies you according to your accepted identify method.\nThe file to identify the role in our SASL context, is the keytab file we generated via the kadmin just now.\nSuggest you put zookeeper.keytab and kafka.keytab under /etc/kafka/ of you server-kafka.\nWe need a way to tell our program where to find this file and how to hand it over to the authority(Kerberos). And that will be the JAAS file.\nWe create the JAAS files for Zookeeper and Kafka and put it to /etc/kafka/zookeeper_jaas.conf and /etc/kafka/kafka_jaas.conf.\nServer {\n  com.sun.security.auth.module.Krb5LoginModule required debug=true\n  useKeyTab=true\n  keyTab=\"/etc/kafka/zookeeper.keytab\"\n  storeKey=true\n  useTicketCache=false\n  principal=\"zookeeper@VISUALSKYRIM.COM\";\n};\n\nKafkaServer {\n  com.sun.security.auth.module.Krb5LoginModule required debug=true\n  useKeyTab=true\n  storeKey=true\n  keyTab=\"/etc/kafka/kafka.keytab\"\n  principal=\"kafka@VISUALSKYRIM.COM\";\n};\n\n// For Zookeeper Client\nClient {\n  com.sun.security.auth.module.Krb5LoginModule required debug=true\n  useKeyTab=true\n  storeKey=true\n  keyTab=\"/etc/kafka.keytab\"\n  principal=\"kafka@VISUALSKYRIM.COM\";\n};\n\nTo specify the locations of these JAAS file, we need to put the locations into JVM options like:\n-Djava.security.krb5.conf=/etc/krb5.conf\n-Djava.security.auth.login.config=/etc/kafka/zookeeper_jaas.conf\n-Dsun.security.krb5.debug=true\n\nand\n-Djava.security.krb5.conf=/etc/krb5.conf\n-Djava.security.auth.login.config=/etc/kafka/kafka_jaas.conf\n-Dsun.security.krb5.debug=true\n\nTo make this post easy and simple, I choose to modify the the bin/kafka-run-class.sh, bin/kafka-server-start.sh and bin/zookeeper-server-start.sh to insert those JVM options into the launch command.\nTo enable SASL authentication in Zookeeper and Kafka broker, simply uncomment and edit the config files config/zookeeper.properties and config/server.properties.\nFor config/zookeeper.properties:\nauthProvider.1=org.apache.zookeeper.server.auth.SASLAuthenticationProvider\njaasLoginRenew=3600000\nkerberos.removeHostFromPrincipal=true\nkerberos.removeRealmFromPrincipal=true\n\nFor config/server.properties:\nlisteners=SASL_PLAINTEXT://kafka.com:9092\nsecurity.inter.broker.protocol=SASL_PLAINTEXT\nsasl.mechanism.inter.broker.protocol=GSSAPI\nsasl.enabled.mechanism=GSSAPI\nsasl.kerberos.service.name=kafka\n\nThen start the Zookeeper and Kafka by:\n$ bin/zookeeper-server-start.sh config/server.properties\n$ bin/kafka-server-start.sh config/zookeeper.properties\n\n\nKafka Client Server\nThe setting up for you server-kafka-client is quite similar to what you've just done for server-kafka.\nFor JAAS file, because we are going to use the same principal and keytab for both producer and consumer in this case, we only need to create one single JAAS file /etc/kafka/kafka_client_jaas.conf:\nKafkaClient {\n  com.sun.security.auth.module.Krb5LoginModule required debug=true\n  useKeyTab=true\n  storeKey=true\n  keyTab=\"/etc/kafka-client.keytab\"\n  principal=\"kafka-client@VISUALSKYRIM.COM\";\n};\n\nWe also need to put JVM options to the bin/kafka-run-class.sh:\n-Djava.security.krb5.conf=/etc/krb5.conf\n-Djava.security.auth.login.config=/etc/kafka/kafka_client_jaas.conf\n-Dsun.security.krb5.debug=true\n\n\nGive it a try\nNow we can check if our setup actually works.\nFirst we start a console-producer:\nbin/kafka-console-producer.sh --broker-list kafka.com:9092 --topic test \\\n--producer-property security.protocol=SASL_PLAINTEXT \\\n--producer-property sasl.mechasim=GSSAPI \\\n--producer-property sasl.kerberos.service.name=kafka\n\nAnd start a console-comsumer:\nbin/kafka-console-consumer.sh --bootstrap-server ssh.com:9092 --topic test \\\n--consumer-property security.protocol=SASL_PLAINTEXT \\\n--consumer-property sasl.mechasim=GSSAPI \\\n--consumer-property sasl.kerberos.service.name=kafka\n\nThen input some message into the console-producer to see if the same message prompted in console-consumer after a few seconds.\n\n***This is a for-beginner tutorial for those who already understand how Kafka works and the basic functionality of Kerberos.***\n\n# Purpose\n\n- Setup a simple pipeline for stream processing within the VMs.\n- Integrate Kafka with Kerberos' SASL authentication.\n- Console pipeline to check if our setup works.\n\nThe versions of components in this post will be:\n\n- Ubuntu: 16.04.1\n- Kafka: 0.10.1.0 with scala 2.11\n- Kerberos: 5\n\n# Prepare the Servers\n\nWe are going to have 3 Ubuntu servers in the VirtualBox:\n\n***server-kerberos*** A server for Kerberos.\n***server-kafka*** A server for both Zookeeper and Kafka Broker.\n***server-kafka-client*** A server for Kafka clients(producer and consumer).\n\nYou can also make ***server-kafka-client*** into two different servers, but the setups for these two servers will be exactly the same.\nTo make things simple and clean, *this post will only use one server to host both producer and consumer*.\n\nFor the same reason, ***server-kafka*** can also be splited into two servers.\n\n## Installation of Kerberos and Kafka\n\nUse VirtualBox to create all these 3 servers with Ubuntu.\nGo to your VirtualBox manager, and make sure all your boxes' network adapters are set to NAT.\n\nFor ***server-kerberos***:\n\nTo install kerberos, enter:\n\n```\napt-get install krb5-admin-server krb5-kdc\n```\n\nDuring the installation, you will be asked for several settings. Enter the settings like below:\n\n> *Default Kerberos version 5 realm?* [VISUALSKYRIM]\n>\n> *Kerberos servers for your realm?* [kerberos.com]\n>\n> *Administrative server for your realm?* [kerberos.com]\n\n\nFor ***server-kafka***, ***server-kafka-client***:\n\nInstall krb5-user for SASL authentication:\n\n```\nsudo apt-get install krb5-user\n```\n\nDuring this installation, you will be asked the same questions. Just answer them with the same answer:\n\n> *Default Kerberos version 5 realm?* [VISUALSKYRIM]\n>\n> *Kerberos servers for your realm?* [kerberos.com]\n>\n> *Administrative server for your realm?* [kerberos.com]\n\n\nThese question will generate a Kerberos config file under you */etc/krb5.config*.\n\n\nInstall kafka:\n\n```\nwget http://ftp.meisei-u.ac.jp/mirror/apache/dist/kafka/0.10.1.0/kafka_2.10-0.10.1.0.tgz\ntar -xzf kafka_2.11-0.10.1.0.tgz\ncd kafka_2.11-0.10.1.0\n```\n\nLater in this post, you will need to transfer authentication files(keytabs) between servers.\nFor that purpose, this post will use *scp*, and *openssh-server* will be installed.\n\nIf you are going to use other methods to transfer files from ***server-kerberos***, feel free to skip this installation.\n\n```\napt-get install openssh-server\n```\n\n## Setting up servers\n\nBefore starting to set up servers, we need to change our VMs' network adapters to **Host-Only** and reboot to get an individual IP address for each VM.\n\nAfter that, go to each server to get their IP address by\n\n```\nifconfig\n```\n\nThen input those IP address and the hostnames into */etc/hosts*. Something like this:\n\n```\n192.168.56.104  kerberos.com\n192.168.56.106  kafka.com\n192.168.56.107  kafka-client.com\n```\n\nThen make sure all these 3 servers can ping each other by using the hostname.\n\nAfter that, we start to set up our servers one by one:\n\n### Kerberos Server\n\nCreate the new realm.\n\n```\nsudo krb5_newrealm\n```\n\n> This might stuck at the place where command-line prompts *Loading random data*.\n>\n> If this happens, run the following code first: *cat /dev/sda > /dev/urandom*\n\nThen edit */etc/krb5.conf*.\n\nThe updated content should be like:\n\n```\n[libdefaults]\n    default_realm = VISUALSKYRIM\n\n...\n\n[realms]\n    VISUALSKYRIM = {\n        kdc = kerberos.com\n        admin_server = kerberos.com\n    }\n\n...\n\n[domain_realm]\n    kerberos.com = VISUALSKYRIM\n```\n\nNext, add principals for each of your roles:\n\n```\n- zookeeper\n- kafka\n- kafka-client\n```\n\nEnter:\n\n```\n$ sudo kadmin.local\n\n> addprinc zookeeper\n> ktadd -k /tmp/zookeeper.keytab zookeeper\n> addprinc kafka\n> ktadd -k /tmp/kafka.keytab kafka\n> addprinc kafka-client\n> ktadd -k /tmp/kafka-client.keytab kafka-client\n```\n\nMove */tmp/zookeeper.keytab* and */tmp/kafka.keytab* to your ***server-kafka***, and move */tmp/kafka-client.keytab* to your ***server-kafka-client***.\n\n### Kafka Server\n\nJust like real world, every individual(program) in the distributed system must tell the authority(Kerberos) two things to identify itself:\n\nThe first thing is the accepted way for this role to be identified.\nIt's like in America, people usually use drive license, and in China people use ID card, while in Japan, people use so called MyNumber card.\n\nThe second thing is the file or document that identifies you according to your accepted identify method.\n\nThe file to identify the role in our SASL context, is the keytab file we generated via the *kadmin* just now.\n\nSuggest you put *zookeeper.keytab* and *kafka.keytab* under */etc/kafka/* of you ***server-kafka***.\n\nWe need a way to tell our program where to find this file and how to hand it over to the authority(Kerberos). And that will be the JAAS file.\n\nWe create the JAAS files for Zookeeper and Kafka and put it to */etc/kafka/zookeeper_jaas.conf* and */etc/kafka/kafka_jaas.conf*.\n\n```\nServer {\n  com.sun.security.auth.module.Krb5LoginModule required debug=true\n  useKeyTab=true\n  keyTab=\"/etc/kafka/zookeeper.keytab\"\n  storeKey=true\n  useTicketCache=false\n  principal=\"zookeeper@VISUALSKYRIM.COM\";\n};\n```\n\n\n```\nKafkaServer {\n  com.sun.security.auth.module.Krb5LoginModule required debug=true\n  useKeyTab=true\n  storeKey=true\n  keyTab=\"/etc/kafka/kafka.keytab\"\n  principal=\"kafka@VISUALSKYRIM.COM\";\n};\n\n// For Zookeeper Client\nClient {\n  com.sun.security.auth.module.Krb5LoginModule required debug=true\n  useKeyTab=true\n  storeKey=true\n  keyTab=\"/etc/kafka.keytab\"\n  principal=\"kafka@VISUALSKYRIM.COM\";\n};\n```\n\nTo specify the locations of these JAAS file, we need to put the locations into JVM options like:\n\n```\n-Djava.security.krb5.conf=/etc/krb5.conf\n-Djava.security.auth.login.config=/etc/kafka/zookeeper_jaas.conf\n-Dsun.security.krb5.debug=true\n```\n\nand\n\n```\n-Djava.security.krb5.conf=/etc/krb5.conf\n-Djava.security.auth.login.config=/etc/kafka/kafka_jaas.conf\n-Dsun.security.krb5.debug=true\n```\n\nTo make this post easy and simple, I choose to modify the the *bin/kafka-run-class.sh*, *bin/kafka-server-start.sh* and *bin/zookeeper-server-start.sh* to insert those JVM options into the launch command.\n\nTo enable SASL authentication in Zookeeper and Kafka broker, simply uncomment and edit the config files *config/zookeeper.properties* and *config/server.properties*.\n\nFor *config/zookeeper.properties*:\n\n```\nauthProvider.1=org.apache.zookeeper.server.auth.SASLAuthenticationProvider\njaasLoginRenew=3600000\nkerberos.removeHostFromPrincipal=true\nkerberos.removeRealmFromPrincipal=true\n```\n\nFor *config/server.properties*:\n\n```\nlisteners=SASL_PLAINTEXT://kafka.com:9092\nsecurity.inter.broker.protocol=SASL_PLAINTEXT\nsasl.mechanism.inter.broker.protocol=GSSAPI\nsasl.enabled.mechanism=GSSAPI\nsasl.kerberos.service.name=kafka\n```\n\nThen start the Zookeeper and Kafka by:\n\n```\n$ bin/zookeeper-server-start.sh config/server.properties\n$ bin/kafka-server-start.sh config/zookeeper.properties\n```\n\n### Kafka Client Server\n\nThe setting up for you ***server-kafka-client*** is quite similar to what you've just done for ***server-kafka***.\n\nFor JAAS file, because we are going to use the same principal and keytab for both producer and consumer in this case, we only need to create one single JAAS file */etc/kafka/kafka_client_jaas.conf*:\n\n```\nKafkaClient {\n  com.sun.security.auth.module.Krb5LoginModule required debug=true\n  useKeyTab=true\n  storeKey=true\n  keyTab=\"/etc/kafka-client.keytab\"\n  principal=\"kafka-client@VISUALSKYRIM.COM\";\n};\n```\n\nWe also need to put JVM options to the *bin/kafka-run-class.sh*:\n\n```\n-Djava.security.krb5.conf=/etc/krb5.conf\n-Djava.security.auth.login.config=/etc/kafka/kafka_client_jaas.conf\n-Dsun.security.krb5.debug=true\n```\n\n## Give it a try\n\nNow we can check if our setup actually works.\n\nFirst we start a console-producer:\n\n```\nbin/kafka-console-producer.sh --broker-list kafka.com:9092 --topic test \\\n--producer-property security.protocol=SASL_PLAINTEXT \\\n--producer-property sasl.mechasim=GSSAPI \\\n--producer-property sasl.kerberos.service.name=kafka\n```\n\n\nAnd start a console-comsumer:\n\n```\nbin/kafka-console-consumer.sh --bootstrap-server ssh.com:9092 --topic test \\\n--consumer-property security.protocol=SASL_PLAINTEXT \\\n--consumer-property sasl.mechasim=GSSAPI \\\n--consumer-property sasl.kerberos.service.name=kafka\n```\n\nThen input some message into the console-producer to see if the same message prompted in console-consumer after a few seconds.\n", "tags": ["Kafka", "StreamProcessing", "SASL", "Kerberos"]}