{"context": " More than 1 year has passed since last update.\u5f8c\u8ff0\u3059\u308b\u30b5\u30a4\u30c8\u306e\u60c5\u5831\u3092\u53c2\u8003\u306b\u3057\u305f\u3089\u3001\u5272\u3068\u3059\u3093\u306a\u308a\u52d5\u304d\u307e\u3057\u305f\u3002\n\u305f\u3060\u3001\u3084\u3084\u52d5\u4f5c\u306b\u96e3\u304c\u3042\u3063\u305f\u308a\u3001\u30a8\u30f3\u30b3\u30fc\u30c9\u6cbc\u306b\u306f\u307e\u308a\u305d\u3046\u306b\u306a\u3063\u305f\u308a\u3057\u3066\u3001\u5de5\u592b\u3057\u3066\u30b3\u30fc\u30c9\u3092\u66f8\u304b\u306a\u3044\u3068\u3044\u3051\u306a\u304b\u3063\u305f\u306e\u3067\u3001\u5927\u5909\u3067\u3057\u305f\u3002\n\nMeCab.Tagger.parseToNode(str) \u304c\u6b63\u5e38\u306b\u52d5\u4f5c\u3057\u306a\u3044\nstr(res.surface.encode())\u3068\u66f8\u304b\u306a\u3044\u3068\u5358\u8a9e\u304c\u53d6\u5f97\u3067\u304d\u306a\u304b\u3063\u305f\u308a\u3001\u3068\u304d\u3069\u304dres.surface\u304c\u53d6\u5f97\u3067\u304d\u306a\u304b\u3063\u305f\u308a\u3068\u3001\u52d5\u4f5c\u304c\u4e0d\u5b89\u5b9a\u3067\u3059\u3002\n\u7d50\u5c40\u3001MeCab.Tagger.parse(str)\u3092\u884c\u3054\u3068\u306bfor\u3067\u56de\u3057\u3066\u30c7\u30fc\u30bf\u3092\u53d6\u5f97\u3059\u308b\u3088\u3046\u306b\u3057\u307e\u3057\u305f\u3002\n\n\u30b3\u30fc\u30c9\n# coding=utf-8\n\ndef is575(text, amari=False, tarazu=False, partial=False):\n    import MeCab\n    import re\n    mt = MeCab.Tagger()\n    res = mt.parse(text)\n    lensum = [0]\n    pat = re.compile(r'[\u3083\u3085\u3087\u30e3\u30e5\u30e7]')\n\n    for s in res.splitlines():\n        if s == 'EOS': continue\n        surface, feature = s.split(\"\\t\")\n        features = feature.split(\",\")\n        if features[0] != '\u8a18\u53f7':\n            if len(features) >= 8:\n                lensum.append(lensum[-1] + len(pat.sub('', features[7])))\n            else:\n                lensum.append(lensum[-1] + len(pat.sub('', surface)))\n\n    senryu = 5, 7, 5\n    offset = 0\n    start = 0\n    end = 1\n\n    while start < len(lensum) and offset < 3:\n        if(any([\n        lensum[end] - lensum[start] == senryu[offset],\n        tarazu and lensum[end] - lensum[start] == senryu[offset]-1,\n        amari and lensum[end] - lensum[start] == senryu[offset]+1])):\n            offset += 1\n            start = end\n            end = start + 1\n            if partial and offset == 3:\n                return True\n        else:\n            end += 1\n            if end == len(lensum):\n                if partial:\n                    offset = 0\n                    start += 1\n                    end = start + 1\n                else:\n                    break\n\n    return offset == 3\n\nif __name__ == '__main__':\n    assert is575('\u4e94\u6708\u96e8\u3092\u96c6\u3081\u3066\u65e9\u3057\u6700\u4e0a\u5ddd')\n    assert is575('\u3046\u3080\u3001\u4e94\u6708\u96e8\u3092\u96c6\u3081\u3066\u65e9\u3057\u6700\u4e0a\u5ddd\u3068\u306f\u3088\u304f\u8a00\u3063\u305f\u3082\u306e\u3067\u3059\u3088', partial=True)\n\n\u5f15\u6570\u306b\u3001amari=True tarazu=True \u3092\u6e21\u3059\u3068\u3001\u305d\u308c\u305e\u308c\u5b57\u4f59\u308a\u30fb\u5b57\u8db3\u3089\u305a\u3092\u8a31\u5bb9\u3059\u308b\u3088\u3046\u306b\u306a\u308a\u307e\u3059\u3002\n\u5fdc\u7528\u3059\u308c\u307057577\u30847775\u3082\u5224\u5b9a\u3067\u304d\u308b\u3057\u3001\u6587\u7ae0\u5185\u306b575\u304c\u3042\u308b\u304b\u3069\u3046\u304b\u306e\u5224\u5b9a\u3060\u3063\u3066\u3067\u304d\u308b\u3088\u3046\u306b\u306a\u308a\u307e\u3059\u3002\n\n\u304d\u3063\u304b\u3051\n575\u3063\u3066\u697d\u3057\u304f\u306a\u3044\uff1f\n\n\u53c2\u8003\n\nMeCab: Yet Another Part-of-Speech and Morphological Analyzer\nPython\u304b\u3089MeCab\uff08\u3068CaboCha\uff09\u3092\u4f7f\u3046\u307e\u3067\nMeCab\u3092Python3\u304b\u3089\u4f7f\u3046(\u4e2d\u9593\u5831\u544a)\n\n\u5f8c\u8ff0\u3059\u308b\u30b5\u30a4\u30c8\u306e\u60c5\u5831\u3092\u53c2\u8003\u306b\u3057\u305f\u3089\u3001\u5272\u3068\u3059\u3093\u306a\u308a\u52d5\u304d\u307e\u3057\u305f\u3002\n\u305f\u3060\u3001\u3084\u3084\u52d5\u4f5c\u306b\u96e3\u304c\u3042\u3063\u305f\u308a\u3001\u30a8\u30f3\u30b3\u30fc\u30c9\u6cbc\u306b\u306f\u307e\u308a\u305d\u3046\u306b\u306a\u3063\u305f\u308a\u3057\u3066\u3001\u5de5\u592b\u3057\u3066\u30b3\u30fc\u30c9\u3092\u66f8\u304b\u306a\u3044\u3068\u3044\u3051\u306a\u304b\u3063\u305f\u306e\u3067\u3001\u5927\u5909\u3067\u3057\u305f\u3002\n\n## MeCab.Tagger.parseToNode(str) \u304c\u6b63\u5e38\u306b\u52d5\u4f5c\u3057\u306a\u3044\n`str(res.surface.encode())`\u3068\u66f8\u304b\u306a\u3044\u3068\u5358\u8a9e\u304c\u53d6\u5f97\u3067\u304d\u306a\u304b\u3063\u305f\u308a\u3001\u3068\u304d\u3069\u304d`res.surface`\u304c\u53d6\u5f97\u3067\u304d\u306a\u304b\u3063\u305f\u308a\u3068\u3001\u52d5\u4f5c\u304c\u4e0d\u5b89\u5b9a\u3067\u3059\u3002\n\u7d50\u5c40\u3001`MeCab.Tagger.parse(str)`\u3092\u884c\u3054\u3068\u306bfor\u3067\u56de\u3057\u3066\u30c7\u30fc\u30bf\u3092\u53d6\u5f97\u3059\u308b\u3088\u3046\u306b\u3057\u307e\u3057\u305f\u3002\n## \u30b3\u30fc\u30c9\n```py3\n# coding=utf-8\n\ndef is575(text, amari=False, tarazu=False, partial=False):\n    import MeCab\n    import re\n    mt = MeCab.Tagger()\n    res = mt.parse(text)\n    lensum = [0]\n    pat = re.compile(r'[\u3083\u3085\u3087\u30e3\u30e5\u30e7]')\n\n    for s in res.splitlines():\n        if s == 'EOS': continue\n        surface, feature = s.split(\"\\t\")\n        features = feature.split(\",\")\n        if features[0] != '\u8a18\u53f7':\n            if len(features) >= 8:\n                lensum.append(lensum[-1] + len(pat.sub('', features[7])))\n            else:\n                lensum.append(lensum[-1] + len(pat.sub('', surface)))\n\n    senryu = 5, 7, 5\n    offset = 0\n    start = 0\n    end = 1\n\n    while start < len(lensum) and offset < 3:\n        if(any([\n        lensum[end] - lensum[start] == senryu[offset],\n        tarazu and lensum[end] - lensum[start] == senryu[offset]-1,\n        amari and lensum[end] - lensum[start] == senryu[offset]+1])):\n            offset += 1\n            start = end\n            end = start + 1\n            if partial and offset == 3:\n                return True\n        else:\n            end += 1\n            if end == len(lensum):\n                if partial:\n                    offset = 0\n                    start += 1\n                    end = start + 1\n                else:\n                    break\n    \n    return offset == 3\n\nif __name__ == '__main__':\n    assert is575('\u4e94\u6708\u96e8\u3092\u96c6\u3081\u3066\u65e9\u3057\u6700\u4e0a\u5ddd')\n    assert is575('\u3046\u3080\u3001\u4e94\u6708\u96e8\u3092\u96c6\u3081\u3066\u65e9\u3057\u6700\u4e0a\u5ddd\u3068\u306f\u3088\u304f\u8a00\u3063\u305f\u3082\u306e\u3067\u3059\u3088', partial=True)\n```\n\u5f15\u6570\u306b\u3001`amari=True` `tarazu=True` \u3092\u6e21\u3059\u3068\u3001\u305d\u308c\u305e\u308c\u5b57\u4f59\u308a\u30fb\u5b57\u8db3\u3089\u305a\u3092\u8a31\u5bb9\u3059\u308b\u3088\u3046\u306b\u306a\u308a\u307e\u3059\u3002\n\u5fdc\u7528\u3059\u308c\u307057577\u30847775\u3082\u5224\u5b9a\u3067\u304d\u308b\u3057\u3001\u6587\u7ae0\u5185\u306b575\u304c\u3042\u308b\u304b\u3069\u3046\u304b\u306e\u5224\u5b9a\u3060\u3063\u3066\u3067\u304d\u308b\u3088\u3046\u306b\u306a\u308a\u307e\u3059\u3002\n## \u304d\u3063\u304b\u3051\n575\u3063\u3066\u697d\u3057\u304f\u306a\u3044\uff1f\n## \u53c2\u8003\n- [MeCab: Yet Another Part-of-Speech and Morphological Analyzer](http://taku910.github.io/mecab/)\n- [Python\u304b\u3089MeCab\uff08\u3068CaboCha\uff09\u3092\u4f7f\u3046\u307e\u3067](http://qiita.com/yoshikyoto/items/1a6de08a639f053b2d0a)\n- [MeCab\u3092Python3\u304b\u3089\u4f7f\u3046(\u4e2d\u9593\u5831\u544a)](http://shogo82148.github.io/blog/2015/06/02/mecab-in-python3/)\n", "tags": ["python3", "mecab", "\u81ea\u7136\u8a00\u8a9e\u51e6\u7406", "Python"]}