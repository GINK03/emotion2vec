{"context": "\n\n\u203b \u4f5c\u6210\u4e2d\n\n\u8abf\u3079\u305f\u3053\u3068\u3092\u3001\u5c11\u3057\u305a\u3064 \u66f8\u3044\u3066\u3044\u304d\u307e\u3059\u3002\n\n\n\u4ee5\u4e0b\u306e\u8ad6\u6587 \u306e Related Works \u3068\u3057\u3066 \u5f15\u7528\u3055\u308c\u3066\u3044\u308b Paper\u3002\n\n\nHtena::Diary shi3z\u306e\u9577\u6587\u65e5\u8a18 \uff082016-09-09\uff09\u300c\u9759\u6b62\u753b\u3092\u898b\u305b\u308b\u3068\u52d5\u753b\u3092\u81ea\u52d5\u751f\u6210\u3059\u308b\u30cb\u30e5\u30fc\u30e9\u30eb\u30fb\u30cd\u30c3\u30c8\u30ef\u30fc\u30af\u3092MIT\u304c\u958b\u767a\u300d\n\n\nCarl Vondrick, Hamed Pirsiavash, Antonio Torralba, Generating Videos with Scene Dynamics, NIPS 2016\n\nAdversarial Learning\n\nGoodfellow et al. ,_Generative Adversarial Networks\nDenton et al , Deep Generative Image Models using a Laplacian Pyramid of Adversarial Networks\nRadford et al., Unsupervised Representation Learning with Deep Convolutional Generative Adversarial Networks\nPathak et al., Context Encoders: Feature Learning by Inpainting\nWang and Gupta., Generative Image Modeling using Style and Structure Adversarial Networks\nReed et al., Generative Adversarial Text to Image Synthesis\n\nGenerative Models of Video\n\u2022 Petrovic et al., Recursive estimation of generative models of video\n\u2022 Ranzato et al., Video (language) modeling: a baseline for generative models of natural videos\n\u2022Walker et al., Patch to the Future: Unsupervised Visual Prediction\n\u2022Srivastava et al., Unsupervised Learning of Video Representations using LSTMs\n\u2022Mathieu et al., Deep multi-scale video prediction beyond mean square error\n\u2022Walker et al., An Uncertain Future: Forecasting from Static Images using Variational Autoencoders\n\u2022Xue _et al., Visual Dynamics: Probabilistic Future Frame Synthesis via Cross Convolutional Networks\n\n\n\uff08 \u5b9f\u88c5\u30b3\u30fc\u30c9 \uff09\n\n\nGitHub cvondrick/videogan Generating Videos with Scene Dynamics\n\n\nCarl Vondrick\nComputer Vision + Machine Learning\nMIT\nCambridge, MA\n\n##__\u203b \u4f5c\u6210\u4e2d__\n\n\u8abf\u3079\u305f\u3053\u3068\u3092\u3001\u5c11\u3057\u305a\u3064 \u66f8\u3044\u3066\u3044\u304d\u307e\u3059\u3002\n\n___\n\n####__\u4ee5\u4e0b\u306e\u8ad6\u6587 \u306e Related Works \u3068\u3057\u3066 \u5f15\u7528\u3055\u308c\u3066\u3044\u308b Paper\u3002__\n\n* [Htena::Diary shi3z\u306e\u9577\u6587\u65e5\u8a18 \uff082016-09-09\uff09\u300c\u9759\u6b62\u753b\u3092\u898b\u305b\u308b\u3068\u52d5\u753b\u3092\u81ea\u52d5\u751f\u6210\u3059\u308b\u30cb\u30e5\u30fc\u30e9\u30eb\u30fb\u30cd\u30c3\u30c8\u30ef\u30fc\u30af\u3092MIT\u304c\u958b\u767a\u300d](http://d.hatena.ne.jp/shi3z/20160909/1473363354)\n\n####__[Carl Vondrick, Hamed Pirsiavash, Antonio Torralba, _Generating Videos with Scene Dynamics_, NIPS 2016](http://web.mit.edu/vondrick/tinyvideo/)__\n\n__Adversarial Learning__\n\n* [Goodfellow et _al. ,_Generative Adversarial Networks_](https://arxiv.org/abs/1406.2661)\n\n* [Denton _et al , Deep Generative Image Models using a Laplacian Pyramid of Adversarial Networks_](https://arxiv.org/abs/1506.05751)\n\n* [Radford _et al., Unsupervised Representation Learning with Deep Convolutional Generative Adversarial Networks_](https://arxiv.org/abs/1511.06434)\n\n* [Pathak _et al., Context Encoders: Feature Learning by Inpainting_](https://arxiv.org/abs/1604.07379)\n\n* [Wang and Gupta., _Generative Image Modeling using Style and Structure Adversarial Networks_](https://arxiv.org/abs/1603.05631)\n\n* [Reed _et al., Generative Adversarial Text to Image Synthesis_](https://arxiv.org/abs/1605.05396)\n\n__Generative Models of Video__\n\n\u2022 [Petrovic _et al., Recursive estimation of generative models of video_](http://ieeexplore.ieee.org/document/1640744/?arnumber=1640744)\n\n\u2022 [Ranzato _et al., Video (language) modeling: a baseline for generative models of natural videos_](https://arxiv.org/abs/1412.6604)\n\n\u2022[Walker _et al., Patch to the Future: Unsupervised Visual Prediction_]( )\n\n\u2022[Srivastava _et al., Unsupervised Learning of Video Representations using LSTMs_](http://www.ri.cmu.edu/pub_files/2014/3/egpaper_final.pdf)\n\n\u2022[Mathieu _et al., Deep multi-scale video prediction beyond mean square error_](https://arxiv.org/abs/1511.05440)\n\n\u2022[Walker _et al., An Uncertain Future: Forecasting from Static Images using Variational Autoencoders_](https://arxiv.org/abs/1606.07873)\n\n\u2022[Xue _et al., Visual Dynamics: Probabilistic Future Frame Synthesis via Cross Convolutional Networks](https://arxiv.org/abs/1607.02586)\n\n\n\n\n\n\n\n\n\n___\n\n####__\uff08 \u5b9f\u88c5\u30b3\u30fc\u30c9 \uff09__\n\n* [GitHub cvondrick/videogan _Generating Videos with Scene Dynamics_](https://github.com/cvondrick/videogan)\n\n>__Carl Vondrick__\n>\n>Computer Vision + Machine Learning\n>\n>MIT\n>Cambridge, MA\n", "tags": ["\u753b\u50cf\u51e6\u7406", "\u753b\u50cf\u8a8d\u8b58", "DeepLearning", "\u4eba\u5de5\u77e5\u80fd", "\u6df1\u5c64\u5b66\u7fd2"]}